INFO 06-01 00:47:00 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:47:01 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_16-16-32/adapters_32_slots_32_rate_3.2-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_16-16-32/adapters_32_slots_32_rate_3.2-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 1080, 270, 270, 1080, 270, 34560, 1080, 270, 270, 270, 34560, 34560, 270, 270, 1080, 1080, 1080, 34560, 34560, 270, 34560, 34560, 34560, 34560, 1080, 270, 1080, 1080, 1080, 1080, 34560]
Prompts retrieved: 394740 . Total input tokens: 87955617 . Total output tokens: 78939968
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.599117144010961,
    "estimated_duration": 3600.0273063315462,
    "input_throughput": 8258.69985700099,
    "output_throughput": 7240.027583723999,
    "total_throughput": 15498.727440724988,
    "itl": 117.32809333381716,
    "ttft": 456081.1781685343,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145733,
    "arrivals": 131339,
    "finished_requests": 119439,
    "scheduler_time": 94.78006878019991
}
#Debug simulation 
Total elapsed time: 8.59923774190247. Arrivals time: 0.34460677625611424 Scheduler time: 8.120172203052789 Scheduler overhead time: 0.04866349510848522 Adapter cache time: 0.013095457572489977 Engine time: 0.05030905595049262 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-8/adapters_32_slots_32_rate_3.2-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-8/adapters_32_slots_32_rate_3.2-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 1080, 135, 135, 1080, 135, 34560, 1080, 135, 135, 135, 34560, 34560, 135, 135, 1080, 1080, 1080, 34560, 34560, 135, 34560, 34560, 34560, 34560, 1080, 135, 1080, 1080, 1080, 1080, 34560]
Prompts retrieved: 393390 . Total input tokens: 87639207 . Total output tokens: 78675947
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 8.760337283834815,
    "estimated_duration": 3600.0013892583543,
    "input_throughput": 8358.383996679224,
    "output_throughput": 7337.144390780794,
    "total_throughput": 15695.528387460017,
    "itl": 115.8095556913613,
    "ttft": 380894.4484703093,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 130909,
    "finished_requests": 120959,
    "scheduler_time": 97.2129111303467
}
#Debug simulation 
Total elapsed time: 8.76046787481755. Arrivals time: 0.3439382207579911 Scheduler time: 8.28133790101856 Scheduler overhead time: 0.04913124209269881 Adapter cache time: 0.013028963934630156 Engine time: 0.05034712329506874 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-16/adapters_32_slots_32_rate_3.2-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-16/adapters_32_slots_32_rate_3.2-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 1080, 135, 135, 1080, 135, 34560, 1080, 135, 135, 135, 34560, 34560, 135, 135, 1080, 1080, 1080, 34560, 34560, 135, 34560, 34560, 34560, 34560, 1080, 135, 1080, 1080, 1080, 1080, 34560]
Prompts retrieved: 393390 . Total input tokens: 87639207 . Total output tokens: 78675947
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.745862344745547,
    "estimated_duration": 3600.0442284729206,
    "input_throughput": 8358.284534955217,
    "output_throughput": 7337.057081435988,
    "total_throughput": 15695.341616391206,
    "itl": 115.80972927336622,
    "ttft": 380892.58164615737,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255728,
    "arrivals": 130909,
    "finished_requests": 120959,
    "scheduler_time": 97.21428186952522
}
#Debug simulation 
Total elapsed time: 8.745993120595813. Arrivals time: 0.36191316973418 Scheduler time: 8.248172347433865 Scheduler overhead time: 0.0493972497060895 Adapter cache time: 0.01332400320097804 Engine time: 0.05036843800917268 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-32/adapters_32_slots_32_rate_3.2-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-32/adapters_32_slots_32_rate_3.2-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 1080, 135, 135, 1080, 135, 34560, 1080, 135, 135, 135, 34560, 34560, 135, 135, 1080, 1080, 1080, 34560, 34560, 135, 34560, 34560, 34560, 34560, 1080, 135, 1080, 1080, 1080, 1080, 34560]
Prompts retrieved: 393390 . Total input tokens: 87639207 . Total output tokens: 78675947
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.675871382001787,
    "estimated_duration": 3600.044265195611,
    "input_throughput": 8358.284449695517,
    "output_throughput": 7337.057006593443,
    "total_throughput": 15695.341456288961,
    "itl": 115.80973913733958,
    "ttft": 380892.6078062049,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033042,
    "arrivals": 130909,
    "finished_requests": 120959,
    "scheduler_time": 97.21427647254484
}
#Debug simulation 
Total elapsed time: 8.676036522723734. Arrivals time: 0.34649053029716015 Scheduler time: 8.193039858713746 Scheduler overhead time: 0.04949857108294964 Adapter cache time: 0.012950375210493803 Engine time: 0.05137331550940871 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-16/adapters_32_slots_32_rate_3.2-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-16/adapters_32_slots_32_rate_3.2-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 1080, 135, 135, 1080, 135, 34560, 1080, 135, 135, 135, 34560, 34560, 135, 135, 1080, 1080, 1080, 34560, 34560, 135, 34560, 34560, 34560, 34560, 1080, 135, 1080, 1080, 1080, 1080, 34560]
Prompts retrieved: 393390 . Total input tokens: 87639207 . Total output tokens: 78675947
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 8.744920426979661,
    "estimated_duration": 3600.0407863684036,
    "input_throughput": 8358.292526556052,
    "output_throughput": 7337.064096611321,
    "total_throughput": 15695.356623167372,
    "itl": 115.81011337625463,
    "ttft": 380893.68084245676,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971348,
    "arrivals": 130909,
    "finished_requests": 120959,
    "scheduler_time": 97.21419404274204
}
#Debug simulation 
Total elapsed time: 8.745036751031876. Arrivals time: 0.3439165223389864 Scheduler time: 8.265563729219139 Scheduler overhead time: 0.0494418335147202 Adapter cache time: 0.012530290987342596 Engine time: 0.050582746509462595 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-32/adapters_32_slots_32_rate_3.2-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-32/adapters_32_slots_32_rate_3.2-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 1080, 135, 135, 1080, 135, 34560, 1080, 135, 135, 135, 34560, 34560, 135, 135, 1080, 1080, 1080, 34560, 34560, 135, 34560, 34560, 34560, 34560, 1080, 135, 1080, 1080, 1080, 1080, 34560]
Prompts retrieved: 393390 . Total input tokens: 87639207 . Total output tokens: 78675947
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 8.744185700081289,
    "estimated_duration": 3600.0500642690895,
    "input_throughput": 8358.270985908955,
    "output_throughput": 7337.045187832054,
    "total_throughput": 15695.31617374101,
    "itl": 115.80976865989531,
    "ttft": 380895.31319588725,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089388,
    "arrivals": 130909,
    "finished_requests": 120959,
    "scheduler_time": 97.21427345791
}
#Debug simulation 
Total elapsed time: 8.744317492004484. Arrivals time: 0.35003282502293587 Scheduler time: 8.258803682867438 Scheduler overhead time: 0.04946110397577286 Adapter cache time: 0.012911080848425627 Engine time: 0.05041444627568126 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-16/adapters_32_slots_32_rate_3.2-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-16/adapters_32_slots_32_rate_3.2-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 1080, 135, 135, 1080, 135, 34560, 1080, 135, 135, 135, 34560, 34560, 135, 135, 1080, 1080, 1080, 34560, 34560, 135, 34560, 34560, 34560, 34560, 1080, 135, 1080, 1080, 1080, 1080, 34560]
Prompts retrieved: 393390 . Total input tokens: 87639207 . Total output tokens: 78675947
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 8.7506985347718,
    "estimated_duration": 3600.0936595949133,
    "input_throughput": 8358.299768063767,
    "output_throughput": 7336.956895441465,
    "total_throughput": 15695.256663505232,
    "itl": 115.80809227991514,
    "ttft": 380887.5732515455,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 130909,
    "finished_requests": 120960,
    "scheduler_time": 97.21597023138011
}
#Debug simulation 
Total elapsed time: 8.750895062927157. Arrivals time: 0.36416316498070955 Scheduler time: 8.2504729218781 Scheduler overhead time: 0.04953502677381039 Adapter cache time: 0.01314241113141179 Engine time: 0.050828144419938326 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-32/adapters_32_slots_32_rate_3.2-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-32/adapters_32_slots_32_rate_3.2-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 1080, 135, 135, 1080, 135, 34560, 1080, 135, 135, 135, 34560, 34560, 135, 135, 1080, 1080, 1080, 34560, 34560, 135, 34560, 34560, 34560, 34560, 1080, 135, 1080, 1080, 1080, 1080, 34560]
Prompts retrieved: 393390 . Total input tokens: 87639207 . Total output tokens: 78675947
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.782005401793867,
    "estimated_duration": 3600.0514968529073,
    "input_throughput": 8358.2676598666,
    "output_throughput": 7337.042268170428,
    "total_throughput": 15695.309928037028,
    "itl": 115.80964663240702,
    "ttft": 380896.58519080566,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145736,
    "arrivals": 130909,
    "finished_requests": 120959,
    "scheduler_time": 97.2142500085359
}
#Debug simulation 
Total elapsed time: 8.782144555822015. Arrivals time: 0.34305667225271463 Scheduler time: 8.303463587071747 Scheduler overhead time: 0.04992189025506377 Adapter cache time: 0.012527920305728912 Engine time: 0.050480443984270096 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-8/adapters_32_slots_32_rate_3.2-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-8/adapters_32_slots_32_rate_3.2-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 1080, 66, 66, 1080, 66, 34560, 1080, 66, 66, 66, 34560, 34560, 66, 66, 1080, 1080, 1080, 34560, 34560, 66, 34560, 34560, 34560, 34560, 1080, 66, 1080, 1080, 1080, 1080, 34560]
Prompts retrieved: 392700 . Total input tokens: 87482444 . Total output tokens: 78533017
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 8.909973267931491,
    "estimated_duration": 3600.05728932339,
    "input_throughput": 8446.680026504553,
    "output_throughput": 7430.956468203277,
    "total_throughput": 15877.636494707831,
    "itl": 114.58431309049388,
    "ttft": 318377.3298776436,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 130707,
    "finished_requests": 122292,
    "scheduler_time": 99.4232585969728
}
#Debug simulation 
Total elapsed time: 8.910157565958798. Arrivals time: 0.3837328846566379 Scheduler time: 8.389124804642051 Scheduler overhead time: 0.050099053885787725 Adapter cache time: 0.012986069079488516 Engine time: 0.05110101914033294 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-16/adapters_32_slots_32_rate_3.2-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-16/adapters_32_slots_32_rate_3.2-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 1080, 66, 66, 1080, 66, 34560, 1080, 66, 66, 66, 34560, 34560, 66, 66, 1080, 1080, 1080, 34560, 34560, 66, 34560, 34560, 34560, 34560, 1080, 66, 1080, 1080, 1080, 1080, 34560]
Prompts retrieved: 392700 . Total input tokens: 87482444 . Total output tokens: 78533017
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.85390210011974,
    "estimated_duration": 3600.0978939329366,
    "input_throughput": 8446.671145039276,
    "output_throughput": 7431.0107080933585,
    "total_throughput": 15877.681853132633,
    "itl": 114.58481115038529,
    "ttft": 318368.2016101224,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255727,
    "arrivals": 130707,
    "finished_requests": 122295,
    "scheduler_time": 99.42491785223241
}
#Debug simulation 
Total elapsed time: 8.854030729271472. Arrivals time: 0.36162342270836234 Scheduler time: 8.356563738081604 Scheduler overhead time: 0.04996691318228841 Adapter cache time: 0.012153082061558962 Engine time: 0.050819564145058393 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-32/adapters_32_slots_32_rate_3.2-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-32/adapters_32_slots_32_rate_3.2-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 1080, 66, 66, 1080, 66, 34560, 1080, 66, 66, 66, 34560, 34560, 66, 66, 1080, 1080, 1080, 34560, 34560, 66, 34560, 34560, 34560, 34560, 1080, 66, 1080, 1080, 1080, 1080, 34560]
Prompts retrieved: 392700 . Total input tokens: 87482444 . Total output tokens: 78533017
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.929890052881092,
    "estimated_duration": 3600.097866552264,
    "input_throughput": 8446.671209280734,
    "output_throughput": 7431.010764610175,
    "total_throughput": 15877.681973890909,
    "itl": 114.58483454576297,
    "ttft": 318368.1587316999,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033041,
    "arrivals": 130707,
    "finished_requests": 122295,
    "scheduler_time": 99.42492382286156
}
#Debug simulation 
Total elapsed time: 8.930006477981806. Arrivals time: 0.3550550024956465 Scheduler time: 8.438789404928684 Scheduler overhead time: 0.04995428025722504 Adapter cache time: 0.012111121788620949 Engine time: 0.051118954084813595 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-16/adapters_32_slots_32_rate_3.2-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-16/adapters_32_slots_32_rate_3.2-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 1080, 66, 66, 1080, 66, 34560, 1080, 66, 66, 66, 34560, 34560, 66, 66, 1080, 1080, 1080, 34560, 34560, 66, 34560, 34560, 34560, 34560, 1080, 66, 1080, 1080, 1080, 1080, 34560]
Prompts retrieved: 392700 . Total input tokens: 87482444 . Total output tokens: 78533017
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 8.835558629129082,
    "estimated_duration": 3600.065205742306,
    "input_throughput": 8446.661452547218,
    "output_throughput": 7430.940127786927,
    "total_throughput": 15877.601580334143,
    "itl": 114.5842565945057,
    "ttft": 318376.2275243315,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971348,
    "arrivals": 130707,
    "finished_requests": 122292,
    "scheduler_time": 99.42362041706343
}
#Debug simulation 
Total elapsed time: 8.835677821189165. Arrivals time: 0.33755631372332573 Scheduler time: 8.361547000240535 Scheduler overhead time: 0.050265738274902105 Adapter cache time: 0.011743729468435049 Engine time: 0.05159182380884886 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-32/adapters_32_slots_32_rate_3.2-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-32/adapters_32_slots_32_rate_3.2-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 1080, 66, 66, 1080, 66, 34560, 1080, 66, 66, 66, 34560, 34560, 66, 66, 1080, 1080, 1080, 34560, 34560, 66, 34560, 34560, 34560, 34560, 1080, 66, 1080, 1080, 1080, 1080, 34560]
Prompts retrieved: 392700 . Total input tokens: 87482444 . Total output tokens: 78533017
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 8.906449317000806,
    "estimated_duration": 3600.1073243069677,
    "input_throughput": 8446.649019235503,
    "output_throughput": 7430.9912427818845,
    "total_throughput": 15877.640262017389,
    "itl": 114.58504528160056,
    "ttft": 318395.4385817534,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089387,
    "arrivals": 130707,
    "finished_requests": 122295,
    "scheduler_time": 99.424891487767
}
#Debug simulation 
Total elapsed time: 8.906573521438986. Arrivals time: 0.3524300171993673 Scheduler time: 8.417319973465055 Scheduler overhead time: 0.05013911984860897 Adapter cache time: 0.01226410549134016 Engine time: 0.05132645508274436 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-16/adapters_32_slots_32_rate_3.2-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-16/adapters_32_slots_32_rate_3.2-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 1080, 66, 66, 1080, 66, 34560, 1080, 66, 66, 66, 34560, 34560, 66, 66, 1080, 1080, 1080, 34560, 34560, 66, 34560, 34560, 34560, 34560, 1080, 66, 1080, 1080, 1080, 1080, 34560]
Prompts retrieved: 392700 . Total input tokens: 87482444 . Total output tokens: 78533017
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 8.952895088121295,
    "estimated_duration": 3600.0438298425797,
    "input_throughput": 8446.592996432953,
    "output_throughput": 7430.944528575304,
    "total_throughput": 15877.537525008256,
    "itl": 114.5840506464291,
    "ttft": 318375.35630403034,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 130707,
    "finished_requests": 122291,
    "scheduler_time": 99.42323655253958
}
#Debug simulation 
Total elapsed time: 8.953058031853288. Arrivals time: 0.3650460308417678 Scheduler time: 8.449809512589127 Scheduler overhead time: 0.05053661111742258 Adapter cache time: 0.01282337261363864 Engine time: 0.05170902702957392 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-32/adapters_32_slots_32_rate_3.2-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-32/adapters_32_slots_32_rate_3.2-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 1080, 66, 66, 1080, 66, 34560, 1080, 66, 66, 66, 34560, 34560, 66, 66, 1080, 1080, 1080, 34560, 34560, 66, 34560, 34560, 34560, 34560, 1080, 66, 1080, 1080, 1080, 1080, 34560]
Prompts retrieved: 392700 . Total input tokens: 87482444 . Total output tokens: 78533017
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.88955396041274,
    "estimated_duration": 3600.1132863914204,
    "input_throughput": 8446.635030888252,
    "output_throughput": 7430.978936447658,
    "total_throughput": 15877.61396733591,
    "itl": 114.58507005490901,
    "ttft": 318399.56365899474,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145733,
    "arrivals": 130707,
    "finished_requests": 122295,
    "scheduler_time": 99.42479150893122
}
#Debug simulation 
Total elapsed time: 8.889685814268887. Arrivals time: 0.35613492503762245 Scheduler time: 8.396501656621695 Scheduler overhead time: 0.05058304965496063 Adapter cache time: 0.012217552401125431 Engine time: 0.05117500014603138 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-8/adapters_32_slots_32_rate_3.2-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-8/adapters_32_slots_32_rate_3.2-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 1080, 33, 33, 1080, 33, 34560, 1080, 33, 33, 33, 34560, 34560, 33, 33, 1080, 1080, 1080, 34560, 34560, 33, 34560, 34560, 34560, 34560, 1080, 33, 1080, 1080, 1080, 1080, 34560]
Prompts retrieved: 392370 . Total input tokens: 87403798 . Total output tokens: 78465602
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 8.890779900830239,
    "estimated_duration": 3600.104704313403,
    "input_throughput": 8471.27806129082,
    "output_throughput": 7465.725362875507,
    "total_throughput": 15937.003424166325,
    "itl": 114.00214196469656,
    "ttft": 303383.74975375104,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 130593,
    "finished_requests": 122625,
    "scheduler_time": 100.04502575794159
}
#Debug simulation 
Total elapsed time: 8.89091970026493. Arrivals time: 0.3432314256206155 Scheduler time: 8.411542683374137 Scheduler overhead time: 0.050044176168739796 Adapter cache time: 0.011494565289467573 Engine time: 0.051624578423798084 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-16/adapters_32_slots_32_rate_3.2-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-16/adapters_32_slots_32_rate_3.2-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 1080, 33, 33, 1080, 33, 34560, 1080, 33, 33, 33, 34560, 34560, 33, 33, 1080, 1080, 1080, 34560, 34560, 33, 34560, 34560, 34560, 34560, 1080, 33, 1080, 1080, 1080, 1080, 34560]
Prompts retrieved: 392370 . Total input tokens: 87403798 . Total output tokens: 78465602
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.962553452700377,
    "estimated_duration": 3600.039034122404,
    "input_throughput": 8471.332035830108,
    "output_throughput": 7465.8079385386345,
    "total_throughput": 15937.139974368743,
    "itl": 114.00288903901196,
    "ttft": 303409.0149155352,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255727,
    "arrivals": 130593,
    "finished_requests": 122624,
    "scheduler_time": 100.04339172303969
}
#Debug simulation 
Total elapsed time: 8.962692633736879. Arrivals time: 0.3553652302362025 Scheduler time: 8.4706563022919 Scheduler overhead time: 0.05036860378459096 Adapter cache time: 0.011842714622616768 Engine time: 0.051249404437839985 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-32/adapters_32_slots_32_rate_3.2-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-32/adapters_32_slots_32_rate_3.2-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 1080, 33, 33, 1080, 33, 34560, 1080, 33, 33, 33, 34560, 34560, 33, 33, 1080, 1080, 1080, 34560, 34560, 33, 34560, 34560, 34560, 34560, 1080, 33, 1080, 1080, 1080, 1080, 34560]
Prompts retrieved: 392370 . Total input tokens: 87403798 . Total output tokens: 78465602
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.90468550985679,
    "estimated_duration": 3600.0391681818455,
    "input_throughput": 8471.331720371862,
    "output_throughput": 7465.807660524425,
    "total_throughput": 15937.139380896286,
    "itl": 114.00289860913901,
    "ttft": 303409.11542570405,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033041,
    "arrivals": 130593,
    "finished_requests": 122624,
    "scheduler_time": 100.0433877074977
}
#Debug simulation 
Total elapsed time: 8.904824981931597. Arrivals time: 0.3636545273475349 Scheduler time: 8.404124054592103 Scheduler overhead time: 0.05051802005618811 Adapter cache time: 0.01213957229629159 Engine time: 0.05130974808707833 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-16/adapters_32_slots_32_rate_3.2-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-16/adapters_32_slots_32_rate_3.2-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 1080, 33, 33, 1080, 33, 34560, 1080, 33, 33, 33, 34560, 34560, 33, 33, 1080, 1080, 1080, 34560, 34560, 33, 34560, 34560, 34560, 34560, 1080, 33, 1080, 1080, 1080, 1080, 34560]
Prompts retrieved: 392370 . Total input tokens: 87403798 . Total output tokens: 78465602
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 9.003215834964067,
    "estimated_duration": 3600.1242911229247,
    "input_throughput": 8471.231972518217,
    "output_throughput": 7465.684744905459,
    "total_throughput": 15936.916717423675,
    "itl": 114.00238659381932,
    "ttft": 303410.6928742155,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971348,
    "arrivals": 130593,
    "finished_requests": 122625,
    "scheduler_time": 100.04542495879352
}
#Debug simulation 
Total elapsed time: 9.003420050721616. Arrivals time: 0.36519542802125216 Scheduler time: 8.501501092221588 Scheduler overhead time: 0.050366591196507215 Adapter cache time: 0.011885376647114754 Engine time: 0.051261527463793755 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-32/adapters_32_slots_32_rate_3.2-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-32/adapters_32_slots_32_rate_3.2-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 1080, 33, 33, 1080, 33, 34560, 1080, 33, 33, 33, 34560, 34560, 33, 33, 1080, 1080, 1080, 34560, 34560, 33, 34560, 34560, 34560, 34560, 1080, 33, 1080, 1080, 1080, 1080, 34560]
Prompts retrieved: 392370 . Total input tokens: 87403798 . Total output tokens: 78465602
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 8.91575477970764,
    "estimated_duration": 3600.0409282213254,
    "input_throughput": 8471.327578786093,
    "output_throughput": 7465.804010533635,
    "total_throughput": 15937.131589319728,
    "itl": 114.00278852578177,
    "ttft": 303409.915886263,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089386,
    "arrivals": 130593,
    "finished_requests": 122624,
    "scheduler_time": 100.04333741371602
}
#Debug simulation 
Total elapsed time: 8.915903190616518. Arrivals time: 0.3443943616002798 Scheduler time: 8.4355479455553 Scheduler overhead time: 0.05028645507991314 Adapter cache time: 0.011480773333460093 Engine time: 0.05122145637869835 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-16/adapters_32_slots_32_rate_3.2-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-16/adapters_32_slots_32_rate_3.2-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 1080, 33, 33, 1080, 33, 34560, 1080, 33, 33, 33, 34560, 34560, 33, 33, 1080, 1080, 1080, 34560, 34560, 33, 34560, 34560, 34560, 34560, 1080, 33, 1080, 1080, 1080, 1080, 34560]
Prompts retrieved: 392370 . Total input tokens: 87403798 . Total output tokens: 78465602
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 8.924454167019576,
    "estimated_duration": 3600.0928743016466,
    "input_throughput": 8471.305898161298,
    "output_throughput": 7465.749895470053,
    "total_throughput": 15937.05579363135,
    "itl": 114.00205247714008,
    "ttft": 303384.53338351124,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 130593,
    "finished_requests": 122625,
    "scheduler_time": 100.04476697802518
}
#Debug simulation 
Total elapsed time: 8.924719447735697. Arrivals time: 0.3873099284246564 Scheduler time: 8.400817818939686 Scheduler overhead time: 0.05031990120187402 Adapter cache time: 0.011590289417654276 Engine time: 0.05153091112151742 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-32/adapters_32_slots_32_rate_3.2-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-32/adapters_32_slots_32_rate_3.2-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 1080, 33, 33, 1080, 33, 34560, 1080, 33, 33, 33, 34560, 34560, 33, 33, 1080, 1080, 1080, 34560, 34560, 33, 34560, 34560, 34560, 34560, 1080, 33, 1080, 1080, 1080, 1080, 34560]
Prompts retrieved: 392370 . Total input tokens: 87403798 . Total output tokens: 78465602
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.956630698870867,
    "estimated_duration": 3600.0446955767434,
    "input_throughput": 8471.318713756753,
    "output_throughput": 7465.796197759192,
    "total_throughput": 15937.114911515946,
    "itl": 114.00261448492398,
    "ttft": 303411.7539642995,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145733,
    "arrivals": 130593,
    "finished_requests": 122624,
    "scheduler_time": 100.04323226037991
}
#Debug simulation 
Total elapsed time: 8.956738604232669. Arrivals time: 0.36555111175403 Scheduler time: 8.454430656507611 Scheduler overhead time: 0.05025202874094248 Adapter cache time: 0.011893824208527803 Engine time: 0.05162688670679927 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-8/adapters_32_slots_32_rate_3.2-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-8/adapters_32_slots_32_rate_3.2-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 540, 270, 270, 540, 270, 34560, 540, 270, 270, 270, 34560, 34560, 270, 270, 540, 540, 540, 34560, 34560, 270, 34560, 34560, 34560, 34560, 540, 270, 540, 540, 540, 540, 34560]
Prompts retrieved: 388800 . Total input tokens: 86598199 . Total output tokens: 77761056
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 8.771790136117488,
    "estimated_duration": 3600.042994730322,
    "input_throughput": 8380.47574547371,
    "output_throughput": 7364.025384920692,
    "total_throughput": 15744.501130394401,
    "itl": 115.31760266548562,
    "ttft": 307681.17110090796,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 129421,
    "finished_requests": 121451,
    "scheduler_time": 98.63011839432362
}
#Debug simulation 
Total elapsed time: 8.771904865745455. Arrivals time: 0.3469464350491762 Scheduler time: 8.286486886441708 Scheduler overhead time: 0.049875639379024506 Adapter cache time: 0.01477525057271123 Engine time: 0.05098624620586634 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-16/adapters_32_slots_32_rate_3.2-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-16/adapters_32_slots_32_rate_3.2-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 540, 270, 270, 540, 270, 34560, 540, 270, 270, 270, 34560, 34560, 270, 270, 540, 540, 540, 34560, 34560, 270, 34560, 34560, 34560, 34560, 540, 270, 540, 540, 540, 540, 34560]
Prompts retrieved: 388800 . Total input tokens: 86598199 . Total output tokens: 77761056
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.768787088803947,
    "estimated_duration": 3600.0954932809423,
    "input_throughput": 8380.353536818142,
    "output_throughput": 7363.917998697143,
    "total_throughput": 15744.271535515285,
    "itl": 115.3179818467196,
    "ttft": 307719.69331071945,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255727,
    "arrivals": 129421,
    "finished_requests": 121451,
    "scheduler_time": 98.63047492836058
}
#Debug simulation 
Total elapsed time: 8.768883259035647. Arrivals time: 0.343754043802619 Scheduler time: 8.286879571154714 Scheduler overhead time: 0.04971839301288128 Adapter cache time: 0.014903529081493616 Engine time: 0.05092344433069229 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-32/adapters_32_slots_32_rate_3.2-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-32/adapters_32_slots_32_rate_3.2-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 540, 270, 270, 540, 270, 34560, 540, 270, 270, 270, 34560, 34560, 270, 270, 540, 540, 540, 34560, 34560, 270, 34560, 34560, 34560, 34560, 540, 270, 540, 540, 540, 540, 34560]
Prompts retrieved: 388800 . Total input tokens: 86598199 . Total output tokens: 77761056
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.744232816156,
    "estimated_duration": 3600.0957456938627,
    "input_throughput": 8380.352949247794,
    "output_throughput": 7363.917482391972,
    "total_throughput": 15744.270431639767,
    "itl": 115.31800648720947,
    "ttft": 307719.9313310845,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033041,
    "arrivals": 129421,
    "finished_requests": 121451,
    "scheduler_time": 98.63046881138892
}
#Debug simulation 
Total elapsed time: 8.744362421799451. Arrivals time: 0.34811190236359835 Scheduler time: 8.25827784044668 Scheduler overhead time: 0.04963141120970249 Adapter cache time: 0.014732041861861944 Engine time: 0.05087391613051295 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-16-16/adapters_32_slots_32_rate_3.2-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-16-16/adapters_32_slots_32_rate_3.2-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 540, 270, 270, 540, 270, 34560, 540, 270, 270, 270, 34560, 34560, 270, 270, 540, 540, 540, 34560, 34560, 270, 34560, 34560, 34560, 34560, 540, 270, 540, 540, 540, 540, 34560]
Prompts retrieved: 388800 . Total input tokens: 86598199 . Total output tokens: 77761056
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 8.783401057124138,
    "estimated_duration": 3600.061815462772,
    "input_throughput": 8380.43193325606,
    "output_throughput": 7363.986886595211,
    "total_throughput": 15744.418819851271,
    "itl": 115.31777178687423,
    "ttft": 307688.02837173623,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971348,
    "arrivals": 129421,
    "finished_requests": 121451,
    "scheduler_time": 98.6300230455932
}
#Debug simulation 
Total elapsed time: 8.783528595231473. Arrivals time: 0.3590332199819386 Scheduler time: 8.28587895212695 Scheduler overhead time: 0.04974910011515021 Adapter cache time: 0.015290327370166779 Engine time: 0.05092754075303674 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-16-32/adapters_32_slots_32_rate_3.2-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-16-32/adapters_32_slots_32_rate_3.2-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 540, 270, 270, 540, 270, 34560, 540, 270, 270, 270, 34560, 34560, 270, 270, 540, 540, 540, 34560, 34560, 270, 34560, 34560, 34560, 34560, 540, 270, 540, 540, 540, 540, 34560]
Prompts retrieved: 388800 . Total input tokens: 86598199 . Total output tokens: 77761056
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 8.7811532150954,
    "estimated_duration": 3600.0070189973208,
    "input_throughput": 8380.353105090002,
    "output_throughput": 7364.020364433553,
    "total_throughput": 15744.373469523556,
    "itl": 115.31906318717022,
    "ttft": 307692.8999106323,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089387,
    "arrivals": 129421,
    "finished_requests": 121450,
    "scheduler_time": 98.62803039826895
}
#Debug simulation 
Total elapsed time: 8.781291904859245. Arrivals time: 0.3507603439502418 Scheduler time: 8.292227851692587 Scheduler overhead time: 0.0497835879214108 Adapter cache time: 0.014935734681785107 Engine time: 0.050747685600072145 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_16-16-16/adapters_32_slots_32_rate_3.2-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_16-16-16/adapters_32_slots_32_rate_3.2-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 540, 270, 270, 540, 270, 34560, 540, 270, 270, 270, 34560, 34560, 270, 270, 540, 540, 540, 34560, 34560, 270, 34560, 34560, 34560, 34560, 540, 270, 540, 540, 540, 540, 34560]
Prompts retrieved: 388800 . Total input tokens: 86598199 . Total output tokens: 77761056
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 8.724877837114036,
    "estimated_duration": 3600.0439723547734,
    "input_throughput": 8380.47346967984,
    "output_throughput": 7364.023385153097,
    "total_throughput": 15744.496854832936,
    "itl": 115.3179801125496,
    "ttft": 307685.475338383,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 129421,
    "finished_requests": 121451,
    "scheduler_time": 98.62966806838662
}
#Debug simulation 
Total elapsed time: 8.725038251373917. Arrivals time: 0.34888552175834775 Scheduler time: 8.238353881053627 Scheduler overhead time: 0.04960475070402026 Adapter cache time: 0.015141646843403578 Engine time: 0.05045574298128486 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_16-16-32/adapters_32_slots_32_rate_3.2-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_16-16-32/adapters_32_slots_32_rate_3.2-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 540, 270, 270, 540, 270, 34560, 540, 270, 270, 270, 34560, 34560, 270, 270, 540, 540, 540, 34560, 34560, 270, 34560, 34560, 34560, 34560, 540, 270, 540, 540, 540, 540, 34560]
Prompts retrieved: 388800 . Total input tokens: 86598199 . Total output tokens: 77761056
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.772824738640338,
    "estimated_duration": 3600.012584336589,
    "input_throughput": 8380.34014971634,
    "output_throughput": 7364.008980231208,
    "total_throughput": 15744.349129947548,
    "itl": 115.31907369574839,
    "ttft": 307693.9931578836,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145733,
    "arrivals": 129421,
    "finished_requests": 121450,
    "scheduler_time": 98.62814836498565
}
#Debug simulation 
Total elapsed time: 8.772981120739132. Arrivals time: 0.3524504639208317 Scheduler time: 8.282644964754581 Scheduler overhead time: 0.049658800940960646 Adapter cache time: 0.014792005065828562 Engine time: 0.05068913893774152 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-8/adapters_32_slots_32_rate_3.2-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-8/adapters_32_slots_32_rate_3.2-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 540, 135, 135, 540, 135, 34560, 540, 135, 135, 135, 34560, 34560, 135, 135, 540, 540, 540, 34560, 34560, 135, 34560, 34560, 34560, 34560, 540, 135, 540, 540, 540, 540, 34560]
Prompts retrieved: 387450 . Total input tokens: 86296579 . Total output tokens: 77492450
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 8.84886205708608,
    "estimated_duration": 3600.011385647675,
    "input_throughput": 8388.132082134294,
    "output_throughput": 7482.226613889986,
    "total_throughput": 15870.358696024281,
    "itl": 114.17605661967585,
    "ttft": 244732.63821985447,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 128920,
    "finished_requests": 122650,
    "scheduler_time": 101.0496652432295
}
#Debug simulation 
Total elapsed time: 8.84897282300517. Arrivals time: 0.3550306432880461 Scheduler time: 8.356352095957845 Scheduler overhead time: 0.04999003140255809 Adapter cache time: 0.013880070764571428 Engine time: 0.05100089590996504 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-16/adapters_32_slots_32_rate_3.2-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-16/adapters_32_slots_32_rate_3.2-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 540, 135, 135, 540, 135, 34560, 540, 135, 135, 135, 34560, 34560, 135, 135, 540, 540, 540, 34560, 34560, 135, 34560, 34560, 34560, 34560, 540, 135, 540, 540, 540, 540, 34560]
Prompts retrieved: 387450 . Total input tokens: 86296579 . Total output tokens: 77492450
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.75202988134697,
    "estimated_duration": 3600.025257455162,
    "input_throughput": 8388.099760540668,
    "output_throughput": 7482.197782979162,
    "total_throughput": 15870.29754351983,
    "itl": 114.17529230153438,
    "ttft": 244733.44040628575,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255727,
    "arrivals": 128920,
    "finished_requests": 122650,
    "scheduler_time": 101.0504445885877
}
#Debug simulation 
Total elapsed time: 8.75215768814087. Arrivals time: 0.3293407545424998 Scheduler time: 8.287342447787523 Scheduler overhead time: 0.049077027942985296 Adapter cache time: 0.013506351970136166 Engine time: 0.05029083462432027 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-32/adapters_32_slots_32_rate_3.2-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-32/adapters_32_slots_32_rate_3.2-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 540, 135, 135, 540, 135, 34560, 540, 135, 135, 135, 34560, 34560, 135, 135, 540, 540, 540, 34560, 34560, 135, 34560, 34560, 34560, 34560, 540, 135, 540, 540, 540, 540, 34560]
Prompts retrieved: 387450 . Total input tokens: 86296579 . Total output tokens: 77492450
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.742392815183848,
    "estimated_duration": 3600.0264916194446,
    "input_throughput": 8388.09688492485,
    "output_throughput": 7482.195217925466,
    "total_throughput": 15870.292102850315,
    "itl": 114.17532705882759,
    "ttft": 244734.50671889435,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033041,
    "arrivals": 128920,
    "finished_requests": 122650,
    "scheduler_time": 101.05040723701998
}
#Debug simulation 
Total elapsed time: 8.742514127399772. Arrivals time: 0.33222221583127975 Scheduler time: 8.274380359333009 Scheduler overhead time: 0.04932984383776784 Adapter cache time: 0.013460142072290182 Engine time: 0.05058097746223211 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-16/adapters_32_slots_32_rate_3.2-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-16/adapters_32_slots_32_rate_3.2-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 540, 135, 135, 540, 135, 34560, 540, 135, 135, 135, 34560, 34560, 135, 135, 540, 540, 540, 34560, 34560, 135, 34560, 34560, 34560, 34560, 540, 135, 540, 540, 540, 540, 34560]
Prompts retrieved: 387450 . Total input tokens: 86296579 . Total output tokens: 77492450
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 8.825358138885349,
    "estimated_duration": 3600.009999738992,
    "input_throughput": 8388.135311343405,
    "output_throughput": 7482.229494349438,
    "total_throughput": 15870.364805692843,
    "itl": 114.17544710237718,
    "ttft": 244730.9465651976,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971348,
    "arrivals": 128920,
    "finished_requests": 122650,
    "scheduler_time": 101.04950698341449
}
#Debug simulation 
Total elapsed time: 8.825474926270545. Arrivals time: 0.34586030803620815 Scheduler time: 8.343502647709101 Scheduler overhead time: 0.049469814635813236 Adapter cache time: 0.01347056170925498 Engine time: 0.05057229707017541 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-32/adapters_32_slots_32_rate_3.2-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-32/adapters_32_slots_32_rate_3.2-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 540, 135, 135, 540, 135, 34560, 540, 135, 135, 135, 34560, 34560, 135, 135, 540, 540, 540, 34560, 34560, 135, 34560, 34560, 34560, 34560, 540, 135, 540, 540, 540, 540, 34560]
Prompts retrieved: 387450 . Total input tokens: 86296579 . Total output tokens: 77492450
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 8.797979013063014,
    "estimated_duration": 3600.0266787946125,
    "input_throughput": 8388.096448804903,
    "output_throughput": 7482.194828905808,
    "total_throughput": 15870.291277710712,
    "itl": 114.17516783744682,
    "ttft": 244734.72804800767,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089387,
    "arrivals": 128920,
    "finished_requests": 122650,
    "scheduler_time": 101.0503894773233
}
#Debug simulation 
Total elapsed time: 8.798131118994206. Arrivals time: 0.3370723915286362 Scheduler time: 8.324814373627305 Scheduler overhead time: 0.04931427072733641 Adapter cache time: 0.013667827937752008 Engine time: 0.05051854718476534 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-16/adapters_32_slots_32_rate_3.2-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-16/adapters_32_slots_32_rate_3.2-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 540, 135, 135, 540, 135, 34560, 540, 135, 135, 135, 34560, 34560, 135, 135, 540, 540, 540, 34560, 34560, 135, 34560, 34560, 34560, 34560, 540, 135, 540, 540, 540, 540, 34560]
Prompts retrieved: 387450 . Total input tokens: 86296579 . Total output tokens: 77492450
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 8.786147565115243,
    "estimated_duration": 3600.09723501841,
    "input_throughput": 8387.932055353382,
    "output_throughput": 7482.048189696258,
    "total_throughput": 15869.980245049639,
    "itl": 114.17502477947434,
    "ttft": 244784.15809435028,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 128920,
    "finished_requests": 122650,
    "scheduler_time": 101.0522956589666
}
#Debug simulation 
Total elapsed time: 8.78630404593423. Arrivals time: 0.3247062861919403 Scheduler time: 8.325739678461105 Scheduler overhead time: 0.04934788914397359 Adapter cache time: 0.013314509764313698 Engine time: 0.05057390406727791 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-32/adapters_32_slots_32_rate_3.2-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-32/adapters_32_slots_32_rate_3.2-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 540, 135, 135, 540, 135, 34560, 540, 135, 135, 135, 34560, 34560, 135, 135, 540, 540, 540, 34560, 34560, 135, 34560, 34560, 34560, 34560, 540, 135, 540, 540, 540, 540, 34560]
Prompts retrieved: 387450 . Total input tokens: 86296579 . Total output tokens: 77492450
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.805983980186284,
    "estimated_duration": 3600.0271956856254,
    "input_throughput": 8388.095244444094,
    "output_throughput": 7482.193754614128,
    "total_throughput": 15870.28899905822,
    "itl": 114.17488858350711,
    "ttft": 244734.39966431414,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145734,
    "arrivals": 128920,
    "finished_requests": 122650,
    "scheduler_time": 101.05030104763804
}
#Debug simulation 
Total elapsed time: 8.806130847893655. Arrivals time: 0.3432981427758932 Scheduler time: 8.325806566048414 Scheduler overhead time: 0.049663360230624676 Adapter cache time: 0.014074895065277815 Engine time: 0.05063100578263402 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-8/adapters_32_slots_32_rate_3.2-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-8/adapters_32_slots_32_rate_3.2-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 540, 66, 66, 540, 66, 34560, 540, 66, 66, 66, 34560, 34560, 66, 66, 540, 540, 540, 34560, 34560, 66, 34560, 34560, 34560, 34560, 540, 66, 540, 540, 540, 540, 34560]
Prompts retrieved: 386760 . Total input tokens: 86146875 . Total output tokens: 77349204
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 8.838303364813328,
    "estimated_duration": 3600.074913220487,
    "input_throughput": 8575.37627526287,
    "output_throughput": 7537.353986816361,
    "total_throughput": 16112.73026207923,
    "itl": 112.69903700805419,
    "ttft": 182449.36597635134,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 128685,
    "finished_requests": 123972,
    "scheduler_time": 102.59386781005034
}
#Debug simulation 
Total elapsed time: 8.838394830934703. Arrivals time: 0.3403464965522289 Scheduler time: 8.360489307437092 Scheduler overhead time: 0.05013433890417218 Adapter cache time: 0.013161806855350733 Engine time: 0.05127854924649 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-16/adapters_32_slots_32_rate_3.2-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-16/adapters_32_slots_32_rate_3.2-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 540, 66, 66, 540, 66, 34560, 540, 66, 66, 66, 34560, 34560, 66, 66, 540, 540, 540, 34560, 34560, 66, 34560, 34560, 34560, 34560, 540, 66, 540, 540, 540, 540, 34560]
Prompts retrieved: 386760 . Total input tokens: 86146875 . Total output tokens: 77349204
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.764150377828628,
    "estimated_duration": 3600.1223996254616,
    "input_throughput": 8575.263164166798,
    "output_throughput": 7537.254567462203,
    "total_throughput": 16112.517731629001,
    "itl": 112.69951479221709,
    "ttft": 182514.68302015387,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255727,
    "arrivals": 128685,
    "finished_requests": 123972,
    "scheduler_time": 102.5945413903371
}
#Debug simulation 
Total elapsed time: 8.764267077669501. Arrivals time: 0.3275013128295541 Scheduler time: 8.300643128808588 Scheduler overhead time: 0.04961782926693559 Adapter cache time: 0.01304944884032011 Engine time: 0.05060792388394475 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-32/adapters_32_slots_32_rate_3.2-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-32/adapters_32_slots_32_rate_3.2-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 540, 66, 66, 540, 66, 34560, 540, 66, 66, 66, 34560, 34560, 66, 66, 540, 540, 540, 34560, 34560, 66, 34560, 34560, 34560, 34560, 540, 66, 540, 540, 540, 540, 34560]
Prompts retrieved: 386760 . Total input tokens: 86146875 . Total output tokens: 77349204
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.836524464190006,
    "estimated_duration": 3600.122634929642,
    "input_throughput": 8575.262603687204,
    "output_throughput": 7537.254074826899,
    "total_throughput": 16112.516678514103,
    "itl": 112.69952260480748,
    "ttft": 182514.9037740693,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033041,
    "arrivals": 128685,
    "finished_requests": 123972,
    "scheduler_time": 102.59453531434028
}
#Debug simulation 
Total elapsed time: 8.836625928990543. Arrivals time: 0.3329900670796633 Scheduler time: 8.366850930731744 Scheduler overhead time: 0.04961816594004631 Adapter cache time: 0.013436062727123499 Engine time: 0.05087903141975403 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-16/adapters_32_slots_32_rate_3.2-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-16/adapters_32_slots_32_rate_3.2-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 540, 66, 66, 540, 66, 34560, 540, 66, 66, 66, 34560, 34560, 66, 66, 540, 540, 540, 34560, 34560, 66, 34560, 34560, 34560, 34560, 540, 66, 540, 540, 540, 540, 34560]
Prompts retrieved: 386760 . Total input tokens: 86146875 . Total output tokens: 77349204
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 8.782230050768703,
    "estimated_duration": 3600.1072255412064,
    "input_throughput": 8575.29930802519,
    "output_throughput": 7537.286336220381,
    "total_throughput": 16112.585644245573,
    "itl": 112.69944773150544,
    "ttft": 182483.91882697493,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971346,
    "arrivals": 128685,
    "finished_requests": 123972,
    "scheduler_time": 102.59450975779697
}
#Debug simulation 
Total elapsed time: 8.782359539996833. Arrivals time: 0.34327673027291894 Scheduler time: 8.3023720132187 Scheduler overhead time: 0.04992849146947265 Adapter cache time: 0.01331688417121768 Engine time: 0.05061005102470517 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-32/adapters_32_slots_32_rate_3.2-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-32/adapters_32_slots_32_rate_3.2-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 540, 66, 66, 540, 66, 34560, 540, 66, 66, 66, 34560, 34560, 66, 66, 540, 540, 540, 34560, 34560, 66, 34560, 34560, 34560, 34560, 540, 66, 540, 540, 540, 540, 34560]
Prompts retrieved: 386760 . Total input tokens: 86146875 . Total output tokens: 77349204
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 8.79364005336538,
    "estimated_duration": 3600.011576792608,
    "input_throughput": 8575.46908988134,
    "output_throughput": 7537.470483407617,
    "total_throughput": 16112.939573288959,
    "itl": 112.70015764732693,
    "ttft": 182495.44209625403,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089387,
    "arrivals": 128685,
    "finished_requests": 123970,
    "scheduler_time": 102.59091766681131
}
#Debug simulation 
Total elapsed time: 8.793735599145293. Arrivals time: 0.33333756821230054 Scheduler time: 8.32358223060146 Scheduler overhead time: 0.050001672469079494 Adapter cache time: 0.013227780349552631 Engine time: 0.05068236496299505 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-16/adapters_32_slots_32_rate_3.2-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-16/adapters_32_slots_32_rate_3.2-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 540, 66, 66, 540, 66, 34560, 540, 66, 66, 66, 34560, 34560, 66, 66, 540, 540, 540, 34560, 34560, 66, 34560, 34560, 34560, 34560, 540, 66, 540, 540, 540, 540, 34560]
Prompts retrieved: 386760 . Total input tokens: 86146875 . Total output tokens: 77349204
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 8.80723237991333,
    "estimated_duration": 3600.0586767932327,
    "input_throughput": 8575.414950597238,
    "output_throughput": 7537.387980623318,
    "total_throughput": 16112.802931220556,
    "itl": 112.6988919485468,
    "ttft": 182410.9414524164,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 128685,
    "finished_requests": 123972,
    "scheduler_time": 102.594223337776
}
#Debug simulation 
Total elapsed time: 8.80748861702159. Arrivals time: 0.32406005123630166 Scheduler time: 8.346264040563256 Scheduler overhead time: 0.04987782333046198 Adapter cache time: 0.013186518102884293 Engine time: 0.051020420622080564 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-32/adapters_32_slots_32_rate_3.2-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-32/adapters_32_slots_32_rate_3.2-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 540, 66, 66, 540, 66, 34560, 540, 66, 66, 66, 34560, 34560, 66, 66, 540, 540, 540, 34560, 34560, 66, 34560, 34560, 34560, 34560, 540, 66, 540, 540, 540, 540, 34560]
Prompts retrieved: 386760 . Total input tokens: 86146875 . Total output tokens: 77349204
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.827136578038335,
    "estimated_duration": 3600.037070461129,
    "input_throughput": 8575.408362682674,
    "output_throughput": 7537.417106797813,
    "total_throughput": 16112.825469480487,
    "itl": 112.70080797209263,
    "ttft": 182495.52016246534,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145734,
    "arrivals": 128685,
    "finished_requests": 123970,
    "scheduler_time": 102.59152474507158
}
#Debug simulation 
Total elapsed time: 8.827238698955625. Arrivals time: 0.33782618679106236 Scheduler time: 8.352649008389562 Scheduler overhead time: 0.05002388311550021 Adapter cache time: 0.013063179329037666 Engine time: 0.05080073093995452 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-8/adapters_32_slots_32_rate_3.2-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-8/adapters_32_slots_32_rate_3.2-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 540, 33, 33, 540, 33, 34560, 540, 33, 33, 33, 34560, 34560, 33, 33, 540, 540, 540, 34560, 34560, 33, 34560, 34560, 34560, 34560, 540, 33, 540, 540, 540, 540, 34560]
Prompts retrieved: 386430 . Total input tokens: 86078451 . Total output tokens: 77288425
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 8.832938936073333,
    "estimated_duration": 3600.0775012066356,
    "input_throughput": 8507.417962456266,
    "output_throughput": 7590.520479306629,
    "total_throughput": 16097.938441762893,
    "itl": 112.41346543815193,
    "ttft": 160931.60330449822,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 128584,
    "finished_requests": 124333,
    "scheduler_time": 103.77133880305755
}
#Debug simulation 
Total elapsed time: 8.833032498136163. Arrivals time: 0.328177020419389 Scheduler time: 8.36862824484706 Scheduler overhead time: 0.05008085770532489 Adapter cache time: 0.012576872948557138 Engine time: 0.050576071720570326 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-16/adapters_32_slots_32_rate_3.2-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-16/adapters_32_slots_32_rate_3.2-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 540, 33, 33, 540, 33, 34560, 540, 33, 33, 33, 34560, 34560, 33, 33, 540, 540, 540, 34560, 34560, 33, 34560, 34560, 34560, 34560, 540, 33, 540, 540, 540, 540, 34560]
Prompts retrieved: 386430 . Total input tokens: 86078451 . Total output tokens: 77288425
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.911286241840571,
    "estimated_duration": 3600.1200173094535,
    "input_throughput": 8507.3505474102,
    "output_throughput": 7590.563055845778,
    "total_throughput": 16097.913603255978,
    "itl": 112.41378659570354,
    "ttft": 160974.0201208708,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255727,
    "arrivals": 128584,
    "finished_requests": 124335,
    "scheduler_time": 103.77348015737242
}
#Debug simulation 
Total elapsed time: 8.911382307764143. Arrivals time: 0.331356308888644 Scheduler time: 8.443550722207874 Scheduler overhead time: 0.049933734349906445 Adapter cache time: 0.012321742717176676 Engine time: 0.05120742367580533 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-32/adapters_32_slots_32_rate_3.2-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-32/adapters_32_slots_32_rate_3.2-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 540, 33, 33, 540, 33, 34560, 540, 33, 33, 33, 34560, 34560, 33, 33, 540, 540, 540, 34560, 34560, 33, 34560, 34560, 34560, 34560, 540, 33, 540, 540, 540, 540, 34560]
Prompts retrieved: 386430 . Total input tokens: 86078451 . Total output tokens: 77288425
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.841833922080696,
    "estimated_duration": 3600.1221384414175,
    "input_throughput": 8507.345535021042,
    "output_throughput": 7590.55858361253,
    "total_throughput": 16097.904118633573,
    "itl": 112.41383749332547,
    "ttft": 160975.90119971838,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033041,
    "arrivals": 128584,
    "finished_requests": 124335,
    "scheduler_time": 103.77344167605244
}
#Debug simulation 
Total elapsed time: 8.84197080694139. Arrivals time: 0.32451788801699877 Scheduler time: 8.38091535307467 Scheduler overhead time: 0.05012876633554697 Adapter cache time: 0.012524199672043324 Engine time: 0.05085441330447793 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-16/adapters_32_slots_32_rate_3.2-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-16/adapters_32_slots_32_rate_3.2-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 540, 33, 33, 540, 33, 34560, 540, 33, 33, 33, 34560, 34560, 33, 33, 540, 540, 540, 34560, 34560, 33, 34560, 34560, 34560, 34560, 540, 33, 540, 540, 540, 540, 34560]
Prompts retrieved: 386430 . Total input tokens: 86078451 . Total output tokens: 77288425
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 8.902086247690022,
    "estimated_duration": 3600.087872982891,
    "input_throughput": 8507.420118782627,
    "output_throughput": 7590.629163548161,
    "total_throughput": 16098.049282330787,
    "itl": 112.41346100358187,
    "ttft": 160895.07078161524,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971348,
    "arrivals": 128584,
    "finished_requests": 124334,
    "scheduler_time": 103.772493124704
}
#Debug simulation 
Total elapsed time: 8.902177631855011. Arrivals time: 0.3414301909506321 Scheduler time: 8.424159921705723 Scheduler overhead time: 0.05019062664359808 Adapter cache time: 0.012541798874735832 Engine time: 0.05091819912195206 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-32/adapters_32_slots_32_rate_3.2-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-32/adapters_32_slots_32_rate_3.2-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 540, 33, 33, 540, 33, 34560, 540, 33, 33, 33, 34560, 34560, 33, 33, 540, 540, 540, 34560, 34560, 33, 34560, 34560, 34560, 34560, 540, 33, 540, 540, 540, 540, 34560]
Prompts retrieved: 386430 . Total input tokens: 86078451 . Total output tokens: 77288425
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 8.8439802210778,
    "estimated_duration": 3600.1215918338144,
    "input_throughput": 8507.346826694013,
    "output_throughput": 7590.559736089448,
    "total_throughput": 16097.90656278346,
    "itl": 112.41369971693305,
    "ttft": 160975.41746385285,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089387,
    "arrivals": 128584,
    "finished_requests": 124335,
    "scheduler_time": 103.77343082941987
}
#Debug simulation 
Total elapsed time: 8.8440963877365. Arrivals time: 0.3190790773369372 Scheduler time: 8.389122097287327 Scheduler overhead time: 0.04986220505088568 Adapter cache time: 0.012419071048498154 Engine time: 0.05063051776960492 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-16/adapters_32_slots_32_rate_3.2-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-16/adapters_32_slots_32_rate_3.2-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 540, 33, 33, 540, 33, 34560, 540, 33, 33, 33, 34560, 34560, 33, 33, 540, 540, 540, 34560, 34560, 33, 34560, 34560, 34560, 34560, 540, 33, 540, 540, 540, 540, 34560]
Prompts retrieved: 386430 . Total input tokens: 86078451 . Total output tokens: 77288425
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 8.80924071976915,
    "estimated_duration": 3600.0574474413265,
    "input_throughput": 8507.465352189818,
    "output_throughput": 7590.562761553089,
    "total_throughput": 16098.028113742906,
    "itl": 112.41313424339741,
    "ttft": 160866.105843987,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 128584,
    "finished_requests": 124333,
    "scheduler_time": 103.77160286895517
}
#Debug simulation 
Total elapsed time: 8.809399909805506. Arrivals time: 0.31964330980554223 Scheduler time: 8.353637692052871 Scheduler overhead time: 0.04993012687191367 Adapter cache time: 0.012385322246700525 Engine time: 0.0508527522906661 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-32/adapters_32_slots_32_rate_3.2-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-32/adapters_32_slots_32_rate_3.2-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 540, 33, 33, 540, 33, 34560, 540, 33, 33, 33, 34560, 34560, 33, 33, 540, 540, 540, 34560, 34560, 33, 34560, 34560, 34560, 34560, 540, 33, 540, 540, 540, 540, 34560]
Prompts retrieved: 386430 . Total input tokens: 86078451 . Total output tokens: 77288425
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.834975581150502,
    "estimated_duration": 3600.120521118453,
    "input_throughput": 8507.349356872344,
    "output_throughput": 7590.561993605234,
    "total_throughput": 16097.91135047758,
    "itl": 112.4135055526208,
    "ttft": 160974.4859797574,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145733,
    "arrivals": 128584,
    "finished_requests": 124335,
    "scheduler_time": 103.77338959697957
}
#Debug simulation 
Total elapsed time: 8.83506748918444. Arrivals time: 0.3325373553670943 Scheduler time: 8.366573927458376 Scheduler overhead time: 0.04986487654969096 Adapter cache time: 0.012410581577569246 Engine time: 0.050680011510849 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-8/adapters_32_slots_32_rate_3.2-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-8/adapters_32_slots_32_rate_3.2-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 135, 135, 270, 135, 34560, 270, 135, 135, 135, 34560, 34560, 135, 135, 270, 270, 270, 34560, 34560, 135, 34560, 34560, 34560, 34560, 270, 135, 270, 270, 270, 270, 34560]
Prompts retrieved: 384480 . Total input tokens: 85647737 . Total output tokens: 76906968
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 8.849845953285694,
    "estimated_duration": 3600.0974723800296,
    "input_throughput": 8645.976182256622,
    "output_throughput": 7598.858144780867,
    "total_throughput": 16244.834327037488,
    "itl": 110.75750967796613,
    "ttft": 105090.22159192694,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 127929,
    "finished_requests": 125119,
    "scheduler_time": 104.48673342627511
}
#Debug simulation 
Total elapsed time: 8.849939770065248. Arrivals time: 0.33706096978858113 Scheduler time: 8.373903959058225 Scheduler overhead time: 0.0504623674787581 Adapter cache time: 0.013677734415978193 Engine time: 0.05172601016238332 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-16/adapters_32_slots_32_rate_3.2-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-16/adapters_32_slots_32_rate_3.2-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 135, 135, 270, 135, 34560, 270, 135, 135, 135, 34560, 34560, 135, 135, 270, 270, 270, 34560, 34560, 135, 34560, 34560, 34560, 34560, 270, 135, 270, 270, 270, 270, 34560]
Prompts retrieved: 384480 . Total input tokens: 85647737 . Total output tokens: 76906968
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.824073725845665,
    "estimated_duration": 3600.1187755318374,
    "input_throughput": 8646.06168317369,
    "output_throughput": 7598.869566729402,
    "total_throughput": 16244.931249903091,
    "itl": 110.75747702711918,
    "ttft": 105063.58924734258,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255727,
    "arrivals": 127929,
    "finished_requests": 125120,
    "scheduler_time": 104.48720065718888
}
#Debug simulation 
Total elapsed time: 8.824172535911202. Arrivals time: 0.3202261640690267 Scheduler time: 8.365860659163445 Scheduler overhead time: 0.05054852133616805 Adapter cache time: 0.01317492127418518 Engine time: 0.05114501854404807 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-32/adapters_32_slots_32_rate_3.2-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-32/adapters_32_slots_32_rate_3.2-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 135, 135, 270, 135, 34560, 270, 135, 135, 135, 34560, 34560, 135, 135, 270, 270, 270, 34560, 34560, 135, 34560, 34560, 34560, 34560, 270, 135, 270, 270, 270, 270, 34560]
Prompts retrieved: 384480 . Total input tokens: 85647737 . Total output tokens: 76906968
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.839952467940748,
    "estimated_duration": 3600.1190013230025,
    "input_throughput": 8646.06114091263,
    "output_throughput": 7598.869090145819,
    "total_throughput": 16244.93023105845,
    "itl": 110.75749425377909,
    "ttft": 105063.80336472868,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033041,
    "arrivals": 127929,
    "finished_requests": 125120,
    "scheduler_time": 104.48719486801654
}
#Debug simulation 
Total elapsed time: 8.840116263832897. Arrivals time: 0.31924476101994514 Scheduler time: 8.382028181571513 Scheduler overhead time: 0.05041628563776612 Adapter cache time: 0.013495375867933035 Engine time: 0.051708378829061985 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-16/adapters_32_slots_32_rate_3.2-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-16/adapters_32_slots_32_rate_3.2-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 135, 135, 270, 135, 34560, 270, 135, 135, 135, 34560, 34560, 135, 135, 270, 270, 270, 34560, 34560, 135, 34560, 34560, 34560, 34560, 270, 135, 270, 270, 270, 270, 34560]
Prompts retrieved: 384480 . Total input tokens: 85647737 . Total output tokens: 76906968
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 8.925735989585519,
    "estimated_duration": 3600.110318007876,
    "input_throughput": 8645.945332370758,
    "output_throughput": 7598.831031138461,
    "total_throughput": 16244.77636350922,
    "itl": 110.75750720974159,
    "ttft": 105093.67790055163,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971346,
    "arrivals": 127929,
    "finished_requests": 125119,
    "scheduler_time": 104.48685387485638
}
#Debug simulation 
Total elapsed time: 8.925827435683459. Arrivals time: 0.34084837045520544 Scheduler time: 8.445437974762172 Scheduler overhead time: 0.050440531224012375 Adapter cache time: 0.013726254925131798 Engine time: 0.052044648211449385 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-32/adapters_32_slots_32_rate_3.2-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-32/adapters_32_slots_32_rate_3.2-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 135, 135, 270, 135, 34560, 270, 135, 135, 135, 34560, 34560, 135, 135, 270, 270, 270, 34560, 34560, 135, 34560, 34560, 34560, 34560, 270, 135, 270, 270, 270, 270, 34560]
Prompts retrieved: 384480 . Total input tokens: 85647737 . Total output tokens: 76906968
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 8.815607178024948,
    "estimated_duration": 3600.118216690165,
    "input_throughput": 8646.063025290608,
    "output_throughput": 7598.870746292051,
    "total_throughput": 16244.93377158266,
    "itl": 110.75735050515183,
    "ttft": 105063.07614895143,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089386,
    "arrivals": 127929,
    "finished_requests": 125120,
    "scheduler_time": 104.48720726001085
}
#Debug simulation 
Total elapsed time: 8.815707374829799. Arrivals time: 0.32691306341439486 Scheduler time: 8.350185091607273 Scheduler overhead time: 0.05054972227662802 Adapter cache time: 0.013486480340361595 Engine time: 0.05139701347798109 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-16/adapters_32_slots_32_rate_3.2-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-16/adapters_32_slots_32_rate_3.2-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 135, 135, 270, 135, 34560, 270, 135, 135, 135, 34560, 34560, 135, 135, 270, 270, 270, 34560, 34560, 135, 34560, 34560, 34560, 34560, 270, 135, 270, 270, 270, 270, 34560]
Prompts retrieved: 384480 . Total input tokens: 85647737 . Total output tokens: 76906968
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 8.875087190885097,
    "estimated_duration": 3600.09862685828,
    "input_throughput": 8645.973409668286,
    "output_throughput": 7598.855707981944,
    "total_throughput": 16244.82911765023,
    "itl": 110.75808719890095,
    "ttft": 105092.2087354944,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 127929,
    "finished_requests": 125119,
    "scheduler_time": 104.48629952545645
}
#Debug simulation 
Total elapsed time: 8.875197147019207. Arrivals time: 0.322624237742275 Scheduler time: 8.413077217526734 Scheduler overhead time: 0.050540050491690636 Adapter cache time: 0.013333802577108145 Engine time: 0.05221765488386154 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-32/adapters_32_slots_32_rate_3.2-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-32/adapters_32_slots_32_rate_3.2-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 135, 135, 270, 135, 34560, 270, 135, 135, 135, 34560, 34560, 135, 135, 270, 270, 270, 34560, 34560, 135, 34560, 34560, 34560, 34560, 270, 135, 270, 270, 270, 270, 34560]
Prompts retrieved: 384480 . Total input tokens: 85647737 . Total output tokens: 76906968
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.872457911726087,
    "estimated_duration": 3600.1166844288296,
    "input_throughput": 8646.066705179135,
    "output_throughput": 7598.873980480511,
    "total_throughput": 16244.940685659645,
    "itl": 110.75705131756303,
    "ttft": 105062.75495074294,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145731,
    "arrivals": 127929,
    "finished_requests": 125120,
    "scheduler_time": 104.48716746168093
}
#Debug simulation 
Total elapsed time: 8.872591888997704. Arrivals time: 0.3250258336775005 Scheduler time: 8.40876769926399 Scheduler overhead time: 0.05027272691950202 Adapter cache time: 0.013573329895734787 Engine time: 0.05176596576347947 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-8/adapters_32_slots_32_rate_3.2-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-8/adapters_32_slots_32_rate_3.2-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 66, 66, 270, 66, 34560, 270, 66, 66, 66, 34560, 34560, 66, 66, 270, 270, 270, 34560, 34560, 66, 34560, 34560, 34560, 34560, 270, 66, 270, 270, 270, 270, 34560]
Prompts retrieved: 383790 . Total input tokens: 85486715 . Total output tokens: 76768251
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 8.979923186823726,
    "estimated_duration": 3600.0950928144844,
    "input_throughput": 8597.152631266596,
    "output_throughput": 7697.015019216304,
    "total_throughput": 16294.1676504829,
    "itl": 110.75669731269262,
    "ttft": 78495.53814891474,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 127708,
    "finished_requests": 125584,
    "scheduler_time": 106.22246895958038
}
#Debug simulation 
Total elapsed time: 8.980028524063528. Arrivals time: 0.3593186247162521 Scheduler time: 8.482414453290403 Scheduler overhead time: 0.050493617076426744 Adapter cache time: 0.013058388140052557 Engine time: 0.051522019784897566 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-16/adapters_32_slots_32_rate_3.2-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-16/adapters_32_slots_32_rate_3.2-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 66, 66, 270, 66, 34560, 270, 66, 66, 66, 34560, 34560, 66, 66, 270, 270, 270, 34560, 34560, 66, 34560, 34560, 34560, 34560, 270, 66, 270, 270, 270, 270, 34560]
Prompts retrieved: 383790 . Total input tokens: 85486715 . Total output tokens: 76768251
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.949145906139165,
    "estimated_duration": 3600.0008514236383,
    "input_throughput": 8597.377411108235,
    "output_throughput": 7697.07012403682,
    "total_throughput": 16294.447535145055,
    "itl": 110.75641530710142,
    "ttft": 78432.25096599678,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255728,
    "arrivals": 127708,
    "finished_requests": 125583,
    "scheduler_time": 106.22070262573132
}
#Debug simulation 
Total elapsed time: 8.9492357801646. Arrivals time: 0.3249449306167662 Scheduler time: 8.487126638181508 Scheduler overhead time: 0.050215103663504124 Adapter cache time: 0.012825186364352703 Engine time: 0.05106980726122856 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-32/adapters_32_slots_32_rate_3.2-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-32/adapters_32_slots_32_rate_3.2-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 66, 66, 270, 66, 34560, 270, 66, 66, 66, 34560, 34560, 66, 66, 270, 270, 270, 34560, 34560, 66, 34560, 34560, 34560, 34560, 270, 66, 270, 270, 270, 270, 34560]
Prompts retrieved: 383790 . Total input tokens: 85486715 . Total output tokens: 76768251
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.910558812785894,
    "estimated_duration": 3600.001000504948,
    "input_throughput": 8597.377055078254,
    "output_throughput": 7697.0698052898815,
    "total_throughput": 16294.446860368136,
    "itl": 110.75642251979372,
    "ttft": 78432.3855292696,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033041,
    "arrivals": 127708,
    "finished_requests": 125583,
    "scheduler_time": 106.22069729899201
}
#Debug simulation 
Total elapsed time: 8.910687095951289. Arrivals time: 0.3115764381363988 Scheduler time: 8.461531766690314 Scheduler overhead time: 0.050707466434687376 Adapter cache time: 0.012487569823861122 Engine time: 0.051079809200018644 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-16/adapters_32_slots_32_rate_3.2-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-16/adapters_32_slots_32_rate_3.2-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 66, 66, 270, 66, 34560, 270, 66, 66, 66, 34560, 34560, 66, 66, 270, 270, 270, 34560, 34560, 66, 34560, 34560, 34560, 34560, 270, 66, 270, 270, 270, 270, 34560]
Prompts retrieved: 383790 . Total input tokens: 85486715 . Total output tokens: 76768251
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 8.926240986213088,
    "estimated_duration": 3600.1173930407217,
    "input_throughput": 8597.231040251778,
    "output_throughput": 7697.099559466104,
    "total_throughput": 16294.330599717881,
    "itl": 110.75680463354772,
    "ttft": 78456.5176301344,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971348,
    "arrivals": 127708,
    "finished_requests": 125586,
    "scheduler_time": 106.22451357803618
}
#Debug simulation 
Total elapsed time: 8.926337861921638. Arrivals time: 0.32688157353550196 Scheduler time: 8.461796411313117 Scheduler overhead time: 0.05034859012812376 Adapter cache time: 0.012834663968533278 Engine time: 0.051353029906749725 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-32/adapters_32_slots_32_rate_3.2-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-32/adapters_32_slots_32_rate_3.2-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 66, 66, 270, 66, 34560, 270, 66, 66, 66, 34560, 34560, 66, 66, 270, 270, 270, 34560, 34560, 66, 34560, 34560, 34560, 34560, 270, 66, 270, 270, 270, 270, 34560]
Prompts retrieved: 383790 . Total input tokens: 85486715 . Total output tokens: 76768251
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 8.947502276860178,
    "estimated_duration": 3600.0031589139353,
    "input_throughput": 8597.372178233672,
    "output_throughput": 7697.2115792141885,
    "total_throughput": 16294.583757447861,
    "itl": 110.75652332855708,
    "ttft": 78404.76371251418,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089388,
    "arrivals": 127708,
    "finished_requests": 125584,
    "scheduler_time": 106.2208205631937
}
#Debug simulation 
Total elapsed time: 8.947616868186742. Arrivals time: 0.3286964828148484 Scheduler time: 8.481348336674273 Scheduler overhead time: 0.05040689371526241 Adapter cache time: 0.012954490259289742 Engine time: 0.0509626567363739 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-16/adapters_32_slots_32_rate_3.2-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-16/adapters_32_slots_32_rate_3.2-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 66, 66, 270, 66, 34560, 270, 66, 66, 66, 34560, 34560, 66, 66, 270, 270, 270, 34560, 34560, 66, 34560, 34560, 34560, 34560, 270, 66, 270, 270, 270, 270, 34560]
Prompts retrieved: 383790 . Total input tokens: 85486715 . Total output tokens: 76768251
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 8.96910428488627,
    "estimated_duration": 3600.1020382536453,
    "input_throughput": 8597.247153309532,
    "output_throughput": 7697.047112987324,
    "total_throughput": 16294.294266296856,
    "itl": 110.75723399724757,
    "ttft": 78470.33716782197,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 127708,
    "finished_requests": 125585,
    "scheduler_time": 106.22253332524363
}
#Debug simulation 
Total elapsed time: 8.969234032090753. Arrivals time: 0.3570597297511995 Scheduler time: 8.473797193262726 Scheduler overhead time: 0.050718430895358324 Adapter cache time: 0.012754178140312433 Engine time: 0.05148337222635746 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-32/adapters_32_slots_32_rate_3.2-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-32/adapters_32_slots_32_rate_3.2-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 66, 66, 270, 66, 34560, 270, 66, 66, 66, 34560, 34560, 66, 66, 270, 270, 270, 34560, 34560, 66, 34560, 34560, 34560, 34560, 270, 66, 270, 270, 270, 270, 34560]
Prompts retrieved: 383790 . Total input tokens: 85486715 . Total output tokens: 76768251
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.882531619165093,
    "estimated_duration": 3600.002849749222,
    "input_throughput": 8597.372916567561,
    "output_throughput": 7697.212240243168,
    "total_throughput": 16294.585156810728,
    "itl": 110.75632341730294,
    "ttft": 78404.51239619078,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145734,
    "arrivals": 127708,
    "finished_requests": 125584,
    "scheduler_time": 106.22086860334267
}
#Debug simulation 
Total elapsed time: 8.88265870232135. Arrivals time: 0.31710146786645055 Scheduler time: 8.428201743401587 Scheduler overhead time: 0.05041436245664954 Adapter cache time: 0.012579001486301422 Engine time: 0.05124373268336058 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-8/adapters_32_slots_32_rate_3.2-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-8/adapters_32_slots_32_rate_3.2-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 33, 33, 270, 33, 34560, 270, 33, 33, 33, 34560, 34560, 33, 33, 270, 270, 270, 34560, 34560, 33, 34560, 34560, 34560, 34560, 270, 33, 270, 270, 270, 270, 34560]
Prompts retrieved: 383460 . Total input tokens: 85416634 . Total output tokens: 76698531
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 8.933842664584517,
    "estimated_duration": 3600.0206784513825,
    "input_throughput": 8685.917607965286,
    "output_throughput": 7729.055881970476,
    "total_throughput": 16414.97348993576,
    "itl": 108.79697178345128,
    "ttft": 34752.330286075754,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 127594,
    "finished_requests": 126504,
    "scheduler_time": 107.21676535423931
}
#Debug simulation 
Total elapsed time: 8.933961941860616. Arrivals time: 0.31723590195178986 Scheduler time: 8.479154718108475 Scheduler overhead time: 0.05074754869565368 Adapter cache time: 0.012000668793916702 Engine time: 0.05147364595904946 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-16/adapters_32_slots_32_rate_3.2-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-16/adapters_32_slots_32_rate_3.2-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 33, 33, 270, 33, 34560, 270, 33, 33, 33, 34560, 34560, 33, 33, 270, 270, 270, 34560, 34560, 33, 34560, 34560, 34560, 34560, 270, 33, 270, 270, 270, 270, 34560]
Prompts retrieved: 383460 . Total input tokens: 85416634 . Total output tokens: 76698531
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.969065974000841,
    "estimated_duration": 3600.094391114909,
    "input_throughput": 8685.739762038904,
    "output_throughput": 7728.897627982188,
    "total_throughput": 16414.637390021093,
    "itl": 108.79788383550851,
    "ttft": 34812.18896066416,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255727,
    "arrivals": 127594,
    "finished_requests": 126504,
    "scheduler_time": 107.21868851112322
}
#Debug simulation 
Total elapsed time: 8.969277950935066. Arrivals time: 0.3153399280272424 Scheduler time: 8.515169949270785 Scheduler overhead time: 0.05091266147792339 Adapter cache time: 0.012178029865026474 Engine time: 0.052014414221048355 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-32/adapters_32_slots_32_rate_3.2-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-32/adapters_32_slots_32_rate_3.2-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 33, 33, 270, 33, 34560, 270, 33, 33, 33, 34560, 34560, 33, 33, 270, 270, 270, 34560, 34560, 33, 34560, 34560, 34560, 34560, 270, 33, 270, 270, 270, 270, 34560]
Prompts retrieved: 383460 . Total input tokens: 85416634 . Total output tokens: 76698531
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.942858606111258,
    "estimated_duration": 3600.0943952185776,
    "input_throughput": 8685.739752138219,
    "output_throughput": 7728.897619172188,
    "total_throughput": 16414.637371310408,
    "itl": 108.79789586260716,
    "ttft": 34812.15267545662,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033041,
    "arrivals": 127594,
    "finished_requests": 126504,
    "scheduler_time": 107.21871821792672
}
#Debug simulation 
Total elapsed time: 8.942970869131386. Arrivals time: 0.31005829060450196 Scheduler time: 8.4950947239995 Scheduler overhead time: 0.05087778810411692 Adapter cache time: 0.011913795489817858 Engine time: 0.05169981764629483 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-16/adapters_32_slots_32_rate_3.2-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-16/adapters_32_slots_32_rate_3.2-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 33, 33, 270, 33, 34560, 270, 33, 33, 33, 34560, 34560, 33, 33, 270, 270, 270, 34560, 34560, 33, 34560, 34560, 34560, 34560, 270, 33, 270, 270, 270, 270, 34560]
Prompts retrieved: 383460 . Total input tokens: 85416634 . Total output tokens: 76698531
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 8.932336841709912,
    "estimated_duration": 3600.0206254550344,
    "input_throughput": 8685.917735831752,
    "output_throughput": 7729.055995750861,
    "total_throughput": 16414.973731582613,
    "itl": 108.79679745106964,
    "ttft": 34752.20748172224,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971346,
    "arrivals": 127594,
    "finished_requests": 126504,
    "scheduler_time": 107.21672602419054
}
#Debug simulation 
Total elapsed time: 8.93245015759021. Arrivals time: 0.31712164683267474 Scheduler time: 8.478109871968627 Scheduler overhead time: 0.050697604194283485 Adapter cache time: 0.011807837523519993 Engine time: 0.05140177300199866 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-32/adapters_32_slots_32_rate_3.2-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-32/adapters_32_slots_32_rate_3.2-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 33, 33, 270, 33, 34560, 270, 33, 33, 33, 34560, 34560, 33, 33, 270, 270, 270, 34560, 34560, 33, 34560, 34560, 34560, 34560, 270, 33, 270, 270, 270, 270, 34560]
Prompts retrieved: 383460 . Total input tokens: 85416634 . Total output tokens: 76698531
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 8.927406562957913,
    "estimated_duration": 3600.0946646546317,
    "input_throughput": 8685.739102085467,
    "output_throughput": 7728.897040730821,
    "total_throughput": 16414.63614281629,
    "itl": 108.79774515218621,
    "ttft": 34812.49370518066,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089387,
    "arrivals": 127594,
    "finished_requests": 126504,
    "scheduler_time": 107.21864925716379
}
#Debug simulation 
Total elapsed time: 8.927491727285087. Arrivals time: 0.3164711082354188 Scheduler time: 8.472856587264687 Scheduler overhead time: 0.05107034835964441 Adapter cache time: 0.011854657903313637 Engine time: 0.05166442459449172 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-16/adapters_32_slots_32_rate_3.2-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-16/adapters_32_slots_32_rate_3.2-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 33, 33, 270, 33, 34560, 270, 33, 33, 33, 34560, 34560, 33, 33, 270, 270, 270, 34560, 34560, 33, 34560, 34560, 34560, 34560, 270, 33, 270, 270, 270, 270, 34560]
Prompts retrieved: 383460 . Total input tokens: 85416634 . Total output tokens: 76698531
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 8.956046949140728,
    "estimated_duration": 3600.0152588791516,
    "input_throughput": 8685.93068400927,
    "output_throughput": 7729.067517525777,
    "total_throughput": 16414.998201535047,
    "itl": 108.797015540092,
    "ttft": 34750.851382980516,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 127594,
    "finished_requests": 126504,
    "scheduler_time": 107.2167825286027
}
#Debug simulation 
Total elapsed time: 8.956203202717006. Arrivals time: 0.3129534595645964 Scheduler time: 8.50482266722247 Scheduler overhead time: 0.05078946193680167 Adapter cache time: 0.012048052158206701 Engine time: 0.05199469020590186 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-32/adapters_32_slots_32_rate_3.2-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-32/adapters_32_slots_32_rate_3.2-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 33, 33, 270, 33, 34560, 270, 33, 33, 33, 34560, 34560, 33, 33, 270, 270, 270, 34560, 34560, 33, 34560, 34560, 34560, 34560, 270, 33, 270, 270, 270, 270, 34560]
Prompts retrieved: 383460 . Total input tokens: 85416634 . Total output tokens: 76698531
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.890642860904336,
    "estimated_duration": 3600.093990571848,
    "input_throughput": 8685.740728406116,
    "output_throughput": 7728.898487892047,
    "total_throughput": 16414.63921629816,
    "itl": 108.79754314134662,
    "ttft": 34812.21748534649,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145733,
    "arrivals": 127594,
    "finished_requests": 126504,
    "scheduler_time": 107.21861472118037
}
#Debug simulation 
Total elapsed time: 8.890739154070616. Arrivals time: 0.3075937912799418 Scheduler time: 8.44550252566114 Scheduler overhead time: 0.0509489388205111 Adapter cache time: 0.011877440847456455 Engine time: 0.05140951694920659 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-8/adapters_32_slots_32_rate_3.2-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-8/adapters_32_slots_32_rate_3.2-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 135, 66, 66, 135, 66, 34560, 135, 66, 66, 66, 34560, 34560, 66, 66, 135, 135, 135, 34560, 34560, 66, 34560, 34560, 34560, 34560, 135, 66, 135, 135, 135, 135, 34560]
Prompts retrieved: 382305 . Total input tokens: 85170431 . Total output tokens: 76468123
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 8.924199039116502,
    "estimated_duration": 3600.087388216883,
    "input_throughput": 8678.980988701955,
    "output_throughput": 7690.16610280465,
    "total_throughput": 16369.147091506606,
    "itl": 98.95257198818938,
    "ttft": 23783.55731936683,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 127174,
    "finished_requests": 126345,
    "scheduler_time": 106.05698613155324
}
#Debug simulation 
Total elapsed time: 8.92432246170938. Arrivals time: 0.31801264360547066 Scheduler time: 8.457765008788556 Scheduler overhead time: 0.054979430977255106 Adapter cache time: 0.012423841748386621 Engine time: 0.05592427169904113 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-16/adapters_32_slots_32_rate_3.2-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-16/adapters_32_slots_32_rate_3.2-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 135, 66, 66, 135, 66, 34560, 135, 66, 66, 66, 34560, 34560, 66, 66, 135, 135, 135, 34560, 34560, 66, 34560, 34560, 34560, 34560, 135, 66, 135, 135, 135, 135, 34560]
Prompts retrieved: 382305 . Total input tokens: 85170431 . Total output tokens: 76468123
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.887632488738745,
    "estimated_duration": 3600.0847489259468,
    "input_throughput": 8678.987351428794,
    "output_throughput": 7690.171740612399,
    "total_throughput": 16369.159092041195,
    "itl": 98.95199467462253,
    "ttft": 23784.407600902457,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255727,
    "arrivals": 127174,
    "finished_requests": 126345,
    "scheduler_time": 106.05686730432716
}
#Debug simulation 
Total elapsed time: 8.887774249073118. Arrivals time: 0.31217041052877903 Scheduler time: 8.427953533828259 Scheduler overhead time: 0.054680051282048225 Adapter cache time: 0.012660468928515911 Engine time: 0.0552817084826529 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-32/adapters_32_slots_32_rate_3.2-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-32/adapters_32_slots_32_rate_3.2-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 135, 66, 66, 135, 66, 34560, 135, 66, 66, 66, 34560, 34560, 66, 66, 135, 135, 135, 34560, 34560, 66, 34560, 34560, 34560, 34560, 135, 66, 135, 135, 135, 135, 34560]
Prompts retrieved: 382305 . Total input tokens: 85170431 . Total output tokens: 76468123
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.907305212691426,
    "estimated_duration": 3600.0991714340867,
    "input_throughput": 8678.98785897989,
    "output_throughput": 7690.283150997607,
    "total_throughput": 16369.271009977496,
    "itl": 98.95212266007005,
    "ttft": 23756.84211663849,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033041,
    "arrivals": 127174,
    "finished_requests": 126346,
    "scheduler_time": 106.05731606142413
}
#Debug simulation 
Total elapsed time: 8.90744715090841. Arrivals time: 0.3047879640944302 Scheduler time: 8.455215285532176 Scheduler overhead time: 0.054615148808807135 Adapter cache time: 0.012142266612499952 Engine time: 0.0556278177537024 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-16/adapters_32_slots_32_rate_3.2-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-16/adapters_32_slots_32_rate_3.2-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 135, 66, 66, 135, 66, 34560, 135, 66, 66, 66, 34560, 34560, 66, 66, 135, 135, 135, 34560, 34560, 66, 34560, 34560, 34560, 34560, 135, 66, 135, 135, 135, 135, 34560]
Prompts retrieved: 382305 . Total input tokens: 85170431 . Total output tokens: 76468123
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 8.842175932135433,
    "estimated_duration": 3600.026092409749,
    "input_throughput": 8678.954595877914,
    "output_throughput": 7690.167595832237,
    "total_throughput": 16369.122191710152,
    "itl": 98.9506973067851,
    "ttft": 23784.05395975252,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971346,
    "arrivals": 127174,
    "finished_requests": 126343,
    "scheduler_time": 106.05502284260653
}
#Debug simulation 
Total elapsed time: 8.842278821859509. Arrivals time: 0.3100928021594882 Scheduler time: 8.384658315684646 Scheduler overhead time: 0.05465252511203289 Adapter cache time: 0.012165375985205173 Engine time: 0.05552083533257246 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-32/adapters_32_slots_32_rate_3.2-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-32/adapters_32_slots_32_rate_3.2-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 135, 66, 66, 135, 66, 34560, 135, 66, 66, 66, 34560, 34560, 66, 66, 135, 135, 135, 34560, 34560, 66, 34560, 34560, 34560, 34560, 135, 66, 135, 135, 135, 135, 34560]
Prompts retrieved: 382305 . Total input tokens: 85170431 . Total output tokens: 76468123
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 8.867681975942105,
    "estimated_duration": 3600.084768436024,
    "input_throughput": 8678.987304394426,
    "output_throughput": 7690.171698936757,
    "total_throughput": 16369.159003331182,
    "itl": 98.95184618900538,
    "ttft": 23784.41521779413,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089387,
    "arrivals": 127174,
    "finished_requests": 126345,
    "scheduler_time": 106.05680323128827
}
#Debug simulation 
Total elapsed time: 8.867768770083785. Arrivals time: 0.31300684018060565 Scheduler time: 8.407199827488512 Scheduler overhead time: 0.054771109484136105 Adapter cache time: 0.012302234303206205 Engine time: 0.05533576477319002 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-16/adapters_32_slots_32_rate_3.2-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-16/adapters_32_slots_32_rate_3.2-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 135, 66, 66, 135, 66, 34560, 135, 66, 66, 66, 34560, 34560, 66, 66, 135, 135, 135, 34560, 34560, 66, 34560, 34560, 34560, 34560, 135, 66, 135, 135, 135, 135, 34560]
Prompts retrieved: 382305 . Total input tokens: 85170431 . Total output tokens: 76468123
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 8.775491192005575,
    "estimated_duration": 3600.0531611166907,
    "input_throughput": 8678.9823932234,
    "output_throughput": 7690.211994372998,
    "total_throughput": 16369.194387596397,
    "itl": 98.95200636888026,
    "ttft": 23755.310913826397,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 127174,
    "finished_requests": 126344,
    "scheduler_time": 106.05582077026467
}
#Debug simulation 
Total elapsed time: 8.775599521119148. Arrivals time: 0.2656767056323588 Scheduler time: 8.362879970576614 Scheduler overhead time: 0.054767240304499865 Adapter cache time: 0.011731122620403767 Engine time: 0.05532762361690402 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-32/adapters_32_slots_32_rate_3.2-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-32/adapters_32_slots_32_rate_3.2-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 135, 66, 66, 135, 66, 34560, 135, 66, 66, 66, 34560, 34560, 66, 66, 135, 135, 135, 34560, 34560, 66, 34560, 34560, 34560, 34560, 135, 66, 135, 135, 135, 135, 34560]
Prompts retrieved: 382305 . Total input tokens: 85170431 . Total output tokens: 76468123
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.869769440032542,
    "estimated_duration": 3600.0847082610926,
    "input_throughput": 8678.987449462531,
    "output_throughput": 7690.171827476942,
    "total_throughput": 16369.159276939474,
    "itl": 98.95139674163639,
    "ttft": 23784.68998559853,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145733,
    "arrivals": 127174,
    "finished_requests": 126345,
    "scheduler_time": 106.05674600690921
}
#Debug simulation 
Total elapsed time: 8.869878568220884. Arrivals time: 0.3110696286894381 Scheduler time: 8.410447855014354 Scheduler overhead time: 0.05483425687998533 Adapter cache time: 0.01220984198153019 Engine time: 0.05607810756191611 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-8/adapters_32_slots_32_rate_3.2-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-8/adapters_32_slots_32_rate_3.2-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 135, 33, 33, 135, 33, 34560, 135, 33, 33, 33, 34560, 34560, 33, 33, 135, 135, 135, 34560, 34560, 33, 34560, 34560, 34560, 34560, 135, 33, 135, 135, 135, 135, 34560]
Prompts retrieved: 381975 . Total input tokens: 85089706 . Total output tokens: 76410156
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 8.925399689003825,
    "estimated_duration": 3600.011028228135,
    "input_throughput": 8647.14712146912,
    "output_throughput": 7746.175992612217,
    "total_throughput": 16393.323114081337,
    "itl": 99.92345594470612,
    "ttft": 25456.433939985807,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 127046,
    "finished_requests": 126159,
    "scheduler_time": 106.9475240769397
}
#Debug simulation 
Total elapsed time: 8.925500771962106. Arrivals time: 0.33321174373850226 Scheduler time: 8.445451672654599 Scheduler overhead time: 0.0544407912530005 Adapter cache time: 0.011948450468480587 Engine time: 0.055433310102671385 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-16/adapters_32_slots_32_rate_3.2-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-16/adapters_32_slots_32_rate_3.2-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 135, 33, 33, 135, 33, 34560, 135, 33, 33, 33, 34560, 34560, 33, 33, 135, 135, 135, 34560, 34560, 33, 34560, 34560, 34560, 34560, 135, 33, 135, 135, 135, 135, 34560]
Prompts retrieved: 381975 . Total input tokens: 85089706 . Total output tokens: 76410156
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.931842498946935,
    "estimated_duration": 3600.014238746856,
    "input_throughput": 8647.264131609732,
    "output_throughput": 7746.169640069831,
    "total_throughput": 16393.433771679564,
    "itl": 99.92277365223367,
    "ttft": 25426.988849959755,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255728,
    "arrivals": 127046,
    "finished_requests": 126160,
    "scheduler_time": 106.94768658619499
}
#Debug simulation 
Total elapsed time: 8.931967104785144. Arrivals time: 0.33734692446887493 Scheduler time: 8.448764509521425 Scheduler overhead time: 0.05406486336141825 Adapter cache time: 0.011898738332092762 Engine time: 0.0549530191347003 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-32/adapters_32_slots_32_rate_3.2-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-32/adapters_32_slots_32_rate_3.2-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 135, 33, 33, 135, 33, 34560, 135, 33, 33, 33, 34560, 34560, 33, 33, 135, 135, 135, 34560, 34560, 33, 34560, 34560, 34560, 34560, 135, 33, 135, 135, 135, 135, 34560]
Prompts retrieved: 381975 . Total input tokens: 85089706 . Total output tokens: 76410156
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.941234440077096,
    "estimated_duration": 3600.10862082777,
    "input_throughput": 8647.455751721705,
    "output_throughput": 7746.439326485579,
    "total_throughput": 16393.895078207286,
    "itl": 99.92175040477045,
    "ttft": 25285.116898395343,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033042,
    "arrivals": 127046,
    "finished_requests": 126167,
    "scheduler_time": 106.95061190419321
}
#Debug simulation 
Total elapsed time: 8.94133183779195. Arrivals time: 0.309746440500021 Scheduler time: 8.484705447219312 Scheduler overhead time: 0.05450071161612868 Adapter cache time: 0.011845019645988941 Engine time: 0.05547265335917473 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-16/adapters_32_slots_32_rate_3.2-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-16/adapters_32_slots_32_rate_3.2-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 135, 33, 33, 135, 33, 34560, 135, 33, 33, 33, 34560, 34560, 33, 33, 135, 135, 135, 34560, 34560, 33, 34560, 34560, 34560, 34560, 135, 33, 135, 135, 135, 135, 34560]
Prompts retrieved: 381975 . Total input tokens: 85089706 . Total output tokens: 76410156
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 8.976057610940188,
    "estimated_duration": 3600.014264013234,
    "input_throughput": 8647.264070919682,
    "output_throughput": 7746.169585704032,
    "total_throughput": 16393.433656623714,
    "itl": 99.9226538919062,
    "ttft": 25428.458846878446,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971348,
    "arrivals": 127046,
    "finished_requests": 126160,
    "scheduler_time": 106.94754670093084
}
#Debug simulation 
Total elapsed time: 8.976158407982439. Arrivals time: 0.31182248890399933 Scheduler time: 8.518146521411836 Scheduler overhead time: 0.05393896950408816 Adapter cache time: 0.011900622863322496 Engine time: 0.05537260044366121 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-32/adapters_32_slots_32_rate_3.2-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-32/adapters_32_slots_32_rate_3.2-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 135, 33, 33, 135, 33, 34560, 135, 33, 33, 33, 34560, 34560, 33, 33, 135, 135, 135, 34560, 34560, 33, 34560, 34560, 34560, 34560, 135, 33, 135, 135, 135, 135, 34560]
Prompts retrieved: 381975 . Total input tokens: 85089706 . Total output tokens: 76410156
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 8.954127910081297,
    "estimated_duration": 3600.0038837688635,
    "input_throughput": 8647.164004559356,
    "output_throughput": 7746.159976584742,
    "total_throughput": 16393.323981144098,
    "itl": 99.92195511074725,
    "ttft": 25483.76715609911,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089388,
    "arrivals": 127046,
    "finished_requests": 126158,
    "scheduler_time": 106.9475817665426
}
#Debug simulation 
Total elapsed time: 8.954270514659584. Arrivals time: 0.3363782800734043 Scheduler time: 8.471525286324322 Scheduler overhead time: 0.05402469588443637 Adapter cache time: 0.011782621499150991 Engine time: 0.05551964696496725 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-16/adapters_32_slots_32_rate_3.2-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-16/adapters_32_slots_32_rate_3.2-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 135, 33, 33, 135, 33, 34560, 135, 33, 33, 33, 34560, 34560, 33, 33, 135, 135, 135, 34560, 34560, 33, 34560, 34560, 34560, 34560, 135, 33, 135, 135, 135, 135, 34560]
Prompts retrieved: 381975 . Total input tokens: 85089706 . Total output tokens: 76410156
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 8.927346509881318,
    "estimated_duration": 3600.0157651767913,
    "input_throughput": 8647.26046511389,
    "output_throughput": 7746.166355643874,
    "total_throughput": 16393.426820757766,
    "itl": 99.9233060203111,
    "ttft": 25428.618909604327,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 127046,
    "finished_requests": 126160,
    "scheduler_time": 106.94789059156398
}
#Debug simulation 
Total elapsed time: 8.927478020079434. Arrivals time: 0.30752059910446405 Scheduler time: 8.473558264784515 Scheduler overhead time: 0.05426943674683571 Adapter cache time: 0.012074071913957596 Engine time: 0.054956570733338594 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-32/adapters_32_slots_32_rate_3.2-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-32/adapters_32_slots_32_rate_3.2-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 135, 33, 33, 135, 33, 34560, 135, 33, 33, 33, 34560, 34560, 33, 33, 135, 135, 135, 34560, 34560, 33, 34560, 34560, 34560, 34560, 135, 33, 135, 135, 135, 135, 34560]
Prompts retrieved: 381975 . Total input tokens: 85089706 . Total output tokens: 76410156
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.944059689994901,
    "estimated_duration": 3600.0005732552604,
    "input_throughput": 8647.171956378663,
    "output_throughput": 7746.16709985249,
    "total_throughput": 16393.339056231154,
    "itl": 99.92166398733394,
    "ttft": 25483.852916383334,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145734,
    "arrivals": 127046,
    "finished_requests": 126158,
    "scheduler_time": 106.94745695392079
}
#Debug simulation 
Total elapsed time: 8.944147906731814. Arrivals time: 0.31252908566966653 Scheduler time: 8.484205096028745 Scheduler overhead time: 0.05450004432350397 Adapter cache time: 0.01212106877937913 Engine time: 0.055726129561662674 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-8/adapters_32_slots_32_rate_3.2-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-8/adapters_32_slots_32_rate_3.2-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 66, 33, 33, 66, 33, 34560, 66, 33, 33, 33, 34560, 34560, 33, 33, 66, 66, 66, 34560, 34560, 33, 34560, 34560, 34560, 34560, 66, 33, 66, 66, 66, 66, 34560]
Prompts retrieved: 381216 . Total input tokens: 84915272 . Total output tokens: 76248271
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 8.890452215913683,
    "estimated_duration": 3600.0961341140596,
    "input_throughput": 8676.052759820666,
    "output_throughput": 7696.92501748124,
    "total_throughput": 16372.977777301905,
    "itl": 90.3858585669294,
    "ttft": 22417.38425569019,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 126799,
    "finished_requests": 126016,
    "scheduler_time": 105.51092450178425
}
#Debug simulation 
Total elapsed time: 8.890573436859995. Arrivals time: 0.30242371605709195 Scheduler time: 8.429964317008853 Scheduler overhead time: 0.05895119672641158 Adapter cache time: 0.011869147419929504 Engine time: 0.06022446323186159 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-16/adapters_32_slots_32_rate_3.2-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-16/adapters_32_slots_32_rate_3.2-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 66, 33, 33, 66, 33, 34560, 66, 33, 33, 33, 34560, 34560, 33, 33, 66, 66, 66, 34560, 34560, 33, 34560, 34560, 34560, 34560, 66, 33, 66, 66, 66, 66, 34560]
Prompts retrieved: 381216 . Total input tokens: 84915272 . Total output tokens: 76248271
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.83648479403928,
    "estimated_duration": 3600.062884431394,
    "input_throughput": 8676.051225403318,
    "output_throughput": 7696.995549669838,
    "total_throughput": 16373.046775073155,
    "itl": 90.38726832072926,
    "ttft": 22361.316283038544,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255727,
    "arrivals": 126799,
    "finished_requests": 126015,
    "scheduler_time": 105.51009954546957
}
#Debug simulation 
Total elapsed time: 8.836584215052426. Arrivals time: 0.3085684604011476 Scheduler time: 8.369590758811682 Scheduler overhead time: 0.05931918881833553 Adapter cache time: 0.011834975332021713 Engine time: 0.060292520094662905 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-32/adapters_32_slots_32_rate_3.2-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-32/adapters_32_slots_32_rate_3.2-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 66, 33, 33, 66, 33, 34560, 66, 33, 33, 33, 34560, 34560, 33, 33, 66, 66, 66, 34560, 34560, 33, 34560, 34560, 34560, 34560, 66, 33, 66, 66, 66, 66, 34560]
Prompts retrieved: 381216 . Total input tokens: 84915272 . Total output tokens: 76248271
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.856332475319505,
    "estimated_duration": 3600.0863132964787,
    "input_throughput": 8675.994762858829,
    "output_throughput": 7696.945458684623,
    "total_throughput": 16372.940221543453,
    "itl": 90.38789733283801,
    "ttft": 22417.881239138387,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033041,
    "arrivals": 126799,
    "finished_requests": 126015,
    "scheduler_time": 105.5109724337741
}
#Debug simulation 
Total elapsed time: 8.856446536257863. Arrivals time: 0.3074583252891898 Scheduler time: 8.391320696100593 Scheduler overhead time: 0.05870426492765546 Adapter cache time: 0.011821459047496319 Engine time: 0.060166393872350454 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-16/adapters_32_slots_32_rate_3.2-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-16/adapters_32_slots_32_rate_3.2-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 66, 33, 33, 66, 33, 34560, 66, 33, 33, 33, 34560, 34560, 33, 33, 66, 66, 66, 34560, 34560, 33, 34560, 34560, 34560, 34560, 66, 33, 66, 66, 66, 66, 34560]
Prompts retrieved: 381216 . Total input tokens: 84915272 . Total output tokens: 76248271
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 8.812653760891408,
    "estimated_duration": 3600.0226156873,
    "input_throughput": 8676.101884442443,
    "output_throughput": 7697.069979297839,
    "total_throughput": 16373.171863740283,
    "itl": 90.38634671807988,
    "ttft": 22389.540599235657,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971348,
    "arrivals": 126799,
    "finished_requests": 126014,
    "scheduler_time": 105.50893249250068
}
#Debug simulation 
Total elapsed time: 8.812761978711933. Arrivals time: 0.30071885231882334 Scheduler time: 8.354370284825563 Scheduler overhead time: 0.05870561907067895 Adapter cache time: 0.011857382487505674 Engine time: 0.060087991412729025 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-32/adapters_32_slots_32_rate_3.2-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-32/adapters_32_slots_32_rate_3.2-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 66, 33, 33, 66, 33, 34560, 66, 33, 33, 33, 34560, 34560, 33, 33, 66, 66, 66, 34560, 34560, 33, 34560, 34560, 34560, 34560, 66, 33, 66, 66, 66, 66, 34560]
Prompts retrieved: 381216 . Total input tokens: 84915272 . Total output tokens: 76248271
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 8.86671492131427,
    "estimated_duration": 3600.0630550146093,
    "input_throughput": 8676.050814302542,
    "output_throughput": 7696.995184960046,
    "total_throughput": 16373.045999262587,
    "itl": 90.3872544395312,
    "ttft": 22361.178859680782,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089387,
    "arrivals": 126799,
    "finished_requests": 126015,
    "scheduler_time": 105.51004116794428
}
#Debug simulation 
Total elapsed time: 8.866804779972881. Arrivals time: 0.31132320407778025 Scheduler time: 8.396698407363147 Scheduler overhead time: 0.05863167531788349 Adapter cache time: 0.011964513920247555 Engine time: 0.06023487122729421 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-16/adapters_32_slots_32_rate_3.2-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-16/adapters_32_slots_32_rate_3.2-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 66, 33, 33, 66, 33, 34560, 66, 33, 33, 33, 34560, 34560, 33, 33, 66, 66, 66, 34560, 34560, 33, 34560, 34560, 34560, 34560, 66, 33, 66, 66, 66, 66, 34560]
Prompts retrieved: 381216 . Total input tokens: 84915272 . Total output tokens: 76248271
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 8.901840885169804,
    "estimated_duration": 3600.1022216725137,
    "input_throughput": 8676.05392201591,
    "output_throughput": 7696.981444912054,
    "total_throughput": 16373.035366927963,
    "itl": 90.38617589357791,
    "ttft": 22389.043677906036,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 126799,
    "finished_requests": 126017,
    "scheduler_time": 105.51110116214026
}
#Debug simulation 
Total elapsed time: 8.90198914334178. Arrivals time: 0.3141824025660753 Scheduler time: 8.430899418424815 Scheduler overhead time: 0.05832607205957174 Adapter cache time: 0.01200284669175744 Engine time: 0.05977332824841142 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-32/adapters_32_slots_32_rate_3.2-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-32/adapters_32_slots_32_rate_3.2-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 66, 33, 33, 66, 33, 34560, 66, 33, 33, 33, 34560, 34560, 33, 33, 66, 66, 66, 34560, 34560, 33, 34560, 34560, 34560, 34560, 66, 33, 66, 66, 66, 66, 34560]
Prompts retrieved: 381216 . Total input tokens: 84915272 . Total output tokens: 76248271
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.867182979360223,
    "estimated_duration": 3600.062306105852,
    "input_throughput": 8676.052619151982,
    "output_throughput": 7696.996786139862,
    "total_throughput": 16373.049405291844,
    "itl": 90.38712814831844,
    "ttft": 22361.135548632243,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145733,
    "arrivals": 126799,
    "finished_requests": 126015,
    "scheduler_time": 105.50988004293016
}
#Debug simulation 
Total elapsed time: 8.867272299248725. Arrivals time: 0.30201529525220394 Scheduler time: 8.40759817045182 Scheduler overhead time: 0.058621169067919254 Adapter cache time: 0.011820774991065264 Engine time: 0.060289934277534485 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-8/adapters_32_slots_32_rate_1.6-0.8-0.4_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-8/adapters_32_slots_32_rate_1.6-0.8-0.4_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 4320, 4320, 8640, 4320, 17280, 8640, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 8640, 8640, 8640, 17280, 17280, 4320, 17280, 17280, 17280, 17280, 8640, 4320, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 328320 . Total input tokens: 73169787 . Total output tokens: 65646572
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 7.637920482084155,
    "estimated_duration": 3600.0089010650768,
    "input_throughput": 7503.613391624692,
    "output_throughput": 6598.232852416663,
    "total_throughput": 14101.846244041355,
    "itl": 100.08922603897162,
    "ttft": 22839.824656561384,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 109373,
    "finished_requests": 108683,
    "scheduler_time": 90.1562325700326
}
#Debug simulation 
Total elapsed time: 7.638023125007749. Arrivals time: 0.27338149724528193 Scheduler time: 7.22508337488398 Scheduler overhead time: 0.052710339426994324 Adapter cache time: 0.008752865716814995 Engine time: 0.05399557948112488 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-16/adapters_32_slots_32_rate_1.6-0.8-0.4_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-16/adapters_32_slots_32_rate_1.6-0.8-0.4_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 4320, 4320, 8640, 4320, 17280, 8640, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 8640, 8640, 8640, 17280, 17280, 4320, 17280, 17280, 17280, 17280, 8640, 4320, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 328320 . Total input tokens: 73169787 . Total output tokens: 65646572
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 7.663261397741735,
    "estimated_duration": 3600.0299613408533,
    "input_throughput": 7503.569773052337,
    "output_throughput": 6598.194808121205,
    "total_throughput": 14101.764581173542,
    "itl": 100.08865430381542,
    "ttft": 22806.832453853527,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255726,
    "arrivals": 109373,
    "finished_requests": 108684,
    "scheduler_time": 90.15667509588445
}
#Debug simulation 
Total elapsed time: 7.663429335691035. Arrivals time: 0.2874322086572647 Scheduler time: 7.235826715826988 Scheduler overhead time: 0.0534324343316257 Adapter cache time: 0.008740291465073824 Engine time: 0.05371084809303284 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-32/adapters_32_slots_32_rate_1.6-0.8-0.4_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-32/adapters_32_slots_32_rate_1.6-0.8-0.4_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 4320, 4320, 8640, 4320, 17280, 8640, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 8640, 8640, 8640, 17280, 17280, 4320, 17280, 17280, 17280, 17280, 8640, 4320, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 328320 . Total input tokens: 73169787 . Total output tokens: 65646572
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 7.710663348902017,
    "estimated_duration": 3600.029987007708,
    "input_throughput": 7503.569719554717,
    "output_throughput": 6598.194761078567,
    "total_throughput": 14101.764480633285,
    "itl": 100.0886442141439,
    "ttft": 22806.803713380945,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033041,
    "arrivals": 109373,
    "finished_requests": 108684,
    "scheduler_time": 90.15667252617361
}
#Debug simulation 
Total elapsed time: 7.710751297883689. Arrivals time: 0.28861794946715236 Scheduler time: 7.282274420838803 Scheduler overhead time: 0.05268073594197631 Adapter cache time: 0.008754128124564886 Engine time: 0.054201452527195215 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-16-16/adapters_32_slots_32_rate_1.6-0.8-0.4_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-16-16/adapters_32_slots_32_rate_1.6-0.8-0.4_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 4320, 4320, 8640, 4320, 17280, 8640, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 8640, 8640, 8640, 17280, 17280, 4320, 17280, 17280, 17280, 17280, 8640, 4320, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 328320 . Total input tokens: 73169787 . Total output tokens: 65646572
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 7.685362257063389,
    "estimated_duration": 3600.0314513876356,
    "input_throughput": 7503.566667337805,
    "output_throughput": 6598.192077139802,
    "total_throughput": 14101.758744477607,
    "itl": 100.08944868367848,
    "ttft": 22806.86406980619,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971346,
    "arrivals": 109373,
    "finished_requests": 108684,
    "scheduler_time": 90.15691603415435
}
#Debug simulation 
Total elapsed time: 7.685477511957288. Arrivals time: 0.27962042670696974 Scheduler time: 7.265474508050829 Scheduler overhead time: 0.05323648266494274 Adapter cache time: 0.008775313384830952 Engine time: 0.05427629826590419 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-16-32/adapters_32_slots_32_rate_1.6-0.8-0.4_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-16-32/adapters_32_slots_32_rate_1.6-0.8-0.4_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 4320, 4320, 8640, 4320, 17280, 8640, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 8640, 8640, 8640, 17280, 17280, 4320, 17280, 17280, 17280, 17280, 8640, 4320, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 328320 . Total input tokens: 73169787 . Total output tokens: 65646572
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 7.675725576933473,
    "estimated_duration": 3600.049580990106,
    "input_throughput": 7503.5552684168,
    "output_throughput": 6598.312458093139,
    "total_throughput": 14101.867726509938,
    "itl": 100.0889234755592,
    "ttft": 22774.038414793125,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089386,
    "arrivals": 109373,
    "finished_requests": 108685,
    "scheduler_time": 90.15728422290199
}
#Debug simulation 
Total elapsed time: 7.675821842160076. Arrivals time: 0.26973895030096173 Scheduler time: 7.268426131922752 Scheduler overhead time: 0.052261860109865665 Adapter cache time: 0.008705568499863148 Engine time: 0.052565719466656446 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_16-16-16/adapters_32_slots_32_rate_1.6-0.8-0.4_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_16-16-16/adapters_32_slots_32_rate_1.6-0.8-0.4_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 4320, 4320, 8640, 4320, 17280, 8640, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 8640, 8640, 8640, 17280, 17280, 4320, 17280, 17280, 17280, 17280, 8640, 4320, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 328320 . Total input tokens: 73169787 . Total output tokens: 65646572
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 7.673960223328322,
    "estimated_duration": 3600.0061913054687,
    "input_throughput": 7503.619039667335,
    "output_throughput": 6598.237818970585,
    "total_throughput": 14101.85685863792,
    "itl": 100.08952115155816,
    "ttft": 22839.943367055454,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 109373,
    "finished_requests": 108683,
    "scheduler_time": 90.15622344433464
}
#Debug simulation 
Total elapsed time: 7.67409583600238. Arrivals time: 0.2769080474972725 Scheduler time: 7.25685514556244 Scheduler overhead time: 0.05292744282633066 Adapter cache time: 0.008764905855059624 Engine time: 0.054447213653475046 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_16-16-32/adapters_32_slots_32_rate_1.6-0.8-0.4_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_16-16-32/adapters_32_slots_32_rate_1.6-0.8-0.4_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 4320, 4320, 8640, 4320, 17280, 8640, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 8640, 8640, 8640, 17280, 17280, 4320, 17280, 17280, 17280, 17280, 8640, 4320, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 328320 . Total input tokens: 73169787 . Total output tokens: 65646572
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 7.663040425162762,
    "estimated_duration": 3600.0871412052625,
    "input_throughput": 7503.4769827700175,
    "output_throughput": 6598.243616971834,
    "total_throughput": 14101.720599741851,
    "itl": 100.08948740215132,
    "ttft": 22806.681336642047,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145731,
    "arrivals": 109373,
    "finished_requests": 108685,
    "scheduler_time": 90.158506995887
}
#Debug simulation 
Total elapsed time: 7.663149292115122. Arrivals time: 0.287727692630142 Scheduler time: 7.235551596619189 Scheduler overhead time: 0.053003502544015646 Adapter cache time: 0.008752277586609125 Engine time: 0.0539721860550344 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-8/adapters_32_slots_32_rate_1.6-0.8-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-8/adapters_32_slots_32_rate_1.6-0.8-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 1080, 1080, 8640, 1080, 17280, 8640, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 8640, 8640, 8640, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 8640, 1080, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 295920 . Total input tokens: 66039020 . Total output tokens: 59116830
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 7.0495543498545885,
    "estimated_duration": 3600.0247667973435,
    "input_throughput": 6803.908746936367,
    "output_throughput": 5971.356696838562,
    "total_throughput": 12775.26544377493,
    "itl": 71.75336429953123,
    "ttft": 13733.632153019045,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 98647,
    "finished_requests": 98271,
    "scheduler_time": 78.19376524135649
}
#Debug simulation 
Total elapsed time: 7.049673654139042. Arrivals time: 0.26728737726807594 Scheduler time: 6.5987425916828215 Scheduler overhead time: 0.06860935175791383 Adapter cache time: 0.0152476760558784 Engine time: 0.06871830066666007 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-16/adapters_32_slots_32_rate_1.6-0.8-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-16/adapters_32_slots_32_rate_1.6-0.8-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 1080, 1080, 8640, 1080, 17280, 8640, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 8640, 8640, 8640, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 8640, 1080, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 295920 . Total input tokens: 66039020 . Total output tokens: 59116830
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 7.0171781573444605,
    "estimated_duration": 3600.026191334397,
    "input_throughput": 6803.906054617033,
    "output_throughput": 5971.354333961621,
    "total_throughput": 12775.260388578654,
    "itl": 71.75317125949563,
    "ttft": 13733.657342227341,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255727,
    "arrivals": 98647,
    "finished_requests": 98271,
    "scheduler_time": 78.19389353962521
}
#Debug simulation 
Total elapsed time: 7.017285204026848. Arrivals time: 0.2595892259851098 Scheduler time: 6.573045329656452 Scheduler overhead time: 0.06815265864133835 Adapter cache time: 0.015097299590706825 Engine time: 0.07009519264101982 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-32/adapters_32_slots_32_rate_1.6-0.8-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-32/adapters_32_slots_32_rate_1.6-0.8-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 1080, 1080, 8640, 1080, 17280, 8640, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 8640, 8640, 8640, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 8640, 1080, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 295920 . Total input tokens: 66039020 . Total output tokens: 59116830
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 7.004465725272894,
    "estimated_duration": 3600.0265182989333,
    "input_throughput": 6803.9054366671435,
    "output_throughput": 5971.353791626421,
    "total_throughput": 12775.259228293566,
    "itl": 71.75313006410931,
    "ttft": 13733.705372524872,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033041,
    "arrivals": 98647,
    "finished_requests": 98271,
    "scheduler_time": 78.19389664201009
}
#Debug simulation 
Total elapsed time: 7.004556625150144. Arrivals time: 0.2553009227849543 Scheduler time: 6.566263989079744 Scheduler overhead time: 0.06778976274654269 Adapter cache time: 0.014949726406484842 Engine time: 0.06919818883761764 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-16-16/adapters_32_slots_32_rate_1.6-0.8-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-16-16/adapters_32_slots_32_rate_1.6-0.8-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 1080, 1080, 8640, 1080, 17280, 8640, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 8640, 8640, 8640, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 8640, 1080, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 295920 . Total input tokens: 66039020 . Total output tokens: 59116830
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 7.764731064904481,
    "estimated_duration": 3600.0264768068578,
    "input_throughput": 6803.905515085499,
    "output_throughput": 5971.3538604492105,
    "total_throughput": 12775.25937553471,
    "itl": 71.75340174851196,
    "ttft": 13733.573846464218,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971346,
    "arrivals": 98647,
    "finished_requests": 98271,
    "scheduler_time": 78.19390717841254
}
#Debug simulation 
Total elapsed time: 7.764856909867376. Arrivals time: 0.25578975724056363 Scheduler time: 7.323001337703317 Scheduler overhead time: 0.06884706066921353 Adapter cache time: 0.015388454776257277 Engine time: 0.06949370820075274 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-16-32/adapters_32_slots_32_rate_1.6-0.8-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-16-32/adapters_32_slots_32_rate_1.6-0.8-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 1080, 1080, 8640, 1080, 17280, 8640, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 8640, 8640, 8640, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 8640, 1080, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 295920 . Total input tokens: 66039020 . Total output tokens: 59116830
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 7.0219016638584435,
    "estimated_duration": 3600.026476072816,
    "input_throughput": 6803.905516472809,
    "output_throughput": 5971.353861666764,
    "total_throughput": 12775.259378139574,
    "itl": 71.75302465532485,
    "ttft": 13733.683608063817,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089388,
    "arrivals": 98647,
    "finished_requests": 98271,
    "scheduler_time": 78.1938810774016
}
#Debug simulation 
Total elapsed time: 7.022024759091437. Arrivals time: 0.2576169208623469 Scheduler time: 6.57947428105399 Scheduler overhead time: 0.06838070414960384 Adapter cache time: 0.01520889112725854 Engine time: 0.06985416263341904 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_16-16-16/adapters_32_slots_32_rate_1.6-0.8-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_16-16-16/adapters_32_slots_32_rate_1.6-0.8-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 1080, 1080, 8640, 1080, 17280, 8640, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 8640, 8640, 8640, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 8640, 1080, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 295920 . Total input tokens: 66039020 . Total output tokens: 59116830
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 7.035655899904668,
    "estimated_duration": 3600.053436259443,
    "input_throughput": 6803.965950419509,
    "output_throughput": 5971.416641619749,
    "total_throughput": 12775.382592039257,
    "itl": 71.75277079920386,
    "ttft": 13733.439815798907,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 98647,
    "finished_requests": 98272,
    "scheduler_time": 78.19416704401263
}
#Debug simulation 
Total elapsed time: 7.035815604031086. Arrivals time: 0.26561516849324107 Scheduler time: 6.585674688220024 Scheduler overhead time: 0.06825413415208459 Adapter cache time: 0.015349785797297955 Engine time: 0.06965409033000469 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_16-16-32/adapters_32_slots_32_rate_1.6-0.8-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_16-16-32/adapters_32_slots_32_rate_1.6-0.8-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 1080, 1080, 8640, 1080, 17280, 8640, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 8640, 8640, 8640, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 8640, 1080, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 295920 . Total input tokens: 66039020 . Total output tokens: 59116830
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 6.962928292807192,
    "estimated_duration": 3600.0264501383895,
    "input_throughput": 6803.905565487835,
    "output_throughput": 5971.353904684124,
    "total_throughput": 12775.259470171959,
    "itl": 71.75287655572728,
    "ttft": 13733.66961846894,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145733,
    "arrivals": 98647,
    "finished_requests": 98271,
    "scheduler_time": 78.19383122850772
}
#Debug simulation 
Total elapsed time: 6.963014161679894. Arrivals time: 0.22254083445295691 Scheduler time: 6.558245818596333 Scheduler overhead time: 0.06767107732594013 Adapter cache time: 0.01477773766964674 Engine time: 0.06854793662205338 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-8/adapters_32_slots_32_rate_1.6-0.8-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-8/adapters_32_slots_32_rate_1.6-0.8-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 540, 540, 8640, 540, 17280, 8640, 540, 540, 540, 17280, 17280, 540, 540, 8640, 8640, 8640, 17280, 17280, 540, 17280, 17280, 17280, 17280, 8640, 540, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 290520 . Total input tokens: 64833163 . Total output tokens: 58016128
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 6.90623863087967,
    "estimated_duration": 3600.0046105778188,
    "input_throughput": 6663.327299503043,
    "output_throughput": 5866.3505424261975,
    "total_throughput": 12529.67784192924,
    "itl": 64.47232271523487,
    "ttft": 15151.376178809225,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 96919,
    "finished_requests": 96513,
    "scheduler_time": 75.68990475349352
}
#Debug simulation 
Total elapsed time: 6.906449602916837. Arrivals time: 0.2522684810683131 Scheduler time: 6.455474600195885 Scheduler overhead time: 0.07378641702234745 Adapter cache time: 0.016533304937183857 Engine time: 0.07394472043961287 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-16/adapters_32_slots_32_rate_1.6-0.8-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-16/adapters_32_slots_32_rate_1.6-0.8-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 540, 540, 8640, 540, 17280, 8640, 540, 540, 540, 17280, 17280, 540, 540, 8640, 8640, 8640, 17280, 17280, 540, 17280, 17280, 17280, 17280, 8640, 540, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 290520 . Total input tokens: 64833163 . Total output tokens: 58016128
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 6.914558396209031,
    "estimated_duration": 3600.014097418597,
    "input_throughput": 6663.309740148154,
    "output_throughput": 5866.335083282973,
    "total_throughput": 12529.644823431126,
    "itl": 64.47225327831475,
    "ttft": 15151.454987720044,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255727,
    "arrivals": 96919,
    "finished_requests": 96513,
    "scheduler_time": 75.69004693917685
}
#Debug simulation 
Total elapsed time: 6.914650239050388. Arrivals time: 0.2502888161689043 Scheduler time: 6.463184156920761 Scheduler overhead time: 0.07451265072450042 Adapter cache time: 0.016576312948018312 Engine time: 0.0757079292088747 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-32/adapters_32_slots_32_rate_1.6-0.8-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-32/adapters_32_slots_32_rate_1.6-0.8-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 540, 540, 8640, 540, 17280, 8640, 540, 540, 540, 17280, 17280, 540, 540, 8640, 8640, 8640, 17280, 17280, 540, 17280, 17280, 17280, 17280, 8640, 540, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 290520 . Total input tokens: 64833163 . Total output tokens: 58016128
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 6.881174384150654,
    "estimated_duration": 3600.0141003363983,
    "input_throughput": 6663.30973474756,
    "output_throughput": 5866.335078528325,
    "total_throughput": 12529.644813275883,
    "itl": 64.47225089840695,
    "ttft": 15151.466834387898,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033041,
    "arrivals": 96919,
    "finished_requests": 96513,
    "scheduler_time": 75.69004285339388
}
#Debug simulation 
Total elapsed time: 6.881293068174273. Arrivals time: 0.24364506779238582 Scheduler time: 6.439413069281727 Scheduler overhead time: 0.0733684110455215 Adapter cache time: 0.01645631669089198 Engine time: 0.07461236184462905 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-16-16/adapters_32_slots_32_rate_1.6-0.8-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-16-16/adapters_32_slots_32_rate_1.6-0.8-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 540, 540, 8640, 540, 17280, 8640, 540, 540, 540, 17280, 17280, 540, 540, 8640, 8640, 8640, 17280, 17280, 540, 17280, 17280, 17280, 17280, 8640, 540, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 290520 . Total input tokens: 64833163 . Total output tokens: 58016128
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 6.910622471012175,
    "estimated_duration": 3600.0049572887638,
    "input_throughput": 6663.326657768231,
    "output_throughput": 5866.349977446992,
    "total_throughput": 12529.676635215223,
    "itl": 64.47218189851162,
    "ttft": 15151.394201870577,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971348,
    "arrivals": 96919,
    "finished_requests": 96513,
    "scheduler_time": 75.68992454129733
}
#Debug simulation 
Total elapsed time: 6.91073253005743. Arrivals time: 0.2462825458496809 Scheduler time: 6.464139477349818 Scheduler overhead time: 0.07401992427185178 Adapter cache time: 0.016588060185313225 Engine time: 0.07549571758136153 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-16-32/adapters_32_slots_32_rate_1.6-0.8-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-16-32/adapters_32_slots_32_rate_1.6-0.8-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 540, 540, 8640, 540, 17280, 8640, 540, 540, 540, 17280, 17280, 540, 540, 8640, 8640, 8640, 17280, 17280, 540, 17280, 17280, 17280, 17280, 8640, 540, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 290520 . Total input tokens: 64833163 . Total output tokens: 58016128
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 6.886243761982769,
    "estimated_duration": 3600.033141702864,
    "input_throughput": 6663.274491037976,
    "output_throughput": 5866.304050192849,
    "total_throughput": 12529.578541230825,
    "itl": 64.47258304130764,
    "ttft": 15188.415799518882,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089387,
    "arrivals": 96919,
    "finished_requests": 96513,
    "scheduler_time": 75.69064704586462
}
#Debug simulation 
Total elapsed time: 6.886388935148716. Arrivals time: 0.2564773759804666 Scheduler time: 6.430310506839305 Scheduler overhead time: 0.073887272272259 Adapter cache time: 0.016473953146487474 Engine time: 0.07519397046416998 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_16-16-16/adapters_32_slots_32_rate_1.6-0.8-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_16-16-16/adapters_32_slots_32_rate_1.6-0.8-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 540, 540, 8640, 540, 17280, 8640, 540, 540, 540, 17280, 17280, 540, 540, 8640, 8640, 8640, 17280, 17280, 540, 17280, 17280, 17280, 17280, 8640, 540, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 290520 . Total input tokens: 64833163 . Total output tokens: 58016128
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 6.933518588077277,
    "estimated_duration": 3600.039133862322,
    "input_throughput": 6663.263400213189,
    "output_throughput": 5866.294285901965,
    "total_throughput": 12529.557686115153,
    "itl": 64.47202285729516,
    "ttft": 15188.35503682236,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 96919,
    "finished_requests": 96513,
    "scheduler_time": 75.69038238312908
}
#Debug simulation 
Total elapsed time: 6.933683718089014. Arrivals time: 0.25895375991240144 Scheduler time: 6.4753391607664526 Scheduler overhead time: 0.07386128837242723 Adapter cache time: 0.016561992466449738 Engine time: 0.07497723819687963 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_16-16-32/adapters_32_slots_32_rate_1.6-0.8-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_16-16-32/adapters_32_slots_32_rate_1.6-0.8-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 540, 540, 8640, 540, 17280, 8640, 540, 540, 540, 17280, 17280, 540, 540, 8640, 8640, 8640, 17280, 17280, 540, 17280, 17280, 17280, 17280, 8640, 540, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 290520 . Total input tokens: 64833163 . Total output tokens: 58016128
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 6.8869543257169425,
    "estimated_duration": 3600.032707034152,
    "input_throughput": 6663.275295563151,
    "output_throughput": 5866.304758491644,
    "total_throughput": 12529.580054054795,
    "itl": 64.47245551774418,
    "ttft": 15188.415267701559,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145734,
    "arrivals": 96919,
    "finished_requests": 96513,
    "scheduler_time": 75.6905739115206
}
#Debug simulation 
Total elapsed time: 6.887048231903464. Arrivals time: 0.2610595035366714 Scheduler time: 6.424930770415813 Scheduler overhead time: 0.0742329889908433 Adapter cache time: 0.016562855802476406 Engine time: 0.07629422144964337 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-8/adapters_32_slots_32_rate_1.6-0.8-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-8/adapters_32_slots_32_rate_1.6-0.8-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 270, 270, 8640, 270, 17280, 8640, 270, 270, 270, 17280, 17280, 270, 270, 8640, 8640, 8640, 17280, 17280, 270, 17280, 17280, 17280, 17280, 8640, 270, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 287820 . Total input tokens: 64223371 . Total output tokens: 57461548
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 6.868911009747535,
    "estimated_duration": 3600.011336708594,
    "input_throughput": 6564.595438637354,
    "output_throughput": 5853.07406816803,
    "total_throughput": 12417.669506805383,
    "itl": 61.023438170681956,
    "ttft": 13632.25174456591,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 96050,
    "finished_requests": 95687,
    "scheduler_time": 74.91072971058465
}
#Debug simulation 
Total elapsed time: 6.869015282019973. Arrivals time: 0.25922811916098 Scheduler time: 6.400298765394837 Scheduler overhead time: 0.07735114358365536 Adapter cache time: 0.016036808490753174 Engine time: 0.08046979736536741 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-16/adapters_32_slots_32_rate_1.6-0.8-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-16/adapters_32_slots_32_rate_1.6-0.8-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 270, 270, 8640, 270, 17280, 8640, 270, 270, 270, 17280, 17280, 270, 270, 8640, 8640, 8640, 17280, 17280, 270, 17280, 17280, 17280, 17280, 8640, 270, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 287820 . Total input tokens: 64223371 . Total output tokens: 57461548
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 6.869145725853741,
    "estimated_duration": 3600.058766188134,
    "input_throughput": 6564.677283038818,
    "output_throughput": 5853.165564380906,
    "total_throughput": 12417.842847419724,
    "itl": 61.023895917321255,
    "ttft": 13594.579069834097,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255728,
    "arrivals": 96050,
    "finished_requests": 95690,
    "scheduler_time": 74.91188534912072
}
#Debug simulation 
Total elapsed time: 6.869232831057161. Arrivals time: 0.24859840609133244 Scheduler time: 6.413085574284196 Scheduler overhead time: 0.07726072426885366 Adapter cache time: 0.0160512775182724 Engine time: 0.0786846368573606 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-32/adapters_32_slots_32_rate_1.6-0.8-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-32/adapters_32_slots_32_rate_1.6-0.8-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 270, 270, 8640, 270, 17280, 8640, 270, 270, 270, 17280, 17280, 270, 270, 8640, 8640, 8640, 17280, 17280, 270, 17280, 17280, 17280, 17280, 8640, 270, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 287820 . Total input tokens: 64223371 . Total output tokens: 57461548
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 6.859913878142834,
    "estimated_duration": 3600.058779763391,
    "input_throughput": 6564.67725828445,
    "output_throughput": 5853.165542309537,
    "total_throughput": 12417.842800593988,
    "itl": 61.02387469235153,
    "ttft": 13594.557743257887,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033042,
    "arrivals": 96050,
    "finished_requests": 95690,
    "scheduler_time": 74.91188130431283
}
#Debug simulation 
Total elapsed time: 6.860016547143459. Arrivals time: 0.24763798713684082 Scheduler time: 6.406921566929668 Scheduler overhead time: 0.07664927234873176 Adapter cache time: 0.016076164320111275 Engine time: 0.07744125230237842 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-16-16/adapters_32_slots_32_rate_1.6-0.8-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-16-16/adapters_32_slots_32_rate_1.6-0.8-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 270, 270, 8640, 270, 17280, 8640, 270, 270, 270, 17280, 17280, 270, 270, 8640, 8640, 8640, 17280, 17280, 270, 17280, 17280, 17280, 17280, 8640, 270, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 287820 . Total input tokens: 64223371 . Total output tokens: 57461548
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 6.886316834017634,
    "estimated_duration": 3600.011347411901,
    "input_throughput": 6564.595419119949,
    "output_throughput": 5853.074050766071,
    "total_throughput": 12417.669469886021,
    "itl": 61.023298671832116,
    "ttft": 13632.262228977243,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971348,
    "arrivals": 96050,
    "finished_requests": 95687,
    "scheduler_time": 74.91067010381187
}
#Debug simulation 
Total elapsed time: 6.886417206842452. Arrivals time: 0.27751245256513357 Scheduler time: 6.4020440597087145 Scheduler overhead time: 0.07711828872561455 Adapter cache time: 0.015839004889130592 Engine time: 0.07853719405829906 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-16-32/adapters_32_slots_32_rate_1.6-0.8-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-16-32/adapters_32_slots_32_rate_1.6-0.8-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 270, 270, 8640, 270, 17280, 8640, 270, 270, 270, 17280, 17280, 270, 270, 8640, 8640, 8640, 17280, 17280, 270, 17280, 17280, 17280, 17280, 8640, 270, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 287820 . Total input tokens: 64223371 . Total output tokens: 57461548
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 6.862513510044664,
    "estimated_duration": 3600.001017209973,
    "input_throughput": 6564.532589581107,
    "output_throughput": 5852.993901743398,
    "total_throughput": 12417.526491324505,
    "itl": 61.02405676747558,
    "ttft": 13669.836688567724,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089388,
    "arrivals": 96050,
    "finished_requests": 95686,
    "scheduler_time": 74.91080683427435
}
#Debug simulation 
Total elapsed time: 6.8626392763108015. Arrivals time: 0.24283016985282302 Scheduler time: 6.413058870472014 Scheduler overhead time: 0.07682718615978956 Adapter cache time: 0.015905107371509075 Engine time: 0.07844018284231424 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_16-16-16/adapters_32_slots_32_rate_1.6-0.8-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_16-16-16/adapters_32_slots_32_rate_1.6-0.8-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 270, 270, 8640, 270, 17280, 8640, 270, 270, 270, 17280, 17280, 270, 270, 8640, 8640, 8640, 17280, 17280, 270, 17280, 17280, 17280, 17280, 8640, 270, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 287820 . Total input tokens: 64223371 . Total output tokens: 57461548
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 6.861951790284365,
    "estimated_duration": 3600.0114000479193,
    "input_throughput": 6564.59532313854,
    "output_throughput": 5853.073965187867,
    "total_throughput": 12417.669288326408,
    "itl": 61.023452541658216,
    "ttft": 13632.34121559197,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 96050,
    "finished_requests": 95687,
    "scheduler_time": 74.91076186417429
}
#Debug simulation 
Total elapsed time: 6.862100849393755. Arrivals time: 0.24685770692303777 Scheduler time: 6.408069154247642 Scheduler overhead time: 0.0770161272957921 Adapter cache time: 0.01601401763036847 Engine time: 0.07878389256075025 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_16-16-32/adapters_32_slots_32_rate_1.6-0.8-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_16-16-32/adapters_32_slots_32_rate_1.6-0.8-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 270, 270, 8640, 270, 17280, 8640, 270, 270, 270, 17280, 17280, 270, 270, 8640, 8640, 8640, 17280, 17280, 270, 17280, 17280, 17280, 17280, 8640, 270, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 287820 . Total input tokens: 64223371 . Total output tokens: 57461548
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 6.882193225901574,
    "estimated_duration": 3600.0119359575524,
    "input_throughput": 6564.634623555497,
    "output_throughput": 5853.229760027233,
    "total_throughput": 12417.86438358273,
    "itl": 61.02435695908411,
    "ttft": 13594.868056282774,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145736,
    "arrivals": 96050,
    "finished_requests": 95688,
    "scheduler_time": 74.91103922049503
}
#Debug simulation 
Total elapsed time: 6.882331705186516. Arrivals time: 0.2545785973779857 Scheduler time: 6.419349897187203 Scheduler overhead time: 0.07724435441195965 Adapter cache time: 0.0162199386395514 Engine time: 0.0793818118982017 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-8/adapters_32_slots_32_rate_1.6-0.8-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-8/adapters_32_slots_32_rate_1.6-0.8-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 135, 135, 8640, 135, 17280, 8640, 135, 135, 135, 17280, 17280, 135, 135, 8640, 8640, 8640, 17280, 17280, 135, 17280, 17280, 17280, 17280, 8640, 135, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 286470 . Total input tokens: 63900674 . Total output tokens: 57178861
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 6.843962989281863,
    "estimated_duration": 3600.0171388763883,
    "input_throughput": 6537.490820764704,
    "output_throughput": 5830.4355758014935,
    "total_throughput": 12367.926396566198,
    "itl": 58.83246994201856,
    "ttft": 15233.940953753134,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 95612,
    "finished_requests": 95210,
    "scheduler_time": 74.20704345816975
}
#Debug simulation 
Total elapsed time: 6.844052920117974. Arrivals time: 0.2533514476381242 Scheduler time: 6.379693271126598 Scheduler overhead time: 0.07909374451264739 Adapter cache time: 0.015423891134560108 Engine time: 0.08015436679124832 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-16/adapters_32_slots_32_rate_1.6-0.8-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-16/adapters_32_slots_32_rate_1.6-0.8-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 135, 135, 8640, 135, 17280, 8640, 135, 135, 135, 17280, 17280, 135, 135, 8640, 8640, 8640, 17280, 17280, 135, 17280, 17280, 17280, 17280, 8640, 135, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 286470 . Total input tokens: 63900674 . Total output tokens: 57178861
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 6.878485640976578,
    "estimated_duration": 3600.0438594838315,
    "input_throughput": 6537.442297543125,
    "output_throughput": 5830.392300556434,
    "total_throughput": 12367.83459809956,
    "itl": 58.832829087750184,
    "ttft": 15234.008276636641,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255727,
    "arrivals": 95612,
    "finished_requests": 95210,
    "scheduler_time": 74.20769128305324
}
#Debug simulation 
Total elapsed time: 6.878603557124734. Arrivals time: 0.2542438842356205 Scheduler time: 6.4112307778559625 Scheduler overhead time: 0.07952693989500403 Adapter cache time: 0.015373709611594677 Engine time: 0.08144069788977504 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-32/adapters_32_slots_32_rate_1.6-0.8-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-32/adapters_32_slots_32_rate_1.6-0.8-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 135, 135, 8640, 135, 17280, 8640, 135, 135, 135, 17280, 17280, 135, 135, 8640, 8640, 8640, 17280, 17280, 135, 17280, 17280, 17280, 17280, 8640, 135, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 286470 . Total input tokens: 63900674 . Total output tokens: 57178861
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 6.878827075008303,
    "estimated_duration": 3600.0448201488643,
    "input_throughput": 6537.440553039228,
    "output_throughput": 5830.390744727468,
    "total_throughput": 12367.831297766696,
    "itl": 58.832819605069105,
    "ttft": 15234.001286036499,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033041,
    "arrivals": 95612,
    "finished_requests": 95210,
    "scheduler_time": 74.20770750326037
}
#Debug simulation 
Total elapsed time: 6.878915741108358. Arrivals time: 0.2565953126177192 Scheduler time: 6.410145479254425 Scheduler overhead time: 0.07905167946591973 Adapter cache time: 0.015317333396524191 Engine time: 0.08129084622487426 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-16/adapters_32_slots_32_rate_1.6-0.8-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-16/adapters_32_slots_32_rate_1.6-0.8-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 135, 135, 8640, 135, 17280, 8640, 135, 135, 135, 17280, 17280, 135, 135, 8640, 8640, 8640, 17280, 17280, 135, 17280, 17280, 17280, 17280, 8640, 135, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 286470 . Total input tokens: 63900674 . Total output tokens: 57178861
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 6.844104531221092,
    "estimated_duration": 3600.037526418363,
    "input_throughput": 6537.453797992707,
    "output_throughput": 5830.402557187337,
    "total_throughput": 12367.856355180045,
    "itl": 58.83269472637183,
    "ttft": 15233.962069445293,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971348,
    "arrivals": 95612,
    "finished_requests": 95210,
    "scheduler_time": 74.20767204241199
}
#Debug simulation 
Total elapsed time: 6.844259038101882. Arrivals time: 0.2558512520045042 Scheduler time: 6.377526187803596 Scheduler overhead time: 0.07880258839577436 Adapter cache time: 0.015232527628540993 Engine time: 0.08056882489472628 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-32/adapters_32_slots_32_rate_1.6-0.8-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-32/adapters_32_slots_32_rate_1.6-0.8-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 135, 135, 8640, 135, 17280, 8640, 135, 135, 135, 17280, 17280, 135, 135, 8640, 8640, 8640, 17280, 17280, 135, 17280, 17280, 17280, 17280, 8640, 135, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 286470 . Total input tokens: 63900674 . Total output tokens: 57178861
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 6.879440636839718,
    "estimated_duration": 3600.0497324361686,
    "input_throughput": 6537.431632666284,
    "output_throughput": 5830.382789127806,
    "total_throughput": 12367.81442179409,
    "itl": 58.832772813640446,
    "ttft": 15233.991047225976,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089387,
    "arrivals": 95612,
    "finished_requests": 95210,
    "scheduler_time": 74.20792877942982
}
#Debug simulation 
Total elapsed time: 6.87953004706651. Arrivals time: 0.25774826295673847 Scheduler time: 6.409575284458697 Scheduler overhead time: 0.07939966209232807 Adapter cache time: 0.01541684614494443 Engine time: 0.08090363815426826 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-16/adapters_32_slots_32_rate_1.6-0.8-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-16/adapters_32_slots_32_rate_1.6-0.8-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 135, 135, 8640, 135, 17280, 8640, 135, 135, 135, 17280, 17280, 135, 135, 8640, 8640, 8640, 17280, 17280, 135, 17280, 17280, 17280, 17280, 8640, 135, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 286470 . Total input tokens: 63900674 . Total output tokens: 57178861
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 6.844691677950323,
    "estimated_duration": 3600.0023650802973,
    "input_throughput": 6537.517649512726,
    "output_throughput": 5830.459502915307,
    "total_throughput": 12367.977152428033,
    "itl": 58.832358501845086,
    "ttft": 15196.47767841362,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 95612,
    "finished_requests": 95210,
    "scheduler_time": 74.20667905667057
}
#Debug simulation 
Total elapsed time: 6.844834132120013. Arrivals time: 0.2500880369916558 Scheduler time: 6.383480802644044 Scheduler overhead time: 0.07899131625890732 Adapter cache time: 0.015288323163986206 Engine time: 0.08049269206821918 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-32/adapters_32_slots_32_rate_1.6-0.8-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-32/adapters_32_slots_32_rate_1.6-0.8-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 135, 135, 8640, 135, 17280, 8640, 135, 135, 135, 17280, 17280, 135, 135, 8640, 8640, 8640, 17280, 17280, 135, 17280, 17280, 17280, 17280, 8640, 135, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 286470 . Total input tokens: 63900674 . Total output tokens: 57178861
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 6.858979440294206,
    "estimated_duration": 3600.049317363253,
    "input_throughput": 6537.43238640896,
    "output_throughput": 5830.383461350259,
    "total_throughput": 12367.815847759219,
    "itl": 58.83261405361464,
    "ttft": 15233.917987672132,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145734,
    "arrivals": 95612,
    "finished_requests": 95210,
    "scheduler_time": 74.20787231601707
}
#Debug simulation 
Total elapsed time: 6.8590875579975545. Arrivals time: 0.24623788660392165 Scheduler time: 6.400931594427675 Scheduler overhead time: 0.07940698228776455 Adapter cache time: 0.015377944335341454 Engine time: 0.08050258085131645 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-8/adapters_32_slots_32_rate_1.6-0.8-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-8/adapters_32_slots_32_rate_1.6-0.8-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 66, 66, 8640, 66, 17280, 8640, 66, 66, 66, 17280, 17280, 66, 66, 8640, 8640, 8640, 17280, 17280, 66, 17280, 17280, 17280, 17280, 8640, 66, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 285780 . Total input tokens: 63750125 . Total output tokens: 57041866
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 6.796530692838132,
    "estimated_duration": 3600.02420348156,
    "input_throughput": 6546.0184898783855,
    "output_throughput": 5798.454071451057,
    "total_throughput": 12344.472561329443,
    "itl": 57.26108048359458,
    "ttft": 14551.532150377141,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 95376,
    "finished_requests": 94993,
    "scheduler_time": 73.43579246139555
}
#Debug simulation 
Total elapsed time: 6.796628907788545. Arrivals time: 0.24636395601555705 Scheduler time: 6.335378683172166 Scheduler overhead time: 0.08076737215742469 Adapter cache time: 0.014962715562433004 Engine time: 0.08192740613594651 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-16/adapters_32_slots_32_rate_1.6-0.8-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-16/adapters_32_slots_32_rate_1.6-0.8-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 66, 66, 8640, 66, 17280, 8640, 66, 66, 66, 17280, 17280, 66, 66, 8640, 8640, 8640, 17280, 17280, 66, 17280, 17280, 17280, 17280, 8640, 66, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 285780 . Total input tokens: 63750125 . Total output tokens: 57041866
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 6.774988526944071,
    "estimated_duration": 3600.0390509650874,
    "input_throughput": 6545.991492420769,
    "output_throughput": 5798.430157140659,
    "total_throughput": 12344.421649561427,
    "itl": 57.26110074492184,
    "ttft": 14551.773070634385,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255727,
    "arrivals": 95376,
    "finished_requests": 94993,
    "scheduler_time": 73.43604127269742
}
#Debug simulation 
Total elapsed time: 6.775093283969909. Arrivals time: 0.24039494013413787 Scheduler time: 6.319887930061668 Scheduler overhead time: 0.08118249848484993 Adapter cache time: 0.01497533405199647 Engine time: 0.08151315292343497 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-32/adapters_32_slots_32_rate_1.6-0.8-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-32/adapters_32_slots_32_rate_1.6-0.8-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 66, 66, 8640, 66, 17280, 8640, 66, 66, 66, 17280, 17280, 66, 66, 8640, 8640, 8640, 17280, 17280, 66, 17280, 17280, 17280, 17280, 8640, 66, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 285780 . Total input tokens: 63750125 . Total output tokens: 57041866
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 6.796527178026736,
    "estimated_duration": 3600.0393524933006,
    "input_throughput": 6545.990944148673,
    "output_throughput": 5798.429671481999,
    "total_throughput": 12344.420615630674,
    "itl": 57.261113677750046,
    "ttft": 14551.750902741443,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033041,
    "arrivals": 95376,
    "finished_requests": 94993,
    "scheduler_time": 73.43604507165594
}
#Debug simulation 
Total elapsed time: 6.796649182215333. Arrivals time: 0.24526402680203319 Scheduler time: 6.335494823753834 Scheduler overhead time: 0.08113045943900943 Adapter cache time: 0.015054254792630672 Engine time: 0.08235859498381615 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-16/adapters_32_slots_32_rate_1.6-0.8-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-16/adapters_32_slots_32_rate_1.6-0.8-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 66, 66, 8640, 66, 17280, 8640, 66, 66, 66, 17280, 17280, 66, 66, 8640, 8640, 8640, 17280, 17280, 66, 17280, 17280, 17280, 17280, 8640, 66, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 285780 . Total input tokens: 63750125 . Total output tokens: 57041866
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 6.809961235150695,
    "estimated_duration": 3600.0241677797803,
    "input_throughput": 6546.018554795869,
    "output_throughput": 5798.454128954873,
    "total_throughput": 12344.472683750742,
    "itl": 57.2609382138436,
    "ttft": 14551.614596321853,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971348,
    "arrivals": 95376,
    "finished_requests": 94993,
    "scheduler_time": 73.43569460747909
}
#Debug simulation 
Total elapsed time: 6.810083020012826. Arrivals time: 0.2522719600237906 Scheduler time: 6.342266687192023 Scheduler overhead time: 0.0811299211345613 Adapter cache time: 0.015084721613675356 Engine time: 0.08216815628111362 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-32/adapters_32_slots_32_rate_1.6-0.8-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-32/adapters_32_slots_32_rate_1.6-0.8-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 66, 66, 8640, 66, 17280, 8640, 66, 66, 66, 17280, 17280, 66, 66, 8640, 8640, 8640, 17280, 17280, 66, 17280, 17280, 17280, 17280, 8640, 66, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 285780 . Total input tokens: 63750125 . Total output tokens: 57041866
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 6.7927765510976315,
    "estimated_duration": 3600.0393516769695,
    "input_throughput": 6545.990945633017,
    "output_throughput": 5798.429672796829,
    "total_throughput": 12344.420618429847,
    "itl": 57.26098190945021,
    "ttft": 14551.719199277279,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089387,
    "arrivals": 95376,
    "finished_requests": 94993,
    "scheduler_time": 73.4359848092844
}
#Debug simulation 
Total elapsed time: 6.792864436749369. Arrivals time: 0.2540212986059487 Scheduler time: 6.3236353737302125 Scheduler overhead time: 0.08102911850437522 Adapter cache time: 0.014996414072811604 Engine time: 0.08197476901113987 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-16/adapters_32_slots_32_rate_1.6-0.8-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-16/adapters_32_slots_32_rate_1.6-0.8-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 66, 66, 8640, 66, 17280, 8640, 66, 66, 66, 17280, 17280, 66, 66, 8640, 8640, 8640, 17280, 17280, 66, 17280, 17280, 17280, 17280, 8640, 66, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 285780 . Total input tokens: 63750125 . Total output tokens: 57041866
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 6.821544206701219,
    "estimated_duration": 3600.018903575963,
    "input_throughput": 6546.028126850013,
    "output_throughput": 5798.462607867117,
    "total_throughput": 12344.49073471713,
    "itl": 57.261073812410906,
    "ttft": 14551.546852301726,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 95376,
    "finished_requests": 94993,
    "scheduler_time": 73.43569007097194
}
#Debug simulation 
Total elapsed time: 6.821758264675736. Arrivals time: 0.25439627980813384 Scheduler time: 6.3500269590877 Scheduler overhead time: 0.08182428311556578 Adapter cache time: 0.015151632949709892 Engine time: 0.08279370423406363 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-32/adapters_32_slots_32_rate_1.6-0.8-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-32/adapters_32_slots_32_rate_1.6-0.8-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 66, 66, 8640, 66, 17280, 8640, 66, 66, 66, 17280, 17280, 66, 66, 8640, 8640, 8640, 17280, 17280, 66, 17280, 17280, 17280, 17280, 8640, 66, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 285780 . Total input tokens: 63750125 . Total output tokens: 57041866
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 6.819568851031363,
    "estimated_duration": 3600.041268424145,
    "input_throughput": 6545.98746039251,
    "output_throughput": 5798.426585575637,
    "total_throughput": 12344.414045968148,
    "itl": 57.26094416281043,
    "ttft": 14551.677742492513,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145733,
    "arrivals": 95376,
    "finished_requests": 94993,
    "scheduler_time": 73.43597696551815
}
#Debug simulation 
Total elapsed time: 6.8196773189119995. Arrivals time: 0.26198098389431834 Scheduler time: 6.341959437355399 Scheduler overhead time: 0.08082385687157512 Adapter cache time: 0.015400904696434736 Engine time: 0.08187026670202613 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-8/adapters_32_slots_32_rate_1.6-0.8-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-8/adapters_32_slots_32_rate_1.6-0.8-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 33, 33, 8640, 33, 17280, 8640, 33, 33, 33, 17280, 17280, 33, 33, 8640, 8640, 8640, 17280, 17280, 33, 17280, 17280, 17280, 17280, 8640, 33, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 285450 . Total input tokens: 63682818 . Total output tokens: 56975482
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 6.802108278963715,
    "estimated_duration": 3600.0372760251266,
    "input_throughput": 6588.7212218506065,
    "output_throughput": 5778.726275570598,
    "total_throughput": 12367.447497421204,
    "itl": 56.321115353391185,
    "ttft": 12715.117334265358,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 95267,
    "finished_requests": 94933,
    "scheduler_time": 72.91526345744215
}
#Debug simulation 
Total elapsed time: 6.802193983923644. Arrivals time: 0.25482172798365355 Scheduler time: 6.330089240800589 Scheduler overhead time: 0.0817732335999608 Adapter cache time: 0.014528412371873856 Engine time: 0.08329579187557101 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-16/adapters_32_slots_32_rate_1.6-0.8-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-16/adapters_32_slots_32_rate_1.6-0.8-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 33, 33, 8640, 33, 17280, 8640, 33, 33, 33, 17280, 17280, 33, 33, 8640, 8640, 8640, 17280, 17280, 33, 17280, 17280, 17280, 17280, 8640, 33, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 285450 . Total input tokens: 63682818 . Total output tokens: 56975482
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 6.819587790872902,
    "estimated_duration": 3600.0046717925065,
    "input_throughput": 6588.780894050776,
    "output_throughput": 5778.778611873718,
    "total_throughput": 12367.559505924493,
    "itl": 56.321236866150166,
    "ttft": 12677.404982082055,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255728,
    "arrivals": 95267,
    "finished_requests": 94933,
    "scheduler_time": 72.9148142643871
}
#Debug simulation 
Total elapsed time: 6.819711591582745. Arrivals time: 0.24743748363107443 Scheduler time: 6.354460534173995 Scheduler overhead time: 0.08181997435167432 Adapter cache time: 0.01438186690211296 Engine time: 0.08388460241258144 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-32/adapters_32_slots_32_rate_1.6-0.8-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-32/adapters_32_slots_32_rate_1.6-0.8-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 33, 33, 8640, 33, 17280, 8640, 33, 33, 33, 17280, 17280, 33, 33, 8640, 8640, 8640, 17280, 17280, 33, 17280, 17280, 17280, 17280, 8640, 33, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 285450 . Total input tokens: 63682818 . Total output tokens: 56975482
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 6.777784463018179,
    "estimated_duration": 3600.0511257789653,
    "input_throughput": 6588.7636512016425,
    "output_throughput": 5778.704599784979,
    "total_throughput": 12367.468250986622,
    "itl": 56.32079366301392,
    "ttft": 12677.292036826098,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033042,
    "arrivals": 95267,
    "finished_requests": 94934,
    "scheduler_time": 72.91550287963949
}
#Debug simulation 
Total elapsed time: 6.777874303981662. Arrivals time: 0.2451047063805163 Scheduler time: 6.316491001751274 Scheduler overhead time: 0.0817068456672132 Adapter cache time: 0.014331521466374397 Engine time: 0.08263699384406209 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-16/adapters_32_slots_32_rate_1.6-0.8-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-16/adapters_32_slots_32_rate_1.6-0.8-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 33, 33, 8640, 33, 17280, 8640, 33, 33, 33, 17280, 17280, 33, 33, 8640, 8640, 8640, 17280, 17280, 33, 17280, 17280, 17280, 17280, 8640, 33, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 285450 . Total input tokens: 63682818 . Total output tokens: 56975482
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 6.7933231382630765,
    "estimated_duration": 3600.048382300416,
    "input_throughput": 6588.768672281868,
    "output_throughput": 5778.709003545826,
    "total_throughput": 12367.477675827695,
    "itl": 56.32093985866447,
    "ttft": 12677.322301581293,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971348,
    "arrivals": 95267,
    "finished_requests": 94934,
    "scheduler_time": 72.91555096661241
}
#Debug simulation 
Total elapsed time: 6.793412371072918. Arrivals time: 0.2558682216331363 Scheduler time: 6.319531170651317 Scheduler overhead time: 0.0820149490609765 Adapter cache time: 0.0145519794896245 Engine time: 0.083459482062608 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-32/adapters_32_slots_32_rate_1.6-0.8-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-32/adapters_32_slots_32_rate_1.6-0.8-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 33, 33, 8640, 33, 17280, 8640, 33, 33, 33, 17280, 17280, 33, 33, 8640, 8640, 8640, 17280, 17280, 33, 17280, 17280, 17280, 17280, 8640, 33, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 285450 . Total input tokens: 63682818 . Total output tokens: 56975482
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 6.811087816953659,
    "estimated_duration": 3600.0053511346996,
    "input_throughput": 6588.779650709051,
    "output_throughput": 5778.77752138419,
    "total_throughput": 12367.55717209324,
    "itl": 56.32122223799344,
    "ttft": 12677.388565644216,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089387,
    "arrivals": 95267,
    "finished_requests": 94933,
    "scheduler_time": 72.91477704161632
}
#Debug simulation 
Total elapsed time: 6.811179224867374. Arrivals time: 0.2555409907363355 Scheduler time: 6.334795416332781 Scheduler overhead time: 0.08409160049632192 Adapter cache time: 0.014500683173537254 Engine time: 0.08419468533247709 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-16/adapters_32_slots_32_rate_1.6-0.8-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-16/adapters_32_slots_32_rate_1.6-0.8-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 33, 33, 8640, 33, 17280, 8640, 33, 33, 33, 17280, 17280, 33, 33, 8640, 8640, 8640, 17280, 17280, 33, 17280, 17280, 17280, 17280, 8640, 33, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 285450 . Total input tokens: 63682818 . Total output tokens: 56975482
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 6.793417413253337,
    "estimated_duration": 3600.0375003877803,
    "input_throughput": 6588.720811226279,
    "output_throughput": 5778.725915427027,
    "total_throughput": 12367.446726653305,
    "itl": 56.32119138184375,
    "ttft": 12715.147059818266,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 95267,
    "finished_requests": 94933,
    "scheduler_time": 72.91535640607738
}
#Debug simulation 
Total elapsed time: 6.793531720992178. Arrivals time: 0.24737126240506768 Scheduler time: 6.329286547377706 Scheduler overhead time: 0.08186977542936802 Adapter cache time: 0.014430890791118145 Engine time: 0.08257675683125854 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-32/adapters_32_slots_32_rate_1.6-0.8-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-32/adapters_32_slots_32_rate_1.6-0.8-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 33, 33, 8640, 33, 17280, 8640, 33, 33, 33, 17280, 17280, 33, 33, 8640, 8640, 8640, 17280, 17280, 33, 17280, 17280, 17280, 17280, 8640, 33, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 285450 . Total input tokens: 63682818 . Total output tokens: 56975482
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 6.811654580291361,
    "estimated_duration": 3600.014008711542,
    "input_throughput": 6588.7638055301195,
    "output_throughput": 5778.763624157589,
    "total_throughput": 12367.527429687709,
    "itl": 56.3212887771859,
    "ttft": 12677.308179663412,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145734,
    "arrivals": 95267,
    "finished_requests": 94933,
    "scheduler_time": 72.91500383769136
}
#Debug simulation 
Total elapsed time: 6.811780074145645. Arrivals time: 0.24728768644854426 Scheduler time: 6.343743334989995 Scheduler overhead time: 0.08313909592106938 Adapter cache time: 0.014528351835906506 Engine time: 0.08522150944918394 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-8/adapters_32_slots_32_rate_1.6-0.4-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-8/adapters_32_slots_32_rate_1.6-0.4-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 1080, 1080, 4320, 1080, 17280, 4320, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 4320, 4320, 4320, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 4320, 1080, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 248400 . Total input tokens: 55382994 . Total output tokens: 49632071
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 5.978787217754871,
    "estimated_duration": 3600.049409437749,
    "input_throughput": 5719.920661648927,
    "output_throughput": 5052.23649217654,
    "total_throughput": 10772.157153825468,
    "itl": 51.90197642796194,
    "ttft": 11620.964872169105,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 83017,
    "finished_requests": 82751,
    "scheduler_time": 61.32248813286656
}
#Debug simulation 
Total elapsed time: 5.978873380925506. Arrivals time: 0.22012260230258107 Scheduler time: 5.5290952902287245 Scheduler overhead time: 0.08433958096429706 Adapter cache time: 0.019859263207763433 Engine time: 0.0859194528311491 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-16/adapters_32_slots_32_rate_1.6-0.4-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-16/adapters_32_slots_32_rate_1.6-0.4-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 1080, 1080, 4320, 1080, 17280, 4320, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 4320, 4320, 4320, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 4320, 1080, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 248400 . Total input tokens: 55382994 . Total output tokens: 49632071
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 5.964482850860804,
    "estimated_duration": 3600.04979440173,
    "input_throughput": 5719.920050000879,
    "output_throughput": 5052.235951925937,
    "total_throughput": 10772.156001926816,
    "itl": 51.90172131878706,
    "ttft": 11621.058773403905,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255726,
    "arrivals": 83017,
    "finished_requests": 82751,
    "scheduler_time": 61.322427337821665
}
#Debug simulation 
Total elapsed time: 5.964593464042991. Arrivals time: 0.21275406377390027 Scheduler time: 5.522251232527196 Scheduler overhead time: 0.08430956164374948 Adapter cache time: 0.019872387871146202 Engine time: 0.08586593111976981 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-32/adapters_32_slots_32_rate_1.6-0.4-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-32/adapters_32_slots_32_rate_1.6-0.4-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 1080, 1080, 4320, 1080, 17280, 4320, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 4320, 4320, 4320, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 4320, 1080, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 248400 . Total input tokens: 55382994 . Total output tokens: 49632071
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 5.9509552721865475,
    "estimated_duration": 3600.048626448528,
    "input_throughput": 5719.921905697741,
    "output_throughput": 5052.237591008008,
    "total_throughput": 10772.15949670575,
    "itl": 51.90169417107382,
    "ttft": 11621.024469791066,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.1048120480403304,
    "arrivals": 83017,
    "finished_requests": 82751,
    "scheduler_time": 61.322358658034716
}
#Debug simulation 
Total elapsed time: 5.951064862776548. Arrivals time: 0.21426926366984844 Scheduler time: 5.506132917944342 Scheduler overhead time: 0.08481585700064898 Adapter cache time: 0.01989794708788395 Engine time: 0.08655936364084482 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-16-16/adapters_32_slots_32_rate_1.6-0.4-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-16-16/adapters_32_slots_32_rate_1.6-0.4-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 1080, 1080, 4320, 1080, 17280, 4320, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 4320, 4320, 4320, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 4320, 1080, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 248400 . Total input tokens: 55382994 . Total output tokens: 49632071
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 5.969885772559792,
    "estimated_duration": 3600.0482585113436,
    "input_throughput": 5719.922490293227,
    "output_throughput": 5052.238107363884,
    "total_throughput": 10772.160597657112,
    "itl": 51.901888702194505,
    "ttft": 11620.974581181255,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971346,
    "arrivals": 83017,
    "finished_requests": 82751,
    "scheduler_time": 61.32244368095274
}
#Debug simulation 
Total elapsed time: 5.9700347715988755. Arrivals time: 0.222633246332407 Scheduler time: 5.516894315369427 Scheduler overhead time: 0.0850868783891201 Adapter cache time: 0.020015953574329615 Engine time: 0.08585410099476576 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-16-32/adapters_32_slots_32_rate_1.6-0.4-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-16-32/adapters_32_slots_32_rate_1.6-0.4-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 1080, 1080, 4320, 1080, 17280, 4320, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 4320, 4320, 4320, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 4320, 1080, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 248400 . Total input tokens: 55382994 . Total output tokens: 49632071
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 5.990529165137559,
    "estimated_duration": 3600.04788195355,
    "input_throughput": 5719.923088585656,
    "output_throughput": 5052.2386358178655,
    "total_throughput": 10772.161724403522,
    "itl": 51.901670187533,
    "ttft": 11621.02739451215,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089386,
    "arrivals": 83017,
    "finished_requests": 82751,
    "scheduler_time": 61.32233510024773
}
#Debug simulation 
Total elapsed time: 5.990632764995098. Arrivals time: 0.2247537267394364 Scheduler time: 5.535466362722218 Scheduler overhead time: 0.0849425308406353 Adapter cache time: 0.019919115584343672 Engine time: 0.08577867457643151 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_16-16-16/adapters_32_slots_32_rate_1.6-0.4-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_16-16-16/adapters_32_slots_32_rate_1.6-0.4-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 1080, 1080, 4320, 1080, 17280, 4320, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 4320, 4320, 4320, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 4320, 1080, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 248400 . Total input tokens: 55382994 . Total output tokens: 49632071
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 5.960733791813254,
    "estimated_duration": 3600.0361332845623,
    "input_throughput": 5719.941755476908,
    "output_throughput": 5052.255123729981,
    "total_throughput": 10772.19687920689,
    "itl": 51.901906261855984,
    "ttft": 11620.884718792684,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 83017,
    "finished_requests": 82751,
    "scheduler_time": 61.32213643944145
}
#Debug simulation 
Total elapsed time: 5.960861919913441. Arrivals time: 0.22359150368720293 Scheduler time: 5.507877663709223 Scheduler overhead time: 0.0848189014941454 Adapter cache time: 0.019966106861829758 Engine time: 0.08524297876283526 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_16-16-32/adapters_32_slots_32_rate_1.6-0.4-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_16-16-32/adapters_32_slots_32_rate_1.6-0.4-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 1080, 1080, 4320, 1080, 17280, 4320, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 4320, 4320, 4320, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 4320, 1080, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 248400 . Total input tokens: 55382994 . Total output tokens: 49632071
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 5.978341577108949,
    "estimated_duration": 3600.0108983369973,
    "input_throughput": 5719.981850475048,
    "output_throughput": 5052.2905384541955,
    "total_throughput": 10772.272388929245,
    "itl": 51.902043805953454,
    "ttft": 11620.936775304473,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145731,
    "arrivals": 83017,
    "finished_requests": 82751,
    "scheduler_time": 61.32189379193464
}
#Debug simulation 
Total elapsed time: 5.978449023794383. Arrivals time: 0.22710823360830545 Scheduler time: 5.520516301039606 Scheduler overhead time: 0.08509818697348237 Adapter cache time: 0.019989666994661093 Engine time: 0.08593761036172509 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-8/adapters_32_slots_32_rate_1.6-0.4-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-8/adapters_32_slots_32_rate_1.6-0.4-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 540, 540, 4320, 540, 17280, 4320, 540, 540, 540, 17280, 17280, 540, 540, 4320, 4320, 4320, 17280, 17280, 540, 17280, 17280, 17280, 17280, 4320, 540, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 243000 . Total input tokens: 54202232 . Total output tokens: 48558410
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 5.8566961460746825,
    "estimated_duration": 3600.008198454339,
    "input_throughput": 5600.885022611079,
    "output_throughput": 4962.166477195754,
    "total_throughput": 10563.051499806834,
    "itl": 48.35594213697235,
    "ttft": 13459.510334694958,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 81259,
    "finished_requests": 80957,
    "scheduler_time": 59.12804839309636
}
#Debug simulation 
Total elapsed time: 5.85679311491549. Arrivals time: 0.21996311703696847 Scheduler time: 5.397954949643463 Scheduler overhead time: 0.08840205427259207 Adapter cache time: 0.020075366366654634 Engine time: 0.08931581443175673 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-16/adapters_32_slots_32_rate_1.6-0.4-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-16/adapters_32_slots_32_rate_1.6-0.4-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 540, 540, 4320, 540, 17280, 4320, 540, 540, 540, 17280, 17280, 540, 540, 4320, 4320, 4320, 17280, 17280, 540, 17280, 17280, 17280, 17280, 4320, 540, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 243000 . Total input tokens: 54202232 . Total output tokens: 48558410
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 5.831327854655683,
    "estimated_duration": 3600.011856530001,
    "input_throughput": 5600.879331390604,
    "output_throughput": 4962.161434995577,
    "total_throughput": 10563.04076638618,
    "itl": 48.3557667591932,
    "ttft": 13459.418738059216,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255726,
    "arrivals": 81259,
    "finished_requests": 80957,
    "scheduler_time": 59.12802482082171
}
#Debug simulation 
Total elapsed time: 5.831432147882879. Arrivals time: 0.21950828889384866 Scheduler time: 5.375601064879447 Scheduler overhead time: 0.08746188040822744 Adapter cache time: 0.019846197217702866 Engine time: 0.0882022469304502 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-32/adapters_32_slots_32_rate_1.6-0.4-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-32/adapters_32_slots_32_rate_1.6-0.4-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 540, 540, 4320, 540, 17280, 4320, 540, 540, 540, 17280, 17280, 540, 540, 4320, 4320, 4320, 17280, 17280, 540, 17280, 17280, 17280, 17280, 4320, 540, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 243000 . Total input tokens: 54202232 . Total output tokens: 48558410
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 5.839883704204112,
    "estimated_duration": 3600.0089036069617,
    "input_throughput": 5600.883925536358,
    "output_throughput": 4962.165505230184,
    "total_throughput": 10563.049430766541,
    "itl": 48.35576038028367,
    "ttft": 13459.442876651972,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.1048120480403304,
    "arrivals": 81259,
    "finished_requests": 80957,
    "scheduler_time": 59.127960103892924
}
#Debug simulation 
Total elapsed time: 5.8399728471413255. Arrivals time: 0.2216274281963706 Scheduler time: 5.379709813278168 Scheduler overhead time: 0.08841979363933206 Adapter cache time: 0.020050103310495615 Engine time: 0.0889039053581655 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-16-16/adapters_32_slots_32_rate_1.6-0.4-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-16-16/adapters_32_slots_32_rate_1.6-0.4-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 540, 540, 4320, 540, 17280, 4320, 540, 540, 540, 17280, 17280, 540, 540, 4320, 4320, 4320, 17280, 17280, 540, 17280, 17280, 17280, 17280, 4320, 540, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 243000 . Total input tokens: 54202232 . Total output tokens: 48558410
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 5.819712023250759,
    "estimated_duration": 3600.0088532397644,
    "input_throughput": 5600.884003897506,
    "output_throughput": 4962.165574655116,
    "total_throughput": 10563.049578552622,
    "itl": 48.35581334018323,
    "ttft": 13459.368660582555,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971348,
    "arrivals": 81259,
    "finished_requests": 80957,
    "scheduler_time": 59.12796423065128
}
#Debug simulation 
Total elapsed time: 5.819908880162984. Arrivals time: 0.22285185009241104 Scheduler time: 5.358980854973197 Scheduler overhead time: 0.08835399895906448 Adapter cache time: 0.020110500510782003 Engine time: 0.08844382222741842 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-16-32/adapters_32_slots_32_rate_1.6-0.4-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-16-32/adapters_32_slots_32_rate_1.6-0.4-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 540, 540, 4320, 540, 17280, 4320, 540, 540, 540, 17280, 17280, 540, 540, 4320, 4320, 4320, 17280, 17280, 540, 17280, 17280, 17280, 17280, 4320, 540, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 243000 . Total input tokens: 54202232 . Total output tokens: 48558410
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 5.857783514074981,
    "estimated_duration": 3600.0089021329622,
    "input_throughput": 5600.883927829603,
    "output_throughput": 4962.16550726191,
    "total_throughput": 10563.049435091512,
    "itl": 48.35573845310315,
    "ttft": 13459.432331408983,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089384,
    "arrivals": 81259,
    "finished_requests": 80957,
    "scheduler_time": 59.12795601810996
}
#Debug simulation 
Total elapsed time: 5.857881689909846. Arrivals time: 0.2269612606614828 Scheduler time: 5.392993933521211 Scheduler overhead time: 0.0882738372310996 Adapter cache time: 0.02023136941716075 Engine time: 0.08817787328734994 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_16-16-16/adapters_32_slots_32_rate_1.6-0.4-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_16-16-16/adapters_32_slots_32_rate_1.6-0.4-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 540, 540, 4320, 540, 17280, 4320, 540, 540, 540, 17280, 17280, 540, 540, 4320, 4320, 4320, 17280, 17280, 540, 17280, 17280, 17280, 17280, 4320, 540, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 243000 . Total input tokens: 54202232 . Total output tokens: 48558410
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 5.873316663317382,
    "estimated_duration": 3600.0247860833974,
    "input_throughput": 5600.859215732328,
    "output_throughput": 4962.143613304047,
    "total_throughput": 10563.002829036375,
    "itl": 48.3552536327557,
    "ttft": 13459.53090253919,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 81259,
    "finished_requests": 80957,
    "scheduler_time": 59.12809363802129
}
#Debug simulation 
Total elapsed time: 5.873444258235395. Arrivals time: 0.2266610162332654 Scheduler time: 5.408330135513097 Scheduler overhead time: 0.08808756526559591 Adapter cache time: 0.02012315997853875 Engine time: 0.08892995025962591 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_16-16-32/adapters_32_slots_32_rate_1.6-0.4-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_16-16-32/adapters_32_slots_32_rate_1.6-0.4-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 540, 540, 4320, 540, 17280, 4320, 540, 540, 540, 17280, 17280, 540, 540, 4320, 4320, 4320, 17280, 17280, 540, 17280, 17280, 17280, 17280, 4320, 540, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 243000 . Total input tokens: 54202232 . Total output tokens: 48558410
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 5.880205255001783,
    "estimated_duration": 3600.011916195401,
    "input_throughput": 5600.879238563493,
    "output_throughput": 4962.161352754363,
    "total_throughput": 10563.040591317857,
    "itl": 48.355693684424175,
    "ttft": 13459.455198740729,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145731,
    "arrivals": 81259,
    "finished_requests": 80957,
    "scheduler_time": 59.1280407542043
}
#Debug simulation 
Total elapsed time: 5.880302474834025. Arrivals time: 0.22544948291033506 Scheduler time: 5.415626234840602 Scheduler overhead time: 0.0888854768127203 Adapter cache time: 0.020183784887194633 Engine time: 0.0888907928019762 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-8/adapters_32_slots_32_rate_1.6-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-8/adapters_32_slots_32_rate_1.6-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 270, 270, 4320, 270, 17280, 4320, 270, 270, 270, 17280, 17280, 270, 270, 4320, 4320, 4320, 17280, 17280, 270, 17280, 17280, 17280, 17280, 4320, 270, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 240300 . Total input tokens: 53596823 . Total output tokens: 48032691
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 5.6963017750531435,
    "estimated_duration": 3600.040363892375,
    "input_throughput": 5501.361095459119,
    "output_throughput": 4870.84566491939,
    "total_throughput": 10372.206760378509,
    "itl": 45.570308252422734,
    "ttft": 12080.967408207041,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 80362,
    "finished_requests": 80094,
    "scheduler_time": 56.93021703523096
}
#Debug simulation 
Total elapsed time: 5.696404557675123. Arrivals time: 0.22213221760466695 Scheduler time: 5.233099762350321 Scheduler overhead time: 0.08986761095002294 Adapter cache time: 0.01922531146556139 Engine time: 0.08983338018879294 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-16/adapters_32_slots_32_rate_1.6-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-16/adapters_32_slots_32_rate_1.6-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 270, 270, 4320, 270, 17280, 4320, 270, 270, 270, 17280, 17280, 270, 270, 4320, 4320, 4320, 17280, 17280, 270, 17280, 17280, 17280, 17280, 4320, 270, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 240300 . Total input tokens: 53596823 . Total output tokens: 48032691
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 5.721690287347883,
    "estimated_duration": 3600.05044068187,
    "input_throughput": 5501.345696769959,
    "output_throughput": 4870.83203108641,
    "total_throughput": 10372.17772785637,
    "itl": 45.57034701480717,
    "ttft": 12081.096395482855,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255727,
    "arrivals": 80362,
    "finished_requests": 80094,
    "scheduler_time": 56.93042291069182
}
#Debug simulation 
Total elapsed time: 5.721774409059435. Arrivals time: 0.22102665156126022 Scheduler time: 5.260520638432354 Scheduler overhead time: 0.08970647258684039 Adapter cache time: 0.019208640791475773 Engine time: 0.08955142507329583 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-32/adapters_32_slots_32_rate_1.6-0.4-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-32/adapters_32_slots_32_rate_1.6-0.4-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 270, 270, 4320, 270, 17280, 4320, 270, 270, 270, 17280, 17280, 270, 270, 4320, 4320, 4320, 17280, 17280, 270, 17280, 17280, 17280, 17280, 4320, 270, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 240300 . Total input tokens: 53596823 . Total output tokens: 48032691
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 5.692074537742883,
    "estimated_duration": 3600.001314140181,
    "input_throughput": 5501.420769544976,
    "output_throughput": 4870.898499710157,
    "total_throughput": 10372.319269255133,
    "itl": 45.570345280146434,
    "ttft": 12036.446720965252,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.1048120480403304,
    "arrivals": 80362,
    "finished_requests": 80094,
    "scheduler_time": 56.92962104081391
}
#Debug simulation 
Total elapsed time: 5.69220474967733. Arrivals time: 0.22207209328189492 Scheduler time: 5.230874883942306 Scheduler overhead time: 0.08953167591243982 Adapter cache time: 0.019191238563507795 Engine time: 0.08881076192483306 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-16-16/adapters_32_slots_32_rate_1.6-0.4-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-16-16/adapters_32_slots_32_rate_1.6-0.4-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 270, 270, 4320, 270, 17280, 4320, 270, 270, 270, 17280, 17280, 270, 270, 4320, 4320, 4320, 17280, 17280, 270, 17280, 17280, 17280, 17280, 4320, 270, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 240300 . Total input tokens: 53596823 . Total output tokens: 48032691
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 5.68704356206581,
    "estimated_duration": 3600.0448136774,
    "input_throughput": 5501.354295578704,
    "output_throughput": 4870.839644378753,
    "total_throughput": 10372.193939957457,
    "itl": 45.57025872207271,
    "ttft": 12080.993944705593,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971346,
    "arrivals": 80362,
    "finished_requests": 80094,
    "scheduler_time": 56.930297767492064
}
#Debug simulation 
Total elapsed time: 5.6871289550326765. Arrivals time: 0.22063411865383387 Scheduler time: 5.225524269044399 Scheduler overhead time: 0.0902001946233213 Adapter cache time: 0.01915966486558318 Engine time: 0.08969153650105 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-16-32/adapters_32_slots_32_rate_1.6-0.4-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-16-32/adapters_32_slots_32_rate_1.6-0.4-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 270, 270, 4320, 270, 17280, 4320, 270, 270, 270, 17280, 17280, 270, 270, 4320, 4320, 4320, 17280, 17280, 270, 17280, 17280, 17280, 17280, 4320, 270, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 240300 . Total input tokens: 53596823 . Total output tokens: 48032691
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 5.674392352346331,
    "estimated_duration": 3600.001309168004,
    "input_throughput": 5501.4207771433175,
    "output_throughput": 4870.898506437646,
    "total_throughput": 10372.319283580964,
    "itl": 45.57033799616461,
    "ttft": 12036.432239258882,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089386,
    "arrivals": 80362,
    "finished_requests": 80094,
    "scheduler_time": 56.92961311509746
}
#Debug simulation 
Total elapsed time: 5.674479501321912. Arrivals time: 0.21921463403850794 Scheduler time: 5.216182617470622 Scheduler overhead time: 0.08910525171086192 Adapter cache time: 0.01907948451116681 Engine time: 0.08900028141215444 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_16-16-16/adapters_32_slots_32_rate_1.6-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_16-16-16/adapters_32_slots_32_rate_1.6-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 270, 270, 4320, 270, 17280, 4320, 270, 270, 270, 17280, 17280, 270, 270, 4320, 4320, 4320, 17280, 17280, 270, 17280, 17280, 17280, 17280, 4320, 270, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 240300 . Total input tokens: 53596823 . Total output tokens: 48032691
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 5.675483901053667,
    "estimated_duration": 3600.0298812855767,
    "input_throughput": 5501.377114383161,
    "output_throughput": 4870.859847901634,
    "total_throughput": 10372.236962284795,
    "itl": 45.57038718529731,
    "ttft": 12080.939429785314,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 80362,
    "finished_requests": 80094,
    "scheduler_time": 56.92994599211731
}
#Debug simulation 
Total elapsed time: 5.675598511938006. Arrivals time: 0.21955089643597603 Scheduler time: 5.214703305158764 Scheduler overhead time: 0.09017713041976094 Adapter cache time: 0.019158349838107824 Engine time: 0.08990068733692169 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_16-16-32/adapters_32_slots_32_rate_1.6-0.4-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_16-16-32/adapters_32_slots_32_rate_1.6-0.4-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 270, 270, 4320, 270, 17280, 4320, 270, 270, 270, 17280, 17280, 270, 270, 4320, 4320, 4320, 17280, 17280, 270, 17280, 17280, 17280, 17280, 4320, 270, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 240300 . Total input tokens: 53596823 . Total output tokens: 48032691
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 5.681146337185055,
    "estimated_duration": 3600.0021453351324,
    "input_throughput": 5501.41949933652,
    "output_throughput": 4870.897375081316,
    "total_throughput": 10372.316874417835,
    "itl": 45.570301705912065,
    "ttft": 12036.382450618052,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145731,
    "arrivals": 80362,
    "finished_requests": 80094,
    "scheduler_time": 56.92963730199623
}
#Debug simulation 
Total elapsed time: 5.681231438182294. Arrivals time: 0.22053501196205616 Scheduler time: 5.221614968497306 Scheduler overhead time: 0.08979967329651117 Adapter cache time: 0.01909866463392973 Engine time: 0.08831609226763248 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-8/adapters_32_slots_32_rate_1.6-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-8/adapters_32_slots_32_rate_1.6-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 135, 135, 4320, 135, 17280, 4320, 135, 135, 135, 17280, 17280, 135, 135, 4320, 4320, 4320, 17280, 17280, 135, 17280, 17280, 17280, 17280, 4320, 135, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 238950 . Total input tokens: 53317414 . Total output tokens: 47749740
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 5.698273411020637,
    "estimated_duration": 3600.031341500712,
    "input_throughput": 5483.813369183163,
    "output_throughput": 4878.874469097876,
    "total_throughput": 10362.687838281037,
    "itl": 44.806158302948,
    "ttft": 9269.121050041633,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 79870,
    "finished_requests": 79665,
    "scheduler_time": 56.77536219866298
}
#Debug simulation 
Total elapsed time: 5.698357322253287. Arrivals time: 0.2161358753219247 Scheduler time: 5.241413811221719 Scheduler overhead time: 0.09018361987546086 Adapter cache time: 0.017939956858754158 Engine time: 0.09064742550253868 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-16/adapters_32_slots_32_rate_1.6-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-16/adapters_32_slots_32_rate_1.6-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 135, 135, 4320, 135, 17280, 4320, 135, 135, 135, 17280, 17280, 135, 135, 4320, 4320, 4320, 17280, 17280, 135, 17280, 17280, 17280, 17280, 4320, 135, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 238950 . Total input tokens: 53317414 . Total output tokens: 47749740
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 5.690851874649525,
    "estimated_duration": 3600.0356544357837,
    "input_throughput": 5483.806799434061,
    "output_throughput": 4878.868624081096,
    "total_throughput": 10362.675423515157,
    "itl": 44.80624775722728,
    "ttft": 9269.161500147782,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255727,
    "arrivals": 79870,
    "finished_requests": 79665,
    "scheduler_time": 56.77538209490365
}
#Debug simulation 
Total elapsed time: 5.690968877635896. Arrivals time: 0.21286968374624848 Scheduler time: 5.239376553799957 Scheduler overhead time: 0.08962886407971382 Adapter cache time: 0.01787178311496973 Engine time: 0.08910862356424332 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-32/adapters_32_slots_32_rate_1.6-0.4-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-32/adapters_32_slots_32_rate_1.6-0.4-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 135, 135, 4320, 135, 17280, 4320, 135, 135, 135, 17280, 17280, 135, 135, 4320, 4320, 4320, 17280, 17280, 135, 17280, 17280, 17280, 17280, 4320, 135, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 238950 . Total input tokens: 53317414 . Total output tokens: 47749740
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 5.696586653124541,
    "estimated_duration": 3600.0360004730064,
    "input_throughput": 5483.806272327867,
    "output_throughput": 4878.868155121855,
    "total_throughput": 10362.674427449721,
    "itl": 44.80624862567364,
    "ttft": 9269.160086518004,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033041,
    "arrivals": 79870,
    "finished_requests": 79665,
    "scheduler_time": 56.7753863036115
}
#Debug simulation 
Total elapsed time: 5.696693961974233. Arrivals time: 0.21074208710342646 Scheduler time: 5.246806335635483 Scheduler overhead time: 0.09009848441928625 Adapter cache time: 0.01792653603479266 Engine time: 0.08907264610752463 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-16/adapters_32_slots_32_rate_1.6-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-16/adapters_32_slots_32_rate_1.6-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 135, 135, 4320, 135, 17280, 4320, 135, 135, 135, 17280, 17280, 135, 135, 4320, 4320, 4320, 17280, 17280, 135, 17280, 17280, 17280, 17280, 4320, 135, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 238950 . Total input tokens: 53317414 . Total output tokens: 47749740
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 5.694820504635572,
    "estimated_duration": 3600.0343364652886,
    "input_throughput": 5483.808807052569,
    "output_throughput": 4878.870410232086,
    "total_throughput": 10362.679217284654,
    "itl": 44.80631087284171,
    "ttft": 9269.169381949156,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971348,
    "arrivals": 79870,
    "finished_requests": 79665,
    "scheduler_time": 56.775406486676786
}
#Debug simulation 
Total elapsed time: 5.694919516798109. Arrivals time: 0.21123006707057357 Scheduler time: 5.2430420499295 Scheduler overhead time: 0.09031668677926064 Adapter cache time: 0.01787544321268797 Engine time: 0.0904669240117073 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-32/adapters_32_slots_32_rate_1.6-0.4-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-32/adapters_32_slots_32_rate_1.6-0.4-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 135, 135, 4320, 135, 17280, 4320, 135, 135, 135, 17280, 17280, 135, 135, 4320, 4320, 4320, 17280, 17280, 135, 17280, 17280, 17280, 17280, 4320, 135, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 238950 . Total input tokens: 53317414 . Total output tokens: 47749740
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 5.69696401944384,
    "estimated_duration": 3600.0031400997254,
    "input_throughput": 5483.856327817847,
    "output_throughput": 4878.912688813224,
    "total_throughput": 10362.769016631071,
    "itl": 44.8063257748062,
    "ttft": 9179.362470795737,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089387,
    "arrivals": 79870,
    "finished_requests": 79665,
    "scheduler_time": 56.77507397843184
}
#Debug simulation 
Total elapsed time: 5.697061285376549. Arrivals time: 0.2093208828009665 Scheduler time: 5.24862493108958 Scheduler overhead time: 0.08985248394310474 Adapter cache time: 0.017879254650324583 Engine time: 0.08946536760777235 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-16/adapters_32_slots_32_rate_1.6-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-16/adapters_32_slots_32_rate_1.6-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 135, 135, 4320, 135, 17280, 4320, 135, 135, 135, 17280, 17280, 135, 135, 4320, 4320, 4320, 17280, 17280, 135, 17280, 17280, 17280, 17280, 4320, 135, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 238950 . Total input tokens: 53317414 . Total output tokens: 47749740
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 5.693999320268631,
    "estimated_duration": 3600.0270723243607,
    "input_throughput": 5483.819872291579,
    "output_throughput": 4878.88025482534,
    "total_throughput": 10362.70012711692,
    "itl": 44.80617277422457,
    "ttft": 9269.172911306503,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 79870,
    "finished_requests": 79665,
    "scheduler_time": 56.77528463624881
}
#Debug simulation 
Total elapsed time: 5.694117492064834. Arrivals time: 0.21147515950724483 Scheduler time: 5.243807343766093 Scheduler overhead time: 0.0897256126627326 Adapter cache time: 0.017883270047605038 Engine time: 0.08898927411064506 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-32/adapters_32_slots_32_rate_1.6-0.4-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-32/adapters_32_slots_32_rate_1.6-0.4-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 135, 135, 4320, 135, 17280, 4320, 135, 135, 135, 17280, 17280, 135, 135, 4320, 4320, 4320, 17280, 17280, 135, 17280, 17280, 17280, 17280, 4320, 135, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 238950 . Total input tokens: 53317414 . Total output tokens: 47749740
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 5.700917637906969,
    "estimated_duration": 3600.008716701667,
    "input_throughput": 5483.847833037348,
    "output_throughput": 4878.9051311220865,
    "total_throughput": 10362.752964159434,
    "itl": 44.80639925875821,
    "ttft": 9269.213828682685,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145734,
    "arrivals": 79870,
    "finished_requests": 79665,
    "scheduler_time": 56.77514690790103
}
#Debug simulation 
Total elapsed time: 5.701011918019503. Arrivals time: 0.2089699087664485 Scheduler time: 5.2531554899178445 Scheduler overhead time: 0.09010258968919516 Adapter cache time: 0.01772743696346879 Engine time: 0.08903601439669728 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-8/adapters_32_slots_32_rate_1.6-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-8/adapters_32_slots_32_rate_1.6-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 66, 66, 4320, 66, 17280, 4320, 66, 66, 66, 17280, 17280, 66, 66, 4320, 4320, 4320, 17280, 17280, 66, 17280, 17280, 17280, 17280, 4320, 66, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 238260 . Total input tokens: 53168695 . Total output tokens: 47604318
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 5.643510407302529,
    "estimated_duration": 3599.9792756289366,
    "input_throughput": 5516.012032188929,
    "output_throughput": 4841.894818118017,
    "total_throughput": 10357.906850306947,
    "itl": 43.88158810572575,
    "ttft": 11052.232414604487,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 79675,
    "finished_requests": 79432,
    "scheduler_time": 55.97085560146679
}
#Debug simulation 
Total elapsed time: 5.643607068341225. Arrivals time: 0.20578620629385114 Scheduler time: 5.195410530548543 Scheduler overhead time: 0.09112487267702818 Adapter cache time: 0.01722801197320223 Engine time: 0.09149540727958083 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-16/adapters_32_slots_32_rate_1.6-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-16/adapters_32_slots_32_rate_1.6-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 66, 66, 4320, 66, 17280, 4320, 66, 66, 66, 17280, 17280, 66, 66, 4320, 4320, 4320, 17280, 17280, 66, 17280, 17280, 17280, 17280, 4320, 66, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 238260 . Total input tokens: 53168695 . Total output tokens: 47604318
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 5.6314295111224055,
    "estimated_duration": 3599.996365960828,
    "input_throughput": 5515.9858459190655,
    "output_throughput": 4841.871832097751,
    "total_throughput": 10357.857678016817,
    "itl": 43.88157885328738,
    "ttft": 11052.234822444958,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255727,
    "arrivals": 79675,
    "finished_requests": 79432,
    "scheduler_time": 55.9711636215018
}
#Debug simulation 
Total elapsed time: 5.6315205078572035. Arrivals time: 0.20934373885393143 Scheduler time: 5.181046686600894 Scheduler overhead time: 0.09092945978045464 Adapter cache time: 0.017117938958108425 Engine time: 0.09071709169074893 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-32/adapters_32_slots_32_rate_1.6-0.4-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-32/adapters_32_slots_32_rate_1.6-0.4-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 66, 66, 4320, 66, 17280, 4320, 66, 66, 66, 17280, 17280, 66, 66, 4320, 4320, 4320, 17280, 17280, 66, 17280, 17280, 17280, 17280, 4320, 66, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 238260 . Total input tokens: 53168695 . Total output tokens: 47604318
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 5.6558599872514606,
    "estimated_duration": 3600.000823160238,
    "input_throughput": 5515.979016518167,
    "output_throughput": 4841.865837324602,
    "total_throughput": 10357.84485384277,
    "itl": 43.881557359966436,
    "ttft": 11052.262101926668,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033041,
    "arrivals": 79675,
    "finished_requests": 79432,
    "scheduler_time": 55.971232178363366
}
#Debug simulation 
Total elapsed time: 5.655945578124374. Arrivals time: 0.20880708936601877 Scheduler time: 5.205893556121737 Scheduler overhead time: 0.09139712480828166 Adapter cache time: 0.01722506294026971 Engine time: 0.0901526645757258 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-16/adapters_32_slots_32_rate_1.6-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-16/adapters_32_slots_32_rate_1.6-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 66, 66, 4320, 66, 17280, 4320, 66, 66, 66, 17280, 17280, 66, 66, 4320, 4320, 4320, 17280, 17280, 66, 17280, 17280, 17280, 17280, 4320, 66, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 238260 . Total input tokens: 53168695 . Total output tokens: 47604318
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 5.635984975844622,
    "estimated_duration": 3599.9877721527787,
    "input_throughput": 5515.99901355367,
    "output_throughput": 4841.883390502879,
    "total_throughput": 10357.882404056549,
    "itl": 43.88165523839082,
    "ttft": 11052.226285707708,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971348,
    "arrivals": 79675,
    "finished_requests": 79432,
    "scheduler_time": 55.97100546423902
}
#Debug simulation 
Total elapsed time: 5.636098795104772. Arrivals time: 0.20505850529298186 Scheduler time: 5.190753272268921 Scheduler overhead time: 0.09053752664476633 Adapter cache time: 0.01720554707571864 Engine time: 0.0901673249900341 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-32/adapters_32_slots_32_rate_1.6-0.4-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-32/adapters_32_slots_32_rate_1.6-0.4-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 66, 66, 4320, 66, 17280, 4320, 66, 66, 66, 17280, 17280, 66, 66, 4320, 4320, 4320, 17280, 17280, 66, 17280, 17280, 17280, 17280, 4320, 66, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 238260 . Total input tokens: 53168695 . Total output tokens: 47604318
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 5.634960972238332,
    "estimated_duration": 3599.9974443151928,
    "input_throughput": 5515.984193643611,
    "output_throughput": 4841.870381748493,
    "total_throughput": 10357.854575392104,
    "itl": 43.881523858096145,
    "ttft": 11052.211128031162,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089387,
    "arrivals": 79675,
    "finished_requests": 79432,
    "scheduler_time": 55.971175755925906
}
#Debug simulation 
Total elapsed time: 5.635074227117002. Arrivals time: 0.2066749674268067 Scheduler time: 5.18792228307575 Scheduler overhead time: 0.09085154393687844 Adapter cache time: 0.017178724519908428 Engine time: 0.08955277409404516 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-16/adapters_32_slots_32_rate_1.6-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-16/adapters_32_slots_32_rate_1.6-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 66, 66, 4320, 66, 17280, 4320, 66, 66, 66, 17280, 17280, 66, 66, 4320, 4320, 4320, 17280, 17280, 66, 17280, 17280, 17280, 17280, 4320, 66, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 238260 . Total input tokens: 53168695 . Total output tokens: 47604318
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 5.649902967270464,
    "estimated_duration": 3600.0192268572778,
    "input_throughput": 5515.950818222463,
    "output_throughput": 4841.841085170137,
    "total_throughput": 10357.791903392601,
    "itl": 43.88160146715652,
    "ttft": 11052.218066409441,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 79675,
    "finished_requests": 79432,
    "scheduler_time": 55.971455640691474
}
#Debug simulation 
Total elapsed time: 5.650026755873114. Arrivals time: 0.21177979977801442 Scheduler time: 5.195814765524119 Scheduler overhead time: 0.09092369023710489 Adapter cache time: 0.017319391947239637 Engine time: 0.09150724112987518 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-32/adapters_32_slots_32_rate_1.6-0.4-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-32/adapters_32_slots_32_rate_1.6-0.4-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 66, 66, 4320, 66, 17280, 4320, 66, 66, 66, 17280, 17280, 66, 66, 4320, 4320, 4320, 17280, 17280, 66, 17280, 17280, 17280, 17280, 4320, 66, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 238260 . Total input tokens: 53168695 . Total output tokens: 47604318
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 5.648682304657996,
    "estimated_duration": 3600.0007930082893,
    "input_throughput": 5515.979062717466,
    "output_throughput": 4841.86587787784,
    "total_throughput": 10357.844940595307,
    "itl": 43.881530922770985,
    "ttft": 11052.252065276203,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145734,
    "arrivals": 79675,
    "finished_requests": 79432,
    "scheduler_time": 55.97119986087393
}
#Debug simulation 
Total elapsed time: 5.648805094882846. Arrivals time: 0.21445708675310016 Scheduler time: 5.1921035083942115 Scheduler overhead time: 0.09117004554718733 Adapter cache time: 0.01736469939351082 Engine time: 0.091121313162148 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-8/adapters_32_slots_32_rate_1.6-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-8/adapters_32_slots_32_rate_1.6-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 33, 33, 4320, 33, 17280, 4320, 33, 33, 33, 17280, 17280, 33, 33, 4320, 4320, 4320, 17280, 17280, 33, 17280, 17280, 17280, 17280, 4320, 33, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 237930 . Total input tokens: 53094608 . Total output tokens: 47535877
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 5.638243074063212,
    "estimated_duration": 3600.015202205417,
    "input_throughput": 5483.374066839183,
    "output_throughput": 4851.316458136294,
    "total_throughput": 10334.690524975476,
    "itl": 43.83969137499975,
    "ttft": 9894.004648490976,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 79540,
    "finished_requests": 79323,
    "scheduler_time": 56.049139689133426
}
#Debug simulation 
Total elapsed time: 5.638360080309212. Arrivals time: 0.21287972200661898 Scheduler time: 5.184433234855533 Scheduler overhead time: 0.09092088276520371 Adapter cache time: 0.016922333277761936 Engine time: 0.09069792600348592 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-16/adapters_32_slots_32_rate_1.6-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-16/adapters_32_slots_32_rate_1.6-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 33, 33, 4320, 33, 17280, 4320, 33, 33, 33, 17280, 17280, 33, 33, 4320, 4320, 4320, 17280, 17280, 33, 17280, 17280, 17280, 17280, 4320, 33, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 237930 . Total input tokens: 53094608 . Total output tokens: 47535877
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 5.68390455795452,
    "estimated_duration": 3599.982870910316,
    "input_throughput": 5483.396923777133,
    "output_throughput": 4851.291971726463,
    "total_throughput": 10334.688895503597,
    "itl": 43.83964681399625,
    "ttft": 9939.1796950089,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255727,
    "arrivals": 79540,
    "finished_requests": 79322,
    "scheduler_time": 56.04854059233133
}
#Debug simulation 
Total elapsed time: 5.683999802917242. Arrivals time: 0.21392571600154042 Scheduler time: 5.229550496209413 Scheduler overhead time: 0.09084614785388112 Adapter cache time: 0.016892625018954277 Engine time: 0.08997701294720173 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-32/adapters_32_slots_32_rate_1.6-0.4-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-32/adapters_32_slots_32_rate_1.6-0.4-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 33, 33, 4320, 33, 17280, 4320, 33, 33, 33, 17280, 17280, 33, 33, 4320, 4320, 4320, 17280, 17280, 33, 17280, 17280, 17280, 17280, 4320, 33, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 237930 . Total input tokens: 53094608 . Total output tokens: 47535877
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 5.661802749615163,
    "estimated_duration": 3599.983097684446,
    "input_throughput": 5483.39657836091,
    "output_throughput": 4851.291666128496,
    "total_throughput": 10334.688244489405,
    "itl": 43.839660320599485,
    "ttft": 9939.16013198803,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033041,
    "arrivals": 79540,
    "finished_requests": 79322,
    "scheduler_time": 56.048532584665026
}
#Debug simulation 
Total elapsed time: 5.661930902861059. Arrivals time: 0.21498347213491797 Scheduler time: 5.205970217008144 Scheduler overhead time: 0.0908796857111156 Adapter cache time: 0.016944519244134426 Engine time: 0.09065914805978537 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-16/adapters_32_slots_32_rate_1.6-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-16/adapters_32_slots_32_rate_1.6-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 33, 33, 4320, 33, 17280, 4320, 33, 33, 33, 17280, 17280, 33, 33, 4320, 4320, 4320, 17280, 17280, 33, 17280, 17280, 17280, 17280, 4320, 33, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 237930 . Total input tokens: 53094608 . Total output tokens: 47535877
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 5.65107647003606,
    "estimated_duration": 3600.0255419773794,
    "input_throughput": 5483.358317829412,
    "output_throughput": 4851.302524483516,
    "total_throughput": 10334.66084231293,
    "itl": 43.83975496910122,
    "ttft": 9893.996805975463,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971346,
    "arrivals": 79540,
    "finished_requests": 79323,
    "scheduler_time": 56.0493136568543
}
#Debug simulation 
Total elapsed time: 5.651192279998213. Arrivals time: 0.21329534333199263 Scheduler time: 5.195496974047273 Scheduler overhead time: 0.09087188728153706 Adapter cache time: 0.0168960839509964 Engine time: 0.09200708428397775 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-32/adapters_32_slots_32_rate_1.6-0.4-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-32/adapters_32_slots_32_rate_1.6-0.4-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 33, 33, 4320, 33, 17280, 4320, 33, 33, 33, 17280, 17280, 33, 33, 4320, 4320, 4320, 17280, 17280, 33, 17280, 17280, 17280, 17280, 4320, 33, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 237930 . Total input tokens: 53094608 . Total output tokens: 47535877
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 5.650380104314536,
    "estimated_duration": 3599.9909315791383,
    "input_throughput": 5483.384646011033,
    "output_throughput": 4851.281109294116,
    "total_throughput": 10334.665755305148,
    "itl": 43.839720361547,
    "ttft": 9939.228025639748,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089387,
    "arrivals": 79540,
    "finished_requests": 79322,
    "scheduler_time": 56.048673866121995
}
#Debug simulation 
Total elapsed time: 5.650484581012279. Arrivals time: 0.21643120609223843 Scheduler time: 5.191755031235516 Scheduler overhead time: 0.09136910596862435 Adapter cache time: 0.016987252049148083 Engine time: 0.09127998305484653 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-16/adapters_32_slots_32_rate_1.6-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-16/adapters_32_slots_32_rate_1.6-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 33, 33, 4320, 33, 17280, 4320, 33, 33, 33, 17280, 17280, 33, 33, 4320, 4320, 4320, 17280, 17280, 33, 17280, 17280, 17280, 17280, 4320, 33, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 237930 . Total input tokens: 53094608 . Total output tokens: 47535877
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 5.655282272025943,
    "estimated_duration": 3600.015673806481,
    "input_throughput": 5483.373348518687,
    "output_throughput": 4851.315822615172,
    "total_throughput": 10334.689171133858,
    "itl": 43.8397304281221,
    "ttft": 9894.028553340999,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 79540,
    "finished_requests": 79323,
    "scheduler_time": 56.04916416285612
}
#Debug simulation 
Total elapsed time: 5.655392960179597. Arrivals time: 0.21544065233319998 Scheduler time: 5.198577874805778 Scheduler overhead time: 0.09169426700100303 Adapter cache time: 0.017003091052174568 Engine time: 0.08984314557164907 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-32/adapters_32_slots_32_rate_1.6-0.4-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-32/adapters_32_slots_32_rate_1.6-0.4-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 33, 33, 4320, 33, 17280, 4320, 33, 33, 33, 17280, 17280, 33, 33, 4320, 4320, 4320, 17280, 17280, 33, 17280, 17280, 17280, 17280, 4320, 33, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 237930 . Total input tokens: 53094608 . Total output tokens: 47535877
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 5.613781854044646,
    "estimated_duration": 3599.9919153300575,
    "input_throughput": 5483.383147595255,
    "output_throughput": 4851.279783609958,
    "total_throughput": 10334.662931205212,
    "itl": 43.83970935137462,
    "ttft": 9939.227223941503,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145733,
    "arrivals": 79540,
    "finished_requests": 79322,
    "scheduler_time": 56.04871423225272
}
#Debug simulation 
Total elapsed time: 5.61386336106807. Arrivals time: 0.18236340302973986 Scheduler time: 5.191896109376103 Scheduler overhead time: 0.09088452020660043 Adapter cache time: 0.016709210816770792 Engine time: 0.08957611164078116 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-8/adapters_32_slots_32_rate_1.6-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-8/adapters_32_slots_32_rate_1.6-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [10 11 11]
Adapter prompts. [17280, 1080, 540, 540, 1080, 540, 17280, 1080, 540, 540, 540, 17280, 17280, 540, 540, 1080, 1080, 1080, 17280, 17280, 540, 17280, 17280, 17280, 17280, 1080, 540, 1080, 1080, 1080, 1080, 17280]
Prompts retrieved: 207360 . Total input tokens: 46296826 . Total output tokens: 41478695
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 5.020564929116517,
    "estimated_duration": 3600.032273641147,
    "input_throughput": 4816.964316395065,
    "output_throughput": 4248.882464747793,
    "total_throughput": 9065.846781142858,
    "itl": 38.188579930002504,
    "ttft": 8667.51454580275,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 69453,
    "finished_requests": 69287,
    "scheduler_time": 45.04842346762743
}
#Debug simulation 
Total elapsed time: 5.020663375966251. Arrivals time: 0.18871119618415833 Scheduler time: 4.5601438488811255 Scheduler overhead time: 0.09877379797399044 Adapter cache time: 0.028292254079133272 Engine time: 0.09833343233913183 
