INFO 06-01 00:47:16 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:47:16 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_320_slots_160_rate_0.4-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_320_slots_160_rate_0.4-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [106 107 107]
Adapter prompts. [66, 4320, 4320, 33, 4320, 4320, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 4320, 4320, 66, 33, 33, 66, 4320, 4320, 66, 66, 33, 33, 66, 4320, 4320, 33, 4320, 66, 33, 66, 4320, 33, 66, 4320, 4320, 66, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 66, 66, 66, 33, 66, 33, 4320, 33, 4320, 66, 4320, 4320, 33, 4320, 33, 4320, 66, 33, 33, 66, 66, 4320, 66, 4320, 4320, 4320, 33, 66, 66, 33, 4320, 66, 4320, 4320, 66, 33, 66, 66, 66, 33, 4320, 66, 4320, 33, 4320, 33, 33, 66, 4320, 4320, 66, 33, 66, 33, 66, 4320, 4320, 66, 33, 66, 33, 4320, 33, 33, 33, 33, 4320, 66, 66, 4320, 66, 66, 33, 66, 4320, 66, 33, 33, 66, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 66, 4320, 66, 66, 66, 33, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 33, 66, 4320, 4320, 4320, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 33, 33, 4320, 66, 4320, 66, 4320, 66, 33, 66, 33, 33, 33, 4320, 4320, 66, 66, 33, 33, 66, 33, 4320, 33, 33, 66, 33, 4320, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 33, 66, 4320, 66, 66, 4320, 66, 33, 66, 33, 4320, 66, 66, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 66, 33, 66, 33, 66, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 66, 66, 4320, 33, 4320, 33, 33, 33, 4320, 66, 4320, 4320, 33, 66, 66, 66, 33, 66, 33, 66, 66, 4320, 33, 33, 66, 33, 66, 66, 33, 4320, 4320, 4320, 33, 66, 66, 66, 66, 33, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 66, 66, 66, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 472800 . Total input tokens: 105331521 . Total output tokens: 94640994
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 5.028598132019397,
    "estimated_duration": 3600.1995906420334,
    "input_throughput": 4647.221238369268,
    "output_throughput": 4104.515493643718,
    "total_throughput": 8751.736732012987,
    "itl": 208.5046265454684,
    "ttft": 1713962.8273281862,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1237,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.8560014123934763,
    "arrivals": 157567,
    "finished_requests": 67622,
    "scheduler_time": 88.63842408059604
}
#Debug simulation 
Total elapsed time: 5.028715658001602. Arrivals time: 0.22487963776802644 Scheduler time: 4.702708800439723 Scheduler overhead time: 0.027706612017937005 Adapter cache time: 0.03279266768367961 Engine time: 0.027951957134064287 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-32/adapters_320_slots_160_rate_0.4-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-32/adapters_320_slots_160_rate_0.4-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [106 107 107]
Adapter prompts. [66, 4320, 4320, 33, 4320, 4320, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 4320, 4320, 66, 33, 33, 66, 4320, 4320, 66, 66, 33, 33, 66, 4320, 4320, 33, 4320, 66, 33, 66, 4320, 33, 66, 4320, 4320, 66, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 66, 66, 66, 33, 66, 33, 4320, 33, 4320, 66, 4320, 4320, 33, 4320, 33, 4320, 66, 33, 33, 66, 66, 4320, 66, 4320, 4320, 4320, 33, 66, 66, 33, 4320, 66, 4320, 4320, 66, 33, 66, 66, 66, 33, 4320, 66, 4320, 33, 4320, 33, 33, 66, 4320, 4320, 66, 33, 66, 33, 66, 4320, 4320, 66, 33, 66, 33, 4320, 33, 33, 33, 33, 4320, 66, 66, 4320, 66, 66, 33, 66, 4320, 66, 33, 33, 66, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 66, 4320, 66, 66, 66, 33, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 33, 66, 4320, 4320, 4320, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 33, 33, 4320, 66, 4320, 66, 4320, 66, 33, 66, 33, 33, 33, 4320, 4320, 66, 66, 33, 33, 66, 33, 4320, 33, 33, 66, 33, 4320, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 33, 66, 4320, 66, 66, 4320, 66, 33, 66, 33, 4320, 66, 66, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 66, 33, 66, 33, 66, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 66, 66, 4320, 33, 4320, 33, 33, 33, 4320, 66, 4320, 4320, 33, 66, 66, 66, 33, 66, 33, 66, 66, 4320, 33, 33, 66, 33, 66, 66, 33, 4320, 4320, 4320, 33, 66, 66, 66, 66, 33, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 66, 66, 66, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 472800 . Total input tokens: 105331521 . Total output tokens: 94640994
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.768960537970997,
    "estimated_duration": 3600.1361803884915,
    "input_throughput": 4267.54995649695,
    "output_throughput": 3784.598503307093,
    "total_throughput": 8052.148459804042,
    "itl": 134.18056007608163,
    "ttft": 1806075.3791450819,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1145,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.790849937181922,
    "arrivals": 157567,
    "finished_requests": 62161,
    "scheduler_time": 100.26795374076272
}
#Debug simulation 
Total elapsed time: 4.769059066020418. Arrivals time: 0.21399198105791584 Scheduler time: 4.409892554744147 Scheduler overhead time: 0.04059502319432795 Adapter cache time: 0.044562065217178315 Engine time: 0.04127268918091431 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_320_slots_160_rate_0.4-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_320_slots_160_rate_0.4-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [106 107 107]
Adapter prompts. [66, 4320, 4320, 33, 4320, 4320, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 4320, 4320, 66, 33, 33, 66, 4320, 4320, 66, 66, 33, 33, 66, 4320, 4320, 33, 4320, 66, 33, 66, 4320, 33, 66, 4320, 4320, 66, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 66, 66, 66, 33, 66, 33, 4320, 33, 4320, 66, 4320, 4320, 33, 4320, 33, 4320, 66, 33, 33, 66, 66, 4320, 66, 4320, 4320, 4320, 33, 66, 66, 33, 4320, 66, 4320, 4320, 66, 33, 66, 66, 66, 33, 4320, 66, 4320, 33, 4320, 33, 33, 66, 4320, 4320, 66, 33, 66, 33, 66, 4320, 4320, 66, 33, 66, 33, 4320, 33, 33, 33, 33, 4320, 66, 66, 4320, 66, 66, 33, 66, 4320, 66, 33, 33, 66, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 66, 4320, 66, 66, 66, 33, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 33, 66, 4320, 4320, 4320, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 33, 33, 4320, 66, 4320, 66, 4320, 66, 33, 66, 33, 33, 33, 4320, 4320, 66, 66, 33, 33, 66, 33, 4320, 33, 33, 66, 33, 4320, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 33, 66, 4320, 66, 66, 4320, 66, 33, 66, 33, 4320, 66, 66, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 66, 33, 66, 33, 66, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 66, 66, 4320, 33, 4320, 33, 33, 33, 4320, 66, 4320, 4320, 33, 66, 66, 66, 33, 66, 33, 66, 66, 4320, 33, 33, 66, 33, 66, 66, 33, 4320, 4320, 4320, 33, 66, 66, 66, 66, 33, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 66, 66, 66, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 472800 . Total input tokens: 105331521 . Total output tokens: 94640994
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.048003664996941,
    "estimated_duration": 3600.2034714904116,
    "input_throughput": 4647.5156564063,
    "output_throughput": 4104.578287593976,
    "total_throughput": 8752.093944000275,
    "itl": 208.49732251381366,
    "ttft": 1713918.4094768849,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1238,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.701682265088799,
    "arrivals": 157567,
    "finished_requests": 67625,
    "scheduler_time": 88.6421259558557
}
#Debug simulation 
Total elapsed time: 5.0481249910080805. Arrivals time: 0.23695937445154414 Scheduler time: 4.709674833808094 Scheduler overhead time: 0.027815864770673215 Adapter cache time: 0.0328381261206232 Engine time: 0.02807997545460239 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-32/adapters_320_slots_160_rate_0.4-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-32/adapters_320_slots_160_rate_0.4-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [106 107 107]
Adapter prompts. [66, 4320, 4320, 33, 4320, 4320, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 4320, 4320, 66, 33, 33, 66, 4320, 4320, 66, 66, 33, 33, 66, 4320, 4320, 33, 4320, 66, 33, 66, 4320, 33, 66, 4320, 4320, 66, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 66, 66, 66, 33, 66, 33, 4320, 33, 4320, 66, 4320, 4320, 33, 4320, 33, 4320, 66, 33, 33, 66, 66, 4320, 66, 4320, 4320, 4320, 33, 66, 66, 33, 4320, 66, 4320, 4320, 66, 33, 66, 66, 66, 33, 4320, 66, 4320, 33, 4320, 33, 33, 66, 4320, 4320, 66, 33, 66, 33, 66, 4320, 4320, 66, 33, 66, 33, 4320, 33, 33, 33, 33, 4320, 66, 66, 4320, 66, 66, 33, 66, 4320, 66, 33, 33, 66, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 66, 4320, 66, 66, 66, 33, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 33, 66, 4320, 4320, 4320, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 33, 33, 4320, 66, 4320, 66, 4320, 66, 33, 66, 33, 33, 33, 4320, 4320, 66, 66, 33, 33, 66, 33, 4320, 33, 33, 66, 33, 4320, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 33, 66, 4320, 66, 66, 4320, 66, 33, 66, 33, 4320, 66, 66, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 66, 33, 66, 33, 66, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 66, 66, 4320, 33, 4320, 33, 33, 33, 4320, 66, 4320, 4320, 33, 66, 66, 66, 33, 66, 33, 66, 66, 4320, 33, 33, 66, 33, 66, 66, 33, 4320, 4320, 4320, 33, 66, 66, 66, 66, 33, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 66, 66, 66, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 472800 . Total input tokens: 105331521 . Total output tokens: 94640994
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.975785331975203,
    "estimated_duration": 3600.121650346501,
    "input_throughput": 4267.473572322568,
    "output_throughput": 3784.5079481379926,
    "total_throughput": 8051.981520460559,
    "itl": 134.14567602479596,
    "ttft": 1806029.8724544928,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1145,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.8362470540777402,
    "arrivals": 157567,
    "finished_requests": 62159,
    "scheduler_time": 100.27466332183862
}
#Debug simulation 
Total elapsed time: 4.975851955998223. Arrivals time: 0.21371514309430495 Scheduler time: 4.617520699510351 Scheduler overhead time: 0.04021872510202229 Adapter cache time: 0.044566117285285145 Engine time: 0.04124402179149911 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_320_slots_160_rate_0.1-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_320_slots_160_rate_0.1-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 270, 1080, 1080, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 1080, 1080, 540, 270, 270, 540, 1080, 1080, 540, 540, 270, 270, 540, 1080, 1080, 270, 1080, 540, 270, 540, 1080, 270, 540, 1080, 1080, 540, 270, 270, 1080, 270, 270, 1080, 1080, 270, 270, 540, 540, 540, 270, 540, 270, 1080, 270, 1080, 540, 1080, 1080, 270, 1080, 270, 1080, 540, 270, 270, 540, 540, 1080, 540, 1080, 1080, 1080, 270, 540, 540, 270, 1080, 540, 1080, 1080, 540, 270, 540, 540, 540, 270, 1080, 540, 1080, 270, 1080, 270, 270, 540, 1080, 1080, 540, 270, 540, 270, 540, 1080, 1080, 540, 270, 540, 270, 1080, 270, 270, 270, 270, 1080, 540, 540, 1080, 540, 540, 270, 540, 1080, 540, 270, 270, 540, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 540, 1080, 540, 540, 540, 270, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 270, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 270, 270, 1080, 540, 1080, 540, 1080, 540, 270, 540, 270, 270, 270, 1080, 1080, 540, 540, 270, 270, 540, 270, 1080, 270, 270, 540, 270, 1080, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 270, 540, 1080, 540, 540, 1080, 540, 270, 540, 270, 1080, 540, 540, 1080, 1080, 270, 270, 270, 1080, 1080, 270, 270, 1080, 540, 270, 540, 270, 540, 1080, 1080, 1080, 270, 1080, 1080, 1080, 1080, 270, 540, 540, 1080, 270, 1080, 270, 270, 270, 1080, 540, 1080, 1080, 270, 540, 540, 540, 270, 540, 270, 540, 540, 1080, 270, 270, 540, 270, 540, 540, 270, 1080, 1080, 1080, 270, 540, 540, 540, 540, 270, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 540, 540, 540, 270, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 1080, 270, 270, 270]
Prompts retrieved: 201960 . Total input tokens: 44943431 . Total output tokens: 40351513
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 11.595529069018085,
    "estimated_duration": 3600.001699735341,
    "input_throughput": 4092.308067822042,
    "output_throughput": 3579.8683097698104,
    "total_throughput": 7672.1763775918525,
    "itl": 224.69139510663203,
    "ttft": 654716.5778900769,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1558,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.76823990504736,
    "arrivals": 67679,
    "finished_requests": 58853,
    "scheduler_time": 55.26356613208116
}
#Debug simulation 
Total elapsed time: 11.595625518995803. Arrivals time: 0.18184814683627337 Scheduler time: 11.303652092639823 Scheduler overhead time: 0.029173856833949685 Adapter cache time: 0.03943240048829466 Engine time: 0.0289166925358586 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_320_slots_160_rate_0.1-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_320_slots_160_rate_0.1-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 270, 1080, 1080, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 1080, 1080, 540, 270, 270, 540, 1080, 1080, 540, 540, 270, 270, 540, 1080, 1080, 270, 1080, 540, 270, 540, 1080, 270, 540, 1080, 1080, 540, 270, 270, 1080, 270, 270, 1080, 1080, 270, 270, 540, 540, 540, 270, 540, 270, 1080, 270, 1080, 540, 1080, 1080, 270, 1080, 270, 1080, 540, 270, 270, 540, 540, 1080, 540, 1080, 1080, 1080, 270, 540, 540, 270, 1080, 540, 1080, 1080, 540, 270, 540, 540, 540, 270, 1080, 540, 1080, 270, 1080, 270, 270, 540, 1080, 1080, 540, 270, 540, 270, 540, 1080, 1080, 540, 270, 540, 270, 1080, 270, 270, 270, 270, 1080, 540, 540, 1080, 540, 540, 270, 540, 1080, 540, 270, 270, 540, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 540, 1080, 540, 540, 540, 270, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 270, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 270, 270, 1080, 540, 1080, 540, 1080, 540, 270, 540, 270, 270, 270, 1080, 1080, 540, 540, 270, 270, 540, 270, 1080, 270, 270, 540, 270, 1080, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 270, 540, 1080, 540, 540, 1080, 540, 270, 540, 270, 1080, 540, 540, 1080, 1080, 270, 270, 270, 1080, 1080, 270, 270, 1080, 540, 270, 540, 270, 540, 1080, 1080, 1080, 270, 1080, 1080, 1080, 1080, 270, 540, 540, 1080, 270, 1080, 270, 270, 270, 1080, 540, 1080, 1080, 270, 540, 540, 540, 270, 540, 270, 540, 540, 1080, 270, 270, 540, 270, 540, 540, 270, 1080, 1080, 1080, 270, 540, 540, 540, 540, 270, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 540, 540, 540, 270, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 1080, 270, 270, 270]
Prompts retrieved: 201960 . Total input tokens: 44943431 . Total output tokens: 40351513
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 10.47485419397708,
    "estimated_duration": 3600.0927121272657,
    "input_throughput": 4092.457660984585,
    "output_throughput": 3578.8839427934518,
    "total_throughput": 7671.341603778036,
    "itl": 224.82476141506956,
    "ttft": 653415.9213270704,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1808,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.897959696585143,
    "arrivals": 67679,
    "finished_requests": 58848,
    "scheduler_time": 55.1935962013335
}
#Debug simulation 
Total elapsed time: 10.475000531994738. Arrivals time: 0.17864898120751604 Scheduler time: 10.181677156186197 Scheduler overhead time: 0.028913135174661875 Adapter cache time: 0.04408220702316612 Engine time: 0.028972421248909086 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-32/adapters_320_slots_160_rate_0.1-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-32/adapters_320_slots_160_rate_0.1-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 270, 1080, 1080, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 1080, 1080, 540, 270, 270, 540, 1080, 1080, 540, 540, 270, 270, 540, 1080, 1080, 270, 1080, 540, 270, 540, 1080, 270, 540, 1080, 1080, 540, 270, 270, 1080, 270, 270, 1080, 1080, 270, 270, 540, 540, 540, 270, 540, 270, 1080, 270, 1080, 540, 1080, 1080, 270, 1080, 270, 1080, 540, 270, 270, 540, 540, 1080, 540, 1080, 1080, 1080, 270, 540, 540, 270, 1080, 540, 1080, 1080, 540, 270, 540, 540, 540, 270, 1080, 540, 1080, 270, 1080, 270, 270, 540, 1080, 1080, 540, 270, 540, 270, 540, 1080, 1080, 540, 270, 540, 270, 1080, 270, 270, 270, 270, 1080, 540, 540, 1080, 540, 540, 270, 540, 1080, 540, 270, 270, 540, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 540, 1080, 540, 540, 540, 270, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 270, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 270, 270, 1080, 540, 1080, 540, 1080, 540, 270, 540, 270, 270, 270, 1080, 1080, 540, 540, 270, 270, 540, 270, 1080, 270, 270, 540, 270, 1080, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 270, 540, 1080, 540, 540, 1080, 540, 270, 540, 270, 1080, 540, 540, 1080, 1080, 270, 270, 270, 1080, 1080, 270, 270, 1080, 540, 270, 540, 270, 540, 1080, 1080, 1080, 270, 1080, 1080, 1080, 1080, 270, 540, 540, 1080, 270, 1080, 270, 270, 270, 1080, 540, 1080, 1080, 270, 540, 540, 540, 270, 540, 270, 540, 540, 1080, 270, 270, 540, 270, 540, 540, 270, 1080, 1080, 1080, 270, 540, 540, 540, 540, 270, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 540, 540, 540, 270, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 1080, 270, 270, 270]
Prompts retrieved: 201960 . Total input tokens: 44943431 . Total output tokens: 40351513
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.7931257779709995,
    "estimated_duration": 3600.171174617363,
    "input_throughput": 3644.3542164059645,
    "output_throughput": 3208.14773514972,
    "total_throughput": 6852.501951555684,
    "itl": 155.74119799915016,
    "ttft": 1098731.042299578,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3552,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.618286700229431,
    "arrivals": 67679,
    "finished_requests": 52489,
    "scheduler_time": 56.85216751153935
}
#Debug simulation 
Total elapsed time: 5.79328797099879. Arrivals time: 0.17531385243637487 Scheduler time: 5.4363711341284215 Scheduler overhead time: 0.0377863246249035 Adapter cache time: 0.0891494260285981 Engine time: 0.03753855003742501 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_320_slots_160_rate_0.1-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_320_slots_160_rate_0.1-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 270, 1080, 1080, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 1080, 1080, 540, 270, 270, 540, 1080, 1080, 540, 540, 270, 270, 540, 1080, 1080, 270, 1080, 540, 270, 540, 1080, 270, 540, 1080, 1080, 540, 270, 270, 1080, 270, 270, 1080, 1080, 270, 270, 540, 540, 540, 270, 540, 270, 1080, 270, 1080, 540, 1080, 1080, 270, 1080, 270, 1080, 540, 270, 270, 540, 540, 1080, 540, 1080, 1080, 1080, 270, 540, 540, 270, 1080, 540, 1080, 1080, 540, 270, 540, 540, 540, 270, 1080, 540, 1080, 270, 1080, 270, 270, 540, 1080, 1080, 540, 270, 540, 270, 540, 1080, 1080, 540, 270, 540, 270, 1080, 270, 270, 270, 270, 1080, 540, 540, 1080, 540, 540, 270, 540, 1080, 540, 270, 270, 540, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 540, 1080, 540, 540, 540, 270, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 270, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 270, 270, 1080, 540, 1080, 540, 1080, 540, 270, 540, 270, 270, 270, 1080, 1080, 540, 540, 270, 270, 540, 270, 1080, 270, 270, 540, 270, 1080, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 270, 540, 1080, 540, 540, 1080, 540, 270, 540, 270, 1080, 540, 540, 1080, 1080, 270, 270, 270, 1080, 1080, 270, 270, 1080, 540, 270, 540, 270, 540, 1080, 1080, 1080, 270, 1080, 1080, 1080, 1080, 270, 540, 540, 1080, 270, 1080, 270, 270, 270, 1080, 540, 1080, 1080, 270, 540, 540, 540, 270, 540, 270, 540, 540, 1080, 270, 270, 540, 270, 540, 540, 270, 1080, 1080, 1080, 270, 540, 540, 540, 540, 270, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 540, 540, 540, 270, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 1080, 270, 270, 270]
Prompts retrieved: 201960 . Total input tokens: 44943431 . Total output tokens: 40351513
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 11.222227522986941,
    "estimated_duration": 3600.145493014554,
    "input_throughput": 4090.3213574486695,
    "output_throughput": 3578.2053878087318,
    "total_throughput": 7668.526745257401,
    "itl": 224.7958271576068,
    "ttft": 653141.5505659184,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1610,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.032170874839532,
    "arrivals": 67679,
    "finished_requests": 58855,
    "scheduler_time": 55.22612941340833
}
#Debug simulation 
Total elapsed time: 11.22231618501246. Arrivals time: 0.18318038032157347 Scheduler time: 10.927657337742858 Scheduler overhead time: 0.029114061093423516 Adapter cache time: 0.04049929283792153 Engine time: 0.02922396856592968 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-32/adapters_320_slots_160_rate_0.1-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-32/adapters_320_slots_160_rate_0.1-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 270, 1080, 1080, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 1080, 1080, 540, 270, 270, 540, 1080, 1080, 540, 540, 270, 270, 540, 1080, 1080, 270, 1080, 540, 270, 540, 1080, 270, 540, 1080, 1080, 540, 270, 270, 1080, 270, 270, 1080, 1080, 270, 270, 540, 540, 540, 270, 540, 270, 1080, 270, 1080, 540, 1080, 1080, 270, 1080, 270, 1080, 540, 270, 270, 540, 540, 1080, 540, 1080, 1080, 1080, 270, 540, 540, 270, 1080, 540, 1080, 1080, 540, 270, 540, 540, 540, 270, 1080, 540, 1080, 270, 1080, 270, 270, 540, 1080, 1080, 540, 270, 540, 270, 540, 1080, 1080, 540, 270, 540, 270, 1080, 270, 270, 270, 270, 1080, 540, 540, 1080, 540, 540, 270, 540, 1080, 540, 270, 270, 540, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 540, 1080, 540, 540, 540, 270, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 270, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 270, 270, 1080, 540, 1080, 540, 1080, 540, 270, 540, 270, 270, 270, 1080, 1080, 540, 540, 270, 270, 540, 270, 1080, 270, 270, 540, 270, 1080, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 270, 540, 1080, 540, 540, 1080, 540, 270, 540, 270, 1080, 540, 540, 1080, 1080, 270, 270, 270, 1080, 1080, 270, 270, 1080, 540, 270, 540, 270, 540, 1080, 1080, 1080, 270, 1080, 1080, 1080, 1080, 270, 540, 540, 1080, 270, 1080, 270, 270, 270, 1080, 540, 1080, 1080, 270, 540, 540, 540, 270, 540, 270, 540, 540, 1080, 270, 270, 540, 270, 540, 540, 270, 1080, 1080, 1080, 270, 540, 540, 540, 540, 270, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 540, 540, 540, 270, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 1080, 270, 270, 270]
Prompts retrieved: 201960 . Total input tokens: 44943431 . Total output tokens: 40351513
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 5.801428370003123,
    "estimated_duration": 3600.008227973208,
    "input_throughput": 3641.971398321364,
    "output_throughput": 3208.3598893613303,
    "total_throughput": 6850.331287682695,
    "itl": 155.77385980931476,
    "ttft": 1098711.2629776644,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3440,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.398113460912661,
    "arrivals": 67679,
    "finished_requests": 52489,
    "scheduler_time": 56.85754272563788
}
#Debug simulation 
Total elapsed time: 5.801518871972803. Arrivals time: 0.17407956905663013 Scheduler time: 5.4497768022702076 Scheduler overhead time: 0.037634875683579594 Adapter cache time: 0.08535038225818425 Engine time: 0.037676657375413924 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_320_slots_160_rate_0.1-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_320_slots_160_rate_0.1-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 270, 1080, 1080, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 1080, 1080, 540, 270, 270, 540, 1080, 1080, 540, 540, 270, 270, 540, 1080, 1080, 270, 1080, 540, 270, 540, 1080, 270, 540, 1080, 1080, 540, 270, 270, 1080, 270, 270, 1080, 1080, 270, 270, 540, 540, 540, 270, 540, 270, 1080, 270, 1080, 540, 1080, 1080, 270, 1080, 270, 1080, 540, 270, 270, 540, 540, 1080, 540, 1080, 1080, 1080, 270, 540, 540, 270, 1080, 540, 1080, 1080, 540, 270, 540, 540, 540, 270, 1080, 540, 1080, 270, 1080, 270, 270, 540, 1080, 1080, 540, 270, 540, 270, 540, 1080, 1080, 540, 270, 540, 270, 1080, 270, 270, 270, 270, 1080, 540, 540, 1080, 540, 540, 270, 540, 1080, 540, 270, 270, 540, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 540, 1080, 540, 540, 540, 270, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 270, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 270, 270, 1080, 540, 1080, 540, 1080, 540, 270, 540, 270, 270, 270, 1080, 1080, 540, 540, 270, 270, 540, 270, 1080, 270, 270, 540, 270, 1080, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 270, 540, 1080, 540, 540, 1080, 540, 270, 540, 270, 1080, 540, 540, 1080, 1080, 270, 270, 270, 1080, 1080, 270, 270, 1080, 540, 270, 540, 270, 540, 1080, 1080, 1080, 270, 1080, 1080, 1080, 1080, 270, 540, 540, 1080, 270, 1080, 270, 270, 270, 1080, 540, 1080, 1080, 270, 540, 540, 540, 270, 540, 270, 540, 540, 1080, 270, 270, 540, 270, 540, 540, 270, 1080, 1080, 1080, 270, 540, 540, 540, 540, 270, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 540, 540, 540, 270, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 1080, 270, 270, 270]
Prompts retrieved: 201960 . Total input tokens: 44943431 . Total output tokens: 40351513
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 10.798047797987238,
    "estimated_duration": 3600.1168814646817,
    "input_throughput": 4083.1293771827527,
    "output_throughput": 3574.738105381775,
    "total_throughput": 7657.867482564528,
    "itl": 225.4971534054057,
    "ttft": 653674.6030477299,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1738,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.196707412539833,
    "arrivals": 67679,
    "finished_requests": 58766,
    "scheduler_time": 55.14318685501301
}
#Debug simulation 
Total elapsed time: 10.7981720759999. Arrivals time: 0.18412273383000866 Scheduler time: 10.500895836041309 Scheduler overhead time: 0.028784616850316525 Adapter cache time: 0.04301910725189373 Engine time: 0.028707667894195765 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-32/adapters_320_slots_160_rate_0.1-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-32/adapters_320_slots_160_rate_0.1-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 270, 1080, 1080, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 1080, 1080, 540, 270, 270, 540, 1080, 1080, 540, 540, 270, 270, 540, 1080, 1080, 270, 1080, 540, 270, 540, 1080, 270, 540, 1080, 1080, 540, 270, 270, 1080, 270, 270, 1080, 1080, 270, 270, 540, 540, 540, 270, 540, 270, 1080, 270, 1080, 540, 1080, 1080, 270, 1080, 270, 1080, 540, 270, 270, 540, 540, 1080, 540, 1080, 1080, 1080, 270, 540, 540, 270, 1080, 540, 1080, 1080, 540, 270, 540, 540, 540, 270, 1080, 540, 1080, 270, 1080, 270, 270, 540, 1080, 1080, 540, 270, 540, 270, 540, 1080, 1080, 540, 270, 540, 270, 1080, 270, 270, 270, 270, 1080, 540, 540, 1080, 540, 540, 270, 540, 1080, 540, 270, 270, 540, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 540, 1080, 540, 540, 540, 270, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 270, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 270, 270, 1080, 540, 1080, 540, 1080, 540, 270, 540, 270, 270, 270, 1080, 1080, 540, 540, 270, 270, 540, 270, 1080, 270, 270, 540, 270, 1080, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 270, 540, 1080, 540, 540, 1080, 540, 270, 540, 270, 1080, 540, 540, 1080, 1080, 270, 270, 270, 1080, 1080, 270, 270, 1080, 540, 270, 540, 270, 540, 1080, 1080, 1080, 270, 1080, 1080, 1080, 1080, 270, 540, 540, 1080, 270, 1080, 270, 270, 270, 1080, 540, 1080, 1080, 270, 540, 540, 540, 270, 540, 270, 540, 540, 1080, 270, 270, 540, 270, 540, 540, 270, 1080, 1080, 1080, 270, 540, 540, 540, 540, 270, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 540, 540, 540, 270, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 1080, 270, 270, 270]
Prompts retrieved: 201960 . Total input tokens: 44943431 . Total output tokens: 40351513
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.828004426031839,
    "estimated_duration": 3600.1639906198207,
    "input_throughput": 3637.806509404371,
    "output_throughput": 3203.721283266951,
    "total_throughput": 6841.5277926713225,
    "itl": 155.40178819230582,
    "ttft": 1103656.840218815,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3466,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.631796325966029,
    "arrivals": 67679,
    "finished_requests": 52407,
    "scheduler_time": 56.89097142137166
}
#Debug simulation 
Total elapsed time: 5.828095059026964. Arrivals time: 0.17620810691732913 Scheduler time: 5.473638871859293 Scheduler overhead time: 0.03758035763166845 Adapter cache time: 0.08620735578006133 Engine time: 0.037482681043911725 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_320_slots_160_rate_0.1-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_320_slots_160_rate_0.1-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 135, 1080, 1080, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 1080, 1080, 540, 135, 135, 540, 1080, 1080, 540, 540, 135, 135, 540, 1080, 1080, 135, 1080, 540, 135, 540, 1080, 135, 540, 1080, 1080, 540, 135, 135, 1080, 135, 135, 1080, 1080, 135, 135, 540, 540, 540, 135, 540, 135, 1080, 135, 1080, 540, 1080, 1080, 135, 1080, 135, 1080, 540, 135, 135, 540, 540, 1080, 540, 1080, 1080, 1080, 135, 540, 540, 135, 1080, 540, 1080, 1080, 540, 135, 540, 540, 540, 135, 1080, 540, 1080, 135, 1080, 135, 135, 540, 1080, 1080, 540, 135, 540, 135, 540, 1080, 1080, 540, 135, 540, 135, 1080, 135, 135, 135, 135, 1080, 540, 540, 1080, 540, 540, 135, 540, 1080, 540, 135, 135, 540, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 540, 1080, 540, 540, 540, 135, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 135, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 135, 135, 1080, 540, 1080, 540, 1080, 540, 135, 540, 135, 135, 135, 1080, 1080, 540, 540, 135, 135, 540, 135, 1080, 135, 135, 540, 135, 1080, 540, 135, 1080, 135, 135, 1080, 540, 1080, 540, 135, 540, 1080, 540, 540, 1080, 540, 135, 540, 135, 1080, 540, 540, 1080, 1080, 135, 135, 135, 1080, 1080, 135, 135, 1080, 540, 135, 540, 135, 540, 1080, 1080, 1080, 135, 1080, 1080, 1080, 1080, 135, 540, 540, 1080, 135, 1080, 135, 135, 135, 1080, 540, 1080, 1080, 135, 540, 540, 540, 135, 540, 135, 540, 540, 1080, 135, 135, 540, 135, 540, 540, 135, 1080, 1080, 1080, 135, 540, 540, 540, 540, 135, 540, 135, 1080, 135, 135, 1080, 540, 1080, 540, 540, 540, 540, 135, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 187650 . Total input tokens: 41734352 . Total output tokens: 37529193
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 10.097717270022258,
    "estimated_duration": 3600.1597990112373,
    "input_throughput": 4061.836645144527,
    "output_throughput": 3551.055706891442,
    "total_throughput": 7612.892352035969,
    "itl": 219.57827877628108,
    "ttft": 338335.5861730372,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1622,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.964111120659063,
    "arrivals": 62899,
    "finished_requests": 58720,
    "scheduler_time": 51.86674501553583
}
#Debug simulation 
Total elapsed time: 10.097808215010446. Arrivals time: 0.16718845756258816 Scheduler time: 9.819317572633736 Scheduler overhead time: 0.029352840734645724 Adapter cache time: 0.04005097399931401 Engine time: 0.028984886594116688 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_320_slots_160_rate_0.1-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_320_slots_160_rate_0.1-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 135, 1080, 1080, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 1080, 1080, 540, 135, 135, 540, 1080, 1080, 540, 540, 135, 135, 540, 1080, 1080, 135, 1080, 540, 135, 540, 1080, 135, 540, 1080, 1080, 540, 135, 135, 1080, 135, 135, 1080, 1080, 135, 135, 540, 540, 540, 135, 540, 135, 1080, 135, 1080, 540, 1080, 1080, 135, 1080, 135, 1080, 540, 135, 135, 540, 540, 1080, 540, 1080, 1080, 1080, 135, 540, 540, 135, 1080, 540, 1080, 1080, 540, 135, 540, 540, 540, 135, 1080, 540, 1080, 135, 1080, 135, 135, 540, 1080, 1080, 540, 135, 540, 135, 540, 1080, 1080, 540, 135, 540, 135, 1080, 135, 135, 135, 135, 1080, 540, 540, 1080, 540, 540, 135, 540, 1080, 540, 135, 135, 540, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 540, 1080, 540, 540, 540, 135, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 135, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 135, 135, 1080, 540, 1080, 540, 1080, 540, 135, 540, 135, 135, 135, 1080, 1080, 540, 540, 135, 135, 540, 135, 1080, 135, 135, 540, 135, 1080, 540, 135, 1080, 135, 135, 1080, 540, 1080, 540, 135, 540, 1080, 540, 540, 1080, 540, 135, 540, 135, 1080, 540, 540, 1080, 1080, 135, 135, 135, 1080, 1080, 135, 135, 1080, 540, 135, 540, 135, 540, 1080, 1080, 1080, 135, 1080, 1080, 1080, 1080, 135, 540, 540, 1080, 135, 1080, 135, 135, 135, 1080, 540, 1080, 1080, 135, 540, 540, 540, 135, 540, 135, 540, 540, 1080, 135, 135, 540, 135, 540, 540, 135, 1080, 1080, 1080, 135, 540, 540, 540, 540, 135, 540, 135, 1080, 135, 135, 1080, 540, 1080, 540, 540, 540, 540, 135, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 187650 . Total input tokens: 41734352 . Total output tokens: 37529193
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 10.318426388024818,
    "estimated_duration": 3600.26014868289,
    "input_throughput": 4062.660028984564,
    "output_throughput": 3546.041528324148,
    "total_throughput": 7608.701557308712,
    "itl": 219.5187107889444,
    "ttft": 333821.3700313246,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1516,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.941920160830406,
    "arrivals": 62899,
    "finished_requests": 58700,
    "scheduler_time": 51.866646139350806
}
#Debug simulation 
Total elapsed time: 10.318554226018023. Arrivals time: 0.17010407702764496 Scheduler time: 10.038752831809688 Scheduler overhead time: 0.029273287858814 Adapter cache time: 0.03832728893030435 Engine time: 0.029168589506298304 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-32/adapters_320_slots_160_rate_0.1-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-32/adapters_320_slots_160_rate_0.1-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 135, 1080, 1080, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 1080, 1080, 540, 135, 135, 540, 1080, 1080, 540, 540, 135, 135, 540, 1080, 1080, 135, 1080, 540, 135, 540, 1080, 135, 540, 1080, 1080, 540, 135, 135, 1080, 135, 135, 1080, 1080, 135, 135, 540, 540, 540, 135, 540, 135, 1080, 135, 1080, 540, 1080, 1080, 135, 1080, 135, 1080, 540, 135, 135, 540, 540, 1080, 540, 1080, 1080, 1080, 135, 540, 540, 135, 1080, 540, 1080, 1080, 540, 135, 540, 540, 540, 135, 1080, 540, 1080, 135, 1080, 135, 135, 540, 1080, 1080, 540, 135, 540, 135, 540, 1080, 1080, 540, 135, 540, 135, 1080, 135, 135, 135, 135, 1080, 540, 540, 1080, 540, 540, 135, 540, 1080, 540, 135, 135, 540, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 540, 1080, 540, 540, 540, 135, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 135, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 135, 135, 1080, 540, 1080, 540, 1080, 540, 135, 540, 135, 135, 135, 1080, 1080, 540, 540, 135, 135, 540, 135, 1080, 135, 135, 540, 135, 1080, 540, 135, 1080, 135, 135, 1080, 540, 1080, 540, 135, 540, 1080, 540, 540, 1080, 540, 135, 540, 135, 1080, 540, 540, 1080, 1080, 135, 135, 135, 1080, 1080, 135, 135, 1080, 540, 135, 540, 135, 540, 1080, 1080, 1080, 135, 1080, 1080, 1080, 1080, 135, 540, 540, 1080, 135, 1080, 135, 135, 135, 1080, 540, 1080, 1080, 135, 540, 540, 540, 135, 540, 135, 540, 540, 1080, 135, 135, 540, 135, 540, 540, 135, 1080, 1080, 1080, 135, 540, 540, 540, 540, 135, 540, 135, 1080, 135, 135, 1080, 540, 1080, 540, 540, 540, 540, 135, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 187650 . Total input tokens: 41734352 . Total output tokens: 37529193
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.485420524026267,
    "estimated_duration": 3600.0607580370506,
    "input_throughput": 3664.0834381896407,
    "output_throughput": 3210.504982227594,
    "total_throughput": 6874.588420417234,
    "itl": 155.58552091862515,
    "ttft": 786519.6128627434,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3446,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.270042892675244,
    "arrivals": 62899,
    "finished_requests": 52969,
    "scheduler_time": 51.94408564793041
}
#Debug simulation 
Total elapsed time: 5.485538016015198. Arrivals time: 0.1611785483546555 Scheduler time: 5.147519240214024 Scheduler overhead time: 0.03763275843812153 Adapter cache time: 0.0846259873942472 Engine time: 0.03752851014724001 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_320_slots_160_rate_0.1-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_320_slots_160_rate_0.1-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 135, 1080, 1080, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 1080, 1080, 540, 135, 135, 540, 1080, 1080, 540, 540, 135, 135, 540, 1080, 1080, 135, 1080, 540, 135, 540, 1080, 135, 540, 1080, 1080, 540, 135, 135, 1080, 135, 135, 1080, 1080, 135, 135, 540, 540, 540, 135, 540, 135, 1080, 135, 1080, 540, 1080, 1080, 135, 1080, 135, 1080, 540, 135, 135, 540, 540, 1080, 540, 1080, 1080, 1080, 135, 540, 540, 135, 1080, 540, 1080, 1080, 540, 135, 540, 540, 540, 135, 1080, 540, 1080, 135, 1080, 135, 135, 540, 1080, 1080, 540, 135, 540, 135, 540, 1080, 1080, 540, 135, 540, 135, 1080, 135, 135, 135, 135, 1080, 540, 540, 1080, 540, 540, 135, 540, 1080, 540, 135, 135, 540, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 540, 1080, 540, 540, 540, 135, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 135, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 135, 135, 1080, 540, 1080, 540, 1080, 540, 135, 540, 135, 135, 135, 1080, 1080, 540, 540, 135, 135, 540, 135, 1080, 135, 135, 540, 135, 1080, 540, 135, 1080, 135, 135, 1080, 540, 1080, 540, 135, 540, 1080, 540, 540, 1080, 540, 135, 540, 135, 1080, 540, 540, 1080, 1080, 135, 135, 135, 1080, 1080, 135, 135, 1080, 540, 135, 540, 135, 540, 1080, 1080, 1080, 135, 1080, 1080, 1080, 1080, 135, 540, 540, 1080, 135, 1080, 135, 135, 135, 1080, 540, 1080, 1080, 135, 540, 540, 540, 135, 540, 135, 540, 540, 1080, 135, 135, 540, 135, 540, 540, 135, 1080, 1080, 1080, 135, 540, 540, 540, 540, 135, 540, 135, 1080, 135, 135, 1080, 540, 1080, 540, 540, 540, 540, 135, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 187650 . Total input tokens: 41734352 . Total output tokens: 37529193
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 10.445172561972868,
    "estimated_duration": 3600.1802737100643,
    "input_throughput": 4062.169360460689,
    "output_throughput": 3550.3477682321673,
    "total_throughput": 7612.517128692856,
    "itl": 219.42271478777957,
    "ttft": 338930.7217079187,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1514,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.727147852517571,
    "arrivals": 62899,
    "finished_requests": 58745,
    "scheduler_time": 51.88292622398403
}
#Debug simulation 
Total elapsed time: 10.445292858988978. Arrivals time: 0.17191969457780942 Scheduler time: 10.16349795710994 Scheduler overhead time: 0.02930291910888627 Adapter cache time: 0.038503236370161176 Engine time: 0.029033195227384567 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-32/adapters_320_slots_160_rate_0.1-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-32/adapters_320_slots_160_rate_0.1-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 135, 1080, 1080, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 1080, 1080, 540, 135, 135, 540, 1080, 1080, 540, 540, 135, 135, 540, 1080, 1080, 135, 1080, 540, 135, 540, 1080, 135, 540, 1080, 1080, 540, 135, 135, 1080, 135, 135, 1080, 1080, 135, 135, 540, 540, 540, 135, 540, 135, 1080, 135, 1080, 540, 1080, 1080, 135, 1080, 135, 1080, 540, 135, 135, 540, 540, 1080, 540, 1080, 1080, 1080, 135, 540, 540, 135, 1080, 540, 1080, 1080, 540, 135, 540, 540, 540, 135, 1080, 540, 1080, 135, 1080, 135, 135, 540, 1080, 1080, 540, 135, 540, 135, 540, 1080, 1080, 540, 135, 540, 135, 1080, 135, 135, 135, 135, 1080, 540, 540, 1080, 540, 540, 135, 540, 1080, 540, 135, 135, 540, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 540, 1080, 540, 540, 540, 135, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 135, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 135, 135, 1080, 540, 1080, 540, 1080, 540, 135, 540, 135, 135, 135, 1080, 1080, 540, 540, 135, 135, 540, 135, 1080, 135, 135, 540, 135, 1080, 540, 135, 1080, 135, 135, 1080, 540, 1080, 540, 135, 540, 1080, 540, 540, 1080, 540, 135, 540, 135, 1080, 540, 540, 1080, 1080, 135, 135, 135, 1080, 1080, 135, 135, 1080, 540, 135, 540, 135, 540, 1080, 1080, 1080, 135, 1080, 1080, 1080, 1080, 135, 540, 540, 1080, 135, 1080, 135, 135, 135, 1080, 540, 1080, 1080, 135, 540, 540, 540, 135, 540, 135, 540, 540, 1080, 135, 135, 540, 135, 540, 540, 135, 1080, 1080, 1080, 135, 540, 540, 540, 540, 135, 540, 135, 1080, 135, 135, 1080, 540, 1080, 540, 540, 540, 540, 135, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 187650 . Total input tokens: 41734352 . Total output tokens: 37529193
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 5.449017444974743,
    "estimated_duration": 3600.145766786477,
    "input_throughput": 3663.5399937633274,
    "output_throughput": 3210.9047102051973,
    "total_throughput": 6874.444703968525,
    "itl": 155.58106018890268,
    "ttft": 786897.617251583,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3426,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.34219148928236,
    "arrivals": 62899,
    "finished_requests": 52967,
    "scheduler_time": 51.949425924559655
}
#Debug simulation 
Total elapsed time: 5.449158852978144. Arrivals time: 0.1597007134114392 Scheduler time: 5.1134418419678695 Scheduler overhead time: 0.037589542858768255 Adapter cache time: 0.08405539632076398 Engine time: 0.03726472973357886 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_320_slots_160_rate_0.1-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_320_slots_160_rate_0.1-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 135, 1080, 1080, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 1080, 1080, 540, 135, 135, 540, 1080, 1080, 540, 540, 135, 135, 540, 1080, 1080, 135, 1080, 540, 135, 540, 1080, 135, 540, 1080, 1080, 540, 135, 135, 1080, 135, 135, 1080, 1080, 135, 135, 540, 540, 540, 135, 540, 135, 1080, 135, 1080, 540, 1080, 1080, 135, 1080, 135, 1080, 540, 135, 135, 540, 540, 1080, 540, 1080, 1080, 1080, 135, 540, 540, 135, 1080, 540, 1080, 1080, 540, 135, 540, 540, 540, 135, 1080, 540, 1080, 135, 1080, 135, 135, 540, 1080, 1080, 540, 135, 540, 135, 540, 1080, 1080, 540, 135, 540, 135, 1080, 135, 135, 135, 135, 1080, 540, 540, 1080, 540, 540, 135, 540, 1080, 540, 135, 135, 540, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 540, 1080, 540, 540, 540, 135, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 135, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 135, 135, 1080, 540, 1080, 540, 1080, 540, 135, 540, 135, 135, 135, 1080, 1080, 540, 540, 135, 135, 540, 135, 1080, 135, 135, 540, 135, 1080, 540, 135, 1080, 135, 135, 1080, 540, 1080, 540, 135, 540, 1080, 540, 540, 1080, 540, 135, 540, 135, 1080, 540, 540, 1080, 1080, 135, 135, 135, 1080, 1080, 135, 135, 1080, 540, 135, 540, 135, 540, 1080, 1080, 1080, 135, 1080, 1080, 1080, 1080, 135, 540, 540, 1080, 135, 1080, 135, 135, 135, 1080, 540, 1080, 1080, 135, 540, 540, 540, 135, 540, 135, 540, 540, 1080, 135, 135, 540, 135, 540, 540, 135, 1080, 1080, 1080, 135, 540, 540, 540, 540, 135, 540, 135, 1080, 135, 135, 1080, 540, 1080, 540, 540, 540, 540, 135, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 187650 . Total input tokens: 41734352 . Total output tokens: 37529193
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 10.098965320037678,
    "estimated_duration": 3600.223692835168,
    "input_throughput": 4057.533988532865,
    "output_throughput": 3547.210142918387,
    "total_throughput": 7604.7441314512525,
    "itl": 219.5018494785392,
    "ttft": 340282.5679582607,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1623,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.852851628626095,
    "arrivals": 62899,
    "finished_requests": 58697,
    "scheduler_time": 51.863135056244445
}
#Debug simulation 
Total elapsed time: 10.099106051027775. Arrivals time: 0.16993526683654636 Scheduler time: 9.81741640844848 Scheduler overhead time: 0.029301932197995484 Adapter cache time: 0.04040357185294852 Engine time: 0.028983567259274423 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-32/adapters_320_slots_160_rate_0.1-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-32/adapters_320_slots_160_rate_0.1-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 135, 1080, 1080, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 1080, 1080, 540, 135, 135, 540, 1080, 1080, 540, 540, 135, 135, 540, 1080, 1080, 135, 1080, 540, 135, 540, 1080, 135, 540, 1080, 1080, 540, 135, 135, 1080, 135, 135, 1080, 1080, 135, 135, 540, 540, 540, 135, 540, 135, 1080, 135, 1080, 540, 1080, 1080, 135, 1080, 135, 1080, 540, 135, 135, 540, 540, 1080, 540, 1080, 1080, 1080, 135, 540, 540, 135, 1080, 540, 1080, 1080, 540, 135, 540, 540, 540, 135, 1080, 540, 1080, 135, 1080, 135, 135, 540, 1080, 1080, 540, 135, 540, 135, 540, 1080, 1080, 540, 135, 540, 135, 1080, 135, 135, 135, 135, 1080, 540, 540, 1080, 540, 540, 135, 540, 1080, 540, 135, 135, 540, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 540, 1080, 540, 540, 540, 135, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 135, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 135, 135, 1080, 540, 1080, 540, 1080, 540, 135, 540, 135, 135, 135, 1080, 1080, 540, 540, 135, 135, 540, 135, 1080, 135, 135, 540, 135, 1080, 540, 135, 1080, 135, 135, 1080, 540, 1080, 540, 135, 540, 1080, 540, 540, 1080, 540, 135, 540, 135, 1080, 540, 540, 1080, 1080, 135, 135, 135, 1080, 1080, 135, 135, 1080, 540, 135, 540, 135, 540, 1080, 1080, 1080, 135, 1080, 1080, 1080, 1080, 135, 540, 540, 1080, 135, 1080, 135, 135, 135, 1080, 540, 1080, 1080, 135, 540, 540, 540, 135, 540, 135, 540, 540, 1080, 135, 135, 540, 135, 540, 540, 135, 1080, 1080, 1080, 135, 540, 540, 540, 540, 135, 540, 135, 1080, 135, 135, 1080, 540, 1080, 540, 540, 540, 540, 135, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 187650 . Total input tokens: 41734352 . Total output tokens: 37529193
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.48461857100483,
    "estimated_duration": 3600.0055496780506,
    "input_throughput": 3665.3437940338886,
    "output_throughput": 3211.4900492400457,
    "total_throughput": 6876.833843273934,
    "itl": 155.5425966965164,
    "ttft": 785956.1800684811,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3398,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.396130964829851,
    "arrivals": 62899,
    "finished_requests": 52980,
    "scheduler_time": 51.944615820136555
}
#Debug simulation 
Total elapsed time: 5.484718879975844. Arrivals time: 0.15999699686653912 Scheduler time: 5.1486569525441155 Scheduler overhead time: 0.03754933481104672 Adapter cache time: 0.08414960821392015 Engine time: 0.03738783241715282 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_320_slots_160_rate_0.1-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_320_slots_160_rate_0.1-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 66, 1080, 1080, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 1080, 1080, 540, 66, 66, 540, 1080, 1080, 540, 540, 66, 66, 540, 1080, 1080, 66, 1080, 540, 66, 540, 1080, 66, 540, 1080, 1080, 540, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 540, 540, 540, 66, 540, 66, 1080, 66, 1080, 540, 1080, 1080, 66, 1080, 66, 1080, 540, 66, 66, 540, 540, 1080, 540, 1080, 1080, 1080, 66, 540, 540, 66, 1080, 540, 1080, 1080, 540, 66, 540, 540, 540, 66, 1080, 540, 1080, 66, 1080, 66, 66, 540, 1080, 1080, 540, 66, 540, 66, 540, 1080, 1080, 540, 66, 540, 66, 1080, 66, 66, 66, 66, 1080, 540, 540, 1080, 540, 540, 66, 540, 1080, 540, 66, 66, 540, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 540, 1080, 540, 540, 540, 66, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 66, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 66, 66, 1080, 540, 1080, 540, 1080, 540, 66, 540, 66, 66, 66, 1080, 1080, 540, 540, 66, 66, 540, 66, 1080, 66, 66, 540, 66, 1080, 540, 66, 1080, 66, 66, 1080, 540, 1080, 540, 66, 540, 1080, 540, 540, 1080, 540, 66, 540, 66, 1080, 540, 540, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 540, 66, 540, 66, 540, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 540, 540, 1080, 66, 1080, 66, 66, 66, 1080, 540, 1080, 1080, 66, 540, 540, 540, 66, 540, 66, 540, 540, 1080, 66, 66, 540, 66, 540, 540, 66, 1080, 1080, 1080, 66, 540, 540, 540, 540, 66, 540, 66, 1080, 66, 66, 1080, 540, 1080, 540, 540, 540, 540, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 180336 . Total input tokens: 40127028 . Total output tokens: 36039199
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 9.20512230094755,
    "estimated_duration": 3600.0180031920586,
    "input_throughput": 3957.9938176325372,
    "output_throughput": 3510.9557754413518,
    "total_throughput": 7468.9495930738885,
    "itl": 213.38919514055618,
    "ttft": 247487.9741114734,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1534,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.694788199192971,
    "arrivals": 60544,
    "finished_requests": 57474,
    "scheduler_time": 50.46833774206342
}
#Debug simulation 
Total elapsed time: 9.205225471989252. Arrivals time: 0.15809078566962853 Scheduler time: 8.935871139226947 Scheduler overhead time: 0.029866085504181683 Adapter cache time: 0.03872294689062983 Engine time: 0.02945670095505193 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_320_slots_160_rate_0.1-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_320_slots_160_rate_0.1-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 66, 1080, 1080, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 1080, 1080, 540, 66, 66, 540, 1080, 1080, 540, 540, 66, 66, 540, 1080, 1080, 66, 1080, 540, 66, 540, 1080, 66, 540, 1080, 1080, 540, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 540, 540, 540, 66, 540, 66, 1080, 66, 1080, 540, 1080, 1080, 66, 1080, 66, 1080, 540, 66, 66, 540, 540, 1080, 540, 1080, 1080, 1080, 66, 540, 540, 66, 1080, 540, 1080, 1080, 540, 66, 540, 540, 540, 66, 1080, 540, 1080, 66, 1080, 66, 66, 540, 1080, 1080, 540, 66, 540, 66, 540, 1080, 1080, 540, 66, 540, 66, 1080, 66, 66, 66, 66, 1080, 540, 540, 1080, 540, 540, 66, 540, 1080, 540, 66, 66, 540, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 540, 1080, 540, 540, 540, 66, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 66, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 66, 66, 1080, 540, 1080, 540, 1080, 540, 66, 540, 66, 66, 66, 1080, 1080, 540, 540, 66, 66, 540, 66, 1080, 66, 66, 540, 66, 1080, 540, 66, 1080, 66, 66, 1080, 540, 1080, 540, 66, 540, 1080, 540, 540, 1080, 540, 66, 540, 66, 1080, 540, 540, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 540, 66, 540, 66, 540, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 540, 540, 1080, 66, 1080, 66, 66, 66, 1080, 540, 1080, 1080, 66, 540, 540, 540, 66, 540, 66, 540, 540, 1080, 66, 66, 540, 66, 540, 540, 66, 1080, 1080, 1080, 66, 540, 540, 540, 540, 66, 540, 66, 1080, 66, 66, 1080, 540, 1080, 540, 540, 540, 540, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 180336 . Total input tokens: 40127028 . Total output tokens: 36039199
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 9.14871655695606,
    "estimated_duration": 3600.0398268688677,
    "input_throughput": 3958.0312122249825,
    "output_throughput": 3511.007824319941,
    "total_throughput": 7469.039036544923,
    "itl": 212.9905283442631,
    "ttft": 247722.74563304667,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1576,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.140935753809655,
    "arrivals": 60544,
    "finished_requests": 57465,
    "scheduler_time": 50.43246041771416
}
#Debug simulation 
Total elapsed time: 9.148847017961089. Arrivals time: 0.15987047011731192 Scheduler time: 8.876364350842778 Scheduler overhead time: 0.029954364930745214 Adapter cache time: 0.03994132927618921 Engine time: 0.029486583778634667 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-32/adapters_320_slots_160_rate_0.1-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-32/adapters_320_slots_160_rate_0.1-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 66, 1080, 1080, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 1080, 1080, 540, 66, 66, 540, 1080, 1080, 540, 540, 66, 66, 540, 1080, 1080, 66, 1080, 540, 66, 540, 1080, 66, 540, 1080, 1080, 540, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 540, 540, 540, 66, 540, 66, 1080, 66, 1080, 540, 1080, 1080, 66, 1080, 66, 1080, 540, 66, 66, 540, 540, 1080, 540, 1080, 1080, 1080, 66, 540, 540, 66, 1080, 540, 1080, 1080, 540, 66, 540, 540, 540, 66, 1080, 540, 1080, 66, 1080, 66, 66, 540, 1080, 1080, 540, 66, 540, 66, 540, 1080, 1080, 540, 66, 540, 66, 1080, 66, 66, 66, 66, 1080, 540, 540, 1080, 540, 540, 66, 540, 1080, 540, 66, 66, 540, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 540, 1080, 540, 540, 540, 66, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 66, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 66, 66, 1080, 540, 1080, 540, 1080, 540, 66, 540, 66, 66, 66, 1080, 1080, 540, 540, 66, 66, 540, 66, 1080, 66, 66, 540, 66, 1080, 540, 66, 1080, 66, 66, 1080, 540, 1080, 540, 66, 540, 1080, 540, 540, 1080, 540, 66, 540, 66, 1080, 540, 540, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 540, 66, 540, 66, 540, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 540, 540, 1080, 66, 1080, 66, 66, 66, 1080, 540, 1080, 1080, 66, 540, 540, 540, 66, 540, 66, 540, 540, 1080, 66, 66, 540, 66, 540, 540, 66, 1080, 1080, 1080, 66, 540, 540, 540, 540, 66, 540, 66, 1080, 66, 66, 1080, 540, 1080, 540, 540, 540, 540, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 180336 . Total input tokens: 40127028 . Total output tokens: 36039199
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.2183093359926715,
    "estimated_duration": 3600.0010452463416,
    "input_throughput": 3612.7417288319234,
    "output_throughput": 3207.907679707287,
    "total_throughput": 6820.6494085392105,
    "itl": 155.15235927698998,
    "ttft": 666370.0933940248,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3307,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.81293177574821,
    "arrivals": 60544,
    "finished_requests": 52371,
    "scheduler_time": 49.922784284326106
}
#Debug simulation 
Total elapsed time: 5.218401767953765. Arrivals time: 0.1540048433234915 Scheduler time: 4.888950597553048 Scheduler overhead time: 0.0375665292958729 Adapter cache time: 0.08325287379557267 Engine time: 0.03757171955658123 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_320_slots_160_rate_0.1-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_320_slots_160_rate_0.1-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 66, 1080, 1080, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 1080, 1080, 540, 66, 66, 540, 1080, 1080, 540, 540, 66, 66, 540, 1080, 1080, 66, 1080, 540, 66, 540, 1080, 66, 540, 1080, 1080, 540, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 540, 540, 540, 66, 540, 66, 1080, 66, 1080, 540, 1080, 1080, 66, 1080, 66, 1080, 540, 66, 66, 540, 540, 1080, 540, 1080, 1080, 1080, 66, 540, 540, 66, 1080, 540, 1080, 1080, 540, 66, 540, 540, 540, 66, 1080, 540, 1080, 66, 1080, 66, 66, 540, 1080, 1080, 540, 66, 540, 66, 540, 1080, 1080, 540, 66, 540, 66, 1080, 66, 66, 66, 66, 1080, 540, 540, 1080, 540, 540, 66, 540, 1080, 540, 66, 66, 540, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 540, 1080, 540, 540, 540, 66, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 66, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 66, 66, 1080, 540, 1080, 540, 1080, 540, 66, 540, 66, 66, 66, 1080, 1080, 540, 540, 66, 66, 540, 66, 1080, 66, 66, 540, 66, 1080, 540, 66, 1080, 66, 66, 1080, 540, 1080, 540, 66, 540, 1080, 540, 540, 1080, 540, 66, 540, 66, 1080, 540, 540, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 540, 66, 540, 66, 540, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 540, 540, 1080, 66, 1080, 66, 66, 66, 1080, 540, 1080, 1080, 66, 540, 540, 540, 66, 540, 66, 540, 540, 1080, 66, 66, 540, 66, 540, 540, 66, 1080, 1080, 1080, 66, 540, 540, 540, 540, 66, 540, 66, 1080, 66, 66, 1080, 540, 1080, 540, 540, 540, 540, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 180336 . Total input tokens: 40127028 . Total output tokens: 36039199
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 9.281559574999847,
    "estimated_duration": 3600.0146774117106,
    "input_throughput": 3958.2638619254553,
    "output_throughput": 3511.787348903122,
    "total_throughput": 7470.0512108285775,
    "itl": 213.308139451204,
    "ttft": 248889.96266591962,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1563,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.87856346078905,
    "arrivals": 60544,
    "finished_requests": 57468,
    "scheduler_time": 50.451831107918736
}
#Debug simulation 
Total elapsed time: 9.281648945994675. Arrivals time: 0.1672035490628332 Scheduler time: 9.002984928549267 Scheduler overhead time: 0.029766298190224916 Adapter cache time: 0.03915061091538519 Engine time: 0.029405470879282802 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-32/adapters_320_slots_160_rate_0.1-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-32/adapters_320_slots_160_rate_0.1-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 66, 1080, 1080, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 1080, 1080, 540, 66, 66, 540, 1080, 1080, 540, 540, 66, 66, 540, 1080, 1080, 66, 1080, 540, 66, 540, 1080, 66, 540, 1080, 1080, 540, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 540, 540, 540, 66, 540, 66, 1080, 66, 1080, 540, 1080, 1080, 66, 1080, 66, 1080, 540, 66, 66, 540, 540, 1080, 540, 1080, 1080, 1080, 66, 540, 540, 66, 1080, 540, 1080, 1080, 540, 66, 540, 540, 540, 66, 1080, 540, 1080, 66, 1080, 66, 66, 540, 1080, 1080, 540, 66, 540, 66, 540, 1080, 1080, 540, 66, 540, 66, 1080, 66, 66, 66, 66, 1080, 540, 540, 1080, 540, 540, 66, 540, 1080, 540, 66, 66, 540, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 540, 1080, 540, 540, 540, 66, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 66, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 66, 66, 1080, 540, 1080, 540, 1080, 540, 66, 540, 66, 66, 66, 1080, 1080, 540, 540, 66, 66, 540, 66, 1080, 66, 66, 540, 66, 1080, 540, 66, 1080, 66, 66, 1080, 540, 1080, 540, 66, 540, 1080, 540, 540, 1080, 540, 66, 540, 66, 1080, 540, 540, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 540, 66, 540, 66, 540, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 540, 540, 1080, 66, 1080, 66, 66, 66, 1080, 540, 1080, 1080, 66, 540, 540, 540, 66, 540, 66, 540, 540, 1080, 66, 66, 540, 66, 540, 540, 66, 1080, 1080, 1080, 66, 540, 540, 540, 540, 66, 540, 66, 1080, 66, 66, 1080, 540, 1080, 540, 540, 540, 540, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 180336 . Total input tokens: 40127028 . Total output tokens: 36039199
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 5.223800807958469,
    "estimated_duration": 3600.1514227557104,
    "input_throughput": 3612.9291445313193,
    "output_throughput": 3208.7786438598005,
    "total_throughput": 6821.70778839112,
    "itl": 155.1816893736768,
    "ttft": 665497.0369247756,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3314,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.974903456437737,
    "arrivals": 60544,
    "finished_requests": 52389,
    "scheduler_time": 49.923563617120436
}
#Debug simulation 
Total elapsed time: 5.2238937899819575. Arrivals time: 0.15699358546407893 Scheduler time: 4.893939399509691 Scheduler overhead time: 0.03774002875434235 Adapter cache time: 0.08063453971408308 Engine time: 0.03753648395650089 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_320_slots_160_rate_0.1-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_320_slots_160_rate_0.1-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 66, 1080, 1080, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 1080, 1080, 540, 66, 66, 540, 1080, 1080, 540, 540, 66, 66, 540, 1080, 1080, 66, 1080, 540, 66, 540, 1080, 66, 540, 1080, 1080, 540, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 540, 540, 540, 66, 540, 66, 1080, 66, 1080, 540, 1080, 1080, 66, 1080, 66, 1080, 540, 66, 66, 540, 540, 1080, 540, 1080, 1080, 1080, 66, 540, 540, 66, 1080, 540, 1080, 1080, 540, 66, 540, 540, 540, 66, 1080, 540, 1080, 66, 1080, 66, 66, 540, 1080, 1080, 540, 66, 540, 66, 540, 1080, 1080, 540, 66, 540, 66, 1080, 66, 66, 66, 66, 1080, 540, 540, 1080, 540, 540, 66, 540, 1080, 540, 66, 66, 540, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 540, 1080, 540, 540, 540, 66, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 66, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 66, 66, 1080, 540, 1080, 540, 1080, 540, 66, 540, 66, 66, 66, 1080, 1080, 540, 540, 66, 66, 540, 66, 1080, 66, 66, 540, 66, 1080, 540, 66, 1080, 66, 66, 1080, 540, 1080, 540, 66, 540, 1080, 540, 540, 1080, 540, 66, 540, 66, 1080, 540, 540, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 540, 66, 540, 66, 540, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 540, 540, 1080, 66, 1080, 66, 66, 66, 1080, 540, 1080, 1080, 66, 540, 540, 540, 66, 540, 66, 540, 540, 1080, 66, 66, 540, 66, 540, 540, 66, 1080, 1080, 1080, 66, 540, 540, 540, 540, 66, 540, 66, 1080, 66, 66, 1080, 540, 1080, 540, 540, 540, 540, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 180336 . Total input tokens: 40127028 . Total output tokens: 36039199
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 9.14159453503089,
    "estimated_duration": 3600.0644882785714,
    "input_throughput": 3960.491831860963,
    "output_throughput": 3512.503467971632,
    "total_throughput": 7472.995299832595,
    "itl": 213.72673697266515,
    "ttft": 245277.07486265764,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1559,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.661488409752363,
    "arrivals": 60544,
    "finished_requests": 57506,
    "scheduler_time": 50.47634844641118
}
#Debug simulation 
Total elapsed time: 9.141710297029931. Arrivals time: 0.15752425143728033 Scheduler time: 8.872900040878449 Scheduler overhead time: 0.02969155495520681 Adapter cache time: 0.03906492976238951 Engine time: 0.0293061452684924 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-32/adapters_320_slots_160_rate_0.1-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-32/adapters_320_slots_160_rate_0.1-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 66, 1080, 1080, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 1080, 1080, 540, 66, 66, 540, 1080, 1080, 540, 540, 66, 66, 540, 1080, 1080, 66, 1080, 540, 66, 540, 1080, 66, 540, 1080, 1080, 540, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 540, 540, 540, 66, 540, 66, 1080, 66, 1080, 540, 1080, 1080, 66, 1080, 66, 1080, 540, 66, 66, 540, 540, 1080, 540, 1080, 1080, 1080, 66, 540, 540, 66, 1080, 540, 1080, 1080, 540, 66, 540, 540, 540, 66, 1080, 540, 1080, 66, 1080, 66, 66, 540, 1080, 1080, 540, 66, 540, 66, 540, 1080, 1080, 540, 66, 540, 66, 1080, 66, 66, 66, 66, 1080, 540, 540, 1080, 540, 540, 66, 540, 1080, 540, 66, 66, 540, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 540, 1080, 540, 540, 540, 66, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 66, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 66, 66, 1080, 540, 1080, 540, 1080, 540, 66, 540, 66, 66, 66, 1080, 1080, 540, 540, 66, 66, 540, 66, 1080, 66, 66, 540, 66, 1080, 540, 66, 1080, 66, 66, 1080, 540, 1080, 540, 66, 540, 1080, 540, 540, 1080, 540, 66, 540, 66, 1080, 540, 540, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 540, 66, 540, 66, 540, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 540, 540, 1080, 66, 1080, 66, 66, 66, 1080, 540, 1080, 1080, 66, 540, 540, 540, 66, 540, 66, 540, 540, 1080, 66, 66, 540, 66, 540, 540, 66, 1080, 1080, 1080, 66, 540, 540, 540, 540, 66, 540, 66, 1080, 66, 66, 1080, 540, 1080, 540, 540, 540, 540, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 180336 . Total input tokens: 40127028 . Total output tokens: 36039199
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.220647621026728,
    "estimated_duration": 3600.1694328238736,
    "input_throughput": 3613.214945219047,
    "output_throughput": 3208.002905280212,
    "total_throughput": 6821.217850499259,
    "itl": 155.14442547183367,
    "ttft": 666644.2562605657,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3288,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.025229791551197,
    "arrivals": 60544,
    "finished_requests": 52368,
    "scheduler_time": 49.923573999885406
}
#Debug simulation 
Total elapsed time: 5.2208055990049616. Arrivals time: 0.15428708138642833 Scheduler time: 4.8924532979144715 Scheduler overhead time: 0.03759850957430899 Adapter cache time: 0.08167887222953141 Engine time: 0.037731781776528805 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_320_slots_160_rate_0.1-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_320_slots_160_rate_0.1-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 33, 1080, 1080, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 1080, 1080, 540, 33, 33, 540, 1080, 1080, 540, 540, 33, 33, 540, 1080, 1080, 33, 1080, 540, 33, 540, 1080, 33, 540, 1080, 1080, 540, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 540, 540, 540, 33, 540, 33, 1080, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 1080, 540, 33, 33, 540, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 33, 1080, 540, 1080, 1080, 540, 33, 540, 540, 540, 33, 1080, 540, 1080, 33, 1080, 33, 33, 540, 1080, 1080, 540, 33, 540, 33, 540, 1080, 1080, 540, 33, 540, 33, 1080, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 540, 33, 540, 1080, 540, 33, 33, 540, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 540, 1080, 540, 540, 540, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 33, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 33, 33, 1080, 540, 1080, 540, 1080, 540, 33, 540, 33, 33, 33, 1080, 1080, 540, 540, 33, 33, 540, 33, 1080, 33, 33, 540, 33, 1080, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 33, 540, 1080, 540, 540, 1080, 540, 33, 540, 33, 1080, 540, 540, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 540, 33, 540, 33, 540, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 540, 540, 1080, 33, 1080, 33, 33, 33, 1080, 540, 1080, 1080, 33, 540, 540, 540, 33, 540, 33, 540, 540, 1080, 33, 33, 540, 33, 540, 540, 33, 1080, 1080, 1080, 33, 540, 540, 540, 540, 33, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 540, 540, 540, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 176838 . Total input tokens: 39355514 . Total output tokens: 35329103
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 7.542567114986014,
    "estimated_duration": 3600.1338700842766,
    "input_throughput": 3999.8123735501285,
    "output_throughput": 3461.620997918132,
    "total_throughput": 7461.433371468261,
    "itl": 197.44591733128053,
    "ttft": 142424.2508012898,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1648,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.0436838020013175,
    "arrivals": 59315,
    "finished_requests": 57580,
    "scheduler_time": 48.684208881293664
}
#Debug simulation 
Total elapsed time: 7.542661499988753. Arrivals time: 0.1512907593860291 Scheduler time: 7.273836038773879 Scheduler overhead time: 0.031463240389712155 Adapter cache time: 0.04123244632501155 Engine time: 0.030966159887611866 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_320_slots_160_rate_0.1-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_320_slots_160_rate_0.1-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 33, 1080, 1080, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 1080, 1080, 540, 33, 33, 540, 1080, 1080, 540, 540, 33, 33, 540, 1080, 1080, 33, 1080, 540, 33, 540, 1080, 33, 540, 1080, 1080, 540, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 540, 540, 540, 33, 540, 33, 1080, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 1080, 540, 33, 33, 540, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 33, 1080, 540, 1080, 1080, 540, 33, 540, 540, 540, 33, 1080, 540, 1080, 33, 1080, 33, 33, 540, 1080, 1080, 540, 33, 540, 33, 540, 1080, 1080, 540, 33, 540, 33, 1080, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 540, 33, 540, 1080, 540, 33, 33, 540, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 540, 1080, 540, 540, 540, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 33, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 33, 33, 1080, 540, 1080, 540, 1080, 540, 33, 540, 33, 33, 33, 1080, 1080, 540, 540, 33, 33, 540, 33, 1080, 33, 33, 540, 33, 1080, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 33, 540, 1080, 540, 540, 1080, 540, 33, 540, 33, 1080, 540, 540, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 540, 33, 540, 33, 540, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 540, 540, 1080, 33, 1080, 33, 33, 33, 1080, 540, 1080, 1080, 33, 540, 540, 540, 33, 540, 33, 540, 540, 1080, 33, 33, 540, 33, 540, 540, 33, 1080, 1080, 1080, 33, 540, 540, 540, 540, 33, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 540, 540, 540, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 176838 . Total input tokens: 39355514 . Total output tokens: 35329103
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 7.548131381976418,
    "estimated_duration": 3600.209507198734,
    "input_throughput": 4001.143258801143,
    "output_throughput": 3463.7878643076497,
    "total_throughput": 7464.931123108793,
    "itl": 197.75441080364365,
    "ttft": 141536.0705872796,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1640,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.350277166694751,
    "arrivals": 59315,
    "finished_requests": 57594,
    "scheduler_time": 48.693582448407874
}
#Debug simulation 
Total elapsed time: 7.5482554659829475. Arrivals time: 0.1505806894856505 Scheduler time: 7.280720431823283 Scheduler overhead time: 0.031148069771006703 Adapter cache time: 0.041018199059180915 Engine time: 0.03089158737566322 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-32/adapters_320_slots_160_rate_0.1-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-32/adapters_320_slots_160_rate_0.1-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 33, 1080, 1080, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 1080, 1080, 540, 33, 33, 540, 1080, 1080, 540, 540, 33, 33, 540, 1080, 1080, 33, 1080, 540, 33, 540, 1080, 33, 540, 1080, 1080, 540, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 540, 540, 540, 33, 540, 33, 1080, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 1080, 540, 33, 33, 540, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 33, 1080, 540, 1080, 1080, 540, 33, 540, 540, 540, 33, 1080, 540, 1080, 33, 1080, 33, 33, 540, 1080, 1080, 540, 33, 540, 33, 540, 1080, 1080, 540, 33, 540, 33, 1080, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 540, 33, 540, 1080, 540, 33, 33, 540, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 540, 1080, 540, 540, 540, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 33, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 33, 33, 1080, 540, 1080, 540, 1080, 540, 33, 540, 33, 33, 33, 1080, 1080, 540, 540, 33, 33, 540, 33, 1080, 33, 33, 540, 33, 1080, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 33, 540, 1080, 540, 540, 1080, 540, 33, 540, 33, 1080, 540, 540, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 540, 33, 540, 33, 540, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 540, 540, 1080, 33, 1080, 33, 33, 33, 1080, 540, 1080, 1080, 33, 540, 540, 540, 33, 540, 33, 540, 540, 1080, 33, 33, 540, 33, 540, 540, 33, 1080, 1080, 1080, 33, 540, 540, 540, 540, 33, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 540, 540, 540, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 176838 . Total input tokens: 39355514 . Total output tokens: 35329103
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.969260721001774,
    "estimated_duration": 3600.100850053609,
    "input_throughput": 3704.514277649029,
    "output_throughput": 3215.761858401163,
    "total_throughput": 6920.276136050192,
    "itl": 155.08091385937811,
    "ttft": 499501.73042125953,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3029,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.902756511829429,
    "arrivals": 59315,
    "finished_requests": 53348,
    "scheduler_time": 48.04445538232419
}
#Debug simulation 
Total elapsed time: 4.969347422011197. Arrivals time: 0.15038580150576308 Scheduler time: 4.65089332126081 Scheduler overhead time: 0.03777474194066599 Adapter cache time: 0.07580245425924659 Engine time: 0.03740213124547154 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_320_slots_160_rate_0.1-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_320_slots_160_rate_0.1-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 33, 1080, 1080, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 1080, 1080, 540, 33, 33, 540, 1080, 1080, 540, 540, 33, 33, 540, 1080, 1080, 33, 1080, 540, 33, 540, 1080, 33, 540, 1080, 1080, 540, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 540, 540, 540, 33, 540, 33, 1080, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 1080, 540, 33, 33, 540, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 33, 1080, 540, 1080, 1080, 540, 33, 540, 540, 540, 33, 1080, 540, 1080, 33, 1080, 33, 33, 540, 1080, 1080, 540, 33, 540, 33, 540, 1080, 1080, 540, 33, 540, 33, 1080, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 540, 33, 540, 1080, 540, 33, 33, 540, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 540, 1080, 540, 540, 540, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 33, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 33, 33, 1080, 540, 1080, 540, 1080, 540, 33, 540, 33, 33, 33, 1080, 1080, 540, 540, 33, 33, 540, 33, 1080, 33, 33, 540, 33, 1080, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 33, 540, 1080, 540, 540, 1080, 540, 33, 540, 33, 1080, 540, 540, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 540, 33, 540, 33, 540, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 540, 540, 1080, 33, 1080, 33, 33, 33, 1080, 540, 1080, 1080, 33, 540, 540, 540, 33, 540, 33, 540, 540, 1080, 33, 33, 540, 33, 540, 540, 33, 1080, 1080, 1080, 33, 540, 540, 540, 540, 33, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 540, 540, 540, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 176838 . Total input tokens: 39355514 . Total output tokens: 35329103
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 7.532613103976473,
    "estimated_duration": 3600.2277523769617,
    "input_throughput": 3999.705571541371,
    "output_throughput": 3463.1047971252187,
    "total_throughput": 7462.810368666589,
    "itl": 197.35400032829327,
    "ttft": 142323.90062903022,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1647,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.139533973203386,
    "arrivals": 59315,
    "finished_requests": 57579,
    "scheduler_time": 48.66993072695063
}
#Debug simulation 
Total elapsed time: 7.532700714014936. Arrivals time: 0.14743570645805448 Scheduler time: 7.268178030499257 Scheduler overhead time: 0.031373885401990265 Adapter cache time: 0.04079221514984965 Engine time: 0.030975442088674754 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-32/adapters_320_slots_160_rate_0.1-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-32/adapters_320_slots_160_rate_0.1-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 33, 1080, 1080, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 1080, 1080, 540, 33, 33, 540, 1080, 1080, 540, 540, 33, 33, 540, 1080, 1080, 33, 1080, 540, 33, 540, 1080, 33, 540, 1080, 1080, 540, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 540, 540, 540, 33, 540, 33, 1080, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 1080, 540, 33, 33, 540, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 33, 1080, 540, 1080, 1080, 540, 33, 540, 540, 540, 33, 1080, 540, 1080, 33, 1080, 33, 33, 540, 1080, 1080, 540, 33, 540, 33, 540, 1080, 1080, 540, 33, 540, 33, 1080, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 540, 33, 540, 1080, 540, 33, 33, 540, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 540, 1080, 540, 540, 540, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 33, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 33, 33, 1080, 540, 1080, 540, 1080, 540, 33, 540, 33, 33, 33, 1080, 1080, 540, 540, 33, 33, 540, 33, 1080, 33, 33, 540, 33, 1080, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 33, 540, 1080, 540, 540, 1080, 540, 33, 540, 33, 1080, 540, 540, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 540, 33, 540, 33, 540, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 540, 540, 1080, 33, 1080, 33, 33, 33, 1080, 540, 1080, 1080, 33, 540, 540, 540, 33, 540, 33, 540, 540, 1080, 33, 33, 540, 33, 540, 540, 33, 1080, 1080, 1080, 33, 540, 540, 540, 540, 33, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 540, 540, 540, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 176838 . Total input tokens: 39355514 . Total output tokens: 35329103
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.96147922804812,
    "estimated_duration": 3600.013765192142,
    "input_throughput": 3705.562497838951,
    "output_throughput": 3216.375201660375,
    "total_throughput": 6921.937699499325,
    "itl": 155.0714148722538,
    "ttft": 498743.21365127433,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3052,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.106828118245568,
    "arrivals": 59315,
    "finished_requests": 53356,
    "scheduler_time": 48.04211535427006
}
#Debug simulation 
Total elapsed time: 4.961570280021988. Arrivals time: 0.15048646740615368 Scheduler time: 4.641388978576288 Scheduler overhead time: 0.03745617077220231 Adapter cache time: 0.07794329943135381 Engine time: 0.03736210096394643 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_320_slots_160_rate_0.1-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_320_slots_160_rate_0.1-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 33, 1080, 1080, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 1080, 1080, 540, 33, 33, 540, 1080, 1080, 540, 540, 33, 33, 540, 1080, 1080, 33, 1080, 540, 33, 540, 1080, 33, 540, 1080, 1080, 540, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 540, 540, 540, 33, 540, 33, 1080, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 1080, 540, 33, 33, 540, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 33, 1080, 540, 1080, 1080, 540, 33, 540, 540, 540, 33, 1080, 540, 1080, 33, 1080, 33, 33, 540, 1080, 1080, 540, 33, 540, 33, 540, 1080, 1080, 540, 33, 540, 33, 1080, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 540, 33, 540, 1080, 540, 33, 33, 540, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 540, 1080, 540, 540, 540, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 33, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 33, 33, 1080, 540, 1080, 540, 1080, 540, 33, 540, 33, 33, 33, 1080, 1080, 540, 540, 33, 33, 540, 33, 1080, 33, 33, 540, 33, 1080, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 33, 540, 1080, 540, 540, 1080, 540, 33, 540, 33, 1080, 540, 540, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 540, 33, 540, 33, 540, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 540, 540, 1080, 33, 1080, 33, 33, 33, 1080, 540, 1080, 1080, 33, 540, 540, 540, 33, 540, 33, 540, 540, 1080, 33, 33, 540, 33, 540, 540, 33, 1080, 1080, 1080, 33, 540, 540, 540, 540, 33, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 540, 540, 540, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 176838 . Total input tokens: 39355514 . Total output tokens: 35329103
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 7.469525597000029,
    "estimated_duration": 3600.1004617122217,
    "input_throughput": 4001.3277832665926,
    "output_throughput": 3463.8833367636257,
    "total_throughput": 7465.211120030218,
    "itl": 197.63454998436868,
    "ttft": 140487.1864576762,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1669,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.990393942191591,
    "arrivals": 59315,
    "finished_requests": 57599,
    "scheduler_time": 48.67804173140338
}
#Debug simulation 
Total elapsed time: 7.46964168298291. Arrivals time: 0.14850666129495949 Scheduler time: 7.203587465104647 Scheduler overhead time: 0.03133064095163718 Adapter cache time: 0.04139669920550659 Engine time: 0.030904896731954068 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-32/adapters_320_slots_160_rate_0.1-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-32/adapters_320_slots_160_rate_0.1-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 33, 1080, 1080, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 1080, 1080, 540, 33, 33, 540, 1080, 1080, 540, 540, 33, 33, 540, 1080, 1080, 33, 1080, 540, 33, 540, 1080, 33, 540, 1080, 1080, 540, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 540, 540, 540, 33, 540, 33, 1080, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 1080, 540, 33, 33, 540, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 33, 1080, 540, 1080, 1080, 540, 33, 540, 540, 540, 33, 1080, 540, 1080, 33, 1080, 33, 33, 540, 1080, 1080, 540, 33, 540, 33, 540, 1080, 1080, 540, 33, 540, 33, 1080, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 540, 33, 540, 1080, 540, 33, 33, 540, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 540, 1080, 540, 540, 540, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 33, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 33, 33, 1080, 540, 1080, 540, 1080, 540, 33, 540, 33, 33, 33, 1080, 1080, 540, 540, 33, 33, 540, 33, 1080, 33, 33, 540, 33, 1080, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 33, 540, 1080, 540, 540, 1080, 540, 33, 540, 33, 1080, 540, 540, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 540, 33, 540, 33, 540, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 540, 540, 1080, 33, 1080, 33, 33, 33, 1080, 540, 1080, 1080, 33, 540, 540, 540, 33, 540, 33, 540, 540, 1080, 33, 33, 540, 33, 540, 540, 33, 1080, 1080, 1080, 33, 540, 540, 540, 540, 33, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 540, 540, 540, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 176838 . Total input tokens: 39355514 . Total output tokens: 35329103
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.9496433219756,
    "estimated_duration": 3600.152730174517,
    "input_throughput": 3704.9311514496294,
    "output_throughput": 3216.1893863427067,
    "total_throughput": 6921.120537792336,
    "itl": 155.09062537807966,
    "ttft": 498981.2373403904,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3061,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.269993834830267,
    "arrivals": 59315,
    "finished_requests": 53359,
    "scheduler_time": 48.045544662775534
}
#Debug simulation 
Total elapsed time: 4.949758180009667. Arrivals time: 0.14748119382420555 Scheduler time: 4.633127455424983 Scheduler overhead time: 0.037809415080118924 Adapter cache time: 0.07691813766723499 Engine time: 0.037420381617266685 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_320_slots_160_rate_0.1-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_320_slots_160_rate_0.1-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 135, 1080, 1080, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 1080, 1080, 270, 135, 135, 270, 1080, 1080, 270, 270, 135, 135, 270, 1080, 1080, 135, 1080, 270, 135, 270, 1080, 135, 270, 1080, 1080, 270, 135, 135, 1080, 135, 135, 1080, 1080, 135, 135, 270, 270, 270, 135, 270, 135, 1080, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 1080, 270, 135, 135, 270, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 135, 1080, 270, 1080, 1080, 270, 135, 270, 270, 270, 135, 1080, 270, 1080, 135, 1080, 135, 135, 270, 1080, 1080, 270, 135, 270, 135, 270, 1080, 1080, 270, 135, 270, 135, 1080, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 270, 135, 270, 1080, 270, 135, 135, 270, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 270, 1080, 270, 270, 270, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 135, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 135, 135, 1080, 270, 1080, 270, 1080, 270, 135, 270, 135, 135, 135, 1080, 1080, 270, 270, 135, 135, 270, 135, 1080, 135, 135, 270, 135, 1080, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 135, 270, 1080, 270, 270, 1080, 270, 135, 270, 135, 1080, 270, 270, 1080, 1080, 135, 135, 135, 1080, 1080, 135, 135, 1080, 270, 135, 270, 135, 270, 1080, 1080, 1080, 135, 1080, 1080, 1080, 1080, 135, 270, 270, 1080, 135, 1080, 135, 135, 135, 1080, 270, 1080, 1080, 135, 270, 270, 270, 135, 270, 135, 270, 270, 1080, 135, 135, 270, 135, 270, 270, 135, 1080, 1080, 1080, 135, 270, 270, 270, 270, 135, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 270, 270, 270, 135, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 158760 . Total input tokens: 35347864 . Total output tokens: 31749041
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.77812279300997,
    "estimated_duration": 3600.1567913982744,
    "input_throughput": 3617.393562168133,
    "output_throughput": 3162.1975540621884,
    "total_throughput": 6779.591116230322,
    "itl": 149.0129787751887,
    "ttft": 78984.62469593716,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4059,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.42251975262216,
    "arrivals": 53129,
    "finished_requests": 52234,
    "scheduler_time": 42.59959867418339
}
#Debug simulation 
Total elapsed time: 5.778212667966727. Arrivals time: 0.13518109620781615 Scheduler time: 5.4597709782538 Scheduler overhead time: 0.039370780577883124 Adapter cache time: 0.0882880114368163 Engine time: 0.03823981567984447 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_320_slots_160_rate_0.1-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_320_slots_160_rate_0.1-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 135, 1080, 1080, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 1080, 1080, 270, 135, 135, 270, 1080, 1080, 270, 270, 135, 135, 270, 1080, 1080, 135, 1080, 270, 135, 270, 1080, 135, 270, 1080, 1080, 270, 135, 135, 1080, 135, 135, 1080, 1080, 135, 135, 270, 270, 270, 135, 270, 135, 1080, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 1080, 270, 135, 135, 270, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 135, 1080, 270, 1080, 1080, 270, 135, 270, 270, 270, 135, 1080, 270, 1080, 135, 1080, 135, 135, 270, 1080, 1080, 270, 135, 270, 135, 270, 1080, 1080, 270, 135, 270, 135, 1080, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 270, 135, 270, 1080, 270, 135, 135, 270, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 270, 1080, 270, 270, 270, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 135, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 135, 135, 1080, 270, 1080, 270, 1080, 270, 135, 270, 135, 135, 135, 1080, 1080, 270, 270, 135, 135, 270, 135, 1080, 135, 135, 270, 135, 1080, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 135, 270, 1080, 270, 270, 1080, 270, 135, 270, 135, 1080, 270, 270, 1080, 1080, 135, 135, 135, 1080, 1080, 135, 135, 1080, 270, 135, 270, 135, 270, 1080, 1080, 1080, 135, 1080, 1080, 1080, 1080, 135, 270, 270, 1080, 135, 1080, 135, 135, 135, 1080, 270, 1080, 1080, 135, 270, 270, 270, 135, 270, 135, 270, 270, 1080, 135, 135, 270, 135, 270, 270, 135, 1080, 1080, 1080, 135, 270, 270, 270, 270, 135, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 270, 270, 270, 135, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 158760 . Total input tokens: 35347864 . Total output tokens: 31749041
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.8250274489982985,
    "estimated_duration": 3600.0168575776283,
    "input_throughput": 3617.336672351733,
    "output_throughput": 3161.7563056798986,
    "total_throughput": 6779.092978031631,
    "itl": 149.07996772799504,
    "ttft": 78938.42496915344,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4049,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.229533579133577,
    "arrivals": 53129,
    "finished_requests": 52233,
    "scheduler_time": 42.599580630460224
}
#Debug simulation 
Total elapsed time: 5.825169526971877. Arrivals time: 0.13886495877522975 Scheduler time: 5.5020390909630805 Scheduler overhead time: 0.038838070700876415 Adapter cache time: 0.08981572347693145 Engine time: 0.038322678476106375 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-32/adapters_320_slots_160_rate_0.1-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-32/adapters_320_slots_160_rate_0.1-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 135, 1080, 1080, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 1080, 1080, 270, 135, 135, 270, 1080, 1080, 270, 270, 135, 135, 270, 1080, 1080, 135, 1080, 270, 135, 270, 1080, 135, 270, 1080, 1080, 270, 135, 135, 1080, 135, 135, 1080, 1080, 135, 135, 270, 270, 270, 135, 270, 135, 1080, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 1080, 270, 135, 135, 270, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 135, 1080, 270, 1080, 1080, 270, 135, 270, 270, 270, 135, 1080, 270, 1080, 135, 1080, 135, 135, 270, 1080, 1080, 270, 135, 270, 135, 270, 1080, 1080, 270, 135, 270, 135, 1080, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 270, 135, 270, 1080, 270, 135, 135, 270, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 270, 1080, 270, 270, 270, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 135, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 135, 135, 1080, 270, 1080, 270, 1080, 270, 135, 270, 135, 135, 135, 1080, 1080, 270, 270, 135, 135, 270, 135, 1080, 135, 135, 270, 135, 1080, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 135, 270, 1080, 270, 270, 1080, 270, 135, 270, 135, 1080, 270, 270, 1080, 1080, 135, 135, 135, 1080, 1080, 135, 135, 1080, 270, 135, 270, 135, 270, 1080, 1080, 1080, 135, 1080, 1080, 1080, 1080, 135, 270, 270, 1080, 135, 1080, 135, 135, 135, 1080, 270, 1080, 1080, 135, 270, 270, 270, 135, 270, 135, 270, 270, 1080, 135, 135, 270, 135, 270, 270, 135, 1080, 1080, 1080, 135, 270, 270, 270, 270, 135, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 270, 270, 270, 135, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 158760 . Total input tokens: 35347864 . Total output tokens: 31749041
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.47603761398932,
    "estimated_duration": 3600.141129125876,
    "input_throughput": 3614.5138574496755,
    "output_throughput": 3158.9831042988426,
    "total_throughput": 6773.496961748518,
    "itl": 148.79268916302595,
    "ttft": 82856.63443441105,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4087,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.372025352287064,
    "arrivals": 53129,
    "finished_requests": 52202,
    "scheduler_time": 42.62288398836281
}
#Debug simulation 
Total elapsed time: 5.476154771982692. Arrivals time: 0.1365844596293755 Scheduler time: 5.151359585986938 Scheduler overhead time: 0.03921502246521413 Adapter cache time: 0.0929228127351962 Engine time: 0.03850001993123442 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_320_slots_160_rate_0.1-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_320_slots_160_rate_0.1-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 135, 1080, 1080, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 1080, 1080, 270, 135, 135, 270, 1080, 1080, 270, 270, 135, 135, 270, 1080, 1080, 135, 1080, 270, 135, 270, 1080, 135, 270, 1080, 1080, 270, 135, 135, 1080, 135, 135, 1080, 1080, 135, 135, 270, 270, 270, 135, 270, 135, 1080, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 1080, 270, 135, 135, 270, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 135, 1080, 270, 1080, 1080, 270, 135, 270, 270, 270, 135, 1080, 270, 1080, 135, 1080, 135, 135, 270, 1080, 1080, 270, 135, 270, 135, 270, 1080, 1080, 270, 135, 270, 135, 1080, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 270, 135, 270, 1080, 270, 135, 135, 270, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 270, 1080, 270, 270, 270, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 135, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 135, 135, 1080, 270, 1080, 270, 1080, 270, 135, 270, 135, 135, 135, 1080, 1080, 270, 270, 135, 135, 270, 135, 1080, 135, 135, 270, 135, 1080, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 135, 270, 1080, 270, 270, 1080, 270, 135, 270, 135, 1080, 270, 270, 1080, 1080, 135, 135, 135, 1080, 1080, 135, 135, 1080, 270, 135, 270, 135, 270, 1080, 1080, 1080, 135, 1080, 1080, 1080, 1080, 135, 270, 270, 1080, 135, 1080, 135, 135, 135, 1080, 270, 1080, 1080, 135, 270, 270, 270, 135, 270, 135, 270, 270, 1080, 135, 135, 270, 135, 270, 270, 135, 1080, 1080, 1080, 135, 270, 270, 270, 270, 135, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 270, 270, 270, 135, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 158760 . Total input tokens: 35347864 . Total output tokens: 31749041
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 5.828677034005523,
    "estimated_duration": 3600.089323872804,
    "input_throughput": 3617.214415666564,
    "output_throughput": 3161.5829431020366,
    "total_throughput": 6778.7973587686,
    "itl": 148.9841563552542,
    "ttft": 79448.89306792566,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4027,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.595396384695322,
    "arrivals": 53129,
    "finished_requests": 52230,
    "scheduler_time": 42.602063102094114
}
#Debug simulation 
Total elapsed time: 5.828790737024974. Arrivals time: 0.13618116808356717 Scheduler time: 5.50893982645357 Scheduler overhead time: 0.03914197895210236 Adapter cache time: 0.0886697947862558 Engine time: 0.03851616755127907 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-32/adapters_320_slots_160_rate_0.1-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-32/adapters_320_slots_160_rate_0.1-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 135, 1080, 1080, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 1080, 1080, 270, 135, 135, 270, 1080, 1080, 270, 270, 135, 135, 270, 1080, 1080, 135, 1080, 270, 135, 270, 1080, 135, 270, 1080, 1080, 270, 135, 135, 1080, 135, 135, 1080, 1080, 135, 135, 270, 270, 270, 135, 270, 135, 1080, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 1080, 270, 135, 135, 270, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 135, 1080, 270, 1080, 1080, 270, 135, 270, 270, 270, 135, 1080, 270, 1080, 135, 1080, 135, 135, 270, 1080, 1080, 270, 135, 270, 135, 270, 1080, 1080, 270, 135, 270, 135, 1080, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 270, 135, 270, 1080, 270, 135, 135, 270, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 270, 1080, 270, 270, 270, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 135, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 135, 135, 1080, 270, 1080, 270, 1080, 270, 135, 270, 135, 135, 135, 1080, 1080, 270, 270, 135, 135, 270, 135, 1080, 135, 135, 270, 135, 1080, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 135, 270, 1080, 270, 270, 1080, 270, 135, 270, 135, 1080, 270, 270, 1080, 1080, 135, 135, 135, 1080, 1080, 135, 135, 1080, 270, 135, 270, 135, 270, 1080, 1080, 1080, 135, 1080, 1080, 1080, 1080, 135, 270, 270, 1080, 135, 1080, 135, 135, 135, 1080, 270, 1080, 1080, 135, 270, 270, 270, 135, 270, 135, 270, 270, 1080, 135, 135, 270, 135, 270, 270, 135, 1080, 1080, 1080, 135, 270, 270, 270, 270, 135, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 270, 270, 270, 135, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 158760 . Total input tokens: 35347864 . Total output tokens: 31749041
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 5.472389043017756,
    "estimated_duration": 3600.021044550869,
    "input_throughput": 3614.3985935013716,
    "output_throughput": 3158.9984778599546,
    "total_throughput": 6773.397071361326,
    "itl": 148.84324270644981,
    "ttft": 82909.16958397637,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4091,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.558579915574757,
    "arrivals": 53129,
    "finished_requests": 52197,
    "scheduler_time": 42.62311472965893
}
#Debug simulation 
Total elapsed time: 5.4724738909862936. Arrivals time: 0.1351063911570236 Scheduler time: 5.149784568173345 Scheduler overhead time: 0.03907153778709471 Adapter cache time: 0.09242703532800078 Engine time: 0.03855123772518709 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_320_slots_160_rate_0.1-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_320_slots_160_rate_0.1-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 135, 1080, 1080, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 1080, 1080, 270, 135, 135, 270, 1080, 1080, 270, 270, 135, 135, 270, 1080, 1080, 135, 1080, 270, 135, 270, 1080, 135, 270, 1080, 1080, 270, 135, 135, 1080, 135, 135, 1080, 1080, 135, 135, 270, 270, 270, 135, 270, 135, 1080, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 1080, 270, 135, 135, 270, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 135, 1080, 270, 1080, 1080, 270, 135, 270, 270, 270, 135, 1080, 270, 1080, 135, 1080, 135, 135, 270, 1080, 1080, 270, 135, 270, 135, 270, 1080, 1080, 270, 135, 270, 135, 1080, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 270, 135, 270, 1080, 270, 135, 135, 270, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 270, 1080, 270, 270, 270, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 135, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 135, 135, 1080, 270, 1080, 270, 1080, 270, 135, 270, 135, 135, 135, 1080, 1080, 270, 270, 135, 135, 270, 135, 1080, 135, 135, 270, 135, 1080, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 135, 270, 1080, 270, 270, 1080, 270, 135, 270, 135, 1080, 270, 270, 1080, 1080, 135, 135, 135, 1080, 1080, 135, 135, 1080, 270, 135, 270, 135, 270, 1080, 1080, 1080, 135, 1080, 1080, 1080, 1080, 135, 270, 270, 1080, 135, 1080, 135, 135, 135, 1080, 270, 1080, 1080, 135, 270, 270, 270, 135, 270, 135, 270, 270, 1080, 135, 135, 270, 135, 270, 270, 135, 1080, 1080, 1080, 135, 270, 270, 270, 270, 135, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 270, 270, 270, 135, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 158760 . Total input tokens: 35347864 . Total output tokens: 31749041
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.838213998998981,
    "estimated_duration": 3600.0751967939354,
    "input_throughput": 3616.8483401668523,
    "output_throughput": 3161.951175391397,
    "total_throughput": 6778.799515558249,
    "itl": 148.9576090496855,
    "ttft": 79322.17229890874,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4061,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.14259424759857,
    "arrivals": 53129,
    "finished_requests": 52227,
    "scheduler_time": 42.59864132438825
}
#Debug simulation 
Total elapsed time: 5.838299285969697. Arrivals time: 0.13843300438020378 Scheduler time: 5.514791554829571 Scheduler overhead time: 0.039617861388251185 Adapter cache time: 0.08929675479885191 Engine time: 0.03872109483927488 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-32/adapters_320_slots_160_rate_0.1-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-32/adapters_320_slots_160_rate_0.1-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 135, 1080, 1080, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 1080, 1080, 270, 135, 135, 270, 1080, 1080, 270, 270, 135, 135, 270, 1080, 1080, 135, 1080, 270, 135, 270, 1080, 135, 270, 1080, 1080, 270, 135, 135, 1080, 135, 135, 1080, 1080, 135, 135, 270, 270, 270, 135, 270, 135, 1080, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 1080, 270, 135, 135, 270, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 135, 1080, 270, 1080, 1080, 270, 135, 270, 270, 270, 135, 1080, 270, 1080, 135, 1080, 135, 135, 270, 1080, 1080, 270, 135, 270, 135, 270, 1080, 1080, 270, 135, 270, 135, 1080, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 270, 135, 270, 1080, 270, 135, 135, 270, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 270, 1080, 270, 270, 270, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 135, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 135, 135, 1080, 270, 1080, 270, 1080, 270, 135, 270, 135, 135, 135, 1080, 1080, 270, 270, 135, 135, 270, 135, 1080, 135, 135, 270, 135, 1080, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 135, 270, 1080, 270, 270, 1080, 270, 135, 270, 135, 1080, 270, 270, 1080, 1080, 135, 135, 135, 1080, 1080, 135, 135, 1080, 270, 135, 270, 135, 270, 1080, 1080, 1080, 135, 1080, 1080, 1080, 1080, 135, 270, 270, 1080, 135, 1080, 135, 135, 135, 1080, 270, 1080, 1080, 135, 270, 270, 270, 135, 270, 135, 270, 270, 1080, 135, 135, 270, 135, 270, 270, 135, 1080, 1080, 1080, 135, 270, 270, 270, 270, 135, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 270, 270, 270, 135, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 158760 . Total input tokens: 35347864 . Total output tokens: 31749041
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.468538104032632,
    "estimated_duration": 3600.1248871089247,
    "input_throughput": 3614.358503671072,
    "output_throughput": 3158.740976103237,
    "total_throughput": 6773.099479774309,
    "itl": 148.85580660610367,
    "ttft": 82955.6991469545,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4084,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.711318524031936,
    "arrivals": 53129,
    "finished_requests": 52200,
    "scheduler_time": 42.62438228720939
}
#Debug simulation 
Total elapsed time: 5.468657225021161. Arrivals time: 0.1356061157421209 Scheduler time: 5.146374471310992 Scheduler overhead time: 0.03881001769332215 Adapter cache time: 0.09201490815030411 Engine time: 0.03837805183138698 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_320_slots_160_rate_0.1-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_320_slots_160_rate_0.1-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 66, 1080, 1080, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 1080, 1080, 270, 66, 66, 270, 1080, 1080, 270, 270, 66, 66, 270, 1080, 1080, 66, 1080, 270, 66, 270, 1080, 66, 270, 1080, 1080, 270, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 270, 270, 270, 66, 270, 66, 1080, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 1080, 270, 66, 66, 270, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 66, 1080, 270, 1080, 1080, 270, 66, 270, 270, 270, 66, 1080, 270, 1080, 66, 1080, 66, 66, 270, 1080, 1080, 270, 66, 270, 66, 270, 1080, 1080, 270, 66, 270, 66, 1080, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 270, 66, 270, 1080, 270, 66, 66, 270, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 270, 1080, 270, 270, 270, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 66, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 66, 66, 1080, 270, 1080, 270, 1080, 270, 66, 270, 66, 66, 66, 1080, 1080, 270, 270, 66, 66, 270, 66, 1080, 66, 66, 270, 66, 1080, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 66, 270, 1080, 270, 270, 1080, 270, 66, 270, 66, 1080, 270, 270, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 270, 66, 270, 66, 270, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 270, 270, 1080, 66, 1080, 66, 66, 66, 1080, 270, 1080, 1080, 66, 270, 270, 270, 66, 270, 66, 270, 270, 1080, 66, 66, 270, 66, 270, 270, 66, 1080, 1080, 1080, 66, 270, 270, 270, 270, 66, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 270, 270, 270, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 151446 . Total input tokens: 33701223 . Total output tokens: 30293712
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.683979774999898,
    "estimated_duration": 3600.106247934961,
    "input_throughput": 3464.728299936925,
    "output_throughput": 3047.4992248612675,
    "total_throughput": 6512.2275247981925,
    "itl": 136.09920134396623,
    "ttft": 53264.48918793954,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5038,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.41873725393156,
    "arrivals": 50759,
    "finished_requests": 50113,
    "scheduler_time": 40.16354766273812
}
#Debug simulation 
Total elapsed time: 4.6840715750004165. Arrivals time: 0.12687309324974194 Scheduler time: 4.350425171898678 Scheduler overhead time: 0.04138437827350572 Adapter cache time: 0.10637591063277796 Engine time: 0.04050156532321125 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_320_slots_160_rate_0.1-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_320_slots_160_rate_0.1-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 66, 1080, 1080, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 1080, 1080, 270, 66, 66, 270, 1080, 1080, 270, 270, 66, 66, 270, 1080, 1080, 66, 1080, 270, 66, 270, 1080, 66, 270, 1080, 1080, 270, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 270, 270, 270, 66, 270, 66, 1080, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 1080, 270, 66, 66, 270, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 66, 1080, 270, 1080, 1080, 270, 66, 270, 270, 270, 66, 1080, 270, 1080, 66, 1080, 66, 66, 270, 1080, 1080, 270, 66, 270, 66, 270, 1080, 1080, 270, 66, 270, 66, 1080, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 270, 66, 270, 1080, 270, 66, 66, 270, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 270, 1080, 270, 270, 270, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 66, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 66, 66, 1080, 270, 1080, 270, 1080, 270, 66, 270, 66, 66, 66, 1080, 1080, 270, 270, 66, 66, 270, 66, 1080, 66, 66, 270, 66, 1080, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 66, 270, 1080, 270, 270, 1080, 270, 66, 270, 66, 1080, 270, 270, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 270, 66, 270, 66, 270, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 270, 270, 1080, 66, 1080, 66, 66, 66, 1080, 270, 1080, 1080, 66, 270, 270, 270, 66, 270, 66, 270, 270, 1080, 66, 66, 270, 66, 270, 270, 66, 1080, 1080, 1080, 66, 270, 270, 270, 270, 66, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 270, 270, 270, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 151446 . Total input tokens: 33701223 . Total output tokens: 30293712
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.638634547009133,
    "estimated_duration": 3600.035591458712,
    "input_throughput": 3464.964076909477,
    "output_throughput": 3047.6623692362823,
    "total_throughput": 6512.6264461457595,
    "itl": 136.22256097066347,
    "ttft": 53074.221550352275,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5030,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.410790276726253,
    "arrivals": 50759,
    "finished_requests": 50114,
    "scheduler_time": 40.166811036986125
}
#Debug simulation 
Total elapsed time: 4.638722939998843. Arrivals time: 0.12867139145964757 Scheduler time: 4.303098001575563 Scheduler overhead time: 0.04152146162232384 Adapter cache time: 0.10638765658950433 Engine time: 0.040553385275416076 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_320_slots_160_rate_0.1-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_320_slots_160_rate_0.1-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 66, 1080, 1080, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 1080, 1080, 270, 66, 66, 270, 1080, 1080, 270, 270, 66, 66, 270, 1080, 1080, 66, 1080, 270, 66, 270, 1080, 66, 270, 1080, 1080, 270, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 270, 270, 270, 66, 270, 66, 1080, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 1080, 270, 66, 66, 270, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 66, 1080, 270, 1080, 1080, 270, 66, 270, 270, 270, 66, 1080, 270, 1080, 66, 1080, 66, 66, 270, 1080, 1080, 270, 66, 270, 66, 270, 1080, 1080, 270, 66, 270, 66, 1080, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 270, 66, 270, 1080, 270, 66, 66, 270, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 270, 1080, 270, 270, 270, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 66, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 66, 66, 1080, 270, 1080, 270, 1080, 270, 66, 270, 66, 66, 66, 1080, 1080, 270, 270, 66, 66, 270, 66, 1080, 66, 66, 270, 66, 1080, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 66, 270, 1080, 270, 270, 1080, 270, 66, 270, 66, 1080, 270, 270, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 270, 66, 270, 66, 270, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 270, 270, 1080, 66, 1080, 66, 66, 66, 1080, 270, 1080, 1080, 66, 270, 270, 270, 66, 270, 66, 270, 270, 1080, 66, 66, 270, 66, 270, 270, 66, 1080, 1080, 1080, 66, 270, 270, 270, 270, 66, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 270, 270, 270, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 151446 . Total input tokens: 33701223 . Total output tokens: 30293712
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.67560295999283,
    "estimated_duration": 3600.107607182602,
    "input_throughput": 3464.48838782373,
    "output_throughput": 3047.5391841373685,
    "total_throughput": 6512.027571961099,
    "itl": 136.22746084879728,
    "ttft": 53442.66986496813,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5020,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.407906480001806,
    "arrivals": 50759,
    "finished_requests": 50111,
    "scheduler_time": 40.168684906348794
}
#Debug simulation 
Total elapsed time: 4.675691903044935. Arrivals time: 0.12773917900631204 Scheduler time: 4.342107559496071 Scheduler overhead time: 0.041378054418601096 Adapter cache time: 0.10535826126579195 Engine time: 0.040501649025827646 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_320_slots_160_rate_0.1-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_320_slots_160_rate_0.1-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 66, 1080, 1080, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 1080, 1080, 270, 66, 66, 270, 1080, 1080, 270, 270, 66, 66, 270, 1080, 1080, 66, 1080, 270, 66, 270, 1080, 66, 270, 1080, 1080, 270, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 270, 270, 270, 66, 270, 66, 1080, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 1080, 270, 66, 66, 270, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 66, 1080, 270, 1080, 1080, 270, 66, 270, 270, 270, 66, 1080, 270, 1080, 66, 1080, 66, 66, 270, 1080, 1080, 270, 66, 270, 66, 270, 1080, 1080, 270, 66, 270, 66, 1080, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 270, 66, 270, 1080, 270, 66, 66, 270, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 270, 1080, 270, 270, 270, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 66, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 66, 66, 1080, 270, 1080, 270, 1080, 270, 66, 270, 66, 66, 66, 1080, 1080, 270, 270, 66, 66, 270, 66, 1080, 66, 66, 270, 66, 1080, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 66, 270, 1080, 270, 270, 1080, 270, 66, 270, 66, 1080, 270, 270, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 270, 66, 270, 66, 270, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 270, 270, 1080, 66, 1080, 66, 66, 66, 1080, 270, 1080, 1080, 66, 270, 270, 270, 66, 270, 66, 270, 270, 1080, 66, 66, 270, 66, 270, 270, 66, 1080, 1080, 1080, 66, 270, 270, 270, 270, 66, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 270, 270, 270, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 151446 . Total input tokens: 33701223 . Total output tokens: 30293712
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.623837868042756,
    "estimated_duration": 3600.0584176226002,
    "input_throughput": 3464.9912731798586,
    "output_throughput": 3047.6441566316216,
    "total_throughput": 6512.63542981148,
    "itl": 136.1359641039344,
    "ttft": 52918.89278862004,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5033,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.716567884575575,
    "arrivals": 50759,
    "finished_requests": 50116,
    "scheduler_time": 40.1644625845422
}
#Debug simulation 
Total elapsed time: 4.623973501031287. Arrivals time: 0.12380747072165832 Scheduler time: 4.2946308918180875 Scheduler overhead time: 0.04123073007212952 Adapter cache time: 0.1056292022112757 Engine time: 0.04024694365216419 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_320_slots_160_rate_0.1-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_320_slots_160_rate_0.1-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 66, 1080, 1080, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 1080, 1080, 270, 66, 66, 270, 1080, 1080, 270, 270, 66, 66, 270, 1080, 1080, 66, 1080, 270, 66, 270, 1080, 66, 270, 1080, 1080, 270, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 270, 270, 270, 66, 270, 66, 1080, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 1080, 270, 66, 66, 270, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 66, 1080, 270, 1080, 1080, 270, 66, 270, 270, 270, 66, 1080, 270, 1080, 66, 1080, 66, 66, 270, 1080, 1080, 270, 66, 270, 66, 270, 1080, 1080, 270, 66, 270, 66, 1080, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 270, 66, 270, 1080, 270, 66, 66, 270, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 270, 1080, 270, 270, 270, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 66, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 66, 66, 1080, 270, 1080, 270, 1080, 270, 66, 270, 66, 66, 66, 1080, 1080, 270, 270, 66, 66, 270, 66, 1080, 66, 66, 270, 66, 1080, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 66, 270, 1080, 270, 270, 1080, 270, 66, 270, 66, 1080, 270, 270, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 270, 66, 270, 66, 270, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 270, 270, 1080, 66, 1080, 66, 66, 66, 1080, 270, 1080, 1080, 66, 270, 270, 270, 66, 270, 66, 270, 270, 1080, 66, 66, 270, 66, 270, 270, 66, 1080, 1080, 1080, 66, 270, 270, 270, 270, 66, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 270, 270, 270, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 151446 . Total input tokens: 33701223 . Total output tokens: 30293712
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.687031835026573,
    "estimated_duration": 3600.037869895417,
    "input_throughput": 3464.469111365855,
    "output_throughput": 3047.518775217417,
    "total_throughput": 6511.987886583272,
    "itl": 136.25653374751678,
    "ttft": 53509.942566627156,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5019,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.62082222629215,
    "arrivals": 50759,
    "finished_requests": 50108,
    "scheduler_time": 40.16848671593051
}
#Debug simulation 
Total elapsed time: 4.687119239999447. Arrivals time: 0.1261416242341511 Scheduler time: 4.354154952510726 Scheduler overhead time: 0.041430362209212035 Adapter cache time: 0.10639756923774257 Engine time: 0.04037702677305788 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_320_slots_160_rate_0.1-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_320_slots_160_rate_0.1-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 66, 1080, 1080, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 1080, 1080, 270, 66, 66, 270, 1080, 1080, 270, 270, 66, 66, 270, 1080, 1080, 66, 1080, 270, 66, 270, 1080, 66, 270, 1080, 1080, 270, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 270, 270, 270, 66, 270, 66, 1080, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 1080, 270, 66, 66, 270, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 66, 1080, 270, 1080, 1080, 270, 66, 270, 270, 270, 66, 1080, 270, 1080, 66, 1080, 66, 66, 270, 1080, 1080, 270, 66, 270, 66, 270, 1080, 1080, 270, 66, 270, 66, 1080, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 270, 66, 270, 1080, 270, 66, 66, 270, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 270, 1080, 270, 270, 270, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 66, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 66, 66, 1080, 270, 1080, 270, 1080, 270, 66, 270, 66, 66, 66, 1080, 1080, 270, 270, 66, 66, 270, 66, 1080, 66, 66, 270, 66, 1080, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 66, 270, 1080, 270, 270, 1080, 270, 66, 270, 66, 1080, 270, 270, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 270, 66, 270, 66, 270, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 270, 270, 1080, 66, 1080, 66, 66, 66, 1080, 270, 1080, 1080, 66, 270, 270, 270, 66, 270, 66, 270, 270, 1080, 66, 66, 270, 66, 270, 270, 66, 1080, 1080, 1080, 66, 270, 270, 270, 270, 66, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 270, 270, 270, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 151446 . Total input tokens: 33701223 . Total output tokens: 30293712
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.664775857003406,
    "estimated_duration": 3600.1484628222747,
    "input_throughput": 3464.9546064055776,
    "output_throughput": 3047.568485939306,
    "total_throughput": 6512.5230923448835,
    "itl": 136.04875830877532,
    "ttft": 52984.59024397537,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5023,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.019022631295215,
    "arrivals": 50759,
    "finished_requests": 50117,
    "scheduler_time": 40.16267832822374
}
#Debug simulation 
Total elapsed time: 4.664866000995971. Arrivals time: 0.12906839640345424 Scheduler time: 4.32900937483646 Scheduler overhead time: 0.04148944799089804 Adapter cache time: 0.10603399795945734 Engine time: 0.040793547697830945 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_320_slots_160_rate_0.1-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_320_slots_160_rate_0.1-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 66, 1080, 1080, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 1080, 1080, 270, 66, 66, 270, 1080, 1080, 270, 270, 66, 66, 270, 1080, 1080, 66, 1080, 270, 66, 270, 1080, 66, 270, 1080, 1080, 270, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 270, 270, 270, 66, 270, 66, 1080, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 1080, 270, 66, 66, 270, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 66, 1080, 270, 1080, 1080, 270, 66, 270, 270, 270, 66, 1080, 270, 1080, 66, 1080, 66, 66, 270, 1080, 1080, 270, 66, 270, 66, 270, 1080, 1080, 270, 66, 270, 66, 1080, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 270, 66, 270, 1080, 270, 66, 66, 270, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 270, 1080, 270, 270, 270, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 66, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 66, 66, 1080, 270, 1080, 270, 1080, 270, 66, 270, 66, 66, 66, 1080, 1080, 270, 270, 66, 66, 270, 66, 1080, 66, 66, 270, 66, 1080, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 66, 270, 1080, 270, 270, 1080, 270, 66, 270, 66, 1080, 270, 270, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 270, 66, 270, 66, 270, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 270, 270, 1080, 66, 1080, 66, 66, 66, 1080, 270, 1080, 1080, 66, 270, 270, 270, 66, 270, 66, 270, 270, 1080, 66, 66, 270, 66, 270, 270, 66, 1080, 1080, 1080, 66, 270, 270, 270, 270, 66, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 270, 270, 270, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 151446 . Total input tokens: 33701223 . Total output tokens: 30293712
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.6715102000162005,
    "estimated_duration": 3600.1091374211396,
    "input_throughput": 3464.2213677260193,
    "output_throughput": 3047.4698352781047,
    "total_throughput": 6511.691203004124,
    "itl": 136.2786317088166,
    "ttft": 53509.1072161487,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5020,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.83090791582941,
    "arrivals": 50759,
    "finished_requests": 50110,
    "scheduler_time": 40.169997999184055
}
#Debug simulation 
Total elapsed time: 4.671598120999988. Arrivals time: 0.1254861571942456 Scheduler time: 4.338435165642295 Scheduler overhead time: 0.0417075504665263 Adapter cache time: 0.10687943728407845 Engine time: 0.04059966647764668 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_320_slots_160_rate_0.1-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_320_slots_160_rate_0.1-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 33, 1080, 1080, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 1080, 1080, 270, 33, 33, 270, 1080, 1080, 270, 270, 33, 33, 270, 1080, 1080, 33, 1080, 270, 33, 270, 1080, 33, 270, 1080, 1080, 270, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 270, 270, 270, 33, 270, 33, 1080, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 1080, 270, 33, 33, 270, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 33, 1080, 270, 1080, 1080, 270, 33, 270, 270, 270, 33, 1080, 270, 1080, 33, 1080, 33, 33, 270, 1080, 1080, 270, 33, 270, 33, 270, 1080, 1080, 270, 33, 270, 33, 1080, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 270, 33, 270, 1080, 270, 33, 33, 270, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 270, 1080, 270, 270, 270, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 33, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 33, 33, 1080, 270, 1080, 270, 1080, 270, 33, 270, 33, 33, 33, 1080, 1080, 270, 270, 33, 33, 270, 33, 1080, 33, 33, 270, 33, 1080, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 33, 270, 1080, 270, 270, 1080, 270, 33, 270, 33, 1080, 270, 270, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 270, 33, 270, 33, 270, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 270, 270, 1080, 33, 1080, 33, 33, 33, 1080, 270, 1080, 1080, 33, 270, 270, 270, 33, 270, 33, 270, 270, 1080, 33, 33, 270, 33, 270, 270, 33, 1080, 1080, 1080, 33, 270, 270, 270, 270, 33, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 270, 270, 270, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 147948 . Total input tokens: 32945481 . Total output tokens: 29592250
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.1909992980072275,
    "estimated_duration": 3600.059466900054,
    "input_throughput": 3377.5889292379784,
    "output_throughput": 2996.962716643796,
    "total_throughput": 6374.551645881774,
    "itl": 130.88552523494232,
    "ttft": 39411.89005833339,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5575,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.062219172423646,
    "arrivals": 49552,
    "finished_requests": 49052,
    "scheduler_time": 39.056681842909214
}
#Debug simulation 
Total elapsed time: 4.191106641024817. Arrivals time: 0.1222357582882978 Scheduler time: 3.8445785470539704 Scheduler overhead time: 0.04299800336593762 Adapter cache time: 0.12003461259882897 Engine time: 0.04206085967598483 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_320_slots_160_rate_0.1-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_320_slots_160_rate_0.1-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 33, 1080, 1080, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 1080, 1080, 270, 33, 33, 270, 1080, 1080, 270, 270, 33, 33, 270, 1080, 1080, 33, 1080, 270, 33, 270, 1080, 33, 270, 1080, 1080, 270, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 270, 270, 270, 33, 270, 33, 1080, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 1080, 270, 33, 33, 270, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 33, 1080, 270, 1080, 1080, 270, 33, 270, 270, 270, 33, 1080, 270, 1080, 33, 1080, 33, 33, 270, 1080, 1080, 270, 33, 270, 33, 270, 1080, 1080, 270, 33, 270, 33, 1080, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 270, 33, 270, 1080, 270, 33, 33, 270, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 270, 1080, 270, 270, 270, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 33, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 33, 33, 1080, 270, 1080, 270, 1080, 270, 33, 270, 33, 33, 33, 1080, 1080, 270, 270, 33, 33, 270, 33, 1080, 33, 33, 270, 33, 1080, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 33, 270, 1080, 270, 270, 1080, 270, 33, 270, 33, 1080, 270, 270, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 270, 33, 270, 33, 270, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 270, 270, 1080, 33, 1080, 33, 33, 33, 1080, 270, 1080, 1080, 33, 270, 270, 270, 33, 270, 33, 270, 270, 1080, 33, 33, 270, 33, 270, 270, 33, 1080, 1080, 1080, 33, 270, 270, 270, 270, 33, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 270, 270, 270, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 147948 . Total input tokens: 32945481 . Total output tokens: 29592250
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.205965376982931,
    "estimated_duration": 3600.0523071831285,
    "input_throughput": 3377.2859288017903,
    "output_throughput": 2996.633404041046,
    "total_throughput": 6373.919332842836,
    "itl": 131.00415416989142,
    "ttft": 39649.167546905046,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5557,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.13854424059888,
    "arrivals": 49552,
    "finished_requests": 49048,
    "scheduler_time": 39.06157482964349
}
#Debug simulation 
Total elapsed time: 4.206055046000984. Arrivals time: 0.12344951811246574 Scheduler time: 3.8615593213471584 Scheduler overhead time: 0.04237382160499692 Adapter cache time: 0.11802788934437558 Engine time: 0.041554899886250496 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_320_slots_160_rate_0.1-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_320_slots_160_rate_0.1-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 33, 1080, 1080, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 1080, 1080, 270, 33, 33, 270, 1080, 1080, 270, 270, 33, 33, 270, 1080, 1080, 33, 1080, 270, 33, 270, 1080, 33, 270, 1080, 1080, 270, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 270, 270, 270, 33, 270, 33, 1080, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 1080, 270, 33, 33, 270, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 33, 1080, 270, 1080, 1080, 270, 33, 270, 270, 270, 33, 1080, 270, 1080, 33, 1080, 33, 33, 270, 1080, 1080, 270, 33, 270, 33, 270, 1080, 1080, 270, 33, 270, 33, 1080, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 270, 33, 270, 1080, 270, 33, 33, 270, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 270, 1080, 270, 270, 270, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 33, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 33, 33, 1080, 270, 1080, 270, 1080, 270, 33, 270, 33, 33, 33, 1080, 1080, 270, 270, 33, 33, 270, 33, 1080, 33, 33, 270, 33, 1080, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 33, 270, 1080, 270, 270, 1080, 270, 33, 270, 33, 1080, 270, 270, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 270, 33, 270, 33, 270, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 270, 270, 1080, 33, 1080, 33, 33, 33, 1080, 270, 1080, 1080, 33, 270, 270, 270, 33, 270, 33, 270, 270, 1080, 33, 33, 270, 33, 270, 270, 33, 1080, 1080, 1080, 33, 270, 270, 270, 270, 33, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 270, 270, 270, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 147948 . Total input tokens: 32945481 . Total output tokens: 29592250
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.1373923740466125,
    "estimated_duration": 3600.098617553782,
    "input_throughput": 3377.538587612968,
    "output_throughput": 2996.808461688988,
    "total_throughput": 6374.347049301956,
    "itl": 131.00759011102534,
    "ttft": 39505.77624248151,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5553,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.156232589351852,
    "arrivals": 49552,
    "finished_requests": 49051,
    "scheduler_time": 39.06217277707237
}
#Debug simulation 
Total elapsed time: 4.137482696038205. Arrivals time: 0.12233667098917067 Scheduler time: 3.793857052514795 Scheduler overhead time: 0.042676046781707555 Adapter cache time: 0.11797525576548651 Engine time: 0.04166491376236081 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_320_slots_160_rate_0.1-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_320_slots_160_rate_0.1-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 33, 1080, 1080, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 1080, 1080, 270, 33, 33, 270, 1080, 1080, 270, 270, 33, 33, 270, 1080, 1080, 33, 1080, 270, 33, 270, 1080, 33, 270, 1080, 1080, 270, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 270, 270, 270, 33, 270, 33, 1080, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 1080, 270, 33, 33, 270, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 33, 1080, 270, 1080, 1080, 270, 33, 270, 270, 270, 33, 1080, 270, 1080, 33, 1080, 33, 33, 270, 1080, 1080, 270, 33, 270, 33, 270, 1080, 1080, 270, 33, 270, 33, 1080, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 270, 33, 270, 1080, 270, 33, 33, 270, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 270, 1080, 270, 270, 270, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 33, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 33, 33, 1080, 270, 1080, 270, 1080, 270, 33, 270, 33, 33, 33, 1080, 1080, 270, 270, 33, 33, 270, 33, 1080, 33, 33, 270, 33, 1080, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 33, 270, 1080, 270, 270, 1080, 270, 33, 270, 33, 1080, 270, 270, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 270, 33, 270, 33, 270, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 270, 270, 1080, 33, 1080, 33, 33, 33, 1080, 270, 1080, 1080, 33, 270, 270, 270, 33, 270, 33, 270, 270, 1080, 33, 33, 270, 33, 270, 270, 33, 1080, 1080, 1080, 33, 270, 270, 270, 270, 33, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 270, 270, 270, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 147948 . Total input tokens: 32945481 . Total output tokens: 29592250
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.201652557007037,
    "estimated_duration": 3600.0867879230746,
    "input_throughput": 3377.5732965079346,
    "output_throughput": 2996.90358471173,
    "total_throughput": 6374.476881219664,
    "itl": 130.91817264158377,
    "ttft": 39493.71745782977,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5563,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.361358052684064,
    "arrivals": 49552,
    "finished_requests": 49051,
    "scheduler_time": 39.058553721110634
}
#Debug simulation 
Total elapsed time: 4.201742938021198. Arrivals time: 0.12254357081837952 Scheduler time: 3.856478068046272 Scheduler overhead time: 0.04273587459465489 Adapter cache time: 0.11881113180425018 Engine time: 0.042005419614724815 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_320_slots_160_rate_0.1-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_320_slots_160_rate_0.1-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 33, 1080, 1080, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 1080, 1080, 270, 33, 33, 270, 1080, 1080, 270, 270, 33, 33, 270, 1080, 1080, 33, 1080, 270, 33, 270, 1080, 33, 270, 1080, 1080, 270, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 270, 270, 270, 33, 270, 33, 1080, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 1080, 270, 33, 33, 270, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 33, 1080, 270, 1080, 1080, 270, 33, 270, 270, 270, 33, 1080, 270, 1080, 33, 1080, 33, 33, 270, 1080, 1080, 270, 33, 270, 33, 270, 1080, 1080, 270, 33, 270, 33, 1080, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 270, 33, 270, 1080, 270, 33, 33, 270, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 270, 1080, 270, 270, 270, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 33, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 33, 33, 1080, 270, 1080, 270, 1080, 270, 33, 270, 33, 33, 33, 1080, 1080, 270, 270, 33, 33, 270, 33, 1080, 33, 33, 270, 33, 1080, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 33, 270, 1080, 270, 270, 1080, 270, 33, 270, 33, 1080, 270, 270, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 270, 33, 270, 33, 270, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 270, 270, 1080, 33, 1080, 33, 33, 33, 1080, 270, 1080, 1080, 33, 270, 270, 270, 33, 270, 33, 270, 270, 1080, 33, 33, 270, 33, 270, 270, 33, 1080, 1080, 1080, 33, 270, 270, 270, 270, 33, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 270, 270, 270, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 147948 . Total input tokens: 32945481 . Total output tokens: 29592250
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.188776908966247,
    "estimated_duration": 3600.0902138249176,
    "input_throughput": 3377.546471837205,
    "output_throughput": 2996.8154571708433,
    "total_throughput": 6374.361929008049,
    "itl": 131.03768565294257,
    "ttft": 39505.31857407826,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5556,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.411051742880364,
    "arrivals": 49552,
    "finished_requests": 49051,
    "scheduler_time": 39.063120926851624
}
#Debug simulation 
Total elapsed time: 4.188881576003041. Arrivals time: 0.1247273184126243 Scheduler time: 3.8421938820392825 Scheduler overhead time: 0.042707188171334565 Adapter cache time: 0.11852998903486878 Engine time: 0.04168850393034518 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_320_slots_160_rate_0.1-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_320_slots_160_rate_0.1-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 33, 1080, 1080, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 1080, 1080, 270, 33, 33, 270, 1080, 1080, 270, 270, 33, 33, 270, 1080, 1080, 33, 1080, 270, 33, 270, 1080, 33, 270, 1080, 1080, 270, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 270, 270, 270, 33, 270, 33, 1080, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 1080, 270, 33, 33, 270, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 33, 1080, 270, 1080, 1080, 270, 33, 270, 270, 270, 33, 1080, 270, 1080, 33, 1080, 33, 33, 270, 1080, 1080, 270, 33, 270, 33, 270, 1080, 1080, 270, 33, 270, 33, 1080, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 270, 33, 270, 1080, 270, 33, 33, 270, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 270, 1080, 270, 270, 270, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 33, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 33, 33, 1080, 270, 1080, 270, 1080, 270, 33, 270, 33, 33, 33, 1080, 1080, 270, 270, 33, 33, 270, 33, 1080, 33, 33, 270, 33, 1080, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 33, 270, 1080, 270, 270, 1080, 270, 33, 270, 33, 1080, 270, 270, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 270, 33, 270, 33, 270, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 270, 270, 1080, 33, 1080, 33, 33, 33, 1080, 270, 1080, 1080, 33, 270, 270, 270, 33, 270, 33, 270, 270, 1080, 33, 33, 270, 33, 270, 270, 33, 1080, 1080, 1080, 33, 270, 270, 270, 270, 33, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 270, 270, 270, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 147948 . Total input tokens: 32945481 . Total output tokens: 29592250
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.161742686992511,
    "estimated_duration": 3600.0381542988594,
    "input_throughput": 3377.618924810586,
    "output_throughput": 2996.9440704722974,
    "total_throughput": 6374.562995282883,
    "itl": 130.84002926127616,
    "ttft": 39406.54912059583,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5571,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.657570192901645,
    "arrivals": 49552,
    "finished_requests": 49051,
    "scheduler_time": 39.05486447097624
}
#Debug simulation 
Total elapsed time: 4.161875506979413. Arrivals time: 0.12044626753777266 Scheduler time: 3.8198685080278665 Scheduler overhead time: 0.04266597126843408 Adapter cache time: 0.11812091583851725 Engine time: 0.041668451216537505 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_320_slots_160_rate_0.1-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_320_slots_160_rate_0.1-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 33, 1080, 1080, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 1080, 1080, 270, 33, 33, 270, 1080, 1080, 270, 270, 33, 33, 270, 1080, 1080, 33, 1080, 270, 33, 270, 1080, 33, 270, 1080, 1080, 270, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 270, 270, 270, 33, 270, 33, 1080, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 1080, 270, 33, 33, 270, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 33, 1080, 270, 1080, 1080, 270, 33, 270, 270, 270, 33, 1080, 270, 1080, 33, 1080, 33, 33, 270, 1080, 1080, 270, 33, 270, 33, 270, 1080, 1080, 270, 33, 270, 33, 1080, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 270, 33, 270, 1080, 270, 33, 33, 270, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 270, 1080, 270, 270, 270, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 33, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 33, 33, 1080, 270, 1080, 270, 1080, 270, 33, 270, 33, 33, 33, 1080, 1080, 270, 270, 33, 33, 270, 33, 1080, 33, 33, 270, 33, 1080, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 33, 270, 1080, 270, 270, 1080, 270, 33, 270, 33, 1080, 270, 270, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 270, 33, 270, 33, 270, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 270, 270, 1080, 33, 1080, 33, 33, 33, 1080, 270, 1080, 1080, 33, 270, 270, 270, 33, 270, 33, 270, 270, 1080, 33, 33, 270, 33, 270, 270, 33, 1080, 1080, 1080, 33, 270, 270, 270, 270, 33, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 270, 270, 270, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 147948 . Total input tokens: 32945481 . Total output tokens: 29592250
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.2042716079740785,
    "estimated_duration": 3600.108063582759,
    "input_throughput": 3377.4750049861896,
    "output_throughput": 2996.706156998944,
    "total_throughput": 6374.181161985134,
    "itl": 131.0614768925644,
    "ttft": 39582.56380594321,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5560,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.647107571958113,
    "arrivals": 49552,
    "finished_requests": 49050,
    "scheduler_time": 39.06426692579407
}
#Debug simulation 
Total elapsed time: 4.204362316988409. Arrivals time: 0.12368025933392346 Scheduler time: 3.8581212612916715 Scheduler overhead time: 0.04265171097358689 Adapter cache time: 0.11871423036791384 Engine time: 0.042122205486521125 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_320_slots_160_rate_0.1-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_320_slots_160_rate_0.1-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [106 107 107]
Adapter prompts. [135, 1080, 1080, 66, 1080, 1080, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 1080, 1080, 135, 66, 66, 135, 1080, 1080, 135, 135, 66, 66, 135, 1080, 1080, 66, 1080, 135, 66, 135, 1080, 66, 135, 1080, 1080, 135, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 135, 66, 1080, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 1080, 135, 66, 66, 135, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 66, 1080, 135, 1080, 1080, 135, 66, 135, 135, 135, 66, 1080, 135, 1080, 66, 1080, 66, 66, 135, 1080, 1080, 135, 66, 135, 66, 135, 1080, 1080, 135, 66, 135, 66, 1080, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 135, 66, 135, 1080, 135, 66, 66, 135, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 135, 1080, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 66, 135, 1080, 1080, 1080, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 66, 66, 1080, 135, 1080, 135, 1080, 135, 66, 135, 66, 66, 66, 1080, 1080, 135, 135, 66, 66, 135, 66, 1080, 66, 66, 135, 66, 1080, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 66, 135, 1080, 135, 135, 1080, 135, 66, 135, 66, 1080, 135, 135, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 135, 66, 135, 66, 135, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 135, 135, 1080, 66, 1080, 66, 66, 66, 1080, 135, 1080, 1080, 66, 135, 135, 135, 66, 135, 66, 135, 135, 1080, 66, 66, 135, 66, 135, 135, 66, 1080, 1080, 1080, 66, 135, 135, 135, 135, 66, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 135, 135, 135, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 137001 . Total input tokens: 30496485 . Total output tokens: 27423595
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.630364054988604,
    "estimated_duration": 3600.0272486359004,
    "input_throughput": 3148.2322819346723,
    "output_throughput": 2794.6182917954684,
    "total_throughput": 5942.85057373014,
    "itl": 91.34637061308865,
    "ttft": 24731.691805176695,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6693,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.483844470141577,
    "arrivals": 45990,
    "finished_requests": 45675,
    "scheduler_time": 33.75668851544066
}
#Debug simulation 
Total elapsed time: 3.630451573000755. Arrivals time: 0.11464379774406552 Scheduler time: 3.2076234827400185 Scheduler overhead time: 0.05205122253391892 Adapter cache time: 0.17970682680606842 Engine time: 0.052515514427796006 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_320_slots_160_rate_0.1-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_320_slots_160_rate_0.1-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [106 107 107]
Adapter prompts. [135, 1080, 1080, 66, 1080, 1080, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 1080, 1080, 135, 66, 66, 135, 1080, 1080, 135, 135, 66, 66, 135, 1080, 1080, 66, 1080, 135, 66, 135, 1080, 66, 135, 1080, 1080, 135, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 135, 66, 1080, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 1080, 135, 66, 66, 135, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 66, 1080, 135, 1080, 1080, 135, 66, 135, 135, 135, 66, 1080, 135, 1080, 66, 1080, 66, 66, 135, 1080, 1080, 135, 66, 135, 66, 135, 1080, 1080, 135, 66, 135, 66, 1080, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 135, 66, 135, 1080, 135, 66, 66, 135, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 135, 1080, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 66, 135, 1080, 1080, 1080, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 66, 66, 1080, 135, 1080, 135, 1080, 135, 66, 135, 66, 66, 66, 1080, 1080, 135, 135, 66, 66, 135, 66, 1080, 66, 66, 135, 66, 1080, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 66, 135, 1080, 135, 135, 1080, 135, 66, 135, 66, 1080, 135, 135, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 135, 66, 135, 66, 135, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 135, 135, 1080, 66, 1080, 66, 66, 66, 1080, 135, 1080, 1080, 66, 135, 135, 135, 66, 135, 66, 135, 135, 1080, 66, 66, 135, 66, 135, 135, 66, 1080, 1080, 1080, 66, 135, 135, 135, 135, 66, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 135, 135, 135, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 137001 . Total input tokens: 30496485 . Total output tokens: 27423595
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.6323357810033485,
    "estimated_duration": 3600.004510869764,
    "input_throughput": 3148.233555202346,
    "output_throughput": 2794.4973317740223,
    "total_throughput": 5942.730886976368,
    "itl": 91.53784335393851,
    "ttft": 24810.379609253996,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6692,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.86525650984038,
    "arrivals": 45990,
    "finished_requests": 45674,
    "scheduler_time": 33.771182449627965
}
#Debug simulation 
Total elapsed time: 3.63242535101017. Arrivals time: 0.11538546270458028 Scheduler time: 3.2098540939041413 Scheduler overhead time: 0.052055872103665024 Adapter cache time: 0.17905426339711994 Engine time: 0.052083441405557096 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_320_slots_160_rate_0.1-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_320_slots_160_rate_0.1-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [106 107 107]
Adapter prompts. [135, 1080, 1080, 66, 1080, 1080, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 1080, 1080, 135, 66, 66, 135, 1080, 1080, 135, 135, 66, 66, 135, 1080, 1080, 66, 1080, 135, 66, 135, 1080, 66, 135, 1080, 1080, 135, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 135, 66, 1080, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 1080, 135, 66, 66, 135, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 66, 1080, 135, 1080, 1080, 135, 66, 135, 135, 135, 66, 1080, 135, 1080, 66, 1080, 66, 66, 135, 1080, 1080, 135, 66, 135, 66, 135, 1080, 1080, 135, 66, 135, 66, 1080, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 135, 66, 135, 1080, 135, 66, 66, 135, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 135, 1080, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 66, 135, 1080, 1080, 1080, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 66, 66, 1080, 135, 1080, 135, 1080, 135, 66, 135, 66, 66, 66, 1080, 1080, 135, 135, 66, 66, 135, 66, 1080, 66, 66, 135, 66, 1080, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 66, 135, 1080, 135, 135, 1080, 135, 66, 135, 66, 1080, 135, 135, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 135, 66, 135, 66, 135, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 135, 135, 1080, 66, 1080, 66, 66, 66, 1080, 135, 1080, 1080, 66, 135, 135, 135, 66, 135, 66, 135, 135, 1080, 66, 66, 135, 66, 135, 135, 66, 1080, 1080, 1080, 66, 135, 135, 135, 135, 66, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 135, 135, 135, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 137001 . Total input tokens: 30496485 . Total output tokens: 27423595
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.6113703890005127,
    "estimated_duration": 3600.027781954087,
    "input_throughput": 3148.213204579248,
    "output_throughput": 2794.4792677514683,
    "total_throughput": 5942.692472330717,
    "itl": 91.54803633139962,
    "ttft": 24810.38795450151,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6695,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.90847406016636,
    "arrivals": 45990,
    "finished_requests": 45674,
    "scheduler_time": 33.77206896725432
}
#Debug simulation 
Total elapsed time: 3.611459728970658. Arrivals time: 0.11636633198941126 Scheduler time: 3.1892780759371817 Scheduler overhead time: 0.051240316475741565 Adapter cache time: 0.17924507829593495 Engine time: 0.05131497362162918 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_320_slots_160_rate_0.1-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_320_slots_160_rate_0.1-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [106 107 107]
Adapter prompts. [135, 1080, 1080, 66, 1080, 1080, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 1080, 1080, 135, 66, 66, 135, 1080, 1080, 135, 135, 66, 66, 135, 1080, 1080, 66, 1080, 135, 66, 135, 1080, 66, 135, 1080, 1080, 135, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 135, 66, 1080, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 1080, 135, 66, 66, 135, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 66, 1080, 135, 1080, 1080, 135, 66, 135, 135, 135, 66, 1080, 135, 1080, 66, 1080, 66, 66, 135, 1080, 1080, 135, 66, 135, 66, 135, 1080, 1080, 135, 66, 135, 66, 1080, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 135, 66, 135, 1080, 135, 66, 66, 135, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 135, 1080, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 66, 135, 1080, 1080, 1080, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 66, 66, 1080, 135, 1080, 135, 1080, 135, 66, 135, 66, 66, 66, 1080, 1080, 135, 135, 66, 66, 135, 66, 1080, 66, 66, 135, 66, 1080, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 66, 135, 1080, 135, 135, 1080, 135, 66, 135, 66, 1080, 135, 135, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 135, 66, 135, 66, 135, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 135, 135, 1080, 66, 1080, 66, 66, 66, 1080, 135, 1080, 1080, 66, 135, 135, 135, 66, 135, 66, 135, 135, 1080, 66, 66, 135, 66, 135, 135, 66, 1080, 1080, 1080, 66, 135, 135, 135, 135, 66, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 135, 135, 135, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 137001 . Total input tokens: 30496485 . Total output tokens: 27423595
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 3.6327613029861823,
    "estimated_duration": 3600.1065414850395,
    "input_throughput": 3148.1629416791798,
    "output_throughput": 2794.5567399374722,
    "total_throughput": 5942.7196816166515,
    "itl": 91.40810264809213,
    "ttft": 24809.49655512927,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6690,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.917872795564797,
    "arrivals": 45990,
    "finished_requests": 45675,
    "scheduler_time": 33.76245388331682
}
#Debug simulation 
Total elapsed time: 3.6328503449913114. Arrivals time: 0.11396435945061967 Scheduler time: 3.2105620651855133 Scheduler overhead time: 0.051704229263123125 Adapter cache time: 0.18015463004121557 Engine time: 0.05231997271766886 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_320_slots_160_rate_0.1-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_320_slots_160_rate_0.1-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [106 107 107]
Adapter prompts. [135, 1080, 1080, 66, 1080, 1080, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 1080, 1080, 135, 66, 66, 135, 1080, 1080, 135, 135, 66, 66, 135, 1080, 1080, 66, 1080, 135, 66, 135, 1080, 66, 135, 1080, 1080, 135, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 135, 66, 1080, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 1080, 135, 66, 66, 135, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 66, 1080, 135, 1080, 1080, 135, 66, 135, 135, 135, 66, 1080, 135, 1080, 66, 1080, 66, 66, 135, 1080, 1080, 135, 66, 135, 66, 135, 1080, 1080, 135, 66, 135, 66, 1080, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 135, 66, 135, 1080, 135, 66, 66, 135, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 135, 1080, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 66, 135, 1080, 1080, 1080, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 66, 66, 1080, 135, 1080, 135, 1080, 135, 66, 135, 66, 66, 66, 1080, 1080, 135, 135, 66, 66, 135, 66, 1080, 66, 66, 135, 66, 1080, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 66, 135, 1080, 135, 135, 1080, 135, 66, 135, 66, 1080, 135, 135, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 135, 66, 135, 66, 135, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 135, 135, 1080, 66, 1080, 66, 66, 66, 1080, 135, 1080, 1080, 66, 135, 135, 135, 66, 135, 66, 135, 135, 1080, 66, 66, 135, 66, 135, 135, 66, 1080, 1080, 1080, 66, 135, 135, 135, 135, 66, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 135, 135, 135, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 137001 . Total input tokens: 30496485 . Total output tokens: 27423595
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 3.6537463099812157,
    "estimated_duration": 3600.019871748313,
    "input_throughput": 3148.220122045028,
    "output_throughput": 2794.4854079692523,
    "total_throughput": 5942.70553001428,
    "itl": 91.58543509424084,
    "ttft": 24810.39757003129,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6694,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.195670280362446,
    "arrivals": 45990,
    "finished_requests": 45674,
    "scheduler_time": 33.77476713077321
}
#Debug simulation 
Total elapsed time: 3.6538329259492457. Arrivals time: 0.11570985312573612 Scheduler time: 3.2311641227570362 Scheduler overhead time: 0.051748755446169525 Adapter cache time: 0.1796257594251074 Engine time: 0.051558476174250245 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_320_slots_160_rate_0.1-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_320_slots_160_rate_0.1-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [106 107 107]
Adapter prompts. [135, 1080, 1080, 66, 1080, 1080, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 1080, 1080, 135, 66, 66, 135, 1080, 1080, 135, 135, 66, 66, 135, 1080, 1080, 66, 1080, 135, 66, 135, 1080, 66, 135, 1080, 1080, 135, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 135, 66, 1080, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 1080, 135, 66, 66, 135, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 66, 1080, 135, 1080, 1080, 135, 66, 135, 135, 135, 66, 1080, 135, 1080, 66, 1080, 66, 66, 135, 1080, 1080, 135, 66, 135, 66, 135, 1080, 1080, 135, 66, 135, 66, 1080, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 135, 66, 135, 1080, 135, 66, 66, 135, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 135, 1080, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 66, 135, 1080, 1080, 1080, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 66, 66, 1080, 135, 1080, 135, 1080, 135, 66, 135, 66, 66, 66, 1080, 1080, 135, 135, 66, 66, 135, 66, 1080, 66, 66, 135, 66, 1080, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 66, 135, 1080, 135, 135, 1080, 135, 66, 135, 66, 1080, 135, 135, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 135, 66, 135, 66, 135, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 135, 135, 1080, 66, 1080, 66, 66, 66, 1080, 135, 1080, 1080, 66, 135, 135, 135, 66, 135, 66, 135, 135, 1080, 66, 66, 135, 66, 135, 135, 66, 1080, 1080, 1080, 66, 135, 135, 135, 135, 66, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 135, 135, 135, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 137001 . Total input tokens: 30496485 . Total output tokens: 27423595
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.6621997419861145,
    "estimated_duration": 3600.0245504622,
    "input_throughput": 3148.2346414956774,
    "output_throughput": 2794.6203863271785,
    "total_throughput": 5942.855027822856,
    "itl": 91.27932263408704,
    "ttft": 24731.541286644057,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6688,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.997456372306264,
    "arrivals": 45990,
    "finished_requests": 45675,
    "scheduler_time": 33.75168626809473
}
#Debug simulation 
Total elapsed time: 3.662285770988092. Arrivals time: 0.11794929375173524 Scheduler time: 3.2318226355710067 Scheduler overhead time: 0.05253121635178104 Adapter cache time: 0.1829999400069937 Engine time: 0.05269192566629499 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_320_slots_160_rate_0.1-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_320_slots_160_rate_0.1-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [106 107 107]
Adapter prompts. [135, 1080, 1080, 66, 1080, 1080, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 1080, 1080, 135, 66, 66, 135, 1080, 1080, 135, 135, 66, 66, 135, 1080, 1080, 66, 1080, 135, 66, 135, 1080, 66, 135, 1080, 1080, 135, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 135, 66, 1080, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 1080, 135, 66, 66, 135, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 66, 1080, 135, 1080, 1080, 135, 66, 135, 135, 135, 66, 1080, 135, 1080, 66, 1080, 66, 66, 135, 1080, 1080, 135, 66, 135, 66, 135, 1080, 1080, 135, 66, 135, 66, 1080, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 135, 66, 135, 1080, 135, 66, 66, 135, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 135, 1080, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 66, 135, 1080, 1080, 1080, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 66, 66, 1080, 135, 1080, 135, 1080, 135, 66, 135, 66, 66, 66, 1080, 1080, 135, 135, 66, 66, 135, 66, 1080, 66, 66, 135, 66, 1080, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 66, 135, 1080, 135, 135, 1080, 135, 66, 135, 66, 1080, 135, 135, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 135, 66, 135, 66, 135, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 135, 135, 1080, 66, 1080, 66, 66, 66, 1080, 135, 1080, 1080, 66, 135, 135, 135, 66, 135, 66, 135, 135, 1080, 66, 66, 135, 66, 135, 135, 66, 1080, 1080, 1080, 66, 135, 135, 135, 135, 66, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 135, 135, 135, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 137001 . Total input tokens: 30496485 . Total output tokens: 27423595
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.602891434042249,
    "estimated_duration": 3600.0280884594117,
    "input_throughput": 3148.212936541309,
    "output_throughput": 2794.4790298303315,
    "total_throughput": 5942.691966371641,
    "itl": 91.62673827836804,
    "ttft": 24810.642076658874,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6693,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.474149475431176,
    "arrivals": 45990,
    "finished_requests": 45674,
    "scheduler_time": 33.778006371452086
}
#Debug simulation 
Total elapsed time: 3.602979334013071. Arrivals time: 0.11456610891036689 Scheduler time: 3.1833457537577488 Scheduler overhead time: 0.051846674527041614 Adapter cache time: 0.17811256676213816 Engine time: 0.05106575362151489 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_320_slots_160_rate_0.1-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_320_slots_160_rate_0.1-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [106 107 107]
Adapter prompts. [135, 1080, 1080, 33, 1080, 1080, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 1080, 1080, 135, 33, 33, 135, 1080, 1080, 135, 135, 33, 33, 135, 1080, 1080, 33, 1080, 135, 33, 135, 1080, 33, 135, 1080, 1080, 135, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 135, 33, 1080, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 1080, 135, 33, 33, 135, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 33, 1080, 135, 1080, 1080, 135, 33, 135, 135, 135, 33, 1080, 135, 1080, 33, 1080, 33, 33, 135, 1080, 1080, 135, 33, 135, 33, 135, 1080, 1080, 135, 33, 135, 33, 1080, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 135, 33, 135, 1080, 135, 33, 33, 135, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 135, 1080, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 33, 135, 1080, 1080, 1080, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 33, 33, 1080, 135, 1080, 135, 1080, 135, 33, 135, 33, 33, 33, 1080, 1080, 135, 135, 33, 33, 135, 33, 1080, 33, 33, 135, 33, 1080, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 33, 135, 1080, 135, 135, 1080, 135, 33, 135, 33, 1080, 135, 135, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 135, 33, 135, 33, 135, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 135, 135, 1080, 33, 1080, 33, 33, 33, 1080, 135, 1080, 1080, 33, 135, 135, 135, 33, 135, 33, 135, 135, 1080, 33, 33, 135, 33, 135, 135, 33, 1080, 1080, 1080, 33, 135, 135, 135, 135, 33, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 135, 135, 135, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 133503 . Total input tokens: 29742321 . Total output tokens: 26714906
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.544765849946998,
    "estimated_duration": 3600.0680248122108,
    "input_throughput": 3089.6352300399103,
    "output_throughput": 2706.119143542622,
    "total_throughput": 5795.754373582533,
    "itl": 73.26663869461954,
    "ttft": 17959.35787436731,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4782,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.635252391484975,
    "arrivals": 44803,
    "finished_requests": 44581,
    "scheduler_time": 30.62534044340656
}
#Debug simulation 
Total elapsed time: 3.5448970359866507. Arrivals time: 0.1152988342801109 Scheduler time: 3.0971015480463393 Scheduler overhead time: 0.05870851274812594 Adapter cache time: 0.18833462055772543 Engine time: 0.05803040956379846 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_320_slots_160_rate_0.1-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_320_slots_160_rate_0.1-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [106 107 107]
Adapter prompts. [135, 1080, 1080, 33, 1080, 1080, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 1080, 1080, 135, 33, 33, 135, 1080, 1080, 135, 135, 33, 33, 135, 1080, 1080, 33, 1080, 135, 33, 135, 1080, 33, 135, 1080, 1080, 135, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 135, 33, 1080, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 1080, 135, 33, 33, 135, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 33, 1080, 135, 1080, 1080, 135, 33, 135, 135, 135, 33, 1080, 135, 1080, 33, 1080, 33, 33, 135, 1080, 1080, 135, 33, 135, 33, 135, 1080, 1080, 135, 33, 135, 33, 1080, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 135, 33, 135, 1080, 135, 33, 33, 135, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 135, 1080, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 33, 135, 1080, 1080, 1080, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 33, 33, 1080, 135, 1080, 135, 1080, 135, 33, 135, 33, 33, 33, 1080, 1080, 135, 135, 33, 33, 135, 33, 1080, 33, 33, 135, 33, 1080, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 33, 135, 1080, 135, 135, 1080, 135, 33, 135, 33, 1080, 135, 135, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 135, 33, 135, 33, 135, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 135, 135, 1080, 33, 1080, 33, 33, 33, 1080, 135, 1080, 1080, 33, 135, 135, 135, 33, 135, 33, 135, 135, 1080, 33, 33, 135, 33, 135, 135, 33, 1080, 1080, 1080, 33, 135, 135, 135, 135, 33, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 135, 135, 135, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 133503 . Total input tokens: 29742321 . Total output tokens: 26714906
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.5288969569955952,
    "estimated_duration": 3600.0746071006783,
    "input_throughput": 3089.4531957928834,
    "output_throughput": 2705.5917065686535,
    "total_throughput": 5795.044902361537,
    "itl": 74.43027305168137,
    "ttft": 18362.640194077845,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4809,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.703409295250767,
    "arrivals": 44803,
    "finished_requests": 44576,
    "scheduler_time": 30.764238426588165
}
#Debug simulation 
Total elapsed time: 3.528985603014007. Arrivals time: 0.1149759583058767 Scheduler time: 3.08454886515392 Scheduler overhead time: 0.05771729827392846 Adapter cache time: 0.18676631205016747 Engine time: 0.05779185122810304 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_320_slots_160_rate_0.1-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_320_slots_160_rate_0.1-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [106 107 107]
Adapter prompts. [135, 1080, 1080, 33, 1080, 1080, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 1080, 1080, 135, 33, 33, 135, 1080, 1080, 135, 135, 33, 33, 135, 1080, 1080, 33, 1080, 135, 33, 135, 1080, 33, 135, 1080, 1080, 135, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 135, 33, 1080, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 1080, 135, 33, 33, 135, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 33, 1080, 135, 1080, 1080, 135, 33, 135, 135, 135, 33, 1080, 135, 1080, 33, 1080, 33, 33, 135, 1080, 1080, 135, 33, 135, 33, 135, 1080, 1080, 135, 33, 135, 33, 1080, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 135, 33, 135, 1080, 135, 33, 33, 135, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 135, 1080, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 33, 135, 1080, 1080, 1080, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 33, 33, 1080, 135, 1080, 135, 1080, 135, 33, 135, 33, 33, 33, 1080, 1080, 135, 135, 33, 33, 135, 33, 1080, 33, 33, 135, 33, 1080, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 33, 135, 1080, 135, 135, 1080, 135, 33, 135, 33, 1080, 135, 135, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 135, 33, 135, 33, 135, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 135, 135, 1080, 33, 1080, 33, 33, 33, 1080, 135, 1080, 1080, 33, 135, 135, 135, 33, 135, 33, 135, 135, 1080, 33, 33, 135, 33, 135, 135, 33, 1080, 1080, 1080, 33, 135, 135, 135, 135, 33, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 135, 135, 135, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 133503 . Total input tokens: 29742321 . Total output tokens: 26714906
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.545474401966203,
    "estimated_duration": 3600.0366081752954,
    "input_throughput": 3089.430805993192,
    "output_throughput": 2705.471932669231,
    "total_throughput": 5794.902738662423,
    "itl": 74.4334783227113,
    "ttft": 18363.424496904805,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4811,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.736062806191404,
    "arrivals": 44803,
    "finished_requests": 44575,
    "scheduler_time": 30.764243921114893
}
#Debug simulation 
Total elapsed time: 3.5455647989874706. Arrivals time: 0.11815307260258123 Scheduler time: 3.0980400482658297 Scheduler overhead time: 0.05771207017824054 Adapter cache time: 0.1869737335946411 Engine time: 0.05763586616376415 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_320_slots_160_rate_0.1-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_320_slots_160_rate_0.1-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [106 107 107]
Adapter prompts. [135, 1080, 1080, 33, 1080, 1080, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 1080, 1080, 135, 33, 33, 135, 1080, 1080, 135, 135, 33, 33, 135, 1080, 1080, 33, 1080, 135, 33, 135, 1080, 33, 135, 1080, 1080, 135, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 135, 33, 1080, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 1080, 135, 33, 33, 135, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 33, 1080, 135, 1080, 1080, 135, 33, 135, 135, 135, 33, 1080, 135, 1080, 33, 1080, 33, 33, 135, 1080, 1080, 135, 33, 135, 33, 135, 1080, 1080, 135, 33, 135, 33, 1080, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 135, 33, 135, 1080, 135, 33, 33, 135, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 135, 1080, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 33, 135, 1080, 1080, 1080, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 33, 33, 1080, 135, 1080, 135, 1080, 135, 33, 135, 33, 33, 33, 1080, 1080, 135, 135, 33, 33, 135, 33, 1080, 33, 33, 135, 33, 1080, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 33, 135, 1080, 135, 135, 1080, 135, 33, 135, 33, 1080, 135, 135, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 135, 33, 135, 33, 135, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 135, 135, 1080, 33, 1080, 33, 33, 33, 1080, 135, 1080, 1080, 33, 135, 135, 135, 33, 135, 33, 135, 135, 1080, 33, 33, 135, 33, 135, 135, 33, 1080, 1080, 1080, 33, 135, 135, 135, 135, 33, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 135, 135, 135, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 133503 . Total input tokens: 29742321 . Total output tokens: 26714906
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 3.545284373976756,
    "estimated_duration": 3600.0456594387088,
    "input_throughput": 3089.6155360802213,
    "output_throughput": 2706.069567328458,
    "total_throughput": 5795.685103408679,
    "itl": 73.2911968854661,
    "ttft": 17959.506031397894,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4786,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.93757452520899,
    "arrivals": 44803,
    "finished_requests": 44580,
    "scheduler_time": 30.628111320338526
}
#Debug simulation 
Total elapsed time: 3.5453727489802986. Arrivals time: 0.11488108121557161 Scheduler time: 3.0980848525068723 Scheduler overhead time: 0.05825241201091558 Adapter cache time: 0.1887288048164919 Engine time: 0.058146169409155846 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_320_slots_160_rate_0.1-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_320_slots_160_rate_0.1-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [106 107 107]
Adapter prompts. [135, 1080, 1080, 33, 1080, 1080, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 1080, 1080, 135, 33, 33, 135, 1080, 1080, 135, 135, 33, 33, 135, 1080, 1080, 33, 1080, 135, 33, 135, 1080, 33, 135, 1080, 1080, 135, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 135, 33, 1080, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 1080, 135, 33, 33, 135, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 33, 1080, 135, 1080, 1080, 135, 33, 135, 135, 135, 33, 1080, 135, 1080, 33, 1080, 33, 33, 135, 1080, 1080, 135, 33, 135, 33, 135, 1080, 1080, 135, 33, 135, 33, 1080, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 135, 33, 135, 1080, 135, 33, 33, 135, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 135, 1080, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 33, 135, 1080, 1080, 1080, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 33, 33, 1080, 135, 1080, 135, 1080, 135, 33, 135, 33, 33, 33, 1080, 1080, 135, 135, 33, 33, 135, 33, 1080, 33, 33, 135, 33, 1080, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 33, 135, 1080, 135, 135, 1080, 135, 33, 135, 33, 1080, 135, 135, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 135, 33, 135, 33, 135, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 135, 135, 1080, 33, 1080, 33, 33, 33, 1080, 135, 1080, 1080, 33, 135, 135, 135, 33, 135, 33, 135, 135, 1080, 33, 33, 135, 33, 135, 135, 33, 1080, 1080, 1080, 33, 135, 135, 135, 135, 33, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 135, 135, 135, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 133503 . Total input tokens: 29742321 . Total output tokens: 26714906
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 3.51701678102836,
    "estimated_duration": 3600.0345230005337,
    "input_throughput": 3089.43259542135,
    "output_throughput": 2705.4734997047017,
    "total_throughput": 5794.906095126052,
    "itl": 74.45340141760374,
    "ttft": 18363.485469022686,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4812,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.95439680738249,
    "arrivals": 44803,
    "finished_requests": 44575,
    "scheduler_time": 30.76658919807516
}
#Debug simulation 
Total elapsed time: 3.517106142011471. Arrivals time: 0.11480467737419531 Scheduler time: 3.073244691709988 Scheduler overhead time: 0.057914833654649556 Adapter cache time: 0.18635229620849714 Engine time: 0.05782480083871633 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_320_slots_160_rate_0.1-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_320_slots_160_rate_0.1-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [106 107 107]
Adapter prompts. [135, 1080, 1080, 33, 1080, 1080, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 1080, 1080, 135, 33, 33, 135, 1080, 1080, 135, 135, 33, 33, 135, 1080, 1080, 33, 1080, 135, 33, 135, 1080, 33, 135, 1080, 1080, 135, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 135, 33, 1080, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 1080, 135, 33, 33, 135, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 33, 1080, 135, 1080, 1080, 135, 33, 135, 135, 135, 33, 1080, 135, 1080, 33, 1080, 33, 33, 135, 1080, 1080, 135, 33, 135, 33, 135, 1080, 1080, 135, 33, 135, 33, 1080, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 135, 33, 135, 1080, 135, 33, 33, 135, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 135, 1080, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 33, 135, 1080, 1080, 1080, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 33, 33, 1080, 135, 1080, 135, 1080, 135, 33, 135, 33, 33, 33, 1080, 1080, 135, 135, 33, 33, 135, 33, 1080, 33, 33, 135, 33, 1080, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 33, 135, 1080, 135, 135, 1080, 135, 33, 135, 33, 1080, 135, 135, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 135, 33, 135, 33, 135, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 135, 135, 1080, 33, 1080, 33, 33, 33, 1080, 135, 1080, 1080, 33, 135, 135, 135, 33, 135, 33, 135, 135, 1080, 33, 33, 135, 33, 135, 135, 33, 1080, 1080, 1080, 33, 135, 135, 135, 135, 33, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 135, 135, 135, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 133503 . Total input tokens: 29742321 . Total output tokens: 26714906
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.512359827000182,
    "estimated_duration": 3600.0223230261913,
    "input_throughput": 3089.6355638845516,
    "output_throughput": 2706.0871088740537,
    "total_throughput": 5795.722672758605,
    "itl": 73.23725315428385,
    "ttft": 17959.56095308115,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4783,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.301410560518505,
    "arrivals": 44803,
    "finished_requests": 44580,
    "scheduler_time": 30.6216400946111
}
#Debug simulation 
Total elapsed time: 3.5124526729923673. Arrivals time: 0.11655434378189966 Scheduler time: 3.063231950683985 Scheduler overhead time: 0.05873888626229018 Adapter cache time: 0.18869791604811326 Engine time: 0.057868267176672816 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_320_slots_160_rate_0.1-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_320_slots_160_rate_0.1-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [106 107 107]
Adapter prompts. [135, 1080, 1080, 33, 1080, 1080, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 1080, 1080, 135, 33, 33, 135, 1080, 1080, 135, 135, 33, 33, 135, 1080, 1080, 33, 1080, 135, 33, 135, 1080, 33, 135, 1080, 1080, 135, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 135, 33, 1080, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 1080, 135, 33, 33, 135, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 33, 1080, 135, 1080, 1080, 135, 33, 135, 135, 135, 33, 1080, 135, 1080, 33, 1080, 33, 33, 135, 1080, 1080, 135, 33, 135, 33, 135, 1080, 1080, 135, 33, 135, 33, 1080, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 135, 33, 135, 1080, 135, 33, 33, 135, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 135, 1080, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 33, 135, 1080, 1080, 1080, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 33, 33, 1080, 135, 1080, 135, 1080, 135, 33, 135, 33, 33, 33, 1080, 1080, 135, 135, 33, 33, 135, 33, 1080, 33, 33, 135, 33, 1080, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 33, 135, 1080, 135, 135, 1080, 135, 33, 135, 33, 1080, 135, 135, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 135, 33, 135, 33, 135, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 135, 135, 1080, 33, 1080, 33, 33, 33, 1080, 135, 1080, 1080, 33, 135, 135, 135, 33, 135, 33, 135, 135, 1080, 33, 33, 135, 33, 135, 135, 33, 1080, 1080, 1080, 33, 135, 135, 135, 135, 33, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 135, 135, 135, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 133503 . Total input tokens: 29742321 . Total output tokens: 26714906
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.528792305965908,
    "estimated_duration": 3600.035337812483,
    "input_throughput": 3089.431896176382,
    "output_throughput": 2705.472887362897,
    "total_throughput": 5794.9047835392785,
    "itl": 74.46656454376067,
    "ttft": 18363.699052925444,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4809,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.136869295275567,
    "arrivals": 44803,
    "finished_requests": 44575,
    "scheduler_time": 30.76805409126101
}
#Debug simulation 
Total elapsed time: 3.528902283986099. Arrivals time: 0.1134370559011586 Scheduler time: 3.0870705040870234 Scheduler overhead time: 0.05788929230766371 Adapter cache time: 0.18669857061468065 Engine time: 0.05696224549319595 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_320_slots_160_rate_0.1-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_320_slots_160_rate_0.1-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [106 107 107]
Adapter prompts. [66, 1080, 1080, 33, 1080, 1080, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 1080, 1080, 66, 33, 33, 66, 1080, 1080, 66, 66, 33, 33, 66, 1080, 1080, 33, 1080, 66, 33, 66, 1080, 33, 66, 1080, 1080, 66, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 66, 33, 1080, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 1080, 66, 33, 33, 66, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 33, 1080, 66, 1080, 1080, 66, 33, 66, 66, 66, 33, 1080, 66, 1080, 33, 1080, 33, 33, 66, 1080, 1080, 66, 33, 66, 33, 66, 1080, 1080, 66, 33, 66, 33, 1080, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 66, 33, 66, 1080, 66, 33, 33, 66, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 66, 1080, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 33, 66, 1080, 1080, 1080, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 33, 33, 1080, 66, 1080, 66, 1080, 66, 33, 66, 33, 33, 33, 1080, 1080, 66, 66, 33, 33, 66, 33, 1080, 33, 33, 66, 33, 1080, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 33, 66, 1080, 66, 66, 1080, 66, 33, 66, 33, 1080, 66, 66, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 66, 33, 66, 33, 66, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 66, 66, 1080, 33, 1080, 33, 33, 33, 1080, 66, 1080, 1080, 33, 66, 66, 66, 33, 66, 33, 66, 66, 1080, 33, 33, 66, 33, 66, 66, 33, 1080, 1080, 1080, 33, 66, 66, 66, 66, 33, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 66, 66, 66, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 126120 . Total input tokens: 28098161 . Total output tokens: 25213446
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.382279123994522,
    "estimated_duration": 3600.052388943888,
    "input_throughput": 2934.9856220008155,
    "output_throughput": 2581.0824388380393,
    "total_throughput": 5516.068060838855,
    "itl": 57.10602026052774,
    "ttft": 11062.53317943808,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2791,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.541821293316419,
    "arrivals": 42341,
    "finished_requests": 42212,
    "scheduler_time": 26.264298817290502
}
#Debug simulation 
Total elapsed time: 3.382394854037557. Arrivals time: 0.11037986207520589 Scheduler time: 2.9106966427061707 Scheduler overhead time: 0.06965472421143204 Adapter cache time: 0.19043601414887235 Engine time: 0.06854542170185596 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_320_slots_160_rate_0.1-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_320_slots_160_rate_0.1-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [106 107 107]
Adapter prompts. [66, 1080, 1080, 33, 1080, 1080, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 1080, 1080, 66, 33, 33, 66, 1080, 1080, 66, 66, 33, 33, 66, 1080, 1080, 33, 1080, 66, 33, 66, 1080, 33, 66, 1080, 1080, 66, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 66, 33, 1080, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 1080, 66, 33, 33, 66, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 33, 1080, 66, 1080, 1080, 66, 33, 66, 66, 66, 33, 1080, 66, 1080, 33, 1080, 33, 33, 66, 1080, 1080, 66, 33, 66, 33, 66, 1080, 1080, 66, 33, 66, 33, 1080, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 66, 33, 66, 1080, 66, 33, 33, 66, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 66, 1080, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 33, 66, 1080, 1080, 1080, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 33, 33, 1080, 66, 1080, 66, 1080, 66, 33, 66, 33, 33, 33, 1080, 1080, 66, 66, 33, 33, 66, 33, 1080, 33, 33, 66, 33, 1080, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 33, 66, 1080, 66, 66, 1080, 66, 33, 66, 33, 1080, 66, 66, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 66, 33, 66, 33, 66, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 66, 66, 1080, 33, 1080, 33, 33, 33, 1080, 66, 1080, 1080, 33, 66, 66, 66, 33, 66, 33, 66, 66, 1080, 33, 33, 66, 33, 66, 66, 33, 1080, 1080, 1080, 33, 66, 66, 66, 66, 33, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 66, 66, 66, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 126120 . Total input tokens: 28098161 . Total output tokens: 25213446
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.4225130879785866,
    "estimated_duration": 3600.010769907289,
    "input_throughput": 2934.9189975540266,
    "output_throughput": 2581.0381117941183,
    "total_throughput": 5515.9571093481445,
    "itl": 57.13322977056514,
    "ttft": 11062.932355118297,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2791,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.110937999829032,
    "arrivals": 42341,
    "finished_requests": 42211,
    "scheduler_time": 26.269508799565084
}
#Debug simulation 
Total elapsed time: 3.422606687003281. Arrivals time: 0.11188876419328153 Scheduler time: 2.946503002254758 Scheduler overhead time: 0.06995060783810914 Adapter cache time: 0.19092121231369674 Engine time: 0.0706950479070656 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_320_slots_160_rate_0.1-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_320_slots_160_rate_0.1-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [106 107 107]
Adapter prompts. [66, 1080, 1080, 33, 1080, 1080, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 1080, 1080, 66, 33, 33, 66, 1080, 1080, 66, 66, 33, 33, 66, 1080, 1080, 33, 1080, 66, 33, 66, 1080, 33, 66, 1080, 1080, 66, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 66, 33, 1080, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 1080, 66, 33, 33, 66, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 33, 1080, 66, 1080, 1080, 66, 33, 66, 66, 66, 33, 1080, 66, 1080, 33, 1080, 33, 33, 66, 1080, 1080, 66, 33, 66, 33, 66, 1080, 1080, 66, 33, 66, 33, 1080, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 66, 33, 66, 1080, 66, 33, 33, 66, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 66, 1080, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 33, 66, 1080, 1080, 1080, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 33, 33, 1080, 66, 1080, 66, 1080, 66, 33, 66, 33, 33, 33, 1080, 1080, 66, 66, 33, 33, 66, 33, 1080, 33, 33, 66, 33, 1080, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 33, 66, 1080, 66, 66, 1080, 66, 33, 66, 33, 1080, 66, 66, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 66, 33, 66, 33, 66, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 66, 66, 1080, 33, 1080, 33, 33, 33, 1080, 66, 1080, 1080, 33, 66, 66, 66, 33, 66, 33, 66, 66, 1080, 33, 33, 66, 33, 66, 66, 33, 1080, 1080, 1080, 33, 66, 66, 66, 66, 33, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 66, 66, 66, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 126120 . Total input tokens: 28098161 . Total output tokens: 25213446
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.3529935789993033,
    "estimated_duration": 3600.0511437352548,
    "input_throughput": 2934.986637172348,
    "output_throughput": 2581.0833315992827,
    "total_throughput": 5516.069968771631,
    "itl": 57.13394470607588,
    "ttft": 11062.602867404998,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2790,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.123082145321877,
    "arrivals": 42341,
    "finished_requests": 42212,
    "scheduler_time": 26.27011477991682
}
#Debug simulation 
Total elapsed time: 3.353120052954182. Arrivals time: 0.10934964974876493 Scheduler time: 2.884783045388758 Scheduler overhead time: 0.0689803107525222 Adapter cache time: 0.18979803653201088 Engine time: 0.06753812992246822 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_320_slots_160_rate_0.1-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_320_slots_160_rate_0.1-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [106 107 107]
Adapter prompts. [66, 1080, 1080, 33, 1080, 1080, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 1080, 1080, 66, 33, 33, 66, 1080, 1080, 66, 66, 33, 33, 66, 1080, 1080, 33, 1080, 66, 33, 66, 1080, 33, 66, 1080, 1080, 66, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 66, 33, 1080, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 1080, 66, 33, 33, 66, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 33, 1080, 66, 1080, 1080, 66, 33, 66, 66, 66, 33, 1080, 66, 1080, 33, 1080, 33, 33, 66, 1080, 1080, 66, 33, 66, 33, 66, 1080, 1080, 66, 33, 66, 33, 1080, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 66, 33, 66, 1080, 66, 33, 33, 66, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 66, 1080, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 33, 66, 1080, 1080, 1080, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 33, 33, 1080, 66, 1080, 66, 1080, 66, 33, 66, 33, 33, 33, 1080, 1080, 66, 66, 33, 33, 66, 33, 1080, 33, 33, 66, 33, 1080, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 33, 66, 1080, 66, 66, 1080, 66, 33, 66, 33, 1080, 66, 66, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 66, 33, 66, 33, 66, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 66, 66, 1080, 33, 1080, 33, 33, 33, 1080, 66, 1080, 1080, 33, 66, 66, 66, 33, 66, 33, 66, 66, 1080, 33, 33, 66, 33, 66, 66, 33, 1080, 1080, 1080, 33, 66, 66, 66, 66, 33, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 66, 66, 66, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 126120 . Total input tokens: 28098161 . Total output tokens: 25213446
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 3.3653696340043098,
    "estimated_duration": 3600.026264327014,
    "input_throughput": 2934.9063657387373,
    "output_throughput": 2581.027003072989,
    "total_throughput": 5515.933368811727,
    "itl": 57.29616229584124,
    "ttft": 11063.163675617005,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2791,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.707654420528424,
    "arrivals": 42341,
    "finished_requests": 42211,
    "scheduler_time": 26.303299102864635
}
#Debug simulation 
Total elapsed time: 3.365456876985263. Arrivals time: 0.1110062338411808 Scheduler time: 2.895402989408467 Scheduler overhead time: 0.06868711090646684 Adapter cache time: 0.18917426222469658 Engine time: 0.06869423494208604 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_320_slots_160_rate_0.1-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_320_slots_160_rate_0.1-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [106 107 107]
Adapter prompts. [66, 1080, 1080, 33, 1080, 1080, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 1080, 1080, 66, 33, 33, 66, 1080, 1080, 66, 66, 33, 33, 66, 1080, 1080, 33, 1080, 66, 33, 66, 1080, 33, 66, 1080, 1080, 66, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 66, 33, 1080, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 1080, 66, 33, 33, 66, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 33, 1080, 66, 1080, 1080, 66, 33, 66, 66, 66, 33, 1080, 66, 1080, 33, 1080, 33, 33, 66, 1080, 1080, 66, 33, 66, 33, 66, 1080, 1080, 66, 33, 66, 33, 1080, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 66, 33, 66, 1080, 66, 33, 33, 66, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 66, 1080, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 33, 66, 1080, 1080, 1080, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 33, 33, 1080, 66, 1080, 66, 1080, 66, 33, 66, 33, 33, 33, 1080, 1080, 66, 66, 33, 33, 66, 33, 1080, 33, 33, 66, 33, 1080, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 33, 66, 1080, 66, 66, 1080, 66, 33, 66, 33, 1080, 66, 66, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 66, 33, 66, 33, 66, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 66, 66, 1080, 33, 1080, 33, 33, 33, 1080, 66, 1080, 1080, 33, 66, 66, 66, 33, 66, 33, 66, 66, 1080, 33, 33, 66, 33, 66, 66, 33, 1080, 1080, 1080, 33, 66, 66, 66, 66, 33, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 66, 66, 66, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 126120 . Total input tokens: 28098161 . Total output tokens: 25213446
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 3.4165416969917715,
    "estimated_duration": 3600.000591343855,
    "input_throughput": 2934.8900734641084,
    "output_throughput": 2581.0448538097185,
    "total_throughput": 5515.934927273827,
    "itl": 57.13998844955697,
    "ttft": 11147.961953341628,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2789,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.2441576136645,
    "arrivals": 42341,
    "finished_requests": 42210,
    "scheduler_time": 26.270770099960746
}
#Debug simulation 
Total elapsed time: 3.416662446979899. Arrivals time: 0.11149971827398986 Scheduler time: 2.9419151985202916 Scheduler overhead time: 0.06971064978279173 Adapter cache time: 0.19088195642689243 Engine time: 0.06976085831411183 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_320_slots_160_rate_0.1-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_320_slots_160_rate_0.1-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [106 107 107]
Adapter prompts. [66, 1080, 1080, 33, 1080, 1080, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 1080, 1080, 66, 33, 33, 66, 1080, 1080, 66, 66, 33, 33, 66, 1080, 1080, 33, 1080, 66, 33, 66, 1080, 33, 66, 1080, 1080, 66, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 66, 33, 1080, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 1080, 66, 33, 33, 66, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 33, 1080, 66, 1080, 1080, 66, 33, 66, 66, 66, 33, 1080, 66, 1080, 33, 1080, 33, 33, 66, 1080, 1080, 66, 33, 66, 33, 66, 1080, 1080, 66, 33, 66, 33, 1080, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 66, 33, 66, 1080, 66, 33, 33, 66, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 66, 1080, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 33, 66, 1080, 1080, 1080, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 33, 33, 1080, 66, 1080, 66, 1080, 66, 33, 66, 33, 33, 33, 1080, 1080, 66, 66, 33, 33, 66, 33, 1080, 33, 33, 66, 33, 1080, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 33, 66, 1080, 66, 66, 1080, 66, 33, 66, 33, 1080, 66, 66, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 66, 33, 66, 33, 66, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 66, 66, 1080, 33, 1080, 33, 33, 33, 1080, 66, 1080, 1080, 33, 66, 66, 66, 33, 66, 33, 66, 66, 1080, 33, 33, 66, 33, 66, 66, 33, 1080, 1080, 1080, 33, 66, 66, 66, 66, 33, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 66, 66, 66, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 126120 . Total input tokens: 28098161 . Total output tokens: 25213446
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.433120023983065,
    "estimated_duration": 3600.03329321122,
    "input_throughput": 2935.0011901070684,
    "output_throughput": 2581.096129728159,
    "total_throughput": 5516.097319835228,
    "itl": 57.09644624031235,
    "ttft": 10977.85988049701,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2791,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.345230373071814,
    "arrivals": 42341,
    "finished_requests": 42212,
    "scheduler_time": 26.262393315224376
}
#Debug simulation 
Total elapsed time: 3.4332329989993013. Arrivals time: 0.11138764588395134 Scheduler time: 2.957497948897071 Scheduler overhead time: 0.07013087579980493 Adapter cache time: 0.1916712921229191 Engine time: 0.0695615757140331 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_320_slots_160_rate_0.1-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_320_slots_160_rate_0.1-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [106 107 107]
Adapter prompts. [66, 1080, 1080, 33, 1080, 1080, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 1080, 1080, 66, 33, 33, 66, 1080, 1080, 66, 66, 33, 33, 66, 1080, 1080, 33, 1080, 66, 33, 66, 1080, 33, 66, 1080, 1080, 66, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 66, 33, 1080, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 1080, 66, 33, 33, 66, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 33, 1080, 66, 1080, 1080, 66, 33, 66, 66, 66, 33, 1080, 66, 1080, 33, 1080, 33, 33, 66, 1080, 1080, 66, 33, 66, 33, 66, 1080, 1080, 66, 33, 66, 33, 1080, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 66, 33, 66, 1080, 66, 33, 33, 66, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 66, 1080, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 33, 66, 1080, 1080, 1080, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 33, 33, 1080, 66, 1080, 66, 1080, 66, 33, 66, 33, 33, 33, 1080, 1080, 66, 66, 33, 33, 66, 33, 1080, 33, 33, 66, 33, 1080, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 33, 66, 1080, 66, 66, 1080, 66, 33, 66, 33, 1080, 66, 66, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 66, 33, 66, 33, 66, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 66, 66, 1080, 33, 1080, 33, 33, 33, 1080, 66, 1080, 1080, 33, 66, 66, 66, 33, 66, 33, 66, 66, 1080, 33, 33, 66, 33, 66, 66, 33, 1080, 1080, 1080, 33, 66, 66, 66, 66, 33, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 66, 66, 66, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 126120 . Total input tokens: 28098161 . Total output tokens: 25213446
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.386698920978233,
    "estimated_duration": 3600.004467191164,
    "input_throughput": 2934.8869136941976,
    "output_throughput": 2581.04207499768,
    "total_throughput": 5515.928988691878,
    "itl": 57.146223549411594,
    "ttft": 11148.083323273513,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2791,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.362125507406423,
    "arrivals": 42341,
    "finished_requests": 42210,
    "scheduler_time": 26.271987089532537
}
#Debug simulation 
Total elapsed time: 3.386787939001806. Arrivals time: 0.1112181194475852 Scheduler time: 2.914338381786365 Scheduler overhead time: 0.06943374942056835 Adapter cache time: 0.1896215610904619 Engine time: 0.06953731417888775 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_320_slots_160_rate_0.05-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_320_slots_160_rate_0.05-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 135, 540, 540, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 540, 270, 540, 540, 135, 540, 270, 270, 540, 540, 270, 135, 135, 270, 540, 540, 270, 270, 135, 135, 270, 540, 540, 135, 540, 270, 135, 270, 540, 135, 270, 540, 540, 270, 135, 135, 540, 135, 135, 540, 540, 135, 135, 270, 270, 270, 135, 270, 135, 540, 135, 540, 270, 540, 540, 135, 540, 135, 540, 270, 135, 135, 270, 270, 540, 270, 540, 540, 540, 135, 270, 270, 135, 540, 270, 540, 540, 270, 135, 270, 270, 270, 135, 540, 270, 540, 135, 540, 135, 135, 270, 540, 540, 270, 135, 270, 135, 270, 540, 540, 270, 135, 270, 135, 540, 135, 135, 135, 135, 540, 270, 270, 540, 270, 270, 135, 270, 540, 270, 135, 135, 270, 540, 135, 135, 135, 540, 540, 540, 135, 270, 540, 270, 270, 270, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 135, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 135, 135, 540, 270, 540, 270, 540, 270, 135, 270, 135, 135, 135, 540, 540, 270, 270, 135, 135, 270, 135, 540, 135, 135, 270, 135, 540, 270, 135, 540, 135, 135, 540, 270, 540, 270, 135, 270, 540, 270, 270, 540, 270, 135, 270, 135, 540, 270, 270, 540, 540, 135, 135, 135, 540, 540, 135, 135, 540, 270, 135, 270, 135, 270, 540, 540, 540, 135, 540, 540, 540, 540, 135, 270, 270, 540, 135, 540, 135, 135, 135, 540, 270, 540, 540, 135, 270, 270, 270, 135, 270, 135, 270, 270, 540, 135, 135, 270, 135, 270, 270, 135, 540, 540, 540, 135, 270, 270, 270, 270, 135, 270, 135, 540, 135, 135, 540, 270, 540, 270, 270, 270, 270, 135, 135, 540, 135, 135, 540, 540, 540, 135, 540, 540, 270, 540, 270, 135, 540, 135, 540, 540, 135, 135, 135]
Prompts retrieved: 100980 . Total input tokens: 22497641 . Total output tokens: 20173181
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 2.9759599690441974,
    "estimated_duration": 3600.013615144406,
    "input_throughput": 2318.3837319085283,
    "output_throughput": 2071.541332129339,
    "total_throughput": 4389.925064037868,
    "itl": 50.66817130860954,
    "ttft": 10288.464414675047,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13563,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 41.50939527095539,
    "arrivals": 33871,
    "finished_requests": 33774,
    "scheduler_time": 17.14376300692984
}
#Debug simulation 
Total elapsed time: 2.97604823904112. Arrivals time: 0.0936902747489512 Scheduler time: 2.3874849076964892 Scheduler overhead time: 0.07572800060734153 Adapter cache time: 0.3092661193222739 Engine time: 0.07391755125718191 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_320_slots_160_rate_0.05-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_320_slots_160_rate_0.05-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 135, 540, 540, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 540, 270, 540, 540, 135, 540, 270, 270, 540, 540, 270, 135, 135, 270, 540, 540, 270, 270, 135, 135, 270, 540, 540, 135, 540, 270, 135, 270, 540, 135, 270, 540, 540, 270, 135, 135, 540, 135, 135, 540, 540, 135, 135, 270, 270, 270, 135, 270, 135, 540, 135, 540, 270, 540, 540, 135, 540, 135, 540, 270, 135, 135, 270, 270, 540, 270, 540, 540, 540, 135, 270, 270, 135, 540, 270, 540, 540, 270, 135, 270, 270, 270, 135, 540, 270, 540, 135, 540, 135, 135, 270, 540, 540, 270, 135, 270, 135, 270, 540, 540, 270, 135, 270, 135, 540, 135, 135, 135, 135, 540, 270, 270, 540, 270, 270, 135, 270, 540, 270, 135, 135, 270, 540, 135, 135, 135, 540, 540, 540, 135, 270, 540, 270, 270, 270, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 135, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 135, 135, 540, 270, 540, 270, 540, 270, 135, 270, 135, 135, 135, 540, 540, 270, 270, 135, 135, 270, 135, 540, 135, 135, 270, 135, 540, 270, 135, 540, 135, 135, 540, 270, 540, 270, 135, 270, 540, 270, 270, 540, 270, 135, 270, 135, 540, 270, 270, 540, 540, 135, 135, 135, 540, 540, 135, 135, 540, 270, 135, 270, 135, 270, 540, 540, 540, 135, 540, 540, 540, 540, 135, 270, 270, 540, 135, 540, 135, 135, 135, 540, 270, 540, 540, 135, 270, 270, 270, 135, 270, 135, 270, 270, 540, 135, 135, 270, 135, 270, 270, 135, 540, 540, 540, 135, 270, 270, 270, 270, 135, 270, 135, 540, 135, 135, 540, 270, 540, 270, 270, 270, 270, 135, 135, 540, 135, 135, 540, 540, 540, 135, 540, 540, 270, 540, 270, 135, 540, 135, 540, 540, 135, 135, 135]
Prompts retrieved: 100980 . Total input tokens: 22497641 . Total output tokens: 20173181
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 2.95952038501855,
    "estimated_duration": 3600.0482787858664,
    "input_throughput": 2318.3614089794373,
    "output_throughput": 2071.52138596183,
    "total_throughput": 4389.882794941268,
    "itl": 50.80885245292159,
    "ttft": 10394.84169467399,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13556,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 44.243167289136395,
    "arrivals": 33871,
    "finished_requests": 33774,
    "scheduler_time": 17.179085519632643
}
#Debug simulation 
Total elapsed time: 2.9596120180212893. Arrivals time: 0.09455777588300407 Scheduler time: 2.3723703739233315 Scheduler overhead time: 0.07603505131555721 Adapter cache time: 0.3065870309364982 Engine time: 0.07422864343971014 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_320_slots_160_rate_0.05-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_320_slots_160_rate_0.05-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 135, 540, 540, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 540, 270, 540, 540, 135, 540, 270, 270, 540, 540, 270, 135, 135, 270, 540, 540, 270, 270, 135, 135, 270, 540, 540, 135, 540, 270, 135, 270, 540, 135, 270, 540, 540, 270, 135, 135, 540, 135, 135, 540, 540, 135, 135, 270, 270, 270, 135, 270, 135, 540, 135, 540, 270, 540, 540, 135, 540, 135, 540, 270, 135, 135, 270, 270, 540, 270, 540, 540, 540, 135, 270, 270, 135, 540, 270, 540, 540, 270, 135, 270, 270, 270, 135, 540, 270, 540, 135, 540, 135, 135, 270, 540, 540, 270, 135, 270, 135, 270, 540, 540, 270, 135, 270, 135, 540, 135, 135, 135, 135, 540, 270, 270, 540, 270, 270, 135, 270, 540, 270, 135, 135, 270, 540, 135, 135, 135, 540, 540, 540, 135, 270, 540, 270, 270, 270, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 135, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 135, 135, 540, 270, 540, 270, 540, 270, 135, 270, 135, 135, 135, 540, 540, 270, 270, 135, 135, 270, 135, 540, 135, 135, 270, 135, 540, 270, 135, 540, 135, 135, 540, 270, 540, 270, 135, 270, 540, 270, 270, 540, 270, 135, 270, 135, 540, 270, 270, 540, 540, 135, 135, 135, 540, 540, 135, 135, 540, 270, 135, 270, 135, 270, 540, 540, 540, 135, 540, 540, 540, 540, 135, 270, 270, 540, 135, 540, 135, 135, 135, 540, 270, 540, 540, 135, 270, 270, 270, 135, 270, 135, 270, 270, 540, 135, 135, 270, 135, 270, 270, 135, 540, 540, 540, 135, 270, 270, 270, 270, 135, 270, 135, 540, 135, 135, 540, 270, 540, 270, 270, 270, 270, 135, 135, 540, 135, 135, 540, 540, 540, 135, 540, 540, 270, 540, 270, 135, 540, 135, 540, 540, 135, 135, 135]
Prompts retrieved: 100980 . Total input tokens: 22497641 . Total output tokens: 20173181
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 2.9387495029950514,
    "estimated_duration": 3600.027805150987,
    "input_throughput": 2318.3745936789937,
    "output_throughput": 2071.5331668632,
    "total_throughput": 4389.9077605421935,
    "itl": 50.81277396875902,
    "ttft": 10288.645908027285,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13560,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 44.33400907712885,
    "arrivals": 33871,
    "finished_requests": 33774,
    "scheduler_time": 17.18009622399441
}
#Debug simulation 
Total elapsed time: 2.9389015680062585. Arrivals time: 0.09346104989526793 Scheduler time: 2.3566595843294635 Scheduler overhead time: 0.07521294668549672 Adapter cache time: 0.30483328783884645 Engine time: 0.07315961021231487 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_320_slots_160_rate_0.05-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_320_slots_160_rate_0.05-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 135, 540, 540, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 540, 270, 540, 540, 135, 540, 270, 270, 540, 540, 270, 135, 135, 270, 540, 540, 270, 270, 135, 135, 270, 540, 540, 135, 540, 270, 135, 270, 540, 135, 270, 540, 540, 270, 135, 135, 540, 135, 135, 540, 540, 135, 135, 270, 270, 270, 135, 270, 135, 540, 135, 540, 270, 540, 540, 135, 540, 135, 540, 270, 135, 135, 270, 270, 540, 270, 540, 540, 540, 135, 270, 270, 135, 540, 270, 540, 540, 270, 135, 270, 270, 270, 135, 540, 270, 540, 135, 540, 135, 135, 270, 540, 540, 270, 135, 270, 135, 270, 540, 540, 270, 135, 270, 135, 540, 135, 135, 135, 135, 540, 270, 270, 540, 270, 270, 135, 270, 540, 270, 135, 135, 270, 540, 135, 135, 135, 540, 540, 540, 135, 270, 540, 270, 270, 270, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 135, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 135, 135, 540, 270, 540, 270, 540, 270, 135, 270, 135, 135, 135, 540, 540, 270, 270, 135, 135, 270, 135, 540, 135, 135, 270, 135, 540, 270, 135, 540, 135, 135, 540, 270, 540, 270, 135, 270, 540, 270, 270, 540, 270, 135, 270, 135, 540, 270, 270, 540, 540, 135, 135, 135, 540, 540, 135, 135, 540, 270, 135, 270, 135, 270, 540, 540, 540, 135, 540, 540, 540, 540, 135, 270, 270, 540, 135, 540, 135, 135, 135, 540, 270, 540, 540, 135, 270, 270, 270, 135, 270, 135, 270, 270, 540, 135, 135, 270, 135, 270, 270, 135, 540, 540, 540, 135, 270, 270, 270, 270, 135, 270, 135, 540, 135, 135, 540, 270, 540, 270, 270, 270, 270, 135, 135, 540, 135, 135, 540, 540, 540, 135, 540, 540, 270, 540, 270, 135, 540, 135, 540, 540, 135, 135, 135]
Prompts retrieved: 100980 . Total input tokens: 22497641 . Total output tokens: 20173181
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 2.9418391829822212,
    "estimated_duration": 3600.0244210502306,
    "input_throughput": 2318.3767730012146,
    "output_throughput": 2071.535114149145,
    "total_throughput": 4389.91188715036,
    "itl": 50.71192098983619,
    "ttft": 10288.454579246009,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13557,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 42.38296268734322,
    "arrivals": 33871,
    "finished_requests": 33774,
    "scheduler_time": 17.15502089446593
}
#Debug simulation 
Total elapsed time: 2.9419261959847063. Arrivals time: 0.09220100240781903 Scheduler time: 2.3561563492403366 Scheduler overhead time: 0.07577515416778624 Adapter cache time: 0.30797840835293755 Engine time: 0.0737798354239203 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_320_slots_160_rate_0.05-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_320_slots_160_rate_0.05-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 135, 540, 540, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 540, 270, 540, 540, 135, 540, 270, 270, 540, 540, 270, 135, 135, 270, 540, 540, 270, 270, 135, 135, 270, 540, 540, 135, 540, 270, 135, 270, 540, 135, 270, 540, 540, 270, 135, 135, 540, 135, 135, 540, 540, 135, 135, 270, 270, 270, 135, 270, 135, 540, 135, 540, 270, 540, 540, 135, 540, 135, 540, 270, 135, 135, 270, 270, 540, 270, 540, 540, 540, 135, 270, 270, 135, 540, 270, 540, 540, 270, 135, 270, 270, 270, 135, 540, 270, 540, 135, 540, 135, 135, 270, 540, 540, 270, 135, 270, 135, 270, 540, 540, 270, 135, 270, 135, 540, 135, 135, 135, 135, 540, 270, 270, 540, 270, 270, 135, 270, 540, 270, 135, 135, 270, 540, 135, 135, 135, 540, 540, 540, 135, 270, 540, 270, 270, 270, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 135, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 135, 135, 540, 270, 540, 270, 540, 270, 135, 270, 135, 135, 135, 540, 540, 270, 270, 135, 135, 270, 135, 540, 135, 135, 270, 135, 540, 270, 135, 540, 135, 135, 540, 270, 540, 270, 135, 270, 540, 270, 270, 540, 270, 135, 270, 135, 540, 270, 270, 540, 540, 135, 135, 135, 540, 540, 135, 135, 540, 270, 135, 270, 135, 270, 540, 540, 540, 135, 540, 540, 540, 540, 135, 270, 270, 540, 135, 540, 135, 135, 135, 540, 270, 540, 540, 135, 270, 270, 270, 135, 270, 135, 270, 270, 540, 135, 135, 270, 135, 270, 270, 135, 540, 540, 540, 135, 270, 270, 270, 270, 135, 270, 135, 540, 135, 135, 540, 270, 540, 270, 270, 270, 270, 135, 135, 540, 135, 135, 540, 540, 540, 135, 540, 540, 270, 540, 270, 135, 540, 135, 540, 540, 135, 135, 135]
Prompts retrieved: 100980 . Total input tokens: 22497641 . Total output tokens: 20173181
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 3.0286141869728453,
    "estimated_duration": 3600.0281608014525,
    "input_throughput": 2318.374364644396,
    "output_throughput": 2071.532962214319,
    "total_throughput": 4389.907326858714,
    "itl": 50.84284292256616,
    "ttft": 10288.850123136526,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13554,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 44.88623574255469,
    "arrivals": 33871,
    "finished_requests": 33774,
    "scheduler_time": 17.187169069681683
}
#Debug simulation 
Total elapsed time: 3.0287020709947683. Arrivals time: 0.09421331528574228 Scheduler time: 2.4319858438684605 Scheduler overhead time: 0.07742846629116684 Adapter cache time: 0.31298412469914183 Engine time: 0.07584207825129852 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_320_slots_160_rate_0.05-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_320_slots_160_rate_0.05-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 135, 540, 540, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 540, 270, 540, 540, 135, 540, 270, 270, 540, 540, 270, 135, 135, 270, 540, 540, 270, 270, 135, 135, 270, 540, 540, 135, 540, 270, 135, 270, 540, 135, 270, 540, 540, 270, 135, 135, 540, 135, 135, 540, 540, 135, 135, 270, 270, 270, 135, 270, 135, 540, 135, 540, 270, 540, 540, 135, 540, 135, 540, 270, 135, 135, 270, 270, 540, 270, 540, 540, 540, 135, 270, 270, 135, 540, 270, 540, 540, 270, 135, 270, 270, 270, 135, 540, 270, 540, 135, 540, 135, 135, 270, 540, 540, 270, 135, 270, 135, 270, 540, 540, 270, 135, 270, 135, 540, 135, 135, 135, 135, 540, 270, 270, 540, 270, 270, 135, 270, 540, 270, 135, 135, 270, 540, 135, 135, 135, 540, 540, 540, 135, 270, 540, 270, 270, 270, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 135, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 135, 135, 540, 270, 540, 270, 540, 270, 135, 270, 135, 135, 135, 540, 540, 270, 270, 135, 135, 270, 135, 540, 135, 135, 270, 135, 540, 270, 135, 540, 135, 135, 540, 270, 540, 270, 135, 270, 540, 270, 270, 540, 270, 135, 270, 135, 540, 270, 270, 540, 540, 135, 135, 135, 540, 540, 135, 135, 540, 270, 135, 270, 135, 270, 540, 540, 540, 135, 540, 540, 540, 540, 135, 270, 270, 540, 135, 540, 135, 135, 135, 540, 270, 540, 540, 135, 270, 270, 270, 135, 270, 135, 270, 270, 540, 135, 135, 270, 135, 270, 270, 135, 540, 540, 540, 135, 270, 270, 270, 270, 135, 270, 135, 540, 135, 135, 540, 270, 540, 270, 270, 270, 270, 135, 135, 540, 135, 135, 540, 540, 540, 135, 540, 540, 270, 540, 270, 135, 540, 135, 540, 540, 135, 135, 135]
Prompts retrieved: 100980 . Total input tokens: 22497641 . Total output tokens: 20173181
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 2.959678847983014,
    "estimated_duration": 3600.013806048436,
    "input_throughput": 2318.383608967667,
    "output_throughput": 2071.541222278208,
    "total_throughput": 4389.924831245875,
    "itl": 50.615688798591364,
    "ttft": 10288.37870461204,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13558,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 40.53910189828752,
    "arrivals": 33871,
    "finished_requests": 33774,
    "scheduler_time": 17.131212853309496
}
#Debug simulation 
Total elapsed time: 2.9597669760114513. Arrivals time: 0.09249467391055077 Scheduler time: 2.374700959189795 Scheduler overhead time: 0.07612943759886548 Adapter cache time: 0.30686587939271703 Engine time: 0.07368392019998282 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_320_slots_160_rate_0.05-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_320_slots_160_rate_0.05-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 135, 540, 540, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 540, 270, 540, 540, 135, 540, 270, 270, 540, 540, 270, 135, 135, 270, 540, 540, 270, 270, 135, 135, 270, 540, 540, 135, 540, 270, 135, 270, 540, 135, 270, 540, 540, 270, 135, 135, 540, 135, 135, 540, 540, 135, 135, 270, 270, 270, 135, 270, 135, 540, 135, 540, 270, 540, 540, 135, 540, 135, 540, 270, 135, 135, 270, 270, 540, 270, 540, 540, 540, 135, 270, 270, 135, 540, 270, 540, 540, 270, 135, 270, 270, 270, 135, 540, 270, 540, 135, 540, 135, 135, 270, 540, 540, 270, 135, 270, 135, 270, 540, 540, 270, 135, 270, 135, 540, 135, 135, 135, 135, 540, 270, 270, 540, 270, 270, 135, 270, 540, 270, 135, 135, 270, 540, 135, 135, 135, 540, 540, 540, 135, 270, 540, 270, 270, 270, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 135, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 135, 135, 540, 270, 540, 270, 540, 270, 135, 270, 135, 135, 135, 540, 540, 270, 270, 135, 135, 270, 135, 540, 135, 135, 270, 135, 540, 270, 135, 540, 135, 135, 540, 270, 540, 270, 135, 270, 540, 270, 270, 540, 270, 135, 270, 135, 540, 270, 270, 540, 540, 135, 135, 135, 540, 540, 135, 135, 540, 270, 135, 270, 135, 270, 540, 540, 540, 135, 540, 540, 540, 540, 135, 270, 270, 540, 135, 540, 135, 135, 135, 540, 270, 540, 540, 135, 270, 270, 270, 135, 270, 135, 270, 270, 540, 135, 135, 270, 135, 270, 270, 135, 540, 540, 540, 135, 270, 270, 270, 270, 135, 270, 135, 540, 135, 135, 540, 270, 540, 270, 270, 270, 270, 135, 135, 540, 135, 135, 540, 540, 540, 135, 540, 540, 270, 540, 270, 135, 540, 135, 540, 540, 135, 135, 135]
Prompts retrieved: 100980 . Total input tokens: 22497641 . Total output tokens: 20173181
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.0346380369737744,
    "estimated_duration": 3600.031676727562,
    "input_throughput": 2318.372100432941,
    "output_throughput": 2071.530939077446,
    "total_throughput": 4389.903039510387,
    "itl": 50.875700097355676,
    "ttft": 10288.904628551281,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13553,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 45.451010583229845,
    "arrivals": 33871,
    "finished_requests": 33774,
    "scheduler_time": 17.1948611073369
}
#Debug simulation 
Total elapsed time: 3.0347350999945775. Arrivals time: 0.0952867396408692 Scheduler time: 2.440947861177847 Scheduler overhead time: 0.07646471366751939 Adapter cache time: 0.3115487172617577 Engine time: 0.07445799803826958 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_320_slots_160_rate_0.05-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_320_slots_160_rate_0.05-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 66, 540, 540, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 540, 270, 540, 540, 66, 540, 270, 270, 540, 540, 270, 66, 66, 270, 540, 540, 270, 270, 66, 66, 270, 540, 540, 66, 540, 270, 66, 270, 540, 66, 270, 540, 540, 270, 66, 66, 540, 66, 66, 540, 540, 66, 66, 270, 270, 270, 66, 270, 66, 540, 66, 540, 270, 540, 540, 66, 540, 66, 540, 270, 66, 66, 270, 270, 540, 270, 540, 540, 540, 66, 270, 270, 66, 540, 270, 540, 540, 270, 66, 270, 270, 270, 66, 540, 270, 540, 66, 540, 66, 66, 270, 540, 540, 270, 66, 270, 66, 270, 540, 540, 270, 66, 270, 66, 540, 66, 66, 66, 66, 540, 270, 270, 540, 270, 270, 66, 270, 540, 270, 66, 66, 270, 540, 66, 66, 66, 540, 540, 540, 66, 270, 540, 270, 270, 270, 66, 540, 66, 540, 270, 66, 270, 66, 66, 270, 66, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 66, 66, 540, 270, 540, 270, 540, 270, 66, 270, 66, 66, 66, 540, 540, 270, 270, 66, 66, 270, 66, 540, 66, 66, 270, 66, 540, 270, 66, 540, 66, 66, 540, 270, 540, 270, 66, 270, 540, 270, 270, 540, 270, 66, 270, 66, 540, 270, 270, 540, 540, 66, 66, 66, 540, 540, 66, 66, 540, 270, 66, 270, 66, 270, 540, 540, 540, 66, 540, 540, 540, 540, 66, 270, 270, 540, 66, 540, 66, 66, 66, 540, 270, 540, 540, 66, 270, 270, 270, 66, 270, 66, 270, 270, 540, 66, 66, 270, 66, 270, 270, 66, 540, 540, 540, 66, 270, 270, 270, 270, 66, 270, 66, 540, 66, 66, 540, 270, 540, 270, 270, 270, 270, 66, 66, 540, 66, 66, 540, 540, 540, 66, 540, 540, 270, 540, 270, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 93666 . Total input tokens: 20908649 . Total output tokens: 18710898
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 2.8119750460027717,
    "estimated_duration": 3599.966697587868,
    "input_throughput": 2154.2218724401723,
    "output_throughput": 1928.0961695147964,
    "total_throughput": 4082.3180419549685,
    "itl": 41.66985166103106,
    "ttft": 9223.74279288063,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10698,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 32.741097884595376,
    "arrivals": 31462,
    "finished_requests": 31382,
    "scheduler_time": 12.342224782368065
}
#Debug simulation 
Total elapsed time: 2.8120658799889497. Arrivals time: 0.08708183077396825 Scheduler time: 2.2216768338694237 Scheduler overhead time: 0.08857825573068112 Adapter cache time: 0.28850664815399796 Engine time: 0.08458363875979558 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_320_slots_160_rate_0.05-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_320_slots_160_rate_0.05-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 66, 540, 540, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 540, 270, 540, 540, 66, 540, 270, 270, 540, 540, 270, 66, 66, 270, 540, 540, 270, 270, 66, 66, 270, 540, 540, 66, 540, 270, 66, 270, 540, 66, 270, 540, 540, 270, 66, 66, 540, 66, 66, 540, 540, 66, 66, 270, 270, 270, 66, 270, 66, 540, 66, 540, 270, 540, 540, 66, 540, 66, 540, 270, 66, 66, 270, 270, 540, 270, 540, 540, 540, 66, 270, 270, 66, 540, 270, 540, 540, 270, 66, 270, 270, 270, 66, 540, 270, 540, 66, 540, 66, 66, 270, 540, 540, 270, 66, 270, 66, 270, 540, 540, 270, 66, 270, 66, 540, 66, 66, 66, 66, 540, 270, 270, 540, 270, 270, 66, 270, 540, 270, 66, 66, 270, 540, 66, 66, 66, 540, 540, 540, 66, 270, 540, 270, 270, 270, 66, 540, 66, 540, 270, 66, 270, 66, 66, 270, 66, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 66, 66, 540, 270, 540, 270, 540, 270, 66, 270, 66, 66, 66, 540, 540, 270, 270, 66, 66, 270, 66, 540, 66, 66, 270, 66, 540, 270, 66, 540, 66, 66, 540, 270, 540, 270, 66, 270, 540, 270, 270, 540, 270, 66, 270, 66, 540, 270, 270, 540, 540, 66, 66, 66, 540, 540, 66, 66, 540, 270, 66, 270, 66, 270, 540, 540, 540, 66, 540, 540, 540, 540, 66, 270, 270, 540, 66, 540, 66, 66, 66, 540, 270, 540, 540, 66, 270, 270, 270, 66, 270, 66, 270, 270, 540, 66, 66, 270, 66, 270, 270, 66, 540, 540, 540, 66, 270, 270, 270, 270, 66, 270, 66, 540, 66, 66, 540, 270, 540, 270, 270, 270, 270, 66, 66, 540, 66, 66, 540, 540, 540, 66, 540, 540, 270, 540, 270, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 93666 . Total input tokens: 20908649 . Total output tokens: 18710898
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 2.8350315089919604,
    "estimated_duration": 3599.9726997960124,
    "input_throughput": 2154.218280721805,
    "output_throughput": 1928.0929548141594,
    "total_throughput": 4082.311235535964,
    "itl": 41.73993799579647,
    "ttft": 9223.903567251155,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10699,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 34.91731637114398,
    "arrivals": 31462,
    "finished_requests": 31382,
    "scheduler_time": 12.367793639618705
}
#Debug simulation 
Total elapsed time: 2.835116514004767. Arrivals time: 0.08855269459309056 Scheduler time: 2.241350917611271 Scheduler overhead time: 0.08771509188227355 Adapter cache time: 0.2884908796986565 Engine time: 0.08754608238814399 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_320_slots_160_rate_0.05-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_320_slots_160_rate_0.05-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 66, 540, 540, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 540, 270, 540, 540, 66, 540, 270, 270, 540, 540, 270, 66, 66, 270, 540, 540, 270, 270, 66, 66, 270, 540, 540, 66, 540, 270, 66, 270, 540, 66, 270, 540, 540, 270, 66, 66, 540, 66, 66, 540, 540, 66, 66, 270, 270, 270, 66, 270, 66, 540, 66, 540, 270, 540, 540, 66, 540, 66, 540, 270, 66, 66, 270, 270, 540, 270, 540, 540, 540, 66, 270, 270, 66, 540, 270, 540, 540, 270, 66, 270, 270, 270, 66, 540, 270, 540, 66, 540, 66, 66, 270, 540, 540, 270, 66, 270, 66, 270, 540, 540, 270, 66, 270, 66, 540, 66, 66, 66, 66, 540, 270, 270, 540, 270, 270, 66, 270, 540, 270, 66, 66, 270, 540, 66, 66, 66, 540, 540, 540, 66, 270, 540, 270, 270, 270, 66, 540, 66, 540, 270, 66, 270, 66, 66, 270, 66, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 66, 66, 540, 270, 540, 270, 540, 270, 66, 270, 66, 66, 66, 540, 540, 270, 270, 66, 66, 270, 66, 540, 66, 66, 270, 66, 540, 270, 66, 540, 66, 66, 540, 270, 540, 270, 66, 270, 540, 270, 270, 540, 270, 66, 270, 66, 540, 270, 270, 540, 540, 66, 66, 66, 540, 540, 66, 66, 540, 270, 66, 270, 66, 270, 540, 540, 540, 66, 540, 540, 540, 540, 66, 270, 270, 540, 66, 540, 66, 66, 66, 540, 270, 540, 540, 66, 270, 270, 270, 66, 270, 66, 270, 270, 540, 66, 66, 270, 66, 270, 270, 66, 540, 540, 540, 66, 270, 270, 270, 270, 66, 270, 66, 540, 66, 66, 540, 270, 540, 270, 270, 270, 270, 66, 66, 540, 66, 66, 540, 540, 540, 66, 540, 540, 270, 540, 270, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 93666 . Total input tokens: 20908649 . Total output tokens: 18710898
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 2.7917431440437213,
    "estimated_duration": 3599.9572597919473,
    "input_throughput": 2154.2275200367776,
    "output_throughput": 1928.1012242909646,
    "total_throughput": 4082.3287443277422,
    "itl": 41.73941091026294,
    "ttft": 9223.994589386268,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10702,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 34.988454265337,
    "arrivals": 31462,
    "finished_requests": 31382,
    "scheduler_time": 12.368435804989295
}
#Debug simulation 
Total elapsed time: 2.791828853019979. Arrivals time: 0.08714983001118526 Scheduler time: 2.2039233386167325 Scheduler overhead time: 0.08757255249656737 Adapter cache time: 0.28725086100166664 Engine time: 0.08453896740684286 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_320_slots_160_rate_0.05-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_320_slots_160_rate_0.05-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 66, 540, 540, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 540, 270, 540, 540, 66, 540, 270, 270, 540, 540, 270, 66, 66, 270, 540, 540, 270, 270, 66, 66, 270, 540, 540, 66, 540, 270, 66, 270, 540, 66, 270, 540, 540, 270, 66, 66, 540, 66, 66, 540, 540, 66, 66, 270, 270, 270, 66, 270, 66, 540, 66, 540, 270, 540, 540, 66, 540, 66, 540, 270, 66, 66, 270, 270, 540, 270, 540, 540, 540, 66, 270, 270, 66, 540, 270, 540, 540, 270, 66, 270, 270, 270, 66, 540, 270, 540, 66, 540, 66, 66, 270, 540, 540, 270, 66, 270, 66, 270, 540, 540, 270, 66, 270, 66, 540, 66, 66, 66, 66, 540, 270, 270, 540, 270, 270, 66, 270, 540, 270, 66, 66, 270, 540, 66, 66, 66, 540, 540, 540, 66, 270, 540, 270, 270, 270, 66, 540, 66, 540, 270, 66, 270, 66, 66, 270, 66, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 66, 66, 540, 270, 540, 270, 540, 270, 66, 270, 66, 66, 66, 540, 540, 270, 270, 66, 66, 270, 66, 540, 66, 66, 270, 66, 540, 270, 66, 540, 66, 66, 540, 270, 540, 270, 66, 270, 540, 270, 270, 540, 270, 66, 270, 66, 540, 270, 270, 540, 540, 66, 66, 66, 540, 540, 66, 66, 540, 270, 66, 270, 66, 270, 540, 540, 540, 66, 540, 540, 540, 540, 66, 270, 270, 540, 66, 540, 66, 66, 66, 540, 270, 540, 540, 66, 270, 270, 270, 66, 270, 66, 270, 270, 540, 66, 66, 270, 66, 270, 270, 66, 540, 540, 540, 66, 270, 270, 270, 270, 66, 270, 66, 540, 66, 66, 540, 270, 540, 270, 270, 270, 270, 66, 66, 540, 66, 66, 540, 540, 540, 66, 540, 540, 270, 540, 270, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 93666 . Total input tokens: 20908649 . Total output tokens: 18710898
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 2.836663228983525,
    "estimated_duration": 3599.9889297393224,
    "input_throughput": 2154.2085687917806,
    "output_throughput": 1928.0842623320534,
    "total_throughput": 4082.2928311238343,
    "itl": 41.690835882946125,
    "ttft": 9223.727445328434,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10690,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 33.414151032964476,
    "arrivals": 31462,
    "finished_requests": 31382,
    "scheduler_time": 12.350211443287462
}
#Debug simulation 
Total elapsed time: 2.836753469950054. Arrivals time: 0.08888824045425281 Scheduler time: 2.243744913372211 Scheduler overhead time: 0.08769704954465851 Adapter cache time: 0.2883999565965496 Engine time: 0.08661577483871952 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_320_slots_160_rate_0.05-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_320_slots_160_rate_0.05-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 66, 540, 540, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 540, 270, 540, 540, 66, 540, 270, 270, 540, 540, 270, 66, 66, 270, 540, 540, 270, 270, 66, 66, 270, 540, 540, 66, 540, 270, 66, 270, 540, 66, 270, 540, 540, 270, 66, 66, 540, 66, 66, 540, 540, 66, 66, 270, 270, 270, 66, 270, 66, 540, 66, 540, 270, 540, 540, 66, 540, 66, 540, 270, 66, 66, 270, 270, 540, 270, 540, 540, 540, 66, 270, 270, 66, 540, 270, 540, 540, 270, 66, 270, 270, 270, 66, 540, 270, 540, 66, 540, 66, 66, 270, 540, 540, 270, 66, 270, 66, 270, 540, 540, 270, 66, 270, 66, 540, 66, 66, 66, 66, 540, 270, 270, 540, 270, 270, 66, 270, 540, 270, 66, 66, 270, 540, 66, 66, 66, 540, 540, 540, 66, 270, 540, 270, 270, 270, 66, 540, 66, 540, 270, 66, 270, 66, 66, 270, 66, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 66, 66, 540, 270, 540, 270, 540, 270, 66, 270, 66, 66, 66, 540, 540, 270, 270, 66, 66, 270, 66, 540, 66, 66, 270, 66, 540, 270, 66, 540, 66, 66, 540, 270, 540, 270, 66, 270, 540, 270, 270, 540, 270, 66, 270, 66, 540, 270, 270, 540, 540, 66, 66, 66, 540, 540, 66, 66, 540, 270, 66, 270, 66, 270, 540, 540, 540, 66, 540, 540, 540, 540, 66, 270, 270, 540, 66, 540, 66, 66, 66, 540, 270, 540, 540, 66, 270, 270, 270, 66, 270, 66, 270, 270, 540, 66, 66, 270, 66, 270, 270, 66, 540, 540, 540, 66, 270, 270, 270, 270, 66, 270, 66, 540, 66, 66, 540, 270, 540, 270, 270, 270, 270, 66, 66, 540, 66, 66, 540, 540, 540, 66, 540, 540, 270, 540, 270, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 93666 . Total input tokens: 20908649 . Total output tokens: 18710898
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 2.7934128909837455,
    "estimated_duration": 3599.9592729282153,
    "input_throughput": 2154.2263153693852,
    "output_throughput": 1928.1001460758491,
    "total_throughput": 4082.326461445234,
    "itl": 41.75572067282055,
    "ttft": 9224.042327642834,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10703,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 35.44643496956759,
    "arrivals": 31462,
    "finished_requests": 31382,
    "scheduler_time": 12.373955508369521
}
#Debug simulation 
Total elapsed time: 2.7935480889864266. Arrivals time: 0.0878428575815633 Scheduler time: 2.2028838547994383 Scheduler overhead time: 0.0875025347340852 Adapter cache time: 0.28861934487940744 Engine time: 0.08512543246615678 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_320_slots_160_rate_0.05-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_320_slots_160_rate_0.05-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 66, 540, 540, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 540, 270, 540, 540, 66, 540, 270, 270, 540, 540, 270, 66, 66, 270, 540, 540, 270, 270, 66, 66, 270, 540, 540, 66, 540, 270, 66, 270, 540, 66, 270, 540, 540, 270, 66, 66, 540, 66, 66, 540, 540, 66, 66, 270, 270, 270, 66, 270, 66, 540, 66, 540, 270, 540, 540, 66, 540, 66, 540, 270, 66, 66, 270, 270, 540, 270, 540, 540, 540, 66, 270, 270, 66, 540, 270, 540, 540, 270, 66, 270, 270, 270, 66, 540, 270, 540, 66, 540, 66, 66, 270, 540, 540, 270, 66, 270, 66, 270, 540, 540, 270, 66, 270, 66, 540, 66, 66, 66, 66, 540, 270, 270, 540, 270, 270, 66, 270, 540, 270, 66, 66, 270, 540, 66, 66, 66, 540, 540, 540, 66, 270, 540, 270, 270, 270, 66, 540, 66, 540, 270, 66, 270, 66, 66, 270, 66, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 66, 66, 540, 270, 540, 270, 540, 270, 66, 270, 66, 66, 66, 540, 540, 270, 270, 66, 66, 270, 66, 540, 66, 66, 270, 66, 540, 270, 66, 540, 66, 66, 540, 270, 540, 270, 66, 270, 540, 270, 270, 540, 270, 66, 270, 66, 540, 270, 270, 540, 540, 66, 66, 66, 540, 540, 66, 66, 540, 270, 66, 270, 66, 270, 540, 540, 540, 66, 540, 540, 540, 540, 66, 270, 270, 540, 66, 540, 66, 66, 66, 540, 270, 540, 540, 66, 270, 270, 270, 66, 270, 66, 270, 270, 540, 66, 66, 270, 66, 270, 270, 66, 540, 540, 540, 66, 270, 270, 270, 270, 66, 270, 66, 540, 66, 66, 540, 270, 540, 270, 270, 270, 270, 66, 66, 540, 66, 66, 540, 540, 540, 66, 540, 540, 270, 540, 270, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 93666 . Total input tokens: 20908649 . Total output tokens: 18710898
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 2.8116019860026427,
    "estimated_duration": 3599.9642897426543,
    "input_throughput": 2154.2233132969163,
    "output_throughput": 1928.0974591267925,
    "total_throughput": 4082.3207724237086,
    "itl": 41.644864315682184,
    "ttft": 9223.566137923579,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10697,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 31.984568004565098,
    "arrivals": 31462,
    "finished_requests": 31382,
    "scheduler_time": 12.333188973315957
}
#Debug simulation 
Total elapsed time: 2.811691497976426. Arrivals time: 0.09337498742388561 Scheduler time: 2.212319376238156 Scheduler overhead time: 0.08783932257210836 Adapter cache time: 0.2860863582463935 Engine time: 0.0904647727147676 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_320_slots_160_rate_0.05-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_320_slots_160_rate_0.05-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 66, 540, 540, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 540, 270, 540, 540, 66, 540, 270, 270, 540, 540, 270, 66, 66, 270, 540, 540, 270, 270, 66, 66, 270, 540, 540, 66, 540, 270, 66, 270, 540, 66, 270, 540, 540, 270, 66, 66, 540, 66, 66, 540, 540, 66, 66, 270, 270, 270, 66, 270, 66, 540, 66, 540, 270, 540, 540, 66, 540, 66, 540, 270, 66, 66, 270, 270, 540, 270, 540, 540, 540, 66, 270, 270, 66, 540, 270, 540, 540, 270, 66, 270, 270, 270, 66, 540, 270, 540, 66, 540, 66, 66, 270, 540, 540, 270, 66, 270, 66, 270, 540, 540, 270, 66, 270, 66, 540, 66, 66, 66, 66, 540, 270, 270, 540, 270, 270, 66, 270, 540, 270, 66, 66, 270, 540, 66, 66, 66, 540, 540, 540, 66, 270, 540, 270, 270, 270, 66, 540, 66, 540, 270, 66, 270, 66, 66, 270, 66, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 66, 66, 540, 270, 540, 270, 540, 270, 66, 270, 66, 66, 66, 540, 540, 270, 270, 66, 66, 270, 66, 540, 66, 66, 270, 66, 540, 270, 66, 540, 66, 66, 540, 270, 540, 270, 66, 270, 540, 270, 270, 540, 270, 66, 270, 66, 540, 270, 270, 540, 540, 66, 66, 66, 540, 540, 66, 66, 540, 270, 66, 270, 66, 270, 540, 540, 540, 66, 540, 540, 540, 540, 66, 270, 270, 540, 66, 540, 66, 66, 66, 540, 270, 540, 540, 66, 270, 270, 270, 66, 270, 66, 270, 270, 540, 66, 66, 270, 66, 270, 270, 66, 540, 540, 540, 66, 270, 270, 270, 270, 66, 270, 66, 540, 66, 66, 540, 270, 540, 270, 270, 270, 270, 66, 66, 540, 66, 66, 540, 540, 540, 66, 540, 540, 270, 540, 270, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 93666 . Total input tokens: 20908649 . Total output tokens: 18710898
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 2.8012096830061637,
    "estimated_duration": 3599.9865158558823,
    "input_throughput": 2154.2100132439664,
    "output_throughput": 1928.0855551620825,
    "total_throughput": 4082.295568406049,
    "itl": 41.76952580344183,
    "ttft": 9223.95339009737,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10698,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 35.875579818261954,
    "arrivals": 31462,
    "finished_requests": 31382,
    "scheduler_time": 12.379079747679437
}
#Debug simulation 
Total elapsed time: 2.8012949430267327. Arrivals time: 0.08720280125271529 Scheduler time: 2.2124306586338207 Scheduler overhead time: 0.08788590022595599 Adapter cache time: 0.2854348194669001 Engine time: 0.08683898946037516 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_320_slots_160_rate_0.05-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_320_slots_160_rate_0.05-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 33, 540, 540, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 540, 270, 540, 540, 33, 540, 270, 270, 540, 540, 270, 33, 33, 270, 540, 540, 270, 270, 33, 33, 270, 540, 540, 33, 540, 270, 33, 270, 540, 33, 270, 540, 540, 270, 33, 33, 540, 33, 33, 540, 540, 33, 33, 270, 270, 270, 33, 270, 33, 540, 33, 540, 270, 540, 540, 33, 540, 33, 540, 270, 33, 33, 270, 270, 540, 270, 540, 540, 540, 33, 270, 270, 33, 540, 270, 540, 540, 270, 33, 270, 270, 270, 33, 540, 270, 540, 33, 540, 33, 33, 270, 540, 540, 270, 33, 270, 33, 270, 540, 540, 270, 33, 270, 33, 540, 33, 33, 33, 33, 540, 270, 270, 540, 270, 270, 33, 270, 540, 270, 33, 33, 270, 540, 33, 33, 33, 540, 540, 540, 33, 270, 540, 270, 270, 270, 33, 540, 33, 540, 270, 33, 270, 33, 33, 270, 33, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 33, 33, 540, 270, 540, 270, 540, 270, 33, 270, 33, 33, 33, 540, 540, 270, 270, 33, 33, 270, 33, 540, 33, 33, 270, 33, 540, 270, 33, 540, 33, 33, 540, 270, 540, 270, 33, 270, 540, 270, 270, 540, 270, 33, 270, 33, 540, 270, 270, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 270, 33, 270, 33, 270, 540, 540, 540, 33, 540, 540, 540, 540, 33, 270, 270, 540, 33, 540, 33, 33, 33, 540, 270, 540, 540, 33, 270, 270, 270, 33, 270, 33, 270, 270, 540, 33, 33, 270, 33, 270, 270, 33, 540, 540, 540, 33, 270, 270, 270, 270, 33, 270, 33, 540, 33, 33, 540, 270, 540, 270, 270, 270, 270, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 270, 540, 270, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 90168 . Total input tokens: 20108351 . Total output tokens: 18015308
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 2.6967395969550125,
    "estimated_duration": 3600.01656017573,
    "input_throughput": 2061.645238553488,
    "output_throughput": 1828.9763088419222,
    "total_throughput": 3890.6215473954103,
    "itl": 37.80706846791832,
    "ttft": 13391.571956724905,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8785,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.88638483045098,
    "arrivals": 30252,
    "finished_requests": 30139,
    "scheduler_time": 9.447035121439505
}
#Debug simulation 
Total elapsed time: 2.6968254139646888. Arrivals time: 0.08556323382072151 Scheduler time: 2.1082758971024305 Scheduler overhead time: 0.09438077959930524 Adapter cache time: 0.2726084098103456 Engine time: 0.09115799725987017 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_320_slots_160_rate_0.05-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_320_slots_160_rate_0.05-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 33, 540, 540, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 540, 270, 540, 540, 33, 540, 270, 270, 540, 540, 270, 33, 33, 270, 540, 540, 270, 270, 33, 33, 270, 540, 540, 33, 540, 270, 33, 270, 540, 33, 270, 540, 540, 270, 33, 33, 540, 33, 33, 540, 540, 33, 33, 270, 270, 270, 33, 270, 33, 540, 33, 540, 270, 540, 540, 33, 540, 33, 540, 270, 33, 33, 270, 270, 540, 270, 540, 540, 540, 33, 270, 270, 33, 540, 270, 540, 540, 270, 33, 270, 270, 270, 33, 540, 270, 540, 33, 540, 33, 33, 270, 540, 540, 270, 33, 270, 33, 270, 540, 540, 270, 33, 270, 33, 540, 33, 33, 33, 33, 540, 270, 270, 540, 270, 270, 33, 270, 540, 270, 33, 33, 270, 540, 33, 33, 33, 540, 540, 540, 33, 270, 540, 270, 270, 270, 33, 540, 33, 540, 270, 33, 270, 33, 33, 270, 33, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 33, 33, 540, 270, 540, 270, 540, 270, 33, 270, 33, 33, 33, 540, 540, 270, 270, 33, 33, 270, 33, 540, 33, 33, 270, 33, 540, 270, 33, 540, 33, 33, 540, 270, 540, 270, 33, 270, 540, 270, 270, 540, 270, 33, 270, 33, 540, 270, 270, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 270, 33, 270, 33, 270, 540, 540, 540, 33, 540, 540, 540, 540, 33, 270, 270, 540, 33, 540, 33, 33, 33, 540, 270, 540, 540, 33, 270, 270, 270, 33, 270, 33, 270, 270, 540, 33, 33, 270, 33, 270, 270, 33, 540, 540, 540, 33, 270, 270, 270, 270, 33, 270, 33, 540, 33, 33, 540, 270, 540, 270, 270, 270, 270, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 270, 540, 270, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 90168 . Total input tokens: 20108351 . Total output tokens: 18015308
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 2.734356287983246,
    "estimated_duration": 3600.0149638206008,
    "input_throughput": 2061.6461527491188,
    "output_throughput": 1828.9771198651376,
    "total_throughput": 3890.6232726142566,
    "itl": 37.85340285358845,
    "ttft": 13391.833378011766,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8787,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.6928648217872,
    "arrivals": 30252,
    "finished_requests": 30139,
    "scheduler_time": 9.466760482290642
}
#Debug simulation 
Total elapsed time: 2.7344448220101185. Arrivals time: 0.08585555874742568 Scheduler time: 2.138812991324812 Scheduler overhead time: 0.09414432541234419 Adapter cache time: 0.27639411063864827 Engine time: 0.0944620871450752 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-32/adapters_320_slots_160_rate_0.05-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-32/adapters_320_slots_160_rate_0.05-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 33, 540, 540, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 540, 270, 540, 540, 33, 540, 270, 270, 540, 540, 270, 33, 33, 270, 540, 540, 270, 270, 33, 33, 270, 540, 540, 33, 540, 270, 33, 270, 540, 33, 270, 540, 540, 270, 33, 33, 540, 33, 33, 540, 540, 33, 33, 270, 270, 270, 33, 270, 33, 540, 33, 540, 270, 540, 540, 33, 540, 33, 540, 270, 33, 33, 270, 270, 540, 270, 540, 540, 540, 33, 270, 270, 33, 540, 270, 540, 540, 270, 33, 270, 270, 270, 33, 540, 270, 540, 33, 540, 33, 33, 270, 540, 540, 270, 33, 270, 33, 270, 540, 540, 270, 33, 270, 33, 540, 33, 33, 33, 33, 540, 270, 270, 540, 270, 270, 33, 270, 540, 270, 33, 33, 270, 540, 33, 33, 33, 540, 540, 540, 33, 270, 540, 270, 270, 270, 33, 540, 33, 540, 270, 33, 270, 33, 33, 270, 33, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 33, 33, 540, 270, 540, 270, 540, 270, 33, 270, 33, 33, 33, 540, 540, 270, 270, 33, 33, 270, 33, 540, 33, 33, 270, 33, 540, 270, 33, 540, 33, 33, 540, 270, 540, 270, 33, 270, 540, 270, 270, 540, 270, 33, 270, 33, 540, 270, 270, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 270, 33, 270, 33, 270, 540, 540, 540, 33, 540, 540, 540, 540, 33, 270, 270, 540, 33, 540, 33, 33, 33, 540, 270, 540, 540, 33, 270, 270, 270, 33, 270, 33, 270, 270, 540, 33, 33, 270, 33, 270, 270, 33, 540, 540, 540, 33, 270, 270, 270, 270, 33, 270, 33, 540, 33, 33, 540, 270, 540, 270, 270, 270, 270, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 270, 540, 270, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 90168 . Total input tokens: 20108351 . Total output tokens: 18015308
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 2.6815698760328814,
    "estimated_duration": 3600.0516842527727,
    "input_throughput": 2061.625124012769,
    "output_throughput": 1828.9584643467826,
    "total_throughput": 3890.5835883595514,
    "itl": 37.853629084438765,
    "ttft": 13510.266662237487,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8783,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.727393968870015,
    "arrivals": 30252,
    "finished_requests": 30139,
    "scheduler_time": 9.467491976813742
}
#Debug simulation 
Total elapsed time: 2.6816554810502566. Arrivals time: 0.08469763572793454 Scheduler time: 2.0944165930268355 Scheduler overhead time: 0.09356529213255271 Adapter cache time: 0.27103903552051634 Engine time: 0.09350454562809318 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_320_slots_160_rate_0.05-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_320_slots_160_rate_0.05-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 33, 540, 540, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 540, 270, 540, 540, 33, 540, 270, 270, 540, 540, 270, 33, 33, 270, 540, 540, 270, 270, 33, 33, 270, 540, 540, 33, 540, 270, 33, 270, 540, 33, 270, 540, 540, 270, 33, 33, 540, 33, 33, 540, 540, 33, 33, 270, 270, 270, 33, 270, 33, 540, 33, 540, 270, 540, 540, 33, 540, 33, 540, 270, 33, 33, 270, 270, 540, 270, 540, 540, 540, 33, 270, 270, 33, 540, 270, 540, 540, 270, 33, 270, 270, 270, 33, 540, 270, 540, 33, 540, 33, 33, 270, 540, 540, 270, 33, 270, 33, 270, 540, 540, 270, 33, 270, 33, 540, 33, 33, 33, 33, 540, 270, 270, 540, 270, 270, 33, 270, 540, 270, 33, 33, 270, 540, 33, 33, 33, 540, 540, 540, 33, 270, 540, 270, 270, 270, 33, 540, 33, 540, 270, 33, 270, 33, 33, 270, 33, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 33, 33, 540, 270, 540, 270, 540, 270, 33, 270, 33, 33, 33, 540, 540, 270, 270, 33, 33, 270, 33, 540, 33, 33, 270, 33, 540, 270, 33, 540, 33, 33, 540, 270, 540, 270, 33, 270, 540, 270, 270, 540, 270, 33, 270, 33, 540, 270, 270, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 270, 33, 270, 33, 270, 540, 540, 540, 33, 540, 540, 540, 540, 33, 270, 270, 540, 33, 540, 33, 33, 33, 540, 270, 540, 540, 33, 270, 270, 270, 33, 270, 33, 270, 270, 540, 33, 33, 270, 33, 270, 270, 33, 540, 540, 540, 33, 270, 270, 270, 270, 33, 270, 33, 540, 33, 33, 540, 270, 540, 270, 270, 270, 270, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 270, 540, 270, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 90168 . Total input tokens: 20108351 . Total output tokens: 18015308
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 2.6910974519560114,
    "estimated_duration": 3600.0208430978546,
    "input_throughput": 2061.642785827132,
    "output_throughput": 1828.9741329203262,
    "total_throughput": 3890.616918747458,
    "itl": 37.82307246501598,
    "ttft": 13510.311716181293,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8786,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.475120889770118,
    "arrivals": 30252,
    "finished_requests": 30139,
    "scheduler_time": 9.453536879187848
}
#Debug simulation 
Total elapsed time: 2.691184422990773. Arrivals time: 0.08477236801991239 Scheduler time: 2.105682123103179 Scheduler overhead time: 0.09537074458785355 Adapter cache time: 0.2694317440036684 Engine time: 0.09087250678567216 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-32/adapters_320_slots_160_rate_0.05-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-32/adapters_320_slots_160_rate_0.05-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 33, 540, 540, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 540, 270, 540, 540, 33, 540, 270, 270, 540, 540, 270, 33, 33, 270, 540, 540, 270, 270, 33, 33, 270, 540, 540, 33, 540, 270, 33, 270, 540, 33, 270, 540, 540, 270, 33, 33, 540, 33, 33, 540, 540, 33, 33, 270, 270, 270, 33, 270, 33, 540, 33, 540, 270, 540, 540, 33, 540, 33, 540, 270, 33, 33, 270, 270, 540, 270, 540, 540, 540, 33, 270, 270, 33, 540, 270, 540, 540, 270, 33, 270, 270, 270, 33, 540, 270, 540, 33, 540, 33, 33, 270, 540, 540, 270, 33, 270, 33, 270, 540, 540, 270, 33, 270, 33, 540, 33, 33, 33, 33, 540, 270, 270, 540, 270, 270, 33, 270, 540, 270, 33, 33, 270, 540, 33, 33, 33, 540, 540, 540, 33, 270, 540, 270, 270, 270, 33, 540, 33, 540, 270, 33, 270, 33, 33, 270, 33, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 33, 33, 540, 270, 540, 270, 540, 270, 33, 270, 33, 33, 33, 540, 540, 270, 270, 33, 33, 270, 33, 540, 33, 33, 270, 33, 540, 270, 33, 540, 33, 33, 540, 270, 540, 270, 33, 270, 540, 270, 270, 540, 270, 33, 270, 33, 540, 270, 270, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 270, 33, 270, 33, 270, 540, 540, 540, 33, 540, 540, 540, 540, 33, 270, 270, 540, 33, 540, 33, 33, 33, 540, 270, 540, 540, 33, 270, 270, 270, 33, 270, 33, 270, 270, 540, 33, 33, 270, 33, 270, 270, 33, 540, 540, 540, 33, 270, 270, 270, 270, 33, 270, 33, 540, 33, 33, 540, 270, 540, 270, 270, 270, 270, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 270, 540, 270, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 90168 . Total input tokens: 20108351 . Total output tokens: 18015308
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 2.6511515289894305,
    "estimated_duration": 3600.0463280063864,
    "input_throughput": 2061.6281913544403,
    "output_throughput": 1828.961185520699,
    "total_throughput": 3890.5893768751394,
    "itl": 37.86271601068354,
    "ttft": 13510.417630150796,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8789,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.121333080231494,
    "arrivals": 30252,
    "finished_requests": 30139,
    "scheduler_time": 9.471596770224345
}
#Debug simulation 
Total elapsed time: 2.651284549967386. Arrivals time: 0.08443656226154417 Scheduler time: 2.0698892200598493 Scheduler overhead time: 0.0935993644525297 Adapter cache time: 0.26872859039576724 Engine time: 0.09012296062428504 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_320_slots_160_rate_0.05-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_320_slots_160_rate_0.05-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 33, 540, 540, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 540, 270, 540, 540, 33, 540, 270, 270, 540, 540, 270, 33, 33, 270, 540, 540, 270, 270, 33, 33, 270, 540, 540, 33, 540, 270, 33, 270, 540, 33, 270, 540, 540, 270, 33, 33, 540, 33, 33, 540, 540, 33, 33, 270, 270, 270, 33, 270, 33, 540, 33, 540, 270, 540, 540, 33, 540, 33, 540, 270, 33, 33, 270, 270, 540, 270, 540, 540, 540, 33, 270, 270, 33, 540, 270, 540, 540, 270, 33, 270, 270, 270, 33, 540, 270, 540, 33, 540, 33, 33, 270, 540, 540, 270, 33, 270, 33, 270, 540, 540, 270, 33, 270, 33, 540, 33, 33, 33, 33, 540, 270, 270, 540, 270, 270, 33, 270, 540, 270, 33, 33, 270, 540, 33, 33, 33, 540, 540, 540, 33, 270, 540, 270, 270, 270, 33, 540, 33, 540, 270, 33, 270, 33, 33, 270, 33, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 33, 33, 540, 270, 540, 270, 540, 270, 33, 270, 33, 33, 33, 540, 540, 270, 270, 33, 33, 270, 33, 540, 33, 33, 270, 33, 540, 270, 33, 540, 33, 33, 540, 270, 540, 270, 33, 270, 540, 270, 270, 540, 270, 33, 270, 33, 540, 270, 270, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 270, 33, 270, 33, 270, 540, 540, 540, 33, 540, 540, 540, 540, 33, 270, 270, 540, 33, 540, 33, 33, 33, 540, 270, 540, 540, 33, 270, 270, 270, 33, 270, 33, 270, 270, 540, 33, 33, 270, 33, 270, 270, 33, 540, 540, 540, 33, 270, 270, 270, 270, 33, 270, 33, 540, 33, 33, 540, 270, 540, 270, 270, 270, 270, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 270, 540, 270, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 90168 . Total input tokens: 20108351 . Total output tokens: 18015308
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 2.7015101200086065,
    "estimated_duration": 3600.0465150686036,
    "input_throughput": 2061.628084230063,
    "output_throughput": 1828.961090485945,
    "total_throughput": 3890.589174716008,
    "itl": 37.792508470697015,
    "ttft": 13510.164429204302,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8785,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.26759184071404,
    "arrivals": 30252,
    "finished_requests": 30139,
    "scheduler_time": 9.440508167725357
}
#Debug simulation 
Total elapsed time: 2.701600167027209. Arrivals time: 0.08530173124745488 Scheduler time: 2.109361130162142 Scheduler overhead time: 0.09482566802762449 Adapter cache time: 0.2736633471795358 Engine time: 0.09374447469599545 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-32/adapters_320_slots_160_rate_0.05-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-32/adapters_320_slots_160_rate_0.05-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 33, 540, 540, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 540, 270, 540, 540, 33, 540, 270, 270, 540, 540, 270, 33, 33, 270, 540, 540, 270, 270, 33, 33, 270, 540, 540, 33, 540, 270, 33, 270, 540, 33, 270, 540, 540, 270, 33, 33, 540, 33, 33, 540, 540, 33, 33, 270, 270, 270, 33, 270, 33, 540, 33, 540, 270, 540, 540, 33, 540, 33, 540, 270, 33, 33, 270, 270, 540, 270, 540, 540, 540, 33, 270, 270, 33, 540, 270, 540, 540, 270, 33, 270, 270, 270, 33, 540, 270, 540, 33, 540, 33, 33, 270, 540, 540, 270, 33, 270, 33, 270, 540, 540, 270, 33, 270, 33, 540, 33, 33, 33, 33, 540, 270, 270, 540, 270, 270, 33, 270, 540, 270, 33, 33, 270, 540, 33, 33, 33, 540, 540, 540, 33, 270, 540, 270, 270, 270, 33, 540, 33, 540, 270, 33, 270, 33, 33, 270, 33, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 33, 33, 540, 270, 540, 270, 540, 270, 33, 270, 33, 33, 33, 540, 540, 270, 270, 33, 33, 270, 33, 540, 33, 33, 270, 33, 540, 270, 33, 540, 33, 33, 540, 270, 540, 270, 33, 270, 540, 270, 270, 540, 270, 33, 270, 33, 540, 270, 270, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 270, 33, 270, 33, 270, 540, 540, 540, 33, 540, 540, 540, 540, 33, 270, 270, 540, 33, 540, 33, 33, 33, 540, 270, 540, 540, 33, 270, 270, 270, 33, 270, 33, 270, 270, 540, 33, 33, 270, 33, 270, 270, 33, 540, 540, 540, 33, 270, 270, 270, 270, 33, 270, 33, 540, 33, 33, 540, 270, 540, 270, 270, 270, 270, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 270, 540, 270, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 90168 . Total input tokens: 20108351 . Total output tokens: 18015308
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 2.6858873550081626,
    "estimated_duration": 3600.0378833988343,
    "input_throughput": 2061.633027314938,
    "output_throughput": 1828.965475714286,
    "total_throughput": 3890.5985030292236,
    "itl": 37.87263290635383,
    "ttft": 13510.354943419969,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8784,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.47523715078586,
    "arrivals": 30252,
    "finished_requests": 30139,
    "scheduler_time": 9.475448011221646
}
#Debug simulation 
Total elapsed time: 2.68597673001932. Arrivals time: 0.08594263379927725 Scheduler time: 2.096615568443667 Scheduler overhead time: 0.09483110188739374 Adapter cache time: 0.2720233533764258 Engine time: 0.0917257847613655 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_320_slots_160_rate_0.05-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_320_slots_160_rate_0.05-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [106 107 107]
Adapter prompts. [135, 540, 540, 66, 540, 540, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 540, 135, 540, 540, 66, 540, 135, 135, 540, 540, 135, 66, 66, 135, 540, 540, 135, 135, 66, 66, 135, 540, 540, 66, 540, 135, 66, 135, 540, 66, 135, 540, 540, 135, 66, 66, 540, 66, 66, 540, 540, 66, 66, 135, 135, 135, 66, 135, 66, 540, 66, 540, 135, 540, 540, 66, 540, 66, 540, 135, 66, 66, 135, 135, 540, 135, 540, 540, 540, 66, 135, 135, 66, 540, 135, 540, 540, 135, 66, 135, 135, 135, 66, 540, 135, 540, 66, 540, 66, 66, 135, 540, 540, 135, 66, 135, 66, 135, 540, 540, 135, 66, 135, 66, 540, 66, 66, 66, 66, 540, 135, 135, 540, 135, 135, 66, 135, 540, 135, 66, 66, 135, 540, 66, 66, 66, 540, 540, 540, 66, 135, 540, 135, 135, 135, 66, 540, 66, 540, 135, 66, 135, 66, 66, 135, 66, 135, 540, 540, 540, 540, 135, 135, 540, 540, 540, 135, 540, 66, 66, 540, 135, 540, 135, 540, 135, 66, 135, 66, 66, 66, 540, 540, 135, 135, 66, 66, 135, 66, 540, 66, 66, 135, 66, 540, 135, 66, 540, 66, 66, 540, 135, 540, 135, 66, 135, 540, 135, 135, 540, 135, 66, 135, 66, 540, 135, 135, 540, 540, 66, 66, 66, 540, 540, 66, 66, 540, 135, 66, 135, 66, 135, 540, 540, 540, 66, 540, 540, 540, 540, 66, 135, 135, 540, 66, 540, 66, 66, 66, 540, 135, 540, 540, 66, 135, 135, 135, 66, 135, 66, 135, 135, 540, 66, 66, 135, 66, 135, 135, 66, 540, 540, 540, 66, 135, 135, 135, 135, 66, 135, 66, 540, 66, 66, 540, 135, 540, 135, 135, 135, 135, 66, 66, 540, 66, 66, 540, 540, 540, 66, 540, 540, 135, 540, 135, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 79221 . Total input tokens: 17627711 . Total output tokens: 15832351
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 2.446296098991297,
    "estimated_duration": 3600.017061641485,
    "input_throughput": 1837.8396231775673,
    "output_throughput": 1596.6613217602653,
    "total_throughput": 3434.5009449378326,
    "itl": 31.95975536858385,
    "ttft": 9399.300997757486,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7505,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.96896051821578,
    "arrivals": 26579,
    "finished_requests": 26510,
    "scheduler_time": 3.5001262289640347
}
#Debug simulation 
Total elapsed time: 2.4463816300267354. Arrivals time: 0.07789123937254772 Scheduler time: 1.8607390117249452 Scheduler overhead time: 0.10720323701389134 Adapter cache time: 0.2434133052593097 Engine time: 0.10595443478086963 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_320_slots_160_rate_0.05-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_320_slots_160_rate_0.05-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [106 107 107]
Adapter prompts. [135, 540, 540, 66, 540, 540, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 540, 135, 540, 540, 66, 540, 135, 135, 540, 540, 135, 66, 66, 135, 540, 540, 135, 135, 66, 66, 135, 540, 540, 66, 540, 135, 66, 135, 540, 66, 135, 540, 540, 135, 66, 66, 540, 66, 66, 540, 540, 66, 66, 135, 135, 135, 66, 135, 66, 540, 66, 540, 135, 540, 540, 66, 540, 66, 540, 135, 66, 66, 135, 135, 540, 135, 540, 540, 540, 66, 135, 135, 66, 540, 135, 540, 540, 135, 66, 135, 135, 135, 66, 540, 135, 540, 66, 540, 66, 66, 135, 540, 540, 135, 66, 135, 66, 135, 540, 540, 135, 66, 135, 66, 540, 66, 66, 66, 66, 540, 135, 135, 540, 135, 135, 66, 135, 540, 135, 66, 66, 135, 540, 66, 66, 66, 540, 540, 540, 66, 135, 540, 135, 135, 135, 66, 540, 66, 540, 135, 66, 135, 66, 66, 135, 66, 135, 540, 540, 540, 540, 135, 135, 540, 540, 540, 135, 540, 66, 66, 540, 135, 540, 135, 540, 135, 66, 135, 66, 66, 66, 540, 540, 135, 135, 66, 66, 135, 66, 540, 66, 66, 135, 66, 540, 135, 66, 540, 66, 66, 540, 135, 540, 135, 66, 135, 540, 135, 135, 540, 135, 66, 135, 66, 540, 135, 135, 540, 540, 66, 66, 66, 540, 540, 66, 66, 540, 135, 66, 135, 66, 135, 540, 540, 540, 66, 540, 540, 540, 540, 66, 135, 135, 540, 66, 540, 66, 66, 66, 540, 135, 540, 540, 66, 135, 135, 135, 66, 135, 66, 135, 135, 540, 66, 66, 135, 66, 135, 135, 66, 540, 540, 540, 66, 135, 135, 135, 135, 66, 135, 66, 540, 66, 66, 540, 135, 540, 135, 135, 135, 135, 66, 66, 540, 66, 66, 540, 540, 540, 66, 540, 540, 135, 540, 135, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 79221 . Total input tokens: 17627711 . Total output tokens: 15832351
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 2.426660967990756,
    "estimated_duration": 3600.0032085519183,
    "input_throughput": 1837.8466953259613,
    "output_throughput": 1596.6674658359832,
    "total_throughput": 3434.5141611619442,
    "itl": 31.984593644265168,
    "ttft": 9399.40164831799,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7502,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.488634740701286,
    "arrivals": 26579,
    "finished_requests": 26510,
    "scheduler_time": 3.5123385472846356
}
#Debug simulation 
Total elapsed time: 2.426748668018263. Arrivals time: 0.07776436774292961 Scheduler time: 1.8395916969748214 Scheduler overhead time: 0.10746436927001923 Adapter cache time: 0.24531986808869988 Engine time: 0.10528698744019493 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-32/adapters_320_slots_160_rate_0.05-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-32/adapters_320_slots_160_rate_0.05-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [106 107 107]
Adapter prompts. [135, 540, 540, 66, 540, 540, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 540, 135, 540, 540, 66, 540, 135, 135, 540, 540, 135, 66, 66, 135, 540, 540, 135, 135, 66, 66, 135, 540, 540, 66, 540, 135, 66, 135, 540, 66, 135, 540, 540, 135, 66, 66, 540, 66, 66, 540, 540, 66, 66, 135, 135, 135, 66, 135, 66, 540, 66, 540, 135, 540, 540, 66, 540, 66, 540, 135, 66, 66, 135, 135, 540, 135, 540, 540, 540, 66, 135, 135, 66, 540, 135, 540, 540, 135, 66, 135, 135, 135, 66, 540, 135, 540, 66, 540, 66, 66, 135, 540, 540, 135, 66, 135, 66, 135, 540, 540, 135, 66, 135, 66, 540, 66, 66, 66, 66, 540, 135, 135, 540, 135, 135, 66, 135, 540, 135, 66, 66, 135, 540, 66, 66, 66, 540, 540, 540, 66, 135, 540, 135, 135, 135, 66, 540, 66, 540, 135, 66, 135, 66, 66, 135, 66, 135, 540, 540, 540, 540, 135, 135, 540, 540, 540, 135, 540, 66, 66, 540, 135, 540, 135, 540, 135, 66, 135, 66, 66, 66, 540, 540, 135, 135, 66, 66, 135, 66, 540, 66, 66, 135, 66, 540, 135, 66, 540, 66, 66, 540, 135, 540, 135, 66, 135, 540, 135, 135, 540, 135, 66, 135, 66, 540, 135, 135, 540, 540, 66, 66, 66, 540, 540, 66, 66, 540, 135, 66, 135, 66, 135, 540, 540, 540, 66, 540, 540, 540, 540, 66, 135, 135, 540, 66, 540, 66, 66, 66, 540, 135, 540, 540, 66, 135, 135, 135, 66, 135, 66, 135, 135, 540, 66, 66, 135, 66, 135, 135, 66, 540, 540, 540, 66, 135, 135, 135, 135, 66, 135, 66, 540, 66, 66, 540, 135, 540, 135, 135, 135, 135, 66, 66, 540, 66, 66, 540, 540, 540, 66, 540, 540, 135, 540, 135, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 79221 . Total input tokens: 17627711 . Total output tokens: 15832351
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 2.419753439957276,
    "estimated_duration": 3600.014962001231,
    "input_throughput": 1837.8406950625715,
    "output_throughput": 1596.6622529826125,
    "total_throughput": 3434.502948045184,
    "itl": 31.98703716351144,
    "ttft": 9399.37637120732,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7504,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.53694382362089,
    "arrivals": 26579,
    "finished_requests": 26510,
    "scheduler_time": 3.51273635620069
}
#Debug simulation 
Total elapsed time: 2.419842681963928. Arrivals time: 0.0779326330521144 Scheduler time: 1.8343730939086527 Scheduler overhead time: 0.10782368143554777 Adapter cache time: 0.24343503266572952 Engine time: 0.10521453886758536 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_320_slots_160_rate_0.05-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_320_slots_160_rate_0.05-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [106 107 107]
Adapter prompts. [135, 540, 540, 66, 540, 540, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 540, 135, 540, 540, 66, 540, 135, 135, 540, 540, 135, 66, 66, 135, 540, 540, 135, 135, 66, 66, 135, 540, 540, 66, 540, 135, 66, 135, 540, 66, 135, 540, 540, 135, 66, 66, 540, 66, 66, 540, 540, 66, 66, 135, 135, 135, 66, 135, 66, 540, 66, 540, 135, 540, 540, 66, 540, 66, 540, 135, 66, 66, 135, 135, 540, 135, 540, 540, 540, 66, 135, 135, 66, 540, 135, 540, 540, 135, 66, 135, 135, 135, 66, 540, 135, 540, 66, 540, 66, 66, 135, 540, 540, 135, 66, 135, 66, 135, 540, 540, 135, 66, 135, 66, 540, 66, 66, 66, 66, 540, 135, 135, 540, 135, 135, 66, 135, 540, 135, 66, 66, 135, 540, 66, 66, 66, 540, 540, 540, 66, 135, 540, 135, 135, 135, 66, 540, 66, 540, 135, 66, 135, 66, 66, 135, 66, 135, 540, 540, 540, 540, 135, 135, 540, 540, 540, 135, 540, 66, 66, 540, 135, 540, 135, 540, 135, 66, 135, 66, 66, 66, 540, 540, 135, 135, 66, 66, 135, 66, 540, 66, 66, 135, 66, 540, 135, 66, 540, 66, 66, 540, 135, 540, 135, 66, 135, 540, 135, 135, 540, 135, 66, 135, 66, 540, 135, 135, 540, 540, 66, 66, 66, 540, 540, 66, 66, 540, 135, 66, 135, 66, 135, 540, 540, 540, 66, 540, 540, 540, 540, 66, 135, 135, 540, 66, 540, 66, 66, 66, 540, 135, 540, 540, 66, 135, 135, 135, 66, 135, 66, 135, 135, 540, 66, 66, 135, 66, 135, 135, 66, 540, 540, 540, 66, 135, 135, 135, 135, 66, 135, 66, 540, 66, 66, 540, 135, 540, 135, 135, 135, 135, 66, 66, 540, 66, 66, 540, 540, 540, 66, 540, 540, 135, 540, 135, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 79221 . Total input tokens: 17627711 . Total output tokens: 15832351
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 2.44357967202086,
    "estimated_duration": 3600.018334037811,
    "input_throughput": 1837.8389736085464,
    "output_throughput": 1596.660757433695,
    "total_throughput": 3434.4997310422414,
    "itl": 31.96633015117587,
    "ttft": 9399.341775079962,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7504,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.478438284330764,
    "arrivals": 26579,
    "finished_requests": 26510,
    "scheduler_time": 3.5041134505846956
}
#Debug simulation 
Total elapsed time: 2.4436697710189037. Arrivals time: 0.07763558049919084 Scheduler time: 1.856848055147566 Scheduler overhead time: 0.10839709441643208 Adapter cache time: 0.24405523261521012 Engine time: 0.10542533546686172 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-32/adapters_320_slots_160_rate_0.05-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-32/adapters_320_slots_160_rate_0.05-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [106 107 107]
Adapter prompts. [135, 540, 540, 66, 540, 540, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 540, 135, 540, 540, 66, 540, 135, 135, 540, 540, 135, 66, 66, 135, 540, 540, 135, 135, 66, 66, 135, 540, 540, 66, 540, 135, 66, 135, 540, 66, 135, 540, 540, 135, 66, 66, 540, 66, 66, 540, 540, 66, 66, 135, 135, 135, 66, 135, 66, 540, 66, 540, 135, 540, 540, 66, 540, 66, 540, 135, 66, 66, 135, 135, 540, 135, 540, 540, 540, 66, 135, 135, 66, 540, 135, 540, 540, 135, 66, 135, 135, 135, 66, 540, 135, 540, 66, 540, 66, 66, 135, 540, 540, 135, 66, 135, 66, 135, 540, 540, 135, 66, 135, 66, 540, 66, 66, 66, 66, 540, 135, 135, 540, 135, 135, 66, 135, 540, 135, 66, 66, 135, 540, 66, 66, 66, 540, 540, 540, 66, 135, 540, 135, 135, 135, 66, 540, 66, 540, 135, 66, 135, 66, 66, 135, 66, 135, 540, 540, 540, 540, 135, 135, 540, 540, 540, 135, 540, 66, 66, 540, 135, 540, 135, 540, 135, 66, 135, 66, 66, 66, 540, 540, 135, 135, 66, 66, 135, 66, 540, 66, 66, 135, 66, 540, 135, 66, 540, 66, 66, 540, 135, 540, 135, 66, 135, 540, 135, 135, 540, 135, 66, 135, 66, 540, 135, 135, 540, 540, 66, 66, 66, 540, 540, 66, 66, 540, 135, 66, 135, 66, 135, 540, 540, 540, 66, 540, 540, 540, 540, 66, 135, 135, 540, 66, 540, 66, 66, 66, 540, 135, 540, 540, 66, 135, 135, 135, 66, 135, 66, 135, 135, 540, 66, 66, 135, 66, 135, 135, 66, 540, 540, 540, 66, 135, 135, 135, 135, 66, 135, 66, 540, 66, 66, 540, 135, 540, 135, 135, 135, 135, 66, 66, 540, 66, 66, 540, 540, 540, 66, 540, 540, 135, 540, 135, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 79221 . Total input tokens: 17627711 . Total output tokens: 15832351
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 2.4443689250038005,
    "estimated_duration": 3599.9973033077476,
    "input_throughput": 1837.849710031965,
    "output_throughput": 1596.670084924402,
    "total_throughput": 3434.519794956367,
    "itl": 31.991878531472466,
    "ttft": 9399.502818918128,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7501,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.839551191403626,
    "arrivals": 26579,
    "finished_requests": 26510,
    "scheduler_time": 3.5150142919919176
}
#Debug simulation 
Total elapsed time: 2.444498147990089. Arrivals time: 0.07782533956924453 Scheduler time: 1.8574653264367953 Scheduler overhead time: 0.10749968921300024 Adapter cache time: 0.2446000769850798 Engine time: 0.10568576114019379 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_320_slots_160_rate_0.05-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_320_slots_160_rate_0.05-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [106 107 107]
Adapter prompts. [135, 540, 540, 66, 540, 540, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 540, 135, 540, 540, 66, 540, 135, 135, 540, 540, 135, 66, 66, 135, 540, 540, 135, 135, 66, 66, 135, 540, 540, 66, 540, 135, 66, 135, 540, 66, 135, 540, 540, 135, 66, 66, 540, 66, 66, 540, 540, 66, 66, 135, 135, 135, 66, 135, 66, 540, 66, 540, 135, 540, 540, 66, 540, 66, 540, 135, 66, 66, 135, 135, 540, 135, 540, 540, 540, 66, 135, 135, 66, 540, 135, 540, 540, 135, 66, 135, 135, 135, 66, 540, 135, 540, 66, 540, 66, 66, 135, 540, 540, 135, 66, 135, 66, 135, 540, 540, 135, 66, 135, 66, 540, 66, 66, 66, 66, 540, 135, 135, 540, 135, 135, 66, 135, 540, 135, 66, 66, 135, 540, 66, 66, 66, 540, 540, 540, 66, 135, 540, 135, 135, 135, 66, 540, 66, 540, 135, 66, 135, 66, 66, 135, 66, 135, 540, 540, 540, 540, 135, 135, 540, 540, 540, 135, 540, 66, 66, 540, 135, 540, 135, 540, 135, 66, 135, 66, 66, 66, 540, 540, 135, 135, 66, 66, 135, 66, 540, 66, 66, 135, 66, 540, 135, 66, 540, 66, 66, 540, 135, 540, 135, 66, 135, 540, 135, 135, 540, 135, 66, 135, 66, 540, 135, 135, 540, 540, 66, 66, 66, 540, 540, 66, 66, 540, 135, 66, 135, 66, 135, 540, 540, 540, 66, 540, 540, 540, 540, 66, 135, 135, 540, 66, 540, 66, 66, 66, 540, 135, 540, 540, 66, 135, 135, 135, 66, 135, 66, 135, 135, 540, 66, 66, 135, 66, 135, 135, 66, 540, 540, 540, 66, 135, 135, 135, 135, 66, 135, 66, 540, 66, 66, 540, 135, 540, 135, 135, 135, 135, 66, 66, 540, 66, 66, 540, 540, 540, 66, 540, 540, 135, 540, 135, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 79221 . Total input tokens: 17627711 . Total output tokens: 15832351
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 2.4114527060301043,
    "estimated_duration": 3599.993303801916,
    "input_throughput": 1837.8517518387164,
    "output_throughput": 1596.6718587864004,
    "total_throughput": 3434.523610625117,
    "itl": 31.950172374487668,
    "ttft": 9399.261360463865,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7506,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.44331751353543,
    "arrivals": 26579,
    "finished_requests": 26510,
    "scheduler_time": 3.49600569518597
}
#Debug simulation 
Total elapsed time: 2.411569627991412. Arrivals time: 0.07687783322762698 Scheduler time: 1.8260602944646962 Scheduler overhead time: 0.10946498328121379 Adapter cache time: 0.24337046995060518 Engine time: 0.10410240746568888 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-32/adapters_320_slots_160_rate_0.05-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-32/adapters_320_slots_160_rate_0.05-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [106 107 107]
Adapter prompts. [135, 540, 540, 66, 540, 540, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 540, 135, 540, 540, 66, 540, 135, 135, 540, 540, 135, 66, 66, 135, 540, 540, 135, 135, 66, 66, 135, 540, 540, 66, 540, 135, 66, 135, 540, 66, 135, 540, 540, 135, 66, 66, 540, 66, 66, 540, 540, 66, 66, 135, 135, 135, 66, 135, 66, 540, 66, 540, 135, 540, 540, 66, 540, 66, 540, 135, 66, 66, 135, 135, 540, 135, 540, 540, 540, 66, 135, 135, 66, 540, 135, 540, 540, 135, 66, 135, 135, 135, 66, 540, 135, 540, 66, 540, 66, 66, 135, 540, 540, 135, 66, 135, 66, 135, 540, 540, 135, 66, 135, 66, 540, 66, 66, 66, 66, 540, 135, 135, 540, 135, 135, 66, 135, 540, 135, 66, 66, 135, 540, 66, 66, 66, 540, 540, 540, 66, 135, 540, 135, 135, 135, 66, 540, 66, 540, 135, 66, 135, 66, 66, 135, 66, 135, 540, 540, 540, 540, 135, 135, 540, 540, 540, 135, 540, 66, 66, 540, 135, 540, 135, 540, 135, 66, 135, 66, 66, 66, 540, 540, 135, 135, 66, 66, 135, 66, 540, 66, 66, 135, 66, 540, 135, 66, 540, 66, 66, 540, 135, 540, 135, 66, 135, 540, 135, 135, 540, 135, 66, 135, 66, 540, 135, 135, 540, 540, 66, 66, 66, 540, 540, 66, 66, 540, 135, 66, 135, 66, 135, 540, 540, 540, 66, 540, 540, 540, 540, 66, 135, 135, 540, 66, 540, 66, 66, 66, 540, 135, 540, 540, 66, 135, 135, 135, 66, 135, 66, 135, 135, 540, 66, 66, 135, 66, 135, 135, 66, 540, 540, 540, 66, 135, 135, 135, 135, 66, 135, 66, 540, 66, 66, 540, 135, 540, 135, 135, 135, 135, 66, 66, 540, 66, 66, 540, 540, 540, 66, 540, 540, 135, 540, 135, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 79221 . Total input tokens: 17627711 . Total output tokens: 15832351
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 2.4335989210521802,
    "estimated_duration": 3600.025381255696,
    "input_throughput": 1837.8353759528877,
    "output_throughput": 1596.6576318956627,
    "total_throughput": 3434.4930078485504,
    "itl": 31.99629113090187,
    "ttft": 9399.324829595535,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7500,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.15667681276596,
    "arrivals": 26579,
    "finished_requests": 26510,
    "scheduler_time": 3.517671522499026
}
#Debug simulation 
Total elapsed time: 2.4336845600046217. Arrivals time: 0.07693101686891168 Scheduler time: 1.8499080312321894 Scheduler overhead time: 0.10760340781416744 Adapter cache time: 0.24444676033454016 Engine time: 0.10371822619345039 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_320_slots_160_rate_0.05-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_320_slots_160_rate_0.05-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [106 107 107]
Adapter prompts. [135, 540, 540, 33, 540, 540, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 540, 135, 540, 540, 33, 540, 135, 135, 540, 540, 135, 33, 33, 135, 540, 540, 135, 135, 33, 33, 135, 540, 540, 33, 540, 135, 33, 135, 540, 33, 135, 540, 540, 135, 33, 33, 540, 33, 33, 540, 540, 33, 33, 135, 135, 135, 33, 135, 33, 540, 33, 540, 135, 540, 540, 33, 540, 33, 540, 135, 33, 33, 135, 135, 540, 135, 540, 540, 540, 33, 135, 135, 33, 540, 135, 540, 540, 135, 33, 135, 135, 135, 33, 540, 135, 540, 33, 540, 33, 33, 135, 540, 540, 135, 33, 135, 33, 135, 540, 540, 135, 33, 135, 33, 540, 33, 33, 33, 33, 540, 135, 135, 540, 135, 135, 33, 135, 540, 135, 33, 33, 135, 540, 33, 33, 33, 540, 540, 540, 33, 135, 540, 135, 135, 135, 33, 540, 33, 540, 135, 33, 135, 33, 33, 135, 33, 135, 540, 540, 540, 540, 135, 135, 540, 540, 540, 135, 540, 33, 33, 540, 135, 540, 135, 540, 135, 33, 135, 33, 33, 33, 540, 540, 135, 135, 33, 33, 135, 33, 540, 33, 33, 135, 33, 540, 135, 33, 540, 33, 33, 540, 135, 540, 135, 33, 135, 540, 135, 135, 540, 135, 33, 135, 33, 540, 135, 135, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 135, 33, 135, 33, 135, 540, 540, 540, 33, 540, 540, 540, 540, 33, 135, 135, 540, 33, 540, 33, 33, 33, 540, 135, 540, 540, 33, 135, 135, 135, 33, 135, 33, 135, 135, 540, 33, 33, 135, 33, 135, 135, 33, 540, 540, 540, 33, 135, 135, 135, 135, 33, 135, 33, 540, 33, 33, 540, 135, 540, 135, 135, 135, 135, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 135, 540, 135, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 75723 . Total input tokens: 16854799 . Total output tokens: 15128237
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 2.3886914619943127,
    "estimated_duration": 3599.917690627143,
    "input_throughput": 1731.5376449382313,
    "output_throughput": 1563.3204655353034,
    "total_throughput": 3294.858110473535,
    "itl": 31.03192336904992,
    "ttft": 5579.901219231375,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5676,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.371328434560954,
    "arrivals": 25398,
    "finished_requests": 25359,
    "scheduler_time": 2.685862006762269
}
#Debug simulation 
Total elapsed time: 2.388779150962364. Arrivals time: 0.07482276781229302 Scheduler time: 1.8139543326688 Scheduler overhead time: 0.1096195787540637 Adapter cache time: 0.23215634183725342 Engine time: 0.10593220428563654 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_320_slots_160_rate_0.05-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_320_slots_160_rate_0.05-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [106 107 107]
Adapter prompts. [135, 540, 540, 33, 540, 540, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 540, 135, 540, 540, 33, 540, 135, 135, 540, 540, 135, 33, 33, 135, 540, 540, 135, 135, 33, 33, 135, 540, 540, 33, 540, 135, 33, 135, 540, 33, 135, 540, 540, 135, 33, 33, 540, 33, 33, 540, 540, 33, 33, 135, 135, 135, 33, 135, 33, 540, 33, 540, 135, 540, 540, 33, 540, 33, 540, 135, 33, 33, 135, 135, 540, 135, 540, 540, 540, 33, 135, 135, 33, 540, 135, 540, 540, 135, 33, 135, 135, 135, 33, 540, 135, 540, 33, 540, 33, 33, 135, 540, 540, 135, 33, 135, 33, 135, 540, 540, 135, 33, 135, 33, 540, 33, 33, 33, 33, 540, 135, 135, 540, 135, 135, 33, 135, 540, 135, 33, 33, 135, 540, 33, 33, 33, 540, 540, 540, 33, 135, 540, 135, 135, 135, 33, 540, 33, 540, 135, 33, 135, 33, 33, 135, 33, 135, 540, 540, 540, 540, 135, 135, 540, 540, 540, 135, 540, 33, 33, 540, 135, 540, 135, 540, 135, 33, 135, 33, 33, 33, 540, 540, 135, 135, 33, 33, 135, 33, 540, 33, 33, 135, 33, 540, 135, 33, 540, 33, 33, 540, 135, 540, 135, 33, 135, 540, 135, 135, 540, 135, 33, 135, 33, 540, 135, 135, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 135, 33, 135, 33, 135, 540, 540, 540, 33, 540, 540, 540, 540, 33, 135, 135, 540, 33, 540, 33, 33, 33, 540, 135, 540, 540, 33, 135, 135, 135, 33, 135, 33, 135, 135, 540, 33, 33, 135, 33, 135, 135, 33, 540, 540, 540, 33, 135, 135, 135, 135, 33, 135, 33, 540, 33, 33, 540, 135, 540, 135, 135, 135, 135, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 135, 540, 135, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 75723 . Total input tokens: 16854799 . Total output tokens: 15128237
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 2.379351249022875,
    "estimated_duration": 3599.9306845067695,
    "input_throughput": 1731.531672769984,
    "output_throughput": 1563.3817684939975,
    "total_throughput": 3294.9134412639814,
    "itl": 31.05084371793279,
    "ttft": 5438.119231450969,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5673,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.51358315177978,
    "arrivals": 25398,
    "finished_requests": 25360,
    "scheduler_time": 2.6937711079469664
}
#Debug simulation 
Total elapsed time: 2.37943778000772. Arrivals time: 0.07410164718749002 Scheduler time: 1.8069158261059783 Scheduler overhead time: 0.10951702098827809 Adapter cache time: 0.22845748928375542 Engine time: 0.10831485962262377 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-32/adapters_320_slots_160_rate_0.05-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-32/adapters_320_slots_160_rate_0.05-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [106 107 107]
Adapter prompts. [135, 540, 540, 33, 540, 540, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 540, 135, 540, 540, 33, 540, 135, 135, 540, 540, 135, 33, 33, 135, 540, 540, 135, 135, 33, 33, 135, 540, 540, 33, 540, 135, 33, 135, 540, 33, 135, 540, 540, 135, 33, 33, 540, 33, 33, 540, 540, 33, 33, 135, 135, 135, 33, 135, 33, 540, 33, 540, 135, 540, 540, 33, 540, 33, 540, 135, 33, 33, 135, 135, 540, 135, 540, 540, 540, 33, 135, 135, 33, 540, 135, 540, 540, 135, 33, 135, 135, 135, 33, 540, 135, 540, 33, 540, 33, 33, 135, 540, 540, 135, 33, 135, 33, 135, 540, 540, 135, 33, 135, 33, 540, 33, 33, 33, 33, 540, 135, 135, 540, 135, 135, 33, 135, 540, 135, 33, 33, 135, 540, 33, 33, 33, 540, 540, 540, 33, 135, 540, 135, 135, 135, 33, 540, 33, 540, 135, 33, 135, 33, 33, 135, 33, 135, 540, 540, 540, 540, 135, 135, 540, 540, 540, 135, 540, 33, 33, 540, 135, 540, 135, 540, 135, 33, 135, 33, 33, 33, 540, 540, 135, 135, 33, 33, 135, 33, 540, 33, 33, 135, 33, 540, 135, 33, 540, 33, 33, 540, 135, 540, 135, 33, 135, 540, 135, 135, 540, 135, 33, 135, 33, 540, 135, 135, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 135, 33, 135, 33, 135, 540, 540, 540, 33, 540, 540, 540, 540, 33, 135, 135, 540, 33, 540, 33, 33, 33, 540, 135, 540, 540, 33, 135, 135, 135, 33, 135, 33, 135, 135, 540, 33, 33, 135, 33, 135, 135, 33, 540, 540, 540, 33, 135, 135, 135, 135, 33, 135, 33, 540, 33, 33, 540, 135, 540, 135, 135, 135, 135, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 135, 540, 135, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 75723 . Total input tokens: 16854799 . Total output tokens: 15128237
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 2.3638960529933684,
    "estimated_duration": 3599.924547797672,
    "input_throughput": 1731.5343466888512,
    "output_throughput": 1563.3174877076071,
    "total_throughput": 3294.8518343964583,
    "itl": 31.051427354909617,
    "ttft": 5579.94794930283,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5674,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.549454684647717,
    "arrivals": 25398,
    "finished_requests": 25359,
    "scheduler_time": 2.6941803842911334
}
#Debug simulation 
Total elapsed time: 2.363979532965459. Arrivals time: 0.07375633640913293 Scheduler time: 1.7974209149833769 Scheduler overhead time: 0.10920208238530904 Adapter cache time: 0.22613139118766412 Engine time: 0.1053625835920684 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-16/adapters_320_slots_160_rate_0.05-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-16/adapters_320_slots_160_rate_0.05-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [106 107 107]
Adapter prompts. [135, 540, 540, 33, 540, 540, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 540, 135, 540, 540, 33, 540, 135, 135, 540, 540, 135, 33, 33, 135, 540, 540, 135, 135, 33, 33, 135, 540, 540, 33, 540, 135, 33, 135, 540, 33, 135, 540, 540, 135, 33, 33, 540, 33, 33, 540, 540, 33, 33, 135, 135, 135, 33, 135, 33, 540, 33, 540, 135, 540, 540, 33, 540, 33, 540, 135, 33, 33, 135, 135, 540, 135, 540, 540, 540, 33, 135, 135, 33, 540, 135, 540, 540, 135, 33, 135, 135, 135, 33, 540, 135, 540, 33, 540, 33, 33, 135, 540, 540, 135, 33, 135, 33, 135, 540, 540, 135, 33, 135, 33, 540, 33, 33, 33, 33, 540, 135, 135, 540, 135, 135, 33, 135, 540, 135, 33, 33, 135, 540, 33, 33, 33, 540, 540, 540, 33, 135, 540, 135, 135, 135, 33, 540, 33, 540, 135, 33, 135, 33, 33, 135, 33, 135, 540, 540, 540, 540, 135, 135, 540, 540, 540, 135, 540, 33, 33, 540, 135, 540, 135, 540, 135, 33, 135, 33, 33, 33, 540, 540, 135, 135, 33, 33, 135, 33, 540, 33, 33, 135, 33, 540, 135, 33, 540, 33, 33, 540, 135, 540, 135, 33, 135, 540, 135, 135, 540, 135, 33, 135, 33, 540, 135, 135, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 135, 33, 135, 33, 135, 540, 540, 540, 33, 540, 540, 540, 540, 33, 135, 135, 540, 33, 540, 33, 33, 33, 540, 135, 540, 540, 33, 135, 135, 135, 33, 135, 33, 135, 135, 540, 33, 33, 135, 33, 135, 135, 33, 540, 540, 540, 33, 135, 135, 135, 135, 33, 135, 33, 540, 33, 33, 540, 135, 540, 135, 135, 135, 135, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 135, 540, 135, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 75723 . Total input tokens: 16854799 . Total output tokens: 15128237
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 2.3794124299893156,
    "estimated_duration": 3599.9431626175124,
    "input_throughput": 1731.5256709407906,
    "output_throughput": 1563.3763495054302,
    "total_throughput": 3294.902020446221,
    "itl": 31.038763384649968,
    "ttft": 5438.17791066305,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5672,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.725681494761652,
    "arrivals": 25398,
    "finished_requests": 25360,
    "scheduler_time": 2.6885116481413154
}
#Debug simulation 
Total elapsed time: 2.3795253930147737. Arrivals time: 0.07440785347716883 Scheduler time: 1.806553389178589 Scheduler overhead time: 0.10961728787515312 Adapter cache time: 0.23013127618469298 Engine time: 0.10675819084281102 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-32/adapters_320_slots_160_rate_0.05-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-32/adapters_320_slots_160_rate_0.05-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [106 107 107]
Adapter prompts. [135, 540, 540, 33, 540, 540, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 540, 135, 540, 540, 33, 540, 135, 135, 540, 540, 135, 33, 33, 135, 540, 540, 135, 135, 33, 33, 135, 540, 540, 33, 540, 135, 33, 135, 540, 33, 135, 540, 540, 135, 33, 33, 540, 33, 33, 540, 540, 33, 33, 135, 135, 135, 33, 135, 33, 540, 33, 540, 135, 540, 540, 33, 540, 33, 540, 135, 33, 33, 135, 135, 540, 135, 540, 540, 540, 33, 135, 135, 33, 540, 135, 540, 540, 135, 33, 135, 135, 135, 33, 540, 135, 540, 33, 540, 33, 33, 135, 540, 540, 135, 33, 135, 33, 135, 540, 540, 135, 33, 135, 33, 540, 33, 33, 33, 33, 540, 135, 135, 540, 135, 135, 33, 135, 540, 135, 33, 33, 135, 540, 33, 33, 33, 540, 540, 540, 33, 135, 540, 135, 135, 135, 33, 540, 33, 540, 135, 33, 135, 33, 33, 135, 33, 135, 540, 540, 540, 540, 135, 135, 540, 540, 540, 135, 540, 33, 33, 540, 135, 540, 135, 540, 135, 33, 135, 33, 33, 33, 540, 540, 135, 135, 33, 33, 135, 33, 540, 33, 33, 135, 33, 540, 135, 33, 540, 33, 33, 540, 135, 540, 135, 33, 135, 540, 135, 135, 540, 135, 33, 135, 33, 540, 135, 135, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 135, 33, 135, 33, 135, 540, 540, 540, 33, 540, 540, 540, 540, 33, 135, 135, 540, 33, 540, 33, 33, 33, 540, 135, 540, 540, 33, 135, 135, 135, 33, 135, 33, 135, 135, 540, 33, 33, 135, 33, 135, 135, 33, 540, 540, 540, 33, 135, 135, 135, 135, 33, 135, 33, 540, 33, 33, 540, 135, 540, 135, 135, 135, 135, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 135, 540, 135, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 75723 . Total input tokens: 16854799 . Total output tokens: 15128237
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 2.391667638963554,
    "estimated_duration": 3599.9398154922037,
    "input_throughput": 1731.5272808658708,
    "output_throughput": 1563.377803089883,
    "total_throughput": 3294.9050839557535,
    "itl": 31.05587811686292,
    "ttft": 5438.238186520759,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5674,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.79115346213689,
    "arrivals": 25398,
    "finished_requests": 25360,
    "scheduler_time": 2.6956265073538903
}
#Debug simulation 
Total elapsed time: 2.3918293599854223. Arrivals time: 0.07439696171786636 Scheduler time: 1.815933749312535 Scheduler overhead time: 0.1097106485394761 Adapter cache time: 0.23156469280365855 Engine time: 0.1081625267979689 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-16/adapters_320_slots_160_rate_0.05-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-16/adapters_320_slots_160_rate_0.05-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [106 107 107]
Adapter prompts. [135, 540, 540, 33, 540, 540, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 540, 135, 540, 540, 33, 540, 135, 135, 540, 540, 135, 33, 33, 135, 540, 540, 135, 135, 33, 33, 135, 540, 540, 33, 540, 135, 33, 135, 540, 33, 135, 540, 540, 135, 33, 33, 540, 33, 33, 540, 540, 33, 33, 135, 135, 135, 33, 135, 33, 540, 33, 540, 135, 540, 540, 33, 540, 33, 540, 135, 33, 33, 135, 135, 540, 135, 540, 540, 540, 33, 135, 135, 33, 540, 135, 540, 540, 135, 33, 135, 135, 135, 33, 540, 135, 540, 33, 540, 33, 33, 135, 540, 540, 135, 33, 135, 33, 135, 540, 540, 135, 33, 135, 33, 540, 33, 33, 33, 33, 540, 135, 135, 540, 135, 135, 33, 135, 540, 135, 33, 33, 135, 540, 33, 33, 33, 540, 540, 540, 33, 135, 540, 135, 135, 135, 33, 540, 33, 540, 135, 33, 135, 33, 33, 135, 33, 135, 540, 540, 540, 540, 135, 135, 540, 540, 540, 135, 540, 33, 33, 540, 135, 540, 135, 540, 135, 33, 135, 33, 33, 33, 540, 540, 135, 135, 33, 33, 135, 33, 540, 33, 33, 135, 33, 540, 135, 33, 540, 33, 33, 540, 135, 540, 135, 33, 135, 540, 135, 135, 540, 135, 33, 135, 33, 540, 135, 135, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 135, 33, 135, 33, 135, 540, 540, 540, 33, 540, 540, 540, 540, 33, 135, 135, 540, 33, 540, 33, 33, 33, 540, 135, 540, 540, 33, 135, 135, 135, 33, 135, 33, 135, 135, 540, 33, 33, 135, 33, 135, 135, 33, 540, 540, 540, 33, 135, 135, 135, 135, 33, 135, 33, 540, 33, 33, 540, 135, 540, 135, 135, 135, 135, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 135, 540, 135, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 75723 . Total input tokens: 16854799 . Total output tokens: 15128237
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 2.3649563619983383,
    "estimated_duration": 3599.9189733838944,
    "input_throughput": 1731.5370279405654,
    "output_throughput": 1563.3199084783541,
    "total_throughput": 3294.8569364189193,
    "itl": 31.02621450926191,
    "ttft": 5579.852567200745,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5677,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.97451552416117,
    "arrivals": 25398,
    "finished_requests": 25359,
    "scheduler_time": 2.683187387670958
}
#Debug simulation 
Total elapsed time: 2.3650705909822136. Arrivals time: 0.07430543767986819 Scheduler time: 1.7910831506014802 Scheduler overhead time: 0.10955648124217987 Adapter cache time: 0.2298211336019449 Engine time: 0.10795707022771239 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-32/adapters_320_slots_160_rate_0.05-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-32/adapters_320_slots_160_rate_0.05-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [106 107 107]
Adapter prompts. [135, 540, 540, 33, 540, 540, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 540, 135, 540, 540, 33, 540, 135, 135, 540, 540, 135, 33, 33, 135, 540, 540, 135, 135, 33, 33, 135, 540, 540, 33, 540, 135, 33, 135, 540, 33, 135, 540, 540, 135, 33, 33, 540, 33, 33, 540, 540, 33, 33, 135, 135, 135, 33, 135, 33, 540, 33, 540, 135, 540, 540, 33, 540, 33, 540, 135, 33, 33, 135, 135, 540, 135, 540, 540, 540, 33, 135, 135, 33, 540, 135, 540, 540, 135, 33, 135, 135, 135, 33, 540, 135, 540, 33, 540, 33, 33, 135, 540, 540, 135, 33, 135, 33, 135, 540, 540, 135, 33, 135, 33, 540, 33, 33, 33, 33, 540, 135, 135, 540, 135, 135, 33, 135, 540, 135, 33, 33, 135, 540, 33, 33, 33, 540, 540, 540, 33, 135, 540, 135, 135, 135, 33, 540, 33, 540, 135, 33, 135, 33, 33, 135, 33, 135, 540, 540, 540, 540, 135, 135, 540, 540, 540, 135, 540, 33, 33, 540, 135, 540, 135, 540, 135, 33, 135, 33, 33, 33, 540, 540, 135, 135, 33, 33, 135, 33, 540, 33, 33, 135, 33, 540, 135, 33, 540, 33, 33, 540, 135, 540, 135, 33, 135, 540, 135, 135, 540, 135, 33, 135, 33, 540, 135, 135, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 135, 33, 135, 33, 135, 540, 540, 540, 33, 540, 540, 540, 540, 33, 135, 135, 540, 33, 540, 33, 33, 33, 540, 135, 540, 540, 33, 135, 135, 135, 33, 135, 33, 135, 135, 540, 33, 33, 135, 33, 135, 135, 33, 540, 540, 540, 33, 135, 135, 135, 135, 33, 135, 33, 540, 33, 33, 540, 135, 540, 135, 135, 135, 135, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 135, 540, 135, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 75723 . Total input tokens: 16854799 . Total output tokens: 15128237
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 2.3489621840417385,
    "estimated_duration": 3599.943456439748,
    "input_throughput": 1731.5255296161422,
    "output_throughput": 1563.3762219048888,
    "total_throughput": 3294.901751521031,
    "itl": 31.05994735535198,
    "ttft": 5438.248865592642,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5676,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.033028849361905,
    "arrivals": 25398,
    "finished_requests": 25360,
    "scheduler_time": 2.697449339920492
}
#Debug simulation 
Total elapsed time: 2.349046334042214. Arrivals time: 0.073639469104819 Scheduler time: 1.7773526174132712 Scheduler overhead time: 0.10978113167220727 Adapter cache time: 0.22951995342737064 Engine time: 0.1069196222233586 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-8/adapters_320_slots_160_rate_0.05-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-8/adapters_320_slots_160_rate_0.05-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [106 107 107]
Adapter prompts. [66, 540, 540, 33, 540, 540, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 540, 66, 540, 540, 33, 540, 66, 66, 540, 540, 66, 33, 33, 66, 540, 540, 66, 66, 33, 33, 66, 540, 540, 33, 540, 66, 33, 66, 540, 33, 66, 540, 540, 66, 33, 33, 540, 33, 33, 540, 540, 33, 33, 66, 66, 66, 33, 66, 33, 540, 33, 540, 66, 540, 540, 33, 540, 33, 540, 66, 33, 33, 66, 66, 540, 66, 540, 540, 540, 33, 66, 66, 33, 540, 66, 540, 540, 66, 33, 66, 66, 66, 33, 540, 66, 540, 33, 540, 33, 33, 66, 540, 540, 66, 33, 66, 33, 66, 540, 540, 66, 33, 66, 33, 540, 33, 33, 33, 33, 540, 66, 66, 540, 66, 66, 33, 66, 540, 66, 33, 33, 66, 540, 33, 33, 33, 540, 540, 540, 33, 66, 540, 66, 66, 66, 33, 540, 33, 540, 66, 33, 66, 33, 33, 66, 33, 66, 540, 540, 540, 540, 66, 66, 540, 540, 540, 66, 540, 33, 33, 540, 66, 540, 66, 540, 66, 33, 66, 33, 33, 33, 540, 540, 66, 66, 33, 33, 66, 33, 540, 33, 33, 66, 33, 540, 66, 33, 540, 33, 33, 540, 66, 540, 66, 33, 66, 540, 66, 66, 540, 66, 33, 66, 33, 540, 66, 66, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 66, 33, 66, 33, 66, 540, 540, 540, 33, 540, 540, 540, 540, 33, 66, 66, 540, 33, 540, 33, 33, 33, 540, 66, 540, 540, 33, 66, 66, 66, 33, 66, 33, 66, 66, 540, 33, 33, 66, 33, 66, 66, 33, 540, 540, 540, 33, 66, 66, 66, 66, 33, 66, 33, 540, 33, 33, 540, 66, 540, 66, 66, 66, 66, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 66, 540, 66, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 68340 . Total input tokens: 15202698 . Total output tokens: 13659282
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 2.1604587439796887,
    "estimated_duration": 3599.9641662745425,
    "input_throughput": 1576.9134740790278,
    "output_throughput": 1406.7817806200292,
    "total_throughput": 2983.695254699057,
    "itl": 28.244090717028076,
    "ttft": 4903.130368349488,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3228,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.87925443741469,
    "arrivals": 22982,
    "finished_requests": 22951,
    "scheduler_time": 0.6067998359721708
}
#Debug simulation 
Total elapsed time: 2.160550909989979. Arrivals time: 0.07001011545071378 Scheduler time: 1.5995411537005566 Scheduler overhead time: 0.11642776289954782 Adapter cache time: 0.2033423907123506 Engine time: 0.1146673351759091 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-16/adapters_320_slots_160_rate_0.05-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-16/adapters_320_slots_160_rate_0.05-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [106 107 107]
Adapter prompts. [66, 540, 540, 33, 540, 540, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 540, 66, 540, 540, 33, 540, 66, 66, 540, 540, 66, 33, 33, 66, 540, 540, 66, 66, 33, 33, 66, 540, 540, 33, 540, 66, 33, 66, 540, 33, 66, 540, 540, 66, 33, 33, 540, 33, 33, 540, 540, 33, 33, 66, 66, 66, 33, 66, 33, 540, 33, 540, 66, 540, 540, 33, 540, 33, 540, 66, 33, 33, 66, 66, 540, 66, 540, 540, 540, 33, 66, 66, 33, 540, 66, 540, 540, 66, 33, 66, 66, 66, 33, 540, 66, 540, 33, 540, 33, 33, 66, 540, 540, 66, 33, 66, 33, 66, 540, 540, 66, 33, 66, 33, 540, 33, 33, 33, 33, 540, 66, 66, 540, 66, 66, 33, 66, 540, 66, 33, 33, 66, 540, 33, 33, 33, 540, 540, 540, 33, 66, 540, 66, 66, 66, 33, 540, 33, 540, 66, 33, 66, 33, 33, 66, 33, 66, 540, 540, 540, 540, 66, 66, 540, 540, 540, 66, 540, 33, 33, 540, 66, 540, 66, 540, 66, 33, 66, 33, 33, 33, 540, 540, 66, 66, 33, 33, 66, 33, 540, 33, 33, 66, 33, 540, 66, 33, 540, 33, 33, 540, 66, 540, 66, 33, 66, 540, 66, 66, 540, 66, 33, 66, 33, 540, 66, 66, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 66, 33, 66, 33, 66, 540, 540, 540, 33, 540, 540, 540, 540, 33, 66, 66, 540, 33, 540, 33, 33, 33, 540, 66, 540, 540, 33, 66, 66, 66, 33, 66, 33, 66, 66, 540, 33, 33, 66, 33, 66, 66, 33, 540, 540, 540, 33, 66, 66, 66, 66, 33, 66, 33, 540, 33, 33, 540, 66, 540, 66, 66, 66, 66, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 66, 540, 66, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 68340 . Total input tokens: 15202698 . Total output tokens: 13659282
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 2.169029857032001,
    "estimated_duration": 3599.9654188305167,
    "input_throughput": 1576.9129254147595,
    "output_throughput": 1406.7812911506264,
    "total_throughput": 2983.694216565386,
    "itl": 28.25226317337013,
    "ttft": 4903.049790812043,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3229,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.541932838573219,
    "arrivals": 22982,
    "finished_requests": 22951,
    "scheduler_time": 0.608261054519111
}
#Debug simulation 
Total elapsed time: 2.169134768017102. Arrivals time: 0.06991842604475096 Scheduler time: 1.6109572788700461 Scheduler overhead time: 0.11657889210619032 Adapter cache time: 0.20363361691124737 Engine time: 0.11239568970631808 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-32/adapters_320_slots_160_rate_0.05-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-32/adapters_320_slots_160_rate_0.05-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [106 107 107]
Adapter prompts. [66, 540, 540, 33, 540, 540, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 540, 66, 540, 540, 33, 540, 66, 66, 540, 540, 66, 33, 33, 66, 540, 540, 66, 66, 33, 33, 66, 540, 540, 33, 540, 66, 33, 66, 540, 33, 66, 540, 540, 66, 33, 33, 540, 33, 33, 540, 540, 33, 33, 66, 66, 66, 33, 66, 33, 540, 33, 540, 66, 540, 540, 33, 540, 33, 540, 66, 33, 33, 66, 66, 540, 66, 540, 540, 540, 33, 66, 66, 33, 540, 66, 540, 540, 66, 33, 66, 66, 66, 33, 540, 66, 540, 33, 540, 33, 33, 66, 540, 540, 66, 33, 66, 33, 66, 540, 540, 66, 33, 66, 33, 540, 33, 33, 33, 33, 540, 66, 66, 540, 66, 66, 33, 66, 540, 66, 33, 33, 66, 540, 33, 33, 33, 540, 540, 540, 33, 66, 540, 66, 66, 66, 33, 540, 33, 540, 66, 33, 66, 33, 33, 66, 33, 66, 540, 540, 540, 540, 66, 66, 540, 540, 540, 66, 540, 33, 33, 540, 66, 540, 66, 540, 66, 33, 66, 33, 33, 33, 540, 540, 66, 66, 33, 33, 66, 33, 540, 33, 33, 66, 33, 540, 66, 33, 540, 33, 33, 540, 66, 540, 66, 33, 66, 540, 66, 66, 540, 66, 33, 66, 33, 540, 66, 66, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 66, 33, 66, 33, 66, 540, 540, 540, 33, 540, 540, 540, 540, 33, 66, 66, 540, 33, 540, 33, 33, 33, 540, 66, 540, 540, 33, 66, 66, 66, 33, 66, 33, 66, 66, 540, 33, 33, 66, 33, 66, 66, 33, 540, 540, 540, 33, 66, 66, 66, 66, 33, 66, 33, 540, 33, 33, 540, 66, 540, 66, 66, 66, 66, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 66, 540, 66, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 68340 . Total input tokens: 15202698 . Total output tokens: 13659282
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 2.1953852649894543,
    "estimated_duration": 3599.96015892308,
    "input_throughput": 1576.915229444709,
    "output_throughput": 1406.7833466009781,
    "total_throughput": 2983.6985760456873,
    "itl": 28.25323424405799,
    "ttft": 4902.913759700284,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3229,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.559686673301739,
    "arrivals": 22982,
    "finished_requests": 22951,
    "scheduler_time": 0.6084818509893617
}
#Debug simulation 
Total elapsed time: 2.195480720954947. Arrivals time: 0.06964829418575391 Scheduler time: 1.6349489330896176 Scheduler overhead time: 0.11647700233152136 Adapter cache time: 0.20344212476629764 Engine time: 0.11500425718259066 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-16/adapters_320_slots_160_rate_0.05-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-16/adapters_320_slots_160_rate_0.05-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [106 107 107]
Adapter prompts. [66, 540, 540, 33, 540, 540, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 540, 66, 540, 540, 33, 540, 66, 66, 540, 540, 66, 33, 33, 66, 540, 540, 66, 66, 33, 33, 66, 540, 540, 33, 540, 66, 33, 66, 540, 33, 66, 540, 540, 66, 33, 33, 540, 33, 33, 540, 540, 33, 33, 66, 66, 66, 33, 66, 33, 540, 33, 540, 66, 540, 540, 33, 540, 33, 540, 66, 33, 33, 66, 66, 540, 66, 540, 540, 540, 33, 66, 66, 33, 540, 66, 540, 540, 66, 33, 66, 66, 66, 33, 540, 66, 540, 33, 540, 33, 33, 66, 540, 540, 66, 33, 66, 33, 66, 540, 540, 66, 33, 66, 33, 540, 33, 33, 33, 33, 540, 66, 66, 540, 66, 66, 33, 66, 540, 66, 33, 33, 66, 540, 33, 33, 33, 540, 540, 540, 33, 66, 540, 66, 66, 66, 33, 540, 33, 540, 66, 33, 66, 33, 33, 66, 33, 66, 540, 540, 540, 540, 66, 66, 540, 540, 540, 66, 540, 33, 33, 540, 66, 540, 66, 540, 66, 33, 66, 33, 33, 33, 540, 540, 66, 66, 33, 33, 66, 33, 540, 33, 33, 66, 33, 540, 66, 33, 540, 33, 33, 540, 66, 540, 66, 33, 66, 540, 66, 66, 540, 66, 33, 66, 33, 540, 66, 66, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 66, 33, 66, 33, 66, 540, 540, 540, 33, 540, 540, 540, 540, 33, 66, 66, 540, 33, 540, 33, 33, 33, 540, 66, 540, 540, 33, 66, 66, 66, 33, 66, 33, 66, 66, 540, 33, 33, 66, 33, 66, 66, 33, 540, 540, 540, 33, 66, 66, 66, 66, 33, 66, 33, 540, 33, 33, 540, 66, 540, 66, 66, 66, 66, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 66, 540, 66, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 68340 . Total input tokens: 15202698 . Total output tokens: 13659282
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 2.187801669992041,
    "estimated_duration": 3599.94425860845,
    "input_throughput": 1576.9221943993005,
    "output_throughput": 1406.7895601132495,
    "total_throughput": 2983.71175451255,
    "itl": 28.246660261503347,
    "ttft": 4902.838499141131,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3228,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.084993389491144,
    "arrivals": 22982,
    "finished_requests": 22951,
    "scheduler_time": 0.6073785356340943
}
#Debug simulation 
Total elapsed time: 2.1878906719502993. Arrivals time: 0.06846163282170892 Scheduler time: 1.6278224781272002 Scheduler overhead time: 0.11734015680849552 Adapter cache time: 0.20383978338213637 Engine time: 0.11403226712718606 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-32/adapters_320_slots_160_rate_0.05-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-32/adapters_320_slots_160_rate_0.05-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [106 107 107]
Adapter prompts. [66, 540, 540, 33, 540, 540, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 540, 66, 540, 540, 33, 540, 66, 66, 540, 540, 66, 33, 33, 66, 540, 540, 66, 66, 33, 33, 66, 540, 540, 33, 540, 66, 33, 66, 540, 33, 66, 540, 540, 66, 33, 33, 540, 33, 33, 540, 540, 33, 33, 66, 66, 66, 33, 66, 33, 540, 33, 540, 66, 540, 540, 33, 540, 33, 540, 66, 33, 33, 66, 66, 540, 66, 540, 540, 540, 33, 66, 66, 33, 540, 66, 540, 540, 66, 33, 66, 66, 66, 33, 540, 66, 540, 33, 540, 33, 33, 66, 540, 540, 66, 33, 66, 33, 66, 540, 540, 66, 33, 66, 33, 540, 33, 33, 33, 33, 540, 66, 66, 540, 66, 66, 33, 66, 540, 66, 33, 33, 66, 540, 33, 33, 33, 540, 540, 540, 33, 66, 540, 66, 66, 66, 33, 540, 33, 540, 66, 33, 66, 33, 33, 66, 33, 66, 540, 540, 540, 540, 66, 66, 540, 540, 540, 66, 540, 33, 33, 540, 66, 540, 66, 540, 66, 33, 66, 33, 33, 33, 540, 540, 66, 66, 33, 33, 66, 33, 540, 33, 33, 66, 33, 540, 66, 33, 540, 33, 33, 540, 66, 540, 66, 33, 66, 540, 66, 66, 540, 66, 33, 66, 33, 540, 66, 66, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 66, 33, 66, 33, 66, 540, 540, 540, 33, 540, 540, 540, 540, 33, 66, 66, 540, 33, 540, 33, 33, 33, 540, 66, 540, 540, 33, 66, 66, 66, 33, 66, 33, 66, 66, 540, 33, 33, 66, 33, 66, 66, 33, 540, 540, 540, 33, 66, 66, 66, 66, 33, 66, 33, 540, 33, 33, 540, 66, 540, 66, 66, 66, 66, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 66, 540, 66, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 68340 . Total input tokens: 15202698 . Total output tokens: 13659282
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 2.1924917790456675,
    "estimated_duration": 3599.960461971337,
    "input_throughput": 1576.9150966984146,
    "output_throughput": 1406.7832281765552,
    "total_throughput": 2983.69832487497,
    "itl": 28.254483617813428,
    "ttft": 4902.990058547188,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3229,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.699399130008581,
    "arrivals": 22982,
    "finished_requests": 22951,
    "scheduler_time": 0.6088091050746915
}
#Debug simulation 
Total elapsed time: 2.192581201030407. Arrivals time: 0.06906190299196169 Scheduler time: 1.6342822896549478 Scheduler overhead time: 0.11593441019067541 Adapter cache time: 0.20258789043873549 Engine time: 0.11466966359876096 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-16/adapters_320_slots_160_rate_0.05-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-16/adapters_320_slots_160_rate_0.05-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [106 107 107]
Adapter prompts. [66, 540, 540, 33, 540, 540, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 540, 66, 540, 540, 33, 540, 66, 66, 540, 540, 66, 33, 33, 66, 540, 540, 66, 66, 33, 33, 66, 540, 540, 33, 540, 66, 33, 66, 540, 33, 66, 540, 540, 66, 33, 33, 540, 33, 33, 540, 540, 33, 33, 66, 66, 66, 33, 66, 33, 540, 33, 540, 66, 540, 540, 33, 540, 33, 540, 66, 33, 33, 66, 66, 540, 66, 540, 540, 540, 33, 66, 66, 33, 540, 66, 540, 540, 66, 33, 66, 66, 66, 33, 540, 66, 540, 33, 540, 33, 33, 66, 540, 540, 66, 33, 66, 33, 66, 540, 540, 66, 33, 66, 33, 540, 33, 33, 33, 33, 540, 66, 66, 540, 66, 66, 33, 66, 540, 66, 33, 33, 66, 540, 33, 33, 33, 540, 540, 540, 33, 66, 540, 66, 66, 66, 33, 540, 33, 540, 66, 33, 66, 33, 33, 66, 33, 66, 540, 540, 540, 540, 66, 66, 540, 540, 540, 66, 540, 33, 33, 540, 66, 540, 66, 540, 66, 33, 66, 33, 33, 33, 540, 540, 66, 66, 33, 33, 66, 33, 540, 33, 33, 66, 33, 540, 66, 33, 540, 33, 33, 540, 66, 540, 66, 33, 66, 540, 66, 66, 540, 66, 33, 66, 33, 540, 66, 66, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 66, 33, 66, 33, 66, 540, 540, 540, 33, 540, 540, 540, 540, 33, 66, 66, 540, 33, 540, 33, 33, 33, 540, 66, 540, 540, 33, 66, 66, 66, 33, 66, 33, 66, 66, 540, 33, 33, 66, 33, 66, 66, 33, 540, 540, 540, 33, 66, 66, 66, 66, 33, 66, 33, 540, 33, 33, 540, 66, 540, 66, 66, 66, 66, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 66, 540, 66, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 68340 . Total input tokens: 15202698 . Total output tokens: 13659282
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 2.1953063319670036,
    "estimated_duration": 3599.957396354733,
    "input_throughput": 1576.9164395523906,
    "output_throughput": 1406.7844261512942,
    "total_throughput": 2983.7008657036845,
    "itl": 28.240808870026083,
    "ttft": 4902.879156869804,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3228,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.651882351944407,
    "arrivals": 22982,
    "finished_requests": 22951,
    "scheduler_time": 0.6060260682842715
}
#Debug simulation 
Total elapsed time: 2.1953930080053397. Arrivals time: 0.06931488338159397 Scheduler time: 1.6352795382845215 Scheduler overhead time: 0.11647360940696672 Adapter cache time: 0.2029387154034339 Engine time: 0.11540115479147062 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-32/adapters_320_slots_160_rate_0.05-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-32/adapters_320_slots_160_rate_0.05-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [106 107 107]
Adapter prompts. [66, 540, 540, 33, 540, 540, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 540, 66, 540, 540, 33, 540, 66, 66, 540, 540, 66, 33, 33, 66, 540, 540, 66, 66, 33, 33, 66, 540, 540, 33, 540, 66, 33, 66, 540, 33, 66, 540, 540, 66, 33, 33, 540, 33, 33, 540, 540, 33, 33, 66, 66, 66, 33, 66, 33, 540, 33, 540, 66, 540, 540, 33, 540, 33, 540, 66, 33, 33, 66, 66, 540, 66, 540, 540, 540, 33, 66, 66, 33, 540, 66, 540, 540, 66, 33, 66, 66, 66, 33, 540, 66, 540, 33, 540, 33, 33, 66, 540, 540, 66, 33, 66, 33, 66, 540, 540, 66, 33, 66, 33, 540, 33, 33, 33, 33, 540, 66, 66, 540, 66, 66, 33, 66, 540, 66, 33, 33, 66, 540, 33, 33, 33, 540, 540, 540, 33, 66, 540, 66, 66, 66, 33, 540, 33, 540, 66, 33, 66, 33, 33, 66, 33, 66, 540, 540, 540, 540, 66, 66, 540, 540, 540, 66, 540, 33, 33, 540, 66, 540, 66, 540, 66, 33, 66, 33, 33, 33, 540, 540, 66, 66, 33, 33, 66, 33, 540, 33, 33, 66, 33, 540, 66, 33, 540, 33, 33, 540, 66, 540, 66, 33, 66, 540, 66, 66, 540, 66, 33, 66, 33, 540, 66, 66, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 66, 33, 66, 33, 66, 540, 540, 540, 33, 540, 540, 540, 540, 33, 66, 66, 540, 33, 540, 33, 33, 33, 540, 66, 540, 540, 33, 66, 66, 66, 33, 66, 33, 66, 66, 540, 33, 33, 66, 33, 66, 66, 33, 540, 540, 540, 33, 66, 66, 66, 66, 33, 66, 33, 540, 33, 33, 540, 66, 540, 66, 66, 66, 66, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 66, 540, 66, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 68340 . Total input tokens: 15202698 . Total output tokens: 13659282
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 2.1990710590034723,
    "estimated_duration": 3599.964273120077,
    "input_throughput": 1576.9134272768515,
    "output_throughput": 1406.7817388672952,
    "total_throughput": 2983.6951661441467,
    "itl": 28.256547048814674,
    "ttft": 4902.943409337088,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3228,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.82919162347852,
    "arrivals": 22982,
    "finished_requests": 22951,
    "scheduler_time": 0.6092915214616168
}
#Debug simulation 
Total elapsed time: 2.1991594689898193. Arrivals time: 0.06866674788761884 Scheduler time: 1.6392564325360581 Scheduler overhead time: 0.11644983518635854 Adapter cache time: 0.20276901189936325 Engine time: 0.11582379043102264 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-8/adapters_320_slots_160_rate_0.025-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-8/adapters_320_slots_160_rate_0.025-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [106 107 107]
Adapter prompts. [135, 270, 270, 66, 270, 270, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 270, 135, 270, 270, 66, 270, 135, 135, 270, 270, 135, 66, 66, 135, 270, 270, 135, 135, 66, 66, 135, 270, 270, 66, 270, 135, 66, 135, 270, 66, 135, 270, 270, 135, 66, 66, 270, 66, 66, 270, 270, 66, 66, 135, 135, 135, 66, 135, 66, 270, 66, 270, 135, 270, 270, 66, 270, 66, 270, 135, 66, 66, 135, 135, 270, 135, 270, 270, 270, 66, 135, 135, 66, 270, 135, 270, 270, 135, 66, 135, 135, 135, 66, 270, 135, 270, 66, 270, 66, 66, 135, 270, 270, 135, 66, 135, 66, 135, 270, 270, 135, 66, 135, 66, 270, 66, 66, 66, 66, 270, 135, 135, 270, 135, 135, 66, 135, 270, 135, 66, 66, 135, 270, 66, 66, 66, 270, 270, 270, 66, 135, 270, 135, 135, 135, 66, 270, 66, 270, 135, 66, 135, 66, 66, 135, 66, 135, 270, 270, 270, 270, 135, 135, 270, 270, 270, 135, 270, 66, 66, 270, 135, 270, 135, 270, 135, 66, 135, 66, 66, 66, 270, 270, 135, 135, 66, 66, 135, 66, 270, 66, 66, 135, 66, 270, 135, 66, 270, 66, 66, 270, 135, 270, 135, 66, 135, 270, 135, 135, 270, 135, 66, 135, 66, 270, 135, 135, 270, 270, 66, 66, 66, 270, 270, 66, 66, 270, 135, 66, 135, 66, 135, 270, 270, 270, 66, 270, 270, 270, 270, 66, 135, 135, 270, 66, 270, 66, 66, 66, 270, 135, 270, 270, 66, 135, 135, 135, 66, 135, 66, 135, 135, 270, 66, 66, 135, 66, 135, 135, 66, 270, 270, 270, 66, 135, 135, 135, 135, 66, 135, 66, 270, 66, 66, 270, 135, 270, 135, 135, 135, 135, 66, 66, 270, 66, 66, 270, 270, 270, 66, 270, 270, 135, 270, 135, 66, 270, 66, 270, 270, 66, 66, 66]
Prompts retrieved: 50331 . Total input tokens: 11166485 . Total output tokens: 10087733
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 1.8145874500041828,
    "estimated_duration": 3599.8150853916877,
    "input_throughput": 1180.9031572902181,
    "output_throughput": 1042.7621727663166,
    "total_throughput": 2223.665330056535,
    "itl": 24.646593766488056,
    "ttft": 7637.66387427627,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6768,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.713381050936608,
    "arrivals": 17062,
    "finished_requests": 17026,
    "scheduler_time": 0.00042925062243853273
}
#Debug simulation 
Total elapsed time: 1.8146759169758298. Arrivals time: 0.05523080739658326 Scheduler time: 1.257391907973215 Scheduler overhead time: 0.12860352243296802 Adapter cache time: 0.1854741399292834 Engine time: 0.1255162800080143 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-16/adapters_320_slots_160_rate_0.025-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-16/adapters_320_slots_160_rate_0.025-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [106 107 107]
Adapter prompts. [135, 270, 270, 66, 270, 270, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 270, 135, 270, 270, 66, 270, 135, 135, 270, 270, 135, 66, 66, 135, 270, 270, 135, 135, 66, 66, 135, 270, 270, 66, 270, 135, 66, 135, 270, 66, 135, 270, 270, 135, 66, 66, 270, 66, 66, 270, 270, 66, 66, 135, 135, 135, 66, 135, 66, 270, 66, 270, 135, 270, 270, 66, 270, 66, 270, 135, 66, 66, 135, 135, 270, 135, 270, 270, 270, 66, 135, 135, 66, 270, 135, 270, 270, 135, 66, 135, 135, 135, 66, 270, 135, 270, 66, 270, 66, 66, 135, 270, 270, 135, 66, 135, 66, 135, 270, 270, 135, 66, 135, 66, 270, 66, 66, 66, 66, 270, 135, 135, 270, 135, 135, 66, 135, 270, 135, 66, 66, 135, 270, 66, 66, 66, 270, 270, 270, 66, 135, 270, 135, 135, 135, 66, 270, 66, 270, 135, 66, 135, 66, 66, 135, 66, 135, 270, 270, 270, 270, 135, 135, 270, 270, 270, 135, 270, 66, 66, 270, 135, 270, 135, 270, 135, 66, 135, 66, 66, 66, 270, 270, 135, 135, 66, 66, 135, 66, 270, 66, 66, 135, 66, 270, 135, 66, 270, 66, 66, 270, 135, 270, 135, 66, 135, 270, 135, 135, 270, 135, 66, 135, 66, 270, 135, 135, 270, 270, 66, 66, 66, 270, 270, 66, 66, 270, 135, 66, 135, 66, 135, 270, 270, 270, 66, 270, 270, 270, 270, 66, 135, 135, 270, 66, 270, 66, 66, 66, 270, 135, 270, 270, 66, 135, 135, 135, 66, 135, 66, 135, 135, 270, 66, 66, 135, 66, 135, 135, 66, 270, 270, 270, 66, 135, 135, 135, 135, 66, 135, 66, 270, 66, 66, 270, 135, 270, 135, 135, 135, 135, 66, 66, 270, 66, 66, 270, 270, 270, 66, 270, 270, 135, 270, 135, 66, 270, 66, 270, 270, 66, 66, 66]
Prompts retrieved: 50331 . Total input tokens: 11166485 . Total output tokens: 10087733
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 1.7830122039886191,
    "estimated_duration": 3599.8067580568354,
    "input_throughput": 1180.9058890413037,
    "output_throughput": 1042.764584959628,
    "total_throughput": 2223.670474000932,
    "itl": 24.660393853332295,
    "ttft": 7637.736194639789,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6770,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.08989993115543,
    "arrivals": 17062,
    "finished_requests": 17026,
    "scheduler_time": 0.00044709782662158274
}
#Debug simulation 
Total elapsed time: 1.7830996689735912. Arrivals time: 0.05443491862388328 Scheduler time: 1.2283243187703192 Scheduler overhead time: 0.12883248808793724 Adapter cache time: 0.18362615368096158 Engine time: 0.12535047152778134 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-32/adapters_320_slots_160_rate_0.025-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-32/adapters_320_slots_160_rate_0.025-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [106 107 107]
Adapter prompts. [135, 270, 270, 66, 270, 270, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 270, 135, 270, 270, 66, 270, 135, 135, 270, 270, 135, 66, 66, 135, 270, 270, 135, 135, 66, 66, 135, 270, 270, 66, 270, 135, 66, 135, 270, 66, 135, 270, 270, 135, 66, 66, 270, 66, 66, 270, 270, 66, 66, 135, 135, 135, 66, 135, 66, 270, 66, 270, 135, 270, 270, 66, 270, 66, 270, 135, 66, 66, 135, 135, 270, 135, 270, 270, 270, 66, 135, 135, 66, 270, 135, 270, 270, 135, 66, 135, 135, 135, 66, 270, 135, 270, 66, 270, 66, 66, 135, 270, 270, 135, 66, 135, 66, 135, 270, 270, 135, 66, 135, 66, 270, 66, 66, 66, 66, 270, 135, 135, 270, 135, 135, 66, 135, 270, 135, 66, 66, 135, 270, 66, 66, 66, 270, 270, 270, 66, 135, 270, 135, 135, 135, 66, 270, 66, 270, 135, 66, 135, 66, 66, 135, 66, 135, 270, 270, 270, 270, 135, 135, 270, 270, 270, 135, 270, 66, 66, 270, 135, 270, 135, 270, 135, 66, 135, 66, 66, 66, 270, 270, 135, 135, 66, 66, 135, 66, 270, 66, 66, 135, 66, 270, 135, 66, 270, 66, 66, 270, 135, 270, 135, 66, 135, 270, 135, 135, 270, 135, 66, 135, 66, 270, 135, 135, 270, 270, 66, 66, 66, 270, 270, 66, 66, 270, 135, 66, 135, 66, 135, 270, 270, 270, 66, 270, 270, 270, 270, 66, 135, 135, 270, 66, 270, 66, 66, 66, 270, 135, 270, 270, 66, 135, 135, 135, 66, 135, 66, 135, 135, 270, 66, 66, 135, 66, 135, 135, 66, 270, 270, 270, 66, 135, 135, 135, 135, 66, 135, 66, 270, 66, 66, 270, 135, 270, 135, 135, 135, 135, 66, 66, 270, 66, 66, 270, 270, 270, 66, 270, 270, 135, 270, 135, 66, 270, 66, 270, 270, 66, 66, 66]
Prompts retrieved: 50331 . Total input tokens: 11166485 . Total output tokens: 10087733
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 1.789983046008274,
    "estimated_duration": 3599.80811380403,
    "input_throughput": 1180.9054442926404,
    "output_throughput": 1042.7641922372616,
    "total_throughput": 2223.669636529902,
    "itl": 24.66153212089849,
    "ttft": 7637.773810438035,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6767,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.119513477403395,
    "arrivals": 17062,
    "finished_requests": 17026,
    "scheduler_time": 0.00043900821053908406
}
#Debug simulation 
Total elapsed time: 1.7900841779774055. Arrivals time: 0.05595815775450319 Scheduler time: 1.234381411690265 Scheduler overhead time: 0.12805412989109755 Adapter cache time: 0.18371582496911287 Engine time: 0.1257212400669232 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-16/adapters_320_slots_160_rate_0.025-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-16/adapters_320_slots_160_rate_0.025-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [106 107 107]
Adapter prompts. [135, 270, 270, 66, 270, 270, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 270, 135, 270, 270, 66, 270, 135, 135, 270, 270, 135, 66, 66, 135, 270, 270, 135, 135, 66, 66, 135, 270, 270, 66, 270, 135, 66, 135, 270, 66, 135, 270, 270, 135, 66, 66, 270, 66, 66, 270, 270, 66, 66, 135, 135, 135, 66, 135, 66, 270, 66, 270, 135, 270, 270, 66, 270, 66, 270, 135, 66, 66, 135, 135, 270, 135, 270, 270, 270, 66, 135, 135, 66, 270, 135, 270, 270, 135, 66, 135, 135, 135, 66, 270, 135, 270, 66, 270, 66, 66, 135, 270, 270, 135, 66, 135, 66, 135, 270, 270, 135, 66, 135, 66, 270, 66, 66, 66, 66, 270, 135, 135, 270, 135, 135, 66, 135, 270, 135, 66, 66, 135, 270, 66, 66, 66, 270, 270, 270, 66, 135, 270, 135, 135, 135, 66, 270, 66, 270, 135, 66, 135, 66, 66, 135, 66, 135, 270, 270, 270, 270, 135, 135, 270, 270, 270, 135, 270, 66, 66, 270, 135, 270, 135, 270, 135, 66, 135, 66, 66, 66, 270, 270, 135, 135, 66, 66, 135, 66, 270, 66, 66, 135, 66, 270, 135, 66, 270, 66, 66, 270, 135, 270, 135, 66, 135, 270, 135, 135, 270, 135, 66, 135, 66, 270, 135, 135, 270, 270, 66, 66, 66, 270, 270, 66, 66, 270, 135, 66, 135, 66, 135, 270, 270, 270, 66, 270, 270, 270, 270, 66, 135, 135, 270, 66, 270, 66, 66, 66, 270, 135, 270, 270, 66, 135, 135, 135, 66, 135, 66, 135, 135, 270, 66, 66, 135, 66, 135, 135, 66, 270, 270, 270, 66, 135, 135, 135, 135, 66, 135, 66, 270, 66, 66, 270, 135, 270, 135, 135, 135, 135, 66, 66, 270, 66, 66, 270, 270, 270, 66, 270, 270, 135, 270, 135, 66, 270, 66, 270, 270, 66, 66, 66]
Prompts retrieved: 50331 . Total input tokens: 11166485 . Total output tokens: 10087733
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 1.788630302005913,
    "estimated_duration": 3599.806512142636,
    "input_throughput": 1180.90596971273,
    "output_throughput": 1042.7646561941838,
    "total_throughput": 2223.6706259069138,
    "itl": 24.65058017867599,
    "ttft": 7637.677506215446,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6768,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.176429628310377,
    "arrivals": 17062,
    "finished_requests": 17026,
    "scheduler_time": 0.00044221903257130697
}
#Debug simulation 
Total elapsed time: 1.7887178880046122. Arrivals time: 0.05516154889483005 Scheduler time: 1.2346555478288792 Scheduler overhead time: 0.12848904263228178 Adapter cache time: 0.18341931013856083 Engine time: 0.12473648111335933 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-32/adapters_320_slots_160_rate_0.025-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-32/adapters_320_slots_160_rate_0.025-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [106 107 107]
Adapter prompts. [135, 270, 270, 66, 270, 270, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 270, 135, 270, 270, 66, 270, 135, 135, 270, 270, 135, 66, 66, 135, 270, 270, 135, 135, 66, 66, 135, 270, 270, 66, 270, 135, 66, 135, 270, 66, 135, 270, 270, 135, 66, 66, 270, 66, 66, 270, 270, 66, 66, 135, 135, 135, 66, 135, 66, 270, 66, 270, 135, 270, 270, 66, 270, 66, 270, 135, 66, 66, 135, 135, 270, 135, 270, 270, 270, 66, 135, 135, 66, 270, 135, 270, 270, 135, 66, 135, 135, 135, 66, 270, 135, 270, 66, 270, 66, 66, 135, 270, 270, 135, 66, 135, 66, 135, 270, 270, 135, 66, 135, 66, 270, 66, 66, 66, 66, 270, 135, 135, 270, 135, 135, 66, 135, 270, 135, 66, 66, 135, 270, 66, 66, 66, 270, 270, 270, 66, 135, 270, 135, 135, 135, 66, 270, 66, 270, 135, 66, 135, 66, 66, 135, 66, 135, 270, 270, 270, 270, 135, 135, 270, 270, 270, 135, 270, 66, 66, 270, 135, 270, 135, 270, 135, 66, 135, 66, 66, 66, 270, 270, 135, 135, 66, 66, 135, 66, 270, 66, 66, 135, 66, 270, 135, 66, 270, 66, 66, 270, 135, 270, 135, 66, 135, 270, 135, 135, 270, 135, 66, 135, 66, 270, 135, 135, 270, 270, 66, 66, 66, 270, 270, 66, 66, 270, 135, 66, 135, 66, 135, 270, 270, 270, 66, 270, 270, 270, 270, 66, 135, 135, 270, 66, 270, 66, 66, 66, 270, 135, 270, 270, 66, 135, 135, 135, 66, 135, 66, 135, 135, 270, 66, 66, 135, 66, 135, 135, 66, 270, 270, 270, 66, 135, 135, 135, 135, 66, 135, 66, 270, 66, 66, 270, 135, 270, 135, 135, 135, 135, 66, 66, 270, 66, 66, 270, 270, 270, 66, 270, 270, 135, 270, 135, 66, 270, 66, 270, 270, 66, 66, 66]
Prompts retrieved: 50331 . Total input tokens: 11166485 . Total output tokens: 10087733
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 1.7976023909868672,
    "estimated_duration": 3599.815466451996,
    "input_throughput": 1180.90303228511,
    "output_throughput": 1042.7620623841933,
    "total_throughput": 2223.665094669303,
    "itl": 24.663571267674286,
    "ttft": 7637.694546734667,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6770,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.408617688565446,
    "arrivals": 17062,
    "finished_requests": 17026,
    "scheduler_time": 0.00044305301858033335
}
#Debug simulation 
Total elapsed time: 1.7977386279962957. Arrivals time: 0.05543969641439617 Scheduler time: 1.2390376398689114 Scheduler overhead time: 0.12829212087672204 Adapter cache time: 0.18503252882510424 Engine time: 0.12742397678084671 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-16/adapters_320_slots_160_rate_0.025-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-16/adapters_320_slots_160_rate_0.025-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [106 107 107]
Adapter prompts. [135, 270, 270, 66, 270, 270, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 270, 135, 270, 270, 66, 270, 135, 135, 270, 270, 135, 66, 66, 135, 270, 270, 135, 135, 66, 66, 135, 270, 270, 66, 270, 135, 66, 135, 270, 66, 135, 270, 270, 135, 66, 66, 270, 66, 66, 270, 270, 66, 66, 135, 135, 135, 66, 135, 66, 270, 66, 270, 135, 270, 270, 66, 270, 66, 270, 135, 66, 66, 135, 135, 270, 135, 270, 270, 270, 66, 135, 135, 66, 270, 135, 270, 270, 135, 66, 135, 135, 135, 66, 270, 135, 270, 66, 270, 66, 66, 135, 270, 270, 135, 66, 135, 66, 135, 270, 270, 135, 66, 135, 66, 270, 66, 66, 66, 66, 270, 135, 135, 270, 135, 135, 66, 135, 270, 135, 66, 66, 135, 270, 66, 66, 66, 270, 270, 270, 66, 135, 270, 135, 135, 135, 66, 270, 66, 270, 135, 66, 135, 66, 66, 135, 66, 135, 270, 270, 270, 270, 135, 135, 270, 270, 270, 135, 270, 66, 66, 270, 135, 270, 135, 270, 135, 66, 135, 66, 66, 66, 270, 270, 135, 135, 66, 66, 135, 66, 270, 66, 66, 135, 66, 270, 135, 66, 270, 66, 66, 270, 135, 270, 135, 66, 135, 270, 135, 135, 270, 135, 66, 135, 66, 270, 135, 135, 270, 270, 66, 66, 66, 270, 270, 66, 66, 270, 135, 66, 135, 66, 135, 270, 270, 270, 66, 270, 270, 270, 270, 66, 135, 135, 270, 66, 270, 66, 66, 66, 270, 135, 270, 270, 66, 135, 135, 135, 66, 135, 66, 135, 135, 270, 66, 66, 135, 66, 135, 135, 66, 270, 270, 270, 66, 135, 135, 135, 135, 66, 135, 66, 270, 66, 66, 270, 135, 270, 135, 135, 135, 135, 66, 66, 270, 66, 66, 270, 270, 270, 66, 270, 270, 135, 270, 135, 66, 270, 66, 270, 270, 66, 66, 66]
Prompts retrieved: 50331 . Total input tokens: 11166485 . Total output tokens: 10087733
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 1.7952608250197954,
    "estimated_duration": 3599.7996373528117,
    "input_throughput": 1180.9082249716782,
    "output_throughput": 1042.7666476349777,
    "total_throughput": 2223.674872606656,
    "itl": 24.641368597150993,
    "ttft": 7637.542445208433,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6770,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.24264049648816,
    "arrivals": 17062,
    "finished_requests": 17026,
    "scheduler_time": 0.00042437182838825686
}
#Debug simulation 
Total elapsed time: 1.7953509030048735. Arrivals time: 0.0543278920231387 Scheduler time: 1.2391776498989202 Scheduler overhead time: 0.1330928186653182 Adapter cache time: 0.18083006248343736 Engine time: 0.12485476129222661 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-32/adapters_320_slots_160_rate_0.025-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-32/adapters_320_slots_160_rate_0.025-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [106 107 107]
Adapter prompts. [135, 270, 270, 66, 270, 270, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 270, 135, 270, 270, 66, 270, 135, 135, 270, 270, 135, 66, 66, 135, 270, 270, 135, 135, 66, 66, 135, 270, 270, 66, 270, 135, 66, 135, 270, 66, 135, 270, 270, 135, 66, 66, 270, 66, 66, 270, 270, 66, 66, 135, 135, 135, 66, 135, 66, 270, 66, 270, 135, 270, 270, 66, 270, 66, 270, 135, 66, 66, 135, 135, 270, 135, 270, 270, 270, 66, 135, 135, 66, 270, 135, 270, 270, 135, 66, 135, 135, 135, 66, 270, 135, 270, 66, 270, 66, 66, 135, 270, 270, 135, 66, 135, 66, 135, 270, 270, 135, 66, 135, 66, 270, 66, 66, 66, 66, 270, 135, 135, 270, 135, 135, 66, 135, 270, 135, 66, 66, 135, 270, 66, 66, 66, 270, 270, 270, 66, 135, 270, 135, 135, 135, 66, 270, 66, 270, 135, 66, 135, 66, 66, 135, 66, 135, 270, 270, 270, 270, 135, 135, 270, 270, 270, 135, 270, 66, 66, 270, 135, 270, 135, 270, 135, 66, 135, 66, 66, 66, 270, 270, 135, 135, 66, 66, 135, 66, 270, 66, 66, 135, 66, 270, 135, 66, 270, 66, 66, 270, 135, 270, 135, 66, 135, 270, 135, 135, 270, 135, 66, 135, 66, 270, 135, 135, 270, 270, 66, 66, 66, 270, 270, 66, 66, 270, 135, 66, 135, 66, 135, 270, 270, 270, 66, 270, 270, 270, 270, 66, 135, 135, 270, 66, 270, 66, 66, 66, 270, 135, 270, 270, 66, 135, 135, 135, 66, 135, 66, 135, 135, 270, 66, 66, 135, 66, 135, 135, 66, 270, 270, 270, 66, 135, 135, 135, 135, 66, 135, 66, 270, 66, 66, 270, 135, 270, 135, 135, 135, 135, 66, 66, 270, 66, 66, 270, 270, 270, 66, 270, 270, 135, 270, 135, 66, 270, 66, 270, 270, 66, 66, 66]
Prompts retrieved: 50331 . Total input tokens: 11166485 . Total output tokens: 10087733
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 1.7892281329841353,
    "estimated_duration": 3599.812598804178,
    "input_throughput": 1180.9039730046368,
    "output_throughput": 1042.7628930591995,
    "total_throughput": 2223.666866063836,
    "itl": 24.666889093896728,
    "ttft": 7637.780606373118,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6766,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.684288318080903,
    "arrivals": 17062,
    "finished_requests": 17026,
    "scheduler_time": 0.0004445958685945036
}
#Debug simulation 
Total elapsed time: 1.7893146789865568. Arrivals time: 0.05539130623219535 Scheduler time: 1.232599411625415 Scheduler overhead time: 0.12824428430758417 Adapter cache time: 0.18350814923178405 Engine time: 0.1273266848293133 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-8/adapters_320_slots_160_rate_0.025-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-8/adapters_320_slots_160_rate_0.025-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [106 107 107]
Adapter prompts. [135, 270, 270, 33, 270, 270, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 270, 135, 270, 270, 33, 270, 135, 135, 270, 270, 135, 33, 33, 135, 270, 270, 135, 135, 33, 33, 135, 270, 270, 33, 270, 135, 33, 135, 270, 33, 135, 270, 270, 135, 33, 33, 270, 33, 33, 270, 270, 33, 33, 135, 135, 135, 33, 135, 33, 270, 33, 270, 135, 270, 270, 33, 270, 33, 270, 135, 33, 33, 135, 135, 270, 135, 270, 270, 270, 33, 135, 135, 33, 270, 135, 270, 270, 135, 33, 135, 135, 135, 33, 270, 135, 270, 33, 270, 33, 33, 135, 270, 270, 135, 33, 135, 33, 135, 270, 270, 135, 33, 135, 33, 270, 33, 33, 33, 33, 270, 135, 135, 270, 135, 135, 33, 135, 270, 135, 33, 33, 135, 270, 33, 33, 33, 270, 270, 270, 33, 135, 270, 135, 135, 135, 33, 270, 33, 270, 135, 33, 135, 33, 33, 135, 33, 135, 270, 270, 270, 270, 135, 135, 270, 270, 270, 135, 270, 33, 33, 270, 135, 270, 135, 270, 135, 33, 135, 33, 33, 33, 270, 270, 135, 135, 33, 33, 135, 33, 270, 33, 33, 135, 33, 270, 135, 33, 270, 33, 33, 270, 135, 270, 135, 33, 135, 270, 135, 135, 270, 135, 33, 135, 33, 270, 135, 135, 270, 270, 33, 33, 33, 270, 270, 33, 33, 270, 135, 33, 135, 33, 135, 270, 270, 270, 33, 270, 270, 270, 270, 33, 135, 135, 270, 33, 270, 33, 33, 33, 270, 135, 270, 270, 33, 135, 135, 135, 33, 135, 33, 135, 135, 270, 33, 33, 135, 33, 135, 135, 33, 270, 270, 270, 33, 135, 135, 135, 135, 33, 135, 33, 270, 33, 33, 270, 135, 270, 135, 135, 135, 135, 33, 33, 270, 33, 33, 270, 270, 270, 33, 270, 270, 135, 270, 135, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 46833 . Total input tokens: 10357816 . Total output tokens: 9396702
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 1.717014519032091,
    "estimated_duration": 3599.8490525710195,
    "input_throughput": 1091.0313023250064,
    "output_throughput": 973.7041605943415,
    "total_throughput": 2064.735462919348,
    "itl": 23.869319657075224,
    "ttft": 6378.217577839992,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5370,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.434819184917227,
    "arrivals": 15904,
    "finished_requests": 15876,
    "scheduler_time": 0.00024122936849709376
}
#Debug simulation 
Total elapsed time: 1.7171006340067834. Arrivals time: 0.05223544599721208 Scheduler time: 1.1672304074745625 Scheduler overhead time: 0.1320729738799855 Adapter cache time: 0.1704361719894223 Engine time: 0.13069938123226166 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-16/adapters_320_slots_160_rate_0.025-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-16/adapters_320_slots_160_rate_0.025-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [106 107 107]
Adapter prompts. [135, 270, 270, 33, 270, 270, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 270, 135, 270, 270, 33, 270, 135, 135, 270, 270, 135, 33, 33, 135, 270, 270, 135, 135, 33, 33, 135, 270, 270, 33, 270, 135, 33, 135, 270, 33, 135, 270, 270, 135, 33, 33, 270, 33, 33, 270, 270, 33, 33, 135, 135, 135, 33, 135, 33, 270, 33, 270, 135, 270, 270, 33, 270, 33, 270, 135, 33, 33, 135, 135, 270, 135, 270, 270, 270, 33, 135, 135, 33, 270, 135, 270, 270, 135, 33, 135, 135, 135, 33, 270, 135, 270, 33, 270, 33, 33, 135, 270, 270, 135, 33, 135, 33, 135, 270, 270, 135, 33, 135, 33, 270, 33, 33, 33, 33, 270, 135, 135, 270, 135, 135, 33, 135, 270, 135, 33, 33, 135, 270, 33, 33, 33, 270, 270, 270, 33, 135, 270, 135, 135, 135, 33, 270, 33, 270, 135, 33, 135, 33, 33, 135, 33, 135, 270, 270, 270, 270, 135, 135, 270, 270, 270, 135, 270, 33, 33, 270, 135, 270, 135, 270, 135, 33, 135, 33, 33, 33, 270, 270, 135, 135, 33, 33, 135, 33, 270, 33, 33, 135, 33, 270, 135, 33, 270, 33, 33, 270, 135, 270, 135, 33, 135, 270, 135, 135, 270, 135, 33, 135, 33, 270, 135, 135, 270, 270, 33, 33, 33, 270, 270, 33, 33, 270, 135, 33, 135, 33, 135, 270, 270, 270, 33, 270, 270, 270, 270, 33, 135, 135, 270, 33, 270, 33, 33, 33, 270, 135, 270, 270, 33, 135, 135, 135, 33, 135, 33, 135, 135, 270, 33, 33, 135, 33, 135, 135, 33, 270, 270, 270, 33, 135, 135, 135, 135, 33, 135, 33, 270, 33, 33, 270, 135, 270, 135, 135, 135, 135, 33, 33, 270, 33, 33, 270, 270, 270, 33, 270, 270, 135, 270, 135, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 46833 . Total input tokens: 10357816 . Total output tokens: 9396702
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 1.7106052199960686,
    "estimated_duration": 3599.8645937027754,
    "input_throughput": 1091.026592186395,
    "output_throughput": 973.6999569738282,
    "total_throughput": 2064.726549160223,
    "itl": 23.881017041707313,
    "ttft": 6378.480856174812,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5369,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.51553408270989,
    "arrivals": 15904,
    "finished_requests": 15876,
    "scheduler_time": 0.00022588412234112292
}
#Debug simulation 
Total elapsed time: 1.7107090590288863. Arrivals time: 0.055546092393342406 Scheduler time: 1.1606283530709334 Scheduler overhead time: 0.13109393359627575 Adapter cache time: 0.1697072004317306 Engine time: 0.129788750607986 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-32/adapters_320_slots_160_rate_0.025-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-32/adapters_320_slots_160_rate_0.025-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [106 107 107]
Adapter prompts. [135, 270, 270, 33, 270, 270, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 270, 135, 270, 270, 33, 270, 135, 135, 270, 270, 135, 33, 33, 135, 270, 270, 135, 135, 33, 33, 135, 270, 270, 33, 270, 135, 33, 135, 270, 33, 135, 270, 270, 135, 33, 33, 270, 33, 33, 270, 270, 33, 33, 135, 135, 135, 33, 135, 33, 270, 33, 270, 135, 270, 270, 33, 270, 33, 270, 135, 33, 33, 135, 135, 270, 135, 270, 270, 270, 33, 135, 135, 33, 270, 135, 270, 270, 135, 33, 135, 135, 135, 33, 270, 135, 270, 33, 270, 33, 33, 135, 270, 270, 135, 33, 135, 33, 135, 270, 270, 135, 33, 135, 33, 270, 33, 33, 33, 33, 270, 135, 135, 270, 135, 135, 33, 135, 270, 135, 33, 33, 135, 270, 33, 33, 33, 270, 270, 270, 33, 135, 270, 135, 135, 135, 33, 270, 33, 270, 135, 33, 135, 33, 33, 135, 33, 135, 270, 270, 270, 270, 135, 135, 270, 270, 270, 135, 270, 33, 33, 270, 135, 270, 135, 270, 135, 33, 135, 33, 33, 33, 270, 270, 135, 135, 33, 33, 135, 33, 270, 33, 33, 135, 33, 270, 135, 33, 270, 33, 33, 270, 135, 270, 135, 33, 135, 270, 135, 135, 270, 135, 33, 135, 33, 270, 135, 135, 270, 270, 33, 33, 33, 270, 270, 33, 33, 270, 135, 33, 135, 33, 135, 270, 270, 270, 33, 270, 270, 270, 270, 33, 135, 135, 270, 33, 270, 33, 33, 33, 270, 135, 270, 270, 33, 135, 135, 135, 33, 135, 33, 135, 135, 270, 33, 33, 135, 33, 135, 135, 33, 270, 270, 270, 33, 135, 135, 135, 135, 33, 135, 33, 270, 33, 33, 270, 135, 270, 135, 135, 135, 135, 33, 33, 270, 33, 33, 270, 270, 270, 33, 270, 270, 135, 270, 135, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 46833 . Total input tokens: 10357816 . Total output tokens: 9396702
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 1.688302738009952,
    "estimated_duration": 3599.8633570078514,
    "input_throughput": 1091.0269669970237,
    "output_throughput": 973.7002914781343,
    "total_throughput": 2064.727258475158,
    "itl": 23.880182890345868,
    "ttft": 6378.451329286035,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5370,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.5503677533183,
    "arrivals": 15904,
    "finished_requests": 15876,
    "scheduler_time": 0.00024206335450612017
}
#Debug simulation 
Total elapsed time: 1.688389499031473. Arrivals time: 0.05200039950432256 Scheduler time: 1.1456312201335095 Scheduler overhead time: 0.130714739440009 Adapter cache time: 0.16848123451927677 Engine time: 0.12781611230457202 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-16/adapters_320_slots_160_rate_0.025-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-16/adapters_320_slots_160_rate_0.025-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [106 107 107]
Adapter prompts. [135, 270, 270, 33, 270, 270, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 270, 135, 270, 270, 33, 270, 135, 135, 270, 270, 135, 33, 33, 135, 270, 270, 135, 135, 33, 33, 135, 270, 270, 33, 270, 135, 33, 135, 270, 33, 135, 270, 270, 135, 33, 33, 270, 33, 33, 270, 270, 33, 33, 135, 135, 135, 33, 135, 33, 270, 33, 270, 135, 270, 270, 33, 270, 33, 270, 135, 33, 33, 135, 135, 270, 135, 270, 270, 270, 33, 135, 135, 33, 270, 135, 270, 270, 135, 33, 135, 135, 135, 33, 270, 135, 270, 33, 270, 33, 33, 135, 270, 270, 135, 33, 135, 33, 135, 270, 270, 135, 33, 135, 33, 270, 33, 33, 33, 33, 270, 135, 135, 270, 135, 135, 33, 135, 270, 135, 33, 33, 135, 270, 33, 33, 33, 270, 270, 270, 33, 135, 270, 135, 135, 135, 33, 270, 33, 270, 135, 33, 135, 33, 33, 135, 33, 135, 270, 270, 270, 270, 135, 135, 270, 270, 270, 135, 270, 33, 33, 270, 135, 270, 135, 270, 135, 33, 135, 33, 33, 33, 270, 270, 135, 135, 33, 33, 135, 33, 270, 33, 33, 135, 33, 270, 135, 33, 270, 33, 33, 270, 135, 270, 135, 33, 135, 270, 135, 135, 270, 135, 33, 135, 33, 270, 135, 135, 270, 270, 33, 33, 33, 270, 270, 33, 33, 270, 135, 33, 135, 33, 135, 270, 270, 270, 33, 270, 270, 270, 270, 33, 135, 135, 270, 33, 270, 33, 33, 33, 270, 135, 270, 270, 33, 135, 135, 135, 33, 135, 33, 135, 135, 270, 33, 33, 135, 33, 135, 135, 33, 270, 270, 270, 33, 135, 135, 135, 135, 33, 135, 33, 270, 33, 33, 270, 135, 270, 135, 135, 135, 135, 33, 33, 270, 33, 33, 270, 270, 270, 33, 270, 270, 135, 270, 135, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 46833 . Total input tokens: 10357816 . Total output tokens: 9396702
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 1.7045982950367033,
    "estimated_duration": 3599.846962933867,
    "input_throughput": 1091.031935646247,
    "output_throughput": 973.7047258095882,
    "total_throughput": 2064.736661455835,
    "itl": 23.87190472771227,
    "ttft": 6378.281766073297,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5367,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.777351171475622,
    "arrivals": 15904,
    "finished_requests": 15876,
    "scheduler_time": 0.00023718456045584445
}
#Debug simulation 
Total elapsed time: 1.7046879910049029. Arrivals time: 0.05338580388342962 Scheduler time: 1.1611247097025625 Scheduler overhead time: 0.13066150102531537 Adapter cache time: 0.16792723664548248 Engine time: 0.12695219239685684 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-32/adapters_320_slots_160_rate_0.025-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-32/adapters_320_slots_160_rate_0.025-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [106 107 107]
Adapter prompts. [135, 270, 270, 33, 270, 270, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 270, 135, 270, 270, 33, 270, 135, 135, 270, 270, 135, 33, 33, 135, 270, 270, 135, 135, 33, 33, 135, 270, 270, 33, 270, 135, 33, 135, 270, 33, 135, 270, 270, 135, 33, 33, 270, 33, 33, 270, 270, 33, 33, 135, 135, 135, 33, 135, 33, 270, 33, 270, 135, 270, 270, 33, 270, 33, 270, 135, 33, 33, 135, 135, 270, 135, 270, 270, 270, 33, 135, 135, 33, 270, 135, 270, 270, 135, 33, 135, 135, 135, 33, 270, 135, 270, 33, 270, 33, 33, 135, 270, 270, 135, 33, 135, 33, 135, 270, 270, 135, 33, 135, 33, 270, 33, 33, 33, 33, 270, 135, 135, 270, 135, 135, 33, 135, 270, 135, 33, 33, 135, 270, 33, 33, 33, 270, 270, 270, 33, 135, 270, 135, 135, 135, 33, 270, 33, 270, 135, 33, 135, 33, 33, 135, 33, 135, 270, 270, 270, 270, 135, 135, 270, 270, 270, 135, 270, 33, 33, 270, 135, 270, 135, 270, 135, 33, 135, 33, 33, 33, 270, 270, 135, 135, 33, 33, 135, 33, 270, 33, 33, 135, 33, 270, 135, 33, 270, 33, 33, 270, 135, 270, 135, 33, 135, 270, 135, 135, 270, 135, 33, 135, 33, 270, 135, 135, 270, 270, 33, 33, 33, 270, 270, 33, 33, 270, 135, 33, 135, 33, 135, 270, 270, 270, 33, 270, 270, 270, 270, 33, 135, 135, 270, 33, 270, 33, 33, 33, 270, 135, 270, 270, 33, 135, 135, 135, 33, 135, 33, 135, 135, 270, 33, 33, 135, 33, 135, 135, 33, 270, 270, 270, 33, 135, 135, 135, 135, 33, 135, 33, 270, 33, 33, 270, 135, 270, 135, 135, 135, 135, 33, 33, 270, 33, 33, 270, 270, 270, 33, 270, 270, 135, 270, 135, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 46833 . Total input tokens: 10357816 . Total output tokens: 9396702
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 1.714170704013668,
    "estimated_duration": 3599.8591559134798,
    "input_throughput": 1091.0282402432958,
    "output_throughput": 973.7014278022617,
    "total_throughput": 2064.7296680455574,
    "itl": 23.883160844853354,
    "ttft": 6378.405470627568,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5370,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.775255537292665,
    "arrivals": 15904,
    "finished_requests": 15876,
    "scheduler_time": 0.00023885253247389726
}
#Debug simulation 
Total elapsed time: 1.7143079710076563. Arrivals time: 0.05245848704362288 Scheduler time: 1.1622235543327406 Scheduler overhead time: 0.1342847285559401 Adapter cache time: 0.1703213358996436 Engine time: 0.13040062779327855 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-16/adapters_320_slots_160_rate_0.025-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-16/adapters_320_slots_160_rate_0.025-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [106 107 107]
Adapter prompts. [135, 270, 270, 33, 270, 270, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 270, 135, 270, 270, 33, 270, 135, 135, 270, 270, 135, 33, 33, 135, 270, 270, 135, 135, 33, 33, 135, 270, 270, 33, 270, 135, 33, 135, 270, 33, 135, 270, 270, 135, 33, 33, 270, 33, 33, 270, 270, 33, 33, 135, 135, 135, 33, 135, 33, 270, 33, 270, 135, 270, 270, 33, 270, 33, 270, 135, 33, 33, 135, 135, 270, 135, 270, 270, 270, 33, 135, 135, 33, 270, 135, 270, 270, 135, 33, 135, 135, 135, 33, 270, 135, 270, 33, 270, 33, 33, 135, 270, 270, 135, 33, 135, 33, 135, 270, 270, 135, 33, 135, 33, 270, 33, 33, 33, 33, 270, 135, 135, 270, 135, 135, 33, 135, 270, 135, 33, 33, 135, 270, 33, 33, 33, 270, 270, 270, 33, 135, 270, 135, 135, 135, 33, 270, 33, 270, 135, 33, 135, 33, 33, 135, 33, 135, 270, 270, 270, 270, 135, 135, 270, 270, 270, 135, 270, 33, 33, 270, 135, 270, 135, 270, 135, 33, 135, 33, 33, 33, 270, 270, 135, 135, 33, 33, 135, 33, 270, 33, 33, 135, 33, 270, 135, 33, 270, 33, 33, 270, 135, 270, 135, 33, 135, 270, 135, 135, 270, 135, 33, 135, 33, 270, 135, 135, 270, 270, 33, 33, 33, 270, 270, 33, 33, 270, 135, 33, 135, 33, 135, 270, 270, 270, 33, 270, 270, 270, 270, 33, 135, 135, 270, 33, 270, 33, 33, 33, 270, 135, 270, 270, 33, 135, 135, 135, 33, 135, 33, 135, 135, 270, 33, 33, 135, 33, 135, 135, 33, 270, 270, 270, 33, 135, 135, 135, 135, 33, 135, 33, 270, 33, 33, 270, 135, 270, 135, 135, 135, 135, 33, 33, 270, 33, 33, 270, 270, 270, 33, 270, 270, 135, 270, 135, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 46833 . Total input tokens: 10357816 . Total output tokens: 9396702
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 1.7087897449964657,
    "estimated_duration": 3599.8493383211285,
    "input_throughput": 1091.0312157207393,
    "output_throughput": 973.7040833033096,
    "total_throughput": 2064.735299024049,
    "itl": 23.865685660108834,
    "ttft": 6378.34069587155,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5368,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.050589983036705,
    "arrivals": 15904,
    "finished_requests": 15876,
    "scheduler_time": 0.00023635057444681805
}
#Debug simulation 
Total elapsed time: 1.7088743000058457. Arrivals time: 0.05222564016003162 Scheduler time: 1.163948382192757 Scheduler overhead time: 0.13183852058136836 Adapter cache time: 0.1687140537542291 Engine time: 0.1281362140434794 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-32/adapters_320_slots_160_rate_0.025-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-32/adapters_320_slots_160_rate_0.025-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [106 107 107]
Adapter prompts. [135, 270, 270, 33, 270, 270, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 270, 135, 270, 270, 33, 270, 135, 135, 270, 270, 135, 33, 33, 135, 270, 270, 135, 135, 33, 33, 135, 270, 270, 33, 270, 135, 33, 135, 270, 33, 135, 270, 270, 135, 33, 33, 270, 33, 33, 270, 270, 33, 33, 135, 135, 135, 33, 135, 33, 270, 33, 270, 135, 270, 270, 33, 270, 33, 270, 135, 33, 33, 135, 135, 270, 135, 270, 270, 270, 33, 135, 135, 33, 270, 135, 270, 270, 135, 33, 135, 135, 135, 33, 270, 135, 270, 33, 270, 33, 33, 135, 270, 270, 135, 33, 135, 33, 135, 270, 270, 135, 33, 135, 33, 270, 33, 33, 33, 33, 270, 135, 135, 270, 135, 135, 33, 135, 270, 135, 33, 33, 135, 270, 33, 33, 33, 270, 270, 270, 33, 135, 270, 135, 135, 135, 33, 270, 33, 270, 135, 33, 135, 33, 33, 135, 33, 135, 270, 270, 270, 270, 135, 135, 270, 270, 270, 135, 270, 33, 33, 270, 135, 270, 135, 270, 135, 33, 135, 33, 33, 33, 270, 270, 135, 135, 33, 33, 135, 33, 270, 33, 33, 135, 33, 270, 135, 33, 270, 33, 33, 270, 135, 270, 135, 33, 135, 270, 135, 135, 270, 135, 33, 135, 33, 270, 135, 135, 270, 270, 33, 33, 33, 270, 270, 33, 33, 270, 135, 33, 135, 33, 135, 270, 270, 270, 33, 270, 270, 270, 270, 33, 135, 135, 270, 33, 270, 33, 33, 33, 270, 135, 270, 270, 33, 135, 135, 135, 33, 135, 33, 135, 135, 270, 33, 33, 135, 33, 135, 135, 33, 270, 270, 270, 33, 135, 135, 135, 135, 33, 135, 33, 270, 33, 33, 270, 135, 270, 135, 135, 135, 135, 33, 33, 270, 33, 33, 270, 270, 270, 33, 270, 270, 135, 270, 135, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 46833 . Total input tokens: 10357816 . Total output tokens: 9396702
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 1.7153869910398498,
    "estimated_duration": 3599.8539433994633,
    "input_throughput": 1091.0298200296104,
    "output_throughput": 973.7028377017799,
    "total_throughput": 2064.73265773139,
    "itl": 23.88542222063102,
    "ttft": 6378.392605382996,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5368,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.993301760851015,
    "arrivals": 15904,
    "finished_requests": 15876,
    "scheduler_time": 0.00023480772443264795
}
#Debug simulation 
Total elapsed time: 1.7154764920123853. Arrivals time: 0.05251433851663023 Scheduler time: 1.1676900783204474 Scheduler overhead time: 0.13069903443101794 Adapter cache time: 0.1709523148019798 Engine time: 0.12969180301297456 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-8/adapters_320_slots_160_rate_0.025-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-8/adapters_320_slots_160_rate_0.025-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [106 107 107]
Adapter prompts. [66, 270, 270, 33, 270, 270, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 270, 66, 270, 270, 33, 270, 66, 66, 270, 270, 66, 33, 33, 66, 270, 270, 66, 66, 33, 33, 66, 270, 270, 33, 270, 66, 33, 66, 270, 33, 66, 270, 270, 66, 33, 33, 270, 33, 33, 270, 270, 33, 33, 66, 66, 66, 33, 66, 33, 270, 33, 270, 66, 270, 270, 33, 270, 33, 270, 66, 33, 33, 66, 66, 270, 66, 270, 270, 270, 33, 66, 66, 33, 270, 66, 270, 270, 66, 33, 66, 66, 66, 33, 270, 66, 270, 33, 270, 33, 33, 66, 270, 270, 66, 33, 66, 33, 66, 270, 270, 66, 33, 66, 33, 270, 33, 33, 33, 33, 270, 66, 66, 270, 66, 66, 33, 66, 270, 66, 33, 33, 66, 270, 33, 33, 33, 270, 270, 270, 33, 66, 270, 66, 66, 66, 33, 270, 33, 270, 66, 33, 66, 33, 33, 66, 33, 66, 270, 270, 270, 270, 66, 66, 270, 270, 270, 66, 270, 33, 33, 270, 66, 270, 66, 270, 66, 33, 66, 33, 33, 33, 270, 270, 66, 66, 33, 33, 66, 33, 270, 33, 33, 66, 33, 270, 66, 33, 270, 33, 33, 270, 66, 270, 66, 33, 66, 270, 66, 66, 270, 66, 33, 66, 33, 270, 66, 66, 270, 270, 33, 33, 33, 270, 270, 33, 33, 270, 66, 33, 66, 33, 66, 270, 270, 270, 33, 270, 270, 270, 270, 33, 66, 66, 270, 33, 270, 33, 33, 33, 270, 66, 270, 270, 33, 66, 66, 66, 33, 66, 33, 66, 66, 270, 33, 33, 66, 33, 66, 66, 33, 270, 270, 270, 33, 66, 66, 66, 66, 33, 66, 33, 270, 33, 33, 270, 66, 270, 66, 66, 66, 66, 33, 33, 270, 33, 33, 270, 270, 270, 33, 270, 270, 66, 270, 66, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 39450 . Total input tokens: 8718347 . Total output tokens: 7929177
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 1.5229638289893046,
    "estimated_duration": 3599.657821348307,
    "input_throughput": 917.7072277282869,
    "output_throughput": 812.8425381565959,
    "total_throughput": 1730.5497658848828,
    "itl": 22.38306670750226,
    "ttft": 5133.747926548362,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3782,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.574764647553003,
    "arrivals": 13422,
    "finished_requests": 13403,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5230491110123694. Arrivals time: 0.04636450647376478 Scheduler time: 0.9884046830120496 Scheduler overhead time: 0.13807763549266383 Adapter cache time: 0.1477751829661429 Engine time: 0.13519264687784016 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-16/adapters_320_slots_160_rate_0.025-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-16/adapters_320_slots_160_rate_0.025-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [106 107 107]
Adapter prompts. [66, 270, 270, 33, 270, 270, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 270, 66, 270, 270, 33, 270, 66, 66, 270, 270, 66, 33, 33, 66, 270, 270, 66, 66, 33, 33, 66, 270, 270, 33, 270, 66, 33, 66, 270, 33, 66, 270, 270, 66, 33, 33, 270, 33, 33, 270, 270, 33, 33, 66, 66, 66, 33, 66, 33, 270, 33, 270, 66, 270, 270, 33, 270, 33, 270, 66, 33, 33, 66, 66, 270, 66, 270, 270, 270, 33, 66, 66, 33, 270, 66, 270, 270, 66, 33, 66, 66, 66, 33, 270, 66, 270, 33, 270, 33, 33, 66, 270, 270, 66, 33, 66, 33, 66, 270, 270, 66, 33, 66, 33, 270, 33, 33, 33, 33, 270, 66, 66, 270, 66, 66, 33, 66, 270, 66, 33, 33, 66, 270, 33, 33, 33, 270, 270, 270, 33, 66, 270, 66, 66, 66, 33, 270, 33, 270, 66, 33, 66, 33, 33, 66, 33, 66, 270, 270, 270, 270, 66, 66, 270, 270, 270, 66, 270, 33, 33, 270, 66, 270, 66, 270, 66, 33, 66, 33, 33, 33, 270, 270, 66, 66, 33, 33, 66, 33, 270, 33, 33, 66, 33, 270, 66, 33, 270, 33, 33, 270, 66, 270, 66, 33, 66, 270, 66, 66, 270, 66, 33, 66, 33, 270, 66, 66, 270, 270, 33, 33, 33, 270, 270, 33, 33, 270, 66, 33, 66, 33, 66, 270, 270, 270, 33, 270, 270, 270, 270, 33, 66, 66, 270, 33, 270, 33, 33, 33, 270, 66, 270, 270, 33, 66, 66, 66, 33, 66, 33, 66, 66, 270, 33, 33, 66, 33, 66, 66, 33, 270, 270, 270, 33, 66, 66, 66, 66, 33, 66, 33, 270, 33, 33, 270, 66, 270, 66, 66, 66, 66, 33, 33, 270, 33, 33, 270, 270, 270, 33, 270, 270, 66, 270, 66, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 39450 . Total input tokens: 8718347 . Total output tokens: 7929177
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 1.5465050209895708,
    "estimated_duration": 3599.645209866009,
    "input_throughput": 917.7104429475052,
    "output_throughput": 812.8453859787237,
    "total_throughput": 1730.555828926229,
    "itl": 22.389790790902182,
    "ttft": 5133.728749397912,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3782,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.335170250561056,
    "arrivals": 13422,
    "finished_requests": 13403,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5465899819973856. Arrivals time: 0.047273324977140874 Scheduler time: 1.0077691954793409 Scheduler overhead time: 0.13771304639521986 Adapter cache time: 0.14853833813685924 Engine time: 0.13700483372667804 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-32/adapters_320_slots_160_rate_0.025-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-32/adapters_320_slots_160_rate_0.025-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [106 107 107]
Adapter prompts. [66, 270, 270, 33, 270, 270, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 270, 66, 270, 270, 33, 270, 66, 66, 270, 270, 66, 33, 33, 66, 270, 270, 66, 66, 33, 33, 66, 270, 270, 33, 270, 66, 33, 66, 270, 33, 66, 270, 270, 66, 33, 33, 270, 33, 33, 270, 270, 33, 33, 66, 66, 66, 33, 66, 33, 270, 33, 270, 66, 270, 270, 33, 270, 33, 270, 66, 33, 33, 66, 66, 270, 66, 270, 270, 270, 33, 66, 66, 33, 270, 66, 270, 270, 66, 33, 66, 66, 66, 33, 270, 66, 270, 33, 270, 33, 33, 66, 270, 270, 66, 33, 66, 33, 66, 270, 270, 66, 33, 66, 33, 270, 33, 33, 33, 33, 270, 66, 66, 270, 66, 66, 33, 66, 270, 66, 33, 33, 66, 270, 33, 33, 33, 270, 270, 270, 33, 66, 270, 66, 66, 66, 33, 270, 33, 270, 66, 33, 66, 33, 33, 66, 33, 66, 270, 270, 270, 270, 66, 66, 270, 270, 270, 66, 270, 33, 33, 270, 66, 270, 66, 270, 66, 33, 66, 33, 33, 33, 270, 270, 66, 66, 33, 33, 66, 33, 270, 33, 33, 66, 33, 270, 66, 33, 270, 33, 33, 270, 66, 270, 66, 33, 66, 270, 66, 66, 270, 66, 33, 66, 33, 270, 66, 66, 270, 270, 33, 33, 33, 270, 270, 33, 33, 270, 66, 33, 66, 33, 66, 270, 270, 270, 33, 270, 270, 270, 270, 33, 66, 66, 270, 33, 270, 33, 33, 33, 270, 66, 270, 270, 33, 66, 66, 66, 33, 66, 33, 66, 66, 270, 33, 33, 66, 33, 66, 66, 33, 270, 270, 270, 33, 66, 66, 66, 66, 33, 66, 33, 270, 33, 33, 270, 66, 270, 66, 66, 66, 66, 33, 33, 270, 33, 33, 270, 270, 270, 33, 270, 270, 66, 270, 66, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 39450 . Total input tokens: 8718347 . Total output tokens: 7929177
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 1.5277916319901124,
    "estimated_duration": 3599.6497129013856,
    "input_throughput": 917.7092949239695,
    "output_throughput": 812.8443691376917,
    "total_throughput": 1730.5536640616613,
    "itl": 22.389238688160088,
    "ttft": 5133.8288527249415,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3782,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.35809123979803,
    "arrivals": 13422,
    "finished_requests": 13403,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5278743809903972. Arrivals time: 0.04653852741466835 Scheduler time: 0.9921169256558642 Scheduler overhead time: 0.13737857498927042 Adapter cache time: 0.14709716220386326 Engine time: 0.13746048556640744 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-16/adapters_320_slots_160_rate_0.025-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-16/adapters_320_slots_160_rate_0.025-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [106 107 107]
Adapter prompts. [66, 270, 270, 33, 270, 270, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 270, 66, 270, 270, 33, 270, 66, 66, 270, 270, 66, 33, 33, 66, 270, 270, 66, 66, 33, 33, 66, 270, 270, 33, 270, 66, 33, 66, 270, 33, 66, 270, 270, 66, 33, 33, 270, 33, 33, 270, 270, 33, 33, 66, 66, 66, 33, 66, 33, 270, 33, 270, 66, 270, 270, 33, 270, 33, 270, 66, 33, 33, 66, 66, 270, 66, 270, 270, 270, 33, 66, 66, 33, 270, 66, 270, 270, 66, 33, 66, 66, 66, 33, 270, 66, 270, 33, 270, 33, 33, 66, 270, 270, 66, 33, 66, 33, 66, 270, 270, 66, 33, 66, 33, 270, 33, 33, 33, 33, 270, 66, 66, 270, 66, 66, 33, 66, 270, 66, 33, 33, 66, 270, 33, 33, 33, 270, 270, 270, 33, 66, 270, 66, 66, 66, 33, 270, 33, 270, 66, 33, 66, 33, 33, 66, 33, 66, 270, 270, 270, 270, 66, 66, 270, 270, 270, 66, 270, 33, 33, 270, 66, 270, 66, 270, 66, 33, 66, 33, 33, 33, 270, 270, 66, 66, 33, 33, 66, 33, 270, 33, 33, 66, 33, 270, 66, 33, 270, 33, 33, 270, 66, 270, 66, 33, 66, 270, 66, 66, 270, 66, 33, 66, 33, 270, 66, 66, 270, 270, 33, 33, 33, 270, 270, 33, 33, 270, 66, 33, 66, 33, 66, 270, 270, 270, 33, 270, 270, 270, 270, 33, 66, 66, 270, 33, 270, 33, 33, 33, 270, 66, 270, 270, 33, 66, 66, 66, 33, 66, 33, 66, 66, 270, 33, 33, 66, 33, 66, 66, 33, 270, 270, 270, 33, 66, 66, 66, 66, 33, 66, 33, 270, 33, 33, 270, 66, 270, 66, 66, 66, 66, 33, 33, 270, 33, 33, 270, 270, 270, 33, 270, 270, 66, 270, 66, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 39450 . Total input tokens: 8718347 . Total output tokens: 7929177
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 1.5271408769767731,
    "estimated_duration": 3599.6378123501604,
    "input_throughput": 917.7123289087879,
    "output_throughput": 812.8470564347359,
    "total_throughput": 1730.5593853435237,
    "itl": 22.384222461432863,
    "ttft": 5133.733416056151,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3782,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.824017507192286,
    "arrivals": 13422,
    "finished_requests": 13403,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5272294839960523. Arrivals time: 0.04738749377429485 Scheduler time: 0.9910168467322364 Scheduler overhead time: 0.13725960307056084 Adapter cache time: 0.147704572242219 Engine time: 0.13696135528152809 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-32/adapters_320_slots_160_rate_0.025-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-32/adapters_320_slots_160_rate_0.025-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [106 107 107]
Adapter prompts. [66, 270, 270, 33, 270, 270, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 270, 66, 270, 270, 33, 270, 66, 66, 270, 270, 66, 33, 33, 66, 270, 270, 66, 66, 33, 33, 66, 270, 270, 33, 270, 66, 33, 66, 270, 33, 66, 270, 270, 66, 33, 33, 270, 33, 33, 270, 270, 33, 33, 66, 66, 66, 33, 66, 33, 270, 33, 270, 66, 270, 270, 33, 270, 33, 270, 66, 33, 33, 66, 66, 270, 66, 270, 270, 270, 33, 66, 66, 33, 270, 66, 270, 270, 66, 33, 66, 66, 66, 33, 270, 66, 270, 33, 270, 33, 33, 66, 270, 270, 66, 33, 66, 33, 66, 270, 270, 66, 33, 66, 33, 270, 33, 33, 33, 33, 270, 66, 66, 270, 66, 66, 33, 66, 270, 66, 33, 33, 66, 270, 33, 33, 33, 270, 270, 270, 33, 66, 270, 66, 66, 66, 33, 270, 33, 270, 66, 33, 66, 33, 33, 66, 33, 66, 270, 270, 270, 270, 66, 66, 270, 270, 270, 66, 270, 33, 33, 270, 66, 270, 66, 270, 66, 33, 66, 33, 33, 33, 270, 270, 66, 66, 33, 33, 66, 33, 270, 33, 33, 66, 33, 270, 66, 33, 270, 33, 33, 270, 66, 270, 66, 33, 66, 270, 66, 66, 270, 66, 33, 66, 33, 270, 66, 66, 270, 270, 33, 33, 33, 270, 270, 33, 33, 270, 66, 33, 66, 33, 66, 270, 270, 270, 33, 270, 270, 270, 270, 33, 66, 66, 270, 33, 270, 33, 33, 33, 270, 66, 270, 270, 33, 66, 66, 66, 33, 66, 33, 66, 66, 270, 33, 33, 66, 33, 66, 66, 33, 270, 270, 270, 33, 66, 66, 66, 66, 33, 66, 33, 270, 33, 33, 270, 66, 270, 66, 66, 66, 66, 33, 33, 270, 33, 33, 270, 270, 270, 33, 270, 270, 66, 270, 66, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 39450 . Total input tokens: 8718347 . Total output tokens: 7929177
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 1.5200099300127476,
    "estimated_duration": 3599.653460348312,
    "input_throughput": 917.7083395356483,
    "output_throughput": 812.8435229198083,
    "total_throughput": 1730.5518624554566,
    "itl": 22.39066515264772,
    "ttft": 5133.719963114887,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3781,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.512028460259693,
    "arrivals": 13422,
    "finished_requests": 13403,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.520093786995858. Arrivals time: 0.04647347319405526 Scheduler time: 0.9864861988462508 Scheduler overhead time: 0.13705995411146432 Adapter cache time: 0.1476311627193354 Engine time: 0.13553049537586048 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-16/adapters_320_slots_160_rate_0.025-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-16/adapters_320_slots_160_rate_0.025-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [106 107 107]
Adapter prompts. [66, 270, 270, 33, 270, 270, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 270, 66, 270, 270, 33, 270, 66, 66, 270, 270, 66, 33, 33, 66, 270, 270, 66, 66, 33, 33, 66, 270, 270, 33, 270, 66, 33, 66, 270, 33, 66, 270, 270, 66, 33, 33, 270, 33, 33, 270, 270, 33, 33, 66, 66, 66, 33, 66, 33, 270, 33, 270, 66, 270, 270, 33, 270, 33, 270, 66, 33, 33, 66, 66, 270, 66, 270, 270, 270, 33, 66, 66, 33, 270, 66, 270, 270, 66, 33, 66, 66, 66, 33, 270, 66, 270, 33, 270, 33, 33, 66, 270, 270, 66, 33, 66, 33, 66, 270, 270, 66, 33, 66, 33, 270, 33, 33, 33, 33, 270, 66, 66, 270, 66, 66, 33, 66, 270, 66, 33, 33, 66, 270, 33, 33, 33, 270, 270, 270, 33, 66, 270, 66, 66, 66, 33, 270, 33, 270, 66, 33, 66, 33, 33, 66, 33, 66, 270, 270, 270, 270, 66, 66, 270, 270, 270, 66, 270, 33, 33, 270, 66, 270, 66, 270, 66, 33, 66, 33, 33, 33, 270, 270, 66, 66, 33, 33, 66, 33, 270, 33, 33, 66, 33, 270, 66, 33, 270, 33, 33, 270, 66, 270, 66, 33, 66, 270, 66, 66, 270, 66, 33, 66, 33, 270, 66, 66, 270, 270, 33, 33, 33, 270, 270, 33, 33, 270, 66, 33, 66, 33, 66, 270, 270, 270, 33, 270, 270, 270, 270, 33, 66, 66, 270, 33, 270, 33, 33, 33, 270, 66, 270, 270, 33, 66, 66, 66, 33, 66, 33, 66, 66, 270, 33, 33, 66, 33, 66, 66, 33, 270, 270, 270, 33, 66, 66, 66, 66, 33, 66, 33, 270, 33, 33, 270, 66, 270, 66, 66, 66, 66, 33, 33, 270, 33, 33, 270, 270, 270, 33, 270, 270, 66, 270, 66, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 39450 . Total input tokens: 8718347 . Total output tokens: 7929177
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 1.5361522989696823,
    "estimated_duration": 3599.650945752231,
    "input_throughput": 917.7089806160833,
    "output_throughput": 812.8440907451801,
    "total_throughput": 1730.5530713612634,
    "itl": 22.380858171866937,
    "ttft": 5133.769109033186,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3782,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.308370215320645,
    "arrivals": 13422,
    "finished_requests": 13403,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5362368159694597. Arrivals time: 0.047079276700969785 Scheduler time: 1.0021517091081478 Scheduler overhead time: 0.13729980628704652 Adapter cache time: 0.14760306081734598 Engine time: 0.13442829763516784 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-32/adapters_320_slots_160_rate_0.025-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-32/adapters_320_slots_160_rate_0.025-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [106 107 107]
Adapter prompts. [66, 270, 270, 33, 270, 270, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 270, 66, 270, 270, 33, 270, 66, 66, 270, 270, 66, 33, 33, 66, 270, 270, 66, 66, 33, 33, 66, 270, 270, 33, 270, 66, 33, 66, 270, 33, 66, 270, 270, 66, 33, 33, 270, 33, 33, 270, 270, 33, 33, 66, 66, 66, 33, 66, 33, 270, 33, 270, 66, 270, 270, 33, 270, 33, 270, 66, 33, 33, 66, 66, 270, 66, 270, 270, 270, 33, 66, 66, 33, 270, 66, 270, 270, 66, 33, 66, 66, 66, 33, 270, 66, 270, 33, 270, 33, 33, 66, 270, 270, 66, 33, 66, 33, 66, 270, 270, 66, 33, 66, 33, 270, 33, 33, 33, 33, 270, 66, 66, 270, 66, 66, 33, 66, 270, 66, 33, 33, 66, 270, 33, 33, 33, 270, 270, 270, 33, 66, 270, 66, 66, 66, 33, 270, 33, 270, 66, 33, 66, 33, 33, 66, 33, 66, 270, 270, 270, 270, 66, 66, 270, 270, 270, 66, 270, 33, 33, 270, 66, 270, 66, 270, 66, 33, 66, 33, 33, 33, 270, 270, 66, 66, 33, 33, 66, 33, 270, 33, 33, 66, 33, 270, 66, 33, 270, 33, 33, 270, 66, 270, 66, 33, 66, 270, 66, 66, 270, 66, 33, 66, 33, 270, 66, 66, 270, 270, 33, 33, 33, 270, 270, 33, 33, 270, 66, 33, 66, 33, 66, 270, 270, 270, 33, 270, 270, 270, 270, 33, 66, 66, 270, 33, 270, 33, 33, 33, 270, 66, 270, 270, 33, 66, 66, 66, 33, 66, 33, 66, 66, 270, 33, 33, 66, 33, 66, 66, 33, 270, 270, 270, 33, 66, 66, 66, 66, 33, 66, 33, 270, 33, 33, 270, 66, 270, 66, 66, 66, 66, 33, 33, 270, 33, 33, 270, 270, 270, 33, 270, 270, 66, 270, 66, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 39450 . Total input tokens: 8718347 . Total output tokens: 7929177
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 1.5393089030403644,
    "estimated_duration": 3599.6468761390493,
    "input_throughput": 917.710018140233,
    "output_throughput": 812.8450097133846,
    "total_throughput": 1730.5550278536175,
    "itl": 22.390885023267177,
    "ttft": 5133.8967898958435,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3782,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.674110505058565,
    "arrivals": 13422,
    "finished_requests": 13403,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.53939273301512. Arrivals time: 0.04663735843496397 Scheduler time: 1.0034254094935022 Scheduler overhead time: 0.13793899229494855 Adapter cache time: 0.14742659404873848 Engine time: 0.13703798985807225 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-8/adapters_320_slots_160_rate_0.0125-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-8/adapters_320_slots_160_rate_0.0125-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [106 107 107]
Adapter prompts. [66, 135, 135, 33, 135, 135, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 135, 66, 135, 135, 33, 135, 66, 66, 135, 135, 66, 33, 33, 66, 135, 135, 66, 66, 33, 33, 66, 135, 135, 33, 135, 66, 33, 66, 135, 33, 66, 135, 135, 66, 33, 33, 135, 33, 33, 135, 135, 33, 33, 66, 66, 66, 33, 66, 33, 135, 33, 135, 66, 135, 135, 33, 135, 33, 135, 66, 33, 33, 66, 66, 135, 66, 135, 135, 135, 33, 66, 66, 33, 135, 66, 135, 135, 66, 33, 66, 66, 66, 33, 135, 66, 135, 33, 135, 33, 33, 66, 135, 135, 66, 33, 66, 33, 66, 135, 135, 66, 33, 66, 33, 135, 33, 33, 33, 33, 135, 66, 66, 135, 66, 66, 33, 66, 135, 66, 33, 33, 66, 135, 33, 33, 33, 135, 135, 135, 33, 66, 135, 66, 66, 66, 33, 135, 33, 135, 66, 33, 66, 33, 33, 66, 33, 66, 135, 135, 135, 135, 66, 66, 135, 135, 135, 66, 135, 33, 33, 135, 66, 135, 66, 135, 66, 33, 66, 33, 33, 33, 135, 135, 66, 66, 33, 33, 66, 33, 135, 33, 33, 66, 33, 135, 66, 33, 135, 33, 33, 135, 66, 135, 66, 33, 66, 135, 66, 66, 135, 66, 33, 66, 33, 135, 66, 66, 135, 135, 33, 33, 33, 135, 135, 33, 33, 135, 66, 33, 66, 33, 66, 135, 135, 135, 33, 135, 135, 135, 135, 33, 66, 66, 135, 33, 135, 33, 33, 33, 135, 66, 135, 135, 33, 66, 66, 66, 33, 66, 33, 66, 66, 135, 33, 33, 66, 33, 66, 66, 33, 135, 135, 135, 33, 66, 66, 66, 66, 33, 66, 33, 135, 33, 33, 135, 66, 135, 66, 66, 66, 66, 33, 33, 135, 33, 33, 135, 135, 135, 33, 135, 135, 66, 135, 66, 33, 135, 33, 135, 135, 33, 33, 33]
Prompts retrieved: 25005 . Total input tokens: 5548470 . Total output tokens: 4996306
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 1.175294134998694,
    "estimated_duration": 3599.9255963048868,
    "input_throughput": 582.6534309911767,
    "output_throughput": 507.4977110291561,
    "total_throughput": 1090.1511420203328,
    "itl": 20.096514994046416,
    "ttft": 5505.020669810639,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3533,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.812703199313942,
    "arrivals": 8555,
    "finished_requests": 8542,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1753757640253752. Arrivals time: 0.03536487452220172 Scheduler time: 0.6690509186591953 Scheduler overhead time: 0.14565078931627795 Adapter cache time: 0.10768217645818368 Engine time: 0.14475369482534006 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-16/adapters_320_slots_160_rate_0.0125-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-16/adapters_320_slots_160_rate_0.0125-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [106 107 107]
Adapter prompts. [66, 135, 135, 33, 135, 135, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 135, 66, 135, 135, 33, 135, 66, 66, 135, 135, 66, 33, 33, 66, 135, 135, 66, 66, 33, 33, 66, 135, 135, 33, 135, 66, 33, 66, 135, 33, 66, 135, 135, 66, 33, 33, 135, 33, 33, 135, 135, 33, 33, 66, 66, 66, 33, 66, 33, 135, 33, 135, 66, 135, 135, 33, 135, 33, 135, 66, 33, 33, 66, 66, 135, 66, 135, 135, 135, 33, 66, 66, 33, 135, 66, 135, 135, 66, 33, 66, 66, 66, 33, 135, 66, 135, 33, 135, 33, 33, 66, 135, 135, 66, 33, 66, 33, 66, 135, 135, 66, 33, 66, 33, 135, 33, 33, 33, 33, 135, 66, 66, 135, 66, 66, 33, 66, 135, 66, 33, 33, 66, 135, 33, 33, 33, 135, 135, 135, 33, 66, 135, 66, 66, 66, 33, 135, 33, 135, 66, 33, 66, 33, 33, 66, 33, 66, 135, 135, 135, 135, 66, 66, 135, 135, 135, 66, 135, 33, 33, 135, 66, 135, 66, 135, 66, 33, 66, 33, 33, 33, 135, 135, 66, 66, 33, 33, 66, 33, 135, 33, 33, 66, 33, 135, 66, 33, 135, 33, 33, 135, 66, 135, 66, 33, 66, 135, 66, 66, 135, 66, 33, 66, 33, 135, 66, 66, 135, 135, 33, 33, 33, 135, 135, 33, 33, 135, 66, 33, 66, 33, 66, 135, 135, 135, 33, 135, 135, 135, 135, 33, 66, 66, 135, 33, 135, 33, 33, 33, 135, 66, 135, 135, 33, 66, 66, 66, 33, 66, 33, 66, 66, 135, 33, 33, 66, 33, 66, 66, 33, 135, 135, 135, 33, 66, 66, 66, 66, 33, 66, 33, 135, 33, 33, 135, 66, 135, 66, 66, 66, 66, 33, 33, 135, 33, 33, 135, 135, 135, 33, 135, 135, 66, 135, 66, 33, 135, 33, 135, 135, 33, 33, 33]
Prompts retrieved: 25005 . Total input tokens: 5548470 . Total output tokens: 4996306
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 1.1815730579546653,
    "estimated_duration": 3599.919592216868,
    "input_throughput": 582.6544027635717,
    "output_throughput": 507.49855745387435,
    "total_throughput": 1090.1529602174462,
    "itl": 20.10104596466272,
    "ttft": 5504.987802541653,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3534,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.541337576664805,
    "arrivals": 8555,
    "finished_requests": 8542,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1816783949616365. Arrivals time: 0.03509646520251408 Scheduler time: 0.6732762890169397 Scheduler overhead time: 0.14572162786498666 Adapter cache time: 0.10868500475771725 Engine time: 0.14636420749593526 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-32/adapters_320_slots_160_rate_0.0125-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-32/adapters_320_slots_160_rate_0.0125-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [106 107 107]
Adapter prompts. [66, 135, 135, 33, 135, 135, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 135, 66, 135, 135, 33, 135, 66, 66, 135, 135, 66, 33, 33, 66, 135, 135, 66, 66, 33, 33, 66, 135, 135, 33, 135, 66, 33, 66, 135, 33, 66, 135, 135, 66, 33, 33, 135, 33, 33, 135, 135, 33, 33, 66, 66, 66, 33, 66, 33, 135, 33, 135, 66, 135, 135, 33, 135, 33, 135, 66, 33, 33, 66, 66, 135, 66, 135, 135, 135, 33, 66, 66, 33, 135, 66, 135, 135, 66, 33, 66, 66, 66, 33, 135, 66, 135, 33, 135, 33, 33, 66, 135, 135, 66, 33, 66, 33, 66, 135, 135, 66, 33, 66, 33, 135, 33, 33, 33, 33, 135, 66, 66, 135, 66, 66, 33, 66, 135, 66, 33, 33, 66, 135, 33, 33, 33, 135, 135, 135, 33, 66, 135, 66, 66, 66, 33, 135, 33, 135, 66, 33, 66, 33, 33, 66, 33, 66, 135, 135, 135, 135, 66, 66, 135, 135, 135, 66, 135, 33, 33, 135, 66, 135, 66, 135, 66, 33, 66, 33, 33, 33, 135, 135, 66, 66, 33, 33, 66, 33, 135, 33, 33, 66, 33, 135, 66, 33, 135, 33, 33, 135, 66, 135, 66, 33, 66, 135, 66, 66, 135, 66, 33, 66, 33, 135, 66, 66, 135, 135, 33, 33, 33, 135, 135, 33, 33, 135, 66, 33, 66, 33, 66, 135, 135, 135, 33, 135, 135, 135, 135, 33, 66, 66, 135, 33, 135, 33, 33, 33, 135, 66, 135, 135, 33, 66, 66, 66, 33, 66, 33, 66, 66, 135, 33, 33, 66, 33, 66, 66, 33, 135, 135, 135, 33, 66, 66, 66, 66, 33, 66, 33, 135, 33, 33, 135, 66, 135, 66, 66, 66, 66, 33, 33, 135, 33, 33, 135, 135, 135, 33, 135, 135, 66, 135, 66, 33, 135, 33, 135, 135, 33, 33, 33]
Prompts retrieved: 25005 . Total input tokens: 5548470 . Total output tokens: 4996306
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 1.179575554037001,
    "estimated_duration": 3599.939622161947,
    "input_throughput": 582.6511608937316,
    "output_throughput": 507.49573374867356,
    "total_throughput": 1090.1468946424052,
    "itl": 20.10157228234441,
    "ttft": 5505.07851261863,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3533,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.557087367157736,
    "arrivals": 8555,
    "finished_requests": 8542,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1796461819903925. Arrivals time: 0.03543488314608112 Scheduler time: 0.6708600377314724 Scheduler overhead time: 0.1459401129395701 Adapter cache time: 0.10732464375905693 Engine time: 0.14769366389373317 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-16/adapters_320_slots_160_rate_0.0125-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-16/adapters_320_slots_160_rate_0.0125-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [106 107 107]
Adapter prompts. [66, 135, 135, 33, 135, 135, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 135, 66, 135, 135, 33, 135, 66, 66, 135, 135, 66, 33, 33, 66, 135, 135, 66, 66, 33, 33, 66, 135, 135, 33, 135, 66, 33, 66, 135, 33, 66, 135, 135, 66, 33, 33, 135, 33, 33, 135, 135, 33, 33, 66, 66, 66, 33, 66, 33, 135, 33, 135, 66, 135, 135, 33, 135, 33, 135, 66, 33, 33, 66, 66, 135, 66, 135, 135, 135, 33, 66, 66, 33, 135, 66, 135, 135, 66, 33, 66, 66, 66, 33, 135, 66, 135, 33, 135, 33, 33, 66, 135, 135, 66, 33, 66, 33, 66, 135, 135, 66, 33, 66, 33, 135, 33, 33, 33, 33, 135, 66, 66, 135, 66, 66, 33, 66, 135, 66, 33, 33, 66, 135, 33, 33, 33, 135, 135, 135, 33, 66, 135, 66, 66, 66, 33, 135, 33, 135, 66, 33, 66, 33, 33, 66, 33, 66, 135, 135, 135, 135, 66, 66, 135, 135, 135, 66, 135, 33, 33, 135, 66, 135, 66, 135, 66, 33, 66, 33, 33, 33, 135, 135, 66, 66, 33, 33, 66, 33, 135, 33, 33, 66, 33, 135, 66, 33, 135, 33, 33, 135, 66, 135, 66, 33, 66, 135, 66, 66, 135, 66, 33, 66, 33, 135, 66, 66, 135, 135, 33, 33, 33, 135, 135, 33, 33, 135, 66, 33, 66, 33, 66, 135, 135, 135, 33, 135, 135, 135, 135, 33, 66, 66, 135, 33, 135, 33, 33, 33, 135, 66, 135, 135, 33, 66, 66, 66, 33, 66, 33, 66, 66, 135, 33, 33, 66, 33, 66, 66, 33, 135, 135, 135, 33, 66, 66, 66, 66, 33, 66, 33, 135, 33, 33, 135, 66, 135, 66, 66, 66, 66, 33, 33, 135, 33, 33, 135, 135, 135, 33, 135, 135, 66, 135, 66, 33, 135, 33, 135, 135, 33, 33, 33]
Prompts retrieved: 25005 . Total input tokens: 5548470 . Total output tokens: 4996306
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 1.1799648419837467,
    "estimated_duration": 3599.9219274438797,
    "input_throughput": 582.654024802514,
    "output_throughput": 507.49822824552933,
    "total_throughput": 1090.1522530480433,
    "itl": 20.097525600117976,
    "ttft": 5504.908470175611,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3534,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.05592633835775,
    "arrivals": 8555,
    "finished_requests": 8542,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1800381600041874. Arrivals time: 0.03548674867488444 Scheduler time: 0.6730086234165356 Scheduler overhead time: 0.14639995287870988 Adapter cache time: 0.10781901964219287 Engine time: 0.14511026471154764 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-32/adapters_320_slots_160_rate_0.0125-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-32/adapters_320_slots_160_rate_0.0125-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [106 107 107]
Adapter prompts. [66, 135, 135, 33, 135, 135, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 135, 66, 135, 135, 33, 135, 66, 66, 135, 135, 66, 33, 33, 66, 135, 135, 66, 66, 33, 33, 66, 135, 135, 33, 135, 66, 33, 66, 135, 33, 66, 135, 135, 66, 33, 33, 135, 33, 33, 135, 135, 33, 33, 66, 66, 66, 33, 66, 33, 135, 33, 135, 66, 135, 135, 33, 135, 33, 135, 66, 33, 33, 66, 66, 135, 66, 135, 135, 135, 33, 66, 66, 33, 135, 66, 135, 135, 66, 33, 66, 66, 66, 33, 135, 66, 135, 33, 135, 33, 33, 66, 135, 135, 66, 33, 66, 33, 66, 135, 135, 66, 33, 66, 33, 135, 33, 33, 33, 33, 135, 66, 66, 135, 66, 66, 33, 66, 135, 66, 33, 33, 66, 135, 33, 33, 33, 135, 135, 135, 33, 66, 135, 66, 66, 66, 33, 135, 33, 135, 66, 33, 66, 33, 33, 66, 33, 66, 135, 135, 135, 135, 66, 66, 135, 135, 135, 66, 135, 33, 33, 135, 66, 135, 66, 135, 66, 33, 66, 33, 33, 33, 135, 135, 66, 66, 33, 33, 66, 33, 135, 33, 33, 66, 33, 135, 66, 33, 135, 33, 33, 135, 66, 135, 66, 33, 66, 135, 66, 66, 135, 66, 33, 66, 33, 135, 66, 66, 135, 135, 33, 33, 33, 135, 135, 33, 33, 135, 66, 33, 66, 33, 66, 135, 135, 135, 33, 135, 135, 135, 135, 33, 66, 66, 135, 33, 135, 33, 33, 33, 135, 66, 135, 135, 33, 66, 66, 66, 33, 66, 33, 66, 66, 135, 33, 33, 66, 33, 66, 66, 33, 135, 135, 135, 33, 66, 66, 66, 66, 33, 66, 33, 135, 33, 33, 135, 66, 135, 66, 66, 66, 66, 33, 33, 135, 33, 33, 135, 135, 135, 33, 135, 135, 66, 135, 66, 33, 135, 33, 135, 135, 33, 33, 33]
Prompts retrieved: 25005 . Total input tokens: 5548470 . Total output tokens: 4996306
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 1.1762847990030423,
    "estimated_duration": 3599.934562605026,
    "input_throughput": 582.6519797854816,
    "output_throughput": 507.4964470126253,
    "total_throughput": 1090.1484267981068,
    "itl": 20.102445569180073,
    "ttft": 5505.155620480033,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3533,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.706482865418554,
    "arrivals": 8555,
    "finished_requests": 8542,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1763600209960714. Arrivals time: 0.0353275173692964 Scheduler time: 0.6692134675686248 Scheduler overhead time: 0.14565109374234453 Adapter cache time: 0.10764059727080166 Engine time: 0.1464585875510238 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-16/adapters_320_slots_160_rate_0.0125-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-16/adapters_320_slots_160_rate_0.0125-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [106 107 107]
Adapter prompts. [66, 135, 135, 33, 135, 135, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 135, 66, 135, 135, 33, 135, 66, 66, 135, 135, 66, 33, 33, 66, 135, 135, 66, 66, 33, 33, 66, 135, 135, 33, 135, 66, 33, 66, 135, 33, 66, 135, 135, 66, 33, 33, 135, 33, 33, 135, 135, 33, 33, 66, 66, 66, 33, 66, 33, 135, 33, 135, 66, 135, 135, 33, 135, 33, 135, 66, 33, 33, 66, 66, 135, 66, 135, 135, 135, 33, 66, 66, 33, 135, 66, 135, 135, 66, 33, 66, 66, 66, 33, 135, 66, 135, 33, 135, 33, 33, 66, 135, 135, 66, 33, 66, 33, 66, 135, 135, 66, 33, 66, 33, 135, 33, 33, 33, 33, 135, 66, 66, 135, 66, 66, 33, 66, 135, 66, 33, 33, 66, 135, 33, 33, 33, 135, 135, 135, 33, 66, 135, 66, 66, 66, 33, 135, 33, 135, 66, 33, 66, 33, 33, 66, 33, 66, 135, 135, 135, 135, 66, 66, 135, 135, 135, 66, 135, 33, 33, 135, 66, 135, 66, 135, 66, 33, 66, 33, 33, 33, 135, 135, 66, 66, 33, 33, 66, 33, 135, 33, 33, 66, 33, 135, 66, 33, 135, 33, 33, 135, 66, 135, 66, 33, 66, 135, 66, 66, 135, 66, 33, 66, 33, 135, 66, 66, 135, 135, 33, 33, 33, 135, 135, 33, 33, 135, 66, 33, 66, 33, 66, 135, 135, 135, 33, 135, 135, 135, 135, 33, 66, 66, 135, 33, 135, 33, 33, 33, 135, 66, 135, 135, 33, 66, 66, 66, 33, 66, 33, 66, 66, 135, 33, 33, 66, 33, 66, 66, 33, 135, 135, 135, 33, 66, 66, 66, 66, 33, 66, 33, 135, 33, 33, 135, 66, 135, 66, 66, 66, 66, 33, 33, 135, 33, 33, 135, 135, 135, 33, 135, 135, 66, 135, 66, 33, 135, 33, 135, 135, 33, 33, 33]
Prompts retrieved: 25005 . Total input tokens: 5548470 . Total output tokens: 4996306
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 1.1812621499993838,
    "estimated_duration": 3599.9195505645184,
    "input_throughput": 582.6544095050904,
    "output_throughput": 507.4985633258131,
    "total_throughput": 1090.1529728309035,
    "itl": 20.095118325859527,
    "ttft": 5504.855087878676,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3533,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.563847691889809,
    "arrivals": 8555,
    "finished_requests": 8542,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.181377451051958. Arrivals time: 0.0349621077766642 Scheduler time: 0.6709377349470742 Scheduler overhead time: 0.14655841089552268 Adapter cache time: 0.10676913289353251 Engine time: 0.14964970480650663 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-32/adapters_320_slots_160_rate_0.0125-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-32/adapters_320_slots_160_rate_0.0125-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [106 107 107]
Adapter prompts. [66, 135, 135, 33, 135, 135, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 135, 66, 135, 135, 33, 135, 66, 66, 135, 135, 66, 33, 33, 66, 135, 135, 66, 66, 33, 33, 66, 135, 135, 33, 135, 66, 33, 66, 135, 33, 66, 135, 135, 66, 33, 33, 135, 33, 33, 135, 135, 33, 33, 66, 66, 66, 33, 66, 33, 135, 33, 135, 66, 135, 135, 33, 135, 33, 135, 66, 33, 33, 66, 66, 135, 66, 135, 135, 135, 33, 66, 66, 33, 135, 66, 135, 135, 66, 33, 66, 66, 66, 33, 135, 66, 135, 33, 135, 33, 33, 66, 135, 135, 66, 33, 66, 33, 66, 135, 135, 66, 33, 66, 33, 135, 33, 33, 33, 33, 135, 66, 66, 135, 66, 66, 33, 66, 135, 66, 33, 33, 66, 135, 33, 33, 33, 135, 135, 135, 33, 66, 135, 66, 66, 66, 33, 135, 33, 135, 66, 33, 66, 33, 33, 66, 33, 66, 135, 135, 135, 135, 66, 66, 135, 135, 135, 66, 135, 33, 33, 135, 66, 135, 66, 135, 66, 33, 66, 33, 33, 33, 135, 135, 66, 66, 33, 33, 66, 33, 135, 33, 33, 66, 33, 135, 66, 33, 135, 33, 33, 135, 66, 135, 66, 33, 66, 135, 66, 66, 135, 66, 33, 66, 33, 135, 66, 66, 135, 135, 33, 33, 33, 135, 135, 33, 33, 135, 66, 33, 66, 33, 66, 135, 135, 135, 33, 135, 135, 135, 135, 33, 66, 66, 135, 33, 135, 33, 33, 33, 135, 66, 135, 135, 33, 66, 66, 66, 33, 66, 33, 66, 66, 135, 33, 33, 66, 33, 66, 66, 33, 135, 135, 135, 33, 66, 66, 66, 66, 33, 66, 33, 135, 33, 33, 135, 66, 135, 66, 66, 66, 66, 33, 33, 135, 33, 33, 135, 135, 135, 33, 135, 135, 66, 135, 66, 33, 135, 33, 135, 135, 33, 33, 33]
Prompts retrieved: 25005 . Total input tokens: 5548470 . Total output tokens: 4996306
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 1.1716881030006334,
    "estimated_duration": 3599.9206100229367,
    "input_throughput": 582.6542380296091,
    "output_throughput": 507.4984139687346,
    "total_throughput": 1090.1526519983438,
    "itl": 20.103589738603898,
    "ttft": 5505.0838156253,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3534,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.860053666605832,
    "arrivals": 8555,
    "finished_requests": 8542,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1717473090393469. Arrivals time: 0.035017700865864754 Scheduler time: 0.6665972956689075 Scheduler overhead time: 0.14688152610324323 Adapter cache time: 0.10606029257178307 Engine time: 0.14492527267429978 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-8/adapters_320_slots_192_rate_3.2-1.6-0.8_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-8/adapters_320_slots_192_rate_3.2-1.6-0.8_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 8640, 34560, 34560, 17280, 17280, 17280, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 17280, 34560, 17280, 34560, 34560, 8640, 34560, 17280, 17280, 34560, 34560, 17280, 8640, 8640, 17280, 34560, 34560, 17280, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 34560, 17280, 8640, 17280, 34560, 8640, 17280, 34560, 34560, 17280, 8640, 8640, 34560, 8640, 8640, 34560, 34560, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 8640, 34560, 8640, 34560, 17280, 34560, 34560, 8640, 34560, 8640, 34560, 17280, 8640, 8640, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 8640, 17280, 17280, 8640, 34560, 17280, 34560, 34560, 17280, 8640, 17280, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 8640, 8640, 17280, 34560, 34560, 17280, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 17280, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 17280, 17280, 34560, 17280, 17280, 8640, 17280, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 8640, 8640, 34560, 34560, 34560, 8640, 17280, 34560, 17280, 17280, 17280, 8640, 34560, 8640, 34560, 17280, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 17280, 8640, 17280, 8640, 8640, 8640, 34560, 34560, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 8640, 8640, 17280, 8640, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 8640, 17280, 34560, 17280, 17280, 34560, 17280, 8640, 17280, 8640, 34560, 17280, 17280, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 34560, 17280, 8640, 17280, 8640, 17280, 34560, 34560, 34560, 8640, 34560, 34560, 34560, 34560, 8640, 17280, 17280, 34560, 8640, 34560, 8640, 8640, 8640, 34560, 17280, 34560, 34560, 8640, 17280, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 34560, 8640, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 34560, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 8640]
Prompts retrieved: 6462720 . Total input tokens: 1438948254 . Total output tokens: 1292672847
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 7.836643127026036,
    "estimated_duration": 3600.1333102912263,
    "input_throughput": 3662.9257484171494,
    "output_throughput": 3231.2178459466504,
    "total_throughput": 6894.1435943638,
    "itl": 264.6938293034534,
    "ttft": 2325863.4474817547,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1303,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.9878155303444807,
    "arrivals": 2153264,
    "finished_requests": 53502,
    "scheduler_time": 65.94064680550021
}
#Debug simulation 
Total elapsed time: 7.836711670039222. Arrivals time: 0.6915194380562752 Scheduler time: 7.048216058523394 Scheduler overhead time: 0.02408763754647225 Adapter cache time: 0.038446777092758566 Engine time: 0.023977272387128323 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-16/adapters_320_slots_192_rate_3.2-1.6-0.8_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-16/adapters_320_slots_192_rate_3.2-1.6-0.8_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 8640, 34560, 34560, 17280, 17280, 17280, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 17280, 34560, 17280, 34560, 34560, 8640, 34560, 17280, 17280, 34560, 34560, 17280, 8640, 8640, 17280, 34560, 34560, 17280, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 34560, 17280, 8640, 17280, 34560, 8640, 17280, 34560, 34560, 17280, 8640, 8640, 34560, 8640, 8640, 34560, 34560, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 8640, 34560, 8640, 34560, 17280, 34560, 34560, 8640, 34560, 8640, 34560, 17280, 8640, 8640, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 8640, 17280, 17280, 8640, 34560, 17280, 34560, 34560, 17280, 8640, 17280, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 8640, 8640, 17280, 34560, 34560, 17280, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 17280, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 17280, 17280, 34560, 17280, 17280, 8640, 17280, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 8640, 8640, 34560, 34560, 34560, 8640, 17280, 34560, 17280, 17280, 17280, 8640, 34560, 8640, 34560, 17280, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 17280, 8640, 17280, 8640, 8640, 8640, 34560, 34560, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 8640, 8640, 17280, 8640, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 8640, 17280, 34560, 17280, 17280, 34560, 17280, 8640, 17280, 8640, 34560, 17280, 17280, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 34560, 17280, 8640, 17280, 8640, 17280, 34560, 34560, 34560, 8640, 34560, 34560, 34560, 34560, 8640, 17280, 17280, 34560, 8640, 34560, 8640, 8640, 8640, 34560, 17280, 34560, 34560, 8640, 17280, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 34560, 8640, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 34560, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 8640]
Prompts retrieved: 6462720 . Total input tokens: 1438948254 . Total output tokens: 1292672847
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 7.33421077800449,
    "estimated_duration": 3600.0116485342764,
    "input_throughput": 3656.695945792205,
    "output_throughput": 3224.877898583128,
    "total_throughput": 6881.573844375333,
    "itl": 262.3127297242873,
    "ttft": 2327176.3318980685,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1348,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.401183751353498,
    "arrivals": 2153264,
    "finished_requests": 53405,
    "scheduler_time": 65.99841644130287
}
#Debug simulation 
Total elapsed time: 7.334277916001156. Arrivals time: 0.2710042071994394 Scheduler time: 6.963772200688254 Scheduler overhead time: 0.024252515635453165 Adapter cache time: 0.04049663379555568 Engine time: 0.024216919322498143 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-32/adapters_320_slots_192_rate_3.2-1.6-0.8_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-32/adapters_320_slots_192_rate_3.2-1.6-0.8_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 8640, 34560, 34560, 17280, 17280, 17280, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 17280, 34560, 17280, 34560, 34560, 8640, 34560, 17280, 17280, 34560, 34560, 17280, 8640, 8640, 17280, 34560, 34560, 17280, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 34560, 17280, 8640, 17280, 34560, 8640, 17280, 34560, 34560, 17280, 8640, 8640, 34560, 8640, 8640, 34560, 34560, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 8640, 34560, 8640, 34560, 17280, 34560, 34560, 8640, 34560, 8640, 34560, 17280, 8640, 8640, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 8640, 17280, 17280, 8640, 34560, 17280, 34560, 34560, 17280, 8640, 17280, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 8640, 8640, 17280, 34560, 34560, 17280, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 17280, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 17280, 17280, 34560, 17280, 17280, 8640, 17280, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 8640, 8640, 34560, 34560, 34560, 8640, 17280, 34560, 17280, 17280, 17280, 8640, 34560, 8640, 34560, 17280, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 17280, 8640, 17280, 8640, 8640, 8640, 34560, 34560, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 8640, 8640, 17280, 8640, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 8640, 17280, 34560, 17280, 17280, 34560, 17280, 8640, 17280, 8640, 34560, 17280, 17280, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 34560, 17280, 8640, 17280, 8640, 17280, 34560, 34560, 34560, 8640, 34560, 34560, 34560, 34560, 8640, 17280, 17280, 34560, 8640, 34560, 8640, 8640, 8640, 34560, 17280, 34560, 34560, 8640, 17280, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 34560, 8640, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 34560, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 8640]
Prompts retrieved: 6462720 . Total input tokens: 1438948254 . Total output tokens: 1292672847
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.637211550027132,
    "estimated_duration": 3600.128436044048,
    "input_throughput": 2814.826520782497,
    "output_throughput": 2497.020914586618,
    "total_throughput": 5311.847435369115,
    "itl": 133.88908263985869,
    "ttft": 2453424.04113346,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9648,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 31.516520610509065,
    "arrivals": 2153264,
    "finished_requests": 41130,
    "scheduler_time": 72.84944653013808
}
#Debug simulation 
Total elapsed time: 3.6372733080061153. Arrivals time: 0.1981449187733233 Scheduler time: 3.118747615662869 Scheduler overhead time: 0.039911361411213875 Adapter cache time: 0.22177398018538952 Engine time: 0.040240873699076474 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-16/adapters_320_slots_192_rate_3.2-1.6-0.8_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-16/adapters_320_slots_192_rate_3.2-1.6-0.8_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 8640, 34560, 34560, 17280, 17280, 17280, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 17280, 34560, 17280, 34560, 34560, 8640, 34560, 17280, 17280, 34560, 34560, 17280, 8640, 8640, 17280, 34560, 34560, 17280, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 34560, 17280, 8640, 17280, 34560, 8640, 17280, 34560, 34560, 17280, 8640, 8640, 34560, 8640, 8640, 34560, 34560, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 8640, 34560, 8640, 34560, 17280, 34560, 34560, 8640, 34560, 8640, 34560, 17280, 8640, 8640, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 8640, 17280, 17280, 8640, 34560, 17280, 34560, 34560, 17280, 8640, 17280, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 8640, 8640, 17280, 34560, 34560, 17280, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 17280, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 17280, 17280, 34560, 17280, 17280, 8640, 17280, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 8640, 8640, 34560, 34560, 34560, 8640, 17280, 34560, 17280, 17280, 17280, 8640, 34560, 8640, 34560, 17280, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 17280, 8640, 17280, 8640, 8640, 8640, 34560, 34560, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 8640, 8640, 17280, 8640, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 8640, 17280, 34560, 17280, 17280, 34560, 17280, 8640, 17280, 8640, 34560, 17280, 17280, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 34560, 17280, 8640, 17280, 8640, 17280, 34560, 34560, 34560, 8640, 34560, 34560, 34560, 34560, 8640, 17280, 17280, 34560, 8640, 34560, 8640, 8640, 8640, 34560, 17280, 34560, 34560, 8640, 17280, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 34560, 8640, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 34560, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 8640]
Prompts retrieved: 6462720 . Total input tokens: 1438948254 . Total output tokens: 1292672847
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 7.318030521972105,
    "estimated_duration": 3600.233259392476,
    "input_throughput": 3659.1362422508737,
    "output_throughput": 3226.165685153404,
    "total_throughput": 6885.301927404277,
    "itl": 262.4258931303506,
    "ttft": 2327170.4029971357,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1337,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.179113565671664,
    "arrivals": 2153264,
    "finished_requests": 53436,
    "scheduler_time": 66.0036341016945
}
#Debug simulation 
Total elapsed time: 7.3181436699815094. Arrivals time: 0.25140653300331905 Scheduler time: 6.970857214415446 Scheduler overhead time: 0.024337730719707906 Adapter cache time: 0.03675311792176217 Engine time: 0.024199213832616806 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-32/adapters_320_slots_192_rate_3.2-1.6-0.8_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-32/adapters_320_slots_192_rate_3.2-1.6-0.8_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 8640, 34560, 34560, 17280, 17280, 17280, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 17280, 34560, 17280, 34560, 34560, 8640, 34560, 17280, 17280, 34560, 34560, 17280, 8640, 8640, 17280, 34560, 34560, 17280, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 34560, 17280, 8640, 17280, 34560, 8640, 17280, 34560, 34560, 17280, 8640, 8640, 34560, 8640, 8640, 34560, 34560, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 8640, 34560, 8640, 34560, 17280, 34560, 34560, 8640, 34560, 8640, 34560, 17280, 8640, 8640, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 8640, 17280, 17280, 8640, 34560, 17280, 34560, 34560, 17280, 8640, 17280, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 8640, 8640, 17280, 34560, 34560, 17280, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 17280, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 17280, 17280, 34560, 17280, 17280, 8640, 17280, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 8640, 8640, 34560, 34560, 34560, 8640, 17280, 34560, 17280, 17280, 17280, 8640, 34560, 8640, 34560, 17280, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 17280, 8640, 17280, 8640, 8640, 8640, 34560, 34560, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 8640, 8640, 17280, 8640, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 8640, 17280, 34560, 17280, 17280, 34560, 17280, 8640, 17280, 8640, 34560, 17280, 17280, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 34560, 17280, 8640, 17280, 8640, 17280, 34560, 34560, 34560, 8640, 34560, 34560, 34560, 34560, 8640, 17280, 17280, 34560, 8640, 34560, 8640, 8640, 8640, 34560, 17280, 34560, 34560, 8640, 17280, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 34560, 8640, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 34560, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 8640]
Prompts retrieved: 6462720 . Total input tokens: 1438948254 . Total output tokens: 1292672847
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 3.620111263997387,
    "estimated_duration": 3600.07362156811,
    "input_throughput": 2814.531052725112,
    "output_throughput": 2496.862549184382,
    "total_throughput": 5311.393601909494,
    "itl": 133.90509745027313,
    "ttft": 2453318.5388433784,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9648,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 31.923334109559047,
    "arrivals": 2153264,
    "finished_requests": 41125,
    "scheduler_time": 72.84019134754583
}
#Debug simulation 
Total elapsed time: 3.6201761870179325. Arrivals time: 0.19578455295413733 Scheduler time: 3.1029888297780417 Scheduler overhead time: 0.04006396816112101 Adapter cache time: 0.22297873842762783 Engine time: 0.04001975274877623 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-16/adapters_320_slots_192_rate_3.2-1.6-0.8_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-16/adapters_320_slots_192_rate_3.2-1.6-0.8_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 8640, 34560, 34560, 17280, 17280, 17280, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 17280, 34560, 17280, 34560, 34560, 8640, 34560, 17280, 17280, 34560, 34560, 17280, 8640, 8640, 17280, 34560, 34560, 17280, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 34560, 17280, 8640, 17280, 34560, 8640, 17280, 34560, 34560, 17280, 8640, 8640, 34560, 8640, 8640, 34560, 34560, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 8640, 34560, 8640, 34560, 17280, 34560, 34560, 8640, 34560, 8640, 34560, 17280, 8640, 8640, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 8640, 17280, 17280, 8640, 34560, 17280, 34560, 34560, 17280, 8640, 17280, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 8640, 8640, 17280, 34560, 34560, 17280, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 17280, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 17280, 17280, 34560, 17280, 17280, 8640, 17280, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 8640, 8640, 34560, 34560, 34560, 8640, 17280, 34560, 17280, 17280, 17280, 8640, 34560, 8640, 34560, 17280, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 17280, 8640, 17280, 8640, 8640, 8640, 34560, 34560, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 8640, 8640, 17280, 8640, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 8640, 17280, 34560, 17280, 17280, 34560, 17280, 8640, 17280, 8640, 34560, 17280, 17280, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 34560, 17280, 8640, 17280, 8640, 17280, 34560, 34560, 34560, 8640, 34560, 34560, 34560, 34560, 8640, 17280, 17280, 34560, 8640, 34560, 8640, 8640, 8640, 34560, 17280, 34560, 34560, 8640, 17280, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 34560, 8640, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 34560, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 8640]
Prompts retrieved: 6462720 . Total input tokens: 1438948254 . Total output tokens: 1292672847
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 7.284958336036652,
    "estimated_duration": 3600.0515697400097,
    "input_throughput": 3659.3209138255174,
    "output_throughput": 3226.328505299388,
    "total_throughput": 6885.649419124905,
    "itl": 262.4140370954603,
    "ttft": 2327102.7419392667,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1337,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.9976972442841037,
    "arrivals": 2153264,
    "finished_requests": 53436,
    "scheduler_time": 66.00336077057048
}
#Debug simulation 
Total elapsed time: 7.285059511021245. Arrivals time: 0.24988237919751555 Scheduler time: 6.939644194324501 Scheduler overhead time: 0.023982914455700666 Adapter cache time: 0.03704669390572235 Engine time: 0.023976782453246415 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-32/adapters_320_slots_192_rate_3.2-1.6-0.8_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-32/adapters_320_slots_192_rate_3.2-1.6-0.8_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 8640, 34560, 34560, 17280, 17280, 17280, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 17280, 34560, 17280, 34560, 34560, 8640, 34560, 17280, 17280, 34560, 34560, 17280, 8640, 8640, 17280, 34560, 34560, 17280, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 34560, 17280, 8640, 17280, 34560, 8640, 17280, 34560, 34560, 17280, 8640, 8640, 34560, 8640, 8640, 34560, 34560, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 8640, 34560, 8640, 34560, 17280, 34560, 34560, 8640, 34560, 8640, 34560, 17280, 8640, 8640, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 8640, 17280, 17280, 8640, 34560, 17280, 34560, 34560, 17280, 8640, 17280, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 8640, 8640, 17280, 34560, 34560, 17280, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 17280, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 17280, 17280, 34560, 17280, 17280, 8640, 17280, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 8640, 8640, 34560, 34560, 34560, 8640, 17280, 34560, 17280, 17280, 17280, 8640, 34560, 8640, 34560, 17280, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 17280, 8640, 17280, 8640, 8640, 8640, 34560, 34560, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 8640, 8640, 17280, 8640, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 8640, 17280, 34560, 17280, 17280, 34560, 17280, 8640, 17280, 8640, 34560, 17280, 17280, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 34560, 17280, 8640, 17280, 8640, 17280, 34560, 34560, 34560, 8640, 34560, 34560, 34560, 34560, 8640, 17280, 17280, 34560, 8640, 34560, 8640, 8640, 8640, 34560, 17280, 34560, 34560, 8640, 17280, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 34560, 8640, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 34560, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 8640]
Prompts retrieved: 6462720 . Total input tokens: 1438948254 . Total output tokens: 1292672847
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.649438081018161,
    "estimated_duration": 3600.001352217757,
    "input_throughput": 2813.7394986698573,
    "output_throughput": 2496.476006728004,
    "total_throughput": 5310.215505397861,
    "itl": 133.92054123086987,
    "ttft": 2453386.4803988794,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9646,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 32.31219398893153,
    "arrivals": 2153264,
    "finished_requests": 41114,
    "scheduler_time": 72.83094737115454
}
#Debug simulation 
Total elapsed time: 3.649503717024345. Arrivals time: 0.20470926974667236 Scheduler time: 3.12238069542218 Scheduler overhead time: 0.04010751313762739 Adapter cache time: 0.2235035338671878 Engine time: 0.040302813111338764 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-8/adapters_320_slots_192_rate_3.2-1.6-0.4_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-8/adapters_320_slots_192_rate_3.2-1.6-0.4_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 4320, 34560, 34560, 17280, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 17280, 34560, 17280, 34560, 34560, 4320, 34560, 17280, 17280, 34560, 34560, 17280, 4320, 4320, 17280, 34560, 34560, 17280, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 34560, 17280, 4320, 17280, 34560, 4320, 17280, 34560, 34560, 17280, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 4320, 34560, 4320, 34560, 17280, 34560, 34560, 4320, 34560, 4320, 34560, 17280, 4320, 4320, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 4320, 17280, 17280, 4320, 34560, 17280, 34560, 34560, 17280, 4320, 17280, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 4320, 4320, 17280, 34560, 34560, 17280, 4320, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 17280, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 17280, 17280, 34560, 17280, 17280, 4320, 17280, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 4320, 17280, 34560, 17280, 17280, 17280, 4320, 34560, 4320, 34560, 17280, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 17280, 4320, 17280, 4320, 4320, 4320, 34560, 34560, 17280, 17280, 4320, 4320, 17280, 4320, 34560, 4320, 4320, 17280, 4320, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 4320, 17280, 34560, 17280, 17280, 34560, 17280, 4320, 17280, 4320, 34560, 17280, 17280, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 17280, 4320, 17280, 4320, 17280, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 17280, 17280, 34560, 4320, 34560, 4320, 4320, 4320, 34560, 17280, 34560, 34560, 4320, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 34560, 4320, 4320, 17280, 4320, 17280, 17280, 4320, 34560, 34560, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 6004800 . Total input tokens: 1336758239 . Total output tokens: 1201018668
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 6.68285211303737,
    "estimated_duration": 3600.1869674393415,
    "input_throughput": 3680.9743826792746,
    "output_throughput": 3227.677369285346,
    "total_throughput": 6908.65175196462,
    "itl": 263.6394579916558,
    "ttft": 2324693.879931676,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1259,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.853154069611435,
    "arrivals": 2000260,
    "finished_requests": 53662,
    "scheduler_time": 65.94472430881103
}
#Debug simulation 
Total elapsed time: 6.682924319989979. Arrivals time: 0.2514258263981901 Scheduler time: 6.3390365142258815 Scheduler overhead time: 0.023788284859620035 Adapter cache time: 0.034419159521348774 Engine time: 0.023802771174814552 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-16/adapters_320_slots_192_rate_3.2-1.6-0.4_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-16/adapters_320_slots_192_rate_3.2-1.6-0.4_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 4320, 34560, 34560, 17280, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 17280, 34560, 17280, 34560, 34560, 4320, 34560, 17280, 17280, 34560, 34560, 17280, 4320, 4320, 17280, 34560, 34560, 17280, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 34560, 17280, 4320, 17280, 34560, 4320, 17280, 34560, 34560, 17280, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 4320, 34560, 4320, 34560, 17280, 34560, 34560, 4320, 34560, 4320, 34560, 17280, 4320, 4320, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 4320, 17280, 17280, 4320, 34560, 17280, 34560, 34560, 17280, 4320, 17280, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 4320, 4320, 17280, 34560, 34560, 17280, 4320, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 17280, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 17280, 17280, 34560, 17280, 17280, 4320, 17280, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 4320, 17280, 34560, 17280, 17280, 17280, 4320, 34560, 4320, 34560, 17280, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 17280, 4320, 17280, 4320, 4320, 4320, 34560, 34560, 17280, 17280, 4320, 4320, 17280, 4320, 34560, 4320, 4320, 17280, 4320, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 4320, 17280, 34560, 17280, 17280, 34560, 17280, 4320, 17280, 4320, 34560, 17280, 17280, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 17280, 4320, 17280, 4320, 17280, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 17280, 17280, 34560, 4320, 34560, 4320, 4320, 4320, 34560, 17280, 34560, 34560, 4320, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 34560, 4320, 4320, 17280, 4320, 17280, 17280, 4320, 34560, 34560, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 6004800 . Total input tokens: 1336758239 . Total output tokens: 1201018668
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 6.631472616980318,
    "estimated_duration": 3600.1490644035357,
    "input_throughput": 3674.4989619455405,
    "output_throughput": 3219.021432913926,
    "total_throughput": 6893.520394859466,
    "itl": 260.98394527101584,
    "ttft": 2325841.573450368,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1259,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.109736365363929,
    "arrivals": 2000260,
    "finished_requests": 53540,
    "scheduler_time": 66.01754256337458
}
#Debug simulation 
Total elapsed time: 6.631572344980668. Arrivals time: 0.2511814935714938 Scheduler time: 6.287626245524734 Scheduler overhead time: 0.02376674406696111 Adapter cache time: 0.03458819701336324 Engine time: 0.023837660439312458 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-32/adapters_320_slots_192_rate_3.2-1.6-0.4_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-32/adapters_320_slots_192_rate_3.2-1.6-0.4_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 4320, 34560, 34560, 17280, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 17280, 34560, 17280, 34560, 34560, 4320, 34560, 17280, 17280, 34560, 34560, 17280, 4320, 4320, 17280, 34560, 34560, 17280, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 34560, 17280, 4320, 17280, 34560, 4320, 17280, 34560, 34560, 17280, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 4320, 34560, 4320, 34560, 17280, 34560, 34560, 4320, 34560, 4320, 34560, 17280, 4320, 4320, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 4320, 17280, 17280, 4320, 34560, 17280, 34560, 34560, 17280, 4320, 17280, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 4320, 4320, 17280, 34560, 34560, 17280, 4320, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 17280, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 17280, 17280, 34560, 17280, 17280, 4320, 17280, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 4320, 17280, 34560, 17280, 17280, 17280, 4320, 34560, 4320, 34560, 17280, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 17280, 4320, 17280, 4320, 4320, 4320, 34560, 34560, 17280, 17280, 4320, 4320, 17280, 4320, 34560, 4320, 4320, 17280, 4320, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 4320, 17280, 34560, 17280, 17280, 34560, 17280, 4320, 17280, 4320, 34560, 17280, 17280, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 17280, 4320, 17280, 4320, 17280, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 17280, 17280, 34560, 4320, 34560, 4320, 4320, 4320, 34560, 17280, 34560, 34560, 4320, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 34560, 4320, 4320, 17280, 4320, 17280, 17280, 4320, 34560, 34560, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 6004800 . Total input tokens: 1336758239 . Total output tokens: 1201018668
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 2.4006649229559116,
    "estimated_duration": 3600.0537520235575,
    "input_throughput": 1735.6565847073252,
    "output_throughput": 1523.2775335417034,
    "total_throughput": 3258.934118249029,
    "itl": 78.9885973218049,
    "ttft": 2689962.8818435743,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5427,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.749479137285483,
    "arrivals": 2000260,
    "finished_requests": 25143,
    "scheduler_time": 84.30335231968276
}
#Debug simulation 
Total elapsed time: 2.4007280449732207. Arrivals time: 0.1503149323980324 Scheduler time: 1.960621114470996 Scheduler overhead time: 0.054128459945786744 Adapter cache time: 0.15916446241317317 Engine time: 0.051631501875817776 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-16-16/adapters_320_slots_192_rate_3.2-1.6-0.4_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-16-16/adapters_320_slots_192_rate_3.2-1.6-0.4_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 4320, 34560, 34560, 17280, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 17280, 34560, 17280, 34560, 34560, 4320, 34560, 17280, 17280, 34560, 34560, 17280, 4320, 4320, 17280, 34560, 34560, 17280, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 34560, 17280, 4320, 17280, 34560, 4320, 17280, 34560, 34560, 17280, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 4320, 34560, 4320, 34560, 17280, 34560, 34560, 4320, 34560, 4320, 34560, 17280, 4320, 4320, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 4320, 17280, 17280, 4320, 34560, 17280, 34560, 34560, 17280, 4320, 17280, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 4320, 4320, 17280, 34560, 34560, 17280, 4320, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 17280, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 17280, 17280, 34560, 17280, 17280, 4320, 17280, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 4320, 17280, 34560, 17280, 17280, 17280, 4320, 34560, 4320, 34560, 17280, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 17280, 4320, 17280, 4320, 4320, 4320, 34560, 34560, 17280, 17280, 4320, 4320, 17280, 4320, 34560, 4320, 4320, 17280, 4320, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 4320, 17280, 34560, 17280, 17280, 34560, 17280, 4320, 17280, 4320, 34560, 17280, 17280, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 17280, 4320, 17280, 4320, 17280, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 17280, 17280, 34560, 4320, 34560, 4320, 4320, 4320, 34560, 17280, 34560, 34560, 4320, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 34560, 4320, 4320, 17280, 4320, 17280, 17280, 4320, 34560, 34560, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 6004800 . Total input tokens: 1336758239 . Total output tokens: 1201018668
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 6.607339782989584,
    "estimated_duration": 3600.2670573062383,
    "input_throughput": 3674.4654742079424,
    "output_throughput": 3219.260075854462,
    "total_throughput": 6893.725550062404,
    "itl": 260.97449617446904,
    "ttft": 2325798.1172321253,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1259,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.933223187797655,
    "arrivals": 2000260,
    "finished_requests": 53544,
    "scheduler_time": 66.02271535773849
}
#Debug simulation 
Total elapsed time: 6.607461030012928. Arrivals time: 0.2511558426776901 Scheduler time: 6.262817217910197 Scheduler overhead time: 0.024075489898677915 Adapter cache time: 0.034760055132210255 Engine time: 0.024116026237607002 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-16-32/adapters_320_slots_192_rate_3.2-1.6-0.4_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-16-32/adapters_320_slots_192_rate_3.2-1.6-0.4_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 4320, 34560, 34560, 17280, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 17280, 34560, 17280, 34560, 34560, 4320, 34560, 17280, 17280, 34560, 34560, 17280, 4320, 4320, 17280, 34560, 34560, 17280, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 34560, 17280, 4320, 17280, 34560, 4320, 17280, 34560, 34560, 17280, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 4320, 34560, 4320, 34560, 17280, 34560, 34560, 4320, 34560, 4320, 34560, 17280, 4320, 4320, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 4320, 17280, 17280, 4320, 34560, 17280, 34560, 34560, 17280, 4320, 17280, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 4320, 4320, 17280, 34560, 34560, 17280, 4320, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 17280, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 17280, 17280, 34560, 17280, 17280, 4320, 17280, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 4320, 17280, 34560, 17280, 17280, 17280, 4320, 34560, 4320, 34560, 17280, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 17280, 4320, 17280, 4320, 4320, 4320, 34560, 34560, 17280, 17280, 4320, 4320, 17280, 4320, 34560, 4320, 4320, 17280, 4320, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 4320, 17280, 34560, 17280, 17280, 34560, 17280, 4320, 17280, 4320, 34560, 17280, 17280, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 17280, 4320, 17280, 4320, 17280, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 17280, 17280, 34560, 4320, 34560, 4320, 4320, 4320, 34560, 17280, 34560, 34560, 4320, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 34560, 4320, 4320, 17280, 4320, 17280, 17280, 4320, 34560, 34560, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 6004800 . Total input tokens: 1336758239 . Total output tokens: 1201018668
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 2.399813025025651,
    "estimated_duration": 3600.0140804300468,
    "input_throughput": 1735.6340448684011,
    "output_throughput": 1523.2909865021732,
    "total_throughput": 3258.9250313705743,
    "itl": 78.9939965150621,
    "ttft": 2689947.152993119,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5427,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.96917100215216,
    "arrivals": 2000260,
    "finished_requests": 25142,
    "scheduler_time": 84.29744570912122
}
#Debug simulation 
Total elapsed time: 2.3998758190427907. Arrivals time: 0.15120262780692428 Scheduler time: 1.9592750244773924 Scheduler overhead time: 0.05455007212003693 Adapter cache time: 0.15849781758151948 Engine time: 0.05160031758714467 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_16-16-16/adapters_320_slots_192_rate_3.2-1.6-0.4_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_16-16-16/adapters_320_slots_192_rate_3.2-1.6-0.4_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 4320, 34560, 34560, 17280, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 17280, 34560, 17280, 34560, 34560, 4320, 34560, 17280, 17280, 34560, 34560, 17280, 4320, 4320, 17280, 34560, 34560, 17280, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 34560, 17280, 4320, 17280, 34560, 4320, 17280, 34560, 34560, 17280, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 4320, 34560, 4320, 34560, 17280, 34560, 34560, 4320, 34560, 4320, 34560, 17280, 4320, 4320, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 4320, 17280, 17280, 4320, 34560, 17280, 34560, 34560, 17280, 4320, 17280, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 4320, 4320, 17280, 34560, 34560, 17280, 4320, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 17280, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 17280, 17280, 34560, 17280, 17280, 4320, 17280, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 4320, 17280, 34560, 17280, 17280, 17280, 4320, 34560, 4320, 34560, 17280, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 17280, 4320, 17280, 4320, 4320, 4320, 34560, 34560, 17280, 17280, 4320, 4320, 17280, 4320, 34560, 4320, 4320, 17280, 4320, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 4320, 17280, 34560, 17280, 17280, 34560, 17280, 4320, 17280, 4320, 34560, 17280, 17280, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 17280, 4320, 17280, 4320, 17280, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 17280, 17280, 34560, 4320, 34560, 4320, 4320, 4320, 34560, 17280, 34560, 34560, 4320, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 34560, 4320, 4320, 17280, 4320, 17280, 17280, 4320, 34560, 34560, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 6004800 . Total input tokens: 1336758239 . Total output tokens: 1201018668
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 6.529472844966222,
    "estimated_duration": 3600.2741432100115,
    "input_throughput": 3676.0217343337995,
    "output_throughput": 3218.6024005572667,
    "total_throughput": 6894.624134891066,
    "itl": 260.96810516904117,
    "ttft": 2325805.7006809358,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1276,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.8153041762950775,
    "arrivals": 2000260,
    "finished_requests": 53544,
    "scheduler_time": 66.02445229657471
}
#Debug simulation 
Total elapsed time: 6.529575289983768. Arrivals time: 0.24377481604460627 Scheduler time: 6.191897429293022 Scheduler overhead time: 0.0237839036853984 Adapter cache time: 0.03597967722453177 Engine time: 0.02366951876319945 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_16-16-32/adapters_320_slots_192_rate_3.2-1.6-0.4_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_16-16-32/adapters_320_slots_192_rate_3.2-1.6-0.4_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 4320, 34560, 34560, 17280, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 17280, 34560, 17280, 34560, 34560, 4320, 34560, 17280, 17280, 34560, 34560, 17280, 4320, 4320, 17280, 34560, 34560, 17280, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 34560, 17280, 4320, 17280, 34560, 4320, 17280, 34560, 34560, 17280, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 4320, 34560, 4320, 34560, 17280, 34560, 34560, 4320, 34560, 4320, 34560, 17280, 4320, 4320, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 4320, 17280, 17280, 4320, 34560, 17280, 34560, 34560, 17280, 4320, 17280, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 4320, 4320, 17280, 34560, 34560, 17280, 4320, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 17280, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 17280, 17280, 34560, 17280, 17280, 4320, 17280, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 4320, 17280, 34560, 17280, 17280, 17280, 4320, 34560, 4320, 34560, 17280, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 17280, 4320, 17280, 4320, 4320, 4320, 34560, 34560, 17280, 17280, 4320, 4320, 17280, 4320, 34560, 4320, 4320, 17280, 4320, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 4320, 17280, 34560, 17280, 17280, 34560, 17280, 4320, 17280, 4320, 34560, 17280, 17280, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 17280, 4320, 17280, 4320, 17280, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 17280, 17280, 34560, 4320, 34560, 4320, 4320, 4320, 34560, 17280, 34560, 34560, 4320, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 34560, 4320, 4320, 17280, 4320, 17280, 17280, 4320, 34560, 34560, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 6004800 . Total input tokens: 1336758239 . Total output tokens: 1201018668
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 2.3928012260003015,
    "estimated_duration": 3600.077123621599,
    "input_throughput": 1735.5239305858615,
    "output_throughput": 1523.165424435048,
    "total_throughput": 3258.6893550209093,
    "itl": 79.0009863164784,
    "ttft": 2689973.3175893994,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5426,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.20547695271537,
    "arrivals": 2000260,
    "finished_requests": 25140,
    "scheduler_time": 84.29356046461605
}
#Debug simulation 
Total elapsed time: 2.392865233006887. Arrivals time: 0.14835710189072415 Scheduler time: 1.9572037914767861 Scheduler overhead time: 0.05403350532287732 Adapter cache time: 0.1573448430863209 Engine time: 0.05134592222748324 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-8/adapters_320_slots_192_rate_3.2-1.6-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-8/adapters_320_slots_192_rate_3.2-1.6-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 1080, 34560, 34560, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 17280, 34560, 17280, 34560, 34560, 1080, 34560, 17280, 17280, 34560, 34560, 17280, 1080, 1080, 17280, 34560, 34560, 17280, 17280, 1080, 1080, 17280, 34560, 34560, 1080, 34560, 17280, 1080, 17280, 34560, 1080, 17280, 34560, 34560, 17280, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 1080, 34560, 1080, 34560, 17280, 34560, 34560, 1080, 34560, 1080, 34560, 17280, 1080, 1080, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 17280, 1080, 34560, 17280, 34560, 34560, 17280, 1080, 17280, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 34560, 1080, 1080, 17280, 34560, 34560, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 17280, 1080, 17280, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 17280, 17280, 34560, 17280, 17280, 1080, 17280, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 17280, 34560, 17280, 17280, 17280, 1080, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 17280, 1080, 17280, 1080, 1080, 1080, 34560, 34560, 17280, 17280, 1080, 1080, 17280, 1080, 34560, 1080, 1080, 17280, 1080, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 1080, 17280, 34560, 17280, 17280, 34560, 17280, 1080, 17280, 1080, 34560, 17280, 17280, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 17280, 17280, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 17280, 34560, 34560, 1080, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 34560, 1080, 1080, 17280, 1080, 17280, 17280, 1080, 34560, 34560, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5661360 . Total input tokens: 1260518946 . Total output tokens: 1132323398
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.710074634989724,
    "estimated_duration": 3600.1681301181793,
    "input_throughput": 3666.237109755962,
    "output_throughput": 3228.2645087518417,
    "total_throughput": 6894.501618507804,
    "itl": 264.4130218438217,
    "ttft": 2323746.3721105144,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1207,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.694008706926926,
    "arrivals": 1885868,
    "finished_requests": 53526,
    "scheduler_time": 65.92513184738064
}
#Debug simulation 
Total elapsed time: 5.710146015975624. Arrivals time: 0.2332718629622832 Scheduler time: 5.387311718426645 Scheduler overhead time: 0.023063415254000574 Adapter cache time: 0.03317005967255682 Engine time: 0.023129459121264517 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-16/adapters_320_slots_192_rate_3.2-1.6-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-16/adapters_320_slots_192_rate_3.2-1.6-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 1080, 34560, 34560, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 17280, 34560, 17280, 34560, 34560, 1080, 34560, 17280, 17280, 34560, 34560, 17280, 1080, 1080, 17280, 34560, 34560, 17280, 17280, 1080, 1080, 17280, 34560, 34560, 1080, 34560, 17280, 1080, 17280, 34560, 1080, 17280, 34560, 34560, 17280, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 1080, 34560, 1080, 34560, 17280, 34560, 34560, 1080, 34560, 1080, 34560, 17280, 1080, 1080, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 17280, 1080, 34560, 17280, 34560, 34560, 17280, 1080, 17280, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 34560, 1080, 1080, 17280, 34560, 34560, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 17280, 1080, 17280, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 17280, 17280, 34560, 17280, 17280, 1080, 17280, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 17280, 34560, 17280, 17280, 17280, 1080, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 17280, 1080, 17280, 1080, 1080, 1080, 34560, 34560, 17280, 17280, 1080, 1080, 17280, 1080, 34560, 1080, 1080, 17280, 1080, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 1080, 17280, 34560, 17280, 17280, 34560, 17280, 1080, 17280, 1080, 34560, 17280, 17280, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 17280, 17280, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 17280, 34560, 34560, 1080, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 34560, 1080, 1080, 17280, 1080, 17280, 17280, 1080, 34560, 34560, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5661360 . Total input tokens: 1260518946 . Total output tokens: 1132323398
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.100922188023105,
    "estimated_duration": 3600.2579931752985,
    "input_throughput": 3655.5402487677193,
    "output_throughput": 3219.337064724532,
    "total_throughput": 6874.877313492251,
    "itl": 261.5723076127562,
    "ttft": 2324804.828755174,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1289,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.207609780579795,
    "arrivals": 1885868,
    "finished_requests": 53359,
    "scheduler_time": 66.00116818225695
}
#Debug simulation 
Total elapsed time: 5.100987787009217. Arrivals time: 0.2326547158882022 Scheduler time: 4.776670545747038 Scheduler overhead time: 0.023135208408348262 Adapter cache time: 0.03508698078803718 Engine time: 0.023150440596509725 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-32/adapters_320_slots_192_rate_3.2-1.6-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-32/adapters_320_slots_192_rate_3.2-1.6-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 1080, 34560, 34560, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 17280, 34560, 17280, 34560, 34560, 1080, 34560, 17280, 17280, 34560, 34560, 17280, 1080, 1080, 17280, 34560, 34560, 17280, 17280, 1080, 1080, 17280, 34560, 34560, 1080, 34560, 17280, 1080, 17280, 34560, 1080, 17280, 34560, 34560, 17280, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 1080, 34560, 1080, 34560, 17280, 34560, 34560, 1080, 34560, 1080, 34560, 17280, 1080, 1080, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 17280, 1080, 34560, 17280, 34560, 34560, 17280, 1080, 17280, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 34560, 1080, 1080, 17280, 34560, 34560, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 17280, 1080, 17280, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 17280, 17280, 34560, 17280, 17280, 1080, 17280, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 17280, 34560, 17280, 17280, 17280, 1080, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 17280, 1080, 17280, 1080, 1080, 1080, 34560, 34560, 17280, 17280, 1080, 1080, 17280, 1080, 34560, 1080, 1080, 17280, 1080, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 1080, 17280, 34560, 17280, 17280, 34560, 17280, 1080, 17280, 1080, 34560, 17280, 17280, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 17280, 17280, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 17280, 34560, 34560, 1080, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 34560, 1080, 1080, 17280, 1080, 17280, 17280, 1080, 34560, 34560, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5661360 . Total input tokens: 1260518946 . Total output tokens: 1132323398
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.7819895549910143,
    "estimated_duration": 3600.1350433373623,
    "input_throughput": 2982.977546876887,
    "output_throughput": 2642.6661459844754,
    "total_throughput": 5625.643692861362,
    "itl": 128.3598257515663,
    "ttft": 2427343.7753328113,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5833,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.092729740644902,
    "arrivals": 1885868,
    "finished_requests": 43528,
    "scheduler_time": 76.53389541503927
}
#Debug simulation 
Total elapsed time: 3.782076524978038. Arrivals time: 0.32944131165277213 Scheduler time: 3.156543339777272 Scheduler overhead time: 0.04023327602772042 Adapter cache time: 0.1959174500661902 Engine time: 0.041150422708597034 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-16-16/adapters_320_slots_192_rate_3.2-1.6-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-16-16/adapters_320_slots_192_rate_3.2-1.6-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 1080, 34560, 34560, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 17280, 34560, 17280, 34560, 34560, 1080, 34560, 17280, 17280, 34560, 34560, 17280, 1080, 1080, 17280, 34560, 34560, 17280, 17280, 1080, 1080, 17280, 34560, 34560, 1080, 34560, 17280, 1080, 17280, 34560, 1080, 17280, 34560, 34560, 17280, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 1080, 34560, 1080, 34560, 17280, 34560, 34560, 1080, 34560, 1080, 34560, 17280, 1080, 1080, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 17280, 1080, 34560, 17280, 34560, 34560, 17280, 1080, 17280, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 34560, 1080, 1080, 17280, 34560, 34560, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 17280, 1080, 17280, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 17280, 17280, 34560, 17280, 17280, 1080, 17280, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 17280, 34560, 17280, 17280, 17280, 1080, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 17280, 1080, 17280, 1080, 1080, 1080, 34560, 34560, 17280, 17280, 1080, 1080, 17280, 1080, 34560, 1080, 1080, 17280, 1080, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 1080, 17280, 34560, 17280, 17280, 34560, 17280, 1080, 17280, 1080, 34560, 17280, 17280, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 17280, 17280, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 17280, 34560, 34560, 1080, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 34560, 1080, 1080, 17280, 1080, 17280, 17280, 1080, 34560, 34560, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5661360 . Total input tokens: 1260518946 . Total output tokens: 1132323398
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 5.0478193199960515,
    "estimated_duration": 3600.0783834342706,
    "input_throughput": 3655.7226255294086,
    "output_throughput": 3219.49767908758,
    "total_throughput": 6875.220304616988,
    "itl": 261.56036116117355,
    "ttft": 2324736.373289412,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1289,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.028236435784442,
    "arrivals": 1885868,
    "finished_requests": 53359,
    "scheduler_time": 66.00093178597915
}
#Debug simulation 
Total elapsed time: 5.047942508012056. Arrivals time: 0.21472105552675202 Scheduler time: 4.743170090077911 Scheduler overhead time: 0.02286192966857925 Adapter cache time: 0.033887730503920466 Engine time: 0.022978553839493543 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-16-32/adapters_320_slots_192_rate_3.2-1.6-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-16-32/adapters_320_slots_192_rate_3.2-1.6-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 1080, 34560, 34560, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 17280, 34560, 17280, 34560, 34560, 1080, 34560, 17280, 17280, 34560, 34560, 17280, 1080, 1080, 17280, 34560, 34560, 17280, 17280, 1080, 1080, 17280, 34560, 34560, 1080, 34560, 17280, 1080, 17280, 34560, 1080, 17280, 34560, 34560, 17280, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 1080, 34560, 1080, 34560, 17280, 34560, 34560, 1080, 34560, 1080, 34560, 17280, 1080, 1080, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 17280, 1080, 34560, 17280, 34560, 34560, 17280, 1080, 17280, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 34560, 1080, 1080, 17280, 34560, 34560, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 17280, 1080, 17280, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 17280, 17280, 34560, 17280, 17280, 1080, 17280, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 17280, 34560, 17280, 17280, 17280, 1080, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 17280, 1080, 17280, 1080, 1080, 1080, 34560, 34560, 17280, 17280, 1080, 1080, 17280, 1080, 34560, 1080, 1080, 17280, 1080, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 1080, 17280, 34560, 17280, 17280, 34560, 17280, 1080, 17280, 1080, 34560, 17280, 17280, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 17280, 17280, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 17280, 34560, 34560, 1080, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 34560, 1080, 1080, 17280, 1080, 17280, 17280, 1080, 34560, 34560, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5661360 . Total input tokens: 1260518946 . Total output tokens: 1132323398
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.066928461019415,
    "estimated_duration": 3600.1010796955416,
    "input_throughput": 2982.8037497514206,
    "output_throughput": 2642.4860828642422,
    "total_throughput": 5625.289832615663,
    "itl": 128.36980396703777,
    "ttft": 2427314.3604987734,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5833,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.348261434639635,
    "arrivals": 1885868,
    "finished_requests": 43523,
    "scheduler_time": 76.52784274864051
}
#Debug simulation 
Total elapsed time: 4.066994785971474. Arrivals time: 0.6424640401965007 Scheduler time: 3.1319207418127917 Scheduler overhead time: 0.039969925535842776 Adapter cache time: 0.192980996274855 Engine time: 0.04100405884673819 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_16-16-16/adapters_320_slots_192_rate_3.2-1.6-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_16-16-16/adapters_320_slots_192_rate_3.2-1.6-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 1080, 34560, 34560, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 17280, 34560, 17280, 34560, 34560, 1080, 34560, 17280, 17280, 34560, 34560, 17280, 1080, 1080, 17280, 34560, 34560, 17280, 17280, 1080, 1080, 17280, 34560, 34560, 1080, 34560, 17280, 1080, 17280, 34560, 1080, 17280, 34560, 34560, 17280, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 1080, 34560, 1080, 34560, 17280, 34560, 34560, 1080, 34560, 1080, 34560, 17280, 1080, 1080, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 17280, 1080, 34560, 17280, 34560, 34560, 17280, 1080, 17280, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 34560, 1080, 1080, 17280, 34560, 34560, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 17280, 1080, 17280, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 17280, 17280, 34560, 17280, 17280, 1080, 17280, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 17280, 34560, 17280, 17280, 17280, 1080, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 17280, 1080, 17280, 1080, 1080, 1080, 34560, 34560, 17280, 17280, 1080, 1080, 17280, 1080, 34560, 1080, 1080, 17280, 1080, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 1080, 17280, 34560, 17280, 17280, 34560, 17280, 1080, 17280, 1080, 34560, 17280, 17280, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 17280, 17280, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 17280, 34560, 34560, 1080, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 34560, 1080, 1080, 17280, 1080, 17280, 17280, 1080, 34560, 34560, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5661360 . Total input tokens: 1260518946 . Total output tokens: 1132323398
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.041396953980438,
    "estimated_duration": 3600.1941246747865,
    "input_throughput": 3656.065074321236,
    "output_throughput": 3219.828597727944,
    "total_throughput": 6875.893672049179,
    "itl": 261.5489482580821,
    "ttft": 2324736.9093059157,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1289,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.8541748301288044,
    "arrivals": 1885868,
    "finished_requests": 53365,
    "scheduler_time": 66.00603296750525
}
#Debug simulation 
Total elapsed time: 5.041462295979727. Arrivals time: 0.2192710333620198 Scheduler time: 4.731621048122179 Scheduler overhead time: 0.022882423596456647 Adapter cache time: 0.03432814159896225 Engine time: 0.02314156445208937 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_16-16-32/adapters_320_slots_192_rate_3.2-1.6-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_16-16-32/adapters_320_slots_192_rate_3.2-1.6-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 1080, 34560, 34560, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 17280, 34560, 17280, 34560, 34560, 1080, 34560, 17280, 17280, 34560, 34560, 17280, 1080, 1080, 17280, 34560, 34560, 17280, 17280, 1080, 1080, 17280, 34560, 34560, 1080, 34560, 17280, 1080, 17280, 34560, 1080, 17280, 34560, 34560, 17280, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 1080, 34560, 1080, 34560, 17280, 34560, 34560, 1080, 34560, 1080, 34560, 17280, 1080, 1080, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 17280, 1080, 34560, 17280, 34560, 34560, 17280, 1080, 17280, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 34560, 1080, 1080, 17280, 34560, 34560, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 17280, 1080, 17280, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 17280, 17280, 34560, 17280, 17280, 1080, 17280, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 17280, 34560, 17280, 17280, 17280, 1080, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 17280, 1080, 17280, 1080, 1080, 1080, 34560, 34560, 17280, 17280, 1080, 1080, 17280, 1080, 34560, 1080, 1080, 17280, 1080, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 1080, 17280, 34560, 17280, 17280, 34560, 17280, 1080, 17280, 1080, 34560, 17280, 17280, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 17280, 17280, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 17280, 34560, 34560, 1080, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 34560, 1080, 1080, 17280, 1080, 17280, 17280, 1080, 34560, 34560, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5661360 . Total input tokens: 1260518946 . Total output tokens: 1132323398
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.7479627610300668,
    "estimated_duration": 3600.057380015028,
    "input_throughput": 2982.2610771707155,
    "output_throughput": 2641.972889876632,
    "total_throughput": 5624.2339670473475,
    "itl": 128.37728512365135,
    "ttft": 2427368.878448324,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5833,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.592349534070514,
    "arrivals": 1885868,
    "finished_requests": 43516,
    "scheduler_time": 76.52180772042215
}
#Debug simulation 
Total elapsed time: 3.7480544010177255. Arrivals time: 0.3233847289229743 Scheduler time: 3.130893304653 Scheduler overhead time: 0.0400268281227909 Adapter cache time: 0.194196451746393 Engine time: 0.04092527547618374 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-8/adapters_320_slots_192_rate_3.2-1.6-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-8/adapters_320_slots_192_rate_3.2-1.6-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 540, 34560, 34560, 17280, 17280, 17280, 17280, 540, 17280, 540, 17280, 540, 17280, 17280, 34560, 17280, 34560, 34560, 540, 34560, 17280, 17280, 34560, 34560, 17280, 540, 540, 17280, 34560, 34560, 17280, 17280, 540, 540, 17280, 34560, 34560, 540, 34560, 17280, 540, 17280, 34560, 540, 17280, 34560, 34560, 17280, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 17280, 17280, 17280, 540, 17280, 540, 34560, 540, 34560, 17280, 34560, 34560, 540, 34560, 540, 34560, 17280, 540, 540, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 540, 17280, 17280, 540, 34560, 17280, 34560, 34560, 17280, 540, 17280, 17280, 17280, 540, 34560, 17280, 34560, 540, 34560, 540, 540, 17280, 34560, 34560, 17280, 540, 17280, 540, 17280, 34560, 34560, 17280, 540, 17280, 540, 34560, 540, 540, 540, 540, 34560, 17280, 17280, 34560, 17280, 17280, 540, 17280, 34560, 17280, 540, 540, 17280, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 17280, 34560, 17280, 17280, 17280, 540, 34560, 540, 34560, 17280, 540, 17280, 540, 540, 17280, 540, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 540, 540, 34560, 17280, 34560, 17280, 34560, 17280, 540, 17280, 540, 540, 540, 34560, 34560, 17280, 17280, 540, 540, 17280, 540, 34560, 540, 540, 17280, 540, 34560, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 540, 17280, 34560, 17280, 17280, 34560, 17280, 540, 17280, 540, 34560, 17280, 17280, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 17280, 540, 17280, 540, 17280, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 17280, 17280, 34560, 540, 34560, 540, 540, 540, 34560, 17280, 34560, 34560, 540, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 34560, 540, 540, 17280, 540, 17280, 17280, 540, 34560, 34560, 34560, 540, 17280, 17280, 17280, 17280, 540, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 17280, 34560, 17280, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5604120 . Total input tokens: 1247723528 . Total output tokens: 1120869396
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.914861495955847,
    "estimated_duration": 3600.2263681854934,
    "input_throughput": 3695.0620987492835,
    "output_throughput": 3224.591404193021,
    "total_throughput": 6919.653502942305,
    "itl": 263.58886761311203,
    "ttft": 2322503.856145649,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1097,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3573550550943114,
    "arrivals": 1866718,
    "finished_requests": 53554,
    "scheduler_time": 65.96150993204252
}
#Debug simulation 
Total elapsed time: 4.914955738990102. Arrivals time: 0.35168583964696154 Scheduler time: 4.478324126568623 Scheduler overhead time: 0.022580670658499002 Adapter cache time: 0.029488777683582157 Engine time: 0.022670181118883193 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-16/adapters_320_slots_192_rate_3.2-1.6-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-16/adapters_320_slots_192_rate_3.2-1.6-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 540, 34560, 34560, 17280, 17280, 17280, 17280, 540, 17280, 540, 17280, 540, 17280, 17280, 34560, 17280, 34560, 34560, 540, 34560, 17280, 17280, 34560, 34560, 17280, 540, 540, 17280, 34560, 34560, 17280, 17280, 540, 540, 17280, 34560, 34560, 540, 34560, 17280, 540, 17280, 34560, 540, 17280, 34560, 34560, 17280, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 17280, 17280, 17280, 540, 17280, 540, 34560, 540, 34560, 17280, 34560, 34560, 540, 34560, 540, 34560, 17280, 540, 540, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 540, 17280, 17280, 540, 34560, 17280, 34560, 34560, 17280, 540, 17280, 17280, 17280, 540, 34560, 17280, 34560, 540, 34560, 540, 540, 17280, 34560, 34560, 17280, 540, 17280, 540, 17280, 34560, 34560, 17280, 540, 17280, 540, 34560, 540, 540, 540, 540, 34560, 17280, 17280, 34560, 17280, 17280, 540, 17280, 34560, 17280, 540, 540, 17280, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 17280, 34560, 17280, 17280, 17280, 540, 34560, 540, 34560, 17280, 540, 17280, 540, 540, 17280, 540, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 540, 540, 34560, 17280, 34560, 17280, 34560, 17280, 540, 17280, 540, 540, 540, 34560, 34560, 17280, 17280, 540, 540, 17280, 540, 34560, 540, 540, 17280, 540, 34560, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 540, 17280, 34560, 17280, 17280, 34560, 17280, 540, 17280, 540, 34560, 17280, 17280, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 17280, 540, 17280, 540, 17280, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 17280, 17280, 34560, 540, 34560, 540, 540, 540, 34560, 17280, 34560, 34560, 540, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 34560, 540, 540, 17280, 540, 17280, 17280, 540, 34560, 34560, 34560, 540, 17280, 17280, 17280, 17280, 540, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 17280, 34560, 17280, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5604120 . Total input tokens: 1247723528 . Total output tokens: 1120869396
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.175256822025403,
    "estimated_duration": 3600.15004455313,
    "input_throughput": 3685.2377917062126,
    "output_throughput": 3217.306461302703,
    "total_throughput": 6902.544253008916,
    "itl": 260.77119177813114,
    "ttft": 2323730.143648698,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1143,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7269341431325342,
    "arrivals": 1866718,
    "finished_requests": 53414,
    "scheduler_time": 66.03551199211401
}
#Debug simulation 
Total elapsed time: 5.175322848022915. Arrivals time: 0.21891833242261782 Scheduler time: 4.8699310311931185 Scheduler overhead time: 0.022828746063169092 Adapter cache time: 0.03045928559731692 Engine time: 0.022964863281231374 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-32/adapters_320_slots_192_rate_3.2-1.6-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-32/adapters_320_slots_192_rate_3.2-1.6-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 540, 34560, 34560, 17280, 17280, 17280, 17280, 540, 17280, 540, 17280, 540, 17280, 17280, 34560, 17280, 34560, 34560, 540, 34560, 17280, 17280, 34560, 34560, 17280, 540, 540, 17280, 34560, 34560, 17280, 17280, 540, 540, 17280, 34560, 34560, 540, 34560, 17280, 540, 17280, 34560, 540, 17280, 34560, 34560, 17280, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 17280, 17280, 17280, 540, 17280, 540, 34560, 540, 34560, 17280, 34560, 34560, 540, 34560, 540, 34560, 17280, 540, 540, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 540, 17280, 17280, 540, 34560, 17280, 34560, 34560, 17280, 540, 17280, 17280, 17280, 540, 34560, 17280, 34560, 540, 34560, 540, 540, 17280, 34560, 34560, 17280, 540, 17280, 540, 17280, 34560, 34560, 17280, 540, 17280, 540, 34560, 540, 540, 540, 540, 34560, 17280, 17280, 34560, 17280, 17280, 540, 17280, 34560, 17280, 540, 540, 17280, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 17280, 34560, 17280, 17280, 17280, 540, 34560, 540, 34560, 17280, 540, 17280, 540, 540, 17280, 540, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 540, 540, 34560, 17280, 34560, 17280, 34560, 17280, 540, 17280, 540, 540, 540, 34560, 34560, 17280, 17280, 540, 540, 17280, 540, 34560, 540, 540, 17280, 540, 34560, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 540, 17280, 34560, 17280, 17280, 34560, 17280, 540, 17280, 540, 34560, 17280, 17280, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 17280, 540, 17280, 540, 17280, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 17280, 17280, 34560, 540, 34560, 540, 540, 540, 34560, 17280, 34560, 34560, 540, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 34560, 540, 540, 17280, 540, 17280, 17280, 540, 34560, 34560, 34560, 540, 17280, 17280, 17280, 17280, 540, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 17280, 34560, 17280, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5604120 . Total input tokens: 1247723528 . Total output tokens: 1120869396
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.6416997460182756,
    "estimated_duration": 3600.1292017859837,
    "input_throughput": 3040.4244921459626,
    "output_throughput": 2667.170943541825,
    "total_throughput": 5707.595435687788,
    "itl": 126.48257725775284,
    "ttft": 2421309.4545543725,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4847,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.840233524831467,
    "arrivals": 1866718,
    "finished_requests": 44058,
    "scheduler_time": 77.48123491127805
}
#Debug simulation 
Total elapsed time: 3.6417617140104994. Arrivals time: 0.18891034106491134 Scheduler time: 3.1651991382823326 Scheduler overhead time: 0.0405142258387059 Adapter cache time: 0.18675386486575007 Engine time: 0.04150070733157918 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-16-16/adapters_320_slots_192_rate_3.2-1.6-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-16-16/adapters_320_slots_192_rate_3.2-1.6-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 540, 34560, 34560, 17280, 17280, 17280, 17280, 540, 17280, 540, 17280, 540, 17280, 17280, 34560, 17280, 34560, 34560, 540, 34560, 17280, 17280, 34560, 34560, 17280, 540, 540, 17280, 34560, 34560, 17280, 17280, 540, 540, 17280, 34560, 34560, 540, 34560, 17280, 540, 17280, 34560, 540, 17280, 34560, 34560, 17280, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 17280, 17280, 17280, 540, 17280, 540, 34560, 540, 34560, 17280, 34560, 34560, 540, 34560, 540, 34560, 17280, 540, 540, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 540, 17280, 17280, 540, 34560, 17280, 34560, 34560, 17280, 540, 17280, 17280, 17280, 540, 34560, 17280, 34560, 540, 34560, 540, 540, 17280, 34560, 34560, 17280, 540, 17280, 540, 17280, 34560, 34560, 17280, 540, 17280, 540, 34560, 540, 540, 540, 540, 34560, 17280, 17280, 34560, 17280, 17280, 540, 17280, 34560, 17280, 540, 540, 17280, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 17280, 34560, 17280, 17280, 17280, 540, 34560, 540, 34560, 17280, 540, 17280, 540, 540, 17280, 540, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 540, 540, 34560, 17280, 34560, 17280, 34560, 17280, 540, 17280, 540, 540, 540, 34560, 34560, 17280, 17280, 540, 540, 17280, 540, 34560, 540, 540, 17280, 540, 34560, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 540, 17280, 34560, 17280, 17280, 34560, 17280, 540, 17280, 540, 34560, 17280, 17280, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 17280, 540, 17280, 540, 17280, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 17280, 17280, 34560, 540, 34560, 540, 540, 540, 34560, 17280, 34560, 34560, 540, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 34560, 540, 540, 17280, 540, 17280, 17280, 540, 34560, 34560, 34560, 540, 17280, 17280, 17280, 17280, 540, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 17280, 34560, 17280, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5604120 . Total input tokens: 1247723528 . Total output tokens: 1120869396
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.866519703005906,
    "estimated_duration": 3600.0633726813044,
    "input_throughput": 3683.883206234336,
    "output_throughput": 3216.4456014494353,
    "total_throughput": 6900.328807683771,
    "itl": 260.4140496188694,
    "ttft": 2323584.1195719754,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1129,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5236782882199202,
    "arrivals": 1866718,
    "finished_requests": 53390,
    "scheduler_time": 66.04826686649474
}
#Debug simulation 
Total elapsed time: 4.866628319956362. Arrivals time: 0.35464210010832176 Scheduler time: 4.425473511044402 Scheduler overhead time: 0.022940416063647717 Adapter cache time: 0.030151011131238192 Engine time: 0.023025103204417974 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-16-32/adapters_320_slots_192_rate_3.2-1.6-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-16-32/adapters_320_slots_192_rate_3.2-1.6-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 540, 34560, 34560, 17280, 17280, 17280, 17280, 540, 17280, 540, 17280, 540, 17280, 17280, 34560, 17280, 34560, 34560, 540, 34560, 17280, 17280, 34560, 34560, 17280, 540, 540, 17280, 34560, 34560, 17280, 17280, 540, 540, 17280, 34560, 34560, 540, 34560, 17280, 540, 17280, 34560, 540, 17280, 34560, 34560, 17280, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 17280, 17280, 17280, 540, 17280, 540, 34560, 540, 34560, 17280, 34560, 34560, 540, 34560, 540, 34560, 17280, 540, 540, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 540, 17280, 17280, 540, 34560, 17280, 34560, 34560, 17280, 540, 17280, 17280, 17280, 540, 34560, 17280, 34560, 540, 34560, 540, 540, 17280, 34560, 34560, 17280, 540, 17280, 540, 17280, 34560, 34560, 17280, 540, 17280, 540, 34560, 540, 540, 540, 540, 34560, 17280, 17280, 34560, 17280, 17280, 540, 17280, 34560, 17280, 540, 540, 17280, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 17280, 34560, 17280, 17280, 17280, 540, 34560, 540, 34560, 17280, 540, 17280, 540, 540, 17280, 540, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 540, 540, 34560, 17280, 34560, 17280, 34560, 17280, 540, 17280, 540, 540, 540, 34560, 34560, 17280, 17280, 540, 540, 17280, 540, 34560, 540, 540, 17280, 540, 34560, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 540, 17280, 34560, 17280, 17280, 34560, 17280, 540, 17280, 540, 34560, 17280, 17280, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 17280, 540, 17280, 540, 17280, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 17280, 17280, 34560, 540, 34560, 540, 540, 540, 34560, 17280, 34560, 34560, 540, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 34560, 540, 540, 17280, 540, 17280, 17280, 540, 34560, 34560, 34560, 540, 17280, 17280, 17280, 17280, 540, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 17280, 34560, 17280, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5604120 . Total input tokens: 1247723528 . Total output tokens: 1120869396
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 3.771021069958806,
    "estimated_duration": 3600.055040075421,
    "input_throughput": 3040.306294808953,
    "output_throughput": 2667.098389639855,
    "total_throughput": 5707.404684448808,
    "itl": 126.49131013072338,
    "ttft": 2421278.524633887,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4845,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.044446831884443,
    "arrivals": 1866718,
    "finished_requests": 44056,
    "scheduler_time": 77.47537533457896
}
#Debug simulation 
Total elapsed time: 3.771108392975293. Arrivals time: 0.324687872431241 Scheduler time: 3.161279468680732 Scheduler overhead time: 0.04053687787381932 Adapter cache time: 0.18449690740089864 Engine time: 0.041162241250276566 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_16-16-16/adapters_320_slots_192_rate_3.2-1.6-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_16-16-16/adapters_320_slots_192_rate_3.2-1.6-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 540, 34560, 34560, 17280, 17280, 17280, 17280, 540, 17280, 540, 17280, 540, 17280, 17280, 34560, 17280, 34560, 34560, 540, 34560, 17280, 17280, 34560, 34560, 17280, 540, 540, 17280, 34560, 34560, 17280, 17280, 540, 540, 17280, 34560, 34560, 540, 34560, 17280, 540, 17280, 34560, 540, 17280, 34560, 34560, 17280, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 17280, 17280, 17280, 540, 17280, 540, 34560, 540, 34560, 17280, 34560, 34560, 540, 34560, 540, 34560, 17280, 540, 540, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 540, 17280, 17280, 540, 34560, 17280, 34560, 34560, 17280, 540, 17280, 17280, 17280, 540, 34560, 17280, 34560, 540, 34560, 540, 540, 17280, 34560, 34560, 17280, 540, 17280, 540, 17280, 34560, 34560, 17280, 540, 17280, 540, 34560, 540, 540, 540, 540, 34560, 17280, 17280, 34560, 17280, 17280, 540, 17280, 34560, 17280, 540, 540, 17280, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 17280, 34560, 17280, 17280, 17280, 540, 34560, 540, 34560, 17280, 540, 17280, 540, 540, 17280, 540, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 540, 540, 34560, 17280, 34560, 17280, 34560, 17280, 540, 17280, 540, 540, 540, 34560, 34560, 17280, 17280, 540, 540, 17280, 540, 34560, 540, 540, 17280, 540, 34560, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 540, 17280, 34560, 17280, 17280, 34560, 17280, 540, 17280, 540, 34560, 17280, 17280, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 17280, 540, 17280, 540, 17280, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 17280, 17280, 34560, 540, 34560, 540, 540, 540, 34560, 17280, 34560, 34560, 540, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 34560, 540, 540, 17280, 540, 17280, 17280, 540, 34560, 34560, 34560, 540, 17280, 17280, 17280, 17280, 540, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 17280, 34560, 17280, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5604120 . Total input tokens: 1247723528 . Total output tokens: 1120869396
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.169331199955195,
    "estimated_duration": 3600.210462752365,
    "input_throughput": 3684.350994819153,
    "output_throughput": 3216.6911128707993,
    "total_throughput": 6901.042107689953,
    "itl": 260.4046762964794,
    "ttft": 2323574.9181742375,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1129,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3757667829444733,
    "arrivals": 1866718,
    "finished_requests": 53399,
    "scheduler_time": 66.05344761785409
}
#Debug simulation 
Total elapsed time: 5.169394162949175. Arrivals time: 0.6538453084067442 Scheduler time: 4.429052937368397 Scheduler overhead time: 0.02288923045853153 Adapter cache time: 0.03024696552893147 Engine time: 0.023091454873792827 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_16-16-32/adapters_320_slots_192_rate_3.2-1.6-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_16-16-32/adapters_320_slots_192_rate_3.2-1.6-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 540, 34560, 34560, 17280, 17280, 17280, 17280, 540, 17280, 540, 17280, 540, 17280, 17280, 34560, 17280, 34560, 34560, 540, 34560, 17280, 17280, 34560, 34560, 17280, 540, 540, 17280, 34560, 34560, 17280, 17280, 540, 540, 17280, 34560, 34560, 540, 34560, 17280, 540, 17280, 34560, 540, 17280, 34560, 34560, 17280, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 17280, 17280, 17280, 540, 17280, 540, 34560, 540, 34560, 17280, 34560, 34560, 540, 34560, 540, 34560, 17280, 540, 540, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 540, 17280, 17280, 540, 34560, 17280, 34560, 34560, 17280, 540, 17280, 17280, 17280, 540, 34560, 17280, 34560, 540, 34560, 540, 540, 17280, 34560, 34560, 17280, 540, 17280, 540, 17280, 34560, 34560, 17280, 540, 17280, 540, 34560, 540, 540, 540, 540, 34560, 17280, 17280, 34560, 17280, 17280, 540, 17280, 34560, 17280, 540, 540, 17280, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 17280, 34560, 17280, 17280, 17280, 540, 34560, 540, 34560, 17280, 540, 17280, 540, 540, 17280, 540, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 540, 540, 34560, 17280, 34560, 17280, 34560, 17280, 540, 17280, 540, 540, 540, 34560, 34560, 17280, 17280, 540, 540, 17280, 540, 34560, 540, 540, 17280, 540, 34560, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 540, 17280, 34560, 17280, 17280, 34560, 17280, 540, 17280, 540, 34560, 17280, 17280, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 17280, 540, 17280, 540, 17280, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 17280, 17280, 34560, 540, 34560, 540, 540, 540, 34560, 17280, 34560, 34560, 540, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 34560, 540, 540, 17280, 540, 17280, 17280, 540, 34560, 34560, 34560, 540, 17280, 17280, 17280, 17280, 540, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 17280, 34560, 17280, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5604120 . Total input tokens: 1247723528 . Total output tokens: 1120869396
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.62752569001168,
    "estimated_duration": 3600.112021898895,
    "input_throughput": 3039.9873485679436,
    "output_throughput": 2666.9206240243043,
    "total_throughput": 5706.9079725922475,
    "itl": 126.49919547441277,
    "ttft": 2421328.5765235717,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4845,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.239490954614027,
    "arrivals": 1866718,
    "finished_requests": 44053,
    "scheduler_time": 77.47251265196643
}
#Debug simulation 
Total elapsed time: 3.6276241000159644. Arrivals time: 0.18749194906558841 Scheduler time: 3.1549506541341543 Scheduler overhead time: 0.04049129242775962 Adapter cache time: 0.18447621969971806 Engine time: 0.041194154240656644 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-8/adapters_320_slots_192_rate_3.2-1.6-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-8/adapters_320_slots_192_rate_3.2-1.6-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 270, 34560, 34560, 17280, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 17280, 17280, 34560, 17280, 34560, 34560, 270, 34560, 17280, 17280, 34560, 34560, 17280, 270, 270, 17280, 34560, 34560, 17280, 17280, 270, 270, 17280, 34560, 34560, 270, 34560, 17280, 270, 17280, 34560, 270, 17280, 34560, 34560, 17280, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 17280, 17280, 17280, 270, 17280, 270, 34560, 270, 34560, 17280, 34560, 34560, 270, 34560, 270, 34560, 17280, 270, 270, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 270, 17280, 17280, 270, 34560, 17280, 34560, 34560, 17280, 270, 17280, 17280, 17280, 270, 34560, 17280, 34560, 270, 34560, 270, 270, 17280, 34560, 34560, 17280, 270, 17280, 270, 17280, 34560, 34560, 17280, 270, 17280, 270, 34560, 270, 270, 270, 270, 34560, 17280, 17280, 34560, 17280, 17280, 270, 17280, 34560, 17280, 270, 270, 17280, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 17280, 34560, 17280, 17280, 17280, 270, 34560, 270, 34560, 17280, 270, 17280, 270, 270, 17280, 270, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 270, 270, 34560, 17280, 34560, 17280, 34560, 17280, 270, 17280, 270, 270, 270, 34560, 34560, 17280, 17280, 270, 270, 17280, 270, 34560, 270, 270, 17280, 270, 34560, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 270, 17280, 34560, 17280, 17280, 34560, 17280, 270, 17280, 270, 34560, 17280, 17280, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 17280, 270, 17280, 270, 17280, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 17280, 17280, 34560, 270, 34560, 270, 270, 270, 34560, 17280, 34560, 34560, 270, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 34560, 270, 270, 17280, 270, 17280, 17280, 270, 34560, 34560, 34560, 270, 17280, 17280, 17280, 17280, 270, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 17280, 34560, 17280, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5575500 . Total input tokens: 1241274911 . Total output tokens: 1115173761
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.529512275999878,
    "estimated_duration": 3600.1991340140917,
    "input_throughput": 3679.514245432889,
    "output_throughput": 3230.916004090809,
    "total_throughput": 6910.430249523698,
    "itl": 264.23873536599694,
    "ttft": 2323447.666824178,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1007,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.081911158140354,
    "arrivals": 1857211,
    "finished_requests": 53518,
    "scheduler_time": 65.94605037406168
}
#Debug simulation 
Total elapsed time: 4.529602317023091. Arrivals time: 0.21672083297744393 Scheduler time: 4.230622053670231 Scheduler overhead time: 0.022457260929513723 Adapter cache time: 0.02686227485537529 Engine time: 0.022801916813477874 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-16/adapters_320_slots_192_rate_3.2-1.6-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-16/adapters_320_slots_192_rate_3.2-1.6-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 270, 34560, 34560, 17280, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 17280, 17280, 34560, 17280, 34560, 34560, 270, 34560, 17280, 17280, 34560, 34560, 17280, 270, 270, 17280, 34560, 34560, 17280, 17280, 270, 270, 17280, 34560, 34560, 270, 34560, 17280, 270, 17280, 34560, 270, 17280, 34560, 34560, 17280, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 17280, 17280, 17280, 270, 17280, 270, 34560, 270, 34560, 17280, 34560, 34560, 270, 34560, 270, 34560, 17280, 270, 270, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 270, 17280, 17280, 270, 34560, 17280, 34560, 34560, 17280, 270, 17280, 17280, 17280, 270, 34560, 17280, 34560, 270, 34560, 270, 270, 17280, 34560, 34560, 17280, 270, 17280, 270, 17280, 34560, 34560, 17280, 270, 17280, 270, 34560, 270, 270, 270, 270, 34560, 17280, 17280, 34560, 17280, 17280, 270, 17280, 34560, 17280, 270, 270, 17280, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 17280, 34560, 17280, 17280, 17280, 270, 34560, 270, 34560, 17280, 270, 17280, 270, 270, 17280, 270, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 270, 270, 34560, 17280, 34560, 17280, 34560, 17280, 270, 17280, 270, 270, 270, 34560, 34560, 17280, 17280, 270, 270, 17280, 270, 34560, 270, 270, 17280, 270, 34560, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 270, 17280, 34560, 17280, 17280, 34560, 17280, 270, 17280, 270, 34560, 17280, 17280, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 17280, 270, 17280, 270, 17280, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 17280, 17280, 34560, 270, 34560, 270, 270, 270, 34560, 17280, 34560, 34560, 270, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 34560, 270, 270, 17280, 270, 17280, 17280, 270, 34560, 34560, 34560, 270, 17280, 17280, 17280, 17280, 270, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 17280, 34560, 17280, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5575500 . Total input tokens: 1241274911 . Total output tokens: 1115173761
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.4712662199744955,
    "estimated_duration": 3600.0124347894616,
    "input_throughput": 3668.660105828883,
    "output_throughput": 3222.9033121877383,
    "total_throughput": 6891.563418016621,
    "itl": 261.31571654810676,
    "ttft": 2324644.219902666,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1041,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.401110651812058,
    "arrivals": 1857211,
    "finished_requests": 53358,
    "scheduler_time": 66.02139056066255
}
#Debug simulation 
Total elapsed time: 4.471349947969429. Arrivals time: 0.21764277602778748 Scheduler time: 4.1706368693266995 Scheduler overhead time: 0.02276447881013155 Adapter cache time: 0.02717845980077982 Engine time: 0.02292965369997546 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-32/adapters_320_slots_192_rate_3.2-1.6-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-32/adapters_320_slots_192_rate_3.2-1.6-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 270, 34560, 34560, 17280, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 17280, 17280, 34560, 17280, 34560, 34560, 270, 34560, 17280, 17280, 34560, 34560, 17280, 270, 270, 17280, 34560, 34560, 17280, 17280, 270, 270, 17280, 34560, 34560, 270, 34560, 17280, 270, 17280, 34560, 270, 17280, 34560, 34560, 17280, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 17280, 17280, 17280, 270, 17280, 270, 34560, 270, 34560, 17280, 34560, 34560, 270, 34560, 270, 34560, 17280, 270, 270, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 270, 17280, 17280, 270, 34560, 17280, 34560, 34560, 17280, 270, 17280, 17280, 17280, 270, 34560, 17280, 34560, 270, 34560, 270, 270, 17280, 34560, 34560, 17280, 270, 17280, 270, 17280, 34560, 34560, 17280, 270, 17280, 270, 34560, 270, 270, 270, 270, 34560, 17280, 17280, 34560, 17280, 17280, 270, 17280, 34560, 17280, 270, 270, 17280, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 17280, 34560, 17280, 17280, 17280, 270, 34560, 270, 34560, 17280, 270, 17280, 270, 270, 17280, 270, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 270, 270, 34560, 17280, 34560, 17280, 34560, 17280, 270, 17280, 270, 270, 270, 34560, 34560, 17280, 17280, 270, 270, 17280, 270, 34560, 270, 270, 17280, 270, 34560, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 270, 17280, 34560, 17280, 17280, 34560, 17280, 270, 17280, 270, 34560, 17280, 17280, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 17280, 270, 17280, 270, 17280, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 17280, 17280, 34560, 270, 34560, 270, 270, 270, 34560, 17280, 34560, 34560, 270, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 34560, 270, 270, 17280, 270, 17280, 17280, 270, 34560, 34560, 34560, 270, 17280, 17280, 17280, 17280, 270, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 17280, 34560, 17280, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5575500 . Total input tokens: 1241274911 . Total output tokens: 1115173761
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.11625775101129,
    "estimated_duration": 3600.088691658707,
    "input_throughput": 3037.341003663424,
    "output_throughput": 2689.3234665113764,
    "total_throughput": 5726.664470174801,
    "itl": 125.56176155231513,
    "ttft": 2416722.0445293556,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4240,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.871745733096132,
    "arrivals": 1857211,
    "finished_requests": 44201,
    "scheduler_time": 78.09744191013522
}
#Debug simulation 
Total elapsed time: 4.116349357995205. Arrivals time: 0.18981597834499553 Scheduler time: 3.6415021119755693 Scheduler overhead time: 0.04080994363175705 Adapter cache time: 0.18316049868008122 Engine time: 0.04201229504542425 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-16-16/adapters_320_slots_192_rate_3.2-1.6-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-16-16/adapters_320_slots_192_rate_3.2-1.6-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 270, 34560, 34560, 17280, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 17280, 17280, 34560, 17280, 34560, 34560, 270, 34560, 17280, 17280, 34560, 34560, 17280, 270, 270, 17280, 34560, 34560, 17280, 17280, 270, 270, 17280, 34560, 34560, 270, 34560, 17280, 270, 17280, 34560, 270, 17280, 34560, 34560, 17280, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 17280, 17280, 17280, 270, 17280, 270, 34560, 270, 34560, 17280, 34560, 34560, 270, 34560, 270, 34560, 17280, 270, 270, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 270, 17280, 17280, 270, 34560, 17280, 34560, 34560, 17280, 270, 17280, 17280, 17280, 270, 34560, 17280, 34560, 270, 34560, 270, 270, 17280, 34560, 34560, 17280, 270, 17280, 270, 17280, 34560, 34560, 17280, 270, 17280, 270, 34560, 270, 270, 270, 270, 34560, 17280, 17280, 34560, 17280, 17280, 270, 17280, 34560, 17280, 270, 270, 17280, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 17280, 34560, 17280, 17280, 17280, 270, 34560, 270, 34560, 17280, 270, 17280, 270, 270, 17280, 270, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 270, 270, 34560, 17280, 34560, 17280, 34560, 17280, 270, 17280, 270, 270, 270, 34560, 34560, 17280, 17280, 270, 270, 17280, 270, 34560, 270, 270, 17280, 270, 34560, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 270, 17280, 34560, 17280, 17280, 34560, 17280, 270, 17280, 270, 34560, 17280, 17280, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 17280, 270, 17280, 270, 17280, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 17280, 17280, 34560, 270, 34560, 270, 270, 270, 34560, 17280, 34560, 34560, 270, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 34560, 270, 270, 17280, 270, 17280, 17280, 270, 34560, 34560, 34560, 270, 17280, 17280, 17280, 17280, 270, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 17280, 34560, 17280, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5575500 . Total input tokens: 1241274911 . Total output tokens: 1115173761
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.479485684016254,
    "estimated_duration": 3600.15358321779,
    "input_throughput": 3668.8604235029266,
    "output_throughput": 3222.981945572755,
    "total_throughput": 6891.842369075682,
    "itl": 261.3037840288052,
    "ttft": 2324659.2199423634,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1041,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2531991465366095,
    "arrivals": 1857211,
    "finished_requests": 53361,
    "scheduler_time": 66.02648013824708
}
#Debug simulation 
Total elapsed time: 4.479571012023371. Arrivals time: 0.2172791578923352 Scheduler time: 4.17837416875409 Scheduler overhead time: 0.022732780023943633 Adapter cache time: 0.028109411126933992 Engine time: 0.02288145391503349 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-16-32/adapters_320_slots_192_rate_3.2-1.6-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-16-32/adapters_320_slots_192_rate_3.2-1.6-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 270, 34560, 34560, 17280, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 17280, 17280, 34560, 17280, 34560, 34560, 270, 34560, 17280, 17280, 34560, 34560, 17280, 270, 270, 17280, 34560, 34560, 17280, 17280, 270, 270, 17280, 34560, 34560, 270, 34560, 17280, 270, 17280, 34560, 270, 17280, 34560, 34560, 17280, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 17280, 17280, 17280, 270, 17280, 270, 34560, 270, 34560, 17280, 34560, 34560, 270, 34560, 270, 34560, 17280, 270, 270, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 270, 17280, 17280, 270, 34560, 17280, 34560, 34560, 17280, 270, 17280, 17280, 17280, 270, 34560, 17280, 34560, 270, 34560, 270, 270, 17280, 34560, 34560, 17280, 270, 17280, 270, 17280, 34560, 34560, 17280, 270, 17280, 270, 34560, 270, 270, 270, 270, 34560, 17280, 17280, 34560, 17280, 17280, 270, 17280, 34560, 17280, 270, 270, 17280, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 17280, 34560, 17280, 17280, 17280, 270, 34560, 270, 34560, 17280, 270, 17280, 270, 270, 17280, 270, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 270, 270, 34560, 17280, 34560, 17280, 34560, 17280, 270, 17280, 270, 270, 270, 34560, 34560, 17280, 17280, 270, 270, 17280, 270, 34560, 270, 270, 17280, 270, 34560, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 270, 17280, 34560, 17280, 17280, 34560, 17280, 270, 17280, 270, 34560, 17280, 17280, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 17280, 270, 17280, 270, 17280, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 17280, 17280, 34560, 270, 34560, 270, 270, 270, 34560, 17280, 34560, 34560, 270, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 34560, 270, 270, 17280, 270, 17280, 17280, 270, 34560, 34560, 34560, 270, 17280, 17280, 17280, 17280, 270, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 17280, 34560, 17280, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5575500 . Total input tokens: 1241274911 . Total output tokens: 1115173761
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 3.668698471970856,
    "estimated_duration": 3600.0009424796463,
    "input_throughput": 3037.2086493035185,
    "output_throughput": 2689.080962665535,
    "total_throughput": 5726.289611969053,
    "itl": 125.56809823597138,
    "ttft": 2416770.3059543353,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4240,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.058993121067916,
    "arrivals": 1857211,
    "finished_requests": 44198,
    "scheduler_time": 78.09156257368939
}
#Debug simulation 
Total elapsed time: 3.6687861459795386. Arrivals time: 0.18920757912565023 Scheduler time: 3.193293960590381 Scheduler overhead time: 0.0409139737021178 Adapter cache time: 0.18461275566369295 Engine time: 0.041718968539498746 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_16-16-16/adapters_320_slots_192_rate_3.2-1.6-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_16-16-16/adapters_320_slots_192_rate_3.2-1.6-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 270, 34560, 34560, 17280, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 17280, 17280, 34560, 17280, 34560, 34560, 270, 34560, 17280, 17280, 34560, 34560, 17280, 270, 270, 17280, 34560, 34560, 17280, 17280, 270, 270, 17280, 34560, 34560, 270, 34560, 17280, 270, 17280, 34560, 270, 17280, 34560, 34560, 17280, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 17280, 17280, 17280, 270, 17280, 270, 34560, 270, 34560, 17280, 34560, 34560, 270, 34560, 270, 34560, 17280, 270, 270, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 270, 17280, 17280, 270, 34560, 17280, 34560, 34560, 17280, 270, 17280, 17280, 17280, 270, 34560, 17280, 34560, 270, 34560, 270, 270, 17280, 34560, 34560, 17280, 270, 17280, 270, 17280, 34560, 34560, 17280, 270, 17280, 270, 34560, 270, 270, 270, 270, 34560, 17280, 17280, 34560, 17280, 17280, 270, 17280, 34560, 17280, 270, 270, 17280, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 17280, 34560, 17280, 17280, 17280, 270, 34560, 270, 34560, 17280, 270, 17280, 270, 270, 17280, 270, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 270, 270, 34560, 17280, 34560, 17280, 34560, 17280, 270, 17280, 270, 270, 270, 34560, 34560, 17280, 17280, 270, 270, 17280, 270, 34560, 270, 270, 17280, 270, 34560, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 270, 17280, 34560, 17280, 17280, 34560, 17280, 270, 17280, 270, 34560, 17280, 17280, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 17280, 270, 17280, 270, 17280, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 17280, 17280, 34560, 270, 34560, 270, 270, 270, 34560, 17280, 34560, 34560, 270, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 34560, 270, 270, 17280, 270, 17280, 17280, 270, 34560, 34560, 34560, 270, 17280, 17280, 17280, 17280, 270, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 17280, 34560, 17280, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5575500 . Total input tokens: 1241274911 . Total output tokens: 1115173761
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.644582087988965,
    "estimated_duration": 3600.0127735207334,
    "input_throughput": 3669.0039260839667,
    "output_throughput": 3223.108008211953,
    "total_throughput": 6892.111934295919,
    "itl": 261.2947747646388,
    "ttft": 2324604.5254220325,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1041,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.112642356993091,
    "arrivals": 1857211,
    "finished_requests": 53361,
    "scheduler_time": 66.0262272307005
}
#Debug simulation 
Total elapsed time: 4.644668466993608. Arrivals time: 0.3594564839731902 Scheduler time: 4.201120096957311 Scheduler overhead time: 0.022775228775572032 Adapter cache time: 0.027984619257040322 Engine time: 0.02308888838160783 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_16-16-32/adapters_320_slots_192_rate_3.2-1.6-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_16-16-32/adapters_320_slots_192_rate_3.2-1.6-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 270, 34560, 34560, 17280, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 17280, 17280, 34560, 17280, 34560, 34560, 270, 34560, 17280, 17280, 34560, 34560, 17280, 270, 270, 17280, 34560, 34560, 17280, 17280, 270, 270, 17280, 34560, 34560, 270, 34560, 17280, 270, 17280, 34560, 270, 17280, 34560, 34560, 17280, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 17280, 17280, 17280, 270, 17280, 270, 34560, 270, 34560, 17280, 34560, 34560, 270, 34560, 270, 34560, 17280, 270, 270, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 270, 17280, 17280, 270, 34560, 17280, 34560, 34560, 17280, 270, 17280, 17280, 17280, 270, 34560, 17280, 34560, 270, 34560, 270, 270, 17280, 34560, 34560, 17280, 270, 17280, 270, 17280, 34560, 34560, 17280, 270, 17280, 270, 34560, 270, 270, 270, 270, 34560, 17280, 17280, 34560, 17280, 17280, 270, 17280, 34560, 17280, 270, 270, 17280, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 17280, 34560, 17280, 17280, 17280, 270, 34560, 270, 34560, 17280, 270, 17280, 270, 270, 17280, 270, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 270, 270, 34560, 17280, 34560, 17280, 34560, 17280, 270, 17280, 270, 270, 270, 34560, 34560, 17280, 17280, 270, 270, 17280, 270, 34560, 270, 270, 17280, 270, 34560, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 270, 17280, 34560, 17280, 17280, 34560, 17280, 270, 17280, 270, 34560, 17280, 17280, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 17280, 270, 17280, 270, 17280, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 17280, 17280, 34560, 270, 34560, 270, 270, 270, 34560, 17280, 34560, 34560, 270, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 34560, 270, 270, 17280, 270, 17280, 17280, 270, 34560, 34560, 34560, 270, 17280, 17280, 17280, 17280, 270, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 17280, 34560, 17280, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5575500 . Total input tokens: 1241274911 . Total output tokens: 1115173761
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.6637847350211814,
    "estimated_duration": 3600.0367959873665,
    "input_throughput": 3037.038402548141,
    "output_throughput": 2688.9791823211053,
    "total_throughput": 5726.017584869246,
    "itl": 125.57386332348264,
    "ttft": 2416862.986560687,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4240,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.232407592534075,
    "arrivals": 1857211,
    "finished_requests": 44196,
    "scheduler_time": 78.08867476019448
}
#Debug simulation 
Total elapsed time: 3.663883032044396. Arrivals time: 0.18925574159948155 Scheduler time: 3.1893444789457135 Scheduler overhead time: 0.04102632199646905 Adapter cache time: 0.1832540620234795 Engine time: 0.04183072521118447 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-8/adapters_320_slots_192_rate_3.2-1.6-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-8/adapters_320_slots_192_rate_3.2-1.6-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 135, 34560, 34560, 17280, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 17280, 17280, 34560, 17280, 34560, 34560, 135, 34560, 17280, 17280, 34560, 34560, 17280, 135, 135, 17280, 34560, 34560, 17280, 17280, 135, 135, 17280, 34560, 34560, 135, 34560, 17280, 135, 17280, 34560, 135, 17280, 34560, 34560, 17280, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 17280, 17280, 17280, 135, 17280, 135, 34560, 135, 34560, 17280, 34560, 34560, 135, 34560, 135, 34560, 17280, 135, 135, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 135, 17280, 17280, 135, 34560, 17280, 34560, 34560, 17280, 135, 17280, 17280, 17280, 135, 34560, 17280, 34560, 135, 34560, 135, 135, 17280, 34560, 34560, 17280, 135, 17280, 135, 17280, 34560, 34560, 17280, 135, 17280, 135, 34560, 135, 135, 135, 135, 34560, 17280, 17280, 34560, 17280, 17280, 135, 17280, 34560, 17280, 135, 135, 17280, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 17280, 34560, 17280, 17280, 17280, 135, 34560, 135, 34560, 17280, 135, 17280, 135, 135, 17280, 135, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 135, 135, 34560, 17280, 34560, 17280, 34560, 17280, 135, 17280, 135, 135, 135, 34560, 34560, 17280, 17280, 135, 135, 17280, 135, 34560, 135, 135, 17280, 135, 34560, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 135, 17280, 34560, 17280, 17280, 34560, 17280, 135, 17280, 135, 34560, 17280, 17280, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 17280, 135, 17280, 135, 17280, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 17280, 17280, 34560, 135, 34560, 135, 135, 135, 34560, 17280, 34560, 34560, 135, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 34560, 135, 135, 17280, 135, 17280, 17280, 135, 34560, 34560, 34560, 135, 17280, 17280, 17280, 17280, 135, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 17280, 34560, 17280, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 5561190 . Total input tokens: 1238053653 . Total output tokens: 1112294447
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.415526065044105,
    "estimated_duration": 3600.2467214650915,
    "input_throughput": 3717.5788315289146,
    "output_throughput": 3227.3968699766133,
    "total_throughput": 6944.9757015055275,
    "itl": 262.6242168510628,
    "ttft": 2322498.3350214213,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 838,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5646887294157006,
    "arrivals": 1852456,
    "finished_requests": 53690,
    "scheduler_time": 65.98895072364108
}
#Debug simulation 
Total elapsed time: 4.415613251039758. Arrivals time: 0.218370022601448 Scheduler time: 4.118580657464918 Scheduler overhead time: 0.022649812803138047 Adapter cache time: 0.02296594192739576 Engine time: 0.022834371717181057 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-16/adapters_320_slots_192_rate_3.2-1.6-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-16/adapters_320_slots_192_rate_3.2-1.6-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 135, 34560, 34560, 17280, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 17280, 17280, 34560, 17280, 34560, 34560, 135, 34560, 17280, 17280, 34560, 34560, 17280, 135, 135, 17280, 34560, 34560, 17280, 17280, 135, 135, 17280, 34560, 34560, 135, 34560, 17280, 135, 17280, 34560, 135, 17280, 34560, 34560, 17280, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 17280, 17280, 17280, 135, 17280, 135, 34560, 135, 34560, 17280, 34560, 34560, 135, 34560, 135, 34560, 17280, 135, 135, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 135, 17280, 17280, 135, 34560, 17280, 34560, 34560, 17280, 135, 17280, 17280, 17280, 135, 34560, 17280, 34560, 135, 34560, 135, 135, 17280, 34560, 34560, 17280, 135, 17280, 135, 17280, 34560, 34560, 17280, 135, 17280, 135, 34560, 135, 135, 135, 135, 34560, 17280, 17280, 34560, 17280, 17280, 135, 17280, 34560, 17280, 135, 135, 17280, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 17280, 34560, 17280, 17280, 17280, 135, 34560, 135, 34560, 17280, 135, 17280, 135, 135, 17280, 135, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 135, 135, 34560, 17280, 34560, 17280, 34560, 17280, 135, 17280, 135, 135, 135, 34560, 34560, 17280, 17280, 135, 135, 17280, 135, 34560, 135, 135, 17280, 135, 34560, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 135, 17280, 34560, 17280, 17280, 34560, 17280, 135, 17280, 135, 34560, 17280, 17280, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 17280, 135, 17280, 135, 17280, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 17280, 17280, 34560, 135, 34560, 135, 135, 135, 34560, 17280, 34560, 34560, 135, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 34560, 135, 135, 17280, 135, 17280, 17280, 135, 34560, 34560, 34560, 135, 17280, 17280, 17280, 17280, 135, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 17280, 34560, 17280, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 5561190 . Total input tokens: 1238053653 . Total output tokens: 1112294447
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.85852710402105,
    "estimated_duration": 3600.1308311066873,
    "input_throughput": 3710.4976531904645,
    "output_throughput": 3221.14515944833,
    "total_throughput": 6931.642812638795,
    "itl": 260.73897258992235,
    "ttft": 2323477.1880844855,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 854,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.789671045904986,
    "arrivals": 1852456,
    "finished_requests": 53588,
    "scheduler_time": 66.0372100078166
}
#Debug simulation 
Total elapsed time: 4.858592350035906. Arrivals time: 0.6562655260204338 Scheduler time: 4.122534659749363 Scheduler overhead time: 0.022666490403935313 Adapter cache time: 0.02402384183369577 Engine time: 0.022924465883988887 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-32/adapters_320_slots_192_rate_3.2-1.6-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-32/adapters_320_slots_192_rate_3.2-1.6-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 135, 34560, 34560, 17280, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 17280, 17280, 34560, 17280, 34560, 34560, 135, 34560, 17280, 17280, 34560, 34560, 17280, 135, 135, 17280, 34560, 34560, 17280, 17280, 135, 135, 17280, 34560, 34560, 135, 34560, 17280, 135, 17280, 34560, 135, 17280, 34560, 34560, 17280, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 17280, 17280, 17280, 135, 17280, 135, 34560, 135, 34560, 17280, 34560, 34560, 135, 34560, 135, 34560, 17280, 135, 135, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 135, 17280, 17280, 135, 34560, 17280, 34560, 34560, 17280, 135, 17280, 17280, 17280, 135, 34560, 17280, 34560, 135, 34560, 135, 135, 17280, 34560, 34560, 17280, 135, 17280, 135, 17280, 34560, 34560, 17280, 135, 17280, 135, 34560, 135, 135, 135, 135, 34560, 17280, 17280, 34560, 17280, 17280, 135, 17280, 34560, 17280, 135, 135, 17280, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 17280, 34560, 17280, 17280, 17280, 135, 34560, 135, 34560, 17280, 135, 17280, 135, 135, 17280, 135, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 135, 135, 34560, 17280, 34560, 17280, 34560, 17280, 135, 17280, 135, 135, 135, 34560, 34560, 17280, 17280, 135, 135, 17280, 135, 34560, 135, 135, 17280, 135, 34560, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 135, 17280, 34560, 17280, 17280, 34560, 17280, 135, 17280, 135, 34560, 17280, 17280, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 17280, 135, 17280, 135, 17280, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 17280, 17280, 34560, 135, 34560, 135, 135, 135, 34560, 17280, 34560, 34560, 135, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 34560, 135, 135, 17280, 135, 17280, 17280, 135, 34560, 34560, 34560, 135, 17280, 17280, 17280, 17280, 135, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 17280, 34560, 17280, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 5561190 . Total input tokens: 1238053653 . Total output tokens: 1112294447
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.657927035004832,
    "estimated_duration": 3600.079037277518,
    "input_throughput": 3069.8795458551076,
    "output_throughput": 2689.974831031323,
    "total_throughput": 5759.85437688643,
    "itl": 125.53893689672726,
    "ttft": 2416681.528364852,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4064,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.315851566045515,
    "arrivals": 1852456,
    "finished_requests": 44413,
    "scheduler_time": 78.07245080353702
}
#Debug simulation 
Total elapsed time: 3.6580091929645278. Arrivals time: 0.19272707402706146 Scheduler time: 3.180136095324997 Scheduler overhead time: 0.04084652743767947 Adapter cache time: 0.18354575132252648 Engine time: 0.04162953334162012 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-16/adapters_320_slots_192_rate_3.2-1.6-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-16/adapters_320_slots_192_rate_3.2-1.6-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 135, 34560, 34560, 17280, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 17280, 17280, 34560, 17280, 34560, 34560, 135, 34560, 17280, 17280, 34560, 34560, 17280, 135, 135, 17280, 34560, 34560, 17280, 17280, 135, 135, 17280, 34560, 34560, 135, 34560, 17280, 135, 17280, 34560, 135, 17280, 34560, 34560, 17280, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 17280, 17280, 17280, 135, 17280, 135, 34560, 135, 34560, 17280, 34560, 34560, 135, 34560, 135, 34560, 17280, 135, 135, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 135, 17280, 17280, 135, 34560, 17280, 34560, 34560, 17280, 135, 17280, 17280, 17280, 135, 34560, 17280, 34560, 135, 34560, 135, 135, 17280, 34560, 34560, 17280, 135, 17280, 135, 17280, 34560, 34560, 17280, 135, 17280, 135, 34560, 135, 135, 135, 135, 34560, 17280, 17280, 34560, 17280, 17280, 135, 17280, 34560, 17280, 135, 135, 17280, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 17280, 34560, 17280, 17280, 17280, 135, 34560, 135, 34560, 17280, 135, 17280, 135, 135, 17280, 135, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 135, 135, 34560, 17280, 34560, 17280, 34560, 17280, 135, 17280, 135, 135, 135, 34560, 34560, 17280, 17280, 135, 135, 17280, 135, 34560, 135, 135, 17280, 135, 34560, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 135, 17280, 34560, 17280, 17280, 34560, 17280, 135, 17280, 135, 34560, 17280, 17280, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 17280, 135, 17280, 135, 17280, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 17280, 17280, 34560, 135, 34560, 135, 135, 135, 34560, 17280, 34560, 34560, 135, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 34560, 135, 135, 17280, 135, 17280, 17280, 135, 34560, 34560, 34560, 135, 17280, 17280, 17280, 17280, 135, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 17280, 34560, 17280, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 5561190 . Total input tokens: 1238053653 . Total output tokens: 1112294447
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.828755481983535,
    "estimated_duration": 3600.014973242829,
    "input_throughput": 3710.617066674893,
    "output_throughput": 3221.248824294206,
    "total_throughput": 6931.865890969099,
    "itl": 260.73164467641834,
    "ttft": 2323428.4580924204,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 854,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.674038570786337,
    "arrivals": 1852456,
    "finished_requests": 53588,
    "scheduler_time": 66.03698461905131
}
#Debug simulation 
Total elapsed time: 4.828822813986335. Arrivals time: 0.6537861537071876 Scheduler time: 4.095868546690326 Scheduler overhead time: 0.022705017065163702 Adapter cache time: 0.023409064509905875 Engine time: 0.02284667536150664 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-32/adapters_320_slots_192_rate_3.2-1.6-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-32/adapters_320_slots_192_rate_3.2-1.6-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 135, 34560, 34560, 17280, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 17280, 17280, 34560, 17280, 34560, 34560, 135, 34560, 17280, 17280, 34560, 34560, 17280, 135, 135, 17280, 34560, 34560, 17280, 17280, 135, 135, 17280, 34560, 34560, 135, 34560, 17280, 135, 17280, 34560, 135, 17280, 34560, 34560, 17280, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 17280, 17280, 17280, 135, 17280, 135, 34560, 135, 34560, 17280, 34560, 34560, 135, 34560, 135, 34560, 17280, 135, 135, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 135, 17280, 17280, 135, 34560, 17280, 34560, 34560, 17280, 135, 17280, 17280, 17280, 135, 34560, 17280, 34560, 135, 34560, 135, 135, 17280, 34560, 34560, 17280, 135, 17280, 135, 17280, 34560, 34560, 17280, 135, 17280, 135, 34560, 135, 135, 135, 135, 34560, 17280, 17280, 34560, 17280, 17280, 135, 17280, 34560, 17280, 135, 135, 17280, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 17280, 34560, 17280, 17280, 17280, 135, 34560, 135, 34560, 17280, 135, 17280, 135, 135, 17280, 135, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 135, 135, 34560, 17280, 34560, 17280, 34560, 17280, 135, 17280, 135, 135, 135, 34560, 34560, 17280, 17280, 135, 135, 17280, 135, 34560, 135, 135, 17280, 135, 34560, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 135, 17280, 34560, 17280, 17280, 34560, 17280, 135, 17280, 135, 34560, 17280, 17280, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 17280, 135, 17280, 135, 17280, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 17280, 17280, 34560, 135, 34560, 135, 135, 135, 34560, 17280, 34560, 34560, 135, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 34560, 135, 135, 17280, 135, 17280, 17280, 135, 34560, 34560, 34560, 135, 17280, 17280, 17280, 17280, 135, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 17280, 34560, 17280, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 5561190 . Total input tokens: 1238053653 . Total output tokens: 1112294447
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 3.668471053999383,
    "estimated_duration": 3600.001820973759,
    "input_throughput": 3069.7370583581583,
    "output_throughput": 2689.7616950040374,
    "total_throughput": 5759.498753362196,
    "itl": 125.54497828366398,
    "ttft": 2416745.858212512,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4064,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.49643400333729,
    "arrivals": 1852456,
    "finished_requests": 44410,
    "scheduler_time": 78.06663751010493
}
#Debug simulation 
Total elapsed time: 3.6685352660133503. Arrivals time: 0.1917860111570917 Scheduler time: 3.1902856244705617 Scheduler overhead time: 0.041175330232363194 Adapter cache time: 0.18462797306710854 Engine time: 0.041623921191785485 
