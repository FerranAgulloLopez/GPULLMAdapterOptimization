INFO 06-01 00:47:01 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:47:02 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-32/adapters_96_slots_16_rate_0.4-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-32/adapters_96_slots_16_rate_0.4-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 4320, 270, 270, 270, 270, 4320, 270, 4320, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 4320, 4320, 270, 135, 4320, 270, 135, 135, 270, 4320, 135, 270, 135, 135, 270, 270, 270, 135, 135, 4320, 270, 270, 135, 4320, 4320, 270, 4320, 4320, 270, 4320, 135, 4320, 270, 270, 270, 4320, 4320, 135, 135, 270, 135, 4320, 135, 135, 4320, 135, 270, 270, 135, 270, 4320, 4320, 4320, 270, 4320, 4320, 135, 135, 4320, 270, 4320, 135, 270, 4320, 135, 4320, 270, 135, 4320, 135, 135, 4320, 135, 135, 270]
Prompts retrieved: 151200 . Total input tokens: 33809263 . Total output tokens: 30204504
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.498461835086346,
    "estimated_duration": 3599.921123121118,
    "input_throughput": 3459.880251265424,
    "output_throughput": 3070.3353273521507,
    "total_throughput": 6530.2155786175745,
    "itl": 30.370206495991038,
    "ttft": 85426.38931946388,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1801,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.028181959427753,
    "arrivals": 50642,
    "finished_requests": 50006,
    "scheduler_time": 34.434544568388105
}
#Debug simulation 
Total elapsed time: 7.498581244144589. Arrivals time: 0.16795278945937753 Scheduler time: 6.982692622113973 Scheduler overhead time: 0.13469768082723022 Adapter cache time: 0.02889974182471633 Engine time: 0.12552443332970142 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_96_slots_16_rate_0.4-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_96_slots_16_rate_0.4-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 4320, 270, 270, 270, 270, 4320, 270, 4320, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 4320, 4320, 270, 66, 4320, 270, 66, 66, 270, 4320, 66, 270, 66, 66, 270, 270, 270, 66, 66, 4320, 270, 270, 66, 4320, 4320, 270, 4320, 4320, 270, 4320, 66, 4320, 270, 270, 270, 4320, 4320, 66, 66, 270, 66, 4320, 66, 66, 4320, 66, 270, 270, 66, 270, 4320, 4320, 4320, 270, 4320, 4320, 66, 66, 4320, 270, 4320, 66, 270, 4320, 66, 4320, 270, 66, 4320, 66, 66, 4320, 66, 66, 270]
Prompts retrieved: 148992 . Total input tokens: 33330154 . Total output tokens: 29754013
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.965916169341654,
    "estimated_duration": 3599.910963970288,
    "input_throughput": 3415.8742044103215,
    "output_throughput": 3026.893195153461,
    "total_throughput": 6442.767399563782,
    "itl": 29.841792051212,
    "ttft": 76080.93007597783,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1837,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.622115985604628,
    "arrivals": 49929,
    "finished_requests": 49350,
    "scheduler_time": 31.740364877806076
}
#Debug simulation 
Total elapsed time: 6.966033302247524. Arrivals time: 0.16042311303317547 Scheduler time: 6.452123846393079 Scheduler overhead time: 0.13843062706291676 Adapter cache time: 0.028740850742906332 Engine time: 0.12671926338225603 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_96_slots_16_rate_0.4-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_96_slots_16_rate_0.4-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 4320, 270, 270, 270, 270, 4320, 270, 4320, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 4320, 4320, 270, 66, 4320, 270, 66, 66, 270, 4320, 66, 270, 66, 66, 270, 270, 270, 66, 66, 4320, 270, 270, 66, 4320, 4320, 270, 4320, 4320, 270, 4320, 66, 4320, 270, 270, 270, 4320, 4320, 66, 66, 270, 66, 4320, 66, 66, 4320, 66, 270, 270, 66, 270, 4320, 4320, 4320, 270, 4320, 4320, 66, 66, 4320, 270, 4320, 66, 270, 4320, 66, 4320, 270, 66, 4320, 66, 66, 4320, 66, 66, 270]
Prompts retrieved: 148992 . Total input tokens: 33330154 . Total output tokens: 29754013
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.892196524888277,
    "estimated_duration": 3599.9252661834853,
    "input_throughput": 3414.5400504471145,
    "output_throughput": 3023.8502732976367,
    "total_throughput": 6438.390323744751,
    "itl": 29.87616280239448,
    "ttft": 77877.85362614042,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1840,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.977706088602834,
    "arrivals": 49929,
    "finished_requests": 49325,
    "scheduler_time": 31.74896339757321
}
#Debug simulation 
Total elapsed time: 6.892320587299764. Arrivals time: 0.1358726704493165 Scheduler time: 6.403603201266378 Scheduler overhead time: 0.1373970820568502 Adapter cache time: 0.028977111913263798 Engine time: 0.12733394280076027 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-32/adapters_96_slots_16_rate_0.4-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-32/adapters_96_slots_16_rate_0.4-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 4320, 270, 270, 270, 270, 4320, 270, 4320, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 4320, 4320, 270, 66, 4320, 270, 66, 66, 270, 4320, 66, 270, 66, 66, 270, 270, 270, 66, 66, 4320, 270, 270, 66, 4320, 4320, 270, 4320, 4320, 270, 4320, 66, 4320, 270, 270, 270, 4320, 4320, 66, 66, 270, 66, 4320, 66, 66, 4320, 66, 270, 270, 66, 270, 4320, 4320, 4320, 270, 4320, 4320, 66, 66, 4320, 270, 4320, 66, 270, 4320, 66, 4320, 270, 66, 4320, 66, 66, 4320, 66, 66, 270]
Prompts retrieved: 148992 . Total input tokens: 33330154 . Total output tokens: 29754013
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.888669196981937,
    "estimated_duration": 3599.9243338134243,
    "input_throughput": 3417.581276484029,
    "output_throughput": 3025.954434009104,
    "total_throughput": 6443.535710493133,
    "itl": 29.903401498172325,
    "ttft": 74575.41938042759,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1846,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.013252610918079,
    "arrivals": 49929,
    "finished_requests": 49368,
    "scheduler_time": 31.689772963634226
}
#Debug simulation 
Total elapsed time: 6.888861847110093. Arrivals time: 0.16149566695094109 Scheduler time: 6.37831747205928 Scheduler overhead time: 0.1355427117086947 Adapter cache time: 0.02885459177196026 Engine time: 0.12589013949036598 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_96_slots_16_rate_0.4-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_96_slots_16_rate_0.4-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 4320, 270, 270, 270, 270, 4320, 270, 4320, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 4320, 4320, 270, 66, 4320, 270, 66, 66, 270, 4320, 66, 270, 66, 66, 270, 270, 270, 66, 66, 4320, 270, 270, 66, 4320, 4320, 270, 4320, 4320, 270, 4320, 66, 4320, 270, 270, 270, 4320, 4320, 66, 66, 270, 66, 4320, 66, 66, 4320, 66, 270, 270, 66, 270, 4320, 4320, 4320, 270, 4320, 4320, 66, 66, 4320, 270, 4320, 66, 270, 4320, 66, 4320, 270, 66, 4320, 66, 66, 4320, 66, 66, 270]
Prompts retrieved: 148992 . Total input tokens: 33330154 . Total output tokens: 29754013
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.892644085921347,
    "estimated_duration": 3599.9160634208206,
    "input_throughput": 3413.0745782790514,
    "output_throughput": 3023.270489717456,
    "total_throughput": 6436.345067996507,
    "itl": 29.938391375385,
    "ttft": 79317.47710791403,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1800,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.621118792111367,
    "arrivals": 49929,
    "finished_requests": 49310,
    "scheduler_time": 31.856909372246697
}
#Debug simulation 
Total elapsed time: 6.892768932040781. Arrivals time: 0.1546808104030788 Scheduler time: 6.392433216329664 Scheduler overhead time: 0.13456466048955917 Adapter cache time: 0.028339361306279898 Engine time: 0.12429444026201963 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-32/adapters_96_slots_16_rate_0.4-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-32/adapters_96_slots_16_rate_0.4-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 4320, 270, 270, 270, 270, 4320, 270, 4320, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 4320, 4320, 270, 66, 4320, 270, 66, 66, 270, 4320, 66, 270, 66, 66, 270, 270, 270, 66, 66, 4320, 270, 270, 66, 4320, 4320, 270, 4320, 4320, 270, 4320, 66, 4320, 270, 270, 270, 4320, 4320, 66, 66, 270, 66, 4320, 66, 66, 4320, 66, 270, 270, 66, 270, 4320, 4320, 4320, 270, 4320, 4320, 66, 66, 4320, 270, 4320, 66, 270, 4320, 66, 4320, 270, 66, 4320, 66, 66, 4320, 66, 66, 270]
Prompts retrieved: 148992 . Total input tokens: 33330154 . Total output tokens: 29754013
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.909564849920571,
    "estimated_duration": 3599.9090194912555,
    "input_throughput": 3416.372450917679,
    "output_throughput": 3026.3206489422955,
    "total_throughput": 6442.693099859975,
    "itl": 30.019062414100375,
    "ttft": 75107.39518869099,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1823,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.007517602965139,
    "arrivals": 49929,
    "finished_requests": 49367,
    "scheduler_time": 31.822665953778927
}
#Debug simulation 
Total elapsed time: 6.909734736662358. Arrivals time: 0.16030339803546667 Scheduler time: 6.400826747529209 Scheduler overhead time: 0.13578834384679794 Adapter cache time: 0.028616410680115223 Engine time: 0.12522159237414598 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_96_slots_16_rate_0.4-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_96_slots_16_rate_0.4-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 4320, 270, 270, 270, 270, 4320, 270, 4320, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 4320, 4320, 270, 66, 4320, 270, 66, 66, 270, 4320, 66, 270, 66, 66, 270, 270, 270, 66, 66, 4320, 270, 270, 66, 4320, 4320, 270, 4320, 4320, 270, 4320, 66, 4320, 270, 270, 270, 4320, 4320, 66, 66, 270, 66, 4320, 66, 66, 4320, 66, 270, 270, 66, 270, 4320, 4320, 4320, 270, 4320, 4320, 66, 66, 4320, 270, 4320, 66, 270, 4320, 66, 4320, 270, 66, 4320, 66, 66, 4320, 66, 66, 270]
Prompts retrieved: 148992 . Total input tokens: 33330154 . Total output tokens: 29754013
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.8908301601186395,
    "estimated_duration": 3599.901814779066,
    "input_throughput": 3413.9264436450335,
    "output_throughput": 3025.186119046518,
    "total_throughput": 6439.112562691552,
    "itl": 29.975116903620716,
    "ttft": 78504.20745205962,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1827,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.4628218887861175,
    "arrivals": 49929,
    "finished_requests": 49317,
    "scheduler_time": 31.724706954997103
}
#Debug simulation 
Total elapsed time: 6.890954670030624. Arrivals time: 0.15698316833004355 Scheduler time: 6.3843913921155035 Scheduler overhead time: 0.13602602016180754 Adapter cache time: 0.02860696194693446 Engine time: 0.12556703854352236 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-32/adapters_96_slots_16_rate_0.4-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-32/adapters_96_slots_16_rate_0.4-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 4320, 270, 270, 270, 270, 4320, 270, 4320, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 4320, 4320, 270, 66, 4320, 270, 66, 66, 270, 4320, 66, 270, 66, 66, 270, 270, 270, 66, 66, 4320, 270, 270, 66, 4320, 4320, 270, 4320, 4320, 270, 4320, 66, 4320, 270, 270, 270, 4320, 4320, 66, 66, 270, 66, 4320, 66, 66, 4320, 66, 270, 270, 66, 270, 4320, 4320, 4320, 270, 4320, 4320, 66, 66, 4320, 270, 4320, 66, 270, 4320, 66, 4320, 270, 66, 4320, 66, 66, 4320, 66, 66, 270]
Prompts retrieved: 148992 . Total input tokens: 33330154 . Total output tokens: 29754013
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.8827115460298955,
    "estimated_duration": 3599.917759041107,
    "input_throughput": 3415.741087172872,
    "output_throughput": 3026.4438604569777,
    "total_throughput": 6442.18494762985,
    "itl": 29.88100212873601,
    "ttft": 76438.62670517308,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1858,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.199347527399499,
    "arrivals": 49929,
    "finished_requests": 49340,
    "scheduler_time": 31.625443718552432
}
#Debug simulation 
Total elapsed time: 6.882830273825675. Arrivals time: 0.1654025441966951 Scheduler time: 6.365885199978948 Scheduler overhead time: 0.13737584790214896 Adapter cache time: 0.028983343858271837 Engine time: 0.12595661357045174 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_96_slots_16_rate_0.4-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_96_slots_16_rate_0.4-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 4320, 270, 270, 270, 270, 4320, 270, 4320, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 270, 33, 4320, 270, 33, 33, 270, 4320, 33, 270, 33, 33, 270, 270, 270, 33, 33, 4320, 270, 270, 33, 4320, 4320, 270, 4320, 4320, 270, 4320, 33, 4320, 270, 270, 270, 4320, 4320, 33, 33, 270, 33, 4320, 33, 33, 4320, 33, 270, 270, 33, 270, 4320, 4320, 4320, 270, 4320, 4320, 33, 33, 4320, 270, 4320, 33, 270, 4320, 33, 4320, 270, 33, 4320, 33, 33, 4320, 33, 33, 270]
Prompts retrieved: 147936 . Total input tokens: 33097985 . Total output tokens: 29538647
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.562163959257305,
    "estimated_duration": 3600.00742005857,
    "input_throughput": 3376.056930405511,
    "output_throughput": 2994.5671611489647,
    "total_throughput": 6370.624091554476,
    "itl": 29.678314752989742,
    "ttft": 77983.40885506976,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1797,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.499696475847314,
    "arrivals": 49606,
    "finished_requests": 48957,
    "scheduler_time": 30.180237042134813
}
#Debug simulation 
Total elapsed time: 6.562291766051203. Arrivals time: 0.15634949877858162 Scheduler time: 6.056564957369119 Scheduler overhead time: 0.13586340611800551 Adapter cache time: 0.028669096529483795 Engine time: 0.12570199510082603 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_96_slots_16_rate_0.4-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_96_slots_16_rate_0.4-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 4320, 270, 270, 270, 270, 4320, 270, 4320, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 270, 33, 4320, 270, 33, 33, 270, 4320, 33, 270, 33, 33, 270, 270, 270, 33, 33, 4320, 270, 270, 33, 4320, 4320, 270, 4320, 4320, 270, 4320, 33, 4320, 270, 270, 270, 4320, 4320, 33, 33, 270, 33, 4320, 33, 33, 4320, 33, 270, 270, 33, 270, 4320, 4320, 4320, 270, 4320, 4320, 33, 33, 4320, 270, 4320, 33, 270, 4320, 33, 4320, 270, 33, 4320, 33, 33, 4320, 33, 33, 270]
Prompts retrieved: 147936 . Total input tokens: 33097985 . Total output tokens: 29538647
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.015797573141754,
    "estimated_duration": 3599.98968927795,
    "input_throughput": 3376.1668918662267,
    "output_throughput": 2994.5021876332594,
    "total_throughput": 6370.669079499486,
    "itl": 29.899692946411175,
    "ttft": 82687.48554574518,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1601,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.183407981025417,
    "arrivals": 49606,
    "finished_requests": 48951,
    "scheduler_time": 31.439074067917186
}
#Debug simulation 
Total elapsed time: 7.015926637221128. Arrivals time: 0.1681773429736495 Scheduler time: 6.497006088960916 Scheduler overhead time: 0.13659805431962013 Adapter cache time: 0.028047210536897182 Engine time: 0.1268072766251862 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-32/adapters_96_slots_16_rate_0.4-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-32/adapters_96_slots_16_rate_0.4-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 4320, 270, 270, 270, 270, 4320, 270, 4320, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 270, 33, 4320, 270, 33, 33, 270, 4320, 33, 270, 33, 33, 270, 270, 270, 33, 33, 4320, 270, 270, 33, 4320, 4320, 270, 4320, 4320, 270, 4320, 33, 4320, 270, 270, 270, 4320, 4320, 33, 33, 270, 33, 4320, 33, 33, 4320, 33, 270, 270, 33, 270, 4320, 4320, 4320, 270, 4320, 4320, 33, 33, 4320, 270, 4320, 33, 270, 4320, 33, 4320, 270, 33, 4320, 33, 33, 4320, 33, 33, 270]
Prompts retrieved: 147936 . Total input tokens: 33097985 . Total output tokens: 29538647
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.034761902876198,
    "estimated_duration": 3600.009688384348,
    "input_throughput": 3375.7203596454733,
    "output_throughput": 2993.123611518903,
    "total_throughput": 6368.843971164376,
    "itl": 29.946193557925,
    "ttft": 83196.19263298927,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1601,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.19980374656611,
    "arrivals": 49606,
    "finished_requests": 48944,
    "scheduler_time": 31.443295005807453
}
#Debug simulation 
Total elapsed time: 7.034891571849585. Arrivals time: 0.15709280408918858 Scheduler time: 6.528721567708999 Scheduler overhead time: 0.1357032279483974 Adapter cache time: 0.02781360177323222 Engine time: 0.12607708387076855 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_96_slots_16_rate_0.4-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_96_slots_16_rate_0.4-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 4320, 270, 270, 270, 270, 4320, 270, 4320, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 270, 33, 4320, 270, 33, 33, 270, 4320, 33, 270, 33, 33, 270, 270, 270, 33, 33, 4320, 270, 270, 33, 4320, 4320, 270, 4320, 4320, 270, 4320, 33, 4320, 270, 270, 270, 4320, 4320, 33, 33, 270, 33, 4320, 33, 33, 4320, 33, 270, 270, 33, 270, 4320, 4320, 4320, 270, 4320, 4320, 33, 33, 4320, 270, 4320, 33, 270, 4320, 33, 4320, 270, 33, 4320, 33, 33, 4320, 33, 33, 270]
Prompts retrieved: 147936 . Total input tokens: 33097985 . Total output tokens: 29538647
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.648894688114524,
    "estimated_duration": 3599.992553448396,
    "input_throughput": 3381.4406055755458,
    "output_throughput": 2997.3414777383305,
    "total_throughput": 6378.782083313877,
    "itl": 29.6723027925247,
    "ttft": 73765.72672356284,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1786,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.5686346097032935,
    "arrivals": 49606,
    "finished_requests": 49021,
    "scheduler_time": 30.335160198347417
}
#Debug simulation 
Total elapsed time: 6.649001912213862. Arrivals time: 0.16814960027113557 Scheduler time: 6.131463840138167 Scheduler overhead time: 0.135799715295434 Adapter cache time: 0.028787994757294655 Engine time: 0.12585158133879304 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-32/adapters_96_slots_16_rate_0.4-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-32/adapters_96_slots_16_rate_0.4-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 4320, 270, 270, 270, 270, 4320, 270, 4320, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 270, 33, 4320, 270, 33, 33, 270, 4320, 33, 270, 33, 33, 270, 270, 270, 33, 33, 4320, 270, 270, 33, 4320, 4320, 270, 4320, 4320, 270, 4320, 33, 4320, 270, 270, 270, 4320, 4320, 33, 33, 270, 33, 4320, 33, 33, 4320, 33, 270, 270, 33, 270, 4320, 4320, 4320, 270, 4320, 4320, 33, 33, 4320, 270, 4320, 33, 270, 4320, 33, 4320, 270, 33, 4320, 33, 33, 4320, 33, 33, 270]
Prompts retrieved: 147936 . Total input tokens: 33097985 . Total output tokens: 29538647
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 7.019646123051643,
    "estimated_duration": 3600.004923222314,
    "input_throughput": 3374.473996309534,
    "output_throughput": 2994.484793746012,
    "total_throughput": 6368.958790055546,
    "itl": 29.893717301143052,
    "ttft": 83915.54657991802,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1600,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.2577508141286,
    "arrivals": 49606,
    "finished_requests": 48935,
    "scheduler_time": 31.4395530695456
}
#Debug simulation 
Total elapsed time: 7.019755526911467. Arrivals time: 0.15792564814910293 Scheduler time: 6.514253618661314 Scheduler overhead time: 0.13532715663313866 Adapter cache time: 0.027714633848518133 Engine time: 0.12545911502093077 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_96_slots_16_rate_0.4-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_96_slots_16_rate_0.4-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 4320, 270, 270, 270, 270, 4320, 270, 4320, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 270, 33, 4320, 270, 33, 33, 270, 4320, 33, 270, 33, 33, 270, 270, 270, 33, 33, 4320, 270, 270, 33, 4320, 4320, 270, 4320, 4320, 270, 4320, 33, 4320, 270, 270, 270, 4320, 4320, 33, 33, 270, 33, 4320, 33, 33, 4320, 33, 270, 270, 33, 270, 4320, 4320, 4320, 270, 4320, 4320, 33, 33, 4320, 270, 4320, 33, 270, 4320, 33, 4320, 270, 33, 4320, 33, 33, 4320, 33, 33, 270]
Prompts retrieved: 147936 . Total input tokens: 33097985 . Total output tokens: 29538647
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.654990798328072,
    "estimated_duration": 3600.0134113733657,
    "input_throughput": 3383.8123940079404,
    "output_throughput": 2999.4657702901827,
    "total_throughput": 6383.278164298123,
    "itl": 29.703577471298722,
    "ttft": 69344.04824549721,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1788,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.346209927284937,
    "arrivals": 49606,
    "finished_requests": 49082,
    "scheduler_time": 30.39671567830803
}
#Debug simulation 
Total elapsed time: 6.6550881010480225. Arrivals time: 0.1685838303528726 Scheduler time: 6.137914082035422 Scheduler overhead time: 0.13539635576307774 Adapter cache time: 0.028604804538190365 Engine time: 0.1257066959515214 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-32/adapters_96_slots_16_rate_0.4-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-32/adapters_96_slots_16_rate_0.4-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 4320, 270, 270, 270, 270, 4320, 270, 4320, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 270, 33, 4320, 270, 33, 33, 270, 4320, 33, 270, 33, 33, 270, 270, 270, 33, 33, 4320, 270, 270, 33, 4320, 4320, 270, 4320, 4320, 270, 4320, 33, 4320, 270, 270, 270, 4320, 4320, 33, 33, 270, 33, 4320, 33, 33, 4320, 33, 270, 270, 33, 270, 4320, 4320, 4320, 270, 4320, 4320, 33, 33, 4320, 270, 4320, 33, 270, 4320, 33, 4320, 270, 33, 4320, 33, 33, 4320, 33, 33, 270]
Prompts retrieved: 147936 . Total input tokens: 33097985 . Total output tokens: 29538647
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.975186181720346,
    "estimated_duration": 3600.0020472004235,
    "input_throughput": 3380.7744663547446,
    "output_throughput": 3000.3569049077983,
    "total_throughput": 6381.131371262543,
    "itl": 29.813209896595765,
    "ttft": 75803.533634426,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1639,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.447624663822262,
    "arrivals": 49606,
    "finished_requests": 49037,
    "scheduler_time": 31.295575944359772
}
#Debug simulation 
Total elapsed time: 6.9753184537403286. Arrivals time: 0.16001809667795897 Scheduler time: 6.465410572942346 Scheduler overhead time: 0.13623292883858085 Adapter cache time: 0.027912890072911978 Engine time: 0.12660559779033065 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_96_slots_16_rate_0.4-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_96_slots_16_rate_0.4-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 4320, 135, 135, 135, 135, 4320, 135, 4320, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 135, 66, 4320, 135, 66, 66, 135, 4320, 66, 135, 66, 66, 135, 135, 135, 66, 66, 4320, 135, 135, 66, 4320, 4320, 135, 4320, 4320, 135, 4320, 66, 4320, 135, 135, 135, 4320, 4320, 66, 66, 135, 66, 4320, 66, 66, 4320, 66, 135, 135, 66, 135, 4320, 4320, 4320, 135, 4320, 4320, 66, 66, 4320, 135, 4320, 66, 135, 4320, 66, 4320, 135, 66, 4320, 66, 66, 4320, 66, 66, 135]
Prompts retrieved: 144672 . Total input tokens: 32354420 . Total output tokens: 28898873
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.462761725764722,
    "estimated_duration": 3599.9355694170536,
    "input_throughput": 3309.8247927613465,
    "output_throughput": 2943.476847202543,
    "total_throughput": 6253.30163996389,
    "itl": 29.417554574845216,
    "ttft": 69736.79902166672,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1763,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.395639892553596,
    "arrivals": 48532,
    "finished_requests": 47994,
    "scheduler_time": 28.796632743159257
}
#Debug simulation 
Total elapsed time: 6.46294632460922. Arrivals time: 0.16231579054147005 Scheduler time: 5.947556846309453 Scheduler overhead time: 0.1360556874424219 Adapter cache time: 0.02865629829466343 Engine time: 0.12895668158307672 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_96_slots_16_rate_0.4-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_96_slots_16_rate_0.4-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 4320, 135, 135, 135, 135, 4320, 135, 4320, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 135, 66, 4320, 135, 66, 66, 135, 4320, 66, 135, 66, 66, 135, 135, 135, 66, 66, 4320, 135, 135, 66, 4320, 4320, 135, 4320, 4320, 135, 4320, 66, 4320, 135, 135, 135, 4320, 4320, 66, 66, 135, 66, 4320, 66, 66, 4320, 66, 135, 135, 66, 135, 4320, 4320, 4320, 135, 4320, 4320, 66, 66, 4320, 135, 4320, 66, 135, 4320, 66, 4320, 135, 66, 4320, 66, 66, 4320, 66, 66, 135]
Prompts retrieved: 144672 . Total input tokens: 32354420 . Total output tokens: 28898873
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.428305994719267,
    "estimated_duration": 3599.927277769074,
    "input_throughput": 3310.9374385436076,
    "output_throughput": 2944.1583627123155,
    "total_throughput": 6255.095801255923,
    "itl": 29.311250643486424,
    "ttft": 68093.3484219713,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1785,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.812027536427909,
    "arrivals": 48532,
    "finished_requests": 48012,
    "scheduler_time": 28.695128229596442
}
#Debug simulation 
Total elapsed time: 6.428393539041281. Arrivals time: 0.15803298726677895 Scheduler time: 5.921381029766053 Scheduler overhead time: 0.1355881793424487 Adapter cache time: 0.02852669171988964 Engine time: 0.1253467076458037 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-32/adapters_96_slots_16_rate_0.4-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-32/adapters_96_slots_16_rate_0.4-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 4320, 135, 135, 135, 135, 4320, 135, 4320, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 135, 66, 4320, 135, 66, 66, 135, 4320, 66, 135, 66, 66, 135, 135, 135, 66, 66, 4320, 135, 135, 66, 4320, 4320, 135, 4320, 4320, 135, 4320, 66, 4320, 135, 135, 135, 4320, 4320, 66, 66, 135, 66, 4320, 66, 66, 4320, 66, 135, 135, 66, 135, 4320, 4320, 4320, 135, 4320, 4320, 66, 66, 4320, 135, 4320, 66, 135, 4320, 66, 4320, 135, 66, 4320, 66, 66, 4320, 66, 66, 135]
Prompts retrieved: 144672 . Total input tokens: 32354420 . Total output tokens: 28898873
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.404145606793463,
    "estimated_duration": 3599.92683447303,
    "input_throughput": 3311.3689661265,
    "output_throughput": 2947.1335079378223,
    "total_throughput": 6258.502474064322,
    "itl": 29.257061501791007,
    "ttft": 65944.12363280474,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1788,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.83301879525179,
    "arrivals": 48532,
    "finished_requests": 48038,
    "scheduler_time": 28.666074121551958
}
#Debug simulation 
Total elapsed time: 6.404267525766045. Arrivals time: 0.15991343092173338 Scheduler time: 5.893069625366479 Scheduler overhead time: 0.13625497184693813 Adapter cache time: 0.028785154223442078 Engine time: 0.1267430023290217 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_96_slots_16_rate_0.4-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_96_slots_16_rate_0.4-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 4320, 135, 135, 135, 135, 4320, 135, 4320, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 135, 66, 4320, 135, 66, 66, 135, 4320, 66, 135, 66, 66, 135, 135, 135, 66, 66, 4320, 135, 135, 66, 4320, 4320, 135, 4320, 4320, 135, 4320, 66, 4320, 135, 135, 135, 4320, 4320, 66, 66, 135, 66, 4320, 66, 66, 4320, 66, 135, 135, 66, 135, 4320, 4320, 4320, 135, 4320, 4320, 66, 66, 4320, 135, 4320, 66, 135, 4320, 66, 4320, 135, 66, 4320, 66, 66, 4320, 66, 66, 135]
Prompts retrieved: 144672 . Total input tokens: 32354420 . Total output tokens: 28898873
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.540399212855846,
    "estimated_duration": 3599.9503343164406,
    "input_throughput": 3310.8753991360772,
    "output_throughput": 2945.6400825633946,
    "total_throughput": 6256.515481699472,
    "itl": 29.366474714689932,
    "ttft": 67994.33705789119,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1757,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.487643485609297,
    "arrivals": 48532,
    "finished_requests": 48023,
    "scheduler_time": 28.902769294760635
}
#Debug simulation 
Total elapsed time: 6.540498445741832. Arrivals time: 0.15923976618796587 Scheduler time: 6.0284651019610465 Scheduler overhead time: 0.13737759226933122 Adapter cache time: 0.028613243252038956 Engine time: 0.1269872304983437 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-32/adapters_96_slots_16_rate_0.4-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-32/adapters_96_slots_16_rate_0.4-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 4320, 135, 135, 135, 135, 4320, 135, 4320, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 135, 66, 4320, 135, 66, 66, 135, 4320, 66, 135, 66, 66, 135, 135, 135, 66, 66, 4320, 135, 135, 66, 4320, 4320, 135, 4320, 4320, 135, 4320, 66, 4320, 135, 135, 135, 4320, 4320, 66, 66, 135, 66, 4320, 66, 66, 4320, 66, 135, 135, 66, 135, 4320, 4320, 4320, 135, 4320, 4320, 66, 66, 4320, 135, 4320, 66, 135, 4320, 66, 4320, 135, 66, 4320, 66, 66, 4320, 66, 66, 135]
Prompts retrieved: 144672 . Total input tokens: 32354420 . Total output tokens: 28898873
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.433417662978172,
    "estimated_duration": 3599.942434591126,
    "input_throughput": 3308.775130831466,
    "output_throughput": 2943.9145743461563,
    "total_throughput": 6252.689705177622,
    "itl": 29.26285327421445,
    "ttft": 69449.531893337,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1792,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.918598780240773,
    "arrivals": 48532,
    "finished_requests": 47991,
    "scheduler_time": 28.631482676419527
}
#Debug simulation 
Total elapsed time: 6.433529938105494. Arrivals time: 0.16270602960139513 Scheduler time: 5.920436043757945 Scheduler overhead time: 0.13569165347144008 Adapter cache time: 0.028819464147090912 Engine time: 0.12655393639579415 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_96_slots_16_rate_0.4-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_96_slots_16_rate_0.4-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 4320, 135, 135, 135, 135, 4320, 135, 4320, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 135, 66, 4320, 135, 66, 66, 135, 4320, 66, 135, 66, 66, 135, 135, 135, 66, 66, 4320, 135, 135, 66, 4320, 4320, 135, 4320, 4320, 135, 4320, 66, 4320, 135, 135, 135, 4320, 4320, 66, 66, 135, 66, 4320, 66, 66, 4320, 66, 135, 135, 66, 135, 4320, 4320, 4320, 135, 4320, 4320, 66, 66, 4320, 135, 4320, 66, 135, 4320, 66, 4320, 135, 66, 4320, 66, 66, 4320, 66, 66, 135]
Prompts retrieved: 144672 . Total input tokens: 32354420 . Total output tokens: 28898873
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.480580403935164,
    "estimated_duration": 3599.929161441944,
    "input_throughput": 3307.802311096126,
    "output_throughput": 2943.247359833048,
    "total_throughput": 6251.049670929174,
    "itl": 29.29042031431651,
    "ttft": 71204.08657803354,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1749,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.229597965783756,
    "arrivals": 48532,
    "finished_requests": 47977,
    "scheduler_time": 28.84565734282915
}
#Debug simulation 
Total elapsed time: 6.480673539917916. Arrivals time: 0.1568851787596941 Scheduler time: 5.973395970650017 Scheduler overhead time: 0.13591471826657653 Adapter cache time: 0.028609899803996086 Engine time: 0.12609762093052268 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-32/adapters_96_slots_16_rate_0.4-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-32/adapters_96_slots_16_rate_0.4-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 4320, 135, 135, 135, 135, 4320, 135, 4320, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 135, 66, 4320, 135, 66, 66, 135, 4320, 66, 135, 66, 66, 135, 135, 135, 66, 66, 4320, 135, 135, 66, 4320, 4320, 135, 4320, 4320, 135, 4320, 66, 4320, 135, 135, 135, 4320, 4320, 66, 66, 135, 66, 4320, 66, 66, 4320, 66, 135, 135, 66, 135, 4320, 4320, 4320, 135, 4320, 4320, 66, 66, 4320, 135, 4320, 66, 135, 4320, 66, 4320, 135, 66, 4320, 66, 66, 4320, 66, 66, 135]
Prompts retrieved: 144672 . Total input tokens: 32354420 . Total output tokens: 28898873
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.498703612014651,
    "estimated_duration": 3599.9391747148316,
    "input_throughput": 3308.708681430302,
    "output_throughput": 2942.559717231646,
    "total_throughput": 6251.268398661948,
    "itl": 29.308805490603394,
    "ttft": 69729.97030861785,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1759,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.878130106292537,
    "arrivals": 48532,
    "finished_requests": 47998,
    "scheduler_time": 28.885597381689838
}
#Debug simulation 
Total elapsed time: 6.498860190156847. Arrivals time: 0.163192140404135 Scheduler time: 5.984537898097187 Scheduler overhead time: 0.13601335743442178 Adapter cache time: 0.02893458493053913 Engine time: 0.1267872890457511 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_96_slots_16_rate_0.4-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_96_slots_16_rate_0.4-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 4320, 135, 135, 135, 135, 4320, 135, 4320, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 135, 33, 4320, 135, 33, 33, 135, 4320, 33, 135, 33, 33, 135, 135, 135, 33, 33, 4320, 135, 135, 33, 4320, 4320, 135, 4320, 4320, 135, 4320, 33, 4320, 135, 135, 135, 4320, 4320, 33, 33, 135, 33, 4320, 33, 33, 4320, 33, 135, 135, 33, 135, 4320, 4320, 4320, 135, 4320, 4320, 33, 33, 4320, 135, 4320, 33, 135, 4320, 33, 4320, 135, 33, 4320, 33, 33, 4320, 33, 33, 135]
Prompts retrieved: 143616 . Total input tokens: 32121383 . Total output tokens: 28686554
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.128386867698282,
    "estimated_duration": 3600.013734603318,
    "input_throughput": 3292.102162300755,
    "output_throughput": 2924.5499534629184,
    "total_throughput": 6216.6521157636735,
    "itl": 29.16046174865616,
    "ttft": 61882.2469181763,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1755,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.371155990602134,
    "arrivals": 48139,
    "finished_requests": 47653,
    "scheduler_time": 27.129343539597205
}
#Debug simulation 
Total elapsed time: 6.128533089067787. Arrivals time: 0.15303944889456034 Scheduler time: 5.624290762003511 Scheduler overhead time: 0.13632510416209698 Adapter cache time: 0.028579247649759054 Engine time: 0.12662427313625813 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_96_slots_16_rate_0.4-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_96_slots_16_rate_0.4-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 4320, 135, 135, 135, 135, 4320, 135, 4320, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 135, 33, 4320, 135, 33, 33, 135, 4320, 33, 135, 33, 33, 135, 135, 135, 33, 33, 4320, 135, 135, 33, 4320, 4320, 135, 4320, 4320, 135, 4320, 33, 4320, 135, 135, 135, 4320, 4320, 33, 33, 135, 33, 4320, 33, 33, 4320, 33, 135, 135, 33, 135, 4320, 4320, 4320, 135, 4320, 4320, 33, 33, 4320, 135, 4320, 33, 135, 4320, 33, 4320, 135, 33, 4320, 33, 33, 4320, 33, 33, 135]
Prompts retrieved: 143616 . Total input tokens: 32121383 . Total output tokens: 28686554
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.113682994153351,
    "estimated_duration": 3600.0169507252676,
    "input_throughput": 3291.0042264143067,
    "output_throughput": 2923.34317978136,
    "total_throughput": 6214.347406195667,
    "itl": 29.11020470902232,
    "ttft": 63538.836781718,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1765,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.725259239512811,
    "arrivals": 48139,
    "finished_requests": 47629,
    "scheduler_time": 27.10599630714584
}
#Debug simulation 
Total elapsed time: 6.113814746960998. Arrivals time: 0.1644649589434266 Scheduler time: 5.597773640882224 Scheduler overhead time: 0.13649239763617516 Adapter cache time: 0.02896510250866413 Engine time: 0.12655301950871944 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-32/adapters_96_slots_16_rate_0.4-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-32/adapters_96_slots_16_rate_0.4-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 4320, 135, 135, 135, 135, 4320, 135, 4320, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 135, 33, 4320, 135, 33, 33, 135, 4320, 33, 135, 33, 33, 135, 135, 135, 33, 33, 4320, 135, 135, 33, 4320, 4320, 135, 4320, 4320, 135, 4320, 33, 4320, 135, 135, 135, 4320, 4320, 33, 33, 135, 33, 4320, 33, 33, 4320, 33, 135, 135, 33, 135, 4320, 4320, 4320, 135, 4320, 4320, 33, 33, 4320, 135, 4320, 33, 135, 4320, 33, 4320, 135, 33, 4320, 33, 33, 4320, 33, 33, 135]
Prompts retrieved: 143616 . Total input tokens: 32121383 . Total output tokens: 28686554
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.122594580054283,
    "estimated_duration": 3600.0129238878735,
    "input_throughput": 3291.4545726694896,
    "output_throughput": 2922.9445067202596,
    "total_throughput": 6214.399079389749,
    "itl": 29.135535225794953,
    "ttft": 64169.54253100339,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1759,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.721823919005632,
    "arrivals": 48139,
    "finished_requests": 47623,
    "scheduler_time": 27.12425055740411
}
#Debug simulation 
Total elapsed time: 6.122696833219379. Arrivals time: 0.15720355371013284 Scheduler time: 5.6108863786794245 Scheduler overhead time: 0.13667777692899108 Adapter cache time: 0.02862131642177701 Engine time: 0.1280741929076612 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_96_slots_16_rate_0.4-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_96_slots_16_rate_0.4-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 4320, 135, 135, 135, 135, 4320, 135, 4320, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 135, 33, 4320, 135, 33, 33, 135, 4320, 33, 135, 33, 33, 135, 135, 135, 33, 33, 4320, 135, 135, 33, 4320, 4320, 135, 4320, 4320, 135, 4320, 33, 4320, 135, 135, 135, 4320, 4320, 33, 33, 135, 33, 4320, 33, 33, 4320, 33, 135, 135, 33, 135, 4320, 4320, 4320, 135, 4320, 4320, 33, 33, 4320, 135, 4320, 33, 135, 4320, 33, 4320, 135, 33, 4320, 33, 33, 4320, 33, 33, 135]
Prompts retrieved: 143616 . Total input tokens: 32121383 . Total output tokens: 28686554
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.13044544076547,
    "estimated_duration": 3600.002428277801,
    "input_throughput": 3291.8694462295834,
    "output_throughput": 2923.094972753713,
    "total_throughput": 6214.964418983297,
    "itl": 29.1529010971134,
    "ttft": 63742.14336138903,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1759,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.491172014288462,
    "arrivals": 48139,
    "finished_requests": 47628,
    "scheduler_time": 27.1394715872982
}
#Debug simulation 
Total elapsed time: 6.130544957704842. Arrivals time: 0.16203718865290284 Scheduler time: 5.618780072778463 Scheduler overhead time: 0.13576475577428937 Adapter cache time: 0.028649020940065384 Engine time: 0.12567263562232256 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-32/adapters_96_slots_16_rate_0.4-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-32/adapters_96_slots_16_rate_0.4-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 4320, 135, 135, 135, 135, 4320, 135, 4320, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 135, 33, 4320, 135, 33, 33, 135, 4320, 33, 135, 33, 33, 135, 135, 135, 33, 33, 4320, 135, 135, 33, 4320, 4320, 135, 4320, 4320, 135, 4320, 33, 4320, 135, 135, 135, 4320, 4320, 33, 33, 135, 33, 4320, 33, 33, 4320, 33, 135, 135, 33, 135, 4320, 4320, 4320, 135, 4320, 4320, 33, 33, 4320, 135, 4320, 33, 135, 4320, 33, 4320, 135, 33, 4320, 33, 33, 4320, 33, 33, 135]
Prompts retrieved: 143616 . Total input tokens: 32121383 . Total output tokens: 28686554
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.091873179655522,
    "estimated_duration": 3600.0125868241944,
    "input_throughput": 3291.1190486842033,
    "output_throughput": 2923.6839444733864,
    "total_throughput": 6214.802993157589,
    "itl": 29.133338949017524,
    "ttft": 63546.81980369025,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1765,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.806105769965704,
    "arrivals": 48139,
    "finished_requests": 47628,
    "scheduler_time": 27.066696978883165
}
#Debug simulation 
Total elapsed time: 6.091998859774321. Arrivals time: 0.1530462116934359 Scheduler time: 5.5888243042863905 Scheduler overhead time: 0.1358644487336278 Adapter cache time: 0.02857058960944414 Engine time: 0.12608094047755003 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_96_slots_16_rate_0.4-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_96_slots_16_rate_0.4-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 4320, 135, 135, 135, 135, 4320, 135, 4320, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 135, 33, 4320, 135, 33, 33, 135, 4320, 33, 135, 33, 33, 135, 135, 135, 33, 33, 4320, 135, 135, 33, 4320, 4320, 135, 4320, 4320, 135, 4320, 33, 4320, 135, 135, 135, 4320, 4320, 33, 33, 135, 33, 4320, 33, 33, 4320, 33, 135, 135, 33, 135, 4320, 4320, 4320, 135, 4320, 4320, 33, 33, 4320, 135, 4320, 33, 135, 4320, 33, 4320, 135, 33, 4320, 33, 33, 4320, 33, 33, 135]
Prompts retrieved: 143616 . Total input tokens: 32121383 . Total output tokens: 28686554
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.113181194290519,
    "estimated_duration": 3600.0243164649833,
    "input_throughput": 3292.041652551231,
    "output_throughput": 2924.4005246991787,
    "total_throughput": 6216.44217725041,
    "itl": 29.104706569678655,
    "ttft": 62625.64631832145,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1760,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.262488519027679,
    "arrivals": 48139,
    "finished_requests": 47642,
    "scheduler_time": 27.107643860789455
}
#Debug simulation 
Total elapsed time: 6.113322113174945. Arrivals time: 0.16199249681085348 Scheduler time: 5.600237694568932 Scheduler overhead time: 0.13658072194084525 Adapter cache time: 0.028753342106938362 Engine time: 0.1262985523790121 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-32/adapters_96_slots_16_rate_0.4-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-32/adapters_96_slots_16_rate_0.4-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 4320, 135, 135, 135, 135, 4320, 135, 4320, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 135, 33, 4320, 135, 33, 33, 135, 4320, 33, 135, 33, 33, 135, 135, 135, 33, 33, 4320, 135, 135, 33, 4320, 4320, 135, 4320, 4320, 135, 4320, 33, 4320, 135, 135, 135, 4320, 4320, 33, 33, 135, 33, 4320, 33, 33, 4320, 33, 135, 135, 33, 135, 4320, 4320, 4320, 135, 4320, 4320, 33, 33, 4320, 135, 4320, 33, 135, 4320, 33, 4320, 135, 33, 4320, 33, 33, 4320, 33, 33, 135]
Prompts retrieved: 143616 . Total input tokens: 32121383 . Total output tokens: 28686554
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.133744345977902,
    "estimated_duration": 3600.0021791998142,
    "input_throughput": 3289.627730901072,
    "output_throughput": 2921.0190651432767,
    "total_throughput": 6210.646796044349,
    "itl": 29.107444131171956,
    "ttft": 64580.81590587264,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1774,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.906651841625435,
    "arrivals": 48139,
    "finished_requests": 47616,
    "scheduler_time": 27.095066448958963
}
#Debug simulation 
Total elapsed time: 6.133841010276228. Arrivals time: 0.15601168060675263 Scheduler time: 5.624006547033787 Scheduler overhead time: 0.13611578848212957 Adapter cache time: 0.028548956383019686 Engine time: 0.12910213926807046 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_96_slots_16_rate_0.4-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_96_slots_16_rate_0.4-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 4320, 66, 66, 66, 66, 4320, 66, 4320, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 66, 33, 4320, 66, 33, 33, 66, 4320, 33, 66, 33, 33, 66, 66, 66, 33, 33, 4320, 66, 66, 33, 4320, 4320, 66, 4320, 4320, 66, 4320, 33, 4320, 66, 66, 66, 4320, 4320, 33, 33, 66, 33, 4320, 33, 33, 4320, 33, 66, 66, 33, 66, 4320, 4320, 4320, 66, 4320, 4320, 33, 33, 4320, 66, 4320, 33, 66, 4320, 33, 4320, 66, 33, 4320, 33, 33, 4320, 33, 33, 66]
Prompts retrieved: 141408 . Total input tokens: 31614290 . Total output tokens: 28253337
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.901146751828492,
    "estimated_duration": 3600.0153806657386,
    "input_throughput": 3253.164434490345,
    "output_throughput": 2905.765918718247,
    "total_throughput": 6158.930353208591,
    "itl": 28.95507264875811,
    "ttft": 44854.30326332528,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1557,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.765179417303427,
    "arrivals": 47462,
    "finished_requests": 47171,
    "scheduler_time": 25.921401592095062
}
#Debug simulation 
Total elapsed time: 5.901295052841306. Arrivals time: 0.16083397855982184 Scheduler time: 5.391686685848981 Scheduler overhead time: 0.13567371293902397 Adapter cache time: 0.027425730600953102 Engine time: 0.12600543769076467 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_96_slots_16_rate_0.4-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_96_slots_16_rate_0.4-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 4320, 66, 66, 66, 66, 4320, 66, 4320, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 66, 33, 4320, 66, 33, 33, 66, 4320, 33, 66, 33, 33, 66, 66, 66, 33, 33, 4320, 66, 66, 33, 4320, 4320, 66, 4320, 4320, 66, 4320, 33, 4320, 66, 66, 66, 4320, 4320, 33, 33, 66, 33, 4320, 33, 33, 4320, 33, 66, 66, 33, 66, 4320, 4320, 4320, 66, 4320, 4320, 33, 33, 4320, 66, 4320, 33, 66, 4320, 33, 4320, 66, 33, 4320, 33, 33, 4320, 33, 33, 66]
Prompts retrieved: 141408 . Total input tokens: 31614290 . Total output tokens: 28253337
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.915614607743919,
    "estimated_duration": 3600.0078408177483,
    "input_throughput": 3253.171247910317,
    "output_throughput": 2905.7720045475817,
    "total_throughput": 6158.943252457899,
    "itl": 28.93141008539049,
    "ttft": 44901.6552721098,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1556,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.050081503710154,
    "arrivals": 47462,
    "finished_requests": 47171,
    "scheduler_time": 25.93514962968577
}
#Debug simulation 
Total elapsed time: 5.915714670903981. Arrivals time: 0.15406030043959618 Scheduler time: 5.411173943430185 Scheduler overhead time: 0.13534414255991578 Adapter cache time: 0.027442265301942825 Engine time: 0.12793772108852863 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-32/adapters_96_slots_16_rate_0.4-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-32/adapters_96_slots_16_rate_0.4-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 4320, 66, 66, 66, 66, 4320, 66, 4320, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 66, 33, 4320, 66, 33, 33, 66, 4320, 33, 66, 33, 33, 66, 66, 66, 33, 33, 4320, 66, 66, 33, 4320, 4320, 66, 4320, 4320, 66, 4320, 33, 4320, 66, 66, 66, 4320, 4320, 33, 33, 66, 33, 4320, 33, 33, 4320, 33, 66, 66, 33, 66, 4320, 4320, 4320, 66, 4320, 4320, 33, 33, 4320, 66, 4320, 33, 66, 4320, 33, 4320, 66, 33, 4320, 33, 33, 4320, 33, 33, 66]
Prompts retrieved: 141408 . Total input tokens: 31614290 . Total output tokens: 28253337
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.9260020279325545,
    "estimated_duration": 3600.014418954259,
    "input_throughput": 3253.16530354397,
    "output_throughput": 2905.766694967483,
    "total_throughput": 6158.931998511453,
    "itl": 28.958116693449927,
    "ttft": 44855.50016130049,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1557,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.067237907200984,
    "arrivals": 47462,
    "finished_requests": 47171,
    "scheduler_time": 25.923671015563762
}
#Debug simulation 
Total elapsed time: 5.926109186839312. Arrivals time: 0.15791594795882702 Scheduler time: 5.418958051130176 Scheduler overhead time: 0.13586413580924273 Adapter cache time: 0.02758343331515789 Engine time: 0.12598149804398417 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_96_slots_16_rate_0.4-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_96_slots_16_rate_0.4-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 4320, 66, 66, 66, 66, 4320, 66, 4320, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 66, 33, 4320, 66, 33, 33, 66, 4320, 33, 66, 33, 33, 66, 66, 66, 33, 33, 4320, 66, 66, 33, 4320, 4320, 66, 4320, 4320, 66, 4320, 33, 4320, 66, 66, 66, 4320, 4320, 33, 33, 66, 33, 4320, 33, 33, 4320, 33, 66, 66, 33, 66, 4320, 4320, 4320, 66, 4320, 4320, 33, 33, 4320, 66, 4320, 33, 66, 4320, 33, 4320, 66, 33, 4320, 33, 33, 4320, 33, 33, 66]
Prompts retrieved: 141408 . Total input tokens: 31614290 . Total output tokens: 28253337
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 5.883412627968937,
    "estimated_duration": 3600.0071302710858,
    "input_throughput": 3253.1718900007045,
    "output_throughput": 2905.7725780705014,
    "total_throughput": 6158.944468071206,
    "itl": 28.929179980917684,
    "ttft": 44901.56362347944,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1556,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.854772941495654,
    "arrivals": 47462,
    "finished_requests": 47171,
    "scheduler_time": 25.93385021172373
}
#Debug simulation 
Total elapsed time: 5.883517398033291. Arrivals time: 0.15296891471371055 Scheduler time: 5.383247093297541 Scheduler overhead time: 0.13467040844261646 Adapter cache time: 0.02748131612315774 Engine time: 0.125768450088799 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-32/adapters_96_slots_16_rate_0.4-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-32/adapters_96_slots_16_rate_0.4-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 4320, 66, 66, 66, 66, 4320, 66, 4320, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 66, 33, 4320, 66, 33, 33, 66, 4320, 33, 66, 33, 33, 66, 66, 66, 33, 33, 4320, 66, 66, 33, 4320, 4320, 66, 4320, 4320, 66, 4320, 33, 4320, 66, 66, 66, 4320, 4320, 33, 33, 66, 33, 4320, 33, 33, 4320, 33, 66, 66, 33, 66, 4320, 4320, 4320, 66, 4320, 4320, 33, 33, 4320, 66, 4320, 33, 66, 4320, 33, 4320, 66, 33, 4320, 33, 33, 4320, 33, 33, 66]
Prompts retrieved: 141408 . Total input tokens: 31614290 . Total output tokens: 28253337
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 5.880588092841208,
    "estimated_duration": 3600.0234285843353,
    "input_throughput": 3253.2935499826935,
    "output_throughput": 2906.126920433432,
    "total_throughput": 6159.420470416126,
    "itl": 28.975850257021484,
    "ttft": 44921.724997908954,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1558,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.130768997315257,
    "arrivals": 47462,
    "finished_requests": 47169,
    "scheduler_time": 25.903053951365184
}
#Debug simulation 
Total elapsed time: 5.880696429871023. Arrivals time: 0.15434848796576262 Scheduler time: 5.379242341965437 Scheduler overhead time: 0.13472327403724194 Adapter cache time: 0.02747095562517643 Engine time: 0.12531140726059675 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_96_slots_16_rate_0.4-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_96_slots_16_rate_0.4-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 4320, 66, 66, 66, 66, 4320, 66, 4320, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 66, 33, 4320, 66, 33, 33, 66, 4320, 33, 66, 33, 33, 66, 66, 66, 33, 33, 4320, 66, 66, 33, 4320, 4320, 66, 4320, 4320, 66, 4320, 33, 4320, 66, 66, 66, 4320, 4320, 33, 33, 66, 33, 4320, 33, 33, 4320, 33, 66, 66, 33, 66, 4320, 4320, 4320, 66, 4320, 4320, 33, 33, 4320, 66, 4320, 33, 66, 4320, 33, 4320, 66, 33, 4320, 33, 33, 4320, 33, 33, 66]
Prompts retrieved: 141408 . Total input tokens: 31614290 . Total output tokens: 28253337
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.925689471885562,
    "estimated_duration": 3600.0124798563047,
    "input_throughput": 3253.167055817391,
    "output_throughput": 2905.7682601193496,
    "total_throughput": 6158.935315936741,
    "itl": 28.953807021408316,
    "ttft": 44853.84942526727,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1557,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.655508309162559,
    "arrivals": 47462,
    "finished_requests": 47171,
    "scheduler_time": 25.92056392439422
}
#Debug simulation 
Total elapsed time: 5.925809264648706. Arrivals time: 0.16397855104878545 Scheduler time: 5.411306986119598 Scheduler overhead time: 0.13651424925774336 Adapter cache time: 0.027673900593072176 Engine time: 0.12635056162253022 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-32/adapters_96_slots_16_rate_0.4-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-32/adapters_96_slots_16_rate_0.4-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 4320, 66, 66, 66, 66, 4320, 66, 4320, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 66, 33, 4320, 66, 33, 33, 66, 4320, 33, 66, 33, 33, 66, 66, 66, 33, 33, 4320, 66, 66, 33, 4320, 4320, 66, 4320, 4320, 66, 4320, 33, 4320, 66, 66, 66, 4320, 4320, 33, 33, 66, 33, 4320, 33, 33, 4320, 33, 66, 66, 33, 66, 4320, 4320, 4320, 66, 4320, 4320, 33, 33, 4320, 66, 4320, 33, 66, 4320, 33, 4320, 66, 33, 4320, 33, 33, 4320, 33, 33, 66]
Prompts retrieved: 141408 . Total input tokens: 31614290 . Total output tokens: 28253337
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.88365817675367,
    "estimated_duration": 3600.0036035671915,
    "input_throughput": 3253.2139657846906,
    "output_throughput": 2906.1504243032437,
    "total_throughput": 6159.364390087934,
    "itl": 28.980266571075187,
    "ttft": 44555.48312467342,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1558,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.192302612736759,
    "arrivals": 47462,
    "finished_requests": 47174,
    "scheduler_time": 25.909174898036873
}
#Debug simulation 
Total elapsed time: 5.8837512107566. Arrivals time: 0.15087268920615315 Scheduler time: 5.382706911768764 Scheduler overhead time: 0.13739630905911326 Adapter cache time: 0.027408153750002384 Engine time: 0.12563069397583604 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_96_slots_16_rate_0.1-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_96_slots_16_rate_0.1-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 1080, 540, 540, 540, 540, 1080, 540, 1080, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 540, 270, 1080, 540, 270, 270, 540, 1080, 270, 540, 270, 270, 540, 540, 540, 270, 270, 1080, 540, 540, 270, 1080, 1080, 540, 1080, 1080, 540, 1080, 270, 1080, 540, 540, 540, 1080, 1080, 270, 270, 540, 270, 1080, 270, 270, 1080, 270, 540, 540, 270, 540, 1080, 1080, 1080, 540, 1080, 1080, 270, 270, 1080, 540, 1080, 270, 540, 1080, 270, 1080, 540, 270, 1080, 270, 270, 1080, 270, 270, 540]
Prompts retrieved: 60480 . Total input tokens: 13412337 . Total output tokens: 12123165
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 2.2215967853553593,
    "estimated_duration": 3599.9654742050366,
    "input_throughput": 1373.18983624187,
    "output_throughput": 1251.7650606066181,
    "total_throughput": 2624.954896848488,
    "itl": 22.702476042595013,
    "ttft": 37178.096175744875,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5499,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.82962210388468,
    "arrivals": 20310,
    "finished_requests": 20194,
    "scheduler_time": 0.016239165432233395
}
#Debug simulation 
Total elapsed time: 2.2216921760700643. Arrivals time: 0.06756206043064594 Scheduler time: 1.7642210791818798 Scheduler overhead time: 0.13902513263747096 Adapter cache time: 0.04710111953318119 Engine time: 0.13689020462334156 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_96_slots_16_rate_0.1-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_96_slots_16_rate_0.1-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 1080, 540, 540, 540, 540, 1080, 540, 1080, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 540, 270, 1080, 540, 270, 270, 540, 1080, 270, 540, 270, 270, 540, 540, 540, 270, 270, 1080, 540, 540, 270, 1080, 1080, 540, 1080, 1080, 540, 1080, 270, 1080, 540, 540, 540, 1080, 1080, 270, 270, 540, 270, 1080, 270, 270, 1080, 270, 540, 540, 270, 540, 1080, 1080, 1080, 540, 1080, 1080, 270, 270, 1080, 540, 1080, 270, 540, 1080, 270, 1080, 540, 270, 1080, 270, 270, 1080, 270, 270, 540]
Prompts retrieved: 60480 . Total input tokens: 13412337 . Total output tokens: 12123165
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 2.225468706805259,
    "estimated_duration": 3599.967177074142,
    "input_throughput": 1373.7900255022644,
    "output_throughput": 1251.9616925127252,
    "total_throughput": 2625.7517180149894,
    "itl": 22.70451811320981,
    "ttft": 35652.158211296824,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5541,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.026145375566937,
    "arrivals": 20310,
    "finished_requests": 20202,
    "scheduler_time": 0.010215371250657686
}
#Debug simulation 
Total elapsed time: 2.2255737050436437. Arrivals time: 0.06822421727702022 Scheduler time: 1.7638340331614017 Scheduler overhead time: 0.13920348463580012 Adapter cache time: 0.04733828455209732 Engine time: 0.14001889107748866 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-32/adapters_96_slots_16_rate_0.1-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-32/adapters_96_slots_16_rate_0.1-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 1080, 540, 540, 540, 540, 1080, 540, 1080, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 540, 270, 1080, 540, 270, 270, 540, 1080, 270, 540, 270, 270, 540, 540, 540, 270, 270, 1080, 540, 540, 270, 1080, 1080, 540, 1080, 1080, 540, 1080, 270, 1080, 540, 540, 540, 1080, 1080, 270, 270, 540, 270, 1080, 270, 270, 1080, 270, 540, 540, 270, 540, 1080, 1080, 1080, 540, 1080, 1080, 270, 270, 1080, 540, 1080, 270, 540, 1080, 270, 1080, 540, 270, 1080, 270, 270, 1080, 270, 270, 540]
Prompts retrieved: 60480 . Total input tokens: 13412337 . Total output tokens: 12123165
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 2.2113298308104277,
    "estimated_duration": 3599.9575872339487,
    "input_throughput": 1372.3545014862252,
    "output_throughput": 1251.2536303131926,
    "total_throughput": 2623.6081317994176,
    "itl": 22.705910099711456,
    "ttft": 38266.77857349566,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5524,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.013673696107077,
    "arrivals": 20310,
    "finished_requests": 20188,
    "scheduler_time": 0.007364435462917554
}
#Debug simulation 
Total elapsed time: 2.211494898889214. Arrivals time: 0.06801948230713606 Scheduler time: 1.7520978040993214 Scheduler overhead time: 0.1398864253424108 Adapter cache time: 0.04716168763116002 Engine time: 0.13742107152938843 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_96_slots_16_rate_0.1-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_96_slots_16_rate_0.1-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 1080, 540, 540, 540, 540, 1080, 540, 1080, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 540, 270, 1080, 540, 270, 270, 540, 1080, 270, 540, 270, 270, 540, 540, 540, 270, 270, 1080, 540, 540, 270, 1080, 1080, 540, 1080, 1080, 540, 1080, 270, 1080, 540, 540, 540, 1080, 1080, 270, 270, 540, 270, 1080, 270, 270, 1080, 270, 540, 540, 270, 540, 1080, 1080, 1080, 540, 1080, 1080, 270, 270, 1080, 540, 1080, 270, 540, 1080, 270, 1080, 540, 270, 1080, 270, 270, 1080, 270, 270, 540]
Prompts retrieved: 60480 . Total input tokens: 13412337 . Total output tokens: 12123165
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 2.234412136953324,
    "estimated_duration": 3599.980751452283,
    "input_throughput": 1372.697895122482,
    "output_throughput": 1251.3844687037938,
    "total_throughput": 2624.082363826276,
    "itl": 22.702964162880903,
    "ttft": 38020.179313755434,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5528,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.267738365960398,
    "arrivals": 20310,
    "finished_requests": 20189,
    "scheduler_time": 0.01309709808434889
}
#Debug simulation 
Total elapsed time: 2.234508933033794. Arrivals time: 0.06760791037231684 Scheduler time: 1.7731908578425646 Scheduler overhead time: 0.13973841816186905 Adapter cache time: 0.047471363097429276 Engine time: 0.1392235471867025 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-32/adapters_96_slots_16_rate_0.1-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-32/adapters_96_slots_16_rate_0.1-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 1080, 540, 540, 540, 540, 1080, 540, 1080, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 540, 270, 1080, 540, 270, 270, 540, 1080, 270, 540, 270, 270, 540, 540, 540, 270, 270, 1080, 540, 540, 270, 1080, 1080, 540, 1080, 1080, 540, 1080, 270, 1080, 540, 540, 540, 1080, 1080, 270, 270, 540, 270, 1080, 270, 270, 1080, 270, 540, 540, 270, 540, 1080, 1080, 1080, 540, 1080, 1080, 270, 270, 1080, 540, 1080, 270, 540, 1080, 270, 1080, 540, 270, 1080, 270, 270, 1080, 270, 270, 540]
Prompts retrieved: 60480 . Total input tokens: 13412337 . Total output tokens: 12123165
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 2.229108582716435,
    "estimated_duration": 3599.9695270891616,
    "input_throughput": 1372.370505590015,
    "output_throughput": 1251.312258646358,
    "total_throughput": 2623.682764236373,
    "itl": 22.70777990207551,
    "ttft": 38011.23064502227,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5524,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.23239383235452,
    "arrivals": 20310,
    "finished_requests": 20189,
    "scheduler_time": 0.008168736069996595
}
#Debug simulation 
Total elapsed time: 2.229206859599799. Arrivals time: 0.06821511127054691 Scheduler time: 1.768983063288033 Scheduler overhead time: 0.1393896541558206 Adapter cache time: 0.04694745922461152 Engine time: 0.13859090441837907 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_96_slots_16_rate_0.1-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_96_slots_16_rate_0.1-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 1080, 540, 540, 540, 540, 1080, 540, 1080, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 540, 270, 1080, 540, 270, 270, 540, 1080, 270, 540, 270, 270, 540, 540, 540, 270, 270, 1080, 540, 540, 270, 1080, 1080, 540, 1080, 1080, 540, 1080, 270, 1080, 540, 540, 540, 1080, 1080, 270, 270, 540, 270, 1080, 270, 270, 1080, 270, 540, 540, 270, 540, 1080, 1080, 1080, 540, 1080, 1080, 270, 270, 1080, 540, 1080, 270, 540, 1080, 270, 1080, 540, 270, 1080, 270, 270, 1080, 270, 270, 540]
Prompts retrieved: 60480 . Total input tokens: 13412337 . Total output tokens: 12123165
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 2.217743828892708,
    "estimated_duration": 3599.9611041846965,
    "input_throughput": 1373.070668528645,
    "output_throughput": 1251.787135911455,
    "total_throughput": 2624.8578044400997,
    "itl": 22.700915663392454,
    "ttft": 36706.30874569596,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5495,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.430326370489155,
    "arrivals": 20310,
    "finished_requests": 20197,
    "scheduler_time": 0.01861303951170136
}
#Debug simulation 
Total elapsed time: 2.217868394218385. Arrivals time: 0.06863199453800917 Scheduler time: 1.7558352202177048 Scheduler overhead time: 0.14018269814550877 Adapter cache time: 0.04667872842401266 Engine time: 0.13891149684786797 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-32/adapters_96_slots_16_rate_0.1-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-32/adapters_96_slots_16_rate_0.1-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 1080, 540, 540, 540, 540, 1080, 540, 1080, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 540, 270, 1080, 540, 270, 270, 540, 1080, 270, 540, 270, 270, 540, 540, 540, 270, 270, 1080, 540, 540, 270, 1080, 1080, 540, 1080, 1080, 540, 1080, 270, 1080, 540, 540, 540, 1080, 1080, 270, 270, 540, 270, 1080, 270, 270, 1080, 270, 540, 540, 270, 540, 1080, 1080, 1080, 540, 1080, 1080, 270, 270, 1080, 540, 1080, 270, 540, 1080, 270, 1080, 540, 270, 1080, 270, 270, 1080, 270, 270, 540]
Prompts retrieved: 60480 . Total input tokens: 13412337 . Total output tokens: 12123165
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 2.231049587018788,
    "estimated_duration": 3599.9740009970683,
    "input_throughput": 1372.939915296912,
    "output_throughput": 1251.7054286369746,
    "total_throughput": 2624.6453439338866,
    "itl": 22.71279533725686,
    "ttft": 36956.239473883186,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5539,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.50911347117136,
    "arrivals": 20310,
    "finished_requests": 20195,
    "scheduler_time": 0.009180837266740988
}
#Debug simulation 
Total elapsed time: 2.231164956931025. Arrivals time: 0.06975956354290247 Scheduler time: 1.769969653338194 Scheduler overhead time: 0.13884831592440605 Adapter cache time: 0.04733381699770689 Engine time: 0.1376428296789527 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_96_slots_16_rate_0.1-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_96_slots_16_rate_0.1-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 1080, 540, 540, 540, 540, 1080, 540, 1080, 540, 135, 1080, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 540, 135, 1080, 540, 135, 135, 540, 1080, 135, 540, 135, 135, 540, 540, 540, 135, 135, 1080, 540, 540, 135, 1080, 1080, 540, 1080, 1080, 540, 1080, 135, 1080, 540, 540, 540, 1080, 1080, 135, 135, 540, 135, 1080, 135, 135, 1080, 135, 540, 540, 135, 540, 1080, 1080, 1080, 540, 1080, 1080, 135, 135, 1080, 540, 1080, 135, 540, 1080, 135, 1080, 540, 135, 1080, 135, 135, 1080, 135, 135, 540]
Prompts retrieved: 56160 . Total input tokens: 12459839 . Total output tokens: 11250841
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 2.044129763264209,
    "estimated_duration": 3599.684679646664,
    "input_throughput": 1294.6561754007435,
    "output_throughput": 1131.9241440891844,
    "total_throughput": 2426.5803194899277,
    "itl": 22.340240180872776,
    "ttft": 32693.255162304013,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6257,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.149471813786462,
    "arrivals": 18897,
    "finished_requests": 18787,
    "scheduler_time": 0.0009706437883253444
}
#Debug simulation 
Total elapsed time: 2.0443240869790316. Arrivals time: 0.06871716678142548 Scheduler time: 1.5777078717947006 Scheduler overhead time: 0.1398086422123015 Adapter cache time: 0.05061499588191509 Engine time: 0.13987263152375817 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_96_slots_16_rate_0.1-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_96_slots_16_rate_0.1-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 1080, 540, 540, 540, 540, 1080, 540, 1080, 540, 135, 1080, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 540, 135, 1080, 540, 135, 135, 540, 1080, 135, 540, 135, 135, 540, 540, 540, 135, 135, 1080, 540, 540, 135, 1080, 1080, 540, 1080, 1080, 540, 1080, 135, 1080, 540, 540, 540, 1080, 1080, 135, 135, 540, 135, 1080, 135, 135, 1080, 135, 540, 540, 135, 540, 1080, 1080, 1080, 540, 1080, 1080, 135, 135, 1080, 540, 1080, 135, 540, 1080, 135, 1080, 540, 135, 1080, 135, 135, 1080, 135, 135, 540]
Prompts retrieved: 56160 . Total input tokens: 12459839 . Total output tokens: 11250841
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 2.034978834912181,
    "estimated_duration": 3599.7058782813433,
    "input_throughput": 1294.6485511824806,
    "output_throughput": 1131.9174781983515,
    "total_throughput": 2426.566029380832,
    "itl": 22.347536494707864,
    "ttft": 32723.11029225537,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6224,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.189293941242713,
    "arrivals": 18897,
    "finished_requests": 18787,
    "scheduler_time": 0.0001105646370665256
}
#Debug simulation 
Total elapsed time: 2.0350914099253714. Arrivals time: 0.06464298069477081 Scheduler time: 1.5727426707744598 Scheduler overhead time: 0.14033523621037602 Adapter cache time: 0.05011421535164118 Engine time: 0.13959833979606628 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-32/adapters_96_slots_16_rate_0.1-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-32/adapters_96_slots_16_rate_0.1-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 1080, 540, 540, 540, 540, 1080, 540, 1080, 540, 135, 1080, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 540, 135, 1080, 540, 135, 135, 540, 1080, 135, 540, 135, 135, 540, 540, 540, 135, 135, 1080, 540, 540, 135, 1080, 1080, 540, 1080, 1080, 540, 1080, 135, 1080, 540, 540, 540, 1080, 1080, 135, 135, 540, 135, 1080, 135, 135, 1080, 135, 540, 540, 135, 540, 1080, 1080, 1080, 540, 1080, 1080, 135, 135, 1080, 540, 1080, 135, 540, 1080, 135, 1080, 540, 135, 1080, 135, 135, 1080, 135, 135, 540]
Prompts retrieved: 56160 . Total input tokens: 12459839 . Total output tokens: 11250841
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 2.0088353268802166,
    "estimated_duration": 3599.697611939169,
    "input_throughput": 1294.651524212183,
    "output_throughput": 1131.9200775325726,
    "total_throughput": 2426.5716017447553,
    "itl": 22.34836228738961,
    "ttft": 32723.316735540026,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6224,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.24632288107577,
    "arrivals": 18897,
    "finished_requests": 18787,
    "scheduler_time": 0.00011442690912093949
}
#Debug simulation 
Total elapsed time: 2.0089572737924755. Arrivals time: 0.06903942348435521 Scheduler time: 1.5442023491486907 Scheduler overhead time: 0.14005853747949004 Adapter cache time: 0.050016374327242374 Engine time: 0.1380844167433679 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_96_slots_16_rate_0.1-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_96_slots_16_rate_0.1-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 1080, 540, 540, 540, 540, 1080, 540, 1080, 540, 135, 1080, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 540, 135, 1080, 540, 135, 135, 540, 1080, 135, 540, 135, 135, 540, 540, 540, 135, 135, 1080, 540, 540, 135, 1080, 1080, 540, 1080, 1080, 540, 1080, 135, 1080, 540, 540, 540, 1080, 1080, 135, 135, 540, 135, 1080, 135, 135, 1080, 135, 540, 540, 135, 540, 1080, 1080, 1080, 540, 1080, 1080, 135, 135, 1080, 540, 1080, 135, 540, 1080, 135, 1080, 540, 135, 1080, 135, 135, 1080, 135, 135, 540]
Prompts retrieved: 56160 . Total input tokens: 12459839 . Total output tokens: 11250841
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 2.0233584749512374,
    "estimated_duration": 3599.6867537175576,
    "input_throughput": 1294.6554294445325,
    "output_throughput": 1131.9234918960683,
    "total_throughput": 2426.578921340601,
    "itl": 22.34518477284169,
    "ttft": 32716.328650154537,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6258,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.521570666646838,
    "arrivals": 18897,
    "finished_requests": 18787,
    "scheduler_time": 0.0002505981179750659
}
#Debug simulation 
Total elapsed time: 2.0234702611342072. Arrivals time: 0.06782440328970551 Scheduler time: 1.5580747942440212 Scheduler overhead time: 0.13971035974100232 Adapter cache time: 0.050502562429755926 Engine time: 0.13997104950249195 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-32/adapters_96_slots_16_rate_0.1-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-32/adapters_96_slots_16_rate_0.1-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 1080, 540, 540, 540, 540, 1080, 540, 1080, 540, 135, 1080, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 540, 135, 1080, 540, 135, 135, 540, 1080, 135, 540, 135, 135, 540, 540, 540, 135, 135, 1080, 540, 540, 135, 1080, 1080, 540, 1080, 1080, 540, 1080, 135, 1080, 540, 540, 540, 1080, 1080, 135, 135, 540, 135, 1080, 135, 135, 1080, 135, 540, 540, 135, 540, 1080, 1080, 1080, 540, 1080, 1080, 135, 135, 1080, 540, 1080, 135, 540, 1080, 135, 1080, 540, 135, 1080, 135, 135, 1080, 135, 135, 540]
Prompts retrieved: 56160 . Total input tokens: 12459839 . Total output tokens: 11250841
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 2.0284644491039217,
    "estimated_duration": 3599.7070339116376,
    "input_throughput": 1294.6481355555777,
    "output_throughput": 1131.9171148137436,
    "total_throughput": 2426.5652503693213,
    "itl": 22.35027278842554,
    "ttft": 32672.730929687325,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6234,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.51683347221352,
    "arrivals": 18897,
    "finished_requests": 18787,
    "scheduler_time": 0.00011248012957472913
}
#Debug simulation 
Total elapsed time: 2.028594216797501. Arrivals time: 0.06784772733226418 Scheduler time: 1.5634716865606606 Scheduler overhead time: 0.14094189601019025 Adapter cache time: 0.050145966932177544 Engine time: 0.13809463381767273 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_96_slots_16_rate_0.1-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_96_slots_16_rate_0.1-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 1080, 540, 540, 540, 540, 1080, 540, 1080, 540, 135, 1080, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 540, 135, 1080, 540, 135, 135, 540, 1080, 135, 540, 135, 135, 540, 540, 540, 135, 135, 1080, 540, 540, 135, 1080, 1080, 540, 1080, 1080, 540, 1080, 135, 1080, 540, 540, 540, 1080, 1080, 135, 135, 540, 135, 1080, 135, 135, 1080, 135, 540, 540, 135, 540, 1080, 1080, 1080, 540, 1080, 1080, 135, 135, 1080, 540, 1080, 135, 540, 1080, 135, 1080, 540, 135, 1080, 135, 135, 1080, 135, 135, 540]
Prompts retrieved: 56160 . Total input tokens: 12459839 . Total output tokens: 11250841
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 2.02282996987924,
    "estimated_duration": 3599.693766313956,
    "input_throughput": 1294.6529073144318,
    "output_throughput": 1131.9212867855456,
    "total_throughput": 2426.5741940999774,
    "itl": 22.338956557466236,
    "ttft": 32729.69865024851,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6248,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.681834242549744,
    "arrivals": 18897,
    "finished_requests": 18787,
    "scheduler_time": 0.00025170098735059586
}
#Debug simulation 
Total elapsed time: 2.0229326118715107. Arrivals time: 0.0679494021460414 Scheduler time: 1.559954009950161 Scheduler overhead time: 0.13958319230005145 Adapter cache time: 0.050046319141983986 Engine time: 0.1378206331282854 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-32/adapters_96_slots_16_rate_0.1-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-32/adapters_96_slots_16_rate_0.1-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 1080, 540, 540, 540, 540, 1080, 540, 1080, 540, 135, 1080, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 540, 135, 1080, 540, 135, 135, 540, 1080, 135, 540, 135, 135, 540, 540, 540, 135, 135, 1080, 540, 540, 135, 1080, 1080, 540, 1080, 1080, 540, 1080, 135, 1080, 540, 540, 540, 1080, 1080, 135, 135, 540, 135, 1080, 135, 135, 1080, 135, 540, 540, 135, 540, 1080, 1080, 1080, 540, 1080, 1080, 135, 135, 1080, 540, 1080, 135, 540, 1080, 135, 1080, 540, 135, 1080, 135, 135, 1080, 135, 135, 540]
Prompts retrieved: 56160 . Total input tokens: 12459839 . Total output tokens: 11250841
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 2.0199030619114637,
    "estimated_duration": 3599.693889077159,
    "input_throughput": 1294.7589832964538,
    "output_throughput": 1132.1407112883107,
    "total_throughput": 2426.8996945847643,
    "itl": 22.352126327574556,
    "ttft": 33053.28511228333,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6229,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.749430864935967,
    "arrivals": 18897,
    "finished_requests": 18785,
    "scheduler_time": 0.00010048243203787216
}
#Debug simulation 
Total elapsed time: 2.020001569762826. Arrivals time: 0.0669126664288342 Scheduler time: 1.5569264651276171 Scheduler overhead time: 0.1421677633188665 Adapter cache time: 0.04980363184586167 Engine time: 0.136004654224962 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_96_slots_16_rate_0.1-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_96_slots_16_rate_0.1-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 1080, 540, 540, 540, 540, 1080, 540, 1080, 540, 66, 1080, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 540, 66, 1080, 540, 66, 66, 540, 1080, 66, 540, 66, 66, 540, 540, 540, 66, 66, 1080, 540, 540, 66, 1080, 1080, 540, 1080, 1080, 540, 1080, 66, 1080, 540, 540, 540, 1080, 1080, 66, 66, 540, 66, 1080, 66, 66, 1080, 66, 540, 540, 66, 540, 1080, 1080, 1080, 540, 1080, 1080, 66, 66, 1080, 540, 1080, 66, 540, 1080, 66, 1080, 540, 66, 1080, 66, 66, 1080, 66, 66, 540]
Prompts retrieved: 53952 . Total input tokens: 11961062 . Total output tokens: 10808170
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.9389080326072872,
    "estimated_duration": 3599.665070062056,
    "input_throughput": 1251.4269834338618,
    "output_throughput": 1095.4377485825428,
    "total_throughput": 2346.8647320164046,
    "itl": 22.26386334507012,
    "ttft": 20866.969031143424,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6426,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.666694242511266,
    "arrivals": 18219,
    "finished_requests": 18160,
    "scheduler_time": 0.0001446176531699965
}
#Debug simulation 
Total elapsed time: 1.938999484758824. Arrivals time: 0.06335717439651489 Scheduler time: 1.4774843673221767 Scheduler overhead time: 0.14031929383054376 Adapter cache time: 0.05082577280700207 Engine time: 0.13916015857830644 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_96_slots_16_rate_0.1-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_96_slots_16_rate_0.1-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 1080, 540, 540, 540, 540, 1080, 540, 1080, 540, 66, 1080, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 540, 66, 1080, 540, 66, 66, 540, 1080, 66, 540, 66, 66, 540, 540, 540, 66, 66, 1080, 540, 540, 66, 1080, 1080, 540, 1080, 1080, 540, 1080, 66, 1080, 540, 540, 540, 1080, 1080, 66, 66, 540, 66, 1080, 66, 66, 1080, 66, 540, 540, 66, 540, 1080, 1080, 1080, 540, 1080, 1080, 66, 66, 1080, 540, 1080, 66, 540, 1080, 66, 1080, 540, 66, 1080, 66, 66, 1080, 66, 66, 540]
Prompts retrieved: 53952 . Total input tokens: 11961062 . Total output tokens: 10808170
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.940042908769101,
    "estimated_duration": 3599.6690251453547,
    "input_throughput": 1251.2517035696426,
    "output_throughput": 1095.41820996745,
    "total_throughput": 2346.6699135370927,
    "itl": 22.270839839232355,
    "ttft": 21116.271342119435,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6390,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.664803928955873,
    "arrivals": 18219,
    "finished_requests": 18159,
    "scheduler_time": 7.739798193583103e-05
}
#Debug simulation 
Total elapsed time: 1.9401432937011123. Arrivals time: 0.06383206974714994 Scheduler time: 1.4796533943153918 Scheduler overhead time: 0.139653823338449 Adapter cache time: 0.05066680395975709 Engine time: 0.13875461369752884 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-32/adapters_96_slots_16_rate_0.1-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-32/adapters_96_slots_16_rate_0.1-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 1080, 540, 540, 540, 540, 1080, 540, 1080, 540, 66, 1080, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 540, 66, 1080, 540, 66, 66, 540, 1080, 66, 540, 66, 66, 540, 540, 540, 66, 66, 1080, 540, 540, 66, 1080, 1080, 540, 1080, 1080, 540, 1080, 66, 1080, 540, 540, 540, 1080, 1080, 66, 66, 540, 66, 1080, 66, 66, 1080, 66, 540, 540, 66, 540, 1080, 1080, 1080, 540, 1080, 1080, 66, 66, 1080, 540, 1080, 66, 540, 1080, 66, 1080, 540, 66, 1080, 66, 66, 1080, 66, 66, 540]
Prompts retrieved: 53952 . Total input tokens: 11961062 . Total output tokens: 10808170
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.9252859926782548,
    "estimated_duration": 3599.6700250800573,
    "input_throughput": 1251.344142273102,
    "output_throughput": 1095.2253880304818,
    "total_throughput": 2346.569530303584,
    "itl": 22.272207957087105,
    "ttft": 21681.560018557877,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6398,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.760719023495206,
    "arrivals": 18219,
    "finished_requests": 18156,
    "scheduler_time": 7.31706379077463e-05
}
#Debug simulation 
Total elapsed time: 1.9254033137112856. Arrivals time: 0.061606934294104576 Scheduler time: 1.46572005469352 Scheduler overhead time: 0.14066052576527 Adapter cache time: 0.05097495578229427 Engine time: 0.1386733641847968 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_96_slots_16_rate_0.1-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_96_slots_16_rate_0.1-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 1080, 540, 540, 540, 540, 1080, 540, 1080, 540, 66, 1080, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 540, 66, 1080, 540, 66, 66, 540, 1080, 66, 540, 66, 66, 540, 540, 540, 66, 66, 1080, 540, 540, 66, 1080, 1080, 540, 1080, 1080, 540, 1080, 66, 1080, 540, 540, 540, 1080, 1080, 66, 66, 540, 66, 1080, 66, 66, 1080, 66, 540, 540, 66, 540, 1080, 1080, 1080, 540, 1080, 1080, 66, 66, 1080, 540, 1080, 66, 540, 1080, 66, 1080, 540, 66, 1080, 66, 66, 1080, 66, 66, 540]
Prompts retrieved: 53952 . Total input tokens: 11961062 . Total output tokens: 10808170
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 1.9263489260338247,
    "estimated_duration": 3599.673579246246,
    "input_throughput": 1251.4129130962085,
    "output_throughput": 1095.304036102515,
    "total_throughput": 2346.716949198724,
    "itl": 22.265260337621097,
    "ttft": 21070.132751620607,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6422,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.01071312905531,
    "arrivals": 18219,
    "finished_requests": 18159,
    "scheduler_time": 0.00013410925985869303
}
#Debug simulation 
Total elapsed time: 1.926475860644132. Arrivals time: 0.06190765043720603 Scheduler time: 1.465385949704796 Scheduler overhead time: 0.13993703993037343 Adapter cache time: 0.05090605700388551 Engine time: 0.13976882491260767 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-32/adapters_96_slots_16_rate_0.1-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-32/adapters_96_slots_16_rate_0.1-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 1080, 540, 540, 540, 540, 1080, 540, 1080, 540, 66, 1080, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 540, 66, 1080, 540, 66, 66, 540, 1080, 66, 540, 66, 66, 540, 540, 540, 66, 66, 1080, 540, 540, 66, 1080, 1080, 540, 1080, 1080, 540, 1080, 66, 1080, 540, 540, 540, 1080, 1080, 66, 66, 540, 66, 1080, 66, 66, 1080, 66, 540, 540, 66, 540, 1080, 1080, 1080, 540, 1080, 1080, 66, 66, 1080, 540, 1080, 66, 540, 1080, 66, 1080, 540, 66, 1080, 66, 66, 1080, 66, 66, 540]
Prompts retrieved: 53952 . Total input tokens: 11961062 . Total output tokens: 10808170
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 1.9253432238474488,
    "estimated_duration": 3599.66786206476,
    "input_throughput": 1251.244051559935,
    "output_throughput": 1095.305220115074,
    "total_throughput": 2346.549271675009,
    "itl": 22.275548762251777,
    "ttft": 21300.264462963205,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6409,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.02688796175526,
    "arrivals": 18219,
    "finished_requests": 18158,
    "scheduler_time": 0.0001405728451287472
}
#Debug simulation 
Total elapsed time: 1.9254492139443755. Arrivals time: 0.062207714188843966 Scheduler time: 1.4662024723365903 Scheduler overhead time: 0.1407393217086792 Adapter cache time: 0.05107814911752939 Engine time: 0.13671441562473774 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_96_slots_16_rate_0.1-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_96_slots_16_rate_0.1-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 1080, 540, 540, 540, 540, 1080, 540, 1080, 540, 66, 1080, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 540, 66, 1080, 540, 66, 66, 540, 1080, 66, 540, 66, 66, 540, 540, 540, 66, 66, 1080, 540, 540, 66, 1080, 1080, 540, 1080, 1080, 540, 1080, 66, 1080, 540, 540, 540, 1080, 1080, 66, 66, 540, 66, 1080, 66, 66, 1080, 66, 540, 540, 66, 540, 1080, 1080, 1080, 540, 1080, 1080, 66, 66, 1080, 540, 1080, 66, 540, 1080, 66, 1080, 540, 66, 1080, 66, 66, 1080, 66, 66, 540]
Prompts retrieved: 53952 . Total input tokens: 11961062 . Total output tokens: 10808170
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.920041257981211,
    "estimated_duration": 3599.674747107362,
    "input_throughput": 1251.4125070938378,
    "output_throughput": 1095.3036807473557,
    "total_throughput": 2346.7161878411935,
    "itl": 22.261160608904856,
    "ttft": 21062.066237166644,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6424,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.208083094452352,
    "arrivals": 18219,
    "finished_requests": 18159,
    "scheduler_time": 0.00013410925985869303
}
#Debug simulation 
Total elapsed time: 1.9201681278645992. Arrivals time: 0.06615772331133485 Scheduler time: 1.45583437057212 Scheduler overhead time: 0.1396537097170949 Adapter cache time: 0.052433951292186975 Engine time: 0.1384200220927596 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-32/adapters_96_slots_16_rate_0.1-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-32/adapters_96_slots_16_rate_0.1-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 1080, 540, 540, 540, 540, 1080, 540, 1080, 540, 66, 1080, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 540, 66, 1080, 540, 66, 66, 540, 1080, 66, 540, 66, 66, 540, 540, 540, 66, 66, 1080, 540, 540, 66, 1080, 1080, 540, 1080, 1080, 540, 1080, 66, 1080, 540, 540, 540, 1080, 1080, 66, 66, 540, 66, 1080, 66, 66, 1080, 66, 540, 540, 66, 540, 1080, 1080, 1080, 540, 1080, 1080, 66, 66, 1080, 540, 1080, 66, 540, 1080, 66, 1080, 540, 66, 1080, 66, 66, 1080, 66, 66, 540]
Prompts retrieved: 53952 . Total input tokens: 11961062 . Total output tokens: 10808170
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.9303933042101562,
    "estimated_duration": 3599.6734942803396,
    "input_throughput": 1251.3429362849872,
    "output_throughput": 1095.224332502465,
    "total_throughput": 2346.567268787452,
    "itl": 22.274349338625772,
    "ttft": 21707.18928397632,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6385,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.196902729755422,
    "arrivals": 18219,
    "finished_requests": 18156,
    "scheduler_time": 7.739798193583103e-05
}
#Debug simulation 
Total elapsed time: 1.930498265195638. Arrivals time: 0.06711314059793949 Scheduler time: 1.4675383842550218 Scheduler overhead time: 0.14008776424452662 Adapter cache time: 0.05068275285884738 Engine time: 0.1374782365746796 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_96_slots_16_rate_0.1-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_96_slots_16_rate_0.1-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 1080, 540, 540, 540, 540, 1080, 540, 1080, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 540, 33, 1080, 540, 33, 33, 540, 1080, 33, 540, 33, 33, 540, 540, 540, 33, 33, 1080, 540, 540, 33, 1080, 1080, 540, 1080, 1080, 540, 1080, 33, 1080, 540, 540, 540, 1080, 1080, 33, 33, 540, 33, 1080, 33, 33, 1080, 33, 540, 540, 33, 540, 1080, 1080, 1080, 540, 1080, 1080, 33, 33, 1080, 540, 1080, 33, 540, 1080, 33, 1080, 540, 33, 1080, 33, 33, 1080, 33, 33, 540]
Prompts retrieved: 52896 . Total input tokens: 11724235 . Total output tokens: 10607449
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.8577710269019008,
    "estimated_duration": 3599.978275227871,
    "input_throughput": 1205.8375545961383,
    "output_throughput": 1094.8982740043075,
    "total_throughput": 2300.735828600446,
    "itl": 22.28494692008601,
    "ttft": 21716.447984986098,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6294,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.26270986031201,
    "arrivals": 17838,
    "finished_requests": 17772,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.8578677661716938. Arrivals time: 0.058940828777849674 Scheduler time: 1.4059556066058576 Scheduler overhead time: 0.14048882061615586 Adapter cache time: 0.049801127053797245 Engine time: 0.13488032296299934 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_96_slots_16_rate_0.1-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_96_slots_16_rate_0.1-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 1080, 540, 540, 540, 540, 1080, 540, 1080, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 540, 33, 1080, 540, 33, 33, 540, 1080, 33, 540, 33, 33, 540, 540, 540, 33, 33, 1080, 540, 540, 33, 1080, 1080, 540, 1080, 1080, 540, 1080, 33, 1080, 540, 540, 540, 1080, 1080, 33, 33, 540, 33, 1080, 33, 33, 1080, 33, 540, 540, 33, 540, 1080, 1080, 1080, 540, 1080, 1080, 33, 33, 1080, 540, 1080, 33, 540, 1080, 33, 1080, 540, 33, 1080, 33, 33, 1080, 33, 33, 540]
Prompts retrieved: 52896 . Total input tokens: 11724235 . Total output tokens: 10607449
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.9217743291519582,
    "estimated_duration": 3599.9776436878983,
    "input_throughput": 1205.7219320821725,
    "output_throughput": 1094.9406885654907,
    "total_throughput": 2300.6626206476635,
    "itl": 22.292033675806657,
    "ttft": 21531.893997655137,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6286,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.28478608946979,
    "arrivals": 17838,
    "finished_requests": 17773,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.92187087982893. Arrivals time: 0.06311075668781996 Scheduler time: 1.460693727247417 Scheduler overhead time: 0.1434445846825838 Adapter cache time: 0.050025018863379955 Engine time: 0.13611900573596358 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-32/adapters_96_slots_16_rate_0.1-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-32/adapters_96_slots_16_rate_0.1-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 1080, 540, 540, 540, 540, 1080, 540, 1080, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 540, 33, 1080, 540, 33, 33, 540, 1080, 33, 540, 33, 33, 540, 540, 540, 33, 33, 1080, 540, 540, 33, 1080, 1080, 540, 1080, 1080, 540, 1080, 33, 1080, 540, 540, 540, 1080, 1080, 33, 33, 540, 33, 1080, 33, 33, 1080, 33, 540, 540, 33, 540, 1080, 1080, 1080, 540, 1080, 1080, 33, 33, 1080, 540, 1080, 33, 540, 1080, 33, 1080, 540, 33, 1080, 33, 33, 1080, 33, 33, 540]
Prompts retrieved: 52896 . Total input tokens: 11724235 . Total output tokens: 10607449
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.899980700109154,
    "estimated_duration": 3599.989785595116,
    "input_throughput": 1205.7178654695706,
    "output_throughput": 1094.93699559161,
    "total_throughput": 2300.6548610611803,
    "itl": 22.293144279431985,
    "ttft": 21532.155416999452,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6286,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.36082660088235,
    "arrivals": 17838,
    "finished_requests": 17773,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.900105319917202. Arrivals time: 0.06136313499882817 Scheduler time: 1.4434723216108978 Scheduler overhead time: 0.13993574539199471 Adapter cache time: 0.04996319720521569 Engine time: 0.1375798829831183 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_96_slots_16_rate_0.1-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_96_slots_16_rate_0.1-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 1080, 540, 540, 540, 540, 1080, 540, 1080, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 540, 33, 1080, 540, 33, 33, 540, 1080, 33, 540, 33, 33, 540, 540, 540, 33, 33, 1080, 540, 540, 33, 1080, 1080, 540, 1080, 1080, 540, 1080, 33, 1080, 540, 540, 540, 1080, 1080, 33, 33, 540, 33, 1080, 33, 33, 1080, 33, 540, 540, 33, 540, 1080, 1080, 1080, 540, 1080, 1080, 33, 33, 1080, 540, 1080, 33, 540, 1080, 33, 1080, 540, 33, 1080, 33, 33, 1080, 33, 33, 540]
Prompts retrieved: 52896 . Total input tokens: 11724235 . Total output tokens: 10607449
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 1.8753886469639838,
    "estimated_duration": 3599.9688251830767,
    "input_throughput": 1205.7468302601915,
    "output_throughput": 1094.8625367053162,
    "total_throughput": 2300.6093669655074,
    "itl": 22.287653859266324,
    "ttft": 21920.191543759513,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6294,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.603062376883113,
    "arrivals": 17838,
    "finished_requests": 17771,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.875478285830468. Arrivals time: 0.06024725129827857 Scheduler time: 1.4221095722168684 Scheduler overhead time: 0.13860410824418068 Adapter cache time: 0.05036661820486188 Engine time: 0.13681847229599953 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-32/adapters_96_slots_16_rate_0.1-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-32/adapters_96_slots_16_rate_0.1-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 1080, 540, 540, 540, 540, 1080, 540, 1080, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 540, 33, 1080, 540, 33, 33, 540, 1080, 33, 540, 33, 33, 540, 540, 540, 33, 33, 1080, 540, 540, 33, 1080, 1080, 540, 1080, 1080, 540, 1080, 33, 1080, 540, 540, 540, 1080, 1080, 33, 33, 540, 33, 1080, 33, 33, 1080, 33, 540, 540, 33, 540, 1080, 1080, 1080, 540, 1080, 1080, 33, 33, 1080, 540, 1080, 33, 540, 1080, 33, 1080, 540, 33, 1080, 33, 33, 1080, 33, 33, 540]
Prompts retrieved: 52896 . Total input tokens: 11724235 . Total output tokens: 10607449
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 1.9191944669000804,
    "estimated_duration": 3599.9685175037457,
    "input_throughput": 1205.6310989657104,
    "output_throughput": 1094.904852871647,
    "total_throughput": 2300.5359518373575,
    "itl": 22.292328718277695,
    "ttft": 21743.61199643069,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6280,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.558856288230686,
    "arrivals": 17838,
    "finished_requests": 17772,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.919291527941823. Arrivals time: 0.06341090658679605 Scheduler time: 1.4583755689673126 Scheduler overhead time: 0.13955232175067067 Adapter cache time: 0.05048042256385088 Engine time: 0.13999694725498557 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_96_slots_16_rate_0.1-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_96_slots_16_rate_0.1-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 1080, 540, 540, 540, 540, 1080, 540, 1080, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 540, 33, 1080, 540, 33, 33, 540, 1080, 33, 540, 33, 33, 540, 540, 540, 33, 33, 1080, 540, 540, 33, 1080, 1080, 540, 1080, 1080, 540, 1080, 33, 1080, 540, 540, 540, 1080, 1080, 33, 33, 540, 33, 1080, 33, 33, 1080, 33, 540, 540, 33, 540, 1080, 1080, 1080, 540, 1080, 1080, 33, 33, 1080, 540, 1080, 33, 540, 1080, 33, 1080, 540, 33, 1080, 33, 33, 1080, 33, 33, 540]
Prompts retrieved: 52896 . Total input tokens: 11724235 . Total output tokens: 10607449
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.9114260468631983,
    "estimated_duration": 3599.9756500851254,
    "input_throughput": 1205.550931961825,
    "output_throughput": 1094.7487936222037,
    "total_throughput": 2300.2997255840287,
    "itl": 22.282494760401153,
    "ttft": 22364.85277380699,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6294,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.8193765561152,
    "arrivals": 17838,
    "finished_requests": 17769,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.9115321808494627. Arrivals time: 0.06428885273635387 Scheduler time: 1.4499642043374479 Scheduler overhead time: 0.14036675449460745 Adapter cache time: 0.04997392324730754 Engine time: 0.13863278133794665 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-32/adapters_96_slots_16_rate_0.1-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-32/adapters_96_slots_16_rate_0.1-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 1080, 540, 540, 540, 540, 1080, 540, 1080, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 540, 33, 1080, 540, 33, 33, 540, 1080, 33, 540, 33, 33, 540, 540, 540, 33, 33, 1080, 540, 540, 33, 1080, 1080, 540, 1080, 1080, 540, 1080, 33, 1080, 540, 540, 540, 1080, 1080, 33, 33, 540, 33, 1080, 33, 33, 1080, 33, 540, 540, 33, 540, 1080, 1080, 1080, 540, 1080, 1080, 33, 33, 1080, 540, 1080, 33, 540, 1080, 33, 1080, 540, 33, 1080, 33, 33, 1080, 33, 33, 540]
Prompts retrieved: 52896 . Total input tokens: 11724235 . Total output tokens: 10607449
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.8995893839746714,
    "estimated_duration": 3599.9869566617,
    "input_throughput": 1205.7188129439921,
    "output_throughput": 1094.9378560124649,
    "total_throughput": 2300.656668956457,
    "itl": 22.295314392125004,
    "ttft": 21544.128256834556,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6291,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.83580575045029,
    "arrivals": 17838,
    "finished_requests": 17773,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.8996893898583949. Arrivals time: 0.06461529666557908 Scheduler time: 1.4410086898133159 Scheduler overhead time: 0.13916382659226656 Adapter cache time: 0.05010920902714133 Engine time: 0.13727850187569857 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_96_slots_16_rate_0.1-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_96_slots_16_rate_0.1-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 1080, 270, 270, 270, 270, 1080, 270, 1080, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 270, 135, 1080, 270, 135, 135, 270, 1080, 135, 270, 135, 135, 270, 270, 270, 135, 135, 1080, 270, 270, 135, 1080, 1080, 270, 1080, 1080, 270, 1080, 135, 1080, 270, 270, 270, 1080, 1080, 135, 135, 270, 135, 1080, 135, 135, 1080, 135, 270, 270, 135, 270, 1080, 1080, 1080, 270, 1080, 1080, 135, 135, 1080, 270, 1080, 135, 270, 1080, 135, 1080, 270, 135, 1080, 135, 135, 1080, 135, 135, 270]
Prompts retrieved: 47520 . Total input tokens: 10522237 . Total output tokens: 9530691
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.74430363625288,
    "estimated_duration": 3600.0094310431455,
    "input_throughput": 1094.8401873652654,
    "output_throughput": 990.8662930825662,
    "total_throughput": 2085.706480447832,
    "itl": 22.01771356313673,
    "ttft": 16982.557659585244,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7156,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.900850295582902,
    "arrivals": 16094,
    "finished_requests": 16045,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.744462350383401. Arrivals time: 0.058954153675585985 Scheduler time: 1.2854737075977027 Scheduler overhead time: 0.1394776445813477 Adapter cache time: 0.053317011799663305 Engine time: 0.1392640033736825 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_96_slots_16_rate_0.1-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_96_slots_16_rate_0.1-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 1080, 270, 270, 270, 270, 1080, 270, 1080, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 270, 135, 1080, 270, 135, 135, 270, 1080, 135, 270, 135, 135, 270, 270, 270, 135, 135, 1080, 270, 270, 135, 1080, 1080, 270, 1080, 1080, 270, 1080, 135, 1080, 270, 270, 270, 1080, 1080, 135, 135, 270, 135, 1080, 135, 135, 1080, 135, 270, 270, 135, 270, 1080, 1080, 1080, 270, 1080, 1080, 135, 135, 1080, 270, 1080, 135, 270, 1080, 135, 1080, 270, 135, 1080, 135, 135, 1080, 135, 135, 270]
Prompts retrieved: 47520 . Total input tokens: 10522237 . Total output tokens: 9530691
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.7495181132107973,
    "estimated_duration": 3600.0180612065974,
    "input_throughput": 1094.8375627534967,
    "output_throughput": 990.8639177227979,
    "total_throughput": 2085.701480476295,
    "itl": 22.025258897305726,
    "ttft": 17009.81023272599,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7142,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.169102420065034,
    "arrivals": 16094,
    "finished_requests": 16045,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.7496065790764987. Arrivals time: 0.05654848087579012 Scheduler time: 1.2949002487584949 Scheduler overhead time: 0.1404545484110713 Adapter cache time: 0.05303699942305684 Engine time: 0.13662889041006565 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-32/adapters_96_slots_16_rate_0.1-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-32/adapters_96_slots_16_rate_0.1-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 1080, 270, 270, 270, 270, 1080, 270, 1080, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 270, 135, 1080, 270, 135, 135, 270, 1080, 135, 270, 135, 135, 270, 270, 270, 135, 135, 1080, 270, 270, 135, 1080, 1080, 270, 1080, 1080, 270, 1080, 135, 1080, 270, 270, 270, 1080, 1080, 135, 135, 270, 135, 1080, 135, 135, 1080, 135, 270, 270, 135, 270, 1080, 1080, 1080, 270, 1080, 1080, 135, 135, 1080, 270, 1080, 135, 270, 1080, 135, 1080, 270, 135, 1080, 135, 135, 1080, 135, 135, 270]
Prompts retrieved: 47520 . Total input tokens: 10522237 . Total output tokens: 9530691
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.7396550490520895,
    "estimated_duration": 3600.0000691983673,
    "input_throughput": 1094.843034510736,
    "output_throughput": 990.8688698426366,
    "total_throughput": 2085.7119043533726,
    "itl": 22.0274003998204,
    "ttft": 17012.319371204456,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7132,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.201394572648915,
    "arrivals": 16094,
    "finished_requests": 16045,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.7397524006664753. Arrivals time: 0.05503487680107355 Scheduler time: 1.2887411275878549 Scheduler overhead time: 0.13936790777370334 Adapter cache time: 0.05299437278881669 Engine time: 0.13552943523973227 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_96_slots_16_rate_0.1-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_96_slots_16_rate_0.1-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 1080, 270, 270, 270, 270, 1080, 270, 1080, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 270, 135, 1080, 270, 135, 135, 270, 1080, 135, 270, 135, 135, 270, 270, 270, 135, 135, 1080, 270, 270, 135, 1080, 1080, 270, 1080, 1080, 270, 1080, 135, 1080, 270, 270, 270, 1080, 1080, 135, 135, 270, 135, 1080, 135, 135, 1080, 135, 270, 270, 135, 270, 1080, 1080, 1080, 270, 1080, 1080, 135, 135, 1080, 270, 1080, 135, 270, 1080, 135, 1080, 270, 135, 1080, 135, 135, 1080, 135, 135, 270]
Prompts retrieved: 47520 . Total input tokens: 10522237 . Total output tokens: 9530691
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 1.7166081322357059,
    "estimated_duration": 3600.0017544455995,
    "input_throughput": 1094.842521988432,
    "output_throughput": 990.8684059931348,
    "total_throughput": 2085.710927981567,
    "itl": 22.021196367765608,
    "ttft": 16983.50846317886,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7154,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.306890513672705,
    "arrivals": 16094,
    "finished_requests": 16045,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.7166985073126853. Arrivals time: 0.05646850820630789 Scheduler time: 1.2655495749786496 Scheduler overhead time: 0.1396827967837453 Adapter cache time: 0.05241933697834611 Engine time: 0.13489417871460319 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-32/adapters_96_slots_16_rate_0.1-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-32/adapters_96_slots_16_rate_0.1-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 1080, 270, 270, 270, 270, 1080, 270, 1080, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 270, 135, 1080, 270, 135, 135, 270, 1080, 135, 270, 135, 135, 270, 270, 270, 135, 135, 1080, 270, 270, 135, 1080, 1080, 270, 1080, 1080, 270, 1080, 135, 1080, 270, 270, 270, 1080, 1080, 135, 135, 270, 135, 1080, 135, 135, 1080, 135, 270, 270, 135, 270, 1080, 1080, 1080, 270, 1080, 1080, 135, 135, 1080, 270, 1080, 135, 270, 1080, 135, 1080, 270, 135, 1080, 135, 135, 1080, 135, 135, 270]
Prompts retrieved: 47520 . Total input tokens: 10522237 . Total output tokens: 9530691
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 1.7454709517769516,
    "estimated_duration": 3600.0211324653787,
    "input_throughput": 1094.8366287230133,
    "output_throughput": 990.8630723945632,
    "total_throughput": 2085.6997011175768,
    "itl": 22.028984647884467,
    "ttft": 17010.607991926012,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7139,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.501632527242283,
    "arrivals": 16094,
    "finished_requests": 16045,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.7455793437547982. Arrivals time: 0.05575461685657501 Scheduler time: 1.2903285408392549 Scheduler overhead time: 0.1391806062310934 Adapter cache time: 0.05298341205343604 Engine time: 0.13966325437650084 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_96_slots_16_rate_0.1-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_96_slots_16_rate_0.1-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 1080, 270, 270, 270, 270, 1080, 270, 1080, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 270, 135, 1080, 270, 135, 135, 270, 1080, 135, 270, 135, 135, 270, 270, 270, 135, 135, 1080, 270, 270, 135, 1080, 1080, 270, 1080, 1080, 270, 1080, 135, 1080, 270, 270, 270, 1080, 1080, 135, 135, 270, 135, 1080, 135, 135, 1080, 135, 270, 270, 135, 270, 1080, 1080, 1080, 270, 1080, 1080, 135, 135, 1080, 270, 1080, 135, 270, 1080, 135, 1080, 270, 135, 1080, 135, 135, 1080, 135, 135, 270]
Prompts retrieved: 47520 . Total input tokens: 10522237 . Total output tokens: 9530691
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.7399742431007326,
    "estimated_duration": 3600.0076619370625,
    "input_throughput": 1094.8407253886858,
    "output_throughput": 990.866780011415,
    "total_throughput": 2085.7075054001007,
    "itl": 22.014507943390974,
    "ttft": 16979.255465643146,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7157,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.399789960614918,
    "arrivals": 16094,
    "finished_requests": 16045,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.7400740282610059. Arrivals time: 0.05805780412629247 Scheduler time: 1.2830131007358432 Scheduler overhead time: 0.14109761081635952 Adapter cache time: 0.0530703030526638 Engine time: 0.13663964439183474 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-32/adapters_96_slots_16_rate_0.1-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-32/adapters_96_slots_16_rate_0.1-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 1080, 270, 270, 270, 270, 1080, 270, 1080, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 270, 135, 1080, 270, 135, 135, 270, 1080, 135, 270, 135, 135, 270, 270, 270, 135, 135, 1080, 270, 270, 135, 1080, 1080, 270, 1080, 1080, 270, 1080, 135, 1080, 270, 270, 270, 1080, 1080, 135, 135, 270, 135, 1080, 135, 135, 1080, 135, 270, 270, 135, 270, 1080, 1080, 1080, 270, 1080, 1080, 135, 135, 1080, 270, 1080, 135, 270, 1080, 135, 1080, 270, 135, 1080, 135, 135, 1080, 135, 135, 270]
Prompts retrieved: 47520 . Total input tokens: 10522237 . Total output tokens: 9530691
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.7511427719146013,
    "estimated_duration": 3600.003559026962,
    "input_throughput": 1094.8419731744161,
    "output_throughput": 990.867909298443,
    "total_throughput": 2085.709882472859,
    "itl": 22.032429121939995,
    "ttft": 17024.418444568673,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7127,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.742254509737638,
    "arrivals": 16094,
    "finished_requests": 16045,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.7513422407209873. Arrivals time: 0.05950363678857684 Scheduler time: 1.2928456319496036 Scheduler overhead time: 0.14008029736578465 Adapter cache time: 0.05289037898182869 Engine time: 0.1381935221143067 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_96_slots_16_rate_0.1-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_96_slots_16_rate_0.1-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 1080, 270, 270, 270, 270, 1080, 270, 1080, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 270, 66, 1080, 270, 66, 66, 270, 1080, 66, 270, 66, 66, 270, 270, 270, 66, 66, 1080, 270, 270, 66, 1080, 1080, 270, 1080, 1080, 270, 1080, 66, 1080, 270, 270, 270, 1080, 1080, 66, 66, 270, 66, 1080, 66, 66, 1080, 66, 270, 270, 66, 270, 1080, 1080, 1080, 270, 1080, 1080, 66, 66, 1080, 270, 1080, 66, 270, 1080, 66, 1080, 270, 66, 1080, 66, 66, 1080, 66, 66, 270]
Prompts retrieved: 45312 . Total input tokens: 10028328 . Total output tokens: 9089061
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.6250650212168694,
    "estimated_duration": 3599.729384149721,
    "input_throughput": 1058.7748670169144,
    "output_throughput": 918.9035194047855,
    "total_throughput": 1977.6783864216998,
    "itl": 21.817483518815955,
    "ttft": 12515.830573537487,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7864,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.067675618287996,
    "arrivals": 15365,
    "finished_requests": 15327,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.625165469944477. Arrivals time: 0.052262564189732075 Scheduler time: 1.1692534247413278 Scheduler overhead time: 0.14128830935806036 Adapter cache time: 0.0557850431650877 Engine time: 0.1380118760280311 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_96_slots_16_rate_0.1-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_96_slots_16_rate_0.1-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 1080, 270, 270, 270, 270, 1080, 270, 1080, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 270, 66, 1080, 270, 66, 66, 270, 1080, 66, 270, 66, 66, 270, 270, 270, 66, 66, 1080, 270, 270, 66, 1080, 1080, 270, 1080, 1080, 270, 1080, 66, 1080, 270, 270, 270, 1080, 1080, 66, 66, 270, 66, 1080, 66, 66, 1080, 66, 270, 270, 66, 270, 1080, 1080, 1080, 270, 1080, 1080, 66, 66, 1080, 270, 1080, 66, 270, 1080, 66, 1080, 270, 66, 1080, 66, 66, 1080, 66, 66, 270]
Prompts retrieved: 45312 . Total input tokens: 10028328 . Total output tokens: 9089061
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.6287600938230753,
    "estimated_duration": 3599.7312330106306,
    "input_throughput": 1058.774323218687,
    "output_throughput": 918.9030474459956,
    "total_throughput": 1977.6773706646827,
    "itl": 21.82605360004394,
    "ttft": 12520.821345403974,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7866,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.433187495954435,
    "arrivals": 15365,
    "finished_requests": 15327,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.628862168174237. Arrivals time: 0.05454774294048548 Scheduler time: 1.1695014722645283 Scheduler overhead time: 0.13941051252186298 Adapter cache time: 0.056407125666737556 Engine time: 0.14113675523549318 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_96_slots_16_rate_0.1-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_96_slots_16_rate_0.1-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 1080, 270, 270, 270, 270, 1080, 270, 1080, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 270, 66, 1080, 270, 66, 66, 270, 1080, 66, 270, 66, 66, 270, 270, 270, 66, 66, 1080, 270, 270, 66, 1080, 1080, 270, 1080, 1080, 270, 1080, 66, 1080, 270, 270, 270, 1080, 1080, 66, 66, 270, 66, 1080, 66, 66, 1080, 66, 270, 270, 66, 270, 1080, 1080, 1080, 270, 1080, 1080, 66, 66, 1080, 270, 1080, 66, 270, 1080, 66, 1080, 270, 66, 1080, 66, 66, 1080, 66, 66, 270]
Prompts retrieved: 45312 . Total input tokens: 10028328 . Total output tokens: 9089061
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.6283841459080577,
    "estimated_duration": 3599.721425334194,
    "input_throughput": 1058.777207918572,
    "output_throughput": 918.9055510574425,
    "total_throughput": 1977.6827589760144,
    "itl": 21.82518880595865,
    "ttft": 12523.192044255018,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7863,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.509844229724283,
    "arrivals": 15365,
    "finished_requests": 15327,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.628475018311292. Arrivals time: 0.054025286342948675 Scheduler time: 1.1730553722009063 Scheduler overhead time: 0.13971945038065314 Adapter cache time: 0.056290324311703444 Engine time: 0.13721592770889401 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_96_slots_16_rate_0.1-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_96_slots_16_rate_0.1-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 1080, 270, 270, 270, 270, 1080, 270, 1080, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 270, 66, 1080, 270, 66, 66, 270, 1080, 66, 270, 66, 66, 270, 270, 270, 66, 66, 1080, 270, 270, 66, 1080, 1080, 270, 1080, 1080, 270, 1080, 66, 1080, 270, 270, 270, 1080, 1080, 66, 66, 270, 66, 1080, 66, 66, 1080, 66, 270, 270, 66, 270, 1080, 1080, 1080, 270, 1080, 1080, 66, 66, 1080, 270, 1080, 66, 270, 1080, 66, 1080, 270, 66, 1080, 66, 66, 1080, 66, 66, 270]
Prompts retrieved: 45312 . Total input tokens: 10028328 . Total output tokens: 9089061
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 1.6309262569993734,
    "estimated_duration": 3599.722038314621,
    "input_throughput": 1058.7770276241774,
    "output_throughput": 918.9053945811615,
    "total_throughput": 1977.6824222053392,
    "itl": 21.820788660000474,
    "ttft": 12519.793815047475,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7865,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.521072862130502,
    "arrivals": 15365,
    "finished_requests": 15327,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.631026147864759. Arrivals time: 0.05636757705360651 Scheduler time: 1.1729450859129429 Scheduler overhead time: 0.14000773383304477 Adapter cache time: 0.056079556699842215 Engine time: 0.1374936504289508 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_96_slots_16_rate_0.1-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_96_slots_16_rate_0.1-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 1080, 270, 270, 270, 270, 1080, 270, 1080, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 270, 66, 1080, 270, 66, 66, 270, 1080, 66, 270, 66, 66, 270, 270, 270, 66, 66, 1080, 270, 270, 66, 1080, 1080, 270, 1080, 1080, 270, 1080, 66, 1080, 270, 270, 270, 1080, 1080, 66, 66, 270, 66, 1080, 66, 66, 1080, 66, 270, 270, 66, 270, 1080, 1080, 1080, 270, 1080, 1080, 66, 66, 1080, 270, 1080, 66, 270, 1080, 66, 1080, 270, 66, 1080, 66, 66, 1080, 66, 66, 270]
Prompts retrieved: 45312 . Total input tokens: 10028328 . Total output tokens: 9089061
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 1.638999602291733,
    "estimated_duration": 3599.719911664638,
    "input_throughput": 1058.7776531306622,
    "output_throughput": 918.9059374539933,
    "total_throughput": 1977.6835905846556,
    "itl": 21.828750289679807,
    "ttft": 12523.600436796192,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7862,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.7868143793558,
    "arrivals": 15365,
    "finished_requests": 15327,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.639232689049095. Arrivals time: 0.05672084167599678 Scheduler time: 1.1798598407767713 Scheduler overhead time: 0.14018867118284106 Adapter cache time: 0.056113623548299074 Engine time: 0.13780450308695436 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_96_slots_16_rate_0.1-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_96_slots_16_rate_0.1-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 1080, 270, 270, 270, 270, 1080, 270, 1080, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 270, 66, 1080, 270, 66, 66, 270, 1080, 66, 270, 66, 66, 270, 270, 270, 66, 66, 1080, 270, 270, 66, 1080, 1080, 270, 1080, 1080, 270, 1080, 66, 1080, 270, 270, 270, 1080, 1080, 66, 66, 270, 66, 1080, 66, 66, 1080, 66, 270, 270, 66, 270, 1080, 1080, 1080, 270, 1080, 1080, 66, 66, 1080, 270, 1080, 66, 270, 1080, 66, 1080, 270, 66, 1080, 66, 66, 1080, 66, 66, 270]
Prompts retrieved: 45312 . Total input tokens: 10028328 . Total output tokens: 9089061
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.6442159502767026,
    "estimated_duration": 3599.726508542928,
    "input_throughput": 1058.7757128090025,
    "output_throughput": 918.904253461997,
    "total_throughput": 1977.6799662709993,
    "itl": 21.81397356985798,
    "ttft": 12507.424778622111,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7870,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.53169582087946,
    "arrivals": 15365,
    "finished_requests": 15327,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6443178430199623. Arrivals time: 0.05505208671092987 Scheduler time: 1.1865883483551443 Scheduler overhead time: 0.140110332518816 Adapter cache time: 0.055912273935973644 Engine time: 0.13813180662691593 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_96_slots_16_rate_0.1-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_96_slots_16_rate_0.1-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 1080, 270, 270, 270, 270, 1080, 270, 1080, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 270, 66, 1080, 270, 66, 66, 270, 1080, 66, 270, 66, 66, 270, 270, 270, 66, 66, 1080, 270, 270, 66, 1080, 1080, 270, 1080, 1080, 270, 1080, 66, 1080, 270, 270, 270, 1080, 1080, 66, 66, 270, 66, 1080, 66, 66, 1080, 66, 270, 270, 66, 270, 1080, 1080, 1080, 270, 1080, 1080, 66, 66, 1080, 270, 1080, 66, 270, 1080, 66, 1080, 270, 66, 1080, 66, 66, 1080, 66, 66, 270]
Prompts retrieved: 45312 . Total input tokens: 10028328 . Total output tokens: 9089061
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.6339053469710052,
    "estimated_duration": 3599.7239356020023,
    "input_throughput": 1058.7764695801914,
    "output_throughput": 918.9049102585743,
    "total_throughput": 1977.6813798387657,
    "itl": 21.82965825667568,
    "ttft": 12528.931545958718,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7864,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.101541222778724,
    "arrivals": 15365,
    "finished_requests": 15327,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6340152868069708. Arrivals time: 0.05408308142796159 Scheduler time: 1.173687569797039 Scheduler overhead time: 0.13937928481027484 Adapter cache time: 0.05590436514467001 Engine time: 0.14016252476722002 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_96_slots_16_rate_0.1-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_96_slots_16_rate_0.1-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 1080, 270, 270, 270, 270, 1080, 270, 1080, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 270, 33, 1080, 270, 33, 33, 270, 1080, 33, 270, 33, 33, 270, 270, 270, 33, 33, 1080, 270, 270, 33, 1080, 1080, 270, 1080, 1080, 270, 1080, 33, 1080, 270, 270, 270, 1080, 1080, 33, 33, 270, 33, 1080, 33, 33, 1080, 33, 270, 270, 33, 270, 1080, 1080, 1080, 270, 1080, 1080, 33, 33, 1080, 270, 1080, 33, 270, 1080, 33, 1080, 270, 33, 1080, 33, 33, 1080, 33, 33, 270]
Prompts retrieved: 44256 . Total input tokens: 9790606 . Total output tokens: 8891185
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.623197159729898,
    "estimated_duration": 3599.749577187318,
    "input_throughput": 1020.8424006181299,
    "output_throughput": 912.2651255551814,
    "total_throughput": 1933.1075261733113,
    "itl": 21.808435284352537,
    "ttft": 10412.882974177284,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7753,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.72796147871135,
    "arrivals": 15003,
    "finished_requests": 14972,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6233541308902204. Arrivals time: 0.05642556119710207 Scheduler time: 1.1641859635710716 Scheduler overhead time: 0.14065398508682847 Adapter cache time: 0.05542275309562683 Engine time: 0.13801235239952803 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_96_slots_16_rate_0.1-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_96_slots_16_rate_0.1-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 1080, 270, 270, 270, 270, 1080, 270, 1080, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 270, 33, 1080, 270, 33, 33, 270, 1080, 33, 270, 33, 33, 270, 270, 270, 33, 33, 1080, 270, 270, 33, 1080, 1080, 270, 1080, 1080, 270, 1080, 33, 1080, 270, 270, 270, 1080, 1080, 33, 33, 270, 33, 1080, 33, 33, 1080, 33, 270, 270, 33, 270, 1080, 1080, 1080, 270, 1080, 1080, 33, 33, 1080, 270, 1080, 33, 270, 1080, 33, 1080, 270, 33, 1080, 33, 33, 1080, 33, 33, 270]
Prompts retrieved: 44256 . Total input tokens: 9790606 . Total output tokens: 8891185
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.628484291024506,
    "estimated_duration": 3599.7462278396238,
    "input_throughput": 1020.8433504506804,
    "output_throughput": 912.2659743630977,
    "total_throughput": 1933.1093248137781,
    "itl": 21.816323280781592,
    "ttft": 10418.42061055588,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7748,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.035007480809252,
    "arrivals": 15003,
    "finished_requests": 14972,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6285833376459777. Arrivals time: 0.05474309157580137 Scheduler time: 1.1685816901735961 Scheduler overhead time: 0.14130142144858837 Adapter cache time: 0.05577683635056019 Engine time: 0.13974557863548398 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_96_slots_16_rate_0.1-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_96_slots_16_rate_0.1-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 1080, 270, 270, 270, 270, 1080, 270, 1080, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 270, 33, 1080, 270, 33, 33, 270, 1080, 33, 270, 33, 33, 270, 270, 270, 33, 33, 1080, 270, 270, 33, 1080, 1080, 270, 1080, 1080, 270, 1080, 33, 1080, 270, 270, 270, 1080, 1080, 33, 33, 270, 33, 1080, 33, 33, 1080, 33, 270, 270, 33, 270, 1080, 1080, 1080, 270, 1080, 1080, 33, 33, 1080, 270, 1080, 33, 270, 1080, 33, 1080, 270, 33, 1080, 33, 33, 1080, 33, 33, 270]
Prompts retrieved: 44256 . Total input tokens: 9790606 . Total output tokens: 8891185
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.630299714859575,
    "estimated_duration": 3599.749658115356,
    "input_throughput": 1020.842377667986,
    "output_throughput": 912.2651050460256,
    "total_throughput": 1933.1074827140117,
    "itl": 21.818314733869585,
    "ttft": 10417.337100104372,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7750,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.12950387040152,
    "arrivals": 15003,
    "finished_requests": 14972,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6304290229454637. Arrivals time: 0.05463839182630181 Scheduler time: 1.1729278988204896 Scheduler overhead time: 0.14062370965257287 Adapter cache time: 0.055505281779915094 Engine time: 0.13816990237683058 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_96_slots_16_rate_0.1-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_96_slots_16_rate_0.1-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 1080, 270, 270, 270, 270, 1080, 270, 1080, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 270, 33, 1080, 270, 33, 33, 270, 1080, 33, 270, 33, 33, 270, 270, 270, 33, 33, 1080, 270, 270, 33, 1080, 1080, 270, 1080, 1080, 270, 1080, 33, 1080, 270, 270, 270, 1080, 1080, 33, 33, 270, 33, 1080, 33, 33, 1080, 33, 270, 270, 33, 270, 1080, 1080, 1080, 270, 1080, 1080, 33, 33, 1080, 270, 1080, 33, 270, 1080, 33, 1080, 270, 33, 1080, 33, 33, 1080, 33, 33, 270]
Prompts retrieved: 44256 . Total input tokens: 9790606 . Total output tokens: 8891185
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 1.6103513580746949,
    "estimated_duration": 3599.754064772272,
    "input_throughput": 1020.8411279986911,
    "output_throughput": 912.2639882921412,
    "total_throughput": 1933.1051162908325,
    "itl": 21.81080626401145,
    "ttft": 10416.332347721249,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7750,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.164142028026784,
    "arrivals": 15003,
    "finished_requests": 14972,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6104484382085502. Arrivals time: 0.055842628702521324 Scheduler time: 1.1526584327220917 Scheduler overhead time: 0.1397814261727035 Adapter cache time: 0.055698476266115904 Engine time: 0.1382239325903356 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_96_slots_16_rate_0.1-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_96_slots_16_rate_0.1-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 1080, 270, 270, 270, 270, 1080, 270, 1080, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 270, 33, 1080, 270, 33, 33, 270, 1080, 33, 270, 33, 33, 270, 270, 270, 33, 33, 1080, 270, 270, 33, 1080, 1080, 270, 1080, 1080, 270, 1080, 33, 1080, 270, 270, 270, 1080, 1080, 33, 33, 270, 33, 1080, 33, 33, 1080, 33, 270, 270, 33, 270, 1080, 1080, 1080, 270, 1080, 1080, 33, 33, 1080, 270, 1080, 33, 270, 1080, 33, 1080, 270, 33, 1080, 33, 33, 1080, 33, 33, 270]
Prompts retrieved: 44256 . Total input tokens: 9790606 . Total output tokens: 8891185
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 1.631499466020614,
    "estimated_duration": 3599.7568474267637,
    "input_throughput": 1020.8403388764615,
    "output_throughput": 912.2632831013209,
    "total_throughput": 1933.1036219777823,
    "itl": 21.81891599515405,
    "ttft": 10420.498077096223,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7743,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.376466366554556,
    "arrivals": 15003,
    "finished_requests": 14972,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6316629168577492. Arrivals time: 0.054351146798580885 Scheduler time: 1.1727503649890423 Scheduler overhead time: 0.13992233201861382 Adapter cache time: 0.055674477480351925 Engine time: 0.14059555856510997 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_96_slots_16_rate_0.1-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_96_slots_16_rate_0.1-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 1080, 270, 270, 270, 270, 1080, 270, 1080, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 270, 33, 1080, 270, 33, 33, 270, 1080, 33, 270, 33, 33, 270, 270, 270, 33, 33, 1080, 270, 270, 33, 1080, 1080, 270, 1080, 1080, 270, 1080, 33, 1080, 270, 270, 270, 1080, 1080, 33, 33, 270, 33, 1080, 33, 33, 1080, 33, 270, 270, 33, 270, 1080, 1080, 1080, 270, 1080, 1080, 33, 33, 1080, 270, 1080, 33, 270, 1080, 33, 1080, 270, 33, 1080, 33, 33, 1080, 33, 33, 270]
Prompts retrieved: 44256 . Total input tokens: 9790606 . Total output tokens: 8891185
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.6444733398966491,
    "estimated_duration": 3599.745937199799,
    "input_throughput": 1020.8434328725341,
    "output_throughput": 912.2660480185244,
    "total_throughput": 1933.1094808910584,
    "itl": 21.805595560543278,
    "ttft": 10409.992359570771,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7757,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.193820137555626,
    "arrivals": 15003,
    "finished_requests": 14972,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6445838720537722. Arrivals time: 0.055832160636782646 Scheduler time: 1.185206100344658 Scheduler overhead time: 0.14091252628713846 Adapter cache time: 0.05611310759559274 Engine time: 0.13766493881121278 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_96_slots_16_rate_0.1-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_96_slots_16_rate_0.1-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 1080, 270, 270, 270, 270, 1080, 270, 1080, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 270, 33, 1080, 270, 33, 33, 270, 1080, 33, 270, 33, 33, 270, 270, 270, 33, 33, 1080, 270, 270, 33, 1080, 1080, 270, 1080, 1080, 270, 1080, 33, 1080, 270, 270, 270, 1080, 1080, 33, 33, 270, 33, 1080, 33, 33, 1080, 33, 270, 270, 33, 270, 1080, 1080, 1080, 270, 1080, 1080, 33, 33, 1080, 270, 1080, 33, 270, 1080, 33, 1080, 270, 33, 1080, 33, 33, 1080, 33, 33, 270]
Prompts retrieved: 44256 . Total input tokens: 9790606 . Total output tokens: 8891185
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.6165487440302968,
    "estimated_duration": 3599.744700329017,
    "input_throughput": 1020.843783633913,
    "output_throughput": 912.2663614727591,
    "total_throughput": 1933.110145106672,
    "itl": 21.81977764110143,
    "ttft": 10420.904997649324,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7744,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.684462817458122,
    "arrivals": 15003,
    "finished_requests": 14972,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6166449738666415. Arrivals time: 0.056069356855005026 Scheduler time: 1.1575455218553543 Scheduler overhead time: 0.14109845459461212 Adapter cache time: 0.05509978299960494 Engine time: 0.1383842690847814 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_96_slots_16_rate_0.1-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_96_slots_16_rate_0.1-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 1080, 135, 135, 135, 135, 1080, 135, 1080, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 135, 66, 1080, 135, 66, 66, 135, 1080, 66, 135, 66, 66, 135, 135, 135, 66, 66, 1080, 135, 135, 66, 1080, 1080, 135, 1080, 1080, 135, 1080, 66, 1080, 135, 135, 135, 1080, 1080, 66, 66, 135, 66, 1080, 66, 66, 1080, 66, 135, 135, 66, 135, 1080, 1080, 1080, 135, 1080, 1080, 66, 66, 1080, 135, 1080, 66, 135, 1080, 66, 1080, 135, 66, 1080, 66, 66, 1080, 66, 66, 135]
Prompts retrieved: 40992 . Total input tokens: 9052551 . Total output tokens: 8252881
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.5463258968666196,
    "estimated_duration": 3599.9353414812263,
    "input_throughput": 945.9022668442997,
    "output_throughput": 854.05478386591,
    "total_throughput": 1799.9570507102098,
    "itl": 21.647118667007817,
    "ttft": 7679.35624672762,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7709,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.593300017978265,
    "arrivals": 13896,
    "finished_requests": 13873,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5464210091158748. Arrivals time: 0.05236906139180064 Scheduler time: 1.0927621331065893 Scheduler overhead time: 0.1411978555843234 Adapter cache time: 0.054302876349538565 Engine time: 0.13718290580436587 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_96_slots_16_rate_0.1-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_96_slots_16_rate_0.1-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 1080, 135, 135, 135, 135, 1080, 135, 1080, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 135, 66, 1080, 135, 66, 66, 135, 1080, 66, 135, 66, 66, 135, 135, 135, 66, 66, 1080, 135, 135, 66, 1080, 1080, 135, 1080, 1080, 135, 1080, 66, 1080, 135, 135, 135, 1080, 1080, 66, 66, 135, 66, 1080, 66, 66, 1080, 66, 135, 135, 66, 135, 1080, 1080, 1080, 135, 1080, 1080, 66, 66, 1080, 135, 1080, 66, 135, 1080, 66, 1080, 135, 66, 1080, 66, 66, 1080, 66, 66, 135]
Prompts retrieved: 40992 . Total input tokens: 9052551 . Total output tokens: 8252881
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.5705966320820153,
    "estimated_duration": 3599.9386488405976,
    "input_throughput": 945.9013978187323,
    "output_throughput": 854.053999223068,
    "total_throughput": 1799.9553970418003,
    "itl": 21.6569911822177,
    "ttft": 7684.014851996888,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7705,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.92196194022922,
    "arrivals": 13896,
    "finished_requests": 13873,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5707007083110511. Arrivals time: 0.0543899149633944 Scheduler time: 1.1125920312479138 Scheduler overhead time: 0.14059606287628412 Adapter cache time: 0.05516348173841834 Engine time: 0.13983178231865168 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_96_slots_16_rate_0.1-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_96_slots_16_rate_0.1-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 1080, 135, 135, 135, 135, 1080, 135, 1080, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 135, 66, 1080, 135, 66, 66, 135, 1080, 66, 135, 66, 66, 135, 135, 135, 66, 66, 1080, 135, 135, 66, 1080, 1080, 135, 1080, 1080, 135, 1080, 66, 1080, 135, 135, 135, 1080, 1080, 66, 66, 135, 66, 1080, 66, 66, 1080, 66, 135, 135, 66, 135, 1080, 1080, 1080, 135, 1080, 1080, 66, 66, 1080, 135, 1080, 66, 135, 1080, 66, 1080, 135, 66, 1080, 66, 66, 1080, 66, 66, 135]
Prompts retrieved: 40992 . Total input tokens: 9052551 . Total output tokens: 8252881
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.569687610026449,
    "estimated_duration": 3599.9265668810613,
    "input_throughput": 945.8740162442044,
    "output_throughput": 853.9574190990903,
    "total_throughput": 1799.8314353432947,
    "itl": 21.657604432043232,
    "ttft": 7942.729406522717,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7702,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.99555587546893,
    "arrivals": 13896,
    "finished_requests": 13872,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5697996374219656. Arrivals time: 0.05143703008070588 Scheduler time: 1.1160505134612322 Scheduler overhead time: 0.1396079701371491 Adapter cache time: 0.05486414907500148 Engine time: 0.13933780835941434 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_96_slots_16_rate_0.1-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_96_slots_16_rate_0.1-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 1080, 135, 135, 135, 135, 1080, 135, 1080, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 135, 66, 1080, 135, 66, 66, 135, 1080, 66, 135, 66, 66, 135, 135, 135, 66, 66, 1080, 135, 135, 66, 1080, 1080, 135, 1080, 1080, 135, 1080, 66, 1080, 135, 135, 135, 1080, 1080, 66, 66, 135, 66, 1080, 66, 66, 1080, 66, 135, 135, 66, 135, 1080, 1080, 1080, 135, 1080, 1080, 66, 66, 1080, 135, 1080, 66, 135, 1080, 66, 1080, 135, 66, 1080, 66, 66, 1080, 66, 66, 135]
Prompts retrieved: 40992 . Total input tokens: 9052551 . Total output tokens: 8252881
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 1.5593167641200125,
    "estimated_duration": 3599.9188180086735,
    "input_throughput": 945.906608495024,
    "output_throughput": 854.0587039406377,
    "total_throughput": 1799.9653124356616,
    "itl": 21.648316659300512,
    "ttft": 7680.956960353151,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7710,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.03309934731442,
    "arrivals": 13896,
    "finished_requests": 13873,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5594060281291604. Arrivals time: 0.051662759855389595 Scheduler time: 1.1014268905855715 Scheduler overhead time: 0.14149993192404509 Adapter cache time: 0.05427651247009635 Engine time: 0.14155983133241534 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_96_slots_16_rate_0.1-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_96_slots_16_rate_0.1-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 1080, 135, 135, 135, 135, 1080, 135, 1080, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 135, 66, 1080, 135, 66, 66, 135, 1080, 66, 135, 66, 66, 135, 135, 135, 66, 66, 1080, 135, 135, 66, 1080, 1080, 135, 1080, 1080, 135, 1080, 66, 1080, 135, 135, 135, 1080, 1080, 66, 66, 135, 66, 1080, 66, 66, 1080, 66, 135, 135, 66, 135, 1080, 1080, 1080, 135, 1080, 1080, 66, 66, 1080, 135, 1080, 66, 135, 1080, 66, 1080, 135, 66, 1080, 66, 66, 1080, 66, 66, 135]
Prompts retrieved: 40992 . Total input tokens: 9052551 . Total output tokens: 8252881
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 1.5305946129374206,
    "estimated_duration": 3599.937296638689,
    "input_throughput": 945.9017531164973,
    "output_throughput": 854.0543200212799,
    "total_throughput": 1799.9560731377771,
    "itl": 21.65937171799352,
    "ttft": 7684.549836754692,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7708,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.29316187424482,
    "arrivals": 13896,
    "finished_requests": 13873,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5306919389404356. Arrivals time: 0.050045267678797245 Scheduler time: 1.0803216500207782 Scheduler overhead time: 0.1414138600230217 Adapter cache time: 0.0541872251778841 Engine time: 0.13623467553406954 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_96_slots_16_rate_0.1-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_96_slots_16_rate_0.1-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 1080, 135, 135, 135, 135, 1080, 135, 1080, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 135, 66, 1080, 135, 66, 66, 135, 1080, 66, 135, 66, 66, 135, 135, 135, 66, 66, 1080, 135, 135, 66, 1080, 1080, 135, 1080, 1080, 135, 1080, 66, 1080, 135, 135, 135, 1080, 1080, 66, 66, 135, 66, 1080, 66, 66, 1080, 66, 135, 135, 66, 135, 1080, 1080, 1080, 135, 1080, 1080, 66, 66, 1080, 135, 1080, 66, 135, 1080, 66, 1080, 135, 66, 1080, 66, 66, 1080, 66, 66, 135]
Prompts retrieved: 40992 . Total input tokens: 9052551 . Total output tokens: 8252881
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.5831395448185503,
    "estimated_duration": 3599.9202160587697,
    "input_throughput": 945.9062411466537,
    "output_throughput": 854.0583722619389,
    "total_throughput": 1799.9646134085924,
    "itl": 21.644244943884676,
    "ttft": 7677.646414501632,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7707,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.044317622810567,
    "arrivals": 13896,
    "finished_requests": 13873,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5832845917902887. Arrivals time: 0.052060005720704794 Scheduler time: 1.1274372600018978 Scheduler overhead time: 0.14072299748659134 Adapter cache time: 0.054875119123607874 Engine time: 0.13960524508729577 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_96_slots_16_rate_0.1-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_96_slots_16_rate_0.1-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 1080, 135, 135, 135, 135, 1080, 135, 1080, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 135, 66, 1080, 135, 66, 66, 135, 1080, 66, 135, 66, 66, 135, 135, 135, 66, 66, 1080, 135, 135, 66, 1080, 1080, 135, 1080, 1080, 135, 1080, 66, 1080, 135, 135, 135, 1080, 1080, 66, 66, 135, 66, 1080, 66, 66, 1080, 66, 135, 135, 66, 135, 1080, 1080, 1080, 135, 1080, 1080, 66, 66, 1080, 135, 1080, 66, 135, 1080, 66, 1080, 135, 66, 1080, 66, 66, 1080, 66, 66, 135]
Prompts retrieved: 40992 . Total input tokens: 9052551 . Total output tokens: 8252881
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.5732434918172657,
    "estimated_duration": 3599.940279419581,
    "input_throughput": 945.9009693763638,
    "output_throughput": 854.0536123826223,
    "total_throughput": 1799.9545817589863,
    "itl": 21.659378387384987,
    "ttft": 7684.175421909955,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7705,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.585211636161134,
    "arrivals": 13896,
    "finished_requests": 13873,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5733302407898009. Arrivals time: 0.04994387272745371 Scheduler time: 1.1177018298767507 Scheduler overhead time: 0.1415726663544774 Adapter cache time: 0.05497142067179084 Engine time: 0.14040939789265394 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_96_slots_16_rate_0.1-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_96_slots_16_rate_0.1-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 1080, 135, 135, 135, 135, 1080, 135, 1080, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 135, 33, 1080, 135, 33, 33, 135, 1080, 33, 135, 33, 33, 135, 135, 135, 33, 33, 1080, 135, 135, 33, 1080, 1080, 135, 1080, 1080, 135, 1080, 33, 1080, 135, 135, 135, 1080, 1080, 33, 33, 135, 33, 1080, 33, 33, 1080, 33, 135, 135, 33, 135, 1080, 1080, 1080, 135, 1080, 1080, 33, 33, 1080, 135, 1080, 33, 135, 1080, 33, 1080, 135, 33, 1080, 33, 33, 1080, 33, 33, 135]
Prompts retrieved: 39936 . Total input tokens: 8825272 . Total output tokens: 8039205
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.5002361750230193,
    "estimated_duration": 3599.9712871487027,
    "input_throughput": 918.5192703631177,
    "output_throughput": 823.8224039694946,
    "total_throughput": 1742.3416743326122,
    "itl": 21.44225391425059,
    "ttft": 10956.492756585787,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7563,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.146468807363938,
    "arrivals": 13527,
    "finished_requests": 13490,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5003258408978581. Arrivals time: 0.04751222673803568 Scheduler time: 1.052963183261454 Scheduler overhead time: 0.14067372400313616 Adapter cache time: 0.0532219922170043 Engine time: 0.136777778621763 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_96_slots_16_rate_0.1-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_96_slots_16_rate_0.1-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 1080, 135, 135, 135, 135, 1080, 135, 1080, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 135, 33, 1080, 135, 33, 33, 135, 1080, 33, 135, 33, 33, 135, 135, 135, 33, 33, 1080, 135, 135, 33, 1080, 1080, 135, 1080, 1080, 135, 1080, 33, 1080, 135, 135, 135, 1080, 1080, 33, 33, 135, 33, 1080, 33, 33, 1080, 33, 135, 135, 33, 135, 1080, 1080, 1080, 135, 1080, 1080, 33, 33, 1080, 135, 1080, 33, 135, 1080, 33, 1080, 135, 33, 1080, 33, 33, 1080, 33, 33, 135]
Prompts retrieved: 39936 . Total input tokens: 8825272 . Total output tokens: 8039205
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.4923604219220579,
    "estimated_duration": 3599.971534031063,
    "input_throughput": 918.5192073720069,
    "output_throughput": 823.8223474725979,
    "total_throughput": 1742.3415548446048,
    "itl": 21.45216424612743,
    "ttft": 10959.30439112983,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7567,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.465206705141345,
    "arrivals": 13527,
    "finished_requests": 13490,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4924744572490454. Arrivals time: 0.049505526665598154 Scheduler time: 1.0410566399805248 Scheduler overhead time: 0.14120032265782356 Adapter cache time: 0.05322168208658695 Engine time: 0.13805172126740217 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_96_slots_16_rate_0.1-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_96_slots_16_rate_0.1-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 1080, 135, 135, 135, 135, 1080, 135, 1080, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 135, 33, 1080, 135, 33, 33, 135, 1080, 33, 135, 33, 33, 135, 135, 135, 33, 33, 1080, 135, 135, 33, 1080, 1080, 135, 1080, 1080, 135, 1080, 33, 1080, 135, 135, 135, 1080, 1080, 33, 33, 135, 33, 1080, 33, 33, 1080, 33, 135, 135, 33, 135, 1080, 1080, 1080, 135, 1080, 1080, 33, 33, 1080, 135, 1080, 33, 135, 1080, 33, 1080, 135, 33, 1080, 33, 33, 1080, 33, 33, 135]
Prompts retrieved: 39936 . Total input tokens: 8825272 . Total output tokens: 8039205
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.5227130632847548,
    "estimated_duration": 3599.9757780188165,
    "input_throughput": 918.5181245357581,
    "output_throughput": 823.8213762738541,
    "total_throughput": 1742.3395008096122,
    "itl": 21.45308378590397,
    "ttft": 10959.380885268793,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7569,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.554682386666407,
    "arrivals": 13527,
    "finished_requests": 13490,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5228077042847872. Arrivals time: 0.04843816161155701 Scheduler time: 1.0736532341688871 Scheduler overhead time: 0.14027640456333756 Adapter cache time: 0.05405234731733799 Engine time: 0.1377390492707491 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_96_slots_16_rate_0.1-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_96_slots_16_rate_0.1-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 1080, 135, 135, 135, 135, 1080, 135, 1080, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 135, 33, 1080, 135, 33, 33, 135, 1080, 33, 135, 33, 33, 135, 135, 135, 33, 33, 1080, 135, 135, 33, 1080, 1080, 135, 1080, 1080, 135, 1080, 33, 1080, 135, 135, 135, 1080, 1080, 33, 33, 135, 33, 1080, 33, 33, 1080, 33, 135, 135, 33, 135, 1080, 1080, 1080, 135, 1080, 1080, 33, 33, 1080, 135, 1080, 33, 135, 1080, 33, 1080, 135, 33, 1080, 33, 33, 1080, 33, 33, 135]
Prompts retrieved: 39936 . Total input tokens: 8825272 . Total output tokens: 8039205
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 1.4917790102772415,
    "estimated_duration": 3599.981598835828,
    "input_throughput": 918.5510840025825,
    "output_throughput": 823.8336554162065,
    "total_throughput": 1742.384739418789,
    "itl": 21.44627235488823,
    "ttft": 10693.390719053017,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7561,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.590850615921664,
    "arrivals": 13527,
    "finished_requests": 13491,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.491867434233427. Arrivals time: 0.0486402940005064 Scheduler time: 1.0433753826655447 Scheduler overhead time: 0.14057974284514785 Adapter cache time: 0.0536863231100142 Engine time: 0.13731085043400526 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_96_slots_16_rate_0.1-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_96_slots_16_rate_0.1-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 1080, 135, 135, 135, 135, 1080, 135, 1080, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 135, 33, 1080, 135, 33, 33, 135, 1080, 33, 135, 33, 33, 135, 135, 135, 33, 33, 1080, 135, 135, 33, 1080, 1080, 135, 1080, 1080, 135, 1080, 33, 1080, 135, 135, 135, 1080, 1080, 33, 33, 135, 33, 1080, 33, 33, 1080, 33, 135, 135, 33, 135, 1080, 1080, 1080, 135, 1080, 1080, 33, 33, 1080, 135, 1080, 33, 135, 1080, 33, 1080, 135, 33, 1080, 33, 33, 1080, 33, 33, 135]
Prompts retrieved: 39936 . Total input tokens: 8825272 . Total output tokens: 8039205
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 1.5097494069486856,
    "estimated_duration": 3599.976206194854,
    "input_throughput": 918.5180152885218,
    "output_throughput": 823.8212782897141,
    "total_throughput": 1742.339293578236,
    "itl": 21.45193384678389,
    "ttft": 10962.309738400449,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7562,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.79603168848797,
    "arrivals": 13527,
    "finished_requests": 13490,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5098903067409992. Arrivals time: 0.05015273252502084 Scheduler time: 1.055964746978134 Scheduler overhead time: 0.14071955485269427 Adapter cache time: 0.05382913816720247 Engine time: 0.14042615238577127 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_96_slots_16_rate_0.1-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_96_slots_16_rate_0.1-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 1080, 135, 135, 135, 135, 1080, 135, 1080, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 135, 33, 1080, 135, 33, 33, 135, 1080, 33, 135, 33, 33, 135, 135, 135, 33, 33, 1080, 135, 135, 33, 1080, 1080, 135, 1080, 1080, 135, 1080, 33, 1080, 135, 135, 135, 1080, 1080, 33, 33, 135, 33, 1080, 33, 33, 1080, 33, 135, 135, 33, 135, 1080, 1080, 1080, 135, 1080, 1080, 33, 33, 1080, 135, 1080, 33, 135, 1080, 33, 1080, 135, 33, 1080, 33, 33, 1080, 33, 33, 135]
Prompts retrieved: 39936 . Total input tokens: 8825272 . Total output tokens: 8039205
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.5059988861903548,
    "estimated_duration": 3599.983648001131,
    "input_throughput": 918.5505611493714,
    "output_throughput": 823.8331864775927,
    "total_throughput": 1742.3837476269641,
    "itl": 21.439239187771413,
    "ttft": 10690.354466324854,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7564,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.616740430639698,
    "arrivals": 13527,
    "finished_requests": 13491,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5060895448550582. Arrivals time: 0.048890594858676195 Scheduler time: 1.0533334352076054 Scheduler overhead time: 0.14154769713059068 Adapter cache time: 0.05387247679755092 Engine time: 0.13936416245996952 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_96_slots_16_rate_0.1-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_96_slots_16_rate_0.1-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 1080, 135, 135, 135, 135, 1080, 135, 1080, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 135, 33, 1080, 135, 33, 33, 135, 1080, 33, 135, 33, 33, 135, 135, 135, 33, 33, 1080, 135, 135, 33, 1080, 1080, 135, 1080, 1080, 135, 1080, 33, 1080, 135, 135, 135, 1080, 1080, 33, 33, 135, 33, 1080, 33, 33, 1080, 33, 135, 135, 33, 135, 1080, 1080, 1080, 135, 1080, 1080, 33, 33, 1080, 135, 1080, 33, 135, 1080, 33, 1080, 135, 33, 1080, 33, 33, 1080, 33, 33, 135]
Prompts retrieved: 39936 . Total input tokens: 8825272 . Total output tokens: 8039205
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.4956805054098368,
    "estimated_duration": 3599.9936008153395,
    "input_throughput": 918.5480216551139,
    "output_throughput": 823.830908846143,
    "total_throughput": 1742.378930501257,
    "itl": 21.456644479728524,
    "ttft": 10695.939730847545,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7566,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.11169537655797,
    "arrivals": 13527,
    "finished_requests": 13491,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.495773961301893. Arrivals time: 0.04836433473974466 Scheduler time: 1.050164938904345 Scheduler overhead time: 0.13984678452834487 Adapter cache time: 0.0535445767454803 Engine time: 0.1354312221519649 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_96_slots_16_rate_0.1-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_96_slots_16_rate_0.1-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 1080, 66, 66, 66, 66, 1080, 66, 1080, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 66, 33, 1080, 66, 33, 33, 66, 1080, 33, 66, 33, 33, 66, 66, 66, 33, 33, 1080, 66, 66, 33, 1080, 1080, 66, 1080, 1080, 66, 1080, 33, 1080, 66, 66, 66, 1080, 1080, 33, 33, 66, 33, 1080, 33, 33, 1080, 33, 66, 66, 33, 66, 1080, 1080, 1080, 66, 1080, 1080, 33, 33, 1080, 66, 1080, 33, 66, 1080, 33, 1080, 66, 33, 1080, 33, 33, 1080, 33, 33, 66]
Prompts retrieved: 37728 . Total input tokens: 8336361 . Total output tokens: 7580355
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.4550966508686543,
    "estimated_duration": 3599.8281946355582,
    "input_throughput": 854.0971495755699,
    "output_throughput": 775.1761609507886,
    "total_throughput": 1629.2733105263585,
    "itl": 21.298794869664167,
    "ttft": 5314.38572612028,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7021,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.487684450151846,
    "arrivals": 12728,
    "finished_requests": 12711,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4551898068748415. Arrivals time: 0.046881251502782106 Scheduler time: 0.9938046294264495 Scheduler overhead time: 0.1490459074266255 Adapter cache time: 0.052234206814318895 Engine time: 0.14232409792020917 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_96_slots_16_rate_0.1-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_96_slots_16_rate_0.1-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 1080, 66, 66, 66, 66, 1080, 66, 1080, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 66, 33, 1080, 66, 33, 33, 66, 1080, 33, 66, 33, 33, 66, 66, 66, 33, 33, 1080, 66, 66, 33, 1080, 1080, 66, 1080, 1080, 66, 1080, 33, 1080, 66, 66, 66, 1080, 1080, 33, 33, 66, 33, 1080, 33, 33, 1080, 33, 66, 66, 33, 66, 1080, 1080, 1080, 66, 1080, 1080, 33, 33, 1080, 66, 1080, 33, 66, 1080, 33, 1080, 66, 33, 1080, 33, 33, 1080, 33, 33, 66]
Prompts retrieved: 37728 . Total input tokens: 8336361 . Total output tokens: 7580355
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.4292059456929564,
    "estimated_duration": 3599.8333238271707,
    "input_throughput": 854.0959326225774,
    "output_throughput": 775.1750564476893,
    "total_throughput": 1629.2709890702668,
    "itl": 21.30835952994213,
    "ttft": 5315.872395839021,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7028,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.73711993043418,
    "arrivals": 12728,
    "finished_requests": 12711,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4292925149202347. Arrivals time: 0.045446349773555994 Scheduler time: 0.9829377676360309 Scheduler overhead time: 0.13954256987199187 Adapter cache time: 0.0521295415237546 Engine time: 0.14035151107236743 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_96_slots_16_rate_0.1-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_96_slots_16_rate_0.1-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 1080, 66, 66, 66, 66, 1080, 66, 1080, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 66, 33, 1080, 66, 33, 33, 66, 1080, 33, 66, 33, 33, 66, 66, 66, 33, 33, 1080, 66, 66, 33, 1080, 1080, 66, 1080, 1080, 66, 1080, 33, 1080, 66, 66, 66, 1080, 1080, 33, 33, 66, 33, 1080, 33, 33, 1080, 33, 66, 66, 33, 66, 1080, 1080, 1080, 66, 1080, 1080, 33, 33, 1080, 66, 1080, 33, 66, 1080, 33, 1080, 66, 33, 1080, 33, 33, 1080, 33, 33, 66]
Prompts retrieved: 37728 . Total input tokens: 8336361 . Total output tokens: 7580355
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.4322832417674363,
    "estimated_duration": 3599.8343636966783,
    "input_throughput": 854.09568590336,
    "output_throughput": 775.1748325260244,
    "total_throughput": 1629.2705184293843,
    "itl": 21.30870014386422,
    "ttft": 5315.898107756267,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7027,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.80830513970894,
    "arrivals": 12728,
    "finished_requests": 12711,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4324176227673888. Arrivals time: 0.04435016633942723 Scheduler time: 0.9812724776566029 Scheduler overhead time: 0.14489014446735382 Adapter cache time: 0.052276380360126495 Engine time: 0.14009556407108903 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_96_slots_16_rate_0.1-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_96_slots_16_rate_0.1-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 1080, 66, 66, 66, 66, 1080, 66, 1080, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 66, 33, 1080, 66, 33, 33, 66, 1080, 33, 66, 33, 33, 66, 66, 66, 33, 33, 1080, 66, 66, 33, 1080, 1080, 66, 1080, 1080, 66, 1080, 33, 1080, 66, 66, 66, 1080, 1080, 33, 33, 66, 33, 1080, 33, 33, 1080, 33, 66, 66, 33, 66, 1080, 1080, 1080, 66, 1080, 1080, 33, 33, 1080, 66, 1080, 33, 66, 1080, 33, 1080, 66, 33, 1080, 33, 33, 1080, 33, 33, 66]
Prompts retrieved: 37728 . Total input tokens: 8336361 . Total output tokens: 7580355
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 1.432590392883867,
    "estimated_duration": 3599.8364446136497,
    "input_throughput": 854.0951921858716,
    "output_throughput": 775.1743844294261,
    "total_throughput": 1629.2695766152979,
    "itl": 21.30357782624503,
    "ttft": 5314.9771874477465,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7024,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.90224875791639,
    "arrivals": 12728,
    "finished_requests": 12711,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.432682408951223. Arrivals time: 0.04568280838429928 Scheduler time: 0.9884877949953079 Scheduler overhead time: 0.14042936637997627 Adapter cache time: 0.051972013898193836 Engine time: 0.13727894518524408 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_96_slots_16_rate_0.1-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_96_slots_16_rate_0.1-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 1080, 66, 66, 66, 66, 1080, 66, 1080, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 66, 33, 1080, 66, 33, 33, 66, 1080, 33, 66, 33, 33, 66, 66, 66, 33, 33, 1080, 66, 66, 33, 1080, 1080, 66, 1080, 1080, 66, 1080, 33, 1080, 66, 66, 66, 1080, 1080, 33, 33, 66, 33, 1080, 33, 33, 1080, 33, 66, 66, 33, 66, 1080, 1080, 1080, 66, 1080, 1080, 33, 33, 1080, 66, 1080, 33, 66, 1080, 33, 1080, 66, 33, 1080, 33, 33, 1080, 33, 33, 66]
Prompts retrieved: 37728 . Total input tokens: 8336361 . Total output tokens: 7580355
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 1.4259425839409232,
    "estimated_duration": 3599.81642355029,
    "input_throughput": 854.0999423986453,
    "output_throughput": 775.1786957091248,
    "total_throughput": 1629.2786381077701,
    "itl": 21.310028436327194,
    "ttft": 5316.1662277789155,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7025,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.05452021142363,
    "arrivals": 12728,
    "finished_requests": 12711,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4260558667592704. Arrivals time: 0.046618889551609755 Scheduler time: 0.9799195509403944 Scheduler overhead time: 0.14187044138088822 Adapter cache time: 0.05164726683869958 Engine time: 0.136698295827955 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_96_slots_16_rate_0.1-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_96_slots_16_rate_0.1-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 1080, 66, 66, 66, 66, 1080, 66, 1080, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 66, 33, 1080, 66, 33, 33, 66, 1080, 33, 66, 33, 33, 66, 66, 66, 33, 33, 1080, 66, 66, 33, 1080, 1080, 66, 1080, 1080, 66, 1080, 33, 1080, 66, 66, 66, 1080, 1080, 33, 33, 66, 33, 1080, 33, 33, 1080, 33, 66, 66, 33, 66, 1080, 1080, 1080, 66, 1080, 1080, 33, 33, 1080, 66, 1080, 33, 66, 1080, 33, 1080, 66, 33, 1080, 33, 33, 1080, 33, 33, 66]
Prompts retrieved: 37728 . Total input tokens: 8336361 . Total output tokens: 7580355
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.4329256801865995,
    "estimated_duration": 3599.824266916688,
    "input_throughput": 854.0980814692521,
    "output_throughput": 775.1770067348629,
    "total_throughput": 1629.2750882041148,
    "itl": 21.29695887364649,
    "ttft": 5313.697443865237,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7029,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.017063522867566,
    "arrivals": 12728,
    "finished_requests": 12711,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4330236441455781. Arrivals time: 0.04744981322437525 Scheduler time: 0.9808056112378836 Scheduler overhead time: 0.14151544217020273 Adapter cache time: 0.05216014385223389 Engine time: 0.14171574637293816 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_96_slots_16_rate_0.1-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_96_slots_16_rate_0.1-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 1080, 66, 66, 66, 66, 1080, 66, 1080, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 66, 33, 1080, 66, 33, 33, 66, 1080, 33, 66, 33, 33, 66, 66, 66, 33, 33, 1080, 66, 66, 33, 1080, 1080, 66, 1080, 1080, 66, 1080, 33, 1080, 66, 66, 66, 1080, 1080, 33, 33, 66, 33, 1080, 33, 33, 1080, 33, 66, 66, 33, 66, 1080, 1080, 1080, 66, 1080, 1080, 33, 33, 1080, 66, 1080, 33, 66, 1080, 33, 1080, 66, 33, 1080, 33, 33, 1080, 33, 33, 66]
Prompts retrieved: 37728 . Total input tokens: 8336361 . Total output tokens: 7580355
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.434143722988665,
    "estimated_duration": 3599.83344023318,
    "input_throughput": 854.0959050041054,
    "output_throughput": 775.1750313812421,
    "total_throughput": 1629.2709363853473,
    "itl": 21.311815468607332,
    "ttft": 5316.329202979888,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7028,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.342326870856745,
    "arrivals": 12728,
    "finished_requests": 12711,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4343334357254207. Arrivals time: 0.047523577231913805 Scheduler time: 0.985651068855077 Scheduler overhead time: 0.141077421605587 Adapter cache time: 0.05212258826941252 Engine time: 0.13893647585064173 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_96_slots_16_rate_0.05-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_96_slots_16_rate_0.05-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 135, 540, 135, 135, 540, 270, 540, 270, 540, 540, 270, 135, 540, 270, 135, 135, 270, 540, 135, 270, 135, 135, 270, 270, 270, 135, 135, 540, 270, 270, 135, 540, 540, 270, 540, 540, 270, 540, 135, 540, 270, 270, 270, 540, 540, 135, 135, 270, 135, 540, 135, 135, 540, 135, 270, 270, 135, 270, 540, 540, 540, 270, 540, 540, 135, 135, 540, 270, 540, 135, 270, 540, 135, 540, 270, 135, 540, 135, 135, 540, 135, 135, 270]
Prompts retrieved: 30240 . Total input tokens: 6671644 . Total output tokens: 6073603
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.2628979268483818,
    "estimated_duration": 3599.878805417063,
    "input_throughput": 688.5659584622667,
    "output_throughput": 616.9654924654294,
    "total_throughput": 1305.5314509276961,
    "itl": 20.766441320939716,
    "ttft": 5822.499422851408,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7853,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.034010253104725,
    "arrivals": 10175,
    "finished_requests": 10160,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2631069938652217. Arrivals time: 0.04071291862055659 Scheduler time: 0.8174910941161215 Scheduler overhead time: 0.14187209634110332 Adapter cache time: 0.05497839441522956 Engine time: 0.1378945684991777 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_96_slots_16_rate_0.05-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_96_slots_16_rate_0.05-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 135, 540, 135, 135, 540, 270, 540, 270, 540, 540, 270, 135, 540, 270, 135, 135, 270, 540, 135, 270, 135, 135, 270, 270, 270, 135, 135, 540, 270, 270, 135, 540, 540, 270, 540, 540, 270, 540, 135, 540, 270, 270, 270, 540, 540, 135, 135, 270, 135, 540, 135, 135, 540, 135, 270, 270, 135, 270, 540, 540, 540, 270, 540, 540, 135, 135, 540, 270, 540, 135, 270, 540, 135, 540, 270, 135, 540, 135, 135, 540, 135, 135, 270]
Prompts retrieved: 30240 . Total input tokens: 6671644 . Total output tokens: 6073603
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.2374090203084052,
    "estimated_duration": 3599.894976717494,
    "input_throughput": 688.5628653145353,
    "output_throughput": 616.9627209583718,
    "total_throughput": 1305.5255862729073,
    "itl": 20.777295208305972,
    "ttft": 5824.393020779999,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7850,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.457259467281457,
    "arrivals": 10175,
    "finished_requests": 10160,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2375040841288865. Arrivals time: 0.04028755100443959 Scheduler time: 0.7971939132548869 Scheduler overhead time: 0.14100519241765141 Adapter cache time: 0.0537071144208312 Engine time: 0.13523392425850034 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_96_slots_16_rate_0.05-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_96_slots_16_rate_0.05-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 135, 540, 135, 135, 540, 270, 540, 270, 540, 540, 270, 135, 540, 270, 135, 135, 270, 540, 135, 270, 135, 135, 270, 270, 270, 135, 135, 540, 270, 270, 135, 540, 540, 270, 540, 540, 270, 540, 135, 540, 270, 270, 270, 540, 540, 135, 135, 270, 135, 540, 135, 135, 540, 135, 270, 270, 135, 270, 540, 540, 540, 270, 540, 540, 135, 135, 540, 270, 540, 135, 270, 540, 135, 540, 270, 135, 540, 135, 135, 540, 135, 135, 270]
Prompts retrieved: 30240 . Total input tokens: 6671644 . Total output tokens: 6073603
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.2469809437170625,
    "estimated_duration": 3599.8963690711207,
    "input_throughput": 688.5625989949237,
    "output_throughput": 616.9624823319799,
    "total_throughput": 1305.5250813269035,
    "itl": 20.777668806044897,
    "ttft": 5824.200054138499,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7847,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.520166239701343,
    "arrivals": 10175,
    "finished_requests": 10160,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.247077508829534. Arrivals time: 0.040435478556901217 Scheduler time: 0.8034361097961664 Scheduler overhead time: 0.14323816169053316 Adapter cache time: 0.0541739403270185 Engine time: 0.1356894806958735 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_96_slots_16_rate_0.05-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_96_slots_16_rate_0.05-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 135, 540, 135, 135, 540, 270, 540, 270, 540, 540, 270, 135, 540, 270, 135, 135, 270, 540, 135, 270, 135, 135, 270, 270, 270, 135, 135, 540, 270, 270, 135, 540, 540, 270, 540, 540, 270, 540, 135, 540, 270, 270, 270, 540, 540, 135, 135, 270, 135, 540, 135, 135, 540, 135, 270, 270, 135, 270, 540, 540, 540, 270, 540, 540, 135, 135, 540, 270, 540, 135, 270, 540, 135, 540, 270, 135, 540, 135, 135, 540, 135, 135, 270]
Prompts retrieved: 30240 . Total input tokens: 6671644 . Total output tokens: 6073603
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 1.241546920966357,
    "estimated_duration": 3599.8944852847235,
    "input_throughput": 688.5629593123894,
    "output_throughput": 616.962805181868,
    "total_throughput": 1305.5257644942574,
    "itl": 20.77087143726383,
    "ttft": 5823.435664151396,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7854,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.48736511824971,
    "arrivals": 10175,
    "finished_requests": 10160,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2417135289870203. Arrivals time: 0.04091645497828722 Scheduler time: 0.7965489467605948 Scheduler overhead time: 0.14140187250450253 Adapter cache time: 0.05350988311693072 Engine time: 0.13641079375520349 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_96_slots_16_rate_0.05-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_96_slots_16_rate_0.05-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 135, 540, 135, 135, 540, 270, 540, 270, 540, 540, 270, 135, 540, 270, 135, 135, 270, 540, 135, 270, 135, 135, 270, 270, 270, 135, 135, 540, 270, 270, 135, 540, 540, 270, 540, 540, 270, 540, 135, 540, 270, 270, 270, 540, 540, 135, 135, 270, 135, 540, 135, 135, 540, 135, 270, 270, 135, 270, 540, 540, 540, 270, 540, 540, 135, 135, 540, 270, 540, 135, 270, 540, 135, 540, 270, 135, 540, 135, 135, 540, 135, 135, 270]
Prompts retrieved: 30240 . Total input tokens: 6671644 . Total output tokens: 6073603
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 1.2573811202310026,
    "estimated_duration": 3599.897357916804,
    "input_throughput": 688.5624098555994,
    "output_throughput": 616.9623128602904,
    "total_throughput": 1305.5247227158898,
    "itl": 20.779361573649027,
    "ttft": 5824.979239802711,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7848,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.826322109865906,
    "arrivals": 10175,
    "finished_requests": 10160,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.257464786991477. Arrivals time: 0.03969354601576924 Scheduler time: 0.8149372488260269 Scheduler overhead time: 0.14133200235664845 Adapter cache time: 0.05441712494939566 Engine time: 0.13736010901629925 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_96_slots_16_rate_0.05-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_96_slots_16_rate_0.05-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 135, 540, 135, 135, 540, 270, 540, 270, 540, 540, 270, 135, 540, 270, 135, 135, 270, 540, 135, 270, 135, 135, 270, 270, 270, 135, 135, 540, 270, 270, 135, 540, 540, 270, 540, 540, 270, 540, 135, 540, 270, 270, 270, 540, 540, 135, 135, 270, 135, 540, 135, 135, 540, 135, 270, 270, 135, 270, 540, 540, 540, 270, 540, 540, 135, 135, 540, 270, 540, 135, 270, 540, 135, 540, 270, 135, 540, 135, 135, 540, 135, 135, 270]
Prompts retrieved: 30240 . Total input tokens: 6671644 . Total output tokens: 6073603
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.2315281592309475,
    "estimated_duration": 3599.8840768432506,
    "input_throughput": 688.5649501729587,
    "output_throughput": 616.9645890229895,
    "total_throughput": 1305.529539195948,
    "itl": 20.63051175304548,
    "ttft": 5593.546643783251,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7889,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.588506776482582,
    "arrivals": 10175,
    "finished_requests": 10160,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2316073351539671. Arrivals time: 0.03697533858940005 Scheduler time: 0.791309479624033 Scheduler overhead time: 0.14352759812027216 Adapter cache time: 0.05377593915909529 Engine time: 0.1358207226730883 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_96_slots_16_rate_0.05-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_96_slots_16_rate_0.05-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 135, 540, 135, 135, 540, 270, 540, 270, 540, 540, 270, 135, 540, 270, 135, 135, 270, 540, 135, 270, 135, 135, 270, 270, 270, 135, 135, 540, 270, 270, 135, 540, 540, 270, 540, 540, 270, 540, 135, 540, 270, 270, 270, 540, 540, 135, 135, 270, 135, 540, 135, 135, 540, 135, 270, 270, 135, 270, 540, 540, 540, 270, 540, 540, 135, 135, 540, 270, 540, 135, 270, 540, 135, 540, 270, 135, 540, 135, 135, 540, 135, 135, 270]
Prompts retrieved: 30240 . Total input tokens: 6671644 . Total output tokens: 6073603
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.2452155211940408,
    "estimated_duration": 3599.8793275656153,
    "input_throughput": 688.5658585884416,
    "output_throughput": 616.9654029769746,
    "total_throughput": 1305.5312615654161,
    "itl": 20.779209781907873,
    "ttft": 5825.330228117496,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7850,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.13995718307574,
    "arrivals": 10175,
    "finished_requests": 10160,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2453021090477705. Arrivals time: 0.03878828277811408 Scheduler time: 0.804670786485076 Scheduler overhead time: 0.14172466099262238 Adapter cache time: 0.053846701979637146 Engine time: 0.1364156841300428 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_96_slots_16_rate_0.05-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_96_slots_16_rate_0.05-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 66, 540, 66, 66, 540, 270, 540, 270, 540, 540, 270, 66, 540, 270, 66, 66, 270, 540, 66, 270, 66, 66, 270, 270, 270, 66, 66, 540, 270, 270, 66, 540, 540, 270, 540, 540, 270, 540, 66, 540, 270, 270, 270, 540, 540, 66, 66, 270, 66, 540, 66, 66, 540, 66, 270, 270, 66, 270, 540, 540, 540, 270, 540, 540, 66, 66, 540, 270, 540, 66, 270, 540, 66, 540, 270, 66, 540, 66, 66, 540, 66, 66, 270]
Prompts retrieved: 28032 . Total input tokens: 6188869 . Total output tokens: 5619558
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.1876323870383203,
    "estimated_duration": 3599.984287286366,
    "input_throughput": 647.0842131802608,
    "output_throughput": 571.1680484999953,
    "total_throughput": 1218.252261680256,
    "itl": 20.450187529454666,
    "ttft": 6317.953739822372,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7186,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.992664927900915,
    "arrivals": 9494,
    "finished_requests": 9478,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.187710190191865. Arrivals time: 0.037912136409431696 Scheduler time: 0.7469698879867792 Scheduler overhead time: 0.14246513228863478 Adapter cache time: 0.05135310487821698 Engine time: 0.1384680261835456 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_96_slots_16_rate_0.05-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_96_slots_16_rate_0.05-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 66, 540, 66, 66, 540, 270, 540, 270, 540, 540, 270, 66, 540, 270, 66, 66, 270, 540, 66, 270, 66, 66, 270, 270, 270, 66, 66, 540, 270, 270, 66, 540, 540, 270, 540, 540, 270, 540, 66, 540, 270, 270, 270, 540, 540, 66, 66, 270, 66, 540, 66, 66, 540, 66, 270, 270, 66, 270, 540, 540, 540, 270, 540, 540, 66, 66, 540, 270, 540, 66, 270, 540, 66, 540, 270, 66, 540, 66, 66, 540, 66, 66, 270]
Prompts retrieved: 28032 . Total input tokens: 6188869 . Total output tokens: 5619558
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.1806759061291814,
    "estimated_duration": 3599.996254416942,
    "input_throughput": 647.0820621387803,
    "output_throughput": 571.166149819515,
    "total_throughput": 1218.2482119582953,
    "itl": 20.457149166713453,
    "ttft": 6318.908135050018,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7187,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.262795151491588,
    "arrivals": 9494,
    "finished_requests": 9478,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1807850641198456. Arrivals time: 0.03742695041000843 Scheduler time: 0.7413896755315363 Scheduler overhead time: 0.14343621162697673 Adapter cache time: 0.051070323679596186 Engine time: 0.13663689233362675 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_96_slots_16_rate_0.05-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_96_slots_16_rate_0.05-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 66, 540, 66, 66, 540, 270, 540, 270, 540, 540, 270, 66, 540, 270, 66, 66, 270, 540, 66, 270, 66, 66, 270, 270, 270, 66, 66, 540, 270, 270, 66, 540, 540, 270, 540, 540, 270, 540, 66, 540, 270, 270, 270, 540, 540, 66, 66, 270, 66, 540, 66, 66, 540, 66, 270, 270, 66, 270, 540, 540, 540, 270, 540, 540, 66, 66, 540, 270, 540, 66, 270, 540, 66, 540, 270, 66, 540, 66, 66, 540, 66, 66, 270]
Prompts retrieved: 28032 . Total input tokens: 6188869 . Total output tokens: 5619558
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.186253354884684,
    "estimated_duration": 3599.9957842439385,
    "input_throughput": 647.082146650134,
    "output_throughput": 571.1662244159646,
    "total_throughput": 1218.2483710660986,
    "itl": 20.45995769311197,
    "ttft": 6318.725131114447,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7186,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.333368830997212,
    "arrivals": 9494,
    "finished_requests": 9478,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1863485570065677. Arrivals time: 0.03849833086133003 Scheduler time: 0.7444680938497186 Scheduler overhead time: 0.14397449744865298 Adapter cache time: 0.051474661100655794 Engine time: 0.13662134343758225 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_96_slots_16_rate_0.05-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_96_slots_16_rate_0.05-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 66, 540, 66, 66, 540, 270, 540, 270, 540, 540, 270, 66, 540, 270, 66, 66, 270, 540, 66, 270, 66, 66, 270, 270, 270, 66, 66, 540, 270, 270, 66, 540, 540, 270, 540, 540, 270, 540, 66, 540, 270, 270, 270, 540, 540, 66, 66, 270, 66, 540, 66, 66, 540, 66, 270, 270, 66, 270, 540, 540, 540, 270, 540, 540, 66, 66, 540, 270, 540, 66, 270, 540, 66, 540, 270, 66, 540, 66, 66, 540, 66, 66, 270]
Prompts retrieved: 28032 . Total input tokens: 6188869 . Total output tokens: 5619558
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 1.1829035547561944,
    "estimated_duration": 3599.9908477531435,
    "input_throughput": 647.0830339621288,
    "output_throughput": 571.1670076281806,
    "total_throughput": 1218.2500415903094,
    "itl": 20.4516522433875,
    "ttft": 6318.201779894825,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7190,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.420252658747312,
    "arrivals": 9494,
    "finished_requests": 9478,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.182996730785817. Arrivals time: 0.03582113888114691 Scheduler time: 0.7438757023774087 Scheduler overhead time: 0.14277714770287275 Adapter cache time: 0.05141640966758132 Engine time: 0.13815388130024076 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_96_slots_16_rate_0.05-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_96_slots_16_rate_0.05-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 66, 540, 66, 66, 540, 270, 540, 270, 540, 540, 270, 66, 540, 270, 66, 66, 270, 540, 66, 270, 66, 66, 270, 270, 270, 66, 66, 540, 270, 270, 66, 540, 540, 270, 540, 540, 270, 540, 66, 540, 270, 270, 270, 540, 540, 66, 66, 270, 66, 540, 66, 66, 540, 66, 270, 270, 66, 270, 540, 540, 540, 270, 540, 540, 66, 66, 540, 270, 540, 66, 270, 540, 66, 540, 270, 66, 540, 66, 66, 540, 66, 66, 270]
Prompts retrieved: 28032 . Total input tokens: 6188869 . Total output tokens: 5619558
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 1.188695783726871,
    "estimated_duration": 3599.9900819156883,
    "input_throughput": 647.0831716181814,
    "output_throughput": 571.167129134373,
    "total_throughput": 1218.2503007525543,
    "itl": 20.459913477292588,
    "ttft": 6319.044093571475,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7187,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.598946242014744,
    "arrivals": 9494,
    "finished_requests": 9478,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1887964489869773. Arrivals time: 0.03812239924445748 Scheduler time: 0.745998227968812 Scheduler overhead time: 0.14229325903579593 Adapter cache time: 0.051752024330198765 Engine time: 0.13980653136968613 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_96_slots_16_rate_0.05-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_96_slots_16_rate_0.05-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 66, 540, 66, 66, 540, 270, 540, 270, 540, 540, 270, 66, 540, 270, 66, 66, 270, 540, 66, 270, 66, 66, 270, 270, 270, 66, 66, 540, 270, 270, 66, 540, 540, 270, 540, 540, 270, 540, 66, 540, 270, 270, 270, 540, 540, 66, 66, 270, 66, 540, 66, 66, 540, 66, 270, 270, 66, 270, 540, 540, 540, 270, 540, 540, 66, 66, 540, 270, 540, 66, 270, 540, 66, 540, 270, 66, 540, 66, 66, 540, 66, 66, 270]
Prompts retrieved: 28032 . Total input tokens: 6188869 . Total output tokens: 5619558
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.2061226246878505,
    "estimated_duration": 3599.991706346676,
    "input_throughput": 647.0828796336322,
    "output_throughput": 571.1668714055616,
    "total_throughput": 1218.2497510391936,
    "itl": 20.44641617461415,
    "ttft": 6317.703631479376,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7186,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.486501419167052,
    "arrivals": 9494,
    "finished_requests": 9478,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.206211821641773. Arrivals time: 0.036320912186056376 Scheduler time: 0.7638686243444681 Scheduler overhead time: 0.14258172223344445 Adapter cache time: 0.05191497877240181 Engine time: 0.14070025272667408 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_96_slots_16_rate_0.05-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_96_slots_16_rate_0.05-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 66, 540, 66, 66, 540, 270, 540, 270, 540, 540, 270, 66, 540, 270, 66, 66, 270, 540, 66, 270, 66, 66, 270, 270, 270, 66, 66, 540, 270, 270, 66, 540, 540, 270, 540, 540, 270, 540, 66, 540, 270, 270, 270, 540, 540, 66, 66, 270, 66, 540, 66, 66, 540, 66, 270, 270, 66, 270, 540, 540, 540, 270, 540, 540, 66, 66, 540, 270, 540, 66, 270, 540, 66, 540, 270, 66, 540, 66, 66, 540, 66, 66, 270]
Prompts retrieved: 28032 . Total input tokens: 6188869 . Total output tokens: 5619558
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.1884650490246713,
    "estimated_duration": 3599.9921865138763,
    "input_throughput": 647.0827933256741,
    "output_throughput": 571.1667952232858,
    "total_throughput": 1218.2495885489598,
    "itl": 20.463320012619732,
    "ttft": 6319.342548507315,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7189,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.88881956178497,
    "arrivals": 9494,
    "finished_requests": 9478,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1885458920150995. Arrivals time: 0.03743472741916776 Scheduler time: 0.7463114401325583 Scheduler overhead time: 0.1455021626316011 Adapter cache time: 0.05102004576474428 Engine time: 0.13700769189745188 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_96_slots_16_rate_0.05-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_96_slots_16_rate_0.05-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 33, 540, 33, 33, 540, 270, 540, 270, 540, 540, 270, 33, 540, 270, 33, 33, 270, 540, 33, 270, 33, 33, 270, 270, 270, 33, 33, 540, 270, 270, 33, 540, 540, 270, 540, 540, 270, 540, 33, 540, 270, 270, 270, 540, 540, 33, 33, 270, 33, 540, 33, 33, 540, 33, 270, 270, 33, 270, 540, 540, 540, 270, 540, 540, 33, 33, 540, 270, 540, 33, 270, 540, 33, 540, 270, 33, 540, 33, 33, 540, 33, 33, 270]
Prompts retrieved: 26976 . Total input tokens: 5949445 . Total output tokens: 5404596
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.164858526084572,
    "estimated_duration": 3599.9270232065205,
    "input_throughput": 623.5784740993118,
    "output_throughput": 558.1140914935536,
    "total_throughput": 1181.6925655928653,
    "itl": 20.399154716434523,
    "ttft": 4914.859670772804,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6737,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.61850593087466,
    "arrivals": 9096,
    "finished_requests": 9084,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1649857140146196. Arrivals time: 0.03686781786382198 Scheduler time: 0.7254244443029165 Scheduler overhead time: 0.14297225885093212 Adapter cache time: 0.049990642350167036 Engine time: 0.13834951166063547 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_96_slots_16_rate_0.05-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_96_slots_16_rate_0.05-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 33, 540, 33, 33, 540, 270, 540, 270, 540, 540, 270, 33, 540, 270, 33, 33, 270, 540, 33, 270, 33, 33, 270, 270, 270, 33, 33, 540, 270, 270, 33, 540, 540, 270, 540, 540, 270, 540, 33, 540, 270, 270, 270, 540, 540, 33, 33, 270, 33, 540, 33, 33, 540, 33, 270, 270, 33, 270, 540, 540, 540, 270, 540, 540, 33, 33, 540, 270, 540, 33, 270, 540, 33, 540, 270, 33, 540, 33, 33, 540, 33, 33, 270]
Prompts retrieved: 26976 . Total input tokens: 5949445 . Total output tokens: 5404596
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.166416303254664,
    "estimated_duration": 3599.939556815632,
    "input_throughput": 623.5763030381811,
    "output_throughput": 558.1121483543003,
    "total_throughput": 1181.6884513924815,
    "itl": 20.405536656404923,
    "ttft": 4915.440585931625,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6735,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.733553454674826,
    "arrivals": 9096,
    "finished_requests": 9084,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.166486019268632. Arrivals time: 0.036463221069425344 Scheduler time: 0.7277142792008817 Scheduler overhead time: 0.1430035186931491 Adapter cache time: 0.04970370139926672 Engine time: 0.138763886410743 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-32/adapters_96_slots_16_rate_0.05-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-32/adapters_96_slots_16_rate_0.05-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 33, 540, 33, 33, 540, 270, 540, 270, 540, 540, 270, 33, 540, 270, 33, 33, 270, 540, 33, 270, 33, 33, 270, 270, 270, 33, 33, 540, 270, 270, 33, 540, 540, 270, 540, 540, 270, 540, 33, 540, 270, 270, 270, 540, 540, 33, 33, 270, 33, 540, 33, 33, 540, 33, 270, 270, 33, 270, 540, 540, 540, 270, 540, 540, 33, 33, 540, 270, 540, 33, 270, 540, 33, 540, 270, 33, 540, 33, 33, 540, 33, 33, 270]
Prompts retrieved: 26976 . Total input tokens: 5949445 . Total output tokens: 5404596
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.1783444369211793,
    "estimated_duration": 3599.9258088998017,
    "input_throughput": 623.5786844412942,
    "output_throughput": 558.1142797534587,
    "total_throughput": 1181.692964194753,
    "itl": 20.404800290142074,
    "ttft": 4915.518042548517,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6736,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.81809443140342,
    "arrivals": 9096,
    "finished_requests": 9084,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1784265139140189. Arrivals time: 0.03637535125017166 Scheduler time: 0.7380243306979537 Scheduler overhead time: 0.1431133346632123 Adapter cache time: 0.05013093072921038 Engine time: 0.1394677571952343 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_96_slots_16_rate_0.05-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_96_slots_16_rate_0.05-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 33, 540, 33, 33, 540, 270, 540, 270, 540, 540, 270, 33, 540, 270, 33, 33, 270, 540, 33, 270, 33, 33, 270, 270, 270, 33, 33, 540, 270, 270, 33, 540, 540, 270, 540, 540, 270, 540, 33, 540, 270, 270, 270, 540, 540, 33, 33, 270, 33, 540, 33, 33, 540, 33, 270, 270, 33, 270, 540, 540, 540, 270, 540, 540, 33, 33, 540, 270, 540, 33, 270, 540, 33, 540, 270, 33, 540, 33, 33, 540, 33, 33, 270]
Prompts retrieved: 26976 . Total input tokens: 5949445 . Total output tokens: 5404596
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 1.172461458016187,
    "estimated_duration": 3599.925007157697,
    "input_throughput": 623.5788233189891,
    "output_throughput": 558.114404051525,
    "total_throughput": 1181.693227370514,
    "itl": 20.402162022934405,
    "ttft": 4915.2063541414,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6737,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.978729072329337,
    "arrivals": 9096,
    "finished_requests": 9084,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.172552625183016. Arrivals time: 0.03689199546352029 Scheduler time: 0.731432338245213 Scheduler overhead time: 0.1456534406170249 Adapter cache time: 0.05017880257219076 Engine time: 0.13678870582953095 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-32/adapters_96_slots_16_rate_0.05-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-32/adapters_96_slots_16_rate_0.05-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 33, 540, 33, 33, 540, 270, 540, 270, 540, 540, 270, 33, 540, 270, 33, 33, 270, 540, 33, 270, 33, 33, 270, 270, 270, 33, 33, 540, 270, 270, 33, 540, 540, 270, 540, 540, 270, 540, 33, 540, 270, 270, 270, 540, 540, 33, 33, 270, 33, 540, 33, 33, 540, 33, 270, 270, 33, 270, 540, 540, 540, 270, 540, 540, 33, 33, 540, 270, 540, 33, 270, 540, 33, 540, 270, 33, 540, 33, 33, 540, 33, 33, 270]
Prompts retrieved: 26976 . Total input tokens: 5949445 . Total output tokens: 5404596
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 1.1747500319033861,
    "estimated_duration": 3599.936644991817,
    "input_throughput": 623.5768074204824,
    "output_throughput": 558.1125997856462,
    "total_throughput": 1181.6894072061286,
    "itl": 20.406296895019146,
    "ttft": 4915.566930055902,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6736,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.052373735493752,
    "arrivals": 9096,
    "finished_requests": 9084,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1748336590826511. Arrivals time: 0.035691451746970415 Scheduler time: 0.7348854807205498 Scheduler overhead time: 0.14575386000797153 Adapter cache time: 0.0497493976727128 Engine time: 0.13726680120453238 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_96_slots_16_rate_0.05-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_96_slots_16_rate_0.05-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 33, 540, 33, 33, 540, 270, 540, 270, 540, 540, 270, 33, 540, 270, 33, 33, 270, 540, 33, 270, 33, 33, 270, 270, 270, 33, 33, 540, 270, 270, 33, 540, 540, 270, 540, 540, 270, 540, 33, 540, 270, 270, 270, 540, 540, 33, 33, 270, 33, 540, 33, 33, 540, 33, 270, 270, 33, 270, 540, 540, 540, 270, 540, 540, 33, 33, 540, 270, 540, 33, 270, 540, 33, 540, 270, 33, 540, 33, 33, 540, 33, 33, 270]
Prompts retrieved: 26976 . Total input tokens: 5949445 . Total output tokens: 5404596
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.1547256079502404,
    "estimated_duration": 3599.94254350466,
    "input_throughput": 623.5757856886735,
    "output_throughput": 558.1116853170685,
    "total_throughput": 1181.687471005742,
    "itl": 20.39434896574425,
    "ttft": 4914.725065579278,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6734,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.134998685871718,
    "arrivals": 9096,
    "finished_requests": 9084,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1547982832416892. Arrivals time: 0.03487724857404828 Scheduler time: 0.7191046015359461 Scheduler overhead time: 0.14258860191330314 Adapter cache time: 0.0493741394020617 Engine time: 0.13769739866256714 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-32/adapters_96_slots_16_rate_0.05-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-32/adapters_96_slots_16_rate_0.05-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 33, 540, 33, 33, 540, 270, 540, 270, 540, 540, 270, 33, 540, 270, 33, 33, 270, 540, 33, 270, 33, 33, 270, 270, 270, 33, 33, 540, 270, 270, 33, 540, 540, 270, 540, 540, 270, 540, 33, 540, 270, 270, 270, 540, 540, 33, 33, 270, 33, 540, 33, 33, 540, 33, 270, 270, 33, 270, 540, 540, 540, 270, 540, 540, 33, 33, 540, 270, 540, 33, 270, 540, 33, 540, 270, 33, 540, 33, 33, 540, 33, 33, 270]
Prompts retrieved: 26976 . Total input tokens: 5949445 . Total output tokens: 5404596
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.1695794640108943,
    "estimated_duration": 3599.924116572983,
    "input_throughput": 623.5789775860652,
    "output_throughput": 558.1145421233679,
    "total_throughput": 1181.693519709433,
    "itl": 20.40893976963417,
    "ttft": 4915.932415033498,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6735,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.3061194485035,
    "arrivals": 9096,
    "finished_requests": 9084,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1696617011912167. Arrivals time: 0.03706651879474521 Scheduler time: 0.7327584475278854 Scheduler overhead time: 0.14175168517977 Adapter cache time: 0.04956116806715727 Engine time: 0.13791494583711028 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_96_slots_16_rate_0.05-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_96_slots_16_rate_0.05-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 540, 135, 135, 135, 135, 540, 135, 540, 135, 66, 540, 66, 66, 540, 135, 540, 135, 540, 540, 135, 66, 540, 135, 66, 66, 135, 540, 66, 135, 66, 66, 135, 135, 135, 66, 66, 540, 135, 135, 66, 540, 540, 135, 540, 540, 135, 540, 66, 540, 135, 135, 135, 540, 540, 66, 66, 135, 66, 540, 66, 66, 540, 66, 135, 135, 66, 135, 540, 540, 540, 135, 540, 540, 66, 66, 540, 135, 540, 66, 135, 540, 66, 540, 135, 66, 540, 66, 66, 540, 66, 66, 135]
Prompts retrieved: 23712 . Total input tokens: 5233067 . Total output tokens: 4747550
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.0819841520860791,
    "estimated_duration": 3599.8259768837884,
    "input_throughput": 543.1431998533855,
    "output_throughput": 491.40403212805273,
    "total_throughput": 1034.5472319814382,
    "itl": 20.00484148997422,
    "ttft": 5880.022016936648,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5770,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.659014282490727,
    "arrivals": 8052,
    "finished_requests": 8039,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0820550019852817. Arrivals time: 0.032879351638257504 Scheduler time: 0.6478221574798226 Scheduler overhead time: 0.1437122798524797 Adapter cache time: 0.04630887554958463 Engine time: 0.13972155936062336 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_96_slots_16_rate_0.05-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_96_slots_16_rate_0.05-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 540, 135, 135, 135, 135, 540, 135, 540, 135, 66, 540, 66, 66, 540, 135, 540, 135, 540, 540, 135, 66, 540, 135, 66, 66, 135, 540, 66, 135, 66, 66, 135, 135, 135, 66, 66, 540, 135, 135, 66, 540, 540, 135, 540, 540, 135, 540, 66, 540, 135, 135, 135, 540, 540, 66, 66, 135, 66, 540, 66, 66, 540, 66, 135, 135, 66, 135, 540, 540, 540, 135, 540, 540, 66, 66, 540, 135, 540, 66, 135, 540, 66, 540, 135, 66, 540, 66, 66, 540, 66, 66, 135]
Prompts retrieved: 23712 . Total input tokens: 5233067 . Total output tokens: 4747550
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.0824328549206257,
    "estimated_duration": 3599.8342719424963,
    "input_throughput": 543.1422260850214,
    "output_throughput": 491.54707309488765,
    "total_throughput": 1034.689299179909,
    "itl": 20.010568122395952,
    "ttft": 5433.094684572616,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5772,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.668224150794764,
    "arrivals": 8052,
    "finished_requests": 8040,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0826407237909734. Arrivals time: 0.032628937158733606 Scheduler time: 0.6497828904539347 Scheduler overhead time: 0.14381203427910805 Adapter cache time: 0.046239643823355436 Engine time: 0.13815859286114573 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-32/adapters_96_slots_16_rate_0.05-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-32/adapters_96_slots_16_rate_0.05-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 540, 135, 135, 135, 135, 540, 135, 540, 135, 66, 540, 66, 66, 540, 135, 540, 135, 540, 540, 135, 66, 540, 135, 66, 66, 135, 540, 66, 135, 66, 66, 135, 135, 135, 66, 66, 540, 135, 135, 66, 540, 540, 135, 540, 540, 135, 540, 66, 540, 135, 135, 135, 540, 540, 66, 66, 135, 66, 540, 66, 66, 540, 66, 135, 135, 66, 135, 540, 540, 540, 135, 540, 540, 66, 66, 540, 135, 540, 66, 135, 540, 66, 540, 135, 66, 540, 66, 66, 540, 66, 66, 135]
Prompts retrieved: 23712 . Total input tokens: 5233067 . Total output tokens: 4747550
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.0923952269367874,
    "estimated_duration": 3599.832796359225,
    "input_throughput": 543.1424487208016,
    "output_throughput": 491.5472745816453,
    "total_throughput": 1034.6897233024467,
    "itl": 20.011051778898345,
    "ttft": 5433.10346801253,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5770,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.72427036600084,
    "arrivals": 8052,
    "finished_requests": 8040,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0924816317856312. Arrivals time: 0.034440236166119576 Scheduler time: 0.655677339527756 Scheduler overhead time: 0.14673259342089295 Adapter cache time: 0.045592672657221556 Engine time: 0.13783918740227818 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_96_slots_16_rate_0.05-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_96_slots_16_rate_0.05-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 540, 135, 135, 135, 135, 540, 135, 540, 135, 66, 540, 66, 66, 540, 135, 540, 135, 540, 540, 135, 66, 540, 135, 66, 66, 135, 540, 66, 135, 66, 66, 135, 135, 135, 66, 66, 540, 135, 135, 66, 540, 540, 135, 540, 540, 135, 540, 66, 540, 135, 135, 135, 540, 540, 66, 66, 135, 66, 540, 66, 66, 540, 66, 135, 135, 66, 135, 540, 540, 540, 135, 540, 540, 66, 66, 540, 135, 540, 66, 135, 540, 66, 540, 135, 66, 540, 66, 66, 540, 66, 66, 135]
Prompts retrieved: 23712 . Total input tokens: 5233067 . Total output tokens: 4747550
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 1.08752067014575,
    "estimated_duration": 3599.830544129526,
    "input_throughput": 543.1427885372286,
    "output_throughput": 491.5475821176131,
    "total_throughput": 1034.6903706548417,
    "itl": 20.005914640384965,
    "ttft": 5432.840364684547,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5772,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.98382699240777,
    "arrivals": 8052,
    "finished_requests": 8040,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0875783269293606. Arrivals time: 0.031442197039723396 Scheduler time: 0.6560795493423939 Scheduler overhead time: 0.1431439514271915 Adapter cache time: 0.04628419037908316 Engine time: 0.1394195295870304 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-32/adapters_96_slots_16_rate_0.05-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-32/adapters_96_slots_16_rate_0.05-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 540, 135, 135, 135, 135, 540, 135, 540, 135, 66, 540, 66, 66, 540, 135, 540, 135, 540, 540, 135, 66, 540, 135, 66, 66, 135, 540, 66, 135, 66, 66, 135, 135, 135, 66, 66, 540, 135, 135, 66, 540, 540, 135, 540, 540, 135, 540, 66, 540, 135, 135, 135, 540, 540, 66, 66, 135, 66, 540, 66, 66, 540, 66, 135, 135, 66, 135, 540, 540, 540, 135, 540, 540, 66, 66, 540, 135, 540, 66, 135, 540, 66, 540, 135, 66, 540, 66, 66, 540, 66, 66, 135]
Prompts retrieved: 23712 . Total input tokens: 5233067 . Total output tokens: 4747550
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 1.093880902044475,
    "estimated_duration": 3599.8397340729057,
    "input_throughput": 543.1414019612024,
    "output_throughput": 491.54632725773547,
    "total_throughput": 1034.6877292189379,
    "itl": 20.012177185358105,
    "ttft": 5433.134564357415,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5770,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.93524520574015,
    "arrivals": 8052,
    "finished_requests": 8040,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0939389350824058. Arrivals time: 0.0323403594084084 Scheduler time: 0.65626135841012 Scheduler overhead time: 0.1474538636393845 Adapter cache time: 0.04612744227051735 Engine time: 0.13960171304643154 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_96_slots_16_rate_0.05-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_96_slots_16_rate_0.05-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 540, 135, 135, 135, 135, 540, 135, 540, 135, 66, 540, 66, 66, 540, 135, 540, 135, 540, 540, 135, 66, 540, 135, 66, 66, 135, 540, 66, 135, 66, 66, 135, 135, 135, 66, 66, 540, 135, 135, 66, 540, 540, 135, 540, 540, 135, 540, 66, 540, 135, 135, 135, 540, 540, 66, 66, 135, 66, 540, 66, 66, 540, 66, 135, 135, 66, 135, 540, 540, 540, 135, 540, 540, 66, 66, 540, 135, 540, 66, 135, 540, 66, 540, 135, 66, 540, 66, 66, 540, 66, 66, 135]
Prompts retrieved: 23712 . Total input tokens: 5233067 . Total output tokens: 4747550
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.0871217888779938,
    "estimated_duration": 3599.8426896579667,
    "input_throughput": 543.1409560248791,
    "output_throughput": 491.54592368260546,
    "total_throughput": 1034.6868797074844,
    "itl": 20.00269962938022,
    "ttft": 5432.803548296302,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5770,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.25259020158698,
    "arrivals": 8052,
    "finished_requests": 8040,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0871974499896169. Arrivals time: 0.032509732991456985 Scheduler time: 0.654670821968466 Scheduler overhead time: 0.14297421695664525 Adapter cache time: 0.04588405275717378 Engine time: 0.13987167598679662 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-32/adapters_96_slots_16_rate_0.05-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-32/adapters_96_slots_16_rate_0.05-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 540, 135, 135, 135, 135, 540, 135, 540, 135, 66, 540, 66, 66, 540, 135, 540, 135, 540, 540, 135, 66, 540, 135, 66, 66, 135, 540, 66, 135, 66, 66, 135, 135, 135, 66, 66, 540, 135, 135, 66, 540, 540, 135, 540, 540, 135, 540, 66, 540, 135, 135, 135, 540, 540, 66, 66, 135, 66, 540, 66, 66, 540, 66, 135, 135, 66, 135, 540, 540, 540, 135, 540, 540, 66, 66, 540, 135, 540, 66, 135, 540, 66, 540, 135, 66, 540, 66, 66, 540, 66, 66, 135]
Prompts retrieved: 23712 . Total input tokens: 5233067 . Total output tokens: 4747550
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.0773780681192875,
    "estimated_duration": 3599.8419962471166,
    "input_throughput": 543.1410606460909,
    "output_throughput": 491.5460183654491,
    "total_throughput": 1034.68707901154,
    "itl": 20.01370152589183,
    "ttft": 5433.047343996521,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5772,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.16500821560471,
    "arrivals": 8052,
    "finished_requests": 8040,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0774679551832378. Arrivals time: 0.034373389557003975 Scheduler time: 0.6455958001315594 Scheduler overhead time: 0.14302710629999638 Adapter cache time: 0.04587078932672739 Engine time: 0.1372708547860384 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_96_slots_16_rate_0.05-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_96_slots_16_rate_0.05-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 540, 135, 135, 135, 135, 540, 135, 540, 135, 33, 540, 33, 33, 540, 135, 540, 135, 540, 540, 135, 33, 540, 135, 33, 33, 135, 540, 33, 135, 33, 33, 135, 135, 135, 33, 33, 540, 135, 135, 33, 540, 540, 135, 540, 540, 135, 540, 33, 540, 135, 135, 135, 540, 540, 33, 33, 135, 33, 540, 33, 33, 540, 33, 135, 135, 33, 135, 540, 540, 540, 135, 540, 540, 33, 33, 540, 135, 540, 33, 135, 540, 33, 540, 135, 33, 540, 33, 33, 540, 33, 33, 135]
Prompts retrieved: 22656 . Total input tokens: 5005309 . Total output tokens: 4536837
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.0626746458001435,
    "estimated_duration": 3599.423219545969,
    "input_throughput": 517.634322599892,
    "output_throughput": 465.54347677163986,
    "total_throughput": 983.1777993715318,
    "itl": 19.78587442923773,
    "ttft": 6659.85141296045,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5200,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.91453626844854,
    "arrivals": 7636,
    "finished_requests": 7622,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0627656150609255. Arrivals time: 0.03287364961579442 Scheduler time: 0.629681330639869 Scheduler overhead time: 0.14354161312803626 Adapter cache time: 0.04460355173796415 Engine time: 0.13987684901803732 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_96_slots_16_rate_0.05-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_96_slots_16_rate_0.05-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 540, 135, 135, 135, 135, 540, 135, 540, 135, 33, 540, 33, 33, 540, 135, 540, 135, 540, 540, 135, 33, 540, 135, 33, 33, 135, 540, 33, 135, 33, 33, 135, 135, 135, 33, 33, 540, 135, 135, 33, 540, 540, 135, 540, 540, 135, 540, 33, 540, 135, 135, 135, 540, 540, 33, 33, 135, 33, 540, 33, 33, 540, 33, 135, 135, 33, 135, 540, 540, 540, 135, 540, 540, 33, 33, 540, 135, 540, 33, 135, 540, 33, 540, 135, 33, 540, 33, 33, 540, 33, 33, 135]
Prompts retrieved: 22656 . Total input tokens: 5005309 . Total output tokens: 4536837
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.0599754489958286,
    "estimated_duration": 3599.433337304101,
    "input_throughput": 517.6328675656168,
    "output_throughput": 465.54216816112915,
    "total_throughput": 983.175035726746,
    "itl": 19.790449457377825,
    "ttft": 6660.0402397805055,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5197,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.816968943370448,
    "arrivals": 7636,
    "finished_requests": 7622,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0600425833836198. Arrivals time: 0.0320047871209681 Scheduler time: 0.6250771945342422 Scheduler overhead time: 0.14467365853488445 Adapter cache time: 0.04434351483359933 Engine time: 0.1418725703842938 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-32/adapters_96_slots_16_rate_0.05-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-32/adapters_96_slots_16_rate_0.05-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 540, 135, 135, 135, 135, 540, 135, 540, 135, 33, 540, 33, 33, 540, 135, 540, 135, 540, 540, 135, 33, 540, 135, 33, 33, 135, 540, 33, 135, 33, 33, 135, 135, 135, 33, 33, 540, 135, 135, 33, 540, 540, 135, 540, 540, 135, 540, 33, 540, 135, 135, 135, 540, 540, 33, 33, 135, 33, 540, 33, 33, 540, 33, 135, 135, 33, 135, 540, 540, 540, 135, 540, 540, 33, 33, 540, 135, 540, 33, 135, 540, 33, 540, 135, 33, 540, 33, 33, 540, 33, 33, 135]
Prompts retrieved: 22656 . Total input tokens: 5005309 . Total output tokens: 4536837
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.058437192812562,
    "estimated_duration": 3599.438128958899,
    "input_throughput": 517.6321784808417,
    "output_throughput": 465.5415484206908,
    "total_throughput": 983.1737269015325,
    "itl": 19.79302599043773,
    "ttft": 6660.017929021148,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5198,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.8751211387651,
    "arrivals": 7636,
    "finished_requests": 7622,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.058521998114884. Arrivals time: 0.032581929583102465 Scheduler time: 0.6251575360074639 Scheduler overhead time: 0.14309801068156958 Adapter cache time: 0.044513775035738945 Engine time: 0.14116211840882897 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-16/adapters_96_slots_16_rate_0.05-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-16/adapters_96_slots_16_rate_0.05-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 540, 135, 135, 135, 135, 540, 135, 540, 135, 33, 540, 33, 33, 540, 135, 540, 135, 540, 540, 135, 33, 540, 135, 33, 33, 135, 540, 33, 135, 33, 33, 135, 135, 135, 33, 33, 540, 135, 135, 33, 540, 540, 135, 540, 540, 135, 540, 33, 540, 135, 135, 135, 540, 540, 33, 33, 135, 33, 540, 33, 33, 540, 33, 135, 135, 33, 135, 540, 540, 540, 135, 540, 540, 33, 33, 540, 135, 540, 33, 135, 540, 33, 540, 135, 33, 540, 33, 33, 540, 33, 33, 135]
Prompts retrieved: 22656 . Total input tokens: 5005309 . Total output tokens: 4536837
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 1.0456075761467218,
    "estimated_duration": 3599.441172292498,
    "input_throughput": 517.6317408219594,
    "output_throughput": 465.54115480452424,
    "total_throughput": 983.1728956264836,
    "itl": 19.78543513100501,
    "ttft": 6659.930134630987,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5198,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.214829327055725,
    "arrivals": 7636,
    "finished_requests": 7622,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0458068479783833. Arrivals time: 0.03119694720953703 Scheduler time: 0.6156102581880987 Scheduler overhead time: 0.1435832343995571 Adapter cache time: 0.044278677087277174 Engine time: 0.13924364373087883 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-32/adapters_96_slots_16_rate_0.05-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-32/adapters_96_slots_16_rate_0.05-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 540, 135, 135, 135, 135, 540, 135, 540, 135, 33, 540, 33, 33, 540, 135, 540, 135, 540, 540, 135, 33, 540, 135, 33, 33, 135, 540, 33, 135, 33, 33, 135, 135, 135, 33, 33, 540, 135, 135, 33, 540, 540, 135, 540, 540, 135, 540, 33, 540, 135, 135, 135, 540, 540, 33, 33, 135, 33, 540, 33, 33, 540, 33, 135, 135, 33, 135, 540, 540, 540, 135, 540, 540, 33, 33, 540, 135, 540, 33, 135, 540, 33, 540, 135, 33, 540, 33, 33, 540, 33, 33, 135]
Prompts retrieved: 22656 . Total input tokens: 5005309 . Total output tokens: 4536837
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 1.071316292975098,
    "estimated_duration": 3599.4269122422056,
    "input_throughput": 517.6337915524887,
    "output_throughput": 465.5429991648745,
    "total_throughput": 983.1767907173632,
    "itl": 19.793364951232626,
    "ttft": 6659.99173449298,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5196,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.054137962477864,
    "arrivals": 7636,
    "finished_requests": 7622,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0713965347968042. Arrivals time: 0.032871268689632416 Scheduler time: 0.6352116228081286 Scheduler overhead time: 0.14556852634996176 Adapter cache time: 0.044475949835032225 Engine time: 0.14059548592194915 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-16/adapters_96_slots_16_rate_0.05-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-16/adapters_96_slots_16_rate_0.05-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 540, 135, 135, 135, 135, 540, 135, 540, 135, 33, 540, 33, 33, 540, 135, 540, 135, 540, 540, 135, 33, 540, 135, 33, 33, 135, 540, 33, 135, 33, 33, 135, 135, 135, 33, 33, 540, 135, 135, 33, 540, 540, 135, 540, 540, 135, 540, 33, 540, 135, 135, 135, 540, 540, 33, 33, 135, 33, 540, 33, 33, 540, 33, 135, 135, 33, 135, 540, 540, 540, 135, 540, 540, 33, 33, 540, 135, 540, 33, 135, 540, 33, 540, 135, 33, 540, 33, 33, 540, 33, 33, 135]
Prompts retrieved: 22656 . Total input tokens: 5005309 . Total output tokens: 4536837
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.0702768303453922,
    "estimated_duration": 3599.433446714851,
    "input_throughput": 517.6328518313072,
    "output_throughput": 465.54215401020275,
    "total_throughput": 983.1750058415099,
    "itl": 19.78335652780203,
    "ttft": 6659.804379212972,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5198,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.542281432903232,
    "arrivals": 7636,
    "finished_requests": 7622,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.070473626255989. Arrivals time: 0.03276760037988424 Scheduler time: 0.6345224701799452 Scheduler overhead time: 0.14520858507603407 Adapter cache time: 0.044585386756807566 Engine time: 0.141079175285995 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-32/adapters_96_slots_16_rate_0.05-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-32/adapters_96_slots_16_rate_0.05-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 540, 135, 135, 135, 135, 540, 135, 540, 135, 33, 540, 33, 33, 540, 135, 540, 135, 540, 540, 135, 33, 540, 135, 33, 33, 135, 540, 33, 135, 33, 33, 135, 135, 135, 33, 33, 540, 135, 135, 33, 540, 540, 135, 540, 540, 135, 540, 33, 540, 135, 135, 135, 540, 540, 33, 33, 135, 33, 540, 33, 33, 540, 33, 135, 135, 33, 135, 540, 540, 540, 135, 540, 540, 33, 33, 540, 135, 540, 33, 135, 540, 33, 540, 135, 33, 540, 33, 33, 540, 33, 33, 135]
Prompts retrieved: 22656 . Total input tokens: 5005309 . Total output tokens: 4536837
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.0481723169796169,
    "estimated_duration": 3599.423194918401,
    "input_throughput": 517.6343261415913,
    "output_throughput": 465.54347995692905,
    "total_throughput": 983.1778060985203,
    "itl": 19.792679646302503,
    "ttft": 6660.01100007598,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5197,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.265435463822076,
    "arrivals": 7636,
    "finished_requests": 7622,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0482519366778433. Arrivals time: 0.03225498320534825 Scheduler time: 0.6160468910820782 Scheduler overhead time: 0.14303735736757517 Adapter cache time: 0.043961357325315475 Engine time: 0.14072648528963327 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-8/adapters_96_slots_16_rate_0.05-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-8/adapters_96_slots_16_rate_0.05-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 540, 66, 66, 66, 66, 540, 66, 540, 66, 33, 540, 33, 33, 540, 66, 540, 66, 540, 540, 66, 33, 540, 66, 33, 33, 66, 540, 33, 66, 33, 33, 66, 66, 66, 33, 33, 540, 66, 66, 33, 540, 540, 66, 540, 540, 66, 540, 33, 540, 66, 66, 66, 540, 540, 33, 33, 66, 33, 540, 33, 33, 540, 33, 66, 66, 33, 66, 540, 540, 540, 66, 540, 540, 33, 33, 540, 66, 540, 33, 66, 540, 33, 540, 66, 33, 540, 33, 33, 540, 33, 33, 66]
Prompts retrieved: 20448 . Total input tokens: 4537851 . Total output tokens: 4108920
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.0073916888795793,
    "estimated_duration": 3599.364163009605,
    "input_throughput": 471.83917022165116,
    "output_throughput": 422.41238483874486,
    "total_throughput": 894.2515550603961,
    "itl": 19.562814996010935,
    "ttft": 5219.905742854419,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4456,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.637533386963153,
    "arrivals": 6944,
    "finished_requests": 6934,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0074873990379274. Arrivals time: 0.03097639884799719 Scheduler time: 0.5737864528782666 Scheduler overhead time: 0.14516011532396078 Adapter cache time: 0.04288853518664837 Engine time: 0.14232426742091775 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-16/adapters_96_slots_16_rate_0.05-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-16/adapters_96_slots_16_rate_0.05-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 540, 66, 66, 66, 66, 540, 66, 540, 66, 33, 540, 33, 33, 540, 66, 540, 66, 540, 540, 66, 33, 540, 66, 33, 33, 66, 540, 33, 66, 33, 33, 66, 66, 66, 33, 33, 540, 66, 66, 33, 540, 540, 66, 540, 540, 66, 540, 33, 540, 66, 66, 66, 540, 540, 33, 33, 66, 33, 540, 33, 33, 540, 33, 66, 66, 33, 66, 540, 540, 540, 66, 540, 540, 33, 33, 540, 66, 540, 33, 66, 540, 33, 540, 66, 33, 540, 33, 33, 540, 33, 33, 66]
Prompts retrieved: 20448 . Total input tokens: 4537851 . Total output tokens: 4108920
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.0128377238288522,
    "estimated_duration": 3599.353949579804,
    "input_throughput": 471.8405090997693,
    "output_throughput": 422.4135834647483,
    "total_throughput": 894.2540925645176,
    "itl": 19.568121750265608,
    "ttft": 5219.896045127182,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4456,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.417065186231335,
    "arrivals": 6944,
    "finished_requests": 6934,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.012987860944122. Arrivals time: 0.030714530032128096 Scheduler time: 0.5808522258885205 Scheduler overhead time: 0.14530672784894705 Adapter cache time: 0.04210207751020789 Engine time: 0.14159049931913614 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-32/adapters_96_slots_16_rate_0.05-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-32/adapters_96_slots_16_rate_0.05-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 540, 66, 66, 66, 66, 540, 66, 540, 66, 33, 540, 33, 33, 540, 66, 540, 66, 540, 540, 66, 33, 540, 66, 33, 33, 66, 540, 33, 66, 33, 33, 66, 66, 66, 33, 33, 540, 66, 66, 33, 540, 540, 66, 540, 540, 66, 540, 33, 540, 66, 66, 66, 540, 540, 33, 33, 66, 33, 540, 33, 33, 540, 33, 66, 66, 33, 66, 540, 540, 540, 66, 540, 540, 33, 33, 540, 66, 540, 33, 66, 540, 33, 540, 66, 33, 540, 33, 33, 540, 33, 33, 66]
Prompts retrieved: 20448 . Total input tokens: 4537851 . Total output tokens: 4108920
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.0028319340199232,
    "estimated_duration": 3599.3588883026914,
    "input_throughput": 471.839861681828,
    "output_throughput": 422.41300386607605,
    "total_throughput": 894.252865547904,
    "itl": 19.567831141533688,
    "ttft": 5219.992584480964,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4457,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.467437804302879,
    "arrivals": 6944,
    "finished_requests": 6934,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0028955899178982. Arrivals time: 0.02945817168802023 Scheduler time: 0.573060795199126 Scheduler overhead time: 0.1443202835507691 Adapter cache time: 0.041895929258316755 Engine time: 0.14162728982046247 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-16/adapters_96_slots_16_rate_0.05-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-16/adapters_96_slots_16_rate_0.05-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 540, 66, 66, 66, 66, 540, 66, 540, 66, 33, 540, 33, 33, 540, 66, 540, 66, 540, 540, 66, 33, 540, 66, 33, 33, 66, 540, 33, 66, 33, 33, 66, 66, 66, 33, 33, 540, 66, 66, 33, 540, 540, 66, 540, 540, 66, 540, 33, 540, 66, 66, 66, 540, 540, 33, 33, 66, 33, 540, 33, 33, 540, 33, 66, 66, 33, 66, 540, 540, 540, 66, 540, 540, 33, 33, 540, 66, 540, 33, 66, 540, 33, 540, 66, 33, 540, 33, 33, 540, 33, 33, 66]
Prompts retrieved: 20448 . Total input tokens: 4537851 . Total output tokens: 4108920
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 1.0028529958799481,
    "estimated_duration": 3599.3507463009705,
    "input_throughput": 471.84092901903307,
    "output_throughput": 422.41395939601654,
    "total_throughput": 894.2548884150497,
    "itl": 19.564741566405072,
    "ttft": 5219.937408126255,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4456,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.887934248851234,
    "arrivals": 6944,
    "finished_requests": 6934,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.002925111912191. Arrivals time: 0.03030478348955512 Scheduler time: 0.5724527551792562 Scheduler overhead time: 0.14414863428100944 Adapter cache time: 0.041814842727035284 Engine time: 0.14169657602906227 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-32/adapters_96_slots_16_rate_0.05-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-32/adapters_96_slots_16_rate_0.05-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 540, 66, 66, 66, 66, 540, 66, 540, 66, 33, 540, 33, 33, 540, 66, 540, 66, 540, 540, 66, 33, 540, 66, 33, 33, 66, 540, 33, 66, 33, 33, 66, 66, 66, 33, 33, 540, 66, 66, 33, 540, 540, 66, 540, 540, 66, 540, 33, 540, 66, 66, 66, 540, 540, 33, 33, 66, 33, 540, 33, 33, 540, 33, 66, 66, 33, 66, 540, 540, 540, 66, 540, 540, 33, 33, 540, 66, 540, 33, 66, 540, 33, 540, 66, 33, 540, 33, 33, 540, 33, 33, 66]
Prompts retrieved: 20448 . Total input tokens: 4537851 . Total output tokens: 4108920
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 1.0116467722691596,
    "estimated_duration": 3599.3597889021157,
    "input_throughput": 471.83974362230276,
    "output_throughput": 422.41289817369454,
    "total_throughput": 894.2526417959973,
    "itl": 19.569368836152176,
    "ttft": 5219.9954999134825,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4456,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.626908191366867,
    "arrivals": 6944,
    "finished_requests": 6934,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.011861409060657. Arrivals time: 0.030481616035103798 Scheduler time: 0.5770365274511278 Scheduler overhead time: 0.14623636147007346 Adapter cache time: 0.042106624227017164 Engine time: 0.1427592458203435 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-16/adapters_96_slots_16_rate_0.05-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-16/adapters_96_slots_16_rate_0.05-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 540, 66, 66, 66, 66, 540, 66, 540, 66, 33, 540, 33, 33, 540, 66, 540, 66, 540, 540, 66, 33, 540, 66, 33, 33, 66, 540, 33, 66, 33, 33, 66, 66, 66, 33, 33, 540, 66, 66, 33, 540, 540, 66, 540, 540, 66, 540, 33, 540, 66, 66, 66, 540, 540, 33, 33, 66, 33, 540, 33, 33, 540, 33, 66, 66, 33, 66, 540, 540, 540, 66, 540, 540, 33, 33, 540, 66, 540, 33, 66, 540, 33, 540, 66, 33, 540, 33, 33, 540, 33, 33, 66]
Prompts retrieved: 20448 . Total input tokens: 4537851 . Total output tokens: 4108920
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.0049927309155464,
    "estimated_duration": 3599.351086939262,
    "input_throughput": 471.8408843645706,
    "output_throughput": 422.4139194192635,
    "total_throughput": 894.2548037838342,
    "itl": 19.560635493100985,
    "ttft": 5219.795901736555,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4457,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.326654164380141,
    "arrivals": 6944,
    "finished_requests": 6934,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0050518792122602. Arrivals time: 0.030036890879273415 Scheduler time: 0.5749635687097907 Scheduler overhead time: 0.1446706443093717 Adapter cache time: 0.041761275846511126 Engine time: 0.1410365323536098 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-32/adapters_96_slots_16_rate_0.05-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-32/adapters_96_slots_16_rate_0.05-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 540, 66, 66, 66, 66, 540, 66, 540, 66, 33, 540, 33, 33, 540, 66, 540, 66, 540, 540, 66, 33, 540, 66, 33, 33, 66, 540, 33, 66, 33, 33, 66, 66, 66, 33, 33, 540, 66, 66, 33, 540, 540, 66, 540, 540, 66, 540, 33, 540, 66, 66, 66, 540, 540, 33, 33, 66, 33, 540, 33, 33, 540, 33, 66, 66, 33, 66, 540, 540, 540, 66, 540, 540, 33, 33, 540, 66, 540, 33, 66, 540, 33, 540, 66, 33, 540, 33, 33, 540, 33, 33, 66]
Prompts retrieved: 20448 . Total input tokens: 4537851 . Total output tokens: 4108920
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.0036950670182705,
    "estimated_duration": 3599.3613081430485,
    "input_throughput": 471.8395444652327,
    "output_throughput": 422.4127198790165,
    "total_throughput": 894.2522643442492,
    "itl": 19.569082913511334,
    "ttft": 5220.046643549475,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4455,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.797404897770724,
    "arrivals": 6944,
    "finished_requests": 6934,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0038262619636953. Arrivals time: 0.03028213419020176 Scheduler time: 0.5739185055717826 Scheduler overhead time: 0.14339370373636484 Adapter cache time: 0.041719046887010336 Engine time: 0.14224611409008503 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-8/adapters_96_slots_16_rate_0.025-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-8/adapters_96_slots_16_rate_0.025-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 270, 135, 135, 135, 135, 270, 135, 270, 135, 66, 270, 66, 66, 270, 135, 270, 135, 270, 270, 135, 66, 270, 135, 66, 66, 135, 270, 66, 135, 66, 66, 135, 135, 135, 66, 66, 270, 135, 135, 66, 270, 270, 135, 270, 270, 135, 270, 66, 270, 135, 135, 135, 270, 270, 66, 66, 135, 66, 270, 66, 66, 270, 66, 135, 135, 66, 135, 270, 270, 270, 135, 270, 270, 66, 66, 270, 135, 270, 66, 135, 270, 66, 270, 135, 66, 270, 66, 66, 270, 66, 66, 135]
Prompts retrieved: 15072 . Total input tokens: 3314737 . Total output tokens: 3054771
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 0.8900543199852109,
    "estimated_duration": 3599.4840255060685,
    "input_throughput": 354.68555797257767,
    "output_throughput": 311.3354558761913,
    "total_throughput": 666.021013848769,
    "itl": 18.919978031559065,
    "ttft": 5714.035771016477,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4001,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.245011463474105,
    "arrivals": 5070,
    "finished_requests": 5062,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8901324779726565. Arrivals time: 0.026080758310854435 Scheduler time: 0.4586768359877169 Scheduler overhead time: 0.1462880726903677 Adapter cache time: 0.039713263511657715 Engine time: 0.14556277729570866 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-16/adapters_96_slots_16_rate_0.025-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-16/adapters_96_slots_16_rate_0.025-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 270, 135, 135, 135, 135, 270, 135, 270, 135, 66, 270, 66, 66, 270, 135, 270, 135, 270, 270, 135, 66, 270, 135, 66, 66, 135, 270, 66, 135, 66, 66, 135, 135, 135, 66, 66, 270, 135, 135, 66, 270, 270, 135, 270, 270, 135, 270, 66, 270, 135, 135, 135, 270, 270, 66, 66, 135, 66, 270, 66, 66, 270, 66, 135, 135, 66, 135, 270, 270, 270, 135, 270, 270, 66, 66, 270, 135, 270, 66, 135, 270, 66, 270, 135, 66, 270, 66, 66, 270, 66, 66, 135]
Prompts retrieved: 15072 . Total input tokens: 3314737 . Total output tokens: 3054771
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 0.8889001780189574,
    "estimated_duration": 3599.4927961495855,
    "input_throughput": 354.6846937339847,
    "output_throughput": 311.3346972658947,
    "total_throughput": 666.0193909998794,
    "itl": 18.925227459485612,
    "ttft": 5714.409518625447,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4002,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.981540646523356,
    "arrivals": 5070,
    "finished_requests": 5062,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8889665082097054. Arrivals time: 0.02558101247996092 Scheduler time: 0.4607694773003459 Scheduler overhead time: 0.14599024457857013 Adapter cache time: 0.03864249354228377 Engine time: 0.1443013260141015 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-32/adapters_96_slots_16_rate_0.025-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-32/adapters_96_slots_16_rate_0.025-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 270, 135, 135, 135, 135, 270, 135, 270, 135, 66, 270, 66, 66, 270, 135, 270, 135, 270, 270, 135, 66, 270, 135, 66, 66, 135, 270, 66, 135, 66, 66, 135, 135, 135, 66, 66, 270, 135, 135, 66, 270, 270, 135, 270, 270, 135, 270, 66, 270, 135, 135, 135, 270, 270, 66, 66, 135, 66, 270, 66, 66, 270, 66, 135, 135, 66, 135, 270, 270, 270, 135, 270, 270, 66, 66, 270, 135, 270, 66, 135, 270, 66, 270, 135, 66, 270, 66, 66, 270, 66, 66, 135]
Prompts retrieved: 15072 . Total input tokens: 3314737 . Total output tokens: 3054771
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 0.8945418009534478,
    "estimated_duration": 3599.481222776913,
    "input_throughput": 354.6858341478076,
    "output_throughput": 311.3356982969473,
    "total_throughput": 666.0215324447549,
    "itl": 18.926696646038405,
    "ttft": 5714.1839600684025,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4001,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.014841690323308,
    "arrivals": 5070,
    "finished_requests": 5062,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8948350236751139. Arrivals time: 0.026082266587764025 Scheduler time: 0.46525076450780034 Scheduler overhead time: 0.147260760422796 Adapter cache time: 0.03875733586028218 Engine time: 0.1432532211765647 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-16/adapters_96_slots_16_rate_0.025-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-16/adapters_96_slots_16_rate_0.025-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 270, 135, 135, 135, 135, 270, 135, 270, 135, 66, 270, 66, 66, 270, 135, 270, 135, 270, 270, 135, 66, 270, 135, 66, 66, 135, 270, 66, 135, 66, 66, 135, 135, 135, 66, 66, 270, 135, 135, 66, 270, 270, 135, 270, 270, 135, 270, 66, 270, 135, 135, 135, 270, 270, 66, 66, 135, 66, 270, 66, 66, 270, 66, 135, 135, 66, 135, 270, 270, 270, 135, 270, 270, 66, 66, 270, 135, 270, 66, 135, 270, 66, 270, 135, 66, 270, 66, 66, 270, 66, 66, 135]
Prompts retrieved: 15072 . Total input tokens: 3314737 . Total output tokens: 3054771
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 0.891279614996165,
    "estimated_duration": 3599.478297378471,
    "input_throughput": 354.6861224110783,
    "output_throughput": 311.335951328329,
    "total_throughput": 666.0220737394072,
    "itl": 18.923513177435865,
    "ttft": 5713.980193597573,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4002,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.480194190797159,
    "arrivals": 5070,
    "finished_requests": 5062,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8913539419882. Arrivals time: 0.026380499824881554 Scheduler time: 0.4610734125599265 Scheduler overhead time: 0.14551871456205845 Adapter cache time: 0.03904810454696417 Engine time: 0.14549763454124331 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-32/adapters_96_slots_16_rate_0.025-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-32/adapters_96_slots_16_rate_0.025-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 270, 135, 135, 135, 135, 270, 135, 270, 135, 66, 270, 66, 66, 270, 135, 270, 135, 270, 270, 135, 66, 270, 135, 66, 66, 135, 270, 66, 135, 66, 66, 135, 135, 135, 66, 66, 270, 135, 135, 66, 270, 270, 135, 270, 270, 135, 270, 66, 270, 135, 135, 135, 270, 270, 66, 66, 135, 66, 270, 66, 66, 270, 66, 135, 135, 66, 135, 270, 270, 270, 135, 270, 270, 66, 66, 270, 135, 270, 66, 135, 270, 66, 270, 135, 66, 270, 66, 66, 270, 66, 66, 135]
Prompts retrieved: 15072 . Total input tokens: 3314737 . Total output tokens: 3054771
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 0.8773898640647531,
    "estimated_duration": 3599.495539716988,
    "input_throughput": 354.68442339016764,
    "output_throughput": 311.3344599638291,
    "total_throughput": 666.0188833539967,
    "itl": 18.926760565934682,
    "ttft": 5714.287003827634,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4003,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.176366120222038,
    "arrivals": 5070,
    "finished_requests": 5062,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8774636979214847. Arrivals time: 0.025285014417022467 Scheduler time: 0.4521593698300421 Scheduler overhead time: 0.14521109592169523 Adapter cache time: 0.038493096362799406 Engine time: 0.14250193629413843 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-16/adapters_96_slots_16_rate_0.025-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-16/adapters_96_slots_16_rate_0.025-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 270, 135, 135, 135, 135, 270, 135, 270, 135, 66, 270, 66, 66, 270, 135, 270, 135, 270, 270, 135, 66, 270, 135, 66, 66, 135, 270, 66, 135, 66, 66, 135, 135, 135, 66, 66, 270, 135, 135, 66, 270, 270, 135, 270, 270, 135, 270, 66, 270, 135, 135, 135, 270, 270, 66, 66, 135, 66, 270, 66, 66, 270, 66, 135, 135, 66, 135, 270, 270, 270, 135, 270, 270, 66, 66, 270, 135, 270, 66, 135, 270, 66, 270, 135, 66, 270, 66, 66, 270, 66, 66, 135]
Prompts retrieved: 15072 . Total input tokens: 3314737 . Total output tokens: 3054771
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 0.8859609407372773,
    "estimated_duration": 3599.4792142066517,
    "input_throughput": 354.6860320685001,
    "output_throughput": 311.335872027531,
    "total_throughput": 666.0219040960311,
    "itl": 18.918937119134387,
    "ttft": 5713.939549508758,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4003,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.969171330494198,
    "arrivals": 5070,
    "finished_requests": 5062,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8860357906669378. Arrivals time: 0.02634564694017172 Scheduler time: 0.45625529484823346 Scheduler overhead time: 0.14605071768164635 Adapter cache time: 0.03880434716120362 Engine time: 0.14516187738627195 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-32/adapters_96_slots_16_rate_0.025-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-32/adapters_96_slots_16_rate_0.025-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 270, 135, 135, 135, 135, 270, 135, 270, 135, 66, 270, 66, 66, 270, 135, 270, 135, 270, 270, 135, 66, 270, 135, 66, 66, 135, 270, 66, 135, 66, 66, 135, 135, 135, 66, 66, 270, 135, 135, 66, 270, 270, 135, 270, 270, 135, 270, 66, 270, 135, 135, 135, 270, 270, 66, 66, 135, 66, 270, 66, 66, 270, 66, 135, 135, 66, 135, 270, 270, 270, 135, 270, 270, 66, 66, 270, 135, 270, 66, 135, 270, 66, 270, 135, 66, 270, 66, 66, 270, 66, 66, 135]
Prompts retrieved: 15072 . Total input tokens: 3314737 . Total output tokens: 3054771
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 0.8914231639355421,
    "estimated_duration": 3599.493295411982,
    "input_throughput": 354.68464453796855,
    "output_throughput": 311.33465408267574,
    "total_throughput": 666.0192986206443,
    "itl": 18.92860611757196,
    "ttft": 5714.340414950977,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4001,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.327214095777874,
    "arrivals": 5070,
    "finished_requests": 5062,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8915267628617585. Arrivals time: 0.02595742465928197 Scheduler time: 0.46175323985517025 Scheduler overhead time: 0.14739747997373343 Adapter cache time: 0.03862972231581807 Engine time: 0.14419871661812067 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-8/adapters_96_slots_16_rate_0.025-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-8/adapters_96_slots_16_rate_0.025-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 270, 135, 135, 135, 135, 270, 135, 270, 135, 33, 270, 33, 33, 270, 135, 270, 135, 270, 270, 135, 33, 270, 135, 33, 33, 135, 270, 33, 135, 33, 33, 135, 135, 135, 33, 33, 270, 135, 135, 33, 270, 270, 135, 270, 270, 135, 270, 33, 270, 135, 135, 135, 270, 270, 33, 33, 135, 33, 270, 33, 33, 270, 33, 135, 135, 33, 135, 270, 270, 270, 135, 270, 270, 33, 33, 270, 135, 270, 33, 135, 270, 33, 270, 135, 33, 270, 33, 33, 270, 33, 33, 135]
Prompts retrieved: 14016 . Total input tokens: 3078471 . Total output tokens: 2840300
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 0.8493605121038854,
    "estimated_duration": 3598.5787460818738,
    "input_throughput": 324.56396883677553,
    "output_throughput": 281.96770769704153,
    "total_throughput": 606.5316765338171,
    "itl": 18.75284185241293,
    "ttft": 6915.008225964209,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3589,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.984090512974133,
    "arrivals": 4708,
    "finished_requests": 4699,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.849432117305696. Arrivals time: 0.025309021584689617 Scheduler time: 0.4217067747376859 Scheduler overhead time: 0.14769265661016107 Adapter cache time: 0.03780158469453454 Engine time: 0.14330299897119403 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-16/adapters_96_slots_16_rate_0.025-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-16/adapters_96_slots_16_rate_0.025-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 270, 135, 135, 135, 135, 270, 135, 270, 135, 33, 270, 33, 33, 270, 135, 270, 135, 270, 270, 135, 33, 270, 135, 33, 33, 135, 270, 33, 135, 33, 33, 135, 135, 135, 33, 33, 270, 135, 135, 33, 270, 270, 135, 270, 270, 135, 270, 33, 270, 135, 135, 135, 270, 270, 33, 33, 135, 33, 270, 33, 33, 270, 33, 135, 135, 33, 135, 270, 270, 270, 135, 270, 270, 33, 33, 270, 135, 270, 33, 135, 270, 33, 270, 135, 33, 270, 33, 33, 270, 33, 33, 135]
Prompts retrieved: 14016 . Total input tokens: 3078471 . Total output tokens: 2840300
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 0.8483415399678051,
    "estimated_duration": 3598.5842295018533,
    "input_throughput": 324.5634742754598,
    "output_throughput": 281.96727804269324,
    "total_throughput": 606.530752318153,
    "itl": 18.757184154335732,
    "ttft": 6915.372586303,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3589,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.599964155408424,
    "arrivals": 4708,
    "finished_requests": 4699,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8484191768802702. Arrivals time: 0.025271249003708363 Scheduler time: 0.4213195643387735 Scheduler overhead time: 0.1464931475929916 Adapter cache time: 0.0374165796674788 Engine time: 0.14366607181727886 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-32/adapters_96_slots_16_rate_0.025-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-32/adapters_96_slots_16_rate_0.025-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 270, 135, 135, 135, 135, 270, 135, 270, 135, 33, 270, 33, 33, 270, 135, 270, 135, 270, 270, 135, 33, 270, 135, 33, 33, 135, 270, 33, 135, 33, 33, 135, 135, 135, 33, 33, 270, 135, 135, 33, 270, 270, 135, 270, 270, 135, 270, 33, 270, 135, 135, 135, 270, 270, 33, 33, 135, 33, 270, 33, 33, 270, 33, 135, 135, 33, 135, 270, 270, 270, 135, 270, 270, 33, 33, 270, 135, 270, 33, 135, 270, 33, 270, 135, 33, 270, 33, 33, 270, 33, 33, 135]
Prompts retrieved: 14016 . Total input tokens: 3078471 . Total output tokens: 2840300
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 0.8486820538528264,
    "estimated_duration": 3598.5855573932727,
    "input_throughput": 324.5633545103338,
    "output_throughput": 281.9671739957217,
    "total_throughput": 606.5305285060555,
    "itl": 18.757298354288572,
    "ttft": 6915.332123140202,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3588,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.63713380273361,
    "arrivals": 4708,
    "finished_requests": 4699,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8487690920010209. Arrivals time: 0.025174438953399658 Scheduler time: 0.4221661905758083 Scheduler overhead time: 0.14678820548579097 Adapter cache time: 0.037305147387087345 Engine time: 0.14377044001594186 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-16/adapters_96_slots_16_rate_0.025-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-16/adapters_96_slots_16_rate_0.025-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 270, 135, 135, 135, 135, 270, 135, 270, 135, 33, 270, 33, 33, 270, 135, 270, 135, 270, 270, 135, 33, 270, 135, 33, 33, 135, 270, 33, 135, 33, 33, 135, 135, 135, 33, 33, 270, 135, 135, 33, 270, 270, 135, 270, 270, 135, 270, 33, 270, 135, 135, 135, 270, 270, 33, 33, 135, 33, 270, 33, 33, 270, 33, 135, 135, 33, 135, 270, 270, 270, 135, 270, 270, 33, 33, 270, 135, 270, 33, 135, 270, 33, 270, 135, 33, 270, 33, 33, 270, 33, 33, 135]
Prompts retrieved: 14016 . Total input tokens: 3078471 . Total output tokens: 2840300
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 0.8711923910304904,
    "estimated_duration": 3598.5848468760623,
    "input_throughput": 324.5634185932606,
    "output_throughput": 281.9672296683092,
    "total_throughput": 606.5306482615698,
    "itl": 18.753363243234176,
    "ttft": 6915.119935582989,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3588,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.178981094349117,
    "arrivals": 4708,
    "finished_requests": 4699,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8712811223231256. Arrivals time: 0.026350528467446566 Scheduler time: 0.4334705248475075 Scheduler overhead time: 0.1543598030693829 Adapter cache time: 0.03781377011910081 Engine time: 0.14496153173968196 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-32/adapters_96_slots_16_rate_0.025-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-32/adapters_96_slots_16_rate_0.025-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 270, 135, 135, 135, 135, 270, 135, 270, 135, 33, 270, 33, 33, 270, 135, 270, 135, 270, 270, 135, 33, 270, 135, 33, 33, 135, 270, 33, 135, 33, 33, 135, 135, 135, 33, 33, 270, 135, 135, 33, 270, 270, 135, 270, 270, 135, 270, 33, 270, 135, 135, 135, 270, 270, 33, 33, 135, 33, 270, 33, 33, 270, 33, 135, 135, 33, 135, 270, 270, 270, 135, 270, 270, 33, 33, 270, 135, 270, 33, 135, 270, 33, 270, 135, 33, 270, 33, 33, 270, 33, 33, 135]
Prompts retrieved: 14016 . Total input tokens: 3078471 . Total output tokens: 2840300
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 0.8528410759754479,
    "estimated_duration": 3598.5713009835454,
    "input_throughput": 324.5646403284481,
    "output_throughput": 281.96829106114177,
    "total_throughput": 606.5329313895899,
    "itl": 18.757970895959982,
    "ttft": 6915.287936126537,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3588,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.765316924954973,
    "arrivals": 4708,
    "finished_requests": 4699,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8529163841158152. Arrivals time: 0.02528725052252412 Scheduler time: 0.42523250123485923 Scheduler overhead time: 0.14773638686165214 Adapter cache time: 0.03734882175922394 Engine time: 0.14312403090298176 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-16/adapters_96_slots_16_rate_0.025-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-16/adapters_96_slots_16_rate_0.025-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 270, 135, 135, 135, 135, 270, 135, 270, 135, 33, 270, 33, 33, 270, 135, 270, 135, 270, 270, 135, 33, 270, 135, 33, 33, 135, 270, 33, 135, 33, 33, 135, 135, 135, 33, 33, 270, 135, 135, 33, 270, 270, 135, 270, 270, 135, 270, 33, 270, 135, 135, 135, 270, 270, 33, 33, 135, 33, 270, 33, 33, 270, 33, 135, 135, 33, 135, 270, 270, 270, 135, 270, 270, 33, 33, 270, 135, 270, 33, 135, 270, 33, 270, 135, 33, 270, 33, 33, 270, 33, 33, 135]
Prompts retrieved: 14016 . Total input tokens: 3078471 . Total output tokens: 2840300
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 0.8447649432346225,
    "estimated_duration": 3598.588124065875,
    "input_throughput": 324.5631230173591,
    "output_throughput": 281.9669728842315,
    "total_throughput": 606.5300959015906,
    "itl": 18.750827106129194,
    "ttft": 6915.238578081058,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3588,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.728300458109471,
    "arrivals": 4708,
    "finished_requests": 4699,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8448262172751129. Arrivals time: 0.024932538624852896 Scheduler time: 0.42036782251670957 Scheduler overhead time: 0.14622316509485245 Adapter cache time: 0.0370035907253623 Engine time: 0.14276796719059348 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-32/adapters_96_slots_16_rate_0.025-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-32/adapters_96_slots_16_rate_0.025-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 270, 135, 135, 135, 135, 270, 135, 270, 135, 33, 270, 33, 33, 270, 135, 270, 135, 270, 270, 135, 33, 270, 135, 33, 33, 135, 270, 33, 135, 33, 33, 135, 135, 135, 33, 33, 270, 135, 135, 33, 270, 270, 135, 270, 270, 135, 270, 33, 270, 135, 135, 135, 270, 270, 33, 33, 135, 33, 270, 33, 33, 270, 33, 135, 135, 33, 135, 270, 270, 270, 135, 270, 270, 33, 33, 270, 135, 270, 33, 135, 270, 33, 270, 135, 33, 270, 33, 33, 270, 33, 33, 135]
Prompts retrieved: 14016 . Total input tokens: 3078471 . Total output tokens: 2840300
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 0.8499411758966744,
    "estimated_duration": 3598.5767221780325,
    "input_throughput": 324.5641513773503,
    "output_throughput": 281.967866280718,
    "total_throughput": 606.5320176580683,
    "itl": 18.758440144796744,
    "ttft": 6915.400354952412,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3587,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.900979832521813,
    "arrivals": 4708,
    "finished_requests": 4699,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8500212170183659. Arrivals time: 0.024354442488402128 Scheduler time: 0.42407303815707564 Scheduler overhead time: 0.14566890010610223 Adapter cache time: 0.03752723429352045 Engine time: 0.1449405518360436 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-8/adapters_96_slots_16_rate_0.025-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-8/adapters_96_slots_16_rate_0.025-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 270, 66, 66, 66, 66, 270, 66, 270, 66, 33, 270, 33, 33, 270, 66, 270, 66, 270, 270, 66, 33, 270, 66, 33, 33, 66, 270, 33, 66, 33, 33, 66, 66, 66, 33, 33, 270, 66, 66, 33, 270, 270, 66, 270, 270, 66, 270, 33, 270, 66, 66, 66, 270, 270, 33, 33, 66, 33, 270, 33, 33, 270, 33, 66, 66, 33, 66, 270, 270, 270, 66, 270, 270, 33, 33, 270, 66, 270, 33, 66, 270, 33, 270, 66, 33, 270, 33, 33, 270, 33, 33, 66]
Prompts retrieved: 11808 . Total input tokens: 2568820 . Total output tokens: 2402004
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 0.816040774807334,
    "estimated_duration": 3599.5774891705664,
    "input_throughput": 265.78536033140136,
    "output_throughput": 238.599669706764,
    "total_throughput": 504.3850300381654,
    "itl": 18.55533727979138,
    "ttft": 3699.475153609109,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2811,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.603031048195058,
    "arrivals": 3927,
    "finished_requests": 3923,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8161354311741889. Arrivals time: 0.023392657283693552 Scheduler time: 0.3850736431777477 Scheduler overhead time: 0.14571559661999345 Adapter cache time: 0.034655742812901735 Engine time: 0.15393831906840205 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-16/adapters_96_slots_16_rate_0.025-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-16/adapters_96_slots_16_rate_0.025-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 270, 66, 66, 66, 66, 270, 66, 270, 66, 33, 270, 33, 33, 270, 66, 270, 66, 270, 270, 66, 33, 270, 66, 33, 33, 66, 270, 33, 66, 33, 33, 66, 66, 66, 33, 33, 270, 66, 66, 33, 270, 270, 66, 270, 270, 66, 270, 33, 270, 66, 66, 66, 270, 270, 33, 33, 66, 33, 270, 33, 33, 270, 33, 66, 66, 33, 66, 270, 270, 270, 66, 270, 270, 33, 33, 270, 66, 270, 33, 66, 270, 33, 270, 66, 33, 270, 33, 33, 270, 33, 33, 66]
Prompts retrieved: 11808 . Total input tokens: 2568820 . Total output tokens: 2402004
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 0.8122291923500597,
    "estimated_duration": 3599.577301698445,
    "input_throughput": 265.785374173956,
    "output_throughput": 238.5996821334415,
    "total_throughput": 504.38505630739746,
    "itl": 18.559520121672442,
    "ttft": 3699.677539013737,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2811,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.10577235009507,
    "arrivals": 3927,
    "finished_requests": 3923,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8122960873879492. Arrivals time: 0.023635723628103733 Scheduler time: 0.38450290402397513 Scheduler overhead time: 0.1492439261637628 Adapter cache time: 0.035040192771703005 Engine time: 0.1457894970662892 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-32/adapters_96_slots_16_rate_0.025-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-32/adapters_96_slots_16_rate_0.025-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 270, 66, 66, 66, 66, 270, 66, 270, 66, 33, 270, 33, 33, 270, 66, 270, 66, 270, 270, 66, 33, 270, 66, 33, 33, 66, 270, 33, 66, 33, 33, 66, 66, 66, 33, 33, 270, 66, 66, 33, 270, 270, 66, 270, 270, 66, 270, 33, 270, 66, 66, 66, 270, 270, 33, 33, 66, 33, 270, 33, 33, 270, 33, 66, 66, 33, 66, 270, 270, 270, 66, 270, 270, 33, 33, 270, 66, 270, 33, 66, 270, 33, 270, 66, 33, 270, 33, 33, 270, 33, 33, 66]
Prompts retrieved: 11808 . Total input tokens: 2568820 . Total output tokens: 2402004
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 0.7991774161346257,
    "estimated_duration": 3599.5787806014873,
    "input_throughput": 265.7852649748462,
    "output_throughput": 238.59958410369487,
    "total_throughput": 504.38484907854104,
    "itl": 18.55969373096985,
    "ttft": 3699.704042061311,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2811,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.133710936996817,
    "arrivals": 3927,
    "finished_requests": 3923,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7993102292530239. Arrivals time: 0.023106287233531475 Scheduler time: 0.3771676626056433 Scheduler overhead time: 0.14566402044147253 Adapter cache time: 0.03430614760145545 Engine time: 0.14521246124058962 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-16/adapters_96_slots_16_rate_0.025-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-16/adapters_96_slots_16_rate_0.025-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 270, 66, 66, 66, 66, 270, 66, 270, 66, 33, 270, 33, 33, 270, 66, 270, 66, 270, 270, 66, 33, 270, 66, 33, 33, 66, 270, 33, 66, 33, 33, 66, 66, 66, 33, 33, 270, 66, 66, 33, 270, 270, 66, 270, 270, 66, 270, 33, 270, 66, 66, 66, 270, 270, 33, 33, 66, 33, 270, 33, 33, 270, 33, 66, 66, 33, 66, 270, 270, 270, 66, 270, 270, 33, 33, 270, 66, 270, 33, 66, 270, 33, 270, 66, 33, 270, 33, 33, 270, 33, 33, 66]
Prompts retrieved: 11808 . Total input tokens: 2568820 . Total output tokens: 2402004
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 0.795487655326724,
    "estimated_duration": 3599.5935827434582,
    "input_throughput": 265.78417202056244,
    "output_throughput": 238.59860294156172,
    "total_throughput": 504.3827749621242,
    "itl": 18.557203905686237,
    "ttft": 3699.492035633237,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2811,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.770315593655555,
    "arrivals": 3927,
    "finished_requests": 3923,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7955579510889947. Arrivals time: 0.023233124054968357 Scheduler time: 0.37574923364445567 Scheduler overhead time: 0.14476636797189713 Adapter cache time: 0.03440093481913209 Engine time: 0.1439471929334104 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-32/adapters_96_slots_16_rate_0.025-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-32/adapters_96_slots_16_rate_0.025-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 270, 66, 66, 66, 66, 270, 66, 270, 66, 33, 270, 33, 33, 270, 66, 270, 66, 270, 270, 66, 33, 270, 66, 33, 33, 66, 270, 33, 66, 33, 33, 66, 66, 66, 33, 33, 270, 66, 66, 33, 270, 270, 66, 270, 270, 66, 270, 33, 270, 66, 66, 66, 270, 270, 33, 33, 66, 33, 270, 33, 33, 270, 33, 66, 66, 33, 66, 270, 270, 270, 66, 270, 270, 33, 33, 270, 66, 270, 33, 66, 270, 33, 270, 66, 33, 270, 33, 33, 270, 33, 33, 66]
Prompts retrieved: 11808 . Total input tokens: 2568820 . Total output tokens: 2402004
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 0.8076710938476026,
    "estimated_duration": 3599.5850210943354,
    "input_throughput": 265.7848041908848,
    "output_throughput": 238.59917045073504,
    "total_throughput": 504.3839746416199,
    "itl": 18.55930411009939,
    "ttft": 3699.817192262426,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2811,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.236954795643301,
    "arrivals": 3927,
    "finished_requests": 3923,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.807788569945842. Arrivals time: 0.02298794174566865 Scheduler time: 0.3840642557479441 Scheduler overhead time: 0.1457511023618281 Adapter cache time: 0.034473489969968796 Engine time: 0.1459302231669426 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-16/adapters_96_slots_16_rate_0.025-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-16/adapters_96_slots_16_rate_0.025-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 270, 66, 66, 66, 66, 270, 66, 270, 66, 33, 270, 33, 33, 270, 66, 270, 66, 270, 270, 66, 33, 270, 66, 33, 33, 66, 270, 33, 66, 33, 33, 66, 66, 66, 33, 33, 270, 66, 66, 33, 270, 270, 66, 270, 270, 66, 270, 33, 270, 66, 66, 66, 270, 270, 33, 33, 66, 33, 270, 33, 33, 270, 33, 66, 66, 33, 66, 270, 270, 270, 66, 270, 270, 33, 33, 270, 66, 270, 33, 66, 270, 33, 270, 66, 33, 270, 33, 33, 270, 33, 33, 66]
Prompts retrieved: 11808 . Total input tokens: 2568820 . Total output tokens: 2402004
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 0.7980566849000752,
    "estimated_duration": 3599.5822177497644,
    "input_throughput": 265.78501118334754,
    "output_throughput": 238.59935627110215,
    "total_throughput": 504.38436745444966,
    "itl": 18.554888189242313,
    "ttft": 3699.5668331674865,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2811,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.405031378969873,
    "arrivals": 3927,
    "finished_requests": 3923,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7981331991031766. Arrivals time: 0.023575336672365665 Scheduler time: 0.3754686922766268 Scheduler overhead time: 0.14574819849804044 Adapter cache time: 0.03428794024512172 Engine time: 0.14493444375693798 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-32/adapters_96_slots_16_rate_0.025-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-32/adapters_96_slots_16_rate_0.025-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 270, 66, 66, 66, 66, 270, 66, 270, 66, 33, 270, 33, 33, 270, 66, 270, 66, 270, 270, 66, 33, 270, 66, 33, 33, 66, 270, 33, 66, 33, 33, 66, 66, 66, 33, 33, 270, 66, 66, 33, 270, 270, 66, 270, 270, 66, 270, 33, 270, 66, 66, 66, 270, 270, 33, 33, 66, 33, 270, 33, 33, 270, 33, 66, 66, 33, 66, 270, 270, 270, 66, 270, 270, 33, 33, 270, 66, 270, 33, 66, 270, 33, 270, 66, 33, 270, 33, 33, 270, 33, 33, 66]
Prompts retrieved: 11808 . Total input tokens: 2568820 . Total output tokens: 2402004
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 0.7984434869140387,
    "estimated_duration": 3599.594981166609,
    "input_throughput": 265.7840687648514,
    "output_throughput": 238.59851024729699,
    "total_throughput": 504.38257901214837,
    "itl": 18.560053540246614,
    "ttft": 3699.7765361110887,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2811,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.349378680698084,
    "arrivals": 3927,
    "finished_requests": 3923,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7985537368804216. Arrivals time: 0.023294624406844378 Scheduler time: 0.3772655329667032 Scheduler overhead time: 0.1456070365384221 Adapter cache time: 0.03445159364491701 Engine time: 0.14406882598996162 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-8/adapters_96_slots_16_rate_0.0125-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-8/adapters_96_slots_16_rate_0.0125-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 135, 66, 66, 66, 66, 135, 66, 135, 66, 33, 135, 33, 33, 135, 66, 135, 66, 135, 135, 66, 33, 135, 66, 33, 33, 66, 135, 33, 66, 33, 33, 66, 66, 66, 33, 33, 135, 66, 66, 33, 135, 135, 66, 135, 135, 66, 135, 33, 135, 66, 66, 66, 135, 135, 33, 33, 66, 33, 135, 33, 33, 135, 33, 66, 66, 33, 66, 135, 135, 135, 66, 135, 135, 33, 33, 135, 66, 135, 33, 66, 135, 33, 135, 66, 33, 135, 33, 33, 135, 33, 33, 66]
Prompts retrieved: 7488 . Total input tokens: 1626076 . Total output tokens: 1517852
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 0.6762287090532482,
    "estimated_duration": 3599.030747739171,
    "input_throughput": 161.63435123899055,
    "output_throughput": 147.422747175277,
    "total_throughput": 309.05709841426756,
    "itl": 17.98712492466264,
    "ttft": 8938.990632593348,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1904,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.82716866444813,
    "arrivals": 2425,
    "finished_requests": 2419,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6763382432982326. Arrivals time: 0.019858740270137787 Scheduler time: 0.2715566256083548 Scheduler overhead time: 0.14241114910691977 Adapter cache time: 0.029596108477562666 Engine time: 0.1405417649075389 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-16/adapters_96_slots_16_rate_0.0125-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-16/adapters_96_slots_16_rate_0.0125-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 135, 66, 66, 66, 66, 135, 66, 135, 66, 33, 135, 33, 33, 135, 66, 135, 66, 135, 135, 66, 33, 135, 66, 33, 33, 66, 135, 33, 66, 33, 33, 66, 66, 66, 33, 33, 135, 66, 66, 33, 135, 135, 66, 135, 135, 66, 135, 33, 135, 66, 66, 66, 135, 135, 33, 33, 66, 33, 135, 33, 33, 135, 33, 66, 66, 33, 66, 135, 135, 135, 66, 135, 135, 33, 33, 135, 66, 135, 33, 66, 135, 33, 135, 66, 33, 135, 33, 33, 135, 33, 33, 66]
Prompts retrieved: 7488 . Total input tokens: 1626076 . Total output tokens: 1517852
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 0.6853373376652598,
    "estimated_duration": 3599.0331078259414,
    "input_throughput": 161.63424524633015,
    "output_throughput": 147.42265050195815,
    "total_throughput": 309.0568957482883,
    "itl": 17.98954870179836,
    "ttft": 8939.009740490124,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1904,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.179692785756008,
    "arrivals": 2425,
    "finished_requests": 2419,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6853886628523469. Arrivals time: 0.0189527478069067 Scheduler time: 0.28213974833488464 Scheduler overhead time: 0.14279839489609003 Adapter cache time: 0.029537001624703407 Engine time: 0.13986086752265692 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-32/adapters_96_slots_16_rate_0.0125-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-32/adapters_96_slots_16_rate_0.0125-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 135, 66, 66, 66, 66, 135, 66, 135, 66, 33, 135, 33, 33, 135, 66, 135, 66, 135, 135, 66, 33, 135, 66, 33, 33, 66, 135, 33, 66, 33, 33, 66, 66, 66, 33, 33, 135, 66, 66, 33, 135, 135, 66, 135, 135, 66, 135, 33, 135, 66, 66, 66, 135, 135, 33, 33, 66, 33, 135, 33, 33, 135, 33, 66, 66, 33, 66, 135, 135, 135, 66, 135, 135, 33, 33, 135, 66, 135, 33, 66, 135, 33, 135, 66, 33, 135, 33, 33, 135, 33, 33, 66]
Prompts retrieved: 7488 . Total input tokens: 1626076 . Total output tokens: 1517852
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 0.6886411961168051,
    "estimated_duration": 3599.033196545268,
    "input_throughput": 161.63424126190418,
    "output_throughput": 147.42264686786044,
    "total_throughput": 309.0568881297646,
    "itl": 17.988933223982674,
    "ttft": 8938.973669417433,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1904,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.196521654035829,
    "arrivals": 2425,
    "finished_requests": 2419,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6887048170901835. Arrivals time: 0.01988968625664711 Scheduler time: 0.2829081346280873 Scheduler overhead time: 0.14197527477517724 Adapter cache time: 0.029932525008916855 Engine time: 0.1415978753939271 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-16/adapters_96_slots_16_rate_0.0125-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-16/adapters_96_slots_16_rate_0.0125-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 135, 66, 66, 66, 66, 135, 66, 135, 66, 33, 135, 33, 33, 135, 66, 135, 66, 135, 135, 66, 33, 135, 66, 33, 33, 66, 135, 33, 66, 33, 33, 66, 66, 66, 33, 33, 135, 66, 66, 33, 135, 135, 66, 135, 135, 66, 135, 33, 135, 66, 66, 66, 135, 135, 33, 33, 66, 33, 135, 33, 33, 135, 33, 66, 66, 33, 66, 135, 135, 135, 66, 135, 135, 33, 33, 135, 66, 135, 33, 66, 135, 33, 135, 66, 33, 135, 33, 33, 135, 33, 33, 66]
Prompts retrieved: 7488 . Total input tokens: 1626076 . Total output tokens: 1517852
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 0.6785303871147335,
    "estimated_duration": 3599.032290635305,
    "input_throughput": 161.63428194674879,
    "output_throughput": 147.42268397551433,
    "total_throughput": 309.05696592226315,
    "itl": 17.988503851016993,
    "ttft": 8939.040896983373,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1904,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.934126999373383,
    "arrivals": 2425,
    "finished_requests": 2419,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6786072417162359. Arrivals time: 0.019495001528412104 Scheduler time: 0.27458679024130106 Scheduler overhead time: 0.14263412822037935 Adapter cache time: 0.029665842652320862 Engine time: 0.14022187888622284 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-32/adapters_96_slots_16_rate_0.0125-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-32/adapters_96_slots_16_rate_0.0125-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 135, 66, 66, 66, 66, 135, 66, 135, 66, 33, 135, 33, 33, 135, 66, 135, 66, 135, 135, 66, 33, 135, 66, 33, 33, 66, 135, 33, 66, 33, 33, 66, 66, 66, 33, 33, 135, 66, 66, 33, 135, 135, 66, 135, 135, 66, 135, 33, 135, 66, 66, 66, 135, 135, 33, 33, 66, 33, 135, 33, 33, 135, 33, 66, 66, 33, 66, 135, 135, 135, 66, 135, 135, 33, 33, 135, 66, 135, 33, 66, 135, 33, 135, 66, 33, 135, 33, 33, 135, 33, 33, 66]
Prompts retrieved: 7488 . Total input tokens: 1626076 . Total output tokens: 1517852
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 0.6810496728867292,
    "estimated_duration": 3599.03344805284,
    "input_throughput": 161.63422996658386,
    "output_throughput": 147.42263656567445,
    "total_throughput": 309.0568665322583,
    "itl": 17.988616725563944,
    "ttft": 8939.078670335994,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1904,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.272099679671095,
    "arrivals": 2425,
    "finished_requests": 2419,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6811215248890221. Arrivals time: 0.019468132872134447 Scheduler time: 0.27459404710680246 Scheduler overhead time: 0.14305243641138077 Adapter cache time: 0.029627420008182526 Engine time: 0.14203012781217694 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-16/adapters_96_slots_16_rate_0.0125-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-16/adapters_96_slots_16_rate_0.0125-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 135, 66, 66, 66, 66, 135, 66, 135, 66, 33, 135, 33, 33, 135, 66, 135, 66, 135, 135, 66, 33, 135, 66, 33, 33, 66, 135, 33, 66, 33, 33, 66, 66, 66, 33, 33, 135, 66, 66, 33, 135, 135, 66, 135, 135, 66, 135, 33, 135, 66, 66, 66, 135, 135, 33, 33, 66, 33, 135, 33, 33, 135, 33, 66, 66, 33, 66, 135, 135, 135, 66, 135, 135, 33, 33, 135, 66, 135, 33, 66, 135, 33, 135, 66, 33, 135, 33, 33, 135, 33, 33, 66]
Prompts retrieved: 7488 . Total input tokens: 1626076 . Total output tokens: 1517852
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 0.6864616181701422,
    "estimated_duration": 3599.029972927234,
    "input_throughput": 161.63438603620693,
    "output_throughput": 147.42277891296888,
    "total_throughput": 309.05716494917584,
    "itl": 17.986330654684345,
    "ttft": 8939.004470203035,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1904,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.693055761493577,
    "arrivals": 2425,
    "finished_requests": 2419,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6865190998651087. Arrivals time: 0.01929472479969263 Scheduler time: 0.2826325595378876 Scheduler overhead time: 0.14158519869670272 Adapter cache time: 0.029704279266297817 Engine time: 0.14112394815310836 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-32/adapters_96_slots_16_rate_0.0125-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-32/adapters_96_slots_16_rate_0.0125-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 135, 66, 66, 66, 66, 135, 66, 135, 66, 33, 135, 33, 33, 135, 66, 135, 66, 135, 135, 66, 33, 135, 66, 33, 33, 66, 135, 33, 66, 33, 33, 66, 66, 66, 33, 33, 135, 66, 66, 33, 135, 135, 66, 135, 135, 66, 135, 33, 135, 66, 66, 66, 135, 135, 33, 33, 66, 33, 135, 33, 33, 135, 33, 66, 66, 33, 66, 135, 135, 135, 66, 135, 135, 33, 33, 135, 66, 135, 33, 66, 135, 33, 135, 66, 33, 135, 33, 33, 135, 33, 33, 66]
Prompts retrieved: 7488 . Total input tokens: 1626076 . Total output tokens: 1517852
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 0.6798657383769751,
    "estimated_duration": 3599.03407682177,
    "input_throughput": 161.63420172829,
    "output_throughput": 147.42261081021576,
    "total_throughput": 309.05681253850577,
    "itl": 17.989034236754996,
    "ttft": 8939.096029897399,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1904,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.3462944136558175,
    "arrivals": 2425,
    "finished_requests": 2419,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6799285393208265. Arrivals time: 0.019599083345383406 Scheduler time: 0.2749703470617533 Scheduler overhead time: 0.1427124459296465 Adapter cache time: 0.02974561881273985 Engine time: 0.14057875145226717 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-8/adapters_96_slots_32_rate_3.2-1.6-0.8_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-8/adapters_96_slots_32_rate_3.2-1.6-0.8_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [8640, 8640, 8640, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 34560, 17280, 17280, 8640, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 8640, 34560, 17280, 17280, 17280, 34560, 34560, 8640, 8640, 17280, 8640, 34560, 8640, 8640, 34560, 8640, 17280, 17280, 8640, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 8640, 8640, 34560, 17280, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 8640, 8640, 17280]
Prompts retrieved: 1935360 . Total input tokens: 431807893 . Total output tokens: 386940663
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 147.8049983768724,
    "estimated_duration": 3600.0315087160557,
    "input_throughput": 7630.955432886675,
    "output_throughput": 6730.630535131553,
    "total_throughput": 14361.58596801823,
    "itl": 124.5376018616614,
    "ttft": 1869224.7828076007,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 156,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.477436088053509,
    "arrivals": 644954,
    "finished_requests": 111124,
    "scheduler_time": 184.18462065002757
}
#Debug simulation 
Total elapsed time: 147.80513721285388. Arrivals time: 0.8945488599129021 Scheduler time: 146.62124698841944 Scheduler overhead time: 0.11564017180353403 Adapter cache time: 0.023170944303274155 Engine time: 0.1158612216822803 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-16/adapters_96_slots_32_rate_3.2-1.6-0.8_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-16/adapters_96_slots_32_rate_3.2-1.6-0.8_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [8640, 8640, 8640, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 34560, 17280, 17280, 8640, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 8640, 34560, 17280, 17280, 17280, 34560, 34560, 8640, 8640, 17280, 8640, 34560, 8640, 8640, 34560, 8640, 17280, 17280, 8640, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 8640, 8640, 34560, 17280, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 8640, 8640, 17280]
Prompts retrieved: 1935360 . Total input tokens: 431807893 . Total output tokens: 386940663
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 130.1640428979881,
    "estimated_duration": 3600.087645207947,
    "input_throughput": 7627.815127376939,
    "output_throughput": 6735.190470230743,
    "total_throughput": 14363.005597607682,
    "itl": 124.92019317876166,
    "ttft": 1868894.6847324856,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 164,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5320449708448726,
    "arrivals": 644954,
    "finished_requests": 111130,
    "scheduler_time": 184.05975913958386
}
#Debug simulation 
Total elapsed time: 130.16428009793162. Arrivals time: 0.9462181492708623 Scheduler time: 128.9509311034344 Scheduler overhead time: 0.10675751604139805 Adapter cache time: 0.021138724870979786 Engine time: 0.10692762490361929 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-32/adapters_96_slots_32_rate_3.2-1.6-0.8_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-32/adapters_96_slots_32_rate_3.2-1.6-0.8_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [8640, 8640, 8640, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 34560, 17280, 17280, 8640, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 8640, 34560, 17280, 17280, 17280, 34560, 34560, 8640, 8640, 17280, 8640, 34560, 8640, 8640, 34560, 8640, 17280, 17280, 8640, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 8640, 8640, 34560, 17280, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 8640, 8640, 17280]
Prompts retrieved: 1935360 . Total input tokens: 431807893 . Total output tokens: 386940663
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 133.41175033524632,
    "estimated_duration": 3600.09084200372,
    "input_throughput": 7627.80835405698,
    "output_throughput": 6735.18448954043,
    "total_throughput": 14362.992843597409,
    "itl": 124.92020393814053,
    "ttft": 1868896.698724014,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 164,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5335363356396575,
    "arrivals": 644954,
    "finished_requests": 111130,
    "scheduler_time": 184.05988110012044
}
#Debug simulation 
Total elapsed time: 133.41190680209547. Arrivals time: 0.9181803907267749 Scheduler time: 132.22551434952766 Scheduler overhead time: 0.10837413230910897 Adapter cache time: 0.01995895244181156 Engine time: 0.10659229755401611 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-16/adapters_96_slots_32_rate_3.2-1.6-0.8_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-16/adapters_96_slots_32_rate_3.2-1.6-0.8_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [8640, 8640, 8640, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 34560, 17280, 17280, 8640, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 8640, 34560, 17280, 17280, 17280, 34560, 34560, 8640, 8640, 17280, 8640, 34560, 8640, 8640, 34560, 8640, 17280, 17280, 8640, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 8640, 8640, 34560, 17280, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 8640, 8640, 17280]
Prompts retrieved: 1935360 . Total input tokens: 431807893 . Total output tokens: 386940663
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 132.1942938277498,
    "estimated_duration": 3600.064702352832,
    "input_throughput": 7627.863738685841,
    "output_throughput": 6735.23339293128,
    "total_throughput": 14363.09713161712,
    "itl": 124.91964427932447,
    "ttft": 1868882.9881042112,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 164,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5112066096044149,
    "arrivals": 644954,
    "finished_requests": 111130,
    "scheduler_time": 184.0592801043331
}
#Debug simulation 
Total elapsed time: 132.19445020891726. Arrivals time: 0.8249786444939673 Scheduler time: 131.0988484234549 Scheduler overhead time: 0.10860040551051497 Adapter cache time: 0.02174099115654826 Engine time: 0.10858301166445017 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-32/adapters_96_slots_32_rate_3.2-1.6-0.8_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-32/adapters_96_slots_32_rate_3.2-1.6-0.8_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [8640, 8640, 8640, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 34560, 17280, 17280, 8640, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 8640, 34560, 17280, 17280, 17280, 34560, 34560, 8640, 8640, 17280, 8640, 34560, 8640, 8640, 34560, 8640, 17280, 17280, 8640, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 8640, 8640, 34560, 17280, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 8640, 8640, 17280]
Prompts retrieved: 1935360 . Total input tokens: 431807893 . Total output tokens: 386940663
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 130.97245141817257,
    "estimated_duration": 3600.09766594859,
    "input_throughput": 7627.793895631537,
    "output_throughput": 6735.171723073541,
    "total_throughput": 14362.965618705079,
    "itl": 124.92026973106827,
    "ttft": 1868899.8699015456,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 164,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5399497787468146,
    "arrivals": 644954,
    "finished_requests": 111130,
    "scheduler_time": 184.06005940438837
}
#Debug simulation 
Total elapsed time: 130.97259993525222. Arrivals time: 0.9458428365178406 Scheduler time: 129.76472704159096 Scheduler overhead time: 0.10601256974041462 Adapter cache time: 0.020291950087994337 Engine time: 0.10344727616757154 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-16/adapters_96_slots_32_rate_3.2-1.6-0.8_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-16/adapters_96_slots_32_rate_3.2-1.6-0.8_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [8640, 8640, 8640, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 34560, 17280, 17280, 8640, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 8640, 34560, 17280, 17280, 17280, 34560, 34560, 8640, 8640, 17280, 8640, 34560, 8640, 8640, 34560, 8640, 17280, 17280, 8640, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 8640, 8640, 34560, 17280, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 8640, 8640, 17280]
Prompts retrieved: 1935360 . Total input tokens: 431807893 . Total output tokens: 386940663
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 149.4949522302486,
    "estimated_duration": 3600.0748363941084,
    "input_throughput": 7610.591791875907,
    "output_throughput": 6718.1339552999025,
    "total_throughput": 14328.72574717581,
    "itl": 123.90026135871527,
    "ttft": 1871407.7009685219,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 155,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4634577957098378,
    "arrivals": 644954,
    "finished_requests": 110826,
    "scheduler_time": 185.2111792347998
}
#Debug simulation 
Total elapsed time: 149.49517254903913. Arrivals time: 0.877160501666367 Scheduler time: 148.33434379426762 Scheduler overhead time: 0.11471456987783313 Adapter cache time: 0.021765627432614565 Engine time: 0.11316254502162337 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-32/adapters_96_slots_32_rate_3.2-1.6-0.8_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-32/adapters_96_slots_32_rate_3.2-1.6-0.8_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [8640, 8640, 8640, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 34560, 17280, 17280, 8640, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 8640, 34560, 17280, 17280, 17280, 34560, 34560, 8640, 8640, 17280, 8640, 34560, 8640, 8640, 34560, 8640, 17280, 17280, 8640, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 8640, 8640, 34560, 17280, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 8640, 8640, 17280]
Prompts retrieved: 1935360 . Total input tokens: 431807893 . Total output tokens: 386940663
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 132.09734099078923,
    "estimated_duration": 3600.1044670508586,
    "input_throughput": 7627.779485659037,
    "output_throughput": 6735.1589993895195,
    "total_throughput": 14362.938485048557,
    "itl": 124.9204427614081,
    "ttft": 1868903.1967240267,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 164,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5463632218539718,
    "arrivals": 644954,
    "finished_requests": 111130,
    "scheduler_time": 184.06010774845896
}
#Debug simulation 
Total elapsed time: 132.09758790396154. Arrivals time: 0.9432499632239342 Scheduler time: 130.88770530885085 Scheduler overhead time: 0.10788282006978989 Adapter cache time: 0.02127741975709796 Engine time: 0.10477045830339193 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-8/adapters_96_slots_32_rate_3.2-1.6-0.4_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-8/adapters_96_slots_32_rate_3.2-1.6-0.4_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 34560, 17280, 17280, 4320, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 4320, 34560, 17280, 17280, 17280, 34560, 34560, 4320, 4320, 17280, 4320, 34560, 4320, 4320, 34560, 4320, 17280, 17280, 4320, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 4320, 4320, 34560, 17280, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 4320, 4320, 17280]
Prompts retrieved: 1797120 . Total input tokens: 400994416 . Total output tokens: 359255850
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 149.17844689404592,
    "estimated_duration": 3600.125029437696,
    "input_throughput": 7649.775431355366,
    "output_throughput": 6746.790959033372,
    "total_throughput": 14396.566390388738,
    "itl": 125.39584030625994,
    "ttft": 1849414.0030752895,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 142,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4345892596384505,
    "arrivals": 599169,
    "finished_requests": 111269,
    "scheduler_time": 183.39855594115764
}
#Debug simulation 
Total elapsed time: 149.1786099378951. Arrivals time: 0.8576841237954795 Scheduler time: 148.0386786214076 Scheduler overhead time: 0.11402057064697146 Adapter cache time: 0.02272798726335168 Engine time: 0.11252578860148787 
