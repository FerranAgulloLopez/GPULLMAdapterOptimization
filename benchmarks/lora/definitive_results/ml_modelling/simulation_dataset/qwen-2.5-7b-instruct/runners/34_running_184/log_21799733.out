INFO 06-01 00:47:02 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:47:02 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-16/adapters_96_slots_32_rate_1.6-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-16/adapters_96_slots_32_rate_1.6-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 33, 17280, 1080, 33, 33, 1080, 17280, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 17280, 1080, 1080, 33, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 33, 17280, 1080, 1080, 1080, 17280, 17280, 33, 33, 1080, 33, 17280, 33, 33, 17280, 33, 1080, 1080, 33, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 33, 33, 17280, 1080, 17280, 33, 1080, 17280, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 33, 33, 1080]
Prompts retrieved: 588576 . Total input tokens: 131231793 . Total output tokens: 117798990
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 59.66816902719438,
    "estimated_duration": 3600.0594629387942,
    "input_throughput": 7697.526745121747,
    "output_throughput": 6801.4693235127515,
    "total_throughput": 14498.996068634498,
    "itl": 126.04756375016274,
    "ttft": 1233134.2326001574,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 51,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.15249256504001107,
    "arrivals": 195753,
    "finished_requests": 112131,
    "scheduler_time": 169.90084714031488
}
#Debug simulation 
Total elapsed time: 59.668434999417514. Arrivals time: 0.6831249208189547 Scheduler time: 58.76316064270213 Scheduler overhead time: 0.08715124614536762 Adapter cache time: 0.016384303104132414 Engine time: 0.08957612700760365 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-32/adapters_96_slots_32_rate_1.6-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-32/adapters_96_slots_32_rate_1.6-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 33, 17280, 1080, 33, 33, 1080, 17280, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 17280, 1080, 1080, 33, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 33, 17280, 1080, 1080, 1080, 17280, 17280, 33, 33, 1080, 33, 17280, 33, 33, 17280, 33, 1080, 1080, 33, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 33, 33, 17280, 1080, 17280, 33, 1080, 17280, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 33, 33, 1080]
Prompts retrieved: 588576 . Total input tokens: 131231793 . Total output tokens: 117798990
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 59.09077163785696,
    "estimated_duration": 3600.034305466728,
    "input_throughput": 7697.5805363630625,
    "output_throughput": 6801.516852997194,
    "total_throughput": 14499.097389360257,
    "itl": 126.04853021165826,
    "ttft": 1233131.640225905,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 51,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.16864649843424542,
    "arrivals": 195753,
    "finished_requests": 112131,
    "scheduler_time": 169.899536043599
}
#Debug simulation 
Total elapsed time: 59.09101192699745. Arrivals time: 0.6908948998898268 Scheduler time: 58.1826751884073 Scheduler overhead time: 0.08663068478927016 Adapter cache time: 0.016690780874341726 Engine time: 0.08528258884325624 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-8/adapters_96_slots_32_rate_1.6-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-8/adapters_96_slots_32_rate_1.6-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 540, 270, 17280, 540, 270, 270, 540, 17280, 270, 540, 270, 270, 540, 540, 540, 270, 270, 17280, 540, 540, 270, 17280, 17280, 540, 17280, 17280, 540, 17280, 270, 17280, 540, 540, 540, 17280, 17280, 270, 270, 540, 270, 17280, 270, 270, 17280, 270, 540, 540, 270, 540, 17280, 17280, 17280, 540, 17280, 17280, 270, 270, 17280, 540, 17280, 270, 540, 17280, 270, 17280, 540, 270, 17280, 270, 270, 17280, 270, 270, 540]
Prompts retrieved: 578880 . Total input tokens: 129047310 . Total output tokens: 115859917
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 41.586993432138115,
    "estimated_duration": 3600.1046595233397,
    "input_throughput": 7698.153976353955,
    "output_throughput": 6808.775943543117,
    "total_throughput": 14506.929919897073,
    "itl": 126.28547668128503,
    "ttft": 1235337.5116169685,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 40,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.12241950975731009,
    "arrivals": 192543,
    "finished_requests": 111748,
    "scheduler_time": 169.62433778582056
}
#Debug simulation 
Total elapsed time: 41.58718010224402. Arrivals time: 0.6245297719724476 Scheduler time: 40.777924180962145 Scheduler overhead time: 0.07383893756195903 Adapter cache time: 0.012951925862580538 Engine time: 0.0715295230038464 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-16/adapters_96_slots_32_rate_1.6-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-16/adapters_96_slots_32_rate_1.6-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 540, 270, 17280, 540, 270, 270, 540, 17280, 270, 540, 270, 270, 540, 540, 540, 270, 270, 17280, 540, 540, 270, 17280, 17280, 540, 17280, 17280, 540, 17280, 270, 17280, 540, 540, 540, 17280, 17280, 270, 270, 540, 270, 17280, 270, 270, 17280, 270, 540, 540, 270, 540, 17280, 17280, 17280, 540, 17280, 17280, 270, 270, 17280, 540, 17280, 270, 540, 17280, 270, 17280, 540, 270, 17280, 270, 270, 17280, 270, 270, 540]
Prompts retrieved: 578880 . Total input tokens: 129047310 . Total output tokens: 115859917
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 41.31574504869059,
    "estimated_duration": 3600.129990777948,
    "input_throughput": 7698.169252497248,
    "output_throughput": 6808.749979248151,
    "total_throughput": 14506.919231745398,
    "itl": 126.28566313757736,
    "ttft": 1235324.2607973216,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 40,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.128999704120215,
    "arrivals": 192543,
    "finished_requests": 111749,
    "scheduler_time": 169.62563739251988
}
#Debug simulation 
Total elapsed time: 41.31591482274234. Arrivals time: 0.6196173932403326 Scheduler time: 40.51403321279213 Scheduler overhead time: 0.07119035301730037 Adapter cache time: 0.013081589248031378 Engine time: 0.07184536196291447 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-32/adapters_96_slots_32_rate_1.6-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-32/adapters_96_slots_32_rate_1.6-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 540, 270, 17280, 540, 270, 270, 540, 17280, 270, 540, 270, 270, 540, 540, 540, 270, 270, 17280, 540, 540, 270, 17280, 17280, 540, 17280, 17280, 540, 17280, 270, 17280, 540, 540, 540, 17280, 17280, 270, 270, 540, 270, 17280, 270, 270, 17280, 270, 540, 540, 270, 540, 17280, 17280, 17280, 540, 17280, 17280, 270, 270, 17280, 540, 17280, 270, 540, 17280, 270, 17280, 540, 270, 17280, 270, 270, 17280, 270, 270, 540]
Prompts retrieved: 578880 . Total input tokens: 129047310 . Total output tokens: 115859917
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 42.20895309187472,
    "estimated_duration": 3600.1335675167857,
    "input_throughput": 7698.16160435297,
    "output_throughput": 6808.743214743437,
    "total_throughput": 14506.904819096408,
    "itl": 126.28570910357759,
    "ttft": 1235325.4542831236,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 40,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.12949744632467625,
    "arrivals": 192543,
    "finished_requests": 111749,
    "scheduler_time": 169.62577729164795
}
#Debug simulation 
Total elapsed time: 42.20915324194357. Arrivals time: 0.6425292235799134 Scheduler time: 41.3778813672252 Scheduler overhead time: 0.07508730655536056 Adapter cache time: 0.013494179584085941 Engine time: 0.07386839529499412 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-16-16/adapters_96_slots_32_rate_1.6-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-16-16/adapters_96_slots_32_rate_1.6-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 540, 270, 17280, 540, 270, 270, 540, 17280, 270, 540, 270, 270, 540, 540, 540, 270, 270, 17280, 540, 540, 270, 17280, 17280, 540, 17280, 17280, 540, 17280, 270, 17280, 540, 540, 540, 17280, 17280, 270, 270, 540, 270, 17280, 270, 270, 17280, 270, 540, 540, 270, 540, 17280, 17280, 17280, 540, 17280, 17280, 270, 270, 17280, 540, 17280, 270, 540, 17280, 270, 17280, 540, 270, 17280, 270, 270, 17280, 270, 270, 540]
Prompts retrieved: 578880 . Total input tokens: 129047310 . Total output tokens: 115859917
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 42.39455703506246,
    "estimated_duration": 3600.11156105057,
    "input_throughput": 7698.139218750367,
    "output_throughput": 6808.762890905225,
    "total_throughput": 14506.902109655592,
    "itl": 126.285369055189,
    "ttft": 1235340.248028888,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 40,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.12450515561737122,
    "arrivals": 192543,
    "finished_requests": 111748,
    "scheduler_time": 169.62470425629488
}
#Debug simulation 
Total elapsed time: 42.39471005089581. Arrivals time: 0.6321863569319248 Scheduler time: 41.575959123205394 Scheduler overhead time: 0.07276849076151848 Adapter cache time: 0.013436521869152784 Engine time: 0.0741145322099328 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-16-32/adapters_96_slots_32_rate_1.6-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-16-32/adapters_96_slots_32_rate_1.6-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 540, 270, 17280, 540, 270, 270, 540, 17280, 270, 540, 270, 270, 540, 540, 540, 270, 270, 17280, 540, 540, 270, 17280, 17280, 540, 17280, 17280, 540, 17280, 270, 17280, 540, 540, 540, 17280, 17280, 270, 270, 540, 270, 17280, 270, 270, 17280, 270, 540, 540, 270, 540, 17280, 17280, 17280, 540, 17280, 17280, 270, 270, 17280, 540, 17280, 270, 540, 17280, 270, 17280, 540, 270, 17280, 270, 270, 17280, 270, 270, 540]
Prompts retrieved: 578880 . Total input tokens: 129047310 . Total output tokens: 115859917
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 41.568293544929475,
    "estimated_duration": 3600.018483721615,
    "input_throughput": 7698.1396415916415,
    "output_throughput": 6808.494209357893,
    "total_throughput": 14506.633850949534,
    "itl": 126.28542544329075,
    "ttft": 1235301.5920318929,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 40,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.13088073797523972,
    "arrivals": 192543,
    "finished_requests": 111744,
    "scheduler_time": 169.61984660541185
}
#Debug simulation 
Total elapsed time: 41.56849159067497. Arrivals time: 0.6225455598905683 Scheduler time: 40.76247129263356 Scheduler overhead time: 0.07221951941028237 Adapter cache time: 0.013104179874062538 Engine time: 0.0726221944205463 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_16-16-16/adapters_96_slots_32_rate_1.6-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_16-16-16/adapters_96_slots_32_rate_1.6-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 540, 270, 17280, 540, 270, 270, 540, 17280, 270, 540, 270, 270, 540, 540, 540, 270, 270, 17280, 540, 540, 270, 17280, 17280, 540, 17280, 17280, 540, 17280, 270, 17280, 540, 540, 540, 17280, 17280, 270, 270, 540, 270, 17280, 270, 270, 17280, 270, 540, 540, 270, 540, 17280, 17280, 17280, 540, 17280, 17280, 270, 270, 17280, 540, 17280, 270, 540, 17280, 270, 17280, 540, 270, 17280, 270, 270, 17280, 270, 270, 540]
Prompts retrieved: 578880 . Total input tokens: 129047310 . Total output tokens: 115859917
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 41.09474247600883,
    "estimated_duration": 3600.0957095747863,
    "input_throughput": 7698.17311420128,
    "output_throughput": 6808.792870369325,
    "total_throughput": 14506.965984570605,
    "itl": 126.28567287676314,
    "ttft": 1235334.6146937264,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 40,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.1196020117960871,
    "arrivals": 192543,
    "finished_requests": 111748,
    "scheduler_time": 169.62373679726716
}
#Debug simulation 
Total elapsed time: 41.09490083530545. Arrivals time: 0.623105991166085 Scheduler time: 40.291313593275845 Scheduler overhead time: 0.07179248426109552 Adapter cache time: 0.013274952303618193 Engine time: 0.06979840155690908 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_16-16-32/adapters_96_slots_32_rate_1.6-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_16-16-32/adapters_96_slots_32_rate_1.6-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 540, 270, 17280, 540, 270, 270, 540, 17280, 270, 540, 270, 270, 540, 540, 540, 270, 270, 17280, 540, 540, 270, 17280, 17280, 540, 17280, 17280, 540, 17280, 270, 17280, 540, 540, 540, 17280, 17280, 270, 270, 540, 270, 17280, 270, 270, 17280, 270, 540, 540, 270, 540, 17280, 17280, 17280, 540, 17280, 17280, 270, 270, 17280, 540, 17280, 270, 540, 17280, 270, 17280, 540, 270, 17280, 270, 270, 17280, 270, 270, 540]
Prompts retrieved: 578880 . Total input tokens: 129047310 . Total output tokens: 115859917
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 41.60102315200493,
    "estimated_duration": 3600.018720760101,
    "input_throughput": 7698.139134717787,
    "output_throughput": 6808.493761061569,
    "total_throughput": 14506.632895779356,
    "itl": 126.28524649118467,
    "ttft": 1235299.3758721922,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 40,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.132389783412218,
    "arrivals": 192543,
    "finished_requests": 111744,
    "scheduler_time": 169.61985080732015
}
#Debug simulation 
Total elapsed time: 41.601221846882254. Arrivals time: 0.6355635882355273 Scheduler time: 40.77694207476452 Scheduler overhead time: 0.07488421397283673 Adapter cache time: 0.0136078717187047 Engine time: 0.07362016243860126 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-8/adapters_96_slots_32_rate_1.6-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-8/adapters_96_slots_32_rate_1.6-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 540, 135, 17280, 540, 135, 135, 540, 17280, 135, 540, 135, 135, 540, 540, 540, 135, 135, 17280, 540, 540, 135, 17280, 17280, 540, 17280, 17280, 540, 17280, 135, 17280, 540, 540, 540, 17280, 17280, 135, 135, 540, 135, 17280, 135, 135, 17280, 135, 540, 540, 135, 540, 17280, 17280, 17280, 540, 17280, 17280, 135, 135, 17280, 540, 17280, 135, 540, 17280, 135, 17280, 540, 135, 17280, 135, 135, 17280, 135, 135, 540]
Prompts retrieved: 574560 . Total input tokens: 128078117 . Total output tokens: 114993343
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 34.14581115776673,
    "estimated_duration": 3600.032243136217,
    "input_throughput": 7695.074135187905,
    "output_throughput": 6810.953720414285,
    "total_throughput": 14506.02785560219,
    "itl": 126.48132302291957,
    "ttft": 1235481.55331519,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 42,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.12854048524517558,
    "arrivals": 191076,
    "finished_requests": 111513,
    "scheduler_time": 169.24760030216578
}
#Debug simulation 
Total elapsed time: 34.14595843665302. Arrivals time: 0.6096124318428338 Scheduler time: 33.36882290383801 Scheduler overhead time: 0.0652886419557035 Adapter cache time: 0.011279397644102573 Engine time: 0.06617984687909484 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-16/adapters_96_slots_32_rate_1.6-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-16/adapters_96_slots_32_rate_1.6-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 540, 135, 17280, 540, 135, 135, 540, 17280, 135, 540, 135, 135, 540, 540, 540, 135, 135, 17280, 540, 540, 135, 17280, 17280, 540, 17280, 17280, 540, 17280, 135, 17280, 540, 540, 540, 17280, 17280, 135, 135, 540, 135, 17280, 135, 135, 17280, 135, 540, 540, 135, 540, 17280, 17280, 17280, 540, 17280, 17280, 135, 135, 17280, 540, 17280, 135, 540, 17280, 135, 17280, 540, 135, 17280, 135, 135, 17280, 135, 135, 540]
Prompts retrieved: 574560 . Total input tokens: 128078117 . Total output tokens: 114993343
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 34.576174517162144,
    "estimated_duration": 3600.0822308572324,
    "input_throughput": 7695.072285447084,
    "output_throughput": 6810.943591741636,
    "total_throughput": 14506.01587718872,
    "itl": 126.48145449787765,
    "ttft": 1235481.732933326,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 42,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.13579699534690007,
    "arrivals": 191076,
    "finished_requests": 111515,
    "scheduler_time": 169.25017323954918
}
#Debug simulation 
Total elapsed time: 34.57644866593182. Arrivals time: 0.6259638131596148 Scheduler time: 33.780558322090656 Scheduler overhead time: 0.06654806947335601 Adapter cache time: 0.011620804201811552 Engine time: 0.06590192345902324 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-32/adapters_96_slots_32_rate_1.6-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-32/adapters_96_slots_32_rate_1.6-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 540, 135, 17280, 540, 135, 135, 540, 17280, 135, 540, 135, 135, 540, 540, 540, 135, 135, 17280, 540, 540, 135, 17280, 17280, 540, 17280, 17280, 540, 17280, 135, 17280, 540, 540, 540, 17280, 17280, 135, 135, 540, 135, 17280, 135, 135, 17280, 135, 540, 540, 135, 540, 17280, 17280, 17280, 540, 17280, 17280, 135, 135, 17280, 540, 17280, 135, 540, 17280, 135, 17280, 540, 135, 17280, 135, 135, 17280, 135, 135, 540]
Prompts retrieved: 574560 . Total input tokens: 128078117 . Total output tokens: 114993343
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 35.05017801607028,
    "estimated_duration": 3600.0830925322475,
    "input_throughput": 7695.070443641948,
    "output_throughput": 6810.941961551506,
    "total_throughput": 14506.012405193454,
    "itl": 126.48142626812603,
    "ttft": 1235482.3662409426,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 42,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.13625897901132702,
    "arrivals": 191076,
    "finished_requests": 111515,
    "scheduler_time": 169.25023361580529
}
#Debug simulation 
Total elapsed time: 35.050344297196716. Arrivals time: 0.6026175897568464 Scheduler time: 34.27374096494168 Scheduler overhead time: 0.0690571223385632 Adapter cache time: 0.011975441593676805 Engine time: 0.06790907308459282 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-16/adapters_96_slots_32_rate_1.6-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-16/adapters_96_slots_32_rate_1.6-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 540, 135, 17280, 540, 135, 135, 540, 17280, 135, 540, 135, 135, 540, 540, 540, 135, 135, 17280, 540, 540, 135, 17280, 17280, 540, 17280, 17280, 540, 17280, 135, 17280, 540, 540, 540, 17280, 17280, 135, 135, 540, 135, 17280, 135, 135, 17280, 135, 540, 540, 135, 540, 17280, 17280, 17280, 540, 17280, 17280, 135, 135, 17280, 540, 17280, 135, 540, 17280, 135, 17280, 540, 135, 17280, 135, 135, 17280, 135, 135, 540]
Prompts retrieved: 574560 . Total input tokens: 128078117 . Total output tokens: 114993343
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 34.590894744265825,
    "estimated_duration": 3600.041724606576,
    "input_throughput": 7695.053868584654,
    "output_throughput": 6810.935782328908,
    "total_throughput": 14505.989650913561,
    "itl": 126.48125117848852,
    "ttft": 1235500.495463774,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 42,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.1313024468440563,
    "arrivals": 191076,
    "finished_requests": 111513,
    "scheduler_time": 169.24813421833386
}
#Debug simulation 
Total elapsed time: 34.59106804803014. Arrivals time: 0.6121911900117993 Scheduler time: 33.80620413925499 Scheduler overhead time: 0.06786580616608262 Adapter cache time: 0.011620769277215004 Engine time: 0.0677943080663681 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-32/adapters_96_slots_32_rate_1.6-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-32/adapters_96_slots_32_rate_1.6-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 540, 135, 17280, 540, 135, 135, 540, 17280, 135, 540, 135, 135, 540, 540, 540, 135, 135, 17280, 540, 540, 135, 17280, 17280, 540, 17280, 17280, 540, 17280, 135, 17280, 540, 540, 540, 17280, 17280, 135, 135, 540, 135, 17280, 135, 135, 17280, 135, 540, 540, 135, 540, 17280, 17280, 17280, 540, 17280, 17280, 135, 135, 17280, 540, 17280, 135, 540, 17280, 135, 17280, 540, 135, 17280, 135, 135, 17280, 135, 135, 540]
Prompts retrieved: 574560 . Total input tokens: 128078117 . Total output tokens: 114993343
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 33.18129225075245,
    "estimated_duration": 3600.0849077794173,
    "input_throughput": 7695.066563607115,
    "output_throughput": 6810.938527314972,
    "total_throughput": 14506.005090922086,
    "itl": 126.48124159701524,
    "ttft": 1235483.1553636405,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 42,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.13764227066189047,
    "arrivals": 191076,
    "finished_requests": 111515,
    "scheduler_time": 169.25038022334644
}
#Debug simulation 
Total elapsed time: 33.18147264467552. Arrivals time: 0.5130592649802566 Scheduler time: 32.51068646926433 Scheduler overhead time: 0.0613850406371057 Adapter cache time: 0.011340271681547165 Engine time: 0.06064160820096731 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-16/adapters_96_slots_32_rate_1.6-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-16/adapters_96_slots_32_rate_1.6-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 540, 135, 17280, 540, 135, 135, 540, 17280, 135, 540, 135, 135, 540, 540, 540, 135, 135, 17280, 540, 540, 135, 17280, 17280, 540, 17280, 17280, 540, 17280, 135, 17280, 540, 540, 540, 17280, 17280, 135, 135, 540, 135, 17280, 135, 135, 17280, 135, 540, 540, 135, 540, 17280, 17280, 17280, 540, 17280, 17280, 135, 135, 17280, 540, 17280, 135, 540, 17280, 135, 17280, 540, 135, 17280, 135, 135, 17280, 135, 135, 540]
Prompts retrieved: 574560 . Total input tokens: 128078117 . Total output tokens: 114993343
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 34.88990869326517,
    "estimated_duration": 3600.024283920056,
    "input_throughput": 7695.091148061593,
    "output_throughput": 6810.968778605188,
    "total_throughput": 14506.059926666781,
    "itl": 126.48138539497889,
    "ttft": 1235478.2993454726,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 42,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.12558211238589145,
    "arrivals": 191076,
    "finished_requests": 111513,
    "scheduler_time": 169.24717626478798
}
#Debug simulation 
Total elapsed time: 34.89005500590429. Arrivals time: 0.6074840729124844 Scheduler time: 34.10820659669116 Scheduler overhead time: 0.0671074646525085 Adapter cache time: 0.011874294839799404 Engine time: 0.07018818520009518 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-32/adapters_96_slots_32_rate_1.6-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-32/adapters_96_slots_32_rate_1.6-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 540, 135, 17280, 540, 135, 135, 540, 17280, 135, 540, 135, 135, 540, 540, 540, 135, 135, 17280, 540, 540, 135, 17280, 17280, 540, 17280, 17280, 540, 17280, 135, 17280, 540, 540, 540, 17280, 17280, 135, 135, 540, 135, 17280, 135, 135, 17280, 135, 540, 540, 135, 540, 17280, 17280, 17280, 540, 17280, 17280, 135, 135, 17280, 540, 17280, 135, 540, 17280, 135, 17280, 540, 135, 17280, 135, 135, 17280, 135, 135, 540]
Prompts retrieved: 574560 . Total input tokens: 128078117 . Total output tokens: 114993343
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 34.26461738999933,
    "estimated_duration": 3600.094135632014,
    "input_throughput": 7695.267944746806,
    "output_throughput": 6811.038844042707,
    "total_throughput": 14506.306788789514,
    "itl": 126.48125258087222,
    "ttft": 1235470.1658375647,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 42,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.13940282367169848,
    "arrivals": 191076,
    "finished_requests": 111516,
    "scheduler_time": 169.2508750950172
}
#Debug simulation 
Total elapsed time: 34.26482354616746. Arrivals time: 0.6165680852718651 Scheduler time: 33.47884580725804 Scheduler overhead time: 0.06745590083301067 Adapter cache time: 0.011583928484469652 Engine time: 0.06549900025129318 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-8/adapters_96_slots_32_rate_1.6-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-8/adapters_96_slots_32_rate_1.6-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 540, 66, 17280, 540, 66, 66, 540, 17280, 66, 540, 66, 66, 540, 540, 540, 66, 66, 17280, 540, 540, 66, 17280, 17280, 540, 17280, 17280, 540, 17280, 66, 17280, 540, 540, 540, 17280, 17280, 66, 66, 540, 66, 17280, 66, 66, 17280, 66, 540, 540, 66, 540, 17280, 17280, 17280, 540, 17280, 17280, 66, 66, 17280, 540, 17280, 66, 540, 17280, 66, 17280, 540, 66, 17280, 66, 66, 17280, 66, 66, 540]
Prompts retrieved: 572352 . Total input tokens: 127568280 . Total output tokens: 114562164
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 30.71699943114072,
    "estimated_duration": 3600.0306973481265,
    "input_throughput": 7679.62034889463,
    "output_throughput": 6810.617758915471,
    "total_throughput": 14490.238107810103,
    "itl": 126.52130989226151,
    "ttft": 1230998.3034919195,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 37,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.11323804652551184,
    "arrivals": 190312,
    "finished_requests": 111733,
    "scheduler_time": 169.00128564206034
}
#Debug simulation 
Total elapsed time: 30.717147835996002. Arrivals time: 0.601104287430644 Scheduler time: 29.95729213859886 Scheduler overhead time: 0.061563422437757254 Adapter cache time: 0.010833132546395063 Engine time: 0.061870621517300606 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-16/adapters_96_slots_32_rate_1.6-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-16/adapters_96_slots_32_rate_1.6-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 540, 66, 17280, 540, 66, 66, 540, 17280, 66, 540, 66, 66, 540, 540, 540, 66, 66, 17280, 540, 540, 66, 17280, 17280, 540, 17280, 17280, 540, 17280, 66, 17280, 540, 540, 540, 17280, 17280, 66, 66, 540, 66, 17280, 66, 66, 17280, 66, 540, 540, 66, 540, 17280, 17280, 17280, 540, 17280, 17280, 66, 66, 17280, 540, 17280, 66, 540, 17280, 66, 17280, 540, 66, 17280, 66, 66, 17280, 66, 66, 540]
Prompts retrieved: 572352 . Total input tokens: 127568280 . Total output tokens: 114562164
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 30.473015271127224,
    "estimated_duration": 3600.0929923187696,
    "input_throughput": 7679.7266234482695,
    "output_throughput": 6810.561297253568,
    "total_throughput": 14490.287920701838,
    "itl": 126.52209504913498,
    "ttft": 1230964.3798164532,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 37,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.1192123625986278,
    "arrivals": 190312,
    "finished_requests": 111736,
    "scheduler_time": 169.00441644495734
}
#Debug simulation 
Total elapsed time: 30.473166100215167. Arrivals time: 0.5911607197485864 Scheduler time: 29.722760372329503 Scheduler overhead time: 0.06167752481997013 Adapter cache time: 0.010911627672612667 Engine time: 0.06267388630658388 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-32/adapters_96_slots_32_rate_1.6-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-32/adapters_96_slots_32_rate_1.6-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 540, 66, 17280, 540, 66, 66, 540, 17280, 66, 540, 66, 66, 540, 540, 540, 66, 66, 17280, 540, 540, 66, 17280, 17280, 540, 17280, 17280, 540, 17280, 66, 17280, 540, 540, 540, 17280, 17280, 66, 66, 540, 66, 17280, 66, 66, 17280, 66, 540, 540, 66, 540, 17280, 17280, 17280, 540, 17280, 17280, 66, 66, 17280, 540, 17280, 66, 540, 17280, 66, 17280, 540, 66, 17280, 66, 66, 17280, 66, 66, 540]
Prompts retrieved: 572352 . Total input tokens: 127568280 . Total output tokens: 114562164
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 30.405001610983163,
    "estimated_duration": 3600.093113482491,
    "input_throughput": 7679.7263649815495,
    "output_throughput": 6810.561068039233,
    "total_throughput": 14490.287433020783,
    "itl": 126.5218934023871,
    "ttft": 1230980.5079340825,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 37,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.1196923947893083,
    "arrivals": 190312,
    "finished_requests": 111736,
    "scheduler_time": 169.00444684345314
}
#Debug simulation 
Total elapsed time: 30.40528451791033. Arrivals time: 0.594712758436799 Scheduler time: 29.65232696896419 Scheduler overhead time: 0.06081131612882018 Adapter cache time: 0.011008558794856071 Engine time: 0.06244823895394802 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-16/adapters_96_slots_32_rate_1.6-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-16/adapters_96_slots_32_rate_1.6-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 540, 66, 17280, 540, 66, 66, 540, 17280, 66, 540, 66, 66, 540, 540, 540, 66, 66, 17280, 540, 540, 66, 17280, 17280, 540, 17280, 17280, 540, 17280, 66, 17280, 540, 540, 540, 17280, 17280, 66, 66, 540, 66, 17280, 66, 66, 17280, 66, 540, 540, 66, 540, 17280, 17280, 17280, 540, 17280, 17280, 66, 66, 17280, 540, 17280, 66, 540, 17280, 66, 17280, 540, 66, 17280, 66, 66, 17280, 66, 66, 540]
Prompts retrieved: 572352 . Total input tokens: 127568280 . Total output tokens: 114562164
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 30.493366731330752,
    "estimated_duration": 3600.036096484868,
    "input_throughput": 7679.608831421118,
    "output_throughput": 6810.607544724395,
    "total_throughput": 14490.216376145512,
    "itl": 126.5212533431268,
    "ttft": 1230999.2971770375,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 37,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.114717814095784,
    "arrivals": 190312,
    "finished_requests": 111733,
    "scheduler_time": 169.00147907843163
}
#Debug simulation 
Total elapsed time: 30.493531379383057. Arrivals time: 0.5913118035532534 Scheduler time: 29.743364152498543 Scheduler overhead time: 0.062114883214235306 Adapter cache time: 0.009678828064352274 Engine time: 0.06305284658446908 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-32/adapters_96_slots_32_rate_1.6-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-32/adapters_96_slots_32_rate_1.6-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 540, 66, 17280, 540, 66, 66, 540, 17280, 66, 540, 66, 66, 540, 540, 540, 66, 66, 17280, 540, 540, 66, 17280, 17280, 540, 17280, 17280, 540, 17280, 66, 17280, 540, 540, 540, 17280, 17280, 66, 66, 540, 66, 17280, 66, 66, 17280, 66, 540, 540, 66, 540, 17280, 17280, 17280, 540, 17280, 17280, 66, 66, 17280, 540, 17280, 66, 540, 17280, 66, 17280, 540, 66, 17280, 66, 66, 17280, 66, 66, 540]
Prompts retrieved: 572352 . Total input tokens: 127568280 . Total output tokens: 114562164
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 31.018961037043482,
    "estimated_duration": 3600.1060737749017,
    "input_throughput": 7679.739828057271,
    "output_throughput": 6810.675434985273,
    "total_throughput": 14490.415263042543,
    "itl": 126.5222190326165,
    "ttft": 1230964.6494661993,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 37,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.12107568643987177,
    "arrivals": 190312,
    "finished_requests": 111737,
    "scheduler_time": 169.00507722376636
}
#Debug simulation 
Total elapsed time: 31.019094567280263. Arrivals time: 0.6344211376272142 Scheduler time: 30.222421725746244 Scheduler overhead time: 0.06366121862083673 Adapter cache time: 0.011014210525900126 Engine time: 0.06299156788736582 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-16/adapters_96_slots_32_rate_1.6-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-16/adapters_96_slots_32_rate_1.6-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 540, 66, 17280, 540, 66, 66, 540, 17280, 66, 540, 66, 66, 540, 540, 540, 66, 66, 17280, 540, 540, 66, 17280, 17280, 540, 17280, 17280, 540, 17280, 66, 17280, 540, 540, 540, 17280, 17280, 66, 66, 540, 66, 17280, 66, 66, 17280, 66, 540, 540, 66, 540, 17280, 17280, 17280, 540, 17280, 17280, 66, 66, 17280, 540, 17280, 66, 540, 17280, 66, 17280, 540, 66, 17280, 66, 66, 17280, 66, 66, 540]
Prompts retrieved: 572352 . Total input tokens: 127568280 . Total output tokens: 114562164
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 30.542345888912678,
    "estimated_duration": 3600.023733457712,
    "input_throughput": 7679.635204361843,
    "output_throughput": 6810.630933382987,
    "total_throughput": 14490.26613774483,
    "itl": 126.52167321606686,
    "ttft": 1230998.505236143,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 37,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.11063186091138055,
    "arrivals": 190312,
    "finished_requests": 111733,
    "scheduler_time": 169.00089593539974
}
#Debug simulation 
Total elapsed time: 30.54252911824733. Arrivals time: 0.613058262038976 Scheduler time: 29.76688701333478 Scheduler overhead time: 0.06397663010284305 Adapter cache time: 0.010988812893629074 Engine time: 0.06321729067713022 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-32/adapters_96_slots_32_rate_1.6-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-32/adapters_96_slots_32_rate_1.6-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 540, 66, 17280, 540, 66, 66, 540, 17280, 66, 540, 66, 66, 540, 540, 540, 66, 66, 17280, 540, 540, 66, 17280, 17280, 540, 17280, 17280, 540, 17280, 66, 17280, 540, 540, 540, 17280, 17280, 66, 66, 540, 66, 17280, 66, 66, 17280, 66, 540, 540, 66, 540, 17280, 17280, 17280, 540, 17280, 17280, 66, 66, 17280, 540, 17280, 66, 540, 17280, 66, 17280, 540, 66, 17280, 66, 66, 17280, 66, 66, 540]
Prompts retrieved: 572352 . Total input tokens: 127568280 . Total output tokens: 114562164
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 30.582775421906263,
    "estimated_duration": 3600.1105142553447,
    "input_throughput": 7679.730355644027,
    "output_throughput": 6810.667034501189,
    "total_throughput": 14490.397390145217,
    "itl": 126.52201930241382,
    "ttft": 1230965.667035385,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 37,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.12233322430402035,
    "arrivals": 190312,
    "finished_requests": 111737,
    "scheduler_time": 169.0053137869714
}
#Debug simulation 
Total elapsed time: 30.582964710891247. Arrivals time: 0.6028354782611132 Scheduler time: 29.818966692313552 Scheduler overhead time: 0.06380687095224857 Adapter cache time: 0.010828330181539059 Engine time: 0.062039651442319155 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-8/adapters_96_slots_32_rate_1.6-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-8/adapters_96_slots_32_rate_1.6-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 540, 33, 17280, 540, 33, 33, 540, 17280, 33, 540, 33, 33, 540, 540, 540, 33, 33, 17280, 540, 540, 33, 17280, 17280, 540, 17280, 17280, 540, 17280, 33, 17280, 540, 540, 540, 17280, 17280, 33, 33, 540, 33, 17280, 33, 33, 17280, 33, 540, 540, 33, 540, 17280, 17280, 17280, 540, 17280, 17280, 33, 33, 17280, 540, 17280, 33, 540, 17280, 33, 17280, 540, 33, 17280, 33, 33, 17280, 33, 33, 540]
Prompts retrieved: 571296 . Total input tokens: 127344419 . Total output tokens: 114344834
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 29.054192313924432,
    "estimated_duration": 3600.0390460902,
    "input_throughput": 7654.253647589351,
    "output_throughput": 6812.198336191474,
    "total_throughput": 14466.451983780824,
    "itl": 126.7141906521041,
    "ttft": 1235291.77953023,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 41,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.12547999750124283,
    "arrivals": 189952,
    "finished_requests": 111543,
    "scheduler_time": 169.20287140960963
}
#Debug simulation 
Total elapsed time: 29.05434394488111. Arrivals time: 0.5885166539810598 Scheduler time: 28.307884061709046 Scheduler overhead time: 0.06163978949189186 Adapter cache time: 0.010841723531484604 Engine time: 0.06178450724110007 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-16/adapters_96_slots_32_rate_1.6-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-16/adapters_96_slots_32_rate_1.6-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 540, 33, 17280, 540, 33, 33, 540, 17280, 33, 540, 33, 33, 540, 540, 540, 33, 33, 17280, 540, 540, 33, 17280, 17280, 540, 17280, 17280, 540, 17280, 33, 17280, 540, 540, 540, 17280, 17280, 33, 33, 540, 33, 17280, 33, 33, 17280, 33, 540, 540, 33, 540, 17280, 17280, 17280, 540, 17280, 17280, 33, 33, 17280, 540, 17280, 33, 540, 17280, 33, 17280, 540, 33, 17280, 33, 33, 17280, 33, 33, 540]
Prompts retrieved: 571296 . Total input tokens: 127344419 . Total output tokens: 114344834
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 29.069811360910535,
    "estimated_duration": 3600.0306382886015,
    "input_throughput": 7654.392356254978,
    "output_throughput": 6812.301189652809,
    "total_throughput": 14466.693545907787,
    "itl": 126.71241514213133,
    "ttft": 1235306.8295778546,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 41,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.13321554037043826,
    "arrivals": 189952,
    "finished_requests": 111545,
    "scheduler_time": 169.20130228514353
}
#Debug simulation 
Total elapsed time: 29.069961410947144. Arrivals time: 0.5740022412501276 Scheduler time: 28.340392517857254 Scheduler overhead time: 0.0617707259953022 Adapter cache time: 0.01031844550743699 Engine time: 0.05945611000061035 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-32/adapters_96_slots_32_rate_1.6-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-32/adapters_96_slots_32_rate_1.6-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 540, 33, 17280, 540, 33, 33, 540, 17280, 33, 540, 33, 33, 540, 540, 540, 33, 33, 17280, 540, 540, 33, 17280, 17280, 540, 17280, 17280, 540, 17280, 33, 17280, 540, 540, 540, 17280, 17280, 33, 33, 540, 33, 17280, 33, 33, 17280, 33, 540, 540, 33, 540, 17280, 17280, 17280, 540, 17280, 17280, 33, 33, 17280, 540, 17280, 33, 540, 17280, 33, 17280, 540, 33, 17280, 33, 33, 17280, 33, 33, 540]
Prompts retrieved: 571296 . Total input tokens: 127344419 . Total output tokens: 114344834
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 29.12787791294977,
    "estimated_duration": 3600.031718306863,
    "input_throughput": 7654.390059918675,
    "output_throughput": 6812.299145945902,
    "total_throughput": 14466.689205864577,
    "itl": 126.7124144689644,
    "ttft": 1235307.654056796,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 41,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.13355270765721797,
    "arrivals": 189952,
    "finished_requests": 111545,
    "scheduler_time": 169.20137957237938
}
#Debug simulation 
Total elapsed time: 29.12808387959376. Arrivals time: 0.5907315886579454 Scheduler time: 28.382212321739644 Scheduler overhead time: 0.060216876212507486 Adapter cache time: 0.010242565535008907 Engine time: 0.060670031234622 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-16/adapters_96_slots_32_rate_1.6-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-16/adapters_96_slots_32_rate_1.6-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 540, 33, 17280, 540, 33, 33, 540, 17280, 33, 540, 33, 33, 540, 540, 540, 33, 33, 17280, 540, 540, 33, 17280, 17280, 540, 17280, 17280, 540, 17280, 33, 17280, 540, 540, 540, 17280, 17280, 33, 33, 540, 33, 17280, 33, 33, 17280, 33, 540, 540, 33, 540, 17280, 17280, 17280, 540, 17280, 17280, 33, 33, 17280, 540, 17280, 33, 540, 17280, 33, 17280, 540, 33, 17280, 33, 33, 17280, 33, 33, 540]
Prompts retrieved: 571296 . Total input tokens: 127344419 . Total output tokens: 114344834
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 29.755367550067604,
    "estimated_duration": 3600.0456996827866,
    "input_throughput": 7654.239501023008,
    "output_throughput": 6812.185745908981,
    "total_throughput": 14466.425246931989,
    "itl": 126.71398391188549,
    "ttft": 1235294.5805855575,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 41,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.12790380123071377,
    "arrivals": 189952,
    "finished_requests": 111543,
    "scheduler_time": 169.20324719000735
}
#Debug simulation 
Total elapsed time: 29.7555505852215. Arrivals time: 0.6020401422865689 Scheduler time: 28.999249181710184 Scheduler overhead time: 0.06007818644866347 Adapter cache time: 0.010252955835312605 Engine time: 0.060140006709843874 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-32/adapters_96_slots_32_rate_1.6-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-32/adapters_96_slots_32_rate_1.6-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 540, 33, 17280, 540, 33, 33, 540, 17280, 33, 540, 33, 33, 540, 540, 540, 33, 33, 17280, 540, 540, 33, 17280, 17280, 540, 17280, 17280, 540, 17280, 33, 17280, 540, 540, 540, 17280, 17280, 33, 33, 540, 33, 17280, 33, 33, 17280, 33, 540, 540, 33, 540, 17280, 17280, 17280, 540, 17280, 17280, 33, 33, 17280, 540, 17280, 33, 540, 17280, 33, 17280, 540, 33, 17280, 33, 33, 17280, 33, 33, 540]
Prompts retrieved: 571296 . Total input tokens: 127344419 . Total output tokens: 114344834
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 29.637653585989028,
    "estimated_duration": 3600.0387475560988,
    "input_throughput": 7654.375114353015,
    "output_throughput": 6812.285844603354,
    "total_throughput": 14466.66095895637,
    "itl": 126.71245370801007,
    "ttft": 1235305.6772127997,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 41,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.13518750688061115,
    "arrivals": 189952,
    "finished_requests": 111545,
    "scheduler_time": 169.20169082922223
}
#Debug simulation 
Total elapsed time: 29.637796928174794. Arrivals time: 0.5950781409628689 Scheduler time: 28.885946184396744 Scheduler overhead time: 0.060942056123167276 Adapter cache time: 0.009887654334306717 Engine time: 0.06218936899676919 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-16/adapters_96_slots_32_rate_1.6-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-16/adapters_96_slots_32_rate_1.6-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 540, 33, 17280, 540, 33, 33, 540, 17280, 33, 540, 33, 33, 540, 540, 540, 33, 33, 17280, 540, 540, 33, 17280, 17280, 540, 17280, 17280, 540, 17280, 33, 17280, 540, 540, 540, 17280, 17280, 33, 33, 540, 33, 17280, 33, 33, 17280, 33, 540, 540, 33, 540, 17280, 17280, 17280, 540, 17280, 17280, 33, 33, 17280, 540, 17280, 33, 540, 17280, 33, 17280, 540, 33, 17280, 33, 33, 17280, 33, 33, 540]
Prompts retrieved: 571296 . Total input tokens: 127344419 . Total output tokens: 114344834
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 29.165985370986164,
    "estimated_duration": 3600.032699403635,
    "input_throughput": 7654.107420903328,
    "output_throughput": 6812.181734922171,
    "total_throughput": 14466.289155825498,
    "itl": 126.7143769066427,
    "ttft": 1235307.0543900293,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 41,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.12259206209098927,
    "arrivals": 189952,
    "finished_requests": 111542,
    "scheduler_time": 169.20244192670395
}
#Debug simulation 
Total elapsed time: 29.166134126018733. Arrivals time: 0.5939780082553625 Scheduler time: 28.41760445944965 Scheduler overhead time: 0.06081520998850465 Adapter cache time: 0.00948312459513545 Engine time: 0.060714705381542444 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-32/adapters_96_slots_32_rate_1.6-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-32/adapters_96_slots_32_rate_1.6-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 540, 33, 17280, 540, 33, 33, 540, 17280, 33, 540, 33, 33, 540, 540, 540, 33, 33, 17280, 540, 540, 33, 17280, 17280, 540, 17280, 17280, 540, 17280, 33, 17280, 540, 540, 540, 17280, 17280, 33, 33, 540, 33, 17280, 33, 33, 17280, 33, 540, 540, 33, 540, 17280, 17280, 17280, 540, 17280, 17280, 33, 33, 17280, 540, 17280, 33, 540, 17280, 33, 17280, 540, 33, 17280, 33, 33, 17280, 33, 33, 540]
Prompts retrieved: 571296 . Total input tokens: 127344419 . Total output tokens: 114344834
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 29.18967844778672,
    "estimated_duration": 3600.044469761316,
    "input_throughput": 7654.362947862967,
    "output_throughput": 6812.275016598886,
    "total_throughput": 14466.637964461854,
    "itl": 126.71249161076418,
    "ttft": 1235307.0931909198,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 41,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.1368223061040043,
    "arrivals": 189952,
    "finished_requests": 111545,
    "scheduler_time": 169.20194334866866
}
#Debug simulation 
Total elapsed time: 29.1898208479397. Arrivals time: 0.5930665815249085 Scheduler time: 28.440976423211396 Scheduler overhead time: 0.060987836215645075 Adapter cache time: 0.00960024306550622 Engine time: 0.06140018068253994 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-8/adapters_96_slots_32_rate_1.6-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-8/adapters_96_slots_32_rate_1.6-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 135, 17280, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 270, 135, 17280, 270, 135, 135, 270, 17280, 135, 270, 135, 135, 270, 270, 270, 135, 135, 17280, 270, 270, 135, 17280, 17280, 270, 17280, 17280, 270, 17280, 135, 17280, 270, 270, 270, 17280, 17280, 135, 135, 270, 135, 17280, 135, 135, 17280, 135, 270, 270, 135, 270, 17280, 17280, 17280, 270, 17280, 17280, 135, 135, 17280, 270, 17280, 135, 270, 17280, 135, 17280, 270, 135, 17280, 135, 135, 17280, 135, 135, 270]
Prompts retrieved: 565920 . Total input tokens: 126139240 . Total output tokens: 113278943
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 21.126558993943036,
    "estimated_duration": 3600.0805947289973,
    "input_throughput": 7739.195072686239,
    "output_throughput": 6807.113717365193,
    "total_throughput": 14546.308790051431,
    "itl": 125.95312265596553,
    "ttft": 1229703.3030205336,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 33,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10099609554978084,
    "arrivals": 188134,
    "finished_requests": 112281,
    "scheduler_time": 168.63383903257815
}
#Debug simulation 
Total elapsed time: 21.12666753400117. Arrivals time: 0.5232290327548981 Scheduler time: 20.467264348175377 Scheduler overhead time: 0.05215855035930872 Adapter cache time: 0.008248802274465561 Engine time: 0.05355702294036746 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-16/adapters_96_slots_32_rate_1.6-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-16/adapters_96_slots_32_rate_1.6-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 135, 17280, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 270, 135, 17280, 270, 135, 135, 270, 17280, 135, 270, 135, 135, 270, 270, 270, 135, 135, 17280, 270, 270, 135, 17280, 17280, 270, 17280, 17280, 270, 17280, 135, 17280, 270, 270, 270, 17280, 17280, 135, 135, 270, 135, 17280, 135, 135, 17280, 135, 270, 270, 135, 270, 17280, 17280, 17280, 270, 17280, 17280, 135, 135, 17280, 270, 17280, 135, 270, 17280, 135, 17280, 270, 135, 17280, 135, 135, 17280, 135, 135, 270]
Prompts retrieved: 565920 . Total input tokens: 126139240 . Total output tokens: 113278943
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 20.5545597798191,
    "estimated_duration": 3600.096415652816,
    "input_throughput": 7739.161062148318,
    "output_throughput": 6807.08380293649,
    "total_throughput": 14546.244865084807,
    "itl": 125.95286019544672,
    "ttft": 1229708.531794039,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 33,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10684356610057874,
    "arrivals": 188134,
    "finished_requests": 112281,
    "scheduler_time": 168.63475169870978
}
#Debug simulation 
Total elapsed time: 20.554715144913644. Arrivals time: 0.46139406505972147 Scheduler time: 19.963457397185266 Scheduler overhead time: 0.050666412338614464 Adapter cache time: 0.00786916445940733 Engine time: 0.04952650610357523 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-32/adapters_96_slots_32_rate_1.6-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-32/adapters_96_slots_32_rate_1.6-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 135, 17280, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 270, 135, 17280, 270, 135, 135, 270, 17280, 135, 270, 135, 135, 270, 270, 270, 135, 135, 17280, 270, 270, 135, 17280, 17280, 270, 17280, 17280, 270, 17280, 135, 17280, 270, 270, 270, 17280, 17280, 135, 135, 270, 135, 17280, 135, 135, 17280, 135, 270, 270, 135, 270, 17280, 17280, 17280, 270, 17280, 17280, 135, 135, 17280, 270, 17280, 135, 270, 17280, 135, 17280, 270, 135, 17280, 135, 135, 17280, 135, 135, 270]
Prompts retrieved: 565920 . Total input tokens: 126139240 . Total output tokens: 113278943
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 20.917671912815422,
    "estimated_duration": 3600.098908719211,
    "input_throughput": 7739.155702783795,
    "output_throughput": 6807.079089034926,
    "total_throughput": 14546.234791818722,
    "itl": 125.95277296161491,
    "ttft": 1229709.271757097,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 33,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.1071810718998313,
    "arrivals": 188134,
    "finished_requests": 112281,
    "scheduler_time": 168.63487136874846
}
#Debug simulation 
Total elapsed time: 20.917829874902964. Arrivals time: 0.4974989593029022 Scheduler time: 20.285969860851765 Scheduler overhead time: 0.05176385957747698 Adapter cache time: 0.008044833317399025 Engine time: 0.0517875119112432 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-16/adapters_96_slots_32_rate_1.6-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-16/adapters_96_slots_32_rate_1.6-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 135, 17280, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 270, 135, 17280, 270, 135, 135, 270, 17280, 135, 270, 135, 135, 270, 270, 270, 135, 135, 17280, 270, 270, 135, 17280, 17280, 270, 17280, 17280, 270, 17280, 135, 17280, 270, 270, 270, 17280, 17280, 135, 135, 270, 135, 17280, 135, 135, 17280, 135, 270, 270, 135, 270, 17280, 17280, 17280, 270, 17280, 17280, 135, 135, 17280, 270, 17280, 135, 270, 17280, 135, 17280, 270, 135, 17280, 135, 135, 17280, 135, 135, 270]
Prompts retrieved: 565920 . Total input tokens: 126139240 . Total output tokens: 113278943
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 21.06752032507211,
    "estimated_duration": 3600.0886146735475,
    "input_throughput": 7739.177832023025,
    "output_throughput": 6807.098553106642,
    "total_throughput": 14546.276385129668,
    "itl": 125.95313271068667,
    "ttft": 1229706.2915836987,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 33,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10275761291617527,
    "arrivals": 188134,
    "finished_requests": 112281,
    "scheduler_time": 168.6342724152232
}
#Debug simulation 
Total elapsed time: 21.06773058185354. Arrivals time: 0.5012350725010037 Scheduler time: 20.430047321598977 Scheduler overhead time: 0.05270937643945217 Adapter cache time: 0.00848440919071436 Engine time: 0.05256961239501834 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-32/adapters_96_slots_32_rate_1.6-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-32/adapters_96_slots_32_rate_1.6-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 135, 17280, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 270, 135, 17280, 270, 135, 135, 270, 17280, 135, 270, 135, 135, 270, 270, 270, 135, 135, 17280, 270, 270, 135, 17280, 17280, 270, 17280, 17280, 270, 17280, 135, 17280, 270, 270, 270, 17280, 17280, 135, 135, 270, 135, 17280, 135, 135, 17280, 135, 270, 270, 135, 270, 17280, 17280, 17280, 270, 17280, 17280, 135, 135, 17280, 270, 17280, 135, 270, 17280, 135, 17280, 270, 135, 17280, 135, 135, 17280, 135, 135, 270]
Prompts retrieved: 565920 . Total input tokens: 126139240 . Total output tokens: 113278943
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 21.186540611088276,
    "estimated_duration": 3600.10112824781,
    "input_throughput": 7739.15093145188,
    "output_throughput": 6807.074892345397,
    "total_throughput": 14546.225823797276,
    "itl": 125.95260287002554,
    "ttft": 1229709.9099184093,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 33,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.1084386097639799,
    "arrivals": 188134,
    "finished_requests": 112281,
    "scheduler_time": 168.63498003639833
}
#Debug simulation 
Total elapsed time: 21.186660191975534. Arrivals time: 0.5180703778751194 Scheduler time: 20.531917760614306 Scheduler overhead time: 0.05306414933875203 Adapter cache time: 0.008586207404732704 Engine time: 0.05270580900833011 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-16/adapters_96_slots_32_rate_1.6-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-16/adapters_96_slots_32_rate_1.6-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 135, 17280, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 270, 135, 17280, 270, 135, 135, 270, 17280, 135, 270, 135, 135, 270, 270, 270, 135, 135, 17280, 270, 270, 135, 17280, 17280, 270, 17280, 17280, 270, 17280, 135, 17280, 270, 270, 270, 17280, 17280, 135, 135, 270, 135, 17280, 135, 135, 17280, 135, 270, 270, 135, 270, 17280, 17280, 17280, 270, 17280, 17280, 135, 135, 17280, 270, 17280, 135, 270, 17280, 135, 17280, 270, 135, 17280, 135, 135, 17280, 135, 135, 270]
Prompts retrieved: 565920 . Total input tokens: 126139240 . Total output tokens: 113278943
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 21.01401188969612,
    "estimated_duration": 3600.029487533213,
    "input_throughput": 7739.181052956017,
    "output_throughput": 6807.209797826389,
    "total_throughput": 14546.390850782405,
    "itl": 125.95249461819033,
    "ttft": 1229709.96055784,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 33,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09867165973177183,
    "arrivals": 188134,
    "finished_requests": 112280,
    "scheduler_time": 168.6311941421532
}
#Debug simulation 
Total elapsed time: 21.014128542039543. Arrivals time: 0.5099916169419885 Scheduler time: 20.367030881345272 Scheduler overhead time: 0.053100448567420244 Adapter cache time: 0.008479145355522633 Engine time: 0.05315738869830966 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-32/adapters_96_slots_32_rate_1.6-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-32/adapters_96_slots_32_rate_1.6-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 135, 17280, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 270, 135, 17280, 270, 135, 135, 270, 17280, 135, 270, 135, 135, 270, 270, 270, 135, 135, 17280, 270, 270, 135, 17280, 17280, 270, 17280, 17280, 270, 17280, 135, 17280, 270, 270, 270, 17280, 17280, 135, 135, 270, 135, 17280, 135, 135, 17280, 135, 270, 270, 135, 270, 17280, 17280, 17280, 270, 17280, 17280, 135, 135, 17280, 270, 17280, 135, 270, 17280, 135, 17280, 270, 135, 17280, 135, 135, 17280, 135, 135, 270]
Prompts retrieved: 565920 . Total input tokens: 126139240 . Total output tokens: 113278943
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 21.087609231937677,
    "estimated_duration": 3600.1061950330813,
    "input_throughput": 7739.14003937986,
    "output_throughput": 6807.06531207611,
    "total_throughput": 14546.20535145597,
    "itl": 125.95256377844154,
    "ttft": 1229711.473998403,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 33,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10969614762812847,
    "arrivals": 188134,
    "finished_requests": 112281,
    "scheduler_time": 168.6352887444099
}
#Debug simulation 
Total elapsed time: 21.087753502186388. Arrivals time: 0.503061999566853 Scheduler time: 20.449452598579228 Scheduler overhead time: 0.05289245629683137 Adapter cache time: 0.008300010580569506 Engine time: 0.051653866190463305 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-8/adapters_96_slots_32_rate_1.6-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-8/adapters_96_slots_32_rate_1.6-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 66, 17280, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 270, 66, 17280, 270, 66, 66, 270, 17280, 66, 270, 66, 66, 270, 270, 270, 66, 66, 17280, 270, 270, 66, 17280, 17280, 270, 17280, 17280, 270, 17280, 66, 17280, 270, 270, 270, 17280, 17280, 66, 66, 270, 66, 17280, 66, 66, 17280, 66, 270, 270, 66, 270, 17280, 17280, 17280, 270, 17280, 17280, 66, 66, 17280, 270, 17280, 66, 270, 17280, 66, 17280, 270, 66, 17280, 66, 66, 17280, 66, 66, 270]
Prompts retrieved: 563712 . Total input tokens: 125628176 . Total output tokens: 112839488
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 18.701022702269256,
    "estimated_duration": 3600.1272292593626,
    "input_throughput": 7687.310263669073,
    "output_throughput": 6810.405421433965,
    "total_throughput": 14497.715685103038,
    "itl": 126.48697916627657,
    "ttft": 1234935.401977273,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 33,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10099609554978084,
    "arrivals": 187468,
    "finished_requests": 111776,
    "scheduler_time": 168.62418356160254
}
#Debug simulation 
Total elapsed time: 18.701252904254943. Arrivals time: 0.4922402105294168 Scheduler time: 18.077653924468905 Scheduler overhead time: 0.050385046284645796 Adapter cache time: 0.0082368073053658 Engine time: 0.05050903232768178 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-16/adapters_96_slots_32_rate_1.6-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-16/adapters_96_slots_32_rate_1.6-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 66, 17280, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 270, 66, 17280, 270, 66, 66, 270, 17280, 66, 270, 66, 66, 270, 270, 270, 66, 66, 17280, 270, 270, 66, 17280, 17280, 270, 17280, 17280, 270, 17280, 66, 17280, 270, 270, 270, 17280, 17280, 66, 66, 270, 66, 17280, 66, 66, 17280, 66, 270, 270, 66, 270, 17280, 17280, 17280, 270, 17280, 17280, 66, 66, 17280, 270, 17280, 66, 270, 17280, 66, 17280, 270, 66, 17280, 66, 66, 17280, 66, 66, 270]
Prompts retrieved: 563712 . Total input tokens: 125628176 . Total output tokens: 112839488
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 18.706730498932302,
    "estimated_duration": 3600.1418051031897,
    "input_throughput": 7687.279140163411,
    "output_throughput": 6810.377848240686,
    "total_throughput": 14497.656988404098,
    "itl": 126.48667574464089,
    "ttft": 1234940.1019278488,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 33,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10643497078213839,
    "arrivals": 187468,
    "finished_requests": 111776,
    "scheduler_time": 168.625015409497
}
#Debug simulation 
Total elapsed time: 18.706878239288926. Arrivals time: 0.4764096047729254 Scheduler time: 18.098258330486715 Scheduler overhead time: 0.051757536362856627 Adapter cache time: 0.008026552852243185 Engine time: 0.050297330133616924 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-32/adapters_96_slots_32_rate_1.6-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-32/adapters_96_slots_32_rate_1.6-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 66, 17280, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 270, 66, 17280, 270, 66, 66, 270, 17280, 66, 270, 66, 66, 270, 270, 270, 66, 66, 17280, 270, 270, 66, 17280, 17280, 270, 17280, 17280, 270, 17280, 66, 17280, 270, 270, 270, 17280, 17280, 66, 66, 270, 66, 17280, 66, 66, 17280, 66, 270, 270, 66, 270, 17280, 17280, 17280, 270, 17280, 17280, 66, 66, 17280, 270, 17280, 66, 270, 17280, 66, 17280, 270, 66, 17280, 66, 66, 17280, 66, 66, 270]
Prompts retrieved: 563712 . Total input tokens: 125628176 . Total output tokens: 112839488
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 18.79506150400266,
    "estimated_duration": 3600.0006634396445,
    "input_throughput": 7687.389694411365,
    "output_throughput": 6810.54318933768,
    "total_throughput": 14497.932883749045,
    "itl": 126.48652327095816,
    "ttft": 1234871.420605711,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 33,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10684382440522311,
    "arrivals": 187468,
    "finished_requests": 111775,
    "scheduler_time": 168.61782466913274
}
#Debug simulation 
Total elapsed time: 18.795175571925938. Arrivals time: 0.4855046235024929 Scheduler time: 18.179402829147875 Scheduler overhead time: 0.05142873711884022 Adapter cache time: 0.008075605612248182 Engine time: 0.04873626586049795 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-16/adapters_96_slots_32_rate_1.6-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-16/adapters_96_slots_32_rate_1.6-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 66, 17280, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 270, 66, 17280, 270, 66, 66, 270, 17280, 66, 270, 66, 66, 270, 270, 270, 66, 66, 17280, 270, 270, 66, 17280, 17280, 270, 17280, 17280, 270, 17280, 66, 17280, 270, 270, 270, 17280, 17280, 66, 66, 270, 66, 17280, 66, 66, 17280, 66, 270, 270, 66, 270, 17280, 17280, 17280, 270, 17280, 17280, 66, 66, 17280, 270, 17280, 66, 270, 17280, 66, 17280, 270, 66, 17280, 66, 66, 17280, 66, 66, 270]
Prompts retrieved: 563712 . Total input tokens: 125628176 . Total output tokens: 112839488
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 18.589237086940557,
    "estimated_duration": 3600.1329750029017,
    "input_throughput": 7687.2979948685625,
    "output_throughput": 6810.394552156851,
    "total_throughput": 14497.692547025414,
    "itl": 126.4869795568476,
    "ttft": 1234938.5890708962,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 33,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.1027576129161753,
    "arrivals": 187468,
    "finished_requests": 111776,
    "scheduler_time": 168.62456394319258
}
#Debug simulation 
Total elapsed time: 18.589356779120862. Arrivals time: 0.41720184311270714 Scheduler time: 18.04335451964289 Scheduler overhead time: 0.050408388022333384 Adapter cache time: 0.008333074860274792 Engine time: 0.04834151919931173 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-32/adapters_96_slots_32_rate_1.6-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-32/adapters_96_slots_32_rate_1.6-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 66, 17280, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 270, 66, 17280, 270, 66, 66, 270, 17280, 66, 270, 66, 66, 270, 270, 270, 66, 66, 17280, 270, 270, 66, 17280, 17280, 270, 17280, 17280, 270, 17280, 66, 17280, 270, 270, 270, 17280, 17280, 66, 66, 270, 66, 17280, 66, 66, 17280, 66, 270, 270, 66, 270, 17280, 17280, 17280, 270, 17280, 17280, 66, 66, 17280, 270, 17280, 66, 270, 17280, 66, 17280, 270, 66, 17280, 66, 66, 17280, 66, 66, 270]
Prompts retrieved: 563712 . Total input tokens: 125628176 . Total output tokens: 112839488
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 19.281639306806028,
    "estimated_duration": 3600.020782559072,
    "input_throughput": 7687.346732572895,
    "output_throughput": 6810.5051278541305,
    "total_throughput": 14497.851860427027,
    "itl": 126.48699783312239,
    "ttft": 1234866.36056147,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 33,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10797560848295684,
    "arrivals": 187468,
    "finished_requests": 111775,
    "scheduler_time": 168.61885042219038
}
#Debug simulation 
Total elapsed time: 19.281774330884218. Arrivals time: 0.5027118134312332 Scheduler time: 18.64782611001283 Scheduler overhead time: 0.05082551250234246 Adapter cache time: 0.008104999549686909 Engine time: 0.0500222435221076 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-16/adapters_96_slots_32_rate_1.6-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-16/adapters_96_slots_32_rate_1.6-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 66, 17280, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 270, 66, 17280, 270, 66, 66, 270, 17280, 66, 270, 66, 66, 270, 270, 270, 66, 66, 17280, 270, 270, 66, 17280, 17280, 270, 17280, 17280, 270, 17280, 66, 17280, 270, 270, 270, 17280, 17280, 66, 66, 270, 66, 17280, 66, 66, 17280, 66, 270, 270, 66, 270, 17280, 17280, 17280, 270, 17280, 17280, 66, 66, 17280, 270, 17280, 66, 270, 17280, 66, 17280, 270, 66, 17280, 66, 66, 17280, 66, 66, 270]
Prompts retrieved: 563712 . Total input tokens: 125628176 . Total output tokens: 112839488
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 18.768676781095564,
    "estimated_duration": 3600.121043070991,
    "input_throughput": 7687.323472988646,
    "output_throughput": 6810.417123943496,
    "total_throughput": 14497.740596932143,
    "itl": 126.48722318195432,
    "ttft": 1234935.1422376144,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 33,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09867165973177183,
    "arrivals": 187468,
    "finished_requests": 111776,
    "scheduler_time": 168.62392966886856
}
#Debug simulation 
Total elapsed time: 18.76884510507807. Arrivals time: 0.48835279140621424 Scheduler time: 18.150079051498324 Scheduler overhead time: 0.05049047525972128 Adapter cache time: 0.00829444918781519 Engine time: 0.04954492533579469 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-32/adapters_96_slots_32_rate_1.6-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-32/adapters_96_slots_32_rate_1.6-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 66, 17280, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 270, 66, 17280, 270, 66, 66, 270, 17280, 66, 270, 66, 66, 270, 270, 270, 66, 66, 17280, 270, 270, 66, 17280, 17280, 270, 17280, 17280, 270, 17280, 66, 17280, 270, 270, 270, 17280, 17280, 66, 66, 270, 66, 17280, 66, 66, 17280, 66, 270, 270, 66, 270, 17280, 17280, 17280, 270, 17280, 17280, 66, 66, 17280, 270, 17280, 66, 270, 17280, 66, 17280, 270, 66, 17280, 66, 66, 17280, 66, 66, 270]
Prompts retrieved: 563712 . Total input tokens: 125628176 . Total output tokens: 112839488
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 18.861593743320554,
    "estimated_duration": 3600.0447701997396,
    "input_throughput": 7687.486341583609,
    "output_throughput": 6810.561413834768,
    "total_throughput": 14498.047755418376,
    "itl": 126.48724534448166,
    "ttft": 1234901.6020230425,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 33,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10923314634710543,
    "arrivals": 187468,
    "finished_requests": 111776,
    "scheduler_time": 168.62007028875527
}
#Debug simulation 
Total elapsed time: 18.861696555279195. Arrivals time: 0.4981666821986437 Scheduler time: 18.23235800070688 Scheduler overhead time: 0.05160121992230415 Adapter cache time: 0.008090691175311804 Engine time: 0.04951108293607831 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-8/adapters_96_slots_32_rate_1.6-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-8/adapters_96_slots_32_rate_1.6-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 33, 17280, 33, 33, 17280, 270, 17280, 270, 17280, 17280, 270, 33, 17280, 270, 33, 33, 270, 17280, 33, 270, 33, 33, 270, 270, 270, 33, 33, 17280, 270, 270, 33, 17280, 17280, 270, 17280, 17280, 270, 17280, 33, 17280, 270, 270, 270, 17280, 17280, 33, 33, 270, 33, 17280, 33, 33, 17280, 33, 270, 270, 33, 270, 17280, 17280, 17280, 270, 17280, 17280, 33, 33, 17280, 270, 17280, 33, 270, 17280, 33, 17280, 270, 33, 17280, 33, 33, 17280, 33, 33, 270]
Prompts retrieved: 562656 . Total input tokens: 125378570 . Total output tokens: 112631294
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 17.517237592022866,
    "estimated_duration": 3600.0382696187457,
    "input_throughput": 7650.787557576963,
    "output_throughput": 6812.910909026934,
    "total_throughput": 14463.698466603897,
    "itl": 126.73876770580117,
    "ttft": 1239214.9890121964,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 37,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.11323804652551184,
    "arrivals": 186986,
    "finished_requests": 111394,
    "scheduler_time": 168.46506089916383
}
#Debug simulation 
Total elapsed time: 17.517354323063046. Arrivals time: 0.5188941629603505 Scheduler time: 16.869213426019996 Scheduler overhead time: 0.050313394982367754 Adapter cache time: 0.008166228421032429 Engine time: 0.04900544648990035 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-16/adapters_96_slots_32_rate_1.6-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-16/adapters_96_slots_32_rate_1.6-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 33, 17280, 33, 33, 17280, 270, 17280, 270, 17280, 17280, 270, 33, 17280, 270, 33, 33, 270, 17280, 33, 270, 33, 33, 270, 270, 270, 33, 33, 17280, 270, 270, 33, 17280, 17280, 270, 17280, 17280, 270, 17280, 33, 17280, 270, 270, 270, 17280, 17280, 33, 33, 270, 33, 17280, 33, 33, 17280, 33, 270, 270, 33, 270, 17280, 17280, 17280, 270, 17280, 17280, 33, 33, 17280, 270, 17280, 33, 270, 17280, 33, 17280, 270, 33, 17280, 33, 33, 17280, 33, 33, 270]
Prompts retrieved: 562656 . Total input tokens: 125378570 . Total output tokens: 112631294
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 17.396864399779588,
    "estimated_duration": 3600.058253916439,
    "input_throughput": 7650.74508725972,
    "output_throughput": 6812.873089850088,
    "total_throughput": 14463.618177109807,
    "itl": 126.73843959662798,
    "ttft": 1239238.1233972765,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 37,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.11962095791706814,
    "arrivals": 186986,
    "finished_requests": 111394,
    "scheduler_time": 168.4662025627882
}
#Debug simulation 
Total elapsed time: 17.39700112072751. Arrivals time: 0.49554668506607413 Scheduler time: 16.772261545527726 Scheduler overhead time: 0.05044601811096072 Adapter cache time: 0.00793326972052455 Engine time: 0.048820096999406815 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-32/adapters_96_slots_32_rate_1.6-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-32/adapters_96_slots_32_rate_1.6-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 33, 17280, 33, 33, 17280, 270, 17280, 270, 17280, 17280, 270, 33, 17280, 270, 33, 33, 270, 17280, 33, 270, 33, 33, 270, 270, 270, 33, 33, 17280, 270, 270, 33, 17280, 17280, 270, 17280, 17280, 270, 17280, 33, 17280, 270, 270, 270, 17280, 17280, 33, 33, 270, 33, 17280, 33, 33, 17280, 33, 270, 270, 33, 270, 17280, 17280, 17280, 270, 17280, 17280, 33, 33, 17280, 270, 17280, 33, 270, 17280, 33, 17280, 270, 33, 17280, 33, 33, 17280, 33, 33, 270]
Prompts retrieved: 562656 . Total input tokens: 125378570 . Total output tokens: 112631294
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 17.370333784259856,
    "estimated_duration": 3600.0578870056015,
    "input_throughput": 7650.74586700865,
    "output_throughput": 6812.873784204748,
    "total_throughput": 14463.619651213397,
    "itl": 126.73831362496341,
    "ttft": 1239237.4964258256,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 37,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.12002964228391647,
    "arrivals": 186986,
    "finished_requests": 111394,
    "scheduler_time": 168.4662143486714
}
#Debug simulation 
Total elapsed time: 17.370511189103127. Arrivals time: 0.4706950639374554 Scheduler time: 16.77279254840687 Scheduler overhead time: 0.04921271977946162 Adapter cache time: 0.007966619450598955 Engine time: 0.04833026509732008 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-16/adapters_96_slots_32_rate_1.6-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-16/adapters_96_slots_32_rate_1.6-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 33, 17280, 33, 33, 17280, 270, 17280, 270, 17280, 17280, 270, 33, 17280, 270, 33, 33, 270, 17280, 33, 270, 33, 33, 270, 270, 270, 33, 33, 17280, 270, 270, 33, 17280, 17280, 270, 17280, 17280, 270, 17280, 33, 17280, 270, 270, 270, 17280, 17280, 33, 33, 270, 33, 17280, 33, 33, 17280, 33, 270, 270, 33, 270, 17280, 17280, 17280, 270, 17280, 17280, 33, 33, 17280, 270, 17280, 33, 270, 17280, 33, 17280, 270, 33, 17280, 33, 33, 17280, 33, 33, 270]
Prompts retrieved: 562656 . Total input tokens: 125378570 . Total output tokens: 112631294
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 17.519158013164997,
    "estimated_duration": 3600.042679511406,
    "input_throughput": 7650.778185701433,
    "output_throughput": 6812.902563513148,
    "total_throughput": 14463.680749214582,
    "itl": 126.73853476134808,
    "ttft": 1239234.3172955075,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 37,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.11512640941422436,
    "arrivals": 186986,
    "finished_requests": 111394,
    "scheduler_time": 168.4653931464603
}
#Debug simulation 
Total elapsed time: 17.51925683906302. Arrivals time: 0.5180116011761129 Scheduler time: 16.871948425658047 Scheduler overhead time: 0.04948960430920124 Adapter cache time: 0.008282140828669071 Engine time: 0.04906146554276347 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-32/adapters_96_slots_32_rate_1.6-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-32/adapters_96_slots_32_rate_1.6-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 33, 17280, 33, 33, 17280, 270, 17280, 270, 17280, 17280, 270, 33, 17280, 270, 33, 33, 270, 17280, 33, 270, 33, 33, 270, 270, 270, 33, 33, 17280, 270, 270, 33, 17280, 17280, 270, 17280, 17280, 270, 17280, 33, 17280, 270, 270, 270, 17280, 17280, 33, 33, 270, 33, 17280, 33, 33, 17280, 33, 270, 270, 33, 270, 17280, 17280, 17280, 270, 17280, 17280, 33, 33, 17280, 270, 17280, 33, 270, 17280, 33, 17280, 270, 33, 17280, 33, 33, 17280, 33, 33, 270]
Prompts retrieved: 562656 . Total input tokens: 125378570 . Total output tokens: 112631294
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 17.478999994695187,
    "estimated_duration": 3600.0646144027637,
    "input_throughput": 7650.731847925262,
    "output_throughput": 6812.955218046536,
    "total_throughput": 14463.687065971797,
    "itl": 126.73851145980893,
    "ttft": 1239222.1669352758,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 37,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.1214129339344799,
    "arrivals": 186986,
    "finished_requests": 111395,
    "scheduler_time": 168.46646872778155
}
#Debug simulation 
Total elapsed time: 17.47912934795022. Arrivals time: 0.4939219285733998 Scheduler time: 16.856439476832747 Scheduler overhead time: 0.050123164895921946 Adapter cache time: 0.00803766818717122 Engine time: 0.04886458022519946 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-16/adapters_96_slots_32_rate_1.6-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-16/adapters_96_slots_32_rate_1.6-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 33, 17280, 33, 33, 17280, 270, 17280, 270, 17280, 17280, 270, 33, 17280, 270, 33, 33, 270, 17280, 33, 270, 33, 33, 270, 270, 270, 33, 33, 17280, 270, 270, 33, 17280, 17280, 270, 17280, 17280, 270, 17280, 33, 17280, 270, 270, 270, 17280, 17280, 33, 33, 270, 33, 17280, 33, 33, 17280, 33, 270, 270, 33, 270, 17280, 17280, 17280, 270, 17280, 17280, 33, 33, 17280, 270, 17280, 33, 270, 17280, 33, 17280, 270, 33, 17280, 33, 33, 17280, 33, 33, 270]
Prompts retrieved: 562656 . Total input tokens: 125378570 . Total output tokens: 112631294
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 17.401505685877055,
    "estimated_duration": 3600.136801202858,
    "input_throughput": 7650.717603508087,
    "output_throughput": 6812.869442018172,
    "total_throughput": 14463.58704552626,
    "itl": 126.73807900508191,
    "ttft": 1239240.2300955064,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 37,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.11063186091138055,
    "arrivals": 186986,
    "finished_requests": 111396,
    "scheduler_time": 168.47017088116877
}
#Debug simulation 
Total elapsed time: 17.401747370138764. Arrivals time: 0.5219339411705732 Scheduler time: 16.752810271456838 Scheduler overhead time: 0.04952449910342693 Adapter cache time: 0.007914426736533642 Engine time: 0.047820248175412416 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-32/adapters_96_slots_32_rate_1.6-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-32/adapters_96_slots_32_rate_1.6-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 33, 17280, 33, 33, 17280, 270, 17280, 270, 17280, 17280, 270, 33, 17280, 270, 33, 33, 270, 17280, 33, 270, 33, 33, 270, 270, 270, 33, 33, 17280, 270, 270, 33, 17280, 17280, 270, 17280, 17280, 270, 17280, 33, 17280, 270, 270, 270, 17280, 17280, 33, 33, 270, 33, 17280, 33, 33, 17280, 33, 270, 270, 33, 270, 17280, 17280, 17280, 270, 17280, 17280, 33, 33, 17280, 270, 17280, 33, 270, 17280, 33, 17280, 270, 33, 17280, 33, 33, 17280, 33, 33, 270]
Prompts retrieved: 562656 . Total input tokens: 125378570 . Total output tokens: 112631294
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 17.258379260078073,
    "estimated_duration": 3600.0704633301925,
    "input_throughput": 7650.719418008733,
    "output_throughput": 6812.944149240786,
    "total_throughput": 14463.66356724952,
    "itl": 126.7383203107458,
    "ttft": 1239223.8498460755,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 37,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.12279622558504337,
    "arrivals": 186986,
    "finished_requests": 111395,
    "scheduler_time": 168.46684611455666
}
#Debug simulation 
Total elapsed time: 17.25849825516343. Arrivals time: 0.4663199041970074 Scheduler time: 16.665990251116455 Scheduler overhead time: 0.04914410784840584 Adapter cache time: 0.007832745555788279 Engine time: 0.04770285449922085 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-8/adapters_96_slots_32_rate_1.6-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-8/adapters_96_slots_32_rate_1.6-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 17280, 135, 135, 135, 135, 17280, 135, 17280, 135, 66, 17280, 66, 66, 17280, 135, 17280, 135, 17280, 17280, 135, 66, 17280, 135, 66, 66, 135, 17280, 66, 135, 66, 66, 135, 135, 135, 66, 66, 17280, 135, 135, 66, 17280, 17280, 135, 17280, 17280, 135, 17280, 66, 17280, 135, 135, 135, 17280, 17280, 66, 66, 135, 66, 17280, 66, 66, 17280, 66, 135, 135, 66, 135, 17280, 17280, 17280, 135, 17280, 17280, 66, 66, 17280, 135, 17280, 66, 135, 17280, 66, 17280, 135, 66, 17280, 66, 66, 17280, 66, 66, 135]
Prompts retrieved: 559392 . Total input tokens: 124640771 . Total output tokens: 111969357
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 14.519459901377559,
    "estimated_duration": 3600.1372668157064,
    "input_throughput": 7688.415454359098,
    "output_throughput": 6808.271513958004,
    "total_throughput": 14496.686968317103,
    "itl": 126.47130299549528,
    "ttft": 1237955.4310669312,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 33,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10099609554978084,
    "arrivals": 186004,
    "finished_requests": 111707,
    "scheduler_time": 168.34853343320313
}
#Debug simulation 
Total elapsed time: 14.519558350089937. Arrivals time: 0.4334901003167033 Scheduler time: 13.961901581380516 Scheduler overhead time: 0.04753128532320261 Adapter cache time: 0.007887897547334433 Engine time: 0.04727056296542287 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-16/adapters_96_slots_32_rate_1.6-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-16/adapters_96_slots_32_rate_1.6-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 17280, 135, 135, 135, 135, 17280, 135, 17280, 135, 66, 17280, 66, 66, 17280, 135, 17280, 135, 17280, 17280, 135, 66, 17280, 135, 66, 66, 135, 17280, 66, 135, 66, 66, 135, 135, 135, 66, 66, 17280, 135, 135, 66, 17280, 17280, 135, 17280, 17280, 135, 17280, 66, 17280, 135, 135, 135, 17280, 17280, 66, 66, 135, 66, 17280, 66, 66, 17280, 66, 135, 135, 66, 135, 17280, 17280, 17280, 135, 17280, 17280, 66, 66, 17280, 135, 17280, 66, 135, 17280, 66, 17280, 135, 66, 17280, 66, 66, 17280, 66, 66, 135]
Prompts retrieved: 559392 . Total input tokens: 124640771 . Total output tokens: 111969357
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 14.036786953918636,
    "estimated_duration": 3600.054128154436,
    "input_throughput": 7688.306346157428,
    "output_throughput": 6808.404853780726,
    "total_throughput": 14496.711199938154,
    "itl": 126.47216121686905,
    "ttft": 1237966.7258612541,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 33,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10684356610057875,
    "arrivals": 186004,
    "finished_requests": 111705,
    "scheduler_time": 168.34431052257048
}
#Debug simulation 
Total elapsed time: 14.037015280220658. Arrivals time: 0.43734880071133375 Scheduler time: 13.477328304201365 Scheduler overhead time: 0.04697355953976512 Adapter cache time: 0.007719364948570728 Engine time: 0.04641315387561917 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-32/adapters_96_slots_32_rate_1.6-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-32/adapters_96_slots_32_rate_1.6-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 17280, 135, 135, 135, 135, 17280, 135, 17280, 135, 66, 17280, 66, 66, 17280, 135, 17280, 135, 17280, 17280, 135, 66, 17280, 135, 66, 66, 135, 17280, 66, 135, 66, 66, 135, 135, 135, 66, 66, 17280, 135, 135, 66, 17280, 17280, 135, 17280, 17280, 135, 17280, 66, 17280, 135, 135, 135, 17280, 17280, 66, 66, 135, 66, 17280, 66, 66, 17280, 66, 135, 135, 66, 135, 17280, 17280, 17280, 135, 17280, 17280, 66, 66, 17280, 135, 17280, 66, 135, 17280, 66, 17280, 135, 66, 17280, 66, 66, 17280, 66, 66, 135]
Prompts retrieved: 559392 . Total input tokens: 124640771 . Total output tokens: 111969357
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 14.179489187896252,
    "estimated_duration": 3600.0546955641876,
    "input_throughput": 7688.305134392508,
    "output_throughput": 6808.403780698332,
    "total_throughput": 14496.708915090841,
    "itl": 126.47215766438202,
    "ttft": 1237967.1760847243,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 33,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10718107189983131,
    "arrivals": 186004,
    "finished_requests": 111705,
    "scheduler_time": 168.34435178250615
}
#Debug simulation 
Total elapsed time: 14.179619286209345. Arrivals time: 0.45965844625607133 Scheduler time: 13.594857628457248 Scheduler overhead time: 0.048270109575241804 Adapter cache time: 0.007694197352975607 Engine time: 0.047741814982146025 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-16/adapters_96_slots_32_rate_1.6-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-16/adapters_96_slots_32_rate_1.6-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 17280, 135, 135, 135, 135, 17280, 135, 17280, 135, 66, 17280, 66, 66, 17280, 135, 17280, 135, 17280, 17280, 135, 66, 17280, 135, 66, 66, 135, 17280, 66, 135, 66, 66, 135, 135, 135, 66, 66, 17280, 135, 135, 66, 17280, 17280, 135, 17280, 17280, 135, 17280, 66, 17280, 135, 135, 135, 17280, 17280, 66, 66, 135, 66, 17280, 66, 66, 17280, 66, 135, 135, 66, 135, 17280, 17280, 17280, 135, 17280, 17280, 66, 66, 17280, 135, 17280, 66, 135, 17280, 66, 17280, 135, 66, 17280, 66, 66, 17280, 66, 66, 135]
Prompts retrieved: 559392 . Total input tokens: 124640771 . Total output tokens: 111969357
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 14.028505409602076,
    "estimated_duration": 3600.0002014350166,
    "input_throughput": 7688.4084586903655,
    "output_throughput": 6808.392396819823,
    "total_throughput": 14496.800855510188,
    "itl": 126.47137381093631,
    "ttft": 1237953.5376866362,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 33,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10316620823461564,
    "arrivals": 186004,
    "finished_requests": 111704,
    "scheduler_time": 168.3415487370464
}
#Debug simulation 
Total elapsed time: 14.028605259023607. Arrivals time: 0.4316428378224373 Scheduler time: 13.474919728003442 Scheduler overhead time: 0.046852787490934134 Adapter cache time: 0.007619790732860565 Engine time: 0.046401218976825476 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-32/adapters_96_slots_32_rate_1.6-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-32/adapters_96_slots_32_rate_1.6-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 17280, 135, 135, 135, 135, 17280, 135, 17280, 135, 66, 17280, 66, 66, 17280, 135, 17280, 135, 17280, 17280, 135, 66, 17280, 135, 66, 66, 135, 17280, 66, 135, 66, 66, 135, 135, 135, 66, 66, 17280, 135, 135, 66, 17280, 17280, 135, 17280, 17280, 135, 17280, 66, 17280, 135, 135, 135, 17280, 17280, 66, 66, 135, 66, 17280, 66, 66, 17280, 66, 135, 135, 66, 135, 17280, 17280, 17280, 135, 17280, 17280, 66, 66, 17280, 135, 17280, 66, 135, 17280, 66, 17280, 135, 66, 17280, 66, 66, 17280, 66, 66, 135]
Prompts retrieved: 559392 . Total input tokens: 124640771 . Total output tokens: 111969357
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 14.13232388580218,
    "estimated_duration": 3600.0730238636033,
    "input_throughput": 7688.265992531337,
    "output_throughput": 6808.369118495036,
    "total_throughput": 14496.635111026373,
    "itl": 126.47258856304552,
    "ttft": 1237967.6233103129,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 33,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10831285597756506,
    "arrivals": 186004,
    "finished_requests": 111705,
    "scheduler_time": 168.34527178985388
}
#Debug simulation 
Total elapsed time: 14.13246124656871. Arrivals time: 0.4631639779545367 Scheduler time: 13.546779335476458 Scheduler overhead time: 0.04721329314634204 Adapter cache time: 0.007714231964200735 Engine time: 0.04639341216534376 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-16/adapters_96_slots_32_rate_1.6-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-16/adapters_96_slots_32_rate_1.6-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 17280, 135, 135, 135, 135, 17280, 135, 17280, 135, 66, 17280, 66, 66, 17280, 135, 17280, 135, 17280, 17280, 135, 66, 17280, 135, 66, 66, 135, 17280, 66, 135, 66, 66, 135, 135, 135, 66, 66, 17280, 135, 135, 66, 17280, 17280, 135, 17280, 17280, 135, 17280, 66, 17280, 135, 135, 135, 17280, 17280, 66, 66, 135, 66, 17280, 66, 66, 17280, 66, 135, 135, 66, 135, 17280, 17280, 17280, 135, 17280, 17280, 66, 66, 17280, 135, 17280, 66, 135, 17280, 66, 17280, 135, 66, 17280, 66, 66, 17280, 66, 66, 135]
Prompts retrieved: 559392 . Total input tokens: 124640771 . Total output tokens: 111969357
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 14.495602784212679,
    "estimated_duration": 3600.132540959729,
    "input_throughput": 7688.425546860893,
    "output_throughput": 6808.280451104141,
    "total_throughput": 14496.705997965035,
    "itl": 126.47141230322131,
    "ttft": 1237953.5090267684,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 33,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09867165973177183,
    "arrivals": 186004,
    "finished_requests": 111707,
    "scheduler_time": 168.3482409246207
}
#Debug simulation 
Total elapsed time: 14.495763426180929. Arrivals time: 0.4956100694835186 Scheduler time: 13.87627191003412 Scheduler overhead time: 0.04805129440501332 Adapter cache time: 0.0076752533204853535 Engine time: 0.04677115427330136 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-32/adapters_96_slots_32_rate_1.6-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-32/adapters_96_slots_32_rate_1.6-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 17280, 135, 135, 135, 135, 17280, 135, 17280, 135, 66, 17280, 66, 66, 17280, 135, 17280, 135, 17280, 17280, 135, 66, 17280, 135, 66, 66, 135, 17280, 66, 135, 66, 66, 135, 135, 135, 66, 66, 17280, 135, 135, 66, 17280, 17280, 135, 17280, 17280, 135, 17280, 66, 17280, 135, 135, 135, 17280, 17280, 66, 66, 135, 66, 17280, 66, 66, 17280, 66, 135, 135, 66, 135, 17280, 17280, 17280, 135, 17280, 17280, 66, 66, 17280, 135, 17280, 66, 135, 17280, 66, 17280, 135, 66, 17280, 66, 66, 17280, 66, 66, 135]
Prompts retrieved: 559392 . Total input tokens: 124640771 . Total output tokens: 111969357
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 14.151630622334778,
    "estimated_duration": 3600.073080493885,
    "input_throughput": 7688.265871592496,
    "output_throughput": 6808.369011397249,
    "total_throughput": 14496.634882989745,
    "itl": 126.47248835802255,
    "ttft": 1237966.9005465317,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 33,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.1096961476281285,
    "arrivals": 186004,
    "finished_requests": 111705,
    "scheduler_time": 168.34530980673807
}
#Debug simulation 
Total elapsed time: 14.151758442167193. Arrivals time: 0.4451880590058863 Scheduler time: 13.583137468900532 Scheduler overhead time: 0.047340802382677794 Adapter cache time: 0.007643408607691526 Engine time: 0.04683668399229646 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-8/adapters_96_slots_32_rate_1.6-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-8/adapters_96_slots_32_rate_1.6-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 17280, 135, 135, 135, 135, 17280, 135, 17280, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 17280, 17280, 135, 33, 17280, 135, 33, 33, 135, 17280, 33, 135, 33, 33, 135, 135, 135, 33, 33, 17280, 135, 135, 33, 17280, 17280, 135, 17280, 17280, 135, 17280, 33, 17280, 135, 135, 135, 17280, 17280, 33, 33, 135, 33, 17280, 33, 33, 17280, 33, 135, 135, 33, 135, 17280, 17280, 17280, 135, 17280, 17280, 33, 33, 17280, 135, 17280, 33, 135, 17280, 33, 17280, 135, 33, 17280, 33, 33, 17280, 33, 33, 135]
Prompts retrieved: 558336 . Total input tokens: 124411758 . Total output tokens: 111757417
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 13.282109553925693,
    "estimated_duration": 3600.0385801729726,
    "input_throughput": 7684.958753600556,
    "output_throughput": 6812.075052490603,
    "total_throughput": 14497.033806091158,
    "itl": 126.34960656649541,
    "ttft": 1236855.3732874575,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 35,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10711707103764634,
    "arrivals": 185665,
    "finished_requests": 111770,
    "scheduler_time": 168.3585408205372
}
#Debug simulation 
Total elapsed time: 13.282280249986798. Arrivals time: 0.4448219146579504 Scheduler time: 12.713695365469903 Scheduler overhead time: 0.047661769669502974 Adapter cache time: 0.0077867708168923855 Engine time: 0.04683031840249896 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-16/adapters_96_slots_32_rate_1.6-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-16/adapters_96_slots_32_rate_1.6-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 17280, 135, 135, 135, 135, 17280, 135, 17280, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 17280, 17280, 135, 33, 17280, 135, 33, 33, 135, 17280, 33, 135, 33, 33, 135, 135, 135, 33, 33, 17280, 135, 135, 33, 17280, 17280, 135, 17280, 17280, 135, 17280, 33, 17280, 135, 135, 135, 17280, 17280, 33, 33, 135, 33, 17280, 33, 33, 17280, 33, 135, 135, 33, 135, 17280, 17280, 17280, 135, 17280, 17280, 33, 33, 17280, 135, 17280, 33, 135, 17280, 33, 17280, 135, 33, 17280, 33, 33, 17280, 33, 33, 135]
Prompts retrieved: 558336 . Total input tokens: 124411758 . Total output tokens: 111757417
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 13.194043923169374,
    "estimated_duration": 3600.073402961091,
    "input_throughput": 7684.8844185355665,
    "output_throughput": 6812.009160654619,
    "total_throughput": 14496.893579190186,
    "itl": 126.34958131632787,
    "ttft": 1236942.5858325295,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 35,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.11364085732726378,
    "arrivals": 185665,
    "finished_requests": 111770,
    "scheduler_time": 168.3603654214853
}
#Debug simulation 
Total elapsed time: 13.194150070194155. Arrivals time: 0.44621740048751235 Scheduler time: 12.625163700431585 Scheduler overhead time: 0.0475024888291955 Adapter cache time: 0.0076828571036458015 Engine time: 0.046299219597131014 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-32/adapters_96_slots_32_rate_1.6-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-32/adapters_96_slots_32_rate_1.6-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 17280, 135, 135, 135, 135, 17280, 135, 17280, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 17280, 17280, 135, 33, 17280, 135, 33, 33, 135, 17280, 33, 135, 33, 33, 135, 135, 135, 33, 33, 17280, 135, 135, 33, 17280, 17280, 135, 17280, 17280, 135, 17280, 33, 17280, 135, 135, 135, 17280, 17280, 33, 33, 135, 33, 17280, 33, 33, 17280, 33, 135, 135, 33, 135, 17280, 17280, 17280, 135, 17280, 17280, 33, 33, 17280, 135, 17280, 33, 135, 17280, 33, 17280, 135, 33, 17280, 33, 33, 17280, 33, 33, 135]
Prompts retrieved: 558336 . Total input tokens: 124411758 . Total output tokens: 111757417
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 13.271413869224489,
    "estimated_duration": 3600.0738668582376,
    "input_throughput": 7684.88342827923,
    "output_throughput": 6812.00828287496,
    "total_throughput": 14496.89171115419,
    "itl": 126.34960631800682,
    "ttft": 1236942.8563447103,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 35,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.11394260458648203,
    "arrivals": 185665,
    "finished_requests": 111770,
    "scheduler_time": 168.36042344951701
}
#Debug simulation 
Total elapsed time: 13.271537833381444. Arrivals time: 0.44352179300040007 Scheduler time: 12.704452898819 Scheduler overhead time: 0.047347687650471926 Adapter cache time: 0.007678474299609661 Engine time: 0.04691515862941742 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-16/adapters_96_slots_32_rate_1.6-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-16/adapters_96_slots_32_rate_1.6-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 17280, 135, 135, 135, 135, 17280, 135, 17280, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 17280, 17280, 135, 33, 17280, 135, 33, 33, 135, 17280, 33, 135, 33, 33, 135, 135, 135, 33, 33, 17280, 135, 135, 33, 17280, 17280, 135, 17280, 17280, 135, 17280, 33, 17280, 135, 135, 135, 17280, 17280, 33, 33, 135, 33, 17280, 33, 33, 17280, 33, 135, 135, 33, 135, 17280, 17280, 17280, 135, 17280, 17280, 33, 33, 17280, 135, 17280, 33, 135, 17280, 33, 17280, 135, 33, 17280, 33, 33, 17280, 33, 33, 135]
Prompts retrieved: 558336 . Total input tokens: 124411758 . Total output tokens: 111757417
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 13.169304180890322,
    "estimated_duration": 3600.0509738220217,
    "input_throughput": 7684.932297119121,
    "output_throughput": 6812.051601026135,
    "total_throughput": 14496.983898145258,
    "itl": 126.34941417070806,
    "ttft": 1236858.3869487313,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 35,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10996349946130067,
    "arrivals": 185665,
    "finished_requests": 111770,
    "scheduler_time": 168.35918030705082
}
#Debug simulation 
Total elapsed time: 13.169421412982047. Arrivals time: 0.42817468009889126 Scheduler time: 12.619565275497735 Scheduler overhead time: 0.04680701671168208 Adapter cache time: 0.007560887839645147 Engine time: 0.046134866774082184 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-32/adapters_96_slots_32_rate_1.6-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-32/adapters_96_slots_32_rate_1.6-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 17280, 135, 135, 135, 135, 17280, 135, 17280, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 17280, 17280, 135, 33, 17280, 135, 33, 33, 135, 17280, 33, 135, 33, 33, 135, 135, 135, 33, 33, 17280, 135, 135, 33, 17280, 17280, 135, 17280, 17280, 135, 17280, 33, 17280, 135, 135, 135, 17280, 17280, 33, 33, 135, 33, 17280, 33, 33, 17280, 33, 135, 135, 33, 135, 17280, 17280, 17280, 135, 17280, 17280, 33, 33, 17280, 135, 17280, 33, 135, 17280, 33, 17280, 135, 33, 17280, 33, 33, 17280, 33, 33, 135]
Prompts retrieved: 558336 . Total input tokens: 124411758 . Total output tokens: 111757417
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 13.176645859144628,
    "estimated_duration": 3600.0770410468363,
    "input_throughput": 7684.876652516078,
    "output_throughput": 6812.002276725986,
    "total_throughput": 14496.878929242064,
    "itl": 126.34952118432119,
    "ttft": 1236943.9634364,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 35,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.11507438866421577,
    "arrivals": 185665,
    "finished_requests": 111770,
    "scheduler_time": 168.3605921357131
}
#Debug simulation 
Total elapsed time: 13.176763433031738. Arrivals time: 0.4414928834885359 Scheduler time: 12.610121936537325 Scheduler overhead time: 0.047860612627118826 Adapter cache time: 0.007766430266201496 Engine time: 0.048395702149719 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-16/adapters_96_slots_32_rate_1.6-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-16/adapters_96_slots_32_rate_1.6-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 17280, 135, 135, 135, 135, 17280, 135, 17280, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 17280, 17280, 135, 33, 17280, 135, 33, 33, 135, 17280, 33, 135, 33, 33, 135, 135, 135, 33, 33, 17280, 135, 135, 33, 17280, 17280, 135, 17280, 17280, 135, 17280, 33, 17280, 135, 135, 135, 17280, 17280, 33, 33, 135, 33, 17280, 33, 33, 17280, 33, 135, 135, 33, 135, 17280, 17280, 17280, 135, 17280, 17280, 33, 33, 17280, 135, 17280, 33, 135, 17280, 33, 17280, 135, 33, 17280, 33, 33, 17280, 33, 33, 135]
Prompts retrieved: 558336 . Total input tokens: 124411758 . Total output tokens: 111757417
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 13.086424998007715,
    "estimated_duration": 3600.015464815294,
    "input_throughput": 7684.830320977367,
    "output_throughput": 6811.945737365939,
    "total_throughput": 14496.776058343306,
    "itl": 126.34926704482172,
    "ttft": 1236889.3000559814,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 35,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10465176032157619,
    "arrivals": 185665,
    "finished_requests": 111768,
    "scheduler_time": 168.35737355667442
}
#Debug simulation 
Total elapsed time: 13.086610698141158. Arrivals time: 0.429354109801352 Scheduler time: 12.535852190572768 Scheduler overhead time: 0.046638044994324446 Adapter cache time: 0.0075302282348275185 Engine time: 0.046081294771283865 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-32/adapters_96_slots_32_rate_1.6-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-32/adapters_96_slots_32_rate_1.6-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 17280, 135, 135, 135, 135, 17280, 135, 17280, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 17280, 17280, 135, 33, 17280, 135, 33, 33, 135, 17280, 33, 135, 33, 33, 135, 135, 135, 33, 33, 17280, 135, 135, 33, 17280, 17280, 135, 17280, 17280, 135, 17280, 33, 17280, 135, 135, 135, 17280, 17280, 33, 33, 135, 33, 17280, 33, 33, 17280, 33, 135, 135, 33, 135, 17280, 17280, 17280, 135, 17280, 17280, 33, 33, 17280, 135, 17280, 33, 135, 17280, 33, 17280, 135, 33, 17280, 33, 33, 17280, 33, 33, 135]
Prompts retrieved: 558336 . Total input tokens: 124411758 . Total output tokens: 111757417
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 13.130043488927186,
    "estimated_duration": 3600.0926563908574,
    "input_throughput": 7684.843319487142,
    "output_throughput": 6811.972729775623,
    "total_throughput": 14496.816049262765,
    "itl": 126.34960707727619,
    "ttft": 1236974.2709093208,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 35,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.11670918788760894,
    "arrivals": 185665,
    "finished_requests": 111770,
    "scheduler_time": 168.3613393918599
}
#Debug simulation 
Total elapsed time: 13.130197353195399. Arrivals time: 0.4372390708886087 Scheduler time: 12.570528759621084 Scheduler overhead time: 0.04766554618254304 Adapter cache time: 0.007678897585719824 Engine time: 0.04595742607489228 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-8/adapters_96_slots_32_rate_1.6-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-8/adapters_96_slots_32_rate_1.6-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 17280, 66, 66, 66, 66, 17280, 66, 17280, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 17280, 17280, 66, 33, 17280, 66, 33, 33, 66, 17280, 33, 66, 33, 33, 66, 66, 66, 33, 33, 17280, 66, 66, 33, 17280, 17280, 66, 17280, 17280, 66, 17280, 33, 17280, 66, 66, 66, 17280, 17280, 33, 33, 66, 33, 17280, 33, 33, 17280, 33, 66, 66, 33, 66, 17280, 17280, 17280, 66, 17280, 17280, 33, 33, 17280, 66, 17280, 33, 66, 17280, 33, 17280, 66, 33, 17280, 33, 33, 17280, 33, 33, 66]
Prompts retrieved: 556128 . Total input tokens: 123911371 . Total output tokens: 111312136
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 11.121140279341489,
    "estimated_duration": 3600.056337659193,
    "input_throughput": 7694.729582485333,
    "output_throughput": 6812.703941168661,
    "total_throughput": 14507.433523653994,
    "itl": 126.33923797876149,
    "ttft": 1231980.7324933137,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 184921,
    "finished_requests": 111762,
    "scheduler_time": 167.89376200355858
}
#Debug simulation 
Total elapsed time: 11.1212920374237. Arrivals time: 0.42245675064623356 Scheduler time: 10.578339482657611 Scheduler overhead time: 0.04643107345327735 Adapter cache time: 0.007440868299454451 Engine time: 0.04556850949302316 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-16/adapters_96_slots_32_rate_1.6-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-16/adapters_96_slots_32_rate_1.6-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 17280, 66, 66, 66, 66, 17280, 66, 17280, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 17280, 17280, 66, 33, 17280, 66, 33, 33, 66, 17280, 33, 66, 33, 33, 66, 66, 66, 33, 33, 17280, 66, 66, 33, 17280, 17280, 66, 17280, 17280, 66, 17280, 33, 17280, 66, 66, 66, 17280, 17280, 33, 33, 66, 33, 17280, 33, 33, 17280, 33, 66, 66, 33, 66, 17280, 17280, 17280, 66, 17280, 17280, 33, 33, 17280, 66, 17280, 33, 66, 17280, 33, 17280, 66, 33, 17280, 33, 33, 17280, 33, 33, 66]
Prompts retrieved: 556128 . Total input tokens: 123911371 . Total output tokens: 111312136
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 11.070029587950557,
    "estimated_duration": 3600.113023732284,
    "input_throughput": 7694.756197204327,
    "output_throughput": 6813.039990220029,
    "total_throughput": 14507.796187424356,
    "itl": 126.34035588588303,
    "ttft": 1231928.4997916613,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10344492048723623,
    "arrivals": 184921,
    "finished_requests": 111767,
    "scheduler_time": 167.896603923201
}
#Debug simulation 
Total elapsed time: 11.070180122274905. Arrivals time: 0.41787492809817195 Scheduler time: 10.53229873906821 Scheduler overhead time: 0.04628632729873061 Adapter cache time: 0.0074478695169091225 Engine time: 0.045180140528827906 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-32/adapters_96_slots_32_rate_1.6-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-32/adapters_96_slots_32_rate_1.6-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 17280, 66, 66, 66, 66, 17280, 66, 17280, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 17280, 17280, 66, 33, 17280, 66, 33, 33, 66, 17280, 33, 66, 33, 33, 66, 66, 66, 33, 33, 17280, 66, 66, 33, 17280, 17280, 66, 17280, 17280, 66, 17280, 33, 17280, 66, 66, 66, 17280, 17280, 33, 33, 66, 33, 17280, 33, 33, 17280, 33, 66, 66, 33, 66, 17280, 17280, 17280, 66, 17280, 17280, 33, 33, 17280, 66, 17280, 33, 66, 17280, 33, 17280, 66, 33, 17280, 33, 33, 17280, 33, 33, 66]
Prompts retrieved: 556128 . Total input tokens: 123911371 . Total output tokens: 111312136
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 11.202147839125246,
    "estimated_duration": 3600.1138923748626,
    "input_throughput": 7694.754340598379,
    "output_throughput": 6813.038346356307,
    "total_throughput": 14507.792686954686,
    "itl": 126.34033125858082,
    "ttft": 1231929.1631705626,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10380030555650592,
    "arrivals": 184921,
    "finished_requests": 111767,
    "scheduler_time": 167.89666476058625
}
#Debug simulation 
Total elapsed time: 11.20229285908863. Arrivals time: 0.4539133310317993 Scheduler time: 10.627214346081018 Scheduler overhead time: 0.04670396726578474 Adapter cache time: 0.007571690250188112 Engine time: 0.0457697412930429 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-16/adapters_96_slots_32_rate_1.6-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-16/adapters_96_slots_32_rate_1.6-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 17280, 66, 66, 66, 66, 17280, 66, 17280, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 17280, 17280, 66, 33, 17280, 66, 33, 33, 66, 17280, 33, 66, 33, 33, 66, 66, 66, 33, 33, 17280, 66, 66, 33, 17280, 17280, 66, 17280, 17280, 66, 17280, 33, 17280, 66, 66, 66, 17280, 17280, 33, 33, 66, 33, 17280, 33, 33, 17280, 33, 66, 66, 33, 66, 17280, 17280, 17280, 66, 17280, 17280, 33, 33, 17280, 66, 17280, 33, 66, 17280, 33, 17280, 66, 33, 17280, 33, 33, 17280, 33, 33, 66]
Prompts retrieved: 556128 . Total input tokens: 123911371 . Total output tokens: 111312136
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 11.25654116878286,
    "estimated_duration": 3600.0585192759518,
    "input_throughput": 7694.7249195191835,
    "output_throughput": 6812.699812705468,
    "total_throughput": 14507.424732224652,
    "itl": 126.33915990135955,
    "ttft": 1231981.393189642,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.0997675626212731,
    "arrivals": 184921,
    "finished_requests": 111762,
    "scheduler_time": 167.89390668840966
}
#Debug simulation 
Total elapsed time: 11.256670165807009. Arrivals time: 0.5210689106024802 Scheduler time: 10.613226470537484 Scheduler overhead time: 0.04718557512387633 Adapter cache time: 0.007518668659031391 Engine time: 0.04624402243643999 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-32/adapters_96_slots_32_rate_1.6-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-32/adapters_96_slots_32_rate_1.6-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 17280, 66, 66, 66, 66, 17280, 66, 17280, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 17280, 17280, 66, 33, 17280, 66, 33, 33, 66, 17280, 33, 66, 33, 33, 66, 66, 66, 33, 33, 17280, 66, 66, 33, 17280, 17280, 66, 17280, 17280, 66, 17280, 33, 17280, 66, 66, 66, 17280, 17280, 33, 33, 66, 33, 17280, 33, 33, 17280, 33, 66, 66, 33, 66, 17280, 17280, 17280, 66, 17280, 17280, 33, 33, 17280, 66, 17280, 33, 66, 17280, 33, 17280, 66, 33, 17280, 33, 33, 17280, 33, 33, 66]
Prompts retrieved: 556128 . Total input tokens: 123911371 . Total output tokens: 111312136
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 11.155012366827577,
    "estimated_duration": 3600.139763370437,
    "input_throughput": 7694.842650793374,
    "output_throughput": 6812.99410916126,
    "total_throughput": 14507.836759954633,
    "itl": 126.3408453698665,
    "ttft": 1231929.1856778837,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10493208963423967,
    "arrivals": 184921,
    "finished_requests": 111768,
    "scheduler_time": 167.89801062744644
}
#Debug simulation 
Total elapsed time: 11.155114545952529. Arrivals time: 0.4227526169270277 Scheduler time: 10.610986082814634 Scheduler overhead time: 0.04660062259063125 Adapter cache time: 0.007486177142709494 Engine time: 0.04616079572588205 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-16/adapters_96_slots_32_rate_1.6-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-16/adapters_96_slots_32_rate_1.6-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 17280, 66, 66, 66, 66, 17280, 66, 17280, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 17280, 17280, 66, 33, 17280, 66, 33, 33, 66, 17280, 33, 66, 33, 33, 66, 66, 66, 33, 33, 17280, 66, 66, 33, 17280, 17280, 66, 17280, 17280, 66, 17280, 33, 17280, 66, 66, 66, 17280, 17280, 33, 33, 66, 33, 17280, 33, 33, 17280, 33, 66, 66, 33, 66, 17280, 17280, 17280, 66, 17280, 17280, 33, 33, 17280, 66, 17280, 33, 66, 17280, 33, 17280, 66, 33, 17280, 33, 33, 17280, 33, 33, 66]
Prompts retrieved: 556128 . Total input tokens: 123911371 . Total output tokens: 111312136
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 11.156369359232485,
    "estimated_duration": 3600.049951177701,
    "input_throughput": 7694.743232920391,
    "output_throughput": 6812.716026891976,
    "total_throughput": 14507.459259812367,
    "itl": 126.33938709006598,
    "ttft": 1231979.6159430144,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 184921,
    "finished_requests": 111762,
    "scheduler_time": 167.8934628416749
}
#Debug simulation 
Total elapsed time: 11.15650144731626. Arrivals time: 0.42265015793964267 Scheduler time: 10.612744025886059 Scheduler overhead time: 0.046654632315039635 Adapter cache time: 0.007532750256359577 Engine time: 0.045805278699845076 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-32/adapters_96_slots_32_rate_1.6-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-32/adapters_96_slots_32_rate_1.6-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 17280, 66, 66, 66, 66, 17280, 66, 17280, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 17280, 17280, 66, 33, 17280, 66, 33, 33, 66, 17280, 33, 66, 33, 33, 66, 66, 66, 33, 33, 17280, 66, 66, 33, 17280, 17280, 66, 17280, 17280, 66, 17280, 33, 17280, 66, 66, 66, 17280, 17280, 33, 33, 66, 33, 17280, 33, 33, 17280, 33, 66, 66, 33, 66, 17280, 17280, 17280, 66, 17280, 17280, 33, 33, 17280, 66, 17280, 33, 66, 17280, 33, 17280, 66, 33, 17280, 33, 33, 17280, 33, 33, 66]
Prompts retrieved: 556128 . Total input tokens: 123911371 . Total output tokens: 111312136
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 11.617945022881031,
    "estimated_duration": 3600.14146714279,
    "input_throughput": 7694.839009197539,
    "output_throughput": 6812.990884901572,
    "total_throughput": 14507.82989409911,
    "itl": 126.34072022076268,
    "ttft": 1231929.9233055015,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10618962749838826,
    "arrivals": 184921,
    "finished_requests": 111768,
    "scheduler_time": 167.8981248967208
}
#Debug simulation 
Total elapsed time: 11.618094275705516. Arrivals time: 0.4275539917871356 Scheduler time: 11.068566471803933 Scheduler overhead time: 0.0469130021519959 Adapter cache time: 0.007566390093415976 Engine time: 0.04600887279957533 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-8/adapters_96_slots_32_rate_0.8-0.4-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-8/adapters_96_slots_32_rate_0.8-0.4-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 4320, 8640, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 8640, 4320, 4320, 1080, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 1080, 8640, 4320, 4320, 4320, 8640, 8640, 1080, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 1080, 1080, 8640, 4320, 8640, 1080, 4320, 8640, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 1080, 4320]
Prompts retrieved: 449280 . Total input tokens: 100180638 . Total output tokens: 89863988
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 173.21665585692972,
    "estimated_duration": 3600.048974222826,
    "input_throughput": 6911.44208819309,
    "output_throughput": 6155.468483531914,
    "total_throughput": 13066.910571725004,
    "itl": 106.48498095596463,
    "ttft": 1274890.8571282483,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 158,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4835570635413745,
    "arrivals": 149510,
    "finished_requests": 100803,
    "scheduler_time": 173.4807796688315
}
#Debug simulation 
Total elapsed time: 173.21681285230443. Arrivals time: 0.7624105960130692 Scheduler time: 172.11875940067694 Scheduler overhead time: 0.13762116571888328 Adapter cache time: 0.02482390310615301 Engine time: 0.13230519276112318 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-16/adapters_96_slots_32_rate_0.8-0.4-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-16/adapters_96_slots_32_rate_0.8-0.4-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 4320, 8640, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 8640, 4320, 4320, 1080, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 1080, 8640, 4320, 4320, 4320, 8640, 8640, 1080, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 1080, 1080, 8640, 4320, 8640, 1080, 4320, 8640, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 1080, 4320]
Prompts retrieved: 449280 . Total input tokens: 100180638 . Total output tokens: 89863988
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 177.8449625428766,
    "estimated_duration": 3600.0626809447426,
    "input_throughput": 6910.076074973161,
    "output_throughput": 6152.818426535609,
    "total_throughput": 13062.89450150877,
    "itl": 106.38963246490115,
    "ttft": 1264903.235678932,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 154,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5013272772589699,
    "arrivals": 149510,
    "finished_requests": 100796,
    "scheduler_time": 173.59285200781528
}
#Debug simulation 
Total elapsed time: 177.84514840180054. Arrivals time: 0.7706675454974174 Scheduler time: 176.72038629837334 Scheduler overhead time: 0.1471502990461886 Adapter cache time: 0.025705440435558558 Engine time: 0.13694053841754794 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-32/adapters_96_slots_32_rate_0.8-0.4-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-32/adapters_96_slots_32_rate_0.8-0.4-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 4320, 8640, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 8640, 4320, 4320, 1080, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 1080, 8640, 4320, 4320, 4320, 8640, 8640, 1080, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 1080, 1080, 8640, 4320, 8640, 1080, 4320, 8640, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 1080, 4320]
Prompts retrieved: 449280 . Total input tokens: 100180638 . Total output tokens: 89863988
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 177.2871618089266,
    "estimated_duration": 3600.0644758156113,
    "input_throughput": 6910.072629842016,
    "output_throughput": 6152.815358947619,
    "total_throughput": 13062.887988789635,
    "itl": 106.38968547806532,
    "ttft": 1264904.0104265513,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 154,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5024266521632688,
    "arrivals": 149510,
    "finished_requests": 100796,
    "scheduler_time": 173.59298442857366
}
#Debug simulation 
Total elapsed time: 177.28736335691065. Arrivals time: 0.774681210052222 Scheduler time: 176.1617364976555 Scheduler overhead time: 0.14303296152502298 Adapter cache time: 0.026888820808380842 Engine time: 0.13796350685879588 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-16-16/adapters_96_slots_32_rate_0.8-0.4-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-16-16/adapters_96_slots_32_rate_0.8-0.4-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 4320, 8640, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 8640, 4320, 4320, 1080, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 1080, 8640, 4320, 4320, 4320, 8640, 8640, 1080, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 1080, 1080, 8640, 4320, 8640, 1080, 4320, 8640, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 1080, 4320]
Prompts retrieved: 449280 . Total input tokens: 100180638 . Total output tokens: 89863988
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 168.3932335670106,
    "estimated_duration": 3600.0017545790956,
    "input_throughput": 6928.419400983375,
    "output_throughput": 6162.388941000329,
    "total_throughput": 13090.808341983706,
    "itl": 106.12349496409058,
    "ttft": 1277663.8828543797,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 159,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.49584776281146364,
    "arrivals": 149510,
    "finished_requests": 100938,
    "scheduler_time": 173.91938844772667
}
#Debug simulation 
Total elapsed time: 168.3933995142579. Arrivals time: 0.7450621984899044 Scheduler time: 167.31181695032865 Scheduler overhead time: 0.13846149295568466 Adapter cache time: 0.024819471407681704 Engine time: 0.13207416329532862 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-16-32/adapters_96_slots_32_rate_0.8-0.4-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-16-32/adapters_96_slots_32_rate_0.8-0.4-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 4320, 8640, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 8640, 4320, 4320, 1080, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 1080, 8640, 4320, 4320, 4320, 8640, 8640, 1080, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 1080, 1080, 8640, 4320, 8640, 1080, 4320, 8640, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 1080, 4320]
Prompts retrieved: 449280 . Total input tokens: 100180638 . Total output tokens: 89863988
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 175.55451748194173,
    "estimated_duration": 3600.071519206589,
    "input_throughput": 6910.059110570814,
    "output_throughput": 6152.803321218936,
    "total_throughput": 13062.862431789748,
    "itl": 106.38990100194897,
    "ttft": 1264906.6441860006,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 154,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.508714341484011,
    "arrivals": 149510,
    "finished_requests": 100796,
    "scheduler_time": 173.5932229236363
}
#Debug simulation 
Total elapsed time: 175.55472030024976. Arrivals time: 0.7777358791790903 Scheduler time: 174.42560549732298 Scheduler overhead time: 0.14484448777511716 Adapter cache time: 0.02661265665665269 Engine time: 0.13750744657590985 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_16-16-16/adapters_96_slots_32_rate_0.8-0.4-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_16-16-16/adapters_96_slots_32_rate_0.8-0.4-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 4320, 8640, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 8640, 4320, 4320, 1080, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 1080, 8640, 4320, 4320, 4320, 8640, 8640, 1080, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 1080, 1080, 8640, 4320, 8640, 1080, 4320, 8640, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 1080, 4320]
Prompts retrieved: 449280 . Total input tokens: 100180638 . Total output tokens: 89863988
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 174.66087412182242,
    "estimated_duration": 3600.0407536602343,
    "input_throughput": 6911.457870220621,
    "output_throughput": 6155.482539321115,
    "total_throughput": 13066.940409541736,
    "itl": 106.48461561873258,
    "ttft": 1274887.441898404,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 158,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.47242794659454435,
    "arrivals": 149510,
    "finished_requests": 100803,
    "scheduler_time": 173.4802609756533
}
#Debug simulation 
Total elapsed time: 174.66105208685622. Arrivals time: 0.7545096282847226 Scheduler time: 173.5682846303098 Scheduler overhead time: 0.13679672218859196 Adapter cache time: 0.025386384688317776 Engine time: 0.13397226762026548 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_16-16-32/adapters_96_slots_32_rate_0.8-0.4-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_16-16-32/adapters_96_slots_32_rate_0.8-0.4-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 4320, 8640, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 8640, 4320, 4320, 1080, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 1080, 8640, 4320, 4320, 4320, 8640, 8640, 1080, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 1080, 1080, 8640, 4320, 8640, 1080, 4320, 8640, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 1080, 4320]
Prompts retrieved: 449280 . Total input tokens: 100180638 . Total output tokens: 89863988
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 177.96626769425347,
    "estimated_duration": 3600.0781903495435,
    "input_throughput": 6910.046305851107,
    "output_throughput": 6152.791919735869,
    "total_throughput": 13062.838225586975,
    "itl": 106.38945990179059,
    "ttft": 1264909.827015032,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 154,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5150020308047532,
    "arrivals": 149510,
    "finished_requests": 100796,
    "scheduler_time": 173.59360637728415
}
#Debug simulation 
Total elapsed time: 177.966455954127. Arrivals time: 0.7757119494490325 Scheduler time: 176.84263958176598 Scheduler overhead time: 0.14289688086137176 Adapter cache time: 0.026939316652715206 Engine time: 0.1350927883759141 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-8/adapters_96_slots_32_rate_0.8-0.4-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-8/adapters_96_slots_32_rate_0.8-0.4-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 540, 8640, 4320, 540, 540, 4320, 8640, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 540, 8640, 4320, 4320, 540, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 540, 8640, 4320, 4320, 4320, 8640, 8640, 540, 540, 4320, 540, 8640, 540, 540, 8640, 540, 4320, 4320, 540, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 540, 540, 8640, 4320, 8640, 540, 4320, 8640, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 540, 540, 4320]
Prompts retrieved: 432000 . Total input tokens: 96291061 . Total output tokens: 86418789
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 129.40095774969086,
    "estimated_duration": 3600.0911003868273,
    "input_throughput": 7277.198067900276,
    "output_throughput": 6409.884738061346,
    "total_throughput": 13687.082805961621,
    "itl": 114.14079559210647,
    "ttft": 1152657.5319297526,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 238,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7283960830559945,
    "arrivals": 143761,
    "finished_requests": 105128,
    "scheduler_time": 160.9215772823114
}
#Debug simulation 
Total elapsed time: 129.40113109583035. Arrivals time: 0.6876131012104452 Scheduler time: 128.4379992634058 Scheduler overhead time: 0.11205071490257978 Adapter cache time: 0.02211650600656867 Engine time: 0.10524696949869394 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-16/adapters_96_slots_32_rate_0.8-0.4-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-16/adapters_96_slots_32_rate_0.8-0.4-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 540, 8640, 4320, 540, 540, 4320, 8640, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 540, 8640, 4320, 4320, 540, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 540, 8640, 4320, 4320, 4320, 8640, 8640, 540, 540, 4320, 540, 8640, 540, 540, 8640, 540, 4320, 4320, 540, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 540, 540, 8640, 4320, 8640, 540, 4320, 8640, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 540, 540, 4320]
Prompts retrieved: 432000 . Total input tokens: 96291061 . Total output tokens: 86418789
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 135.61221912596375,
    "estimated_duration": 3600.0586835090207,
    "input_throughput": 7244.821069021512,
    "output_throughput": 6384.267319108663,
    "total_throughput": 13629.088388130176,
    "itl": 114.07483086347384,
    "ttft": 1154098.1586972738,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 218,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7110772854625272,
    "arrivals": 143761,
    "finished_requests": 104783,
    "scheduler_time": 161.52651628165108
}
#Debug simulation 
Total elapsed time: 135.61238365620375. Arrivals time: 0.7126219933852553 Scheduler time: 134.61177762644365 Scheduler overhead time: 0.11759525537490845 Adapter cache time: 0.022267443127930164 Engine time: 0.11155177978798747 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-32/adapters_96_slots_32_rate_0.8-0.4-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-32/adapters_96_slots_32_rate_0.8-0.4-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 540, 8640, 4320, 540, 540, 4320, 8640, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 540, 8640, 4320, 4320, 540, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 540, 8640, 4320, 4320, 4320, 8640, 8640, 540, 540, 4320, 540, 8640, 540, 540, 8640, 540, 4320, 4320, 540, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 540, 540, 8640, 4320, 8640, 540, 4320, 8640, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 540, 540, 4320]
Prompts retrieved: 432000 . Total input tokens: 96291061 . Total output tokens: 86418789
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 134.5893992795609,
    "estimated_duration": 3600.060432629531,
    "input_throughput": 7244.81754906251,
    "output_throughput": 6384.264217257147,
    "total_throughput": 13629.081766319658,
    "itl": 114.07481504993302,
    "ttft": 1154099.215484321,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 218,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7123879957385393,
    "arrivals": 143761,
    "finished_requests": 104783,
    "scheduler_time": 161.5266419759837
}
#Debug simulation 
Total elapsed time: 134.58955530868843. Arrivals time: 0.7200847840867937 Scheduler time: 133.58413443062454 Scheduler overhead time: 0.11574661452323198 Adapter cache time: 0.02294841129332781 Engine time: 0.11036876169964671 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-16-16/adapters_96_slots_32_rate_0.8-0.4-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-16-16/adapters_96_slots_32_rate_0.8-0.4-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 540, 8640, 4320, 540, 540, 4320, 8640, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 540, 8640, 4320, 4320, 540, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 540, 8640, 4320, 4320, 4320, 8640, 8640, 540, 540, 4320, 540, 8640, 540, 540, 8640, 540, 4320, 4320, 540, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 540, 540, 8640, 4320, 8640, 540, 4320, 8640, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 540, 540, 4320]
Prompts retrieved: 432000 . Total input tokens: 96291061 . Total output tokens: 86418789
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 118.94729302683845,
    "estimated_duration": 3600.0850821104655,
    "input_throughput": 7289.37855674678,
    "output_throughput": 6406.6724741069,
    "total_throughput": 13696.051030853681,
    "itl": 114.45806025013557,
    "ttft": 1137464.21378562,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 221,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6918543593748488,
    "arrivals": 143761,
    "finished_requests": 105283,
    "scheduler_time": 160.54116848321206
}
#Debug simulation 
Total elapsed time: 118.94744580704719. Arrivals time: 0.7128917938098311 Scheduler time: 117.96198115451261 Scheduler overhead time: 0.11028179014101624 Adapter cache time: 0.022100217174738646 Engine time: 0.1049680057913065 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-16-32/adapters_96_slots_32_rate_0.8-0.4-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-16-32/adapters_96_slots_32_rate_0.8-0.4-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 540, 8640, 4320, 540, 540, 4320, 8640, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 540, 8640, 4320, 4320, 540, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 540, 8640, 4320, 4320, 4320, 8640, 8640, 540, 540, 4320, 540, 8640, 540, 540, 8640, 540, 4320, 4320, 540, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 540, 540, 8640, 4320, 8640, 540, 4320, 8640, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 540, 540, 4320]
Prompts retrieved: 432000 . Total input tokens: 96291061 . Total output tokens: 86418789
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 133.42179824784398,
    "estimated_duration": 3600.0789228238264,
    "input_throughput": 7247.530834555769,
    "output_throughput": 6383.768937480222,
    "total_throughput": 13631.29977203599,
    "itl": 114.07026772848111,
    "ttft": 1158018.1910904911,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 216,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7142177343927351,
    "arrivals": 143761,
    "finished_requests": 104806,
    "scheduler_time": 161.52645252806118
}
#Debug simulation 
Total elapsed time: 133.42198196984828. Arrivals time: 0.7023423374630511 Scheduler time: 132.4409968368709 Scheduler overhead time: 0.1117994706146419 Adapter cache time: 0.022335262969136238 Engine time: 0.10849154088646173 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_16-16-16/adapters_96_slots_32_rate_0.8-0.4-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_16-16-16/adapters_96_slots_32_rate_0.8-0.4-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 540, 8640, 4320, 540, 540, 4320, 8640, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 540, 8640, 4320, 4320, 540, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 540, 8640, 4320, 4320, 4320, 8640, 8640, 540, 540, 4320, 540, 8640, 540, 540, 8640, 540, 4320, 4320, 540, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 540, 540, 8640, 4320, 8640, 540, 4320, 8640, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 540, 540, 4320]
Prompts retrieved: 432000 . Total input tokens: 96291061 . Total output tokens: 86418789
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 140.12575765885413,
    "estimated_duration": 3600.087307744988,
    "input_throughput": 7216.951084520868,
    "output_throughput": 6359.474657946752,
    "total_throughput": 13576.42574246762,
    "itl": 112.8677147978753,
    "ttft": 1160711.6379104806,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 218,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6518309642886752,
    "arrivals": 143761,
    "finished_requests": 104423,
    "scheduler_time": 162.3871547906222
}
#Debug simulation 
Total elapsed time: 140.12592234881595. Arrivals time: 0.7014953279867768 Scheduler time: 139.1368849701248 Scheduler overhead time: 0.11587533541023731 Adapter cache time: 0.02333525987342 Engine time: 0.11058763833716512 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_16-16-32/adapters_96_slots_32_rate_0.8-0.4-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_16-16-32/adapters_96_slots_32_rate_0.8-0.4-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 540, 8640, 4320, 540, 540, 4320, 8640, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 540, 8640, 4320, 4320, 540, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 540, 8640, 4320, 4320, 4320, 8640, 8640, 540, 540, 4320, 540, 8640, 540, 540, 8640, 540, 4320, 4320, 540, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 540, 540, 8640, 4320, 8640, 540, 4320, 8640, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 540, 540, 4320]
Prompts retrieved: 432000 . Total input tokens: 96291061 . Total output tokens: 86418789
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 135.01763467490673,
    "estimated_duration": 3600.089635057643,
    "input_throughput": 7247.687320313685,
    "output_throughput": 6383.843828830672,
    "total_throughput": 13631.531149144355,
    "itl": 114.06869785656954,
    "ttft": 1157979.7022091185,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 215,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7201027343794726,
    "arrivals": 143761,
    "finished_requests": 104809,
    "scheduler_time": 161.52967196940563
}
#Debug simulation 
Total elapsed time: 135.01780265197158. Arrivals time: 0.6951415450312197 Scheduler time: 134.03859611740336 Scheduler overhead time: 0.11550408927723765 Adapter cache time: 0.022258074022829533 Engine time: 0.10941799217835069 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-8/adapters_96_slots_32_rate_0.8-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-8/adapters_96_slots_32_rate_0.8-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 270, 8640, 4320, 270, 270, 4320, 8640, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 270, 8640, 4320, 4320, 270, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 270, 8640, 4320, 4320, 4320, 8640, 8640, 270, 270, 4320, 270, 8640, 270, 270, 8640, 270, 4320, 4320, 270, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 270, 270, 8640, 4320, 8640, 270, 4320, 8640, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 270, 270, 4320]
Prompts retrieved: 423360 . Total input tokens: 94371362 . Total output tokens: 84676963
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 147.26579337427393,
    "estimated_duration": 3600.0440119269592,
    "input_throughput": 6911.104396938354,
    "output_throughput": 6089.81665984277,
    "total_throughput": 13000.921056781124,
    "itl": 103.52272738819093,
    "ttft": 1228105.4280160302,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 190,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5814926713472225,
    "arrivals": 140843,
    "finished_requests": 100197,
    "scheduler_time": 169.3072057271384
}
#Debug simulation 
Total elapsed time: 147.26596680888906. Arrivals time: 0.6890549180097878 Scheduler time: 146.26134244166315 Scheduler overhead time: 0.12727899989113212 Adapter cache time: 0.02401433140039444 Engine time: 0.1236649239435792 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-16/adapters_96_slots_32_rate_0.8-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-16/adapters_96_slots_32_rate_0.8-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 270, 8640, 4320, 270, 270, 4320, 8640, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 270, 8640, 4320, 4320, 270, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 270, 8640, 4320, 4320, 4320, 8640, 8640, 270, 270, 4320, 270, 8640, 270, 270, 8640, 270, 4320, 4320, 270, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 270, 270, 8640, 4320, 8640, 270, 4320, 8640, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 270, 270, 4320]
Prompts retrieved: 423360 . Total input tokens: 94371362 . Total output tokens: 84676963
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 148.50569824920967,
    "estimated_duration": 3600.0516467474476,
    "input_throughput": 6925.948415914258,
    "output_throughput": 6104.218815820126,
    "total_throughput": 13030.167231734384,
    "itl": 104.09875416585928,
    "ttft": 1229964.0351880232,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 190,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6208183521102193,
    "arrivals": 140843,
    "finished_requests": 100423,
    "scheduler_time": 168.82497978880886
}
#Debug simulation 
Total elapsed time: 148.5058704521507. Arrivals time: 0.6837369399145246 Scheduler time: 147.50824753101915 Scheduler overhead time: 0.12771692033857107 Adapter cache time: 0.024503799621015787 Engine time: 0.12171027669683099 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-32/adapters_96_slots_32_rate_0.8-0.4-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-32/adapters_96_slots_32_rate_0.8-0.4-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 270, 8640, 4320, 270, 270, 4320, 8640, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 270, 8640, 4320, 4320, 270, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 270, 8640, 4320, 4320, 4320, 8640, 8640, 270, 270, 4320, 270, 8640, 270, 270, 8640, 270, 4320, 4320, 270, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 270, 270, 8640, 4320, 8640, 270, 4320, 8640, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 270, 270, 4320]
Prompts retrieved: 423360 . Total input tokens: 94371362 . Total output tokens: 84676963
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 145.8964144536294,
    "estimated_duration": 3600.0528080938843,
    "input_throughput": 6925.946181662167,
    "output_throughput": 6104.21684665102,
    "total_throughput": 13030.163028313187,
    "itl": 104.09868581680145,
    "ttft": 1229964.5415006767,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 190,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6217735080607261,
    "arrivals": 140843,
    "finished_requests": 100423,
    "scheduler_time": 168.82507287425548
}
#Debug simulation 
Total elapsed time: 145.89657836966217. Arrivals time: 0.702190529089421 Scheduler time: 144.88539991993457 Scheduler overhead time: 0.1260066833347082 Adapter cache time: 0.024135096929967403 Engine time: 0.11876279395073652 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-16-16/adapters_96_slots_32_rate_0.8-0.4-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-16-16/adapters_96_slots_32_rate_0.8-0.4-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 270, 8640, 4320, 270, 270, 4320, 8640, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 270, 8640, 4320, 4320, 270, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 270, 8640, 4320, 4320, 4320, 8640, 8640, 270, 270, 4320, 270, 8640, 270, 270, 8640, 270, 4320, 4320, 270, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 270, 270, 8640, 4320, 8640, 270, 4320, 8640, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 270, 270, 4320]
Prompts retrieved: 423360 . Total input tokens: 94371362 . Total output tokens: 84676963
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 146.99648945685476,
    "estimated_duration": 3600.0841348995277,
    "input_throughput": 6926.317293052904,
    "output_throughput": 6103.73485080044,
    "total_throughput": 13030.052143853343,
    "itl": 104.08116686780563,
    "ttft": 1229754.1460174024,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 189,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5908610107982538,
    "arrivals": 140843,
    "finished_requests": 100429,
    "scheduler_time": 168.83196471853444
}
#Debug simulation 
Total elapsed time: 146.99665794195607. Arrivals time: 0.6841401271522045 Scheduler time: 145.99885748699307 Scheduler overhead time: 0.1277423412539065 Adapter cache time: 0.02404611697420478 Engine time: 0.12204770697280765 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-16-32/adapters_96_slots_32_rate_0.8-0.4-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-16-32/adapters_96_slots_32_rate_0.8-0.4-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 270, 8640, 4320, 270, 270, 4320, 8640, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 270, 8640, 4320, 4320, 270, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 270, 8640, 4320, 4320, 4320, 8640, 8640, 270, 270, 4320, 270, 8640, 270, 270, 8640, 270, 4320, 4320, 270, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 270, 270, 8640, 4320, 8640, 270, 4320, 8640, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 270, 270, 4320]
Prompts retrieved: 423360 . Total input tokens: 94371362 . Total output tokens: 84676963
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 146.27881182078272,
    "estimated_duration": 3600.0594436158053,
    "input_throughput": 6925.933415965258,
    "output_throughput": 6104.205595541051,
    "total_throughput": 13030.139011506308,
    "itl": 104.09857816194926,
    "ttft": 1229966.968501813,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 190,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6299475041776912,
    "arrivals": 140843,
    "finished_requests": 100423,
    "scheduler_time": 168.8252923605358
}
#Debug simulation 
Total elapsed time: 146.27897406974807. Arrivals time: 0.6946037048473954 Scheduler time: 145.27010051393881 Scheduler overhead time: 0.12822476495057344 Adapter cache time: 0.02482195384800434 Engine time: 0.12152755679562688 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_16-16-16/adapters_96_slots_32_rate_0.8-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_16-16-16/adapters_96_slots_32_rate_0.8-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 270, 8640, 4320, 270, 270, 4320, 8640, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 270, 8640, 4320, 4320, 270, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 270, 8640, 4320, 4320, 4320, 8640, 8640, 270, 270, 4320, 270, 8640, 270, 270, 8640, 270, 4320, 4320, 270, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 270, 270, 8640, 4320, 8640, 270, 4320, 8640, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 270, 270, 4320]
Prompts retrieved: 423360 . Total input tokens: 94371362 . Total output tokens: 84676963
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 149.72920212009922,
    "estimated_duration": 3600.0975516662893,
    "input_throughput": 6917.93476220463,
    "output_throughput": 6092.167138595643,
    "total_throughput": 13010.101900800273,
    "itl": 103.5498470266448,
    "ttft": 1221954.6211353093,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 177,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5292389021976858,
    "arrivals": 140843,
    "finished_requests": 100243,
    "scheduler_time": 169.26614606352632
}
#Debug simulation 
Total elapsed time: 149.72937773307785. Arrivals time: 0.7117097158916295 Scheduler time: 148.70163342915475 Scheduler overhead time: 0.12951339315623045 Adapter cache time: 0.024322922807186842 Engine time: 0.12129274010658264 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_16-16-32/adapters_96_slots_32_rate_0.8-0.4-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_16-16-32/adapters_96_slots_32_rate_0.8-0.4-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 270, 8640, 4320, 270, 270, 4320, 8640, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 270, 8640, 4320, 4320, 270, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 270, 8640, 4320, 4320, 4320, 8640, 8640, 270, 270, 4320, 270, 8640, 270, 270, 8640, 270, 4320, 4320, 270, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 270, 270, 8640, 4320, 8640, 270, 4320, 8640, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 270, 270, 4320]
Prompts retrieved: 423360 . Total input tokens: 94371362 . Total output tokens: 84676963
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 146.4936621496454,
    "estimated_duration": 3600.0675683792556,
    "input_throughput": 6925.917785266775,
    "output_throughput": 6104.191819347806,
    "total_throughput": 13030.109604614581,
    "itl": 104.09876513911189,
    "ttft": 1229969.939747566,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 190,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6379957465082415,
    "arrivals": 140843,
    "finished_requests": 100423,
    "scheduler_time": 168.82548688661433
}
#Debug simulation 
Total elapsed time: 146.49384206579998. Arrivals time: 0.6848310977220535 Scheduler time: 145.49577455129474 Scheduler overhead time: 0.12668418884277344 Adapter cache time: 0.02415827428922057 Engine time: 0.12102032173424959 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-8/adapters_96_slots_32_rate_0.8-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-8/adapters_96_slots_32_rate_0.8-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 135, 8640, 4320, 135, 135, 4320, 8640, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 135, 8640, 4320, 4320, 135, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 135, 8640, 4320, 4320, 4320, 8640, 8640, 135, 135, 4320, 135, 8640, 135, 135, 8640, 135, 4320, 4320, 135, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 135, 135, 8640, 4320, 8640, 135, 4320, 8640, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 135, 135, 4320]
Prompts retrieved: 419040 . Total input tokens: 93435824 . Total output tokens: 83813115
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 176.62393498094752,
    "estimated_duration": 3600.0885854550866,
    "input_throughput": 6827.798376770432,
    "output_throughput": 5978.035120288429,
    "total_throughput": 12805.83349705886,
    "itl": 100.22251628846979,
    "ttft": 1247801.5175158714,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 199,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6090370610426172,
    "arrivals": 139377,
    "finished_requests": 98630,
    "scheduler_time": 172.27334393457727
}
#Debug simulation 
Total elapsed time: 176.62410927703604. Arrivals time: 0.7071120222099125 Scheduler time: 175.57895691646263 Scheduler overhead time: 0.13853200245648623 Adapter cache time: 0.02564111491665244 Engine time: 0.1301610409282148 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-16/adapters_96_slots_32_rate_0.8-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-16/adapters_96_slots_32_rate_0.8-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 135, 8640, 4320, 135, 135, 4320, 8640, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 135, 8640, 4320, 4320, 135, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 135, 8640, 4320, 4320, 4320, 8640, 8640, 135, 135, 4320, 135, 8640, 135, 135, 8640, 135, 4320, 4320, 135, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 135, 135, 8640, 4320, 8640, 135, 4320, 8640, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 135, 135, 4320]
Prompts retrieved: 419040 . Total input tokens: 93435824 . Total output tokens: 83813115
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 176.4913464221172,
    "estimated_duration": 3600.133721243798,
    "input_throughput": 6827.712774932067,
    "output_throughput": 5977.960172147335,
    "total_throughput": 12805.672947079402,
    "itl": 100.22403690147829,
    "ttft": 1247816.9019987546,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 199,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6509975673118624,
    "arrivals": 139377,
    "finished_requests": 98630,
    "scheduler_time": 172.27492567587063
}
#Debug simulation 
Total elapsed time: 176.4915218600072. Arrivals time: 0.7032924625091255 Scheduler time: 175.44643266266212 Scheduler overhead time: 0.13840969232842326 Adapter cache time: 0.02673979103565216 Engine time: 0.13270545145496726 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-32/adapters_96_slots_32_rate_0.8-0.4-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-32/adapters_96_slots_32_rate_0.8-0.4-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 135, 8640, 4320, 135, 135, 4320, 8640, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 135, 8640, 4320, 4320, 135, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 135, 8640, 4320, 4320, 4320, 8640, 8640, 135, 135, 4320, 135, 8640, 135, 135, 8640, 135, 4320, 4320, 135, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 135, 135, 8640, 4320, 8640, 135, 4320, 8640, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 135, 135, 4320]
Prompts retrieved: 419040 . Total input tokens: 93435824 . Total output tokens: 83813115
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 177.3255896558985,
    "estimated_duration": 3600.1350009471334,
    "input_throughput": 6827.71034795452,
    "output_throughput": 5977.958047222694,
    "total_throughput": 12805.668395177216,
    "itl": 100.22405387587843,
    "ttft": 1247817.5283255286,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 199,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6518631576560465,
    "arrivals": 139377,
    "finished_requests": 98630,
    "scheduler_time": 172.27501109025167
}
#Debug simulation 
Total elapsed time: 177.3257596520707. Arrivals time: 0.6971533801406622 Scheduler time: 176.2832961184904 Scheduler overhead time: 0.1403660075739026 Adapter cache time: 0.02621070109307766 Engine time: 0.13410747237503529 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-16/adapters_96_slots_32_rate_0.8-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-16/adapters_96_slots_32_rate_0.8-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 135, 8640, 4320, 135, 135, 4320, 8640, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 135, 8640, 4320, 4320, 135, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 135, 8640, 4320, 4320, 4320, 8640, 8640, 135, 135, 4320, 135, 8640, 135, 135, 8640, 135, 4320, 4320, 135, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 135, 135, 8640, 4320, 8640, 135, 4320, 8640, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 135, 135, 4320]
Prompts retrieved: 419040 . Total input tokens: 93435824 . Total output tokens: 83813115
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 176.7593086650595,
    "estimated_duration": 3600.1042331467934,
    "input_throughput": 6827.768700050782,
    "output_throughput": 5978.009137026691,
    "total_throughput": 12805.777837077474,
    "itl": 100.22269465262617,
    "ttft": 1247806.378354165,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 199,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6236216809763585,
    "arrivals": 139377,
    "finished_requests": 98630,
    "scheduler_time": 172.27389544827935
}
#Debug simulation 
Total elapsed time: 176.75952956592664. Arrivals time: 0.7097419272176921 Scheduler time: 175.7060050885193 Scheduler overhead time: 0.14132191240787506 Adapter cache time: 0.02641718601807952 Engine time: 0.13184289960190654 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-32/adapters_96_slots_32_rate_0.8-0.4-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-32/adapters_96_slots_32_rate_0.8-0.4-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 135, 8640, 4320, 135, 135, 4320, 8640, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 135, 8640, 4320, 4320, 135, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 135, 8640, 4320, 4320, 4320, 8640, 8640, 135, 135, 4320, 135, 8640, 135, 135, 8640, 135, 4320, 4320, 135, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 135, 135, 8640, 4320, 8640, 135, 4320, 8640, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 135, 135, 4320]
Prompts retrieved: 419040 . Total input tokens: 93435824 . Total output tokens: 83813115
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 175.76377962063998,
    "estimated_duration": 3600.0065943286327,
    "input_throughput": 6827.95388173006,
    "output_throughput": 5978.1712716594475,
    "total_throughput": 12806.125153389508,
    "itl": 100.22562602077727,
    "ttft": 1247745.0957636074,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 199,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6602886613458414,
    "arrivals": 139377,
    "finished_requests": 98630,
    "scheduler_time": 172.26830622196712
}
#Debug simulation 
Total elapsed time: 175.76396016590297. Arrivals time: 0.7124457326717675 Scheduler time: 174.7097285897471 Scheduler overhead time: 0.13896266696974635 Adapter cache time: 0.02711201086640358 Engine time: 0.13165453355759382 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-16/adapters_96_slots_32_rate_0.8-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-16/adapters_96_slots_32_rate_0.8-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 135, 8640, 4320, 135, 135, 4320, 8640, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 135, 8640, 4320, 4320, 135, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 135, 8640, 4320, 4320, 4320, 8640, 8640, 135, 135, 4320, 135, 8640, 135, 135, 8640, 135, 4320, 4320, 135, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 135, 135, 8640, 4320, 8640, 135, 4320, 8640, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 135, 135, 4320]
Prompts retrieved: 419040 . Total input tokens: 93435824 . Total output tokens: 83813115
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 177.14790684822947,
    "estimated_duration": 3600.0308448353453,
    "input_throughput": 6836.011984537755,
    "output_throughput": 5986.045378171095,
    "total_throughput": 12822.05736270885,
    "itl": 100.37945245816114,
    "ttft": 1247731.9644762266,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 206,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.615950360749849,
    "arrivals": 139377,
    "finished_requests": 98766,
    "scheduler_time": 171.94605781150707
}
#Debug simulation 
Total elapsed time: 177.14807419711724. Arrivals time: 0.7098919413983822 Scheduler time: 176.09694056864828 Scheduler overhead time: 0.140350051689893 Adapter cache time: 0.026276446878910065 Engine time: 0.13071103999391198 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-32/adapters_96_slots_32_rate_0.8-0.4-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-32/adapters_96_slots_32_rate_0.8-0.4-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 135, 8640, 4320, 135, 135, 4320, 8640, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 135, 8640, 4320, 4320, 135, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 135, 8640, 4320, 4320, 4320, 8640, 8640, 135, 135, 4320, 135, 8640, 135, 135, 8640, 135, 4320, 4320, 135, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 135, 135, 8640, 4320, 8640, 135, 4320, 8640, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 135, 135, 4320]
Prompts retrieved: 419040 . Total input tokens: 93435824 . Total output tokens: 83813115
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 178.19835383910686,
    "estimated_duration": 3600.051133412212,
    "input_throughput": 6827.80801968834,
    "output_throughput": 5978.192309618986,
    "total_throughput": 12806.000329307326,
    "itl": 100.22593511198933,
    "ttft": 1247738.066079544,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 199,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6690914263948814,
    "arrivals": 139377,
    "finished_requests": 98629,
    "scheduler_time": 172.26972645261813
}
#Debug simulation 
Total elapsed time: 178.19849964324385. Arrivals time: 0.6884442288428545 Scheduler time: 177.1667678016238 Scheduler overhead time: 0.14026160538196564 Adapter cache time: 0.02629343094304204 Engine time: 0.1322629153728485 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-8/adapters_96_slots_32_rate_0.8-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-8/adapters_96_slots_32_rate_0.8-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 66, 8640, 66, 66, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 66, 8640, 4320, 66, 66, 4320, 8640, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 66, 8640, 4320, 4320, 66, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 66, 8640, 4320, 4320, 4320, 8640, 8640, 66, 66, 4320, 66, 8640, 66, 66, 8640, 66, 4320, 4320, 66, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 66, 66, 8640, 4320, 8640, 66, 4320, 8640, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 66, 66, 4320]
Prompts retrieved: 416832 . Total input tokens: 92923418 . Total output tokens: 83384390
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 135.49754152307287,
    "estimated_duration": 3600.050964551365,
    "input_throughput": 7015.733735077138,
    "output_throughput": 6202.758855327143,
    "total_throughput": 13218.492590404281,
    "itl": 105.33790089370622,
    "ttft": 1164910.7168693836,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 205,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6273999875062137,
    "arrivals": 138774,
    "finished_requests": 102059,
    "scheduler_time": 163.36836489887565
}
#Debug simulation 
Total elapsed time: 135.4977500261739. Arrivals time: 0.682988784275949 Scheduler time: 134.51002759067342 Scheduler overhead time: 0.12354048760607839 Adapter cache time: 0.02324155531823635 Engine time: 0.1176648335531354 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-16/adapters_96_slots_32_rate_0.8-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-16/adapters_96_slots_32_rate_0.8-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 66, 8640, 66, 66, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 66, 8640, 4320, 66, 66, 4320, 8640, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 66, 8640, 4320, 4320, 66, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 66, 8640, 4320, 4320, 4320, 8640, 8640, 66, 66, 4320, 66, 8640, 66, 66, 8640, 66, 4320, 4320, 66, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 66, 66, 8640, 4320, 8640, 66, 4320, 8640, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 66, 66, 4320]
Prompts retrieved: 416832 . Total input tokens: 92923418 . Total output tokens: 83384390
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 134.99761883122846,
    "estimated_duration": 3600.0095590098535,
    "input_throughput": 7012.499990956525,
    "output_throughput": 6204.927135288993,
    "total_throughput": 13217.427126245517,
    "itl": 105.56965251904053,
    "ttft": 1161475.3285740016,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 222,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7275320351449799,
    "arrivals": 138774,
    "finished_requests": 102130,
    "scheduler_time": 163.26394438575008
}
#Debug simulation 
Total elapsed time: 134.9977761954069. Arrivals time: 0.7014285423792899 Scheduler time: 133.99104647850618 Scheduler overhead time: 0.12305369228124619 Adapter cache time: 0.023814224172383547 Engine time: 0.11962477769702673 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-32/adapters_96_slots_32_rate_0.8-0.4-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-32/adapters_96_slots_32_rate_0.8-0.4-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 66, 8640, 66, 66, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 66, 8640, 4320, 66, 66, 4320, 8640, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 66, 8640, 4320, 4320, 66, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 66, 8640, 4320, 4320, 4320, 8640, 8640, 66, 66, 4320, 66, 8640, 66, 66, 8640, 66, 4320, 4320, 66, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 66, 66, 8640, 4320, 8640, 66, 4320, 8640, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 66, 66, 4320]
Prompts retrieved: 416832 . Total input tokens: 92923418 . Total output tokens: 83384390
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 126.84730553999543,
    "estimated_duration": 3600.010218037847,
    "input_throughput": 7012.498707228558,
    "output_throughput": 6204.925999397583,
    "total_throughput": 13217.42470662614,
    "itl": 105.56966040005058,
    "ttft": 1161475.5735903862,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 222,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7282717935740981,
    "arrivals": 138774,
    "finished_requests": 102130,
    "scheduler_time": 163.2639996946356
}
#Debug simulation 
Total elapsed time: 126.84748257184401. Arrivals time: 0.6319439942017198 Scheduler time: 125.92638363223523 Scheduler overhead time: 0.11651675775647163 Adapter cache time: 0.022036558482795954 Engine time: 0.11265335232019424 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-16/adapters_96_slots_32_rate_0.8-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-16/adapters_96_slots_32_rate_0.8-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 66, 8640, 66, 66, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 66, 8640, 4320, 66, 66, 4320, 8640, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 66, 8640, 4320, 4320, 66, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 66, 8640, 4320, 4320, 4320, 8640, 8640, 66, 66, 4320, 66, 8640, 66, 66, 8640, 66, 4320, 4320, 66, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 66, 66, 8640, 4320, 8640, 66, 4320, 8640, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 66, 66, 4320]
Prompts retrieved: 416832 . Total input tokens: 92923418 . Total output tokens: 83384390
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 129.46589589491487,
    "estimated_duration": 3600.0419048681583,
    "input_throughput": 7055.619815328296,
    "output_throughput": 6243.607600679628,
    "total_throughput": 13299.227416007923,
    "itl": 107.23429997940772,
    "ttft": 1136584.6197965094,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 191,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5980668973433794,
    "arrivals": 138774,
    "finished_requests": 102799,
    "scheduler_time": 161.6920959459871
}
#Debug simulation 
Total elapsed time: 129.4660750287585. Arrivals time: 0.6799143776297569 Scheduler time: 128.4904586612247 Scheduler overhead time: 0.11934702610597014 Adapter cache time: 0.02357284352183342 Engine time: 0.11464321101084352 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-32/adapters_96_slots_32_rate_0.8-0.4-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-32/adapters_96_slots_32_rate_0.8-0.4-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 66, 8640, 66, 66, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 66, 8640, 4320, 66, 66, 4320, 8640, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 66, 8640, 4320, 4320, 66, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 66, 8640, 4320, 4320, 4320, 8640, 8640, 66, 66, 4320, 66, 8640, 66, 66, 8640, 66, 4320, 4320, 66, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 66, 66, 8640, 4320, 8640, 66, 4320, 8640, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 66, 66, 4320]
Prompts retrieved: 416832 . Total input tokens: 92923418 . Total output tokens: 83384390
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 142.73440641118214,
    "estimated_duration": 3600.05130269718,
    "input_throughput": 7011.223695920519,
    "output_throughput": 6203.877145658182,
    "total_throughput": 13215.100841578702,
    "itl": 105.56670363560517,
    "ttft": 1153870.6675373737,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 216,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7180074845626975,
    "arrivals": 138774,
    "finished_requests": 102148,
    "scheduler_time": 163.25296334344208
}
#Debug simulation 
Total elapsed time: 142.73456411017105. Arrivals time: 0.6867239736020565 Scheduler time: 141.72905002068728 Scheduler overhead time: 0.1291255010291934 Adapter cache time: 0.025183733087033033 Engine time: 0.12278526509180665 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-16/adapters_96_slots_32_rate_0.8-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-16/adapters_96_slots_32_rate_0.8-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 66, 8640, 66, 66, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 66, 8640, 4320, 66, 66, 4320, 8640, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 66, 8640, 4320, 4320, 66, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 66, 8640, 4320, 4320, 4320, 8640, 8640, 66, 66, 4320, 66, 8640, 66, 66, 8640, 66, 4320, 4320, 66, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 66, 66, 8640, 4320, 8640, 66, 4320, 8640, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 66, 66, 4320]
Prompts retrieved: 416832 . Total input tokens: 92923418 . Total output tokens: 83384390
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 135.86160956555977,
    "estimated_duration": 3600.137551428507,
    "input_throughput": 7014.515873144824,
    "output_throughput": 6201.770815990275,
    "total_throughput": 13216.286689135099,
    "itl": 105.34673692697913,
    "ttft": 1165387.7370616675,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 205,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6129603104549468,
    "arrivals": 138774,
    "finished_requests": 102037,
    "scheduler_time": 163.36955344707147
}
#Debug simulation 
Total elapsed time: 135.86176893580705. Arrivals time: 0.6815333571285009 Scheduler time: 134.86913824127987 Scheduler overhead time: 0.12682765442878008 Adapter cache time: 0.02418331243097782 Engine time: 0.1195857529528439 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-32/adapters_96_slots_32_rate_0.8-0.4-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-32/adapters_96_slots_32_rate_0.8-0.4-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 66, 8640, 66, 66, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 66, 8640, 4320, 66, 66, 4320, 8640, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 66, 8640, 4320, 4320, 66, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 66, 8640, 4320, 4320, 4320, 8640, 8640, 66, 66, 4320, 66, 8640, 66, 66, 8640, 66, 4320, 4320, 66, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 66, 66, 8640, 4320, 8640, 66, 4320, 8640, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 66, 66, 4320]
Prompts retrieved: 416832 . Total input tokens: 92923418 . Total output tokens: 83384390
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 140.2919746101834,
    "estimated_duration": 3600.0625781446406,
    "input_throughput": 7011.201736667672,
    "output_throughput": 6203.857715026272,
    "total_throughput": 13215.059451693944,
    "itl": 105.56673344902961,
    "ttft": 1153875.210879412,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 216,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7273132647573969,
    "arrivals": 138774,
    "finished_requests": 102148,
    "scheduler_time": 163.25346264531163
}
#Debug simulation 
Total elapsed time: 140.29217083519325. Arrivals time: 0.7277007829397917 Scheduler time: 139.25377676216885 Scheduler overhead time: 0.1266425922513008 Adapter cache time: 0.02510116435587406 Engine time: 0.11917509092018008 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-8/adapters_96_slots_32_rate_0.8-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-8/adapters_96_slots_32_rate_0.8-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 33, 8640, 33, 33, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 33, 8640, 4320, 33, 33, 4320, 8640, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 33, 8640, 4320, 4320, 33, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 33, 8640, 4320, 4320, 4320, 8640, 8640, 33, 33, 4320, 33, 8640, 33, 33, 8640, 33, 4320, 4320, 33, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 33, 33, 8640, 4320, 8640, 33, 4320, 8640, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 33, 33, 4320]
Prompts retrieved: 415776 . Total input tokens: 92702535 . Total output tokens: 83169576
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 121.50828095059842,
    "estimated_duration": 3600.0920582216604,
    "input_throughput": 7138.842725231667,
    "output_throughput": 6300.989150595582,
    "total_throughput": 13439.831875827249,
    "itl": 109.00979476443757,
    "ttft": 1113239.3189880864,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 261,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7987873011664477,
    "arrivals": 138381,
    "finished_requests": 103555,
    "scheduler_time": 159.22877709027085
}
#Debug simulation 
Total elapsed time: 121.50845388881862. Arrivals time: 0.6679362426511943 Scheduler time: 120.551161469426 Scheduler overhead time: 0.11710903281345963 Adapter cache time: 0.023265807889401913 Engine time: 0.11114344000816345 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-16/adapters_96_slots_32_rate_0.8-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-16/adapters_96_slots_32_rate_0.8-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 33, 8640, 33, 33, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 33, 8640, 4320, 33, 33, 4320, 8640, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 33, 8640, 4320, 4320, 33, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 33, 8640, 4320, 4320, 4320, 8640, 8640, 33, 33, 4320, 33, 8640, 33, 33, 8640, 33, 4320, 4320, 33, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 33, 33, 8640, 4320, 8640, 33, 4320, 8640, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 33, 33, 4320]
Prompts retrieved: 415776 . Total input tokens: 92702535 . Total output tokens: 83169576
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 121.0680157491006,
    "estimated_duration": 3600.0299538906356,
    "input_throughput": 7133.12592642392,
    "output_throughput": 6301.223126069892,
    "total_throughput": 13434.349052493812,
    "itl": 109.05023993106701,
    "ttft": 1115184.8724500474,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 275,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9043914901046135,
    "arrivals": 138381,
    "finished_requests": 103523,
    "scheduler_time": 159.19685646182086
}
#Debug simulation 
Total elapsed time: 121.06817352585495. Arrivals time: 0.6694642975926399 Scheduler time: 120.1123585109599 Scheduler overhead time: 0.11537925293669105 Adapter cache time: 0.023727824445813894 Engine time: 0.10961920721456409 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-32/adapters_96_slots_32_rate_0.8-0.4-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-32/adapters_96_slots_32_rate_0.8-0.4-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 33, 8640, 33, 33, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 33, 8640, 4320, 33, 33, 4320, 8640, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 33, 8640, 4320, 4320, 33, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 33, 8640, 4320, 4320, 4320, 8640, 8640, 33, 33, 4320, 33, 8640, 33, 33, 8640, 33, 4320, 4320, 33, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 33, 33, 8640, 4320, 8640, 33, 4320, 8640, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 33, 33, 4320]
Prompts retrieved: 415776 . Total input tokens: 92702535 . Total output tokens: 83169576
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 122.18119464581832,
    "estimated_duration": 3600.0321159881896,
    "input_throughput": 7133.1216424304375,
    "output_throughput": 6301.219341698345,
    "total_throughput": 13434.340984128783,
    "itl": 109.05022177537771,
    "ttft": 1115186.0974102488,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 275,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9047544298134791,
    "arrivals": 138381,
    "finished_requests": 103523,
    "scheduler_time": 159.19711059992795
}
#Debug simulation 
Total elapsed time: 122.18134946702048. Arrivals time: 0.6434457316063344 Scheduler time: 121.25083007477224 Scheduler overhead time: 0.11617811303585768 Adapter cache time: 0.02307034283876419 Engine time: 0.11102182418107986 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-16/adapters_96_slots_32_rate_0.8-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-16/adapters_96_slots_32_rate_0.8-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 33, 8640, 33, 33, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 33, 8640, 4320, 33, 33, 4320, 8640, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 33, 8640, 4320, 4320, 33, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 33, 8640, 4320, 4320, 4320, 8640, 8640, 33, 33, 4320, 33, 8640, 33, 33, 8640, 33, 4320, 4320, 33, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 33, 33, 8640, 4320, 8640, 33, 4320, 8640, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 33, 33, 4320]
Prompts retrieved: 415776 . Total input tokens: 92702535 . Total output tokens: 83169576
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 122.56622841069475,
    "estimated_duration": 3600.120078869895,
    "input_throughput": 7138.787161806997,
    "output_throughput": 6300.940108397918,
    "total_throughput": 13439.727270204916,
    "itl": 109.01035991295899,
    "ttft": 1113328.5998357218,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 261,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8192196822213031,
    "arrivals": 138381,
    "finished_requests": 103555,
    "scheduler_time": 159.23034658211623
}
#Debug simulation 
Total elapsed time: 122.56639801664278. Arrivals time: 0.6660465733148158 Scheduler time: 121.6057953927666 Scheduler overhead time: 0.11916242772713304 Adapter cache time: 0.022762923501431942 Engine time: 0.11482154950499535 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-32/adapters_96_slots_32_rate_0.8-0.4-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-32/adapters_96_slots_32_rate_0.8-0.4-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 33, 8640, 33, 33, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 33, 8640, 4320, 33, 33, 4320, 8640, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 33, 8640, 4320, 4320, 33, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 33, 8640, 4320, 4320, 4320, 8640, 8640, 33, 33, 4320, 33, 8640, 33, 33, 8640, 33, 4320, 4320, 33, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 33, 33, 8640, 4320, 8640, 33, 4320, 8640, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 33, 33, 4320]
Prompts retrieved: 415776 . Total input tokens: 92702535 . Total output tokens: 83169576
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 120.53342531668022,
    "estimated_duration": 3600.118211041675,
    "input_throughput": 7138.790865582078,
    "output_throughput": 6300.943377477726,
    "total_throughput": 13439.734243059804,
    "itl": 109.01323349526862,
    "ttft": 1113234.6574583093,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 262,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8738885733299003,
    "arrivals": 138381,
    "finished_requests": 103555,
    "scheduler_time": 159.2274288239733
}
#Debug simulation 
Total elapsed time: 120.53359126579016. Arrivals time: 0.6696707648225129 Scheduler time: 119.5730094765313 Scheduler overhead time: 0.11645735334604979 Adapter cache time: 0.023015276063233614 Engine time: 0.11211245600134134 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-16/adapters_96_slots_32_rate_0.8-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-16/adapters_96_slots_32_rate_0.8-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 33, 8640, 33, 33, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 33, 8640, 4320, 33, 33, 4320, 8640, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 33, 8640, 4320, 4320, 33, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 33, 8640, 4320, 4320, 4320, 8640, 8640, 33, 33, 4320, 33, 8640, 33, 33, 8640, 33, 4320, 4320, 33, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 33, 33, 8640, 4320, 8640, 33, 4320, 8640, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 33, 33, 4320]
Prompts retrieved: 415776 . Total input tokens: 92702535 . Total output tokens: 83169576
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 121.58090889500454,
    "estimated_duration": 3600.053602706528,
    "input_throughput": 7138.8942599850125,
    "output_throughput": 6301.001458130002,
    "total_throughput": 13439.895718115014,
    "itl": 109.00721987106584,
    "ttft": 1113291.737327691,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 261,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7804031269694689,
    "arrivals": 138381,
    "finished_requests": 103554,
    "scheduler_time": 159.2287531376302
}
#Debug simulation 
Total elapsed time: 121.58107329206541. Arrivals time: 0.6692927735857666 Scheduler time: 120.62428279500455 Scheduler overhead time: 0.11537122260779142 Adapter cache time: 0.023112837690860033 Engine time: 0.11154447169974446 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-32/adapters_96_slots_32_rate_0.8-0.4-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-32/adapters_96_slots_32_rate_0.8-0.4-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 33, 8640, 33, 33, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 33, 8640, 4320, 33, 33, 4320, 8640, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 33, 8640, 4320, 4320, 33, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 33, 8640, 4320, 4320, 4320, 8640, 8640, 33, 33, 4320, 33, 8640, 33, 33, 8640, 33, 4320, 4320, 33, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 33, 33, 8640, 4320, 8640, 33, 4320, 8640, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 33, 33, 4320]
Prompts retrieved: 415776 . Total input tokens: 92702535 . Total output tokens: 83169576
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 122.40856775734574,
    "estimated_duration": 3600.125005689083,
    "input_throughput": 7138.777392281352,
    "output_throughput": 6300.931485477165,
    "total_throughput": 13439.708877758516,
    "itl": 109.01314943826628,
    "ttft": 1113247.4465064725,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 261,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8827916641905946,
    "arrivals": 138381,
    "finished_requests": 103555,
    "scheduler_time": 159.2282537614864
}
#Debug simulation 
Total elapsed time: 122.40874129440635. Arrivals time: 0.647643028292805 Scheduler time: 121.47130461316556 Scheduler overhead time: 0.11738864285871387 Adapter cache time: 0.023117722012102604 Engine time: 0.11201001051813364 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-8/adapters_96_slots_32_rate_0.8-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-8/adapters_96_slots_32_rate_0.8-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 540, 8640, 540, 540, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 540, 8640, 1080, 540, 540, 1080, 8640, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 8640, 1080, 1080, 540, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 540, 8640, 1080, 1080, 1080, 8640, 8640, 540, 540, 1080, 540, 8640, 540, 540, 8640, 540, 1080, 1080, 540, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 540, 540, 8640, 1080, 8640, 540, 1080, 8640, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 540, 540, 1080]
Prompts retrieved: 328320 . Total input tokens: 73232281 . Total output tokens: 65736162
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 197.31652831379324,
    "estimated_duration": 3600.0573192916513,
    "input_throughput": 6354.802152011684,
    "output_throughput": 5678.374866548588,
    "total_throughput": 12033.177018560273,
    "itl": 70.98488711201779,
    "ttft": 562819.2623291014,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 76,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23259706853888906,
    "arrivals": 109384,
    "finished_requests": 92437,
    "scheduler_time": 125.95361140856278
}
#Debug simulation 
Total elapsed time: 197.31670308485627. Arrivals time: 0.6698200297541916 Scheduler time: 196.23033141484484 Scheduler overhead time: 0.1717010522261262 Adapter cache time: 0.02944895252585411 Engine time: 0.16362005611881614 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-16/adapters_96_slots_32_rate_0.8-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-16/adapters_96_slots_32_rate_0.8-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 540, 8640, 540, 540, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 540, 8640, 1080, 540, 540, 1080, 8640, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 8640, 1080, 1080, 540, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 540, 8640, 1080, 1080, 1080, 8640, 8640, 540, 540, 1080, 540, 8640, 540, 540, 8640, 540, 1080, 1080, 540, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 540, 540, 8640, 1080, 8640, 540, 1080, 8640, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 540, 540, 1080]
Prompts retrieved: 328320 . Total input tokens: 73232281 . Total output tokens: 65736162
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 196.1742308731191,
    "estimated_duration": 3600.0416549036718,
    "input_throughput": 6354.829802826865,
    "output_throughput": 5678.399574114647,
    "total_throughput": 12033.229376941512,
    "itl": 70.98518988484122,
    "ttft": 562819.2549940164,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 76,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24603920706082136,
    "arrivals": 109384,
    "finished_requests": 92437,
    "scheduler_time": 125.95286945735069
}
#Debug simulation 
Total elapsed time: 196.17438912019134. Arrivals time: 0.673603662289679 Scheduler time: 195.07628560857847 Scheduler overhead time: 0.1742041353136301 Adapter cache time: 0.02933132229372859 Engine time: 0.16586445504799485 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-32/adapters_96_slots_32_rate_0.8-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-32/adapters_96_slots_32_rate_0.8-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 540, 8640, 540, 540, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 540, 8640, 1080, 540, 540, 1080, 8640, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 8640, 1080, 1080, 540, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 540, 8640, 1080, 1080, 1080, 8640, 8640, 540, 540, 1080, 540, 8640, 540, 540, 8640, 540, 1080, 1080, 540, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 540, 540, 8640, 1080, 8640, 540, 1080, 8640, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 540, 540, 1080]
Prompts retrieved: 328320 . Total input tokens: 73232281 . Total output tokens: 65736162
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 198.93370870500803,
    "estimated_duration": 3600.0416745939383,
    "input_throughput": 6354.829768069408,
    "output_throughput": 5678.399543056896,
    "total_throughput": 12033.229311126304,
    "itl": 70.98516381928523,
    "ttft": 562819.3026153994,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 76,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24682081725448352,
    "arrivals": 109384,
    "finished_requests": 92437,
    "scheduler_time": 125.95285000258741
}
#Debug simulation 
Total elapsed time: 198.93386642728. Arrivals time: 0.6793718156404793 Scheduler time: 197.83108750358224 Scheduler overhead time: 0.1740216314792633 Adapter cache time: 0.03126316424459219 Engine time: 0.16604992048814893 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-16-16/adapters_96_slots_32_rate_0.8-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-16-16/adapters_96_slots_32_rate_0.8-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 540, 8640, 540, 540, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 540, 8640, 1080, 540, 540, 1080, 8640, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 8640, 1080, 1080, 540, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 540, 8640, 1080, 1080, 1080, 8640, 8640, 540, 540, 1080, 540, 8640, 540, 540, 8640, 540, 1080, 1080, 540, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 540, 540, 8640, 1080, 8640, 540, 1080, 8640, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 540, 540, 1080]
Prompts retrieved: 328320 . Total input tokens: 73232281 . Total output tokens: 65736162
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 203.93812593305483,
    "estimated_duration": 3600.0040068719677,
    "input_throughput": 6354.527371728446,
    "output_throughput": 5678.082569069479,
    "total_throughput": 12032.609940797925,
    "itl": 70.98493004026307,
    "ttft": 562951.223766804,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 76,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23664151473669345,
    "arrivals": 109384,
    "finished_requests": 92433,
    "scheduler_time": 125.95110066588286
}
#Debug simulation 
Total elapsed time: 203.93828828493133. Arrivals time: 0.6745183211751282 Scheduler time: 202.83177274698392 Scheduler overhead time: 0.17770242039114237 Adapter cache time: 0.03218489699065685 Engine time: 0.1686438750475645 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-16-32/adapters_96_slots_32_rate_0.8-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-16-32/adapters_96_slots_32_rate_0.8-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 540, 8640, 540, 540, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 540, 8640, 1080, 540, 540, 1080, 8640, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 8640, 1080, 1080, 540, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 540, 8640, 1080, 1080, 1080, 8640, 8640, 540, 540, 1080, 540, 8640, 540, 540, 8640, 540, 1080, 1080, 540, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 540, 540, 8640, 1080, 8640, 540, 1080, 8640, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 540, 540, 1080]
Prompts retrieved: 328320 . Total input tokens: 73232281 . Total output tokens: 65736162
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 199.12548550404608,
    "estimated_duration": 3600.0469123374364,
    "input_throughput": 6354.820522365363,
    "output_throughput": 5678.3912814978075,
    "total_throughput": 12033.21180386317,
    "itl": 70.98541399140073,
    "ttft": 562819.3697212383,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 76,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24971315434202526,
    "arrivals": 109384,
    "finished_requests": 92437,
    "scheduler_time": 125.953194702554
}
#Debug simulation 
Total elapsed time: 199.1256425869651. Arrivals time: 0.6815263675525784 Scheduler time: 198.0140492762439 Scheduler overhead time: 0.17813609493896365 Adapter cache time: 0.03205929510295391 Engine time: 0.16516581224277616 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_16-16-16/adapters_96_slots_32_rate_0.8-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_16-16-16/adapters_96_slots_32_rate_0.8-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 540, 8640, 540, 540, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 540, 8640, 1080, 540, 540, 1080, 8640, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 8640, 1080, 1080, 540, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 540, 8640, 1080, 1080, 1080, 8640, 8640, 540, 540, 1080, 540, 8640, 540, 540, 8640, 540, 1080, 1080, 540, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 540, 540, 8640, 1080, 8640, 540, 1080, 8640, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 540, 540, 1080]
Prompts retrieved: 328320 . Total input tokens: 73232281 . Total output tokens: 65736162
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 198.13981847511604,
    "estimated_duration": 3600.041611704577,
    "input_throughput": 6354.829879082343,
    "output_throughput": 5678.399642253226,
    "total_throughput": 12033.22952133557,
    "itl": 70.9847553300871,
    "ttft": 562818.9908186143,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 76,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.22724382241256558,
    "arrivals": 109384,
    "finished_requests": 92437,
    "scheduler_time": 125.9527374059059
}
#Debug simulation 
Total elapsed time: 198.1399837518111. Arrivals time: 0.6779528963379562 Scheduler time: 197.03416982572526 Scheduler overhead time: 0.17728712921962142 Adapter cache time: 0.029771428555250168 Engine time: 0.1659934287890792 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_16-16-32/adapters_96_slots_32_rate_0.8-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_16-16-32/adapters_96_slots_32_rate_0.8-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 540, 8640, 540, 540, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 540, 8640, 1080, 540, 540, 1080, 8640, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 8640, 1080, 1080, 540, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 540, 8640, 1080, 1080, 1080, 8640, 8640, 540, 540, 1080, 540, 8640, 540, 540, 8640, 540, 1080, 1080, 540, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 540, 540, 8640, 1080, 8640, 540, 1080, 8640, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 540, 540, 1080]
Prompts retrieved: 328320 . Total input tokens: 73232281 . Total output tokens: 65736162
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 197.515374423936,
    "estimated_duration": 3600.0450857386754,
    "input_throughput": 6354.823746688119,
    "output_throughput": 5678.394162612413,
    "total_throughput": 12033.217909300532,
    "itl": 70.98537776178543,
    "ttft": 562819.0626435094,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 76,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.252605491429567,
    "arrivals": 109384,
    "finished_requests": 92437,
    "scheduler_time": 125.95299996795298
}
#Debug simulation 
Total elapsed time: 197.51553709199652. Arrivals time: 0.6688815383240581 Scheduler time: 196.41770126810297 Scheduler overhead time: 0.1764179700985551 Adapter cache time: 0.03112923353910446 Engine time: 0.16965538589283824 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-8/adapters_96_slots_32_rate_0.8-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-8/adapters_96_slots_32_rate_0.8-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 270, 8640, 270, 270, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 270, 8640, 1080, 270, 270, 1080, 8640, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 8640, 1080, 1080, 270, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 270, 8640, 1080, 1080, 1080, 8640, 8640, 270, 270, 1080, 270, 8640, 270, 270, 8640, 270, 1080, 1080, 270, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 270, 270, 8640, 1080, 8640, 270, 1080, 8640, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 270, 270, 1080]
Prompts retrieved: 319680 . Total input tokens: 71285179 . Total output tokens: 64022908
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 168.49108934914693,
    "estimated_duration": 3600.0151515484044,
    "input_throughput": 6373.997895572877,
    "output_throughput": 5583.742054906104,
    "total_throughput": 11957.739950478981,
    "itl": 67.58253276173257,
    "ttft": 497277.752268059,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19587121561169607,
    "arrivals": 106465,
    "finished_requests": 91802,
    "scheduler_time": 118.56705062038094
}
#Debug simulation 
Total elapsed time: 168.49126787716523. Arrivals time: 0.6303153797052801 Scheduler time: 167.45547241019085 Scheduler overhead time: 0.16535613732412457 Adapter cache time: 0.027737265918403864 Engine time: 0.16200631251558661 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-16/adapters_96_slots_32_rate_0.8-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-16/adapters_96_slots_32_rate_0.8-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 270, 8640, 270, 270, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 270, 8640, 1080, 270, 270, 1080, 8640, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 8640, 1080, 1080, 270, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 270, 8640, 1080, 1080, 1080, 8640, 8640, 270, 270, 1080, 270, 8640, 270, 270, 8640, 270, 1080, 1080, 270, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 270, 270, 8640, 1080, 8640, 270, 1080, 8640, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 270, 270, 1080]
Prompts retrieved: 319680 . Total input tokens: 71285179 . Total output tokens: 64022908
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 169.66852653212845,
    "estimated_duration": 3600.0675126934925,
    "input_throughput": 6374.194905814739,
    "output_throughput": 5583.698341523698,
    "total_throughput": 11957.893247338438,
    "itl": 67.58285603000861,
    "ttft": 497239.6708398734,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20566405501915144,
    "arrivals": 106465,
    "finished_requests": 91804,
    "scheduler_time": 118.56957552688979
}
#Debug simulation 
Total elapsed time: 169.6687056259252. Arrivals time: 0.636442918330431 Scheduler time: 168.61923304060474 Scheduler overhead time: 0.17009825631976128 Adapter cache time: 0.030317580793052912 Engine time: 0.16173289623111486 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-32/adapters_96_slots_32_rate_0.8-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-32/adapters_96_slots_32_rate_0.8-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 270, 8640, 270, 270, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 270, 8640, 1080, 270, 270, 1080, 8640, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 8640, 1080, 1080, 270, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 270, 8640, 1080, 1080, 1080, 8640, 8640, 270, 270, 1080, 270, 8640, 270, 270, 8640, 270, 1080, 1080, 270, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 270, 270, 8640, 1080, 8640, 270, 1080, 8640, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 270, 270, 1080]
Prompts retrieved: 319680 . Total input tokens: 71285179 . Total output tokens: 64022908
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 168.86628078483045,
    "estimated_duration": 3600.073394982175,
    "input_throughput": 6374.184490789699,
    "output_throughput": 5583.689218119268,
    "total_throughput": 11957.873708908966,
    "itl": 67.58302323345082,
    "ttft": 497239.69776698784,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20658886862918716,
    "arrivals": 106465,
    "finished_requests": 91804,
    "scheduler_time": 118.56982594129963
}
#Debug simulation 
Total elapsed time: 168.86643958790228. Arrivals time: 0.6327575352042913 Scheduler time: 167.82526833517477 Scheduler overhead time: 0.1657300996594131 Adapter cache time: 0.028341957833617926 Engine time: 0.16263391077518463 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-16-16/adapters_96_slots_32_rate_0.8-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-16-16/adapters_96_slots_32_rate_0.8-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 270, 8640, 270, 270, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 270, 8640, 1080, 270, 270, 1080, 8640, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 8640, 1080, 1080, 270, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 270, 8640, 1080, 1080, 1080, 8640, 8640, 270, 270, 1080, 270, 8640, 270, 270, 8640, 270, 1080, 1080, 270, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 270, 270, 8640, 1080, 8640, 270, 1080, 8640, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 270, 270, 1080]
Prompts retrieved: 319680 . Total input tokens: 71285179 . Total output tokens: 64022908
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 170.9098779335618,
    "estimated_duration": 3600.0307806940427,
    "input_throughput": 6373.970223547975,
    "output_throughput": 5583.7178136917655,
    "total_throughput": 11957.68803723974,
    "itl": 67.58283304926796,
    "ttft": 497277.8457085541,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19749214865034456,
    "arrivals": 106465,
    "finished_requests": 91802,
    "scheduler_time": 118.56773782356665
}
#Debug simulation 
Total elapsed time: 170.91004247963428. Arrivals time: 0.6364047052338719 Scheduler time: 169.8591917809099 Scheduler overhead time: 0.17046652734279633 Adapter cache time: 0.029102441389113665 Engine time: 0.16315015824511647 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-16-32/adapters_96_slots_32_rate_0.8-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-16-32/adapters_96_slots_32_rate_0.8-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 270, 8640, 270, 270, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 270, 8640, 1080, 270, 270, 1080, 8640, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 8640, 1080, 1080, 270, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 270, 8640, 1080, 1080, 1080, 8640, 8640, 270, 270, 1080, 270, 8640, 270, 270, 8640, 270, 1080, 1080, 270, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 270, 270, 8640, 1080, 8640, 270, 1080, 8640, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 270, 270, 1080]
Prompts retrieved: 319680 . Total input tokens: 71285179 . Total output tokens: 64022908
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 169.1345032849349,
    "estimated_duration": 3600.075151865243,
    "input_throughput": 6374.181380105525,
    "output_throughput": 5583.686493206974,
    "total_throughput": 11957.867873312498,
    "itl": 67.58279118333228,
    "ttft": 497239.7276961489,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2091039443574843,
    "arrivals": 106465,
    "finished_requests": 91804,
    "scheduler_time": 118.56989548459669
}
#Debug simulation 
Total elapsed time: 169.1346721672453. Arrivals time: 0.6398393586277962 Scheduler time: 168.08370662201196 Scheduler overhead time: 0.16792950173839927 Adapter cache time: 0.028208616189658642 Engine time: 0.16373457061126828 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_16-16-16/adapters_96_slots_32_rate_0.8-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_16-16-16/adapters_96_slots_32_rate_0.8-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 270, 8640, 270, 270, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 270, 8640, 1080, 270, 270, 1080, 8640, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 8640, 1080, 1080, 270, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 270, 8640, 1080, 1080, 1080, 8640, 8640, 270, 270, 1080, 270, 8640, 270, 270, 8640, 270, 1080, 1080, 270, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 270, 270, 8640, 1080, 8640, 270, 1080, 8640, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 270, 270, 1080]
Prompts retrieved: 319680 . Total input tokens: 71285179 . Total output tokens: 64022908
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 169.0001857690513,
    "estimated_duration": 3600.076882681763,
    "input_throughput": 6374.178315576962,
    "output_throughput": 5583.683808726297,
    "total_throughput": 11957.86212430326,
    "itl": 67.58221344257421,
    "ttft": 497239.82728341036,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19136321887373942,
    "arrivals": 106465,
    "finished_requests": 91804,
    "scheduler_time": 118.56980266092462
}
#Debug simulation 
Total elapsed time: 169.0003604311496. Arrivals time: 0.6325249578803778 Scheduler time: 167.96111362660304 Scheduler overhead time: 0.16876685107126832 Adapter cache time: 0.026376658119261265 Engine time: 0.1603431385010481 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_16-16-32/adapters_96_slots_32_rate_0.8-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_16-16-32/adapters_96_slots_32_rate_0.8-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 270, 8640, 270, 270, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 270, 8640, 1080, 270, 270, 1080, 8640, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 8640, 1080, 1080, 270, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 270, 8640, 1080, 1080, 1080, 8640, 8640, 270, 270, 1080, 270, 8640, 270, 270, 8640, 270, 1080, 1080, 270, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 270, 270, 8640, 1080, 8640, 270, 1080, 8640, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 270, 270, 1080]
Prompts retrieved: 319680 . Total input tokens: 71285179 . Total output tokens: 64022908
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 168.2334967823699,
    "estimated_duration": 3600.0752159222725,
    "input_throughput": 6374.181266688137,
    "output_throughput": 5583.686393855057,
    "total_throughput": 11957.867660543194,
    "itl": 67.5827127182208,
    "ttft": 497239.79661628755,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21099025115370718,
    "arrivals": 106465,
    "finished_requests": 91804,
    "scheduler_time": 118.56986651425125
}
#Debug simulation 
Total elapsed time: 168.23367346310988. Arrivals time: 0.6308168126270175 Scheduler time: 167.18844589125365 Scheduler overhead time: 0.17093298071995378 Adapter cache time: 0.0299090133048594 Engine time: 0.1614222889766097 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-8/adapters_96_slots_32_rate_0.8-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-8/adapters_96_slots_32_rate_0.8-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 135, 8640, 1080, 135, 135, 1080, 8640, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 8640, 1080, 1080, 135, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 135, 8640, 1080, 1080, 1080, 8640, 8640, 135, 135, 1080, 135, 8640, 135, 135, 8640, 135, 1080, 1080, 135, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 135, 135, 8640, 1080, 8640, 135, 1080, 8640, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 135, 135, 1080]
Prompts retrieved: 315360 . Total input tokens: 70338575 . Total output tokens: 63127808
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 145.35105332685634,
    "estimated_duration": 3600.0284892219606,
    "input_throughput": 6319.2008252458545,
    "output_throughput": 5632.047929815676,
    "total_throughput": 11951.248755061531,
    "itl": 68.82821304892174,
    "ttft": 452700.1756108305,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 59,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.18056877689203232,
    "arrivals": 105012,
    "finished_requests": 91926,
    "scheduler_time": 113.87202247776891
}
#Debug simulation 
Total elapsed time: 145.35122836381197. Arrivals time: 0.6107833627611399 Scheduler time: 144.34953755140305 Scheduler overhead time: 0.1608202811330557 Adapter cache time: 0.027409164234995842 Engine time: 0.15420048823580146 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-16/adapters_96_slots_32_rate_0.8-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-16/adapters_96_slots_32_rate_0.8-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 135, 8640, 1080, 135, 135, 1080, 8640, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 8640, 1080, 1080, 135, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 135, 8640, 1080, 1080, 1080, 8640, 8640, 135, 135, 1080, 135, 8640, 135, 135, 8640, 135, 1080, 1080, 135, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 135, 135, 8640, 1080, 8640, 135, 1080, 8640, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 135, 135, 1080]
Prompts retrieved: 315360 . Total input tokens: 70338575 . Total output tokens: 63127808
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 144.0065941689536,
    "estimated_duration": 3599.9739405654623,
    "input_throughput": 6319.187409569619,
    "output_throughput": 5632.035768796509,
    "total_throughput": 11951.223178366128,
    "itl": 68.82817167667127,
    "ttft": 452768.850615088,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 59,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19153099418152125,
    "arrivals": 105012,
    "finished_requests": 91924,
    "scheduler_time": 113.86977479855284
}
#Debug simulation 
Total elapsed time: 144.006767494604. Arrivals time: 0.6128419521264732 Scheduler time: 143.01060452777892 Scheduler overhead time: 0.15631109848618507 Adapter cache time: 0.027983075473457575 Engine time: 0.1492733363993466 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-32/adapters_96_slots_32_rate_0.8-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-32/adapters_96_slots_32_rate_0.8-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 135, 8640, 1080, 135, 135, 1080, 8640, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 8640, 1080, 1080, 135, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 135, 8640, 1080, 1080, 1080, 8640, 8640, 135, 135, 1080, 135, 8640, 135, 135, 8640, 135, 1080, 1080, 135, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 135, 135, 8640, 1080, 8640, 135, 1080, 8640, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 135, 135, 1080]
Prompts retrieved: 315360 . Total input tokens: 70338575 . Total output tokens: 63127808
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 144.77845277963206,
    "estimated_duration": 3599.97375533613,
    "input_throughput": 6319.187734710564,
    "output_throughput": 5632.0360585814615,
    "total_throughput": 11951.223793292025,
    "itl": 68.82813659382504,
    "ttft": 452768.82810953597,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 59,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19204576937481752,
    "arrivals": 105012,
    "finished_requests": 91924,
    "scheduler_time": 113.86975342421452
}
#Debug simulation 
Total elapsed time: 144.77863182360306. Arrivals time: 0.6023676809854805 Scheduler time: 143.7955160168931 Scheduler overhead time: 0.15430375514551997 Adapter cache time: 0.026241717860102654 Engine time: 0.15048326225951314 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-16/adapters_96_slots_32_rate_0.8-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-16/adapters_96_slots_32_rate_0.8-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 135, 8640, 1080, 135, 135, 1080, 8640, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 8640, 1080, 1080, 135, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 135, 8640, 1080, 1080, 1080, 8640, 8640, 135, 135, 1080, 135, 8640, 135, 135, 8640, 135, 1080, 1080, 135, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 135, 135, 8640, 1080, 8640, 135, 1080, 8640, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 135, 135, 1080]
Prompts retrieved: 315360 . Total input tokens: 70338575 . Total output tokens: 63127808
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 143.807729461696,
    "estimated_duration": 3599.9654101561546,
    "input_throughput": 6319.202383395464,
    "output_throughput": 5632.049114360943,
    "total_throughput": 11951.251497756406,
    "itl": 68.82866266366983,
    "ttft": 452768.84078295215,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 59,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.1845848737680354,
    "arrivals": 105012,
    "finished_requests": 91924,
    "scheduler_time": 113.86943398317699
}
#Debug simulation 
Total elapsed time: 143.8078890829347. Arrivals time: 0.5950628705322742 Scheduler time: 142.83042156742886 Scheduler overhead time: 0.15248829824849963 Adapter cache time: 0.027124798856675625 Engine time: 0.1513241659849882 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-32/adapters_96_slots_32_rate_0.8-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-32/adapters_96_slots_32_rate_0.8-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 135, 8640, 1080, 135, 135, 1080, 8640, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 8640, 1080, 1080, 135, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 135, 8640, 1080, 1080, 1080, 8640, 8640, 135, 135, 1080, 135, 8640, 135, 135, 8640, 135, 1080, 1080, 135, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 135, 135, 8640, 1080, 8640, 135, 1080, 8640, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 135, 135, 1080]
Prompts retrieved: 315360 . Total input tokens: 70338575 . Total output tokens: 63127808
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 144.57235916983336,
    "estimated_duration": 3599.9751066600024,
    "input_throughput": 6319.185362674928,
    "output_throughput": 5632.033944482183,
    "total_throughput": 11951.219307157111,
    "itl": 68.82805612995489,
    "ttft": 452768.8425152806,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 59,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19418358374387013,
    "arrivals": 105012,
    "finished_requests": 91924,
    "scheduler_time": 113.86987994050078
}
#Debug simulation 
Total elapsed time: 144.57256216881797. Arrivals time: 0.6024432322010398 Scheduler time: 143.58149669738486 Scheduler overhead time: 0.1579871135763824 Adapter cache time: 0.02637861715629697 Engine time: 0.15311863273382187 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-16/adapters_96_slots_32_rate_0.8-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-16/adapters_96_slots_32_rate_0.8-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 135, 8640, 1080, 135, 135, 1080, 8640, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 8640, 1080, 1080, 135, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 135, 8640, 1080, 1080, 1080, 8640, 8640, 135, 135, 1080, 135, 8640, 135, 135, 8640, 135, 1080, 1080, 135, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 135, 135, 8640, 1080, 8640, 135, 1080, 8640, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 135, 135, 1080]
Prompts retrieved: 315360 . Total input tokens: 70338575 . Total output tokens: 63127808
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 152.58762230537832,
    "estimated_duration": 3600.0284628214176,
    "input_throughput": 6319.200871587247,
    "output_throughput": 5632.047971117884,
    "total_throughput": 11951.248842705132,
    "itl": 68.82819312092813,
    "ttft": 452700.49726491387,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 59,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.17641296739922852,
    "arrivals": 105012,
    "finished_requests": 91926,
    "scheduler_time": 113.8721377450393
}
#Debug simulation 
Total elapsed time: 152.58778687240556. Arrivals time: 0.5973968682810664 Scheduler time: 151.59007156873122 Scheduler overhead time: 0.1633988362737 Adapter cache time: 0.02851605089381337 Engine time: 0.15657519595697522 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-32/adapters_96_slots_32_rate_0.8-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-32/adapters_96_slots_32_rate_0.8-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 135, 8640, 1080, 135, 135, 1080, 8640, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 8640, 1080, 1080, 135, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 135, 8640, 1080, 1080, 1080, 8640, 8640, 135, 135, 1080, 135, 8640, 135, 135, 8640, 135, 1080, 1080, 135, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 135, 135, 8640, 1080, 8640, 135, 1080, 8640, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 135, 135, 1080]
Prompts retrieved: 315360 . Total input tokens: 70338575 . Total output tokens: 63127808
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 144.95380491530523,
    "estimated_duration": 3600.019075769395,
    "input_throughput": 6319.217348907527,
    "output_throughput": 5632.062656686539,
    "total_throughput": 11951.280005594066,
    "itl": 68.82851745133397,
    "ttft": 452700.5794974252,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 59,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19669865947216728,
    "arrivals": 105012,
    "finished_requests": 91926,
    "scheduler_time": 113.87187998597524
}
#Debug simulation 
Total elapsed time: 144.95398245891556. Arrivals time: 0.6055796737782657 Scheduler time: 143.96585027175024 Scheduler overhead time: 0.15672165248543024 Adapter cache time: 0.026471561286598444 Engine time: 0.15024392679333687 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-8/adapters_96_slots_32_rate_0.8-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-8/adapters_96_slots_32_rate_0.8-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 66, 8640, 1080, 66, 66, 1080, 8640, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 8640, 1080, 1080, 66, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 66, 8640, 1080, 1080, 1080, 8640, 8640, 66, 66, 1080, 66, 8640, 66, 66, 8640, 66, 1080, 1080, 66, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 66, 66, 8640, 1080, 8640, 66, 1080, 8640, 66, 8640, 1080, 66, 8640, 66, 66, 8640, 66, 66, 1080]
Prompts retrieved: 313152 . Total input tokens: 69865127 . Total output tokens: 62689687
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 59.462560473009944,
    "estimated_duration": 3600.111328017132,
    "input_throughput": 6839.935423208895,
    "output_throughput": 6056.787974945711,
    "total_throughput": 12896.723398154607,
    "itl": 88.06619822727244,
    "ttft": 319263.8317571618,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 200,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.61209754878655,
    "arrivals": 104295,
    "finished_requests": 99046,
    "scheduler_time": 104.55831803524673
}
#Debug simulation 
Total elapsed time: 59.462738851085305. Arrivals time: 0.46745649026706815 Scheduler time: 58.75029628397897 Scheduler overhead time: 0.0967106674797833 Adapter cache time: 0.017652161419391632 Engine time: 0.09477503318339586 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-16/adapters_96_slots_32_rate_0.8-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-16/adapters_96_slots_32_rate_0.8-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 66, 8640, 1080, 66, 66, 1080, 8640, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 8640, 1080, 1080, 66, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 66, 8640, 1080, 1080, 1080, 8640, 8640, 66, 66, 1080, 66, 8640, 66, 66, 8640, 66, 1080, 1080, 66, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 66, 66, 8640, 1080, 8640, 66, 1080, 8640, 66, 8640, 1080, 66, 8640, 66, 66, 8640, 66, 66, 1080]
Prompts retrieved: 313152 . Total input tokens: 69865127 . Total output tokens: 62689687
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 58.61303143110126,
    "estimated_duration": 3600.064961629893,
    "input_throughput": 6838.935758773993,
    "output_throughput": 6055.654059678393,
    "total_throughput": 12894.589818452387,
    "itl": 88.09606575026594,
    "ttft": 319845.8992980947,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 200,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.649901664422361,
    "arrivals": 104295,
    "finished_requests": 99029,
    "scheduler_time": 104.55446112935701
}
#Debug simulation 
Total elapsed time: 58.613199518062174. Arrivals time: 0.4836644809693098 Scheduler time: 57.89304162468761 Scheduler overhead time: 0.09280435275286436 Adapter cache time: 0.017147949896752834 Engine time: 0.09199859155341983 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-32/adapters_96_slots_32_rate_0.8-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-32/adapters_96_slots_32_rate_0.8-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 66, 8640, 1080, 66, 66, 1080, 8640, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 8640, 1080, 1080, 66, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 66, 8640, 1080, 1080, 1080, 8640, 8640, 66, 66, 1080, 66, 8640, 66, 66, 8640, 66, 1080, 1080, 66, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 66, 66, 8640, 1080, 8640, 66, 1080, 8640, 66, 8640, 1080, 66, 8640, 66, 66, 8640, 66, 66, 1080]
Prompts retrieved: 313152 . Total input tokens: 69865127 . Total output tokens: 62689687
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 58.61131127830595,
    "estimated_duration": 3600.0630639361425,
    "input_throughput": 6838.939363767967,
    "output_throughput": 6055.657251782714,
    "total_throughput": 12894.596615550681,
    "itl": 88.09614146649112,
    "ttft": 319845.27568084945,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 200,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.651534201558682,
    "arrivals": 104295,
    "finished_requests": 99029,
    "scheduler_time": 104.554259194918
}
#Debug simulation 
Total elapsed time: 58.61147367814556. Arrivals time: 0.48263294575735927 Scheduler time: 57.889077864121646 Scheduler overhead time: 0.09549413528293371 Adapter cache time: 0.017677188850939274 Engine time: 0.09210661659017205 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-16/adapters_96_slots_32_rate_0.8-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-16/adapters_96_slots_32_rate_0.8-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 66, 8640, 1080, 66, 66, 1080, 8640, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 8640, 1080, 1080, 66, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 66, 8640, 1080, 1080, 1080, 8640, 8640, 66, 66, 1080, 66, 8640, 66, 66, 8640, 66, 1080, 1080, 66, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 66, 66, 8640, 1080, 8640, 66, 1080, 8640, 66, 8640, 1080, 66, 8640, 66, 66, 8640, 66, 66, 1080]
Prompts retrieved: 313152 . Total input tokens: 69865127 . Total output tokens: 62689687
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 59.54742331197485,
    "estimated_duration": 3600.116275603252,
    "input_throughput": 6840.750441004383,
    "output_throughput": 6055.116371580871,
    "total_throughput": 12895.866812585253,
    "itl": 88.05861069850828,
    "ttft": 320305.8969251015,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 202,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6305488552688631,
    "arrivals": 104295,
    "finished_requests": 99019,
    "scheduler_time": 104.55850545927055
}
#Debug simulation 
Total elapsed time: 59.5476114070043. Arrivals time: 0.47623722767457366 Scheduler time: 58.830979076679796 Scheduler overhead time: 0.09505845606327057 Adapter cache time: 0.017838723491877317 Engine time: 0.09151470940560102 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-32/adapters_96_slots_32_rate_0.8-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-32/adapters_96_slots_32_rate_0.8-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 66, 8640, 1080, 66, 66, 1080, 8640, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 8640, 1080, 1080, 66, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 66, 8640, 1080, 1080, 1080, 8640, 8640, 66, 66, 1080, 66, 8640, 66, 66, 8640, 66, 1080, 1080, 66, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 66, 66, 8640, 1080, 8640, 66, 1080, 8640, 66, 8640, 1080, 66, 8640, 66, 66, 8640, 66, 66, 1080]
Prompts retrieved: 313152 . Total input tokens: 69865127 . Total output tokens: 62689687
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 58.95451567089185,
    "estimated_duration": 3600.0034576285534,
    "input_throughput": 6839.052320304839,
    "output_throughput": 6055.756961511616,
    "total_throughput": 12894.809281816455,
    "itl": 88.09442423732489,
    "ttft": 319855.25203674176,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 200,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6593309363164028,
    "arrivals": 104295,
    "finished_requests": 99028,
    "scheduler_time": 104.55264816790663
}
#Debug simulation 
Total elapsed time: 58.95467206509784. Arrivals time: 0.47748114401474595 Scheduler time: 58.23589340830222 Scheduler overhead time: 0.09677586983889341 Adapter cache time: 0.017804120667278767 Engine time: 0.09147963486611843 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-16/adapters_96_slots_32_rate_0.8-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-16/adapters_96_slots_32_rate_0.8-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 66, 8640, 1080, 66, 66, 1080, 8640, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 8640, 1080, 1080, 66, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 66, 8640, 1080, 1080, 1080, 8640, 8640, 66, 66, 1080, 66, 8640, 66, 66, 8640, 66, 1080, 1080, 66, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 66, 66, 8640, 1080, 8640, 66, 1080, 8640, 66, 8640, 1080, 66, 8640, 66, 66, 8640, 66, 66, 1080]
Prompts retrieved: 313152 . Total input tokens: 69865127 . Total output tokens: 62689687
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 59.67297722492367,
    "estimated_duration": 3600.0931461295154,
    "input_throughput": 6838.929161171835,
    "output_throughput": 6055.607206563012,
    "total_throughput": 12894.536367734847,
    "itl": 88.09187315203967,
    "ttft": 319902.0385516071,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 200,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5980100589804359,
    "arrivals": 104295,
    "finished_requests": 99030,
    "scheduler_time": 104.55566964911056
}
#Debug simulation 
Total elapsed time: 59.673122856765985. Arrivals time: 0.479405474383384 Scheduler time: 58.955386029556394 Scheduler overhead time: 0.09271508455276489 Adapter cache time: 0.017578843981027603 Engine time: 0.09371686493977904 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-32/adapters_96_slots_32_rate_0.8-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-32/adapters_96_slots_32_rate_0.8-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 66, 8640, 1080, 66, 66, 1080, 8640, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 8640, 1080, 1080, 66, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 66, 8640, 1080, 1080, 1080, 8640, 8640, 66, 66, 1080, 66, 8640, 66, 66, 8640, 66, 1080, 1080, 66, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 66, 66, 8640, 1080, 8640, 66, 1080, 8640, 66, 8640, 1080, 66, 8640, 66, 66, 8640, 66, 66, 1080]
Prompts retrieved: 313152 . Total input tokens: 69865127 . Total output tokens: 62689687
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 57.96590311918408,
    "estimated_duration": 3600.0828314754413,
    "input_throughput": 6838.901812131251,
    "output_throughput": 6055.624001035911,
    "total_throughput": 12894.525813167162,
    "itl": 88.09612203145446,
    "ttft": 319943.7481979206,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 200,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6675049324333683,
    "arrivals": 104295,
    "finished_requests": 99029,
    "scheduler_time": 104.55497516429553
}
#Debug simulation 
Total elapsed time: 57.966052189935. Arrivals time: 0.48785945028066635 Scheduler time: 57.24306379118934 Scheduler overhead time: 0.09359115734696388 Adapter cache time: 0.017297263257205486 Engine time: 0.08938441798090935 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-8/adapters_96_slots_32_rate_0.8-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-8/adapters_96_slots_32_rate_0.8-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 33, 8640, 1080, 33, 33, 1080, 8640, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 8640, 1080, 1080, 33, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 33, 8640, 1080, 1080, 1080, 8640, 8640, 33, 33, 1080, 33, 8640, 33, 33, 8640, 33, 1080, 1080, 33, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 33, 33, 8640, 1080, 8640, 33, 1080, 8640, 33, 8640, 1080, 33, 8640, 33, 33, 8640, 33, 33, 1080]
Prompts retrieved: 312096 . Total input tokens: 69630651 . Total output tokens: 62481129
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 136.27623615274206,
    "estimated_duration": 3600.07704807691,
    "input_throughput": 6350.317700064845,
    "output_throughput": 5582.077475462598,
    "total_throughput": 11932.395175527443,
    "itl": 66.74107058604434,
    "ttft": 426837.6338157189,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 56,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.17138731366023408,
    "arrivals": 103971,
    "finished_requests": 91651,
    "scheduler_time": 111.25239620506056
}
#Debug simulation 
Total elapsed time: 136.27640442596748. Arrivals time: 0.5905195763334632 Scheduler time: 135.316108611878 Scheduler overhead time: 0.1508737369440496 Adapter cache time: 0.025162181351333857 Engine time: 0.1437259204685688 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-16/adapters_96_slots_32_rate_0.8-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-16/adapters_96_slots_32_rate_0.8-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 33, 8640, 1080, 33, 33, 1080, 8640, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 8640, 1080, 1080, 33, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 33, 8640, 1080, 1080, 1080, 8640, 8640, 33, 33, 1080, 33, 8640, 33, 33, 8640, 33, 1080, 1080, 33, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 33, 33, 8640, 1080, 8640, 33, 1080, 8640, 33, 8640, 1080, 33, 8640, 33, 33, 8640, 33, 33, 1080]
Prompts retrieved: 312096 . Total input tokens: 69630651 . Total output tokens: 62481129
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 137.31146723311394,
    "estimated_duration": 3600.028435949766,
    "input_throughput": 6350.321784046875,
    "output_throughput": 5582.107574297063,
    "total_throughput": 11932.42935834394,
    "itl": 66.7409936252067,
    "ttft": 426811.10927985003,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 56,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.180517866704613,
    "arrivals": 103971,
    "finished_requests": 91650,
    "scheduler_time": 111.25048581594443
}
#Debug simulation 
Total elapsed time: 137.31161759095266. Arrivals time: 0.5953712654300034 Scheduler time: 136.33931083371863 Scheduler overhead time: 0.1548696612007916 Adapter cache time: 0.026378404814749956 Engine time: 0.1456502196379006 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-32/adapters_96_slots_32_rate_0.8-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-32/adapters_96_slots_32_rate_0.8-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 33, 8640, 1080, 33, 33, 1080, 8640, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 8640, 1080, 1080, 33, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 33, 8640, 1080, 1080, 1080, 8640, 8640, 33, 33, 1080, 33, 8640, 33, 33, 8640, 33, 1080, 1080, 33, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 33, 33, 8640, 1080, 8640, 33, 1080, 8640, 33, 8640, 1080, 33, 8640, 33, 33, 8640, 33, 33, 1080]
Prompts retrieved: 312096 . Total input tokens: 69630651 . Total output tokens: 62481129
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 137.09810371603817,
    "estimated_duration": 3600.0373064815703,
    "input_throughput": 6350.306136783651,
    "output_throughput": 5582.093819922162,
    "total_throughput": 11932.399956705813,
    "itl": 66.7411144433604,
    "ttft": 426811.1385064043,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 56,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.18122897535562507,
    "arrivals": 103971,
    "finished_requests": 91650,
    "scheduler_time": 111.25084099195992
}
#Debug simulation 
Total elapsed time: 137.09827196598053. Arrivals time: 0.5989195583388209 Scheduler time: 136.11572130629793 Scheduler overhead time: 0.15639992244541645 Adapter cache time: 0.027109066024422646 Engine time: 0.14993533259257674 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-16/adapters_96_slots_32_rate_0.8-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-16/adapters_96_slots_32_rate_0.8-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 33, 8640, 1080, 33, 33, 1080, 8640, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 8640, 1080, 1080, 33, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 33, 8640, 1080, 1080, 1080, 8640, 8640, 33, 33, 1080, 33, 8640, 33, 33, 8640, 33, 1080, 1080, 33, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 33, 33, 8640, 1080, 8640, 33, 1080, 8640, 33, 8640, 1080, 33, 8640, 33, 33, 8640, 33, 33, 1080]
Prompts retrieved: 312096 . Total input tokens: 69630651 . Total output tokens: 62481129
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 136.41722422791645,
    "estimated_duration": 3600.0163819216596,
    "input_throughput": 6350.343046993804,
    "output_throughput": 5582.126265012454,
    "total_throughput": 11932.469312006257,
    "itl": 66.74107259357008,
    "ttft": 426780.843228842,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 56,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.17479753224644817,
    "arrivals": 103971,
    "finished_requests": 91650,
    "scheduler_time": 111.24995960618735
}
#Debug simulation 
Total elapsed time: 136.41739147575572. Arrivals time: 0.5933983777649701 Scheduler time: 135.44934630999342 Scheduler overhead time: 0.15420199558138847 Adapter cache time: 0.025218747090548277 Engine time: 0.14638708205893636 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-32/adapters_96_slots_32_rate_0.8-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-32/adapters_96_slots_32_rate_0.8-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 33, 8640, 1080, 33, 33, 1080, 8640, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 8640, 1080, 1080, 33, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 33, 8640, 1080, 1080, 1080, 8640, 8640, 33, 33, 1080, 33, 8640, 33, 33, 8640, 33, 1080, 1080, 33, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 33, 33, 8640, 1080, 8640, 33, 1080, 8640, 33, 8640, 1080, 33, 8640, 33, 33, 8640, 33, 33, 1080]
Prompts retrieved: 312096 . Total input tokens: 69630651 . Total output tokens: 62481129
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 136.1217033630237,
    "estimated_duration": 3600.0382183984466,
    "input_throughput": 6350.304528203134,
    "output_throughput": 5582.092405935629,
    "total_throughput": 11932.396934138764,
    "itl": 66.74105681529664,
    "ttft": 426811.15475589933,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 56,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.18298952836543309,
    "arrivals": 103971,
    "finished_requests": 91650,
    "scheduler_time": 111.25091761240853
}
#Debug simulation 
Total elapsed time: 136.1218998739496. Arrivals time: 0.5942505276761949 Scheduler time: 135.1525650927797 Scheduler overhead time: 0.15342193376272917 Adapter cache time: 0.026019319891929626 Engine time: 0.14615040505304933 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-16/adapters_96_slots_32_rate_0.8-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-16/adapters_96_slots_32_rate_0.8-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 33, 8640, 1080, 33, 33, 1080, 8640, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 8640, 1080, 1080, 33, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 33, 8640, 1080, 1080, 1080, 8640, 8640, 33, 33, 1080, 33, 8640, 33, 33, 8640, 33, 1080, 1080, 33, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 33, 33, 8640, 1080, 8640, 33, 1080, 8640, 33, 8640, 1080, 33, 8640, 33, 33, 8640, 33, 33, 1080]
Prompts retrieved: 312096 . Total input tokens: 69630651 . Total output tokens: 62481129
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 136.93346722284332,
    "estimated_duration": 3600.061145763596,
    "input_throughput": 6350.264085625958,
    "output_throughput": 5582.056855797532,
    "total_throughput": 11932.32094142349,
    "itl": 66.7409108853326,
    "ttft": 426841.7050753552,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 56,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.16744281651452197,
    "arrivals": 103971,
    "finished_requests": 91650,
    "scheduler_time": 111.25174419493649
}
#Debug simulation 
Total elapsed time: 136.93362144380808. Arrivals time: 0.5885277558118105 Scheduler time: 135.96905892109498 Scheduler overhead time: 0.15302599873393774 Adapter cache time: 0.025805811397731304 Engine time: 0.14678311999887228 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-32/adapters_96_slots_32_rate_0.8-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-32/adapters_96_slots_32_rate_0.8-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 33, 8640, 1080, 33, 33, 1080, 8640, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 8640, 1080, 1080, 33, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 33, 8640, 1080, 1080, 1080, 8640, 8640, 33, 33, 1080, 33, 8640, 33, 33, 8640, 33, 1080, 1080, 33, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 33, 33, 8640, 1080, 8640, 33, 1080, 8640, 33, 8640, 1080, 33, 8640, 33, 33, 8640, 33, 33, 1080]
Prompts retrieved: 312096 . Total input tokens: 69630651 . Total output tokens: 62481129
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 134.92782832263038,
    "estimated_duration": 3600.040036771367,
    "input_throughput": 6350.301320677198,
    "output_throughput": 5582.089586432077,
    "total_throughput": 11932.390907109275,
    "itl": 66.74101373681944,
    "ttft": 426811.16995055653,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 56,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.18525309652090052,
    "arrivals": 103971,
    "finished_requests": 91650,
    "scheduler_time": 111.25104202559196
}
#Debug simulation 
Total elapsed time: 134.9280093088746. Arrivals time: 0.5844583683647215 Scheduler time: 133.96731067122892 Scheduler overhead time: 0.1537514990195632 Adapter cache time: 0.025432957336306572 Engine time: 0.14726858399808407 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-8/adapters_96_slots_32_rate_0.8-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-8/adapters_96_slots_32_rate_0.8-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 8640, 540, 540, 540, 540, 8640, 540, 8640, 540, 270, 8640, 270, 270, 8640, 540, 8640, 540, 8640, 8640, 540, 270, 8640, 540, 270, 270, 540, 8640, 270, 540, 270, 270, 540, 540, 540, 270, 270, 8640, 540, 540, 270, 8640, 8640, 540, 8640, 8640, 540, 8640, 270, 8640, 540, 540, 540, 8640, 8640, 270, 270, 540, 270, 8640, 270, 270, 8640, 270, 540, 540, 270, 540, 8640, 8640, 8640, 540, 8640, 8640, 270, 270, 8640, 540, 8640, 270, 540, 8640, 270, 8640, 540, 270, 8640, 270, 270, 8640, 270, 270, 540]
Prompts retrieved: 302400 . Total input tokens: 67462409 . Total output tokens: 60534546
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 76.93184902193025,
    "estimated_duration": 3600.0462050965975,
    "input_throughput": 6385.500265928719,
    "output_throughput": 5712.536125476807,
    "total_throughput": 12098.036391405527,
    "itl": 69.59416525456474,
    "ttft": 318086.7071071497,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 82,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.25095999500248556,
    "arrivals": 100828,
    "finished_requests": 93061,
    "scheduler_time": 99.7159194823398
}
#Debug simulation 
Total elapsed time: 76.9320258712396. Arrivals time: 0.5024713021703064 Scheduler time: 76.14385695196688 Scheduler overhead time: 0.11395231215283275 Adapter cache time: 0.01955939596518874 Engine time: 0.11077549308538437 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-16/adapters_96_slots_32_rate_0.8-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-16/adapters_96_slots_32_rate_0.8-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 8640, 540, 540, 540, 540, 8640, 540, 8640, 540, 270, 8640, 270, 270, 8640, 540, 8640, 540, 8640, 8640, 540, 270, 8640, 540, 270, 270, 540, 8640, 270, 540, 270, 270, 540, 540, 540, 270, 270, 8640, 540, 540, 270, 8640, 8640, 540, 8640, 8640, 540, 8640, 270, 8640, 540, 540, 540, 8640, 8640, 270, 270, 540, 270, 8640, 270, 270, 8640, 270, 540, 540, 270, 540, 8640, 8640, 8640, 540, 8640, 8640, 270, 270, 8640, 540, 8640, 270, 540, 8640, 270, 8640, 540, 270, 8640, 270, 270, 8640, 270, 270, 540]
Prompts retrieved: 302400 . Total input tokens: 67462409 . Total output tokens: 60534546
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 75.72950880182907,
    "estimated_duration": 3600.0102523940327,
    "input_throughput": 6385.564036855937,
    "output_throughput": 5712.593175623282,
    "total_throughput": 12098.157212479218,
    "itl": 69.59473791171092,
    "ttft": 318054.0767586481,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 82,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2672482713777572,
    "arrivals": 100828,
    "finished_requests": 93061,
    "scheduler_time": 99.71457629734724
}
#Debug simulation 
Total elapsed time: 75.72967973491177. Arrivals time: 0.4627803056500852 Scheduler time: 74.98816004348919 Scheduler overhead time: 0.11385931447148323 Adapter cache time: 0.016393948812037706 Engine time: 0.10943256178870797 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-32/adapters_96_slots_32_rate_0.8-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-32/adapters_96_slots_32_rate_0.8-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 8640, 540, 540, 540, 540, 8640, 540, 8640, 540, 270, 8640, 270, 270, 8640, 540, 8640, 540, 8640, 8640, 540, 270, 8640, 540, 270, 270, 540, 8640, 270, 540, 270, 270, 540, 540, 540, 270, 270, 8640, 540, 540, 270, 8640, 8640, 540, 8640, 8640, 540, 8640, 270, 8640, 540, 540, 540, 8640, 8640, 270, 270, 540, 270, 8640, 270, 270, 8640, 270, 540, 540, 270, 540, 8640, 8640, 8640, 540, 8640, 8640, 270, 270, 8640, 540, 8640, 270, 540, 8640, 270, 8640, 540, 270, 8640, 270, 270, 8640, 270, 270, 540]
Prompts retrieved: 302400 . Total input tokens: 67462409 . Total output tokens: 60534546
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 75.41184293618426,
    "estimated_duration": 3600.0104372697933,
    "input_throughput": 6385.563708930219,
    "output_throughput": 5712.592882257463,
    "total_throughput": 12098.156591187682,
    "itl": 69.59472959627325,
    "ttft": 318054.08257722907,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 82,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2677799103036523,
    "arrivals": 100828,
    "finished_requests": 93061,
    "scheduler_time": 99.71456884927251
}
#Debug simulation 
Total elapsed time: 75.41200773930177. Arrivals time: 0.4698937009088695 Scheduler time: 74.66315508866683 Scheduler overhead time: 0.11143176909536123 Adapter cache time: 0.018270788714289665 Engine time: 0.10873841401189566 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-16-16/adapters_96_slots_32_rate_0.8-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-16-16/adapters_96_slots_32_rate_0.8-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 8640, 540, 540, 540, 540, 8640, 540, 8640, 540, 270, 8640, 270, 270, 8640, 540, 8640, 540, 8640, 8640, 540, 270, 8640, 540, 270, 270, 540, 8640, 270, 540, 270, 270, 540, 540, 540, 270, 270, 8640, 540, 540, 270, 8640, 8640, 540, 8640, 8640, 540, 8640, 270, 8640, 540, 540, 540, 8640, 8640, 270, 270, 540, 270, 8640, 270, 270, 8640, 270, 540, 540, 270, 540, 8640, 8640, 8640, 540, 8640, 8640, 270, 270, 8640, 540, 8640, 270, 540, 8640, 270, 8640, 540, 270, 8640, 270, 270, 8640, 270, 270, 540]
Prompts retrieved: 302400 . Total input tokens: 67462409 . Total output tokens: 60534546
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 74.58682322269306,
    "estimated_duration": 3600.050910490269,
    "input_throughput": 6385.491919854376,
    "output_throughput": 5712.52865899036,
    "total_throughput": 12098.020578844735,
    "itl": 69.59383684996136,
    "ttft": 318086.95886116615,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 82,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2553990071429872,
    "arrivals": 100828,
    "finished_requests": 93061,
    "scheduler_time": 99.71604145515911
}
#Debug simulation 
Total elapsed time: 74.58697364572436. Arrivals time: 0.4641939792782068 Scheduler time: 73.84693768573925 Scheduler overhead time: 0.10948707023635507 Adapter cache time: 0.018223269376903772 Engine time: 0.10840304708108306 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-16-32/adapters_96_slots_32_rate_0.8-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-16-32/adapters_96_slots_32_rate_0.8-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 8640, 540, 540, 540, 540, 8640, 540, 8640, 540, 270, 8640, 270, 270, 8640, 540, 8640, 540, 8640, 8640, 540, 270, 8640, 540, 270, 270, 540, 8640, 270, 540, 270, 270, 540, 540, 540, 270, 270, 8640, 540, 540, 270, 8640, 8640, 540, 8640, 8640, 540, 8640, 270, 8640, 540, 540, 540, 8640, 8640, 270, 270, 540, 270, 8640, 270, 270, 8640, 270, 540, 540, 270, 540, 8640, 8640, 8640, 540, 8640, 8640, 270, 270, 8640, 540, 8640, 270, 540, 8640, 270, 8640, 540, 270, 8640, 270, 270, 8640, 270, 270, 540]
Prompts retrieved: 302400 . Total input tokens: 67462409 . Total output tokens: 60534546
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 74.74044307880104,
    "estimated_duration": 3600.026332470871,
    "input_throughput": 6385.53551474224,
    "output_throughput": 5712.567659438475,
    "total_throughput": 12098.103174180715,
    "itl": 69.59477304414004,
    "ttft": 318054.3042716735,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 82,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.27142677010968314,
    "arrivals": 100828,
    "finished_requests": 93061,
    "scheduler_time": 99.71512218553829
}
#Debug simulation 
Total elapsed time: 74.74061691761017. Arrivals time: 0.4709307001903653 Scheduler time: 73.99368616379797 Scheduler overhead time: 0.11108982656151056 Adapter cache time: 0.01854779850691557 Engine time: 0.10572736850008368 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_16-16-16/adapters_96_slots_32_rate_0.8-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_16-16-16/adapters_96_slots_32_rate_0.8-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 8640, 540, 540, 540, 540, 8640, 540, 8640, 540, 270, 8640, 270, 270, 8640, 540, 8640, 540, 8640, 8640, 540, 270, 8640, 540, 270, 270, 540, 8640, 270, 540, 270, 270, 540, 540, 540, 270, 270, 8640, 540, 540, 270, 8640, 8640, 540, 8640, 8640, 540, 8640, 270, 8640, 540, 540, 540, 8640, 8640, 270, 270, 540, 270, 8640, 270, 270, 8640, 270, 540, 540, 270, 540, 8640, 8640, 8640, 540, 8640, 8640, 270, 270, 8640, 540, 8640, 270, 540, 8640, 270, 8640, 540, 270, 8640, 270, 270, 8640, 270, 270, 540]
Prompts retrieved: 302400 . Total input tokens: 67462409 . Total output tokens: 60534546
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 75.70434660697356,
    "estimated_duration": 3600.007440036596,
    "input_throughput": 6385.569025314657,
    "output_throughput": 5712.597638351253,
    "total_throughput": 12098.16666366591,
    "itl": 69.59360305718074,
    "ttft": 318054.08538559696,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 82,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24518412418197866,
    "arrivals": 100828,
    "finished_requests": 93061,
    "scheduler_time": 99.7145915353788
}
#Debug simulation 
Total elapsed time: 75.70464629074559. Arrivals time: 0.4645022861659527 Scheduler time: 74.9653802071698 Scheduler overhead time: 0.10921096475794911 Adapter cache time: 0.018775769975036383 Engine time: 0.10557947400957346 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_16-16-32/adapters_96_slots_32_rate_0.8-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_16-16-32/adapters_96_slots_32_rate_0.8-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 8640, 540, 540, 540, 540, 8640, 540, 8640, 540, 270, 8640, 270, 270, 8640, 540, 8640, 540, 8640, 8640, 540, 270, 8640, 540, 270, 270, 540, 8640, 270, 540, 270, 270, 540, 540, 540, 270, 270, 8640, 540, 540, 270, 8640, 8640, 540, 8640, 8640, 540, 8640, 270, 8640, 540, 540, 540, 8640, 8640, 270, 270, 540, 270, 8640, 270, 270, 8640, 270, 540, 540, 270, 540, 8640, 8640, 8640, 540, 8640, 8640, 270, 270, 8640, 540, 8640, 270, 540, 8640, 270, 8640, 540, 270, 8640, 270, 270, 8640, 270, 270, 540]
Prompts retrieved: 302400 . Total input tokens: 67462409 . Total output tokens: 60534546
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 74.94244884280488,
    "estimated_duration": 3600.0526636754494,
    "input_throughput": 6385.488810191588,
    "output_throughput": 5712.525877053115,
    "total_throughput": 12098.014687244702,
    "itl": 69.59494518178145,
    "ttft": 318086.7706297977,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 82,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2745706147700545,
    "arrivals": 100828,
    "finished_requests": 93061,
    "scheduler_time": 99.71606052041285
}
#Debug simulation 
Total elapsed time: 74.94262936897576. Arrivals time: 0.47173154866322875 Scheduler time: 74.18800083268434 Scheduler overhead time: 0.11279681278392673 Adapter cache time: 0.018374644685536623 Engine time: 0.11113937012851238 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-8/adapters_96_slots_32_rate_0.8-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-8/adapters_96_slots_32_rate_0.8-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 8640, 540, 540, 540, 540, 8640, 540, 8640, 540, 135, 8640, 135, 135, 8640, 540, 8640, 540, 8640, 8640, 540, 135, 8640, 540, 135, 135, 540, 8640, 135, 540, 135, 135, 540, 540, 540, 135, 135, 8640, 540, 540, 135, 8640, 8640, 540, 8640, 8640, 540, 8640, 135, 8640, 540, 540, 540, 8640, 8640, 135, 135, 540, 135, 8640, 135, 135, 8640, 135, 540, 540, 135, 540, 8640, 8640, 8640, 540, 8640, 8640, 135, 135, 8640, 540, 8640, 135, 540, 8640, 135, 8640, 540, 135, 8640, 135, 135, 8640, 135, 135, 540]
Prompts retrieved: 298080 . Total input tokens: 66485273 . Total output tokens: 59678888
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 71.09316669590771,
    "estimated_duration": 3600.001044816271,
    "input_throughput": 6358.407043509128,
    "output_throughput": 5571.162271988614,
    "total_throughput": 11929.569315497742,
    "itl": 65.5914990243818,
    "ttft": 279906.92700857995,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 39,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.11935902201337734,
    "arrivals": 99385,
    "finished_requests": 91660,
    "scheduler_time": 96.29908660402923
}
#Debug simulation 
Total elapsed time: 71.09331570891663. Arrivals time: 0.45407205866649747 Scheduler time: 70.36402451293543 Scheduler overhead time: 0.10885463748127222 Adapter cache time: 0.017687025479972363 Engine time: 0.10720061650499701 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-16/adapters_96_slots_32_rate_0.8-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-16/adapters_96_slots_32_rate_0.8-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 8640, 540, 540, 540, 540, 8640, 540, 8640, 540, 135, 8640, 135, 135, 8640, 540, 8640, 540, 8640, 8640, 540, 135, 8640, 540, 135, 135, 540, 8640, 135, 540, 135, 135, 540, 540, 540, 135, 135, 8640, 540, 540, 135, 8640, 8640, 540, 8640, 8640, 540, 8640, 135, 8640, 540, 540, 540, 8640, 8640, 135, 135, 540, 135, 8640, 135, 135, 8640, 135, 540, 540, 135, 540, 8640, 8640, 8640, 540, 8640, 8640, 135, 135, 8640, 540, 8640, 135, 540, 8640, 135, 8640, 540, 135, 8640, 135, 135, 8640, 135, 135, 540]
Prompts retrieved: 298080 . Total input tokens: 66485273 . Total output tokens: 59678888
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 71.34797640098259,
    "estimated_duration": 3600.0200835459896,
    "input_throughput": 6358.373417031961,
    "output_throughput": 5571.1328088605605,
    "total_throughput": 11929.506225892523,
    "itl": 65.59163949619209,
    "ttft": 279907.1189694565,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 39,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.1264182491437532,
    "arrivals": 99385,
    "finished_requests": 91660,
    "scheduler_time": 96.29974389946317
}
#Debug simulation 
Total elapsed time: 71.34821172291413. Arrivals time: 0.4516783868893981 Scheduler time: 70.61645057052374 Scheduler overhead time: 0.11103506060317159 Adapter cache time: 0.017484287731349468 Engine time: 0.1095037842169404 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-32/adapters_96_slots_32_rate_0.8-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-32/adapters_96_slots_32_rate_0.8-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 8640, 540, 540, 540, 540, 8640, 540, 8640, 540, 135, 8640, 135, 135, 8640, 540, 8640, 540, 8640, 8640, 540, 135, 8640, 540, 135, 135, 540, 8640, 135, 540, 135, 135, 540, 540, 540, 135, 135, 8640, 540, 540, 135, 8640, 8640, 540, 8640, 8640, 540, 8640, 135, 8640, 540, 540, 540, 8640, 8640, 135, 135, 540, 135, 8640, 135, 135, 8640, 135, 540, 540, 135, 540, 8640, 8640, 8640, 540, 8640, 8640, 135, 135, 8640, 540, 8640, 135, 540, 8640, 135, 8640, 540, 135, 8640, 135, 135, 8640, 135, 135, 540]
Prompts retrieved: 298080 . Total input tokens: 66485273 . Total output tokens: 59678888
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 71.9262791192159,
    "estimated_duration": 3600.020104691596,
    "input_throughput": 6358.373379684486,
    "output_throughput": 5571.132776137138,
    "total_throughput": 11929.506155821624,
    "itl": 65.59163494755528,
    "ttft": 279907.12056794425,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 39,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.12679117497056722,
    "arrivals": 99385,
    "finished_requests": 91660,
    "scheduler_time": 96.29973796756035
}
#Debug simulation 
Total elapsed time: 71.92644572397694. Arrivals time: 0.44528532959520817 Scheduler time: 71.2073477320373 Scheduler overhead time: 0.10822890512645245 Adapter cache time: 0.016735493205487728 Engine time: 0.10864363331347704 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-16/adapters_96_slots_32_rate_0.8-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-16/adapters_96_slots_32_rate_0.8-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 8640, 540, 540, 540, 540, 8640, 540, 8640, 540, 135, 8640, 135, 135, 8640, 540, 8640, 540, 8640, 8640, 540, 135, 8640, 540, 135, 135, 540, 8640, 135, 540, 135, 135, 540, 540, 540, 135, 135, 8640, 540, 540, 135, 8640, 8640, 540, 8640, 8640, 540, 8640, 135, 8640, 540, 540, 540, 8640, 8640, 135, 135, 540, 135, 8640, 135, 135, 8640, 135, 540, 540, 135, 540, 8640, 8640, 8640, 540, 8640, 8640, 135, 135, 8640, 540, 8640, 135, 540, 8640, 135, 8640, 540, 135, 8640, 135, 135, 8640, 135, 135, 540]
Prompts retrieved: 298080 . Total input tokens: 66485273 . Total output tokens: 59678888
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 71.29637941392139,
    "estimated_duration": 3600.0010125692565,
    "input_throughput": 6358.407100464569,
    "output_throughput": 5571.162321892309,
    "total_throughput": 11929.569422356877,
    "itl": 65.59143917637978,
    "ttft": 279906.95967602025,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 39,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.12069791468558837,
    "arrivals": 99385,
    "finished_requests": 91660,
    "scheduler_time": 96.29907762463523
}
#Debug simulation 
Total elapsed time: 71.29653335688636. Arrivals time: 0.45361924916505814 Scheduler time: 70.56076846038923 Scheduler overhead time: 0.11084869038313627 Adapter cache time: 0.016886629164218903 Engine time: 0.11207294790074229 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-32/adapters_96_slots_32_rate_0.8-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-32/adapters_96_slots_32_rate_0.8-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 8640, 540, 540, 540, 540, 8640, 540, 8640, 540, 135, 8640, 135, 135, 8640, 540, 8640, 540, 8640, 8640, 540, 135, 8640, 540, 135, 135, 540, 8640, 135, 540, 135, 135, 540, 540, 540, 135, 135, 8640, 540, 540, 135, 8640, 8640, 540, 8640, 8640, 540, 8640, 135, 8640, 540, 540, 540, 8640, 8640, 135, 135, 540, 135, 8640, 135, 135, 8640, 135, 540, 540, 135, 540, 8640, 8640, 8640, 540, 8640, 8640, 135, 135, 8640, 540, 8640, 135, 540, 8640, 135, 8640, 540, 135, 8640, 135, 135, 8640, 135, 135, 540]
Prompts retrieved: 298080 . Total input tokens: 66485273 . Total output tokens: 59678888
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 72.15296057518572,
    "estimated_duration": 3600.0321883410693,
    "input_throughput": 6358.563980103861,
    "output_throughput": 5571.130187378163,
    "total_throughput": 11929.694167482023,
    "itl": 65.59185937719218,
    "ttft": 279870.7925759634,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 39,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.12855172798037526,
    "arrivals": 99385,
    "finished_requests": 91661,
    "scheduler_time": 96.30018390604536
}
#Debug simulation 
Total elapsed time: 72.15314173698425. Arrivals time: 0.4591908883303404 Scheduler time: 71.41414407780394 Scheduler overhead time: 0.11486496822908521 Adapter cache time: 0.016991132404655218 Engine time: 0.1062776711769402 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-16/adapters_96_slots_32_rate_0.8-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-16/adapters_96_slots_32_rate_0.8-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 8640, 540, 540, 540, 540, 8640, 540, 8640, 540, 135, 8640, 135, 135, 8640, 540, 8640, 540, 8640, 8640, 540, 135, 8640, 540, 135, 135, 540, 8640, 135, 540, 135, 135, 540, 540, 540, 135, 135, 8640, 540, 540, 135, 8640, 8640, 540, 8640, 8640, 540, 8640, 135, 8640, 540, 540, 540, 8640, 8640, 135, 135, 540, 135, 8640, 135, 135, 8640, 135, 540, 540, 135, 540, 8640, 8640, 8640, 540, 8640, 8640, 135, 135, 8640, 540, 8640, 135, 540, 8640, 135, 8640, 540, 135, 8640, 135, 135, 8640, 135, 135, 540]
Prompts retrieved: 298080 . Total input tokens: 66485273 . Total output tokens: 59678888
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 72.1368720899336,
    "estimated_duration": 3600.059868746093,
    "input_throughput": 6358.515089909599,
    "output_throughput": 5571.087351662745,
    "total_throughput": 11929.602441572344,
    "itl": 65.5914290973378,
    "ttft": 279870.6897317145,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 39,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.11661196150118491,
    "arrivals": 99385,
    "finished_requests": 91661,
    "scheduler_time": 96.30100055949043
}
#Debug simulation 
Total elapsed time: 72.1370582417585. Arrivals time: 0.4546255189925432 Scheduler time: 71.40654535638168 Scheduler overhead time: 0.10998419718816876 Adapter cache time: 0.017451278865337372 Engine time: 0.1066717877984047 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-32/adapters_96_slots_32_rate_0.8-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-32/adapters_96_slots_32_rate_0.8-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 8640, 540, 540, 540, 540, 8640, 540, 8640, 540, 135, 8640, 135, 135, 8640, 540, 8640, 540, 8640, 8640, 540, 135, 8640, 540, 135, 135, 540, 8640, 135, 540, 135, 135, 540, 540, 540, 135, 135, 8640, 540, 540, 135, 8640, 8640, 540, 8640, 8640, 540, 8640, 135, 8640, 540, 540, 540, 8640, 8640, 135, 135, 540, 135, 8640, 135, 135, 8640, 135, 540, 540, 135, 540, 8640, 8640, 8640, 540, 8640, 8640, 135, 135, 8640, 540, 8640, 135, 540, 8640, 135, 8640, 540, 135, 8640, 135, 135, 8640, 135, 135, 540]
Prompts retrieved: 298080 . Total input tokens: 66485273 . Total output tokens: 59678888
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 72.22753284825012,
    "estimated_duration": 3600.0447417014825,
    "input_throughput": 6358.541807783492,
    "output_throughput": 5571.110760840393,
    "total_throughput": 11929.652568623884,
    "itl": 65.59202711902242,
    "ttft": 279870.6986012689,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 39,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.12980926584452385,
    "arrivals": 99385,
    "finished_requests": 91661,
    "scheduler_time": 96.30070011233944
}
#Debug simulation 
Total elapsed time: 72.22772735217586. Arrivals time: 0.46328294090926647 Scheduler time: 71.48156666010618 Scheduler overhead time: 0.11260656686499715 Adapter cache time: 0.017214398831129074 Engine time: 0.11246339464560151 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-8/adapters_96_slots_32_rate_0.8-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-8/adapters_96_slots_32_rate_0.8-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 8640, 540, 540, 540, 540, 8640, 540, 8640, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 8640, 8640, 540, 66, 8640, 540, 66, 66, 540, 8640, 66, 540, 66, 66, 540, 540, 540, 66, 66, 8640, 540, 540, 66, 8640, 8640, 540, 8640, 8640, 540, 8640, 66, 8640, 540, 540, 540, 8640, 8640, 66, 66, 540, 66, 8640, 66, 66, 8640, 66, 540, 540, 66, 540, 8640, 8640, 8640, 540, 8640, 8640, 66, 66, 8640, 540, 8640, 66, 540, 8640, 66, 8640, 540, 66, 8640, 66, 66, 8640, 66, 66, 540]
Prompts retrieved: 295872 . Total input tokens: 65996354 . Total output tokens: 59243662
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 57.60615531587973,
    "estimated_duration": 3599.9985521858675,
    "input_throughput": 6307.436703332221,
    "output_throughput": 5637.134211534049,
    "total_throughput": 11944.570914866272,
    "itl": 66.91640720475564,
    "ttft": 247136.11483511864,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 50,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.15302438719663758,
    "arrivals": 98626,
    "finished_requests": 91862,
    "scheduler_time": 94.17695552152888
}
#Debug simulation 
Total elapsed time: 57.60629963316023. Arrivals time: 0.4217002261430025 Scheduler time: 56.936614889185876 Scheduler overhead time: 0.09769781259819865 Adapter cache time: 0.015218673273921013 Engine time: 0.0961919603869319 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-16/adapters_96_slots_32_rate_0.8-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-16/adapters_96_slots_32_rate_0.8-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 8640, 540, 540, 540, 540, 8640, 540, 8640, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 8640, 8640, 540, 66, 8640, 540, 66, 66, 540, 8640, 66, 540, 66, 66, 540, 540, 540, 66, 66, 8640, 540, 540, 66, 8640, 8640, 540, 8640, 8640, 540, 8640, 66, 8640, 540, 540, 540, 8640, 8640, 66, 66, 540, 66, 8640, 66, 66, 8640, 66, 540, 540, 66, 540, 8640, 8640, 8640, 540, 8640, 8640, 66, 66, 8640, 540, 8640, 66, 540, 8640, 66, 8640, 540, 66, 8640, 66, 66, 8640, 66, 66, 540]
Prompts retrieved: 295872 . Total input tokens: 65996354 . Total output tokens: 59243662
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 58.32358405785635,
    "estimated_duration": 3600.044238194771,
    "input_throughput": 6307.3569371987005,
    "output_throughput": 5637.123228845738,
    "total_throughput": 11944.480166044437,
    "itl": 66.91685527714148,
    "ttft": 247099.86135806772,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 50,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.16012599302455782,
    "arrivals": 98626,
    "finished_requests": 91863,
    "scheduler_time": 94.17863610988914
}
#Debug simulation 
Total elapsed time: 58.32374380575493. Arrivals time: 0.42179724713787436 Scheduler time: 57.64938163757324 Scheduler overhead time: 0.09864064492285252 Adapter cache time: 0.015824722591787577 Engine time: 0.09889085358008742 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-32/adapters_96_slots_32_rate_0.8-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-32/adapters_96_slots_32_rate_0.8-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 8640, 540, 540, 540, 540, 8640, 540, 8640, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 8640, 8640, 540, 66, 8640, 540, 66, 66, 540, 8640, 66, 540, 66, 66, 540, 540, 540, 66, 66, 8640, 540, 540, 66, 8640, 8640, 540, 8640, 8640, 540, 8640, 66, 8640, 540, 540, 540, 8640, 8640, 66, 66, 540, 66, 8640, 66, 66, 8640, 66, 540, 540, 66, 540, 8640, 8640, 8640, 540, 8640, 8640, 66, 66, 8640, 540, 8640, 66, 540, 8640, 66, 8640, 540, 66, 8640, 66, 66, 8640, 66, 66, 540]
Prompts retrieved: 295872 . Total input tokens: 65996354 . Total output tokens: 59243662
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 58.449306580703706,
    "estimated_duration": 3600.0442345632164,
    "input_throughput": 6307.356943561264,
    "output_throughput": 5637.123234532201,
    "total_throughput": 11944.480178093465,
    "itl": 66.91677847128113,
    "ttft": 247099.84832637655,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 50,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.16094437729567282,
    "arrivals": 98626,
    "finished_requests": 91863,
    "scheduler_time": 94.17860664593474
}
#Debug simulation 
Total elapsed time: 58.44946983177215. Arrivals time: 0.4225256973877549 Scheduler time: 57.77504395600408 Scheduler overhead time: 0.0988255008123815 Adapter cache time: 0.01575982291251421 Engine time: 0.09859390510246158 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-16/adapters_96_slots_32_rate_0.8-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-16/adapters_96_slots_32_rate_0.8-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 8640, 540, 540, 540, 540, 8640, 540, 8640, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 8640, 8640, 540, 66, 8640, 540, 66, 66, 540, 8640, 66, 540, 66, 66, 540, 540, 540, 66, 66, 8640, 540, 540, 66, 8640, 8640, 540, 8640, 8640, 540, 8640, 66, 8640, 540, 540, 540, 8640, 8640, 66, 66, 540, 66, 8640, 66, 66, 8640, 66, 540, 540, 66, 540, 8640, 8640, 8640, 540, 8640, 8640, 66, 66, 8640, 540, 8640, 66, 540, 8640, 66, 8640, 540, 66, 8640, 66, 66, 8640, 66, 66, 540]
Prompts retrieved: 295872 . Total input tokens: 65996354 . Total output tokens: 59243662
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 59.24439555918798,
    "estimated_duration": 3600.0025342529784,
    "input_throughput": 6307.42972649373,
    "output_throughput": 5637.127976136566,
    "total_throughput": 11944.557702630296,
    "itl": 66.91643690472064,
    "ttft": 247136.17560585047,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 50,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.1552228492032737,
    "arrivals": 98626,
    "finished_requests": 91862,
    "scheduler_time": 94.17706548547542
}
#Debug simulation 
Total elapsed time: 59.24457852030173. Arrivals time: 0.4287982117384672 Scheduler time: 58.55990303028375 Scheduler overhead time: 0.1019490803591907 Adapter cache time: 0.016332038678228855 Engine time: 0.09813617449253798 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-32/adapters_96_slots_32_rate_0.8-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-32/adapters_96_slots_32_rate_0.8-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 8640, 540, 540, 540, 540, 8640, 540, 8640, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 8640, 8640, 540, 66, 8640, 540, 66, 66, 540, 8640, 66, 540, 66, 66, 540, 540, 540, 66, 66, 8640, 540, 540, 66, 8640, 8640, 540, 8640, 8640, 540, 8640, 66, 8640, 540, 540, 540, 8640, 8640, 66, 66, 540, 66, 8640, 66, 66, 8640, 66, 540, 540, 66, 540, 8640, 8640, 8640, 540, 8640, 8640, 66, 66, 8640, 540, 8640, 66, 540, 8640, 66, 8640, 540, 66, 8640, 66, 66, 8640, 66, 66, 540]
Prompts retrieved: 295872 . Total input tokens: 65996354 . Total output tokens: 59243662
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 58.89030133606866,
    "estimated_duration": 3600.044218583716,
    "input_throughput": 6307.356971557701,
    "output_throughput": 5637.123259553675,
    "total_throughput": 11944.480231111376,
    "itl": 66.9167248132948,
    "ttft": 247099.853055173,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 50,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.16245342273265112,
    "arrivals": 98626,
    "finished_requests": 91863,
    "scheduler_time": 94.17856586950968
}
#Debug simulation 
Total elapsed time: 58.890492003876716. Arrivals time: 0.42505611712113023 Scheduler time: 58.21190879447386 Scheduler overhead time: 0.10050785401836038 Adapter cache time: 0.015765853691846132 Engine time: 0.09806850925087929 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-16/adapters_96_slots_32_rate_0.8-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-16/adapters_96_slots_32_rate_0.8-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 8640, 540, 540, 540, 540, 8640, 540, 8640, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 8640, 8640, 540, 66, 8640, 540, 66, 66, 540, 8640, 66, 540, 66, 66, 540, 540, 540, 66, 66, 8640, 540, 540, 66, 8640, 8640, 540, 8640, 8640, 540, 8640, 66, 8640, 540, 540, 540, 8640, 8640, 66, 66, 540, 66, 8640, 66, 66, 8640, 66, 540, 540, 66, 540, 8640, 8640, 8640, 540, 8640, 8640, 66, 66, 8640, 540, 8640, 66, 540, 8640, 66, 8640, 540, 66, 8640, 66, 66, 8640, 66, 66, 540]
Prompts retrieved: 295872 . Total input tokens: 65996354 . Total output tokens: 59243662
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 58.909259701147676,
    "estimated_duration": 3600.051280708912,
    "input_throughput": 6307.344598582676,
    "output_throughput": 5637.11220135836,
    "total_throughput": 11944.456799941036,
    "itl": 66.91619870118434,
    "ttft": 247099.68614688722,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 50,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.1495025147451089,
    "arrivals": 98626,
    "finished_requests": 91863,
    "scheduler_time": 94.17856415709853
}
#Debug simulation 
Total elapsed time: 58.90950396610424. Arrivals time: 0.42185792000964284 Scheduler time: 58.235010074451566 Scheduler overhead time: 0.09924679202958941 Adapter cache time: 0.016125132329761982 Engine time: 0.09852695744484663 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-32/adapters_96_slots_32_rate_0.8-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-32/adapters_96_slots_32_rate_0.8-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 8640, 540, 540, 540, 540, 8640, 540, 8640, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 8640, 8640, 540, 66, 8640, 540, 66, 66, 540, 8640, 66, 540, 66, 66, 540, 540, 540, 66, 66, 8640, 540, 540, 66, 8640, 8640, 540, 8640, 8640, 540, 8640, 66, 8640, 540, 540, 540, 8640, 8640, 66, 66, 540, 66, 8640, 66, 66, 8640, 66, 540, 540, 66, 540, 8640, 8640, 8640, 540, 8640, 8640, 66, 66, 8640, 540, 8640, 66, 540, 8640, 66, 8640, 540, 66, 8640, 66, 66, 8640, 66, 66, 540]
Prompts retrieved: 295872 . Total input tokens: 65996354 . Total output tokens: 59243662
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 58.3850824451074,
    "estimated_duration": 3600.0443708785856,
    "input_throughput": 6307.356704733738,
    "output_throughput": 5637.123021083016,
    "total_throughput": 11944.479725816755,
    "itl": 66.91665295104875,
    "ttft": 247099.8288257225,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 50,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.16421397574245913,
    "arrivals": 98626,
    "finished_requests": 91863,
    "scheduler_time": 94.17854108180627
}
#Debug simulation 
Total elapsed time: 58.38529038010165. Arrivals time: 0.4245529742911458 Scheduler time: 57.707629883196205 Scheduler overhead time: 0.10040481155738235 Adapter cache time: 0.015757028479129076 Engine time: 0.09821261186152697 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-8/adapters_96_slots_32_rate_0.8-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-8/adapters_96_slots_32_rate_0.8-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 8640, 540, 540, 540, 540, 8640, 540, 8640, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 8640, 8640, 540, 33, 8640, 540, 33, 33, 540, 8640, 33, 540, 33, 33, 540, 540, 540, 33, 33, 8640, 540, 540, 33, 8640, 8640, 540, 8640, 8640, 540, 8640, 33, 8640, 540, 540, 540, 8640, 8640, 33, 33, 540, 33, 8640, 33, 33, 8640, 33, 540, 540, 33, 540, 8640, 8640, 8640, 540, 8640, 8640, 33, 33, 8640, 540, 8640, 33, 540, 8640, 33, 8640, 540, 33, 8640, 33, 33, 8640, 33, 33, 540]
Prompts retrieved: 294816 . Total input tokens: 65753074 . Total output tokens: 59033708
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 54.87144141783938,
    "estimated_duration": 3600.026425002271,
    "input_throughput": 6383.016480215282,
    "output_throughput": 5582.612633180136,
    "total_throughput": 11965.629113395418,
    "itl": 65.48617676099383,
    "ttft": 235441.58393986794,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 46,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.14078243622090658,
    "arrivals": 98351,
    "finished_requests": 91920,
    "scheduler_time": 92.0750462952123
}
#Debug simulation 
Total elapsed time: 54.87158974073827. Arrivals time: 0.41540429508313537 Scheduler time: 54.20817261515185 Scheduler overhead time: 0.09748705150559545 Adapter cache time: 0.016485813073813915 Engine time: 0.09522731881588697 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-16/adapters_96_slots_32_rate_0.8-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-16/adapters_96_slots_32_rate_0.8-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 8640, 540, 540, 540, 540, 8640, 540, 8640, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 8640, 8640, 540, 33, 8640, 540, 33, 33, 540, 8640, 33, 540, 33, 33, 540, 540, 540, 33, 33, 8640, 540, 540, 33, 8640, 8640, 540, 8640, 8640, 540, 8640, 33, 8640, 540, 540, 540, 8640, 8640, 33, 33, 540, 33, 8640, 33, 33, 8640, 33, 540, 540, 33, 540, 8640, 8640, 8640, 540, 8640, 8640, 33, 33, 8640, 540, 8640, 33, 540, 8640, 33, 8640, 540, 33, 8640, 33, 33, 8640, 33, 33, 540]
Prompts retrieved: 294816 . Total input tokens: 65753074 . Total output tokens: 59033708
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 54.108238972723484,
    "estimated_duration": 3600.0603040231526,
    "input_throughput": 6382.956411680213,
    "output_throughput": 5582.560096990739,
    "total_throughput": 11965.516508670953,
    "itl": 65.48622832399548,
    "ttft": 235509.97846607963,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 46,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.14775719652650882,
    "arrivals": 98351,
    "finished_requests": 91920,
    "scheduler_time": 92.07621657695134
}
#Debug simulation 
Total elapsed time: 54.108497893903404. Arrivals time: 0.41719076316803694 Scheduler time: 53.43976816581562 Scheduler overhead time: 0.10022961487993598 Adapter cache time: 0.01530496310442686 Engine time: 0.09681586269289255 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-32/adapters_96_slots_32_rate_0.8-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-32/adapters_96_slots_32_rate_0.8-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 8640, 540, 540, 540, 540, 8640, 540, 8640, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 8640, 8640, 540, 33, 8640, 540, 33, 33, 540, 8640, 33, 540, 33, 33, 540, 540, 540, 33, 33, 8640, 540, 540, 33, 8640, 8640, 540, 8640, 8640, 540, 8640, 33, 8640, 540, 540, 540, 8640, 8640, 33, 33, 540, 33, 8640, 33, 33, 8640, 33, 540, 540, 33, 540, 8640, 8640, 8640, 540, 8640, 8640, 33, 33, 8640, 540, 8640, 33, 540, 8640, 33, 8640, 540, 33, 8640, 33, 33, 8640, 33, 33, 540]
Prompts retrieved: 294816 . Total input tokens: 65753074 . Total output tokens: 59033708
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 54.42480320110917,
    "estimated_duration": 3600.0603141782317,
    "input_throughput": 6382.956393675118,
    "output_throughput": 5582.560081243409,
    "total_throughput": 11965.516474918528,
    "itl": 65.4861773614223,
    "ttft": 235509.9544895139,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 46,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.14843305440619584,
    "arrivals": 98351,
    "finished_requests": 91920,
    "scheduler_time": 92.07618669949561
}
#Debug simulation 
Total elapsed time: 54.42495945608243. Arrivals time: 0.4168551512993872 Scheduler time: 53.758058917243034 Scheduler overhead time: 0.09919675858691335 Adapter cache time: 0.014814909547567368 Engine time: 0.09686042368412018 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-16/adapters_96_slots_32_rate_0.8-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-16/adapters_96_slots_32_rate_0.8-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 8640, 540, 540, 540, 540, 8640, 540, 8640, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 8640, 8640, 540, 33, 8640, 540, 33, 33, 540, 8640, 33, 540, 33, 33, 540, 540, 540, 33, 33, 8640, 540, 540, 33, 8640, 8640, 540, 8640, 8640, 540, 8640, 33, 8640, 540, 540, 540, 8640, 8640, 33, 33, 540, 33, 8640, 33, 33, 8640, 33, 540, 540, 33, 540, 8640, 8640, 8640, 540, 8640, 8640, 33, 33, 8640, 540, 8640, 33, 540, 8640, 33, 8640, 540, 33, 8640, 33, 33, 8640, 33, 33, 540]
Prompts retrieved: 294816 . Total input tokens: 65753074 . Total output tokens: 59033708
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 53.91093401610851,
    "estimated_duration": 3600.0408606398246,
    "input_throughput": 6382.990885252343,
    "output_throughput": 5582.590247719611,
    "total_throughput": 11965.581132971955,
    "itl": 65.48619538379172,
    "ttft": 235475.86049043585,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 46,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.14367124334210535,
    "arrivals": 98351,
    "finished_requests": 91920,
    "scheduler_time": 92.07554490135767
}
#Debug simulation 
Total elapsed time: 53.91111602401361. Arrivals time: 0.4078523851931095 Scheduler time: 53.25305354781449 Scheduler overhead time: 0.09886896377429366 Adapter cache time: 0.015508600510656834 Engine time: 0.0963312853127718 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-32/adapters_96_slots_32_rate_0.8-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-32/adapters_96_slots_32_rate_0.8-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 8640, 540, 540, 540, 540, 8640, 540, 8640, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 8640, 8640, 540, 33, 8640, 540, 33, 33, 540, 8640, 33, 540, 33, 33, 540, 540, 540, 33, 33, 8640, 540, 540, 33, 8640, 8640, 540, 8640, 8640, 540, 8640, 33, 8640, 540, 540, 540, 8640, 8640, 33, 33, 540, 33, 8640, 33, 33, 8640, 33, 540, 540, 33, 540, 8640, 8640, 8640, 540, 8640, 8640, 33, 33, 8640, 540, 8640, 33, 540, 8640, 33, 8640, 540, 33, 8640, 33, 33, 8640, 33, 33, 540]
Prompts retrieved: 294816 . Total input tokens: 65753074 . Total output tokens: 59033708
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 54.66210554493591,
    "estimated_duration": 3600.067375868066,
    "input_throughput": 6382.943873226591,
    "output_throughput": 5582.549130807303,
    "total_throughput": 11965.493004033893,
    "itl": 65.486315048287,
    "ttft": 235509.97780669233,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 46,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.14969059227034442,
    "arrivals": 98351,
    "finished_requests": 91920,
    "scheduler_time": 92.07647572251896
}
#Debug simulation 
Total elapsed time: 54.662262581754476. Arrivals time: 0.41341256676241755 Scheduler time: 53.99660087423399 Scheduler overhead time: 0.0986115112900734 Adapter cache time: 0.015417714603245258 Engine time: 0.0997233740054071 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-16/adapters_96_slots_32_rate_0.8-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-16/adapters_96_slots_32_rate_0.8-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 8640, 540, 540, 540, 540, 8640, 540, 8640, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 8640, 8640, 540, 33, 8640, 540, 33, 33, 540, 8640, 33, 540, 33, 33, 540, 540, 540, 33, 33, 8640, 540, 540, 33, 8640, 8640, 540, 8640, 8640, 540, 8640, 33, 8640, 540, 540, 540, 8640, 8640, 33, 33, 540, 33, 8640, 33, 33, 8640, 33, 540, 540, 33, 540, 8640, 8640, 8640, 540, 8640, 8640, 33, 33, 8640, 540, 8640, 33, 540, 8640, 33, 8640, 540, 33, 8640, 33, 33, 8640, 33, 33, 540]
Prompts retrieved: 294816 . Total input tokens: 65753074 . Total output tokens: 59033708
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 53.97324596811086,
    "estimated_duration": 3600.0080898157958,
    "input_throughput": 6383.048989530405,
    "output_throughput": 5582.6410659617,
    "total_throughput": 11965.690055492107,
    "itl": 65.48583219733003,
    "ttft": 235407.29422548594,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 46,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.13754231356550017,
    "arrivals": 98351,
    "finished_requests": 91920,
    "scheduler_time": 92.07441669645954
}
#Debug simulation 
Total elapsed time: 53.9734237450175. Arrivals time: 0.4126240420155227 Scheduler time: 53.31370828067884 Scheduler overhead time: 0.0978985084220767 Adapter cache time: 0.015260280575603247 Engine time: 0.09494435274973512 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-32/adapters_96_slots_32_rate_0.8-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-32/adapters_96_slots_32_rate_0.8-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 8640, 540, 540, 540, 540, 8640, 540, 8640, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 8640, 8640, 540, 33, 8640, 540, 33, 33, 540, 8640, 33, 540, 33, 33, 540, 540, 540, 33, 33, 8640, 540, 540, 33, 8640, 8640, 540, 8640, 8640, 540, 8640, 33, 8640, 540, 540, 540, 8640, 8640, 33, 33, 540, 33, 8640, 33, 33, 8640, 33, 540, 540, 33, 540, 8640, 8640, 8640, 540, 8640, 8640, 33, 33, 8640, 540, 8640, 33, 540, 8640, 33, 8640, 540, 33, 8640, 33, 33, 8640, 33, 33, 540]
Prompts retrieved: 294816 . Total input tokens: 65753074 . Total output tokens: 59033708
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 54.4864722318016,
    "estimated_duration": 3600.067761825469,
    "input_throughput": 6382.94318892157,
    "output_throughput": 5582.548532311301,
    "total_throughput": 11965.491721232871,
    "itl": 65.48618810103729,
    "ttft": 235509.97474853683,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 46,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.15157689906656732,
    "arrivals": 98351,
    "finished_requests": 91920,
    "scheduler_time": 92.07644900514248
}
#Debug simulation 
Total elapsed time: 54.48664923105389. Arrivals time: 0.42000528052449226 Scheduler time: 53.81435773521662 Scheduler overhead time: 0.09932465851306915 Adapter cache time: 0.015593442134559155 Engine time: 0.09809803683310747 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-8/adapters_96_slots_32_rate_0.8-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-8/adapters_96_slots_32_rate_0.8-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 8640, 270, 270, 270, 270, 8640, 270, 8640, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 8640, 8640, 270, 135, 8640, 270, 135, 135, 270, 8640, 135, 270, 135, 135, 270, 270, 270, 135, 135, 8640, 270, 270, 135, 8640, 8640, 270, 8640, 8640, 270, 8640, 135, 8640, 270, 270, 270, 8640, 8640, 135, 135, 270, 135, 8640, 135, 135, 8640, 135, 270, 270, 135, 270, 8640, 8640, 8640, 270, 8640, 8640, 135, 135, 8640, 270, 8640, 135, 270, 8640, 135, 8640, 270, 135, 8640, 135, 135, 8640, 135, 135, 270]
Prompts retrieved: 289440 . Total input tokens: 64589415 . Total output tokens: 57941137
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 38.617635092232376,
    "estimated_duration": 3600.018556479888,
    "input_throughput": 6342.380363262874,
    "output_throughput": 5609.861361311243,
    "total_throughput": 11952.241724574116,
    "itl": 66.04944367277419,
    "ttft": 181183.07534476783,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 44,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.13466146073304108,
    "arrivals": 96609,
    "finished_requests": 91745,
    "scheduler_time": 87.1455512984476
}
#Debug simulation 
Total elapsed time: 38.61779778730124. Arrivals time: 0.370614864397794 Scheduler time: 38.02189262770116 Scheduler overhead time: 0.08826554473489523 Adapter cache time: 0.01353971054777503 Engine time: 0.08611700357869267 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-16/adapters_96_slots_32_rate_0.8-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-16/adapters_96_slots_32_rate_0.8-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 8640, 270, 270, 270, 270, 8640, 270, 8640, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 8640, 8640, 270, 135, 8640, 270, 135, 135, 270, 8640, 135, 270, 135, 135, 270, 270, 270, 135, 135, 8640, 270, 270, 135, 8640, 8640, 270, 8640, 8640, 270, 8640, 135, 8640, 270, 270, 270, 8640, 8640, 135, 135, 270, 135, 8640, 135, 135, 8640, 135, 270, 270, 135, 270, 8640, 8640, 8640, 270, 8640, 8640, 135, 135, 8640, 270, 8640, 135, 270, 8640, 135, 8640, 270, 135, 8640, 135, 135, 8640, 135, 135, 270]
Prompts retrieved: 289440 . Total input tokens: 64589415 . Total output tokens: 57941137
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 38.75219421507791,
    "estimated_duration": 3600.052019115517,
    "input_throughput": 6342.394187295588,
    "output_throughput": 5609.870049867178,
    "total_throughput": 11952.264237162766,
    "itl": 66.04965825612837,
    "ttft": 181322.76607670222,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 44,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.14177709593670443,
    "arrivals": 96609,
    "finished_requests": 91746,
    "scheduler_time": 87.14659115187754
}
#Debug simulation 
Total elapsed time: 38.752357153221965. Arrivals time: 0.3663795776665211 Scheduler time: 38.16006023623049 Scheduler overhead time: 0.08906836109235883 Adapter cache time: 0.01396970171481371 Engine time: 0.08541124733164907 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-32/adapters_96_slots_32_rate_0.8-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-32/adapters_96_slots_32_rate_0.8-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 8640, 270, 270, 270, 270, 8640, 270, 8640, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 8640, 8640, 270, 135, 8640, 270, 135, 135, 270, 8640, 135, 270, 135, 135, 270, 270, 270, 135, 135, 8640, 270, 270, 135, 8640, 8640, 270, 8640, 8640, 270, 8640, 135, 8640, 270, 270, 270, 8640, 8640, 135, 135, 270, 135, 8640, 135, 135, 8640, 135, 270, 270, 135, 270, 8640, 8640, 8640, 270, 8640, 8640, 135, 135, 8640, 270, 8640, 135, 270, 8640, 135, 8640, 270, 135, 8640, 135, 135, 8640, 135, 135, 270]
Prompts retrieved: 289440 . Total input tokens: 64589415 . Total output tokens: 57941137
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 38.25572981592268,
    "estimated_duration": 3600.051209311327,
    "input_throughput": 6342.395613969013,
    "output_throughput": 5609.871311764859,
    "total_throughput": 11952.266925733871,
    "itl": 66.04960126785059,
    "ttft": 181322.74853123995,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 44,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.14234601670876143,
    "arrivals": 96609,
    "finished_requests": 91746,
    "scheduler_time": 87.14653668227828
}
#Debug simulation 
Total elapsed time: 38.25587652716786. Arrivals time: 0.35425429604947567 Scheduler time: 37.679639528505504 Scheduler overhead time: 0.08661150326952338 Adapter cache time: 0.014023131225258112 Engine time: 0.08428895706310868 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-16/adapters_96_slots_32_rate_0.8-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-16/adapters_96_slots_32_rate_0.8-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 8640, 270, 270, 270, 270, 8640, 270, 8640, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 8640, 8640, 270, 135, 8640, 270, 135, 135, 270, 8640, 135, 270, 135, 135, 270, 270, 270, 135, 135, 8640, 270, 270, 135, 8640, 8640, 270, 8640, 8640, 270, 8640, 135, 8640, 270, 270, 270, 8640, 8640, 135, 135, 270, 135, 8640, 135, 135, 8640, 135, 270, 270, 135, 270, 8640, 8640, 8640, 270, 8640, 8640, 135, 135, 8640, 270, 8640, 135, 270, 8640, 135, 8640, 270, 135, 8640, 135, 135, 8640, 135, 135, 270]
Prompts retrieved: 289440 . Total input tokens: 64589415 . Total output tokens: 57941137
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 38.95023624273017,
    "estimated_duration": 3600.0189599534006,
    "input_throughput": 6342.3796524381505,
    "output_throughput": 5609.860732583868,
    "total_throughput": 11952.240385022018,
    "itl": 66.0493727584016,
    "ttft": 181183.06860867128,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 44,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.13646535679697994,
    "arrivals": 96609,
    "finished_requests": 91745,
    "scheduler_time": 87.14550813626958
}
#Debug simulation 
Total elapsed time: 38.95038706390187. Arrivals time: 0.3675538254901767 Scheduler time: 38.35592334391549 Scheduler overhead time: 0.08914111601188779 Adapter cache time: 0.013405975885689259 Engine time: 0.08715629298239946 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-32/adapters_96_slots_32_rate_0.8-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-32/adapters_96_slots_32_rate_0.8-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 8640, 270, 270, 270, 270, 8640, 270, 8640, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 8640, 8640, 270, 135, 8640, 270, 135, 135, 270, 8640, 135, 270, 135, 135, 270, 270, 270, 135, 135, 8640, 270, 270, 135, 8640, 8640, 270, 8640, 8640, 270, 8640, 135, 8640, 270, 270, 270, 8640, 8640, 135, 135, 270, 135, 8640, 135, 135, 8640, 135, 270, 270, 135, 270, 8640, 8640, 8640, 270, 8640, 8640, 135, 135, 8640, 270, 8640, 135, 270, 8640, 135, 8640, 270, 135, 8640, 135, 135, 8640, 135, 135, 270]
Prompts retrieved: 289440 . Total input tokens: 64589415 . Total output tokens: 57941137
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 38.78686609212309,
    "estimated_duration": 3600.0524136911486,
    "input_throughput": 6342.393492151767,
    "output_throughput": 5609.869435010014,
    "total_throughput": 11952.26292716178,
    "itl": 66.04951332619044,
    "ttft": 181322.79041208667,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 44,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.14398081593215462,
    "arrivals": 96609,
    "finished_requests": 91746,
    "scheduler_time": 87.14655868301064
}
#Debug simulation 
Total elapsed time: 38.786994421854615. Arrivals time: 0.3654538616538048 Scheduler time: 38.196564830839634 Scheduler overhead time: 0.08680777344852686 Adapter cache time: 0.014321482740342617 Engine time: 0.0867361226119101 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-16/adapters_96_slots_32_rate_0.8-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-16/adapters_96_slots_32_rate_0.8-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 8640, 270, 270, 270, 270, 8640, 270, 8640, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 8640, 8640, 270, 135, 8640, 270, 135, 135, 270, 8640, 135, 270, 135, 135, 270, 270, 270, 135, 135, 8640, 270, 270, 135, 8640, 8640, 270, 8640, 8640, 270, 8640, 135, 8640, 270, 270, 270, 8640, 8640, 135, 135, 270, 135, 8640, 135, 135, 8640, 135, 270, 270, 135, 270, 8640, 8640, 8640, 270, 8640, 8640, 135, 135, 8640, 270, 8640, 135, 270, 8640, 135, 8640, 270, 135, 8640, 135, 135, 8640, 135, 135, 270]
Prompts retrieved: 289440 . Total input tokens: 64589415 . Total output tokens: 57941137
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 38.71374343987554,
    "estimated_duration": 3600.018119237197,
    "input_throughput": 6342.381133581069,
    "output_throughput": 5609.862042660835,
    "total_throughput": 11952.243176241904,
    "itl": 66.04970678757302,
    "ttft": 181183.23797700112,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 44,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.1315622129756958,
    "arrivals": 96609,
    "finished_requests": 91745,
    "scheduler_time": 87.14561671969288
}
#Debug simulation 
Total elapsed time: 38.713892893865705. Arrivals time: 0.3681307816877961 Scheduler time: 38.117589129600674 Scheduler overhead time: 0.08976974943652749 Adapter cache time: 0.014008351135998964 Engine time: 0.08703065337613225 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-32/adapters_96_slots_32_rate_0.8-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-32/adapters_96_slots_32_rate_0.8-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 8640, 270, 270, 270, 270, 8640, 270, 8640, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 8640, 8640, 270, 135, 8640, 270, 135, 135, 270, 8640, 135, 270, 135, 135, 270, 270, 270, 135, 135, 8640, 270, 270, 135, 8640, 8640, 270, 8640, 8640, 270, 8640, 135, 8640, 270, 270, 270, 8640, 8640, 135, 135, 270, 135, 8640, 135, 135, 8640, 135, 270, 270, 135, 270, 8640, 8640, 8640, 270, 8640, 8640, 135, 135, 8640, 270, 8640, 135, 270, 8640, 135, 8640, 270, 135, 8640, 135, 135, 8640, 135, 135, 270]
Prompts retrieved: 289440 . Total input tokens: 64589415 . Total output tokens: 57941137
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 38.632196481805295,
    "estimated_duration": 3600.060173476874,
    "input_throughput": 6342.379821376248,
    "output_throughput": 5609.857343160805,
    "total_throughput": 11952.237164537053,
    "itl": 66.04959638978664,
    "ttft": 181322.82472056733,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 44,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.1454898613691329,
    "arrivals": 96609,
    "finished_requests": 91746,
    "scheduler_time": 87.14682138987537
}
#Debug simulation 
Total elapsed time: 38.63237155787647. Arrivals time: 0.3713525254279375 Scheduler time: 38.035683173686266 Scheduler overhead time: 0.08857698272913694 Adapter cache time: 0.013641967438161373 Engine time: 0.08578817127272487 
