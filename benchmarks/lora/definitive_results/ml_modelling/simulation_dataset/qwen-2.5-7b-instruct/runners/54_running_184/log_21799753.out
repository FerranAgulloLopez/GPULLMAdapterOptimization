INFO 06-01 00:47:02 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:47:02 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_128_slots_32_rate_0.4-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_128_slots_32_rate_0.4-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 66, 4320, 4320, 33, 33, 4320, 33, 66, 66, 66, 33, 4320, 66, 33, 4320, 66, 33, 33, 33, 33, 66, 66, 4320, 66, 33, 66, 66, 66, 66, 4320, 66, 33, 66, 33, 4320, 4320, 33, 66, 66, 33, 66, 33, 66, 66, 4320, 4320, 4320, 4320, 66, 66, 33, 66, 4320, 4320, 66, 33, 33, 33, 4320, 66, 66, 66, 66, 4320, 66, 4320, 33, 33, 66, 33, 4320, 4320, 33, 33, 66, 66, 66, 33, 4320, 33, 4320, 66, 33, 4320, 4320, 66, 66, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 66, 4320, 4320, 66, 4320, 33, 66, 4320, 33, 4320, 66, 33, 66, 66, 4320, 4320, 33, 33, 4320, 33, 33, 33, 66, 33]
Prompts retrieved: 189984 . Total input tokens: 42380508 . Total output tokens: 37972669
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 8.310711836908013,
    "estimated_duration": 3600.020576719785,
    "input_throughput": 4401.304843217654,
    "output_throughput": 3864.4748560510475,
    "total_throughput": 8265.779699268702,
    "itl": 41.41593593230846,
    "ttft": 42974.763526906485,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1507,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.728690242967476,
    "arrivals": 63755,
    "finished_requests": 63294,
    "scheduler_time": 44.51321741943833
}
#Debug simulation 
Total elapsed time: 8.310817972989753. Arrivals time: 0.17541091912426054 Scheduler time: 7.851887048222125 Scheduler overhead time: 0.10815206565894186 Adapter cache time: 0.026513952063396573 Engine time: 0.10186353139579296 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-32/adapters_128_slots_32_rate_0.4-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-32/adapters_128_slots_32_rate_0.4-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 66, 4320, 4320, 33, 33, 4320, 33, 66, 66, 66, 33, 4320, 66, 33, 4320, 66, 33, 33, 33, 33, 66, 66, 4320, 66, 33, 66, 66, 66, 66, 4320, 66, 33, 66, 33, 4320, 4320, 33, 66, 66, 33, 66, 33, 66, 66, 4320, 4320, 4320, 4320, 66, 66, 33, 66, 4320, 4320, 66, 33, 33, 33, 4320, 66, 66, 66, 66, 4320, 66, 4320, 33, 33, 66, 33, 4320, 4320, 33, 33, 66, 66, 66, 33, 4320, 33, 4320, 66, 33, 4320, 4320, 66, 66, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 66, 4320, 4320, 66, 4320, 33, 66, 4320, 33, 4320, 66, 33, 66, 66, 4320, 4320, 33, 33, 4320, 33, 33, 33, 66, 33]
Prompts retrieved: 189984 . Total input tokens: 42380508 . Total output tokens: 37972669
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 8.206324940081686,
    "estimated_duration": 3600.0115412410078,
    "input_throughput": 4400.602003219917,
    "output_throughput": 3863.3665033211346,
    "total_throughput": 8263.968506541052,
    "itl": 41.51633346620531,
    "ttft": 42496.19926332194,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1523,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.037529955878809,
    "arrivals": 63755,
    "finished_requests": 63297,
    "scheduler_time": 44.4563268261843
}
#Debug simulation 
Total elapsed time: 8.206458617001772. Arrivals time: 0.17266568215563893 Scheduler time: 7.748935231007636 Scheduler overhead time: 0.10929111251607537 Adapter cache time: 0.02673130016773939 Engine time: 0.10166610381565988 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_128_slots_32_rate_0.4-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_128_slots_32_rate_0.4-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 66, 4320, 4320, 33, 33, 4320, 33, 66, 66, 66, 33, 4320, 66, 33, 4320, 66, 33, 33, 33, 33, 66, 66, 4320, 66, 33, 66, 66, 66, 66, 4320, 66, 33, 66, 33, 4320, 4320, 33, 66, 66, 33, 66, 33, 66, 66, 4320, 4320, 4320, 4320, 66, 66, 33, 66, 4320, 4320, 66, 33, 33, 33, 4320, 66, 66, 66, 66, 4320, 66, 4320, 33, 33, 66, 33, 4320, 4320, 33, 33, 66, 66, 66, 33, 4320, 33, 4320, 66, 33, 4320, 4320, 66, 66, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 66, 4320, 4320, 66, 4320, 33, 66, 4320, 33, 4320, 66, 33, 66, 66, 4320, 4320, 33, 33, 4320, 33, 33, 33, 66, 33]
Prompts retrieved: 189984 . Total input tokens: 42380508 . Total output tokens: 37972669
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 8.32404024200514,
    "estimated_duration": 3600.028886378789,
    "input_throughput": 4397.028329381703,
    "output_throughput": 3865.7298147400766,
    "total_throughput": 8262.758144121779,
    "itl": 41.47164156395856,
    "ttft": 46536.41567975436,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1489,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.452184889109218,
    "arrivals": 63755,
    "finished_requests": 63238,
    "scheduler_time": 44.55400515735188
}
#Debug simulation 
Total elapsed time: 8.32418693578802. Arrivals time: 0.17435760493390262 Scheduler time: 7.863925767829642 Scheduler overhead time: 0.11020002840086818 Adapter cache time: 0.026502638356760144 Engine time: 0.10219049197621644 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-32/adapters_128_slots_32_rate_0.4-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-32/adapters_128_slots_32_rate_0.4-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 66, 4320, 4320, 33, 33, 4320, 33, 66, 66, 66, 33, 4320, 66, 33, 4320, 66, 33, 33, 33, 33, 66, 66, 4320, 66, 33, 66, 66, 66, 66, 4320, 66, 33, 66, 33, 4320, 4320, 33, 66, 66, 33, 66, 33, 66, 66, 4320, 4320, 4320, 4320, 66, 66, 33, 66, 4320, 4320, 66, 33, 33, 33, 4320, 66, 66, 66, 66, 4320, 66, 4320, 33, 33, 66, 33, 4320, 4320, 33, 33, 66, 66, 66, 33, 4320, 33, 4320, 66, 33, 4320, 4320, 66, 66, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 66, 4320, 4320, 66, 4320, 33, 66, 4320, 33, 4320, 66, 33, 66, 66, 4320, 4320, 33, 33, 4320, 33, 33, 33, 66, 33]
Prompts retrieved: 189984 . Total input tokens: 42380508 . Total output tokens: 37972669
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 8.194164058892056,
    "estimated_duration": 3600.0332547453636,
    "input_throughput": 4400.575461106552,
    "output_throughput": 3863.343201529328,
    "total_throughput": 8263.91866263588,
    "itl": 41.45188590290176,
    "ttft": 42695.52210401021,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1520,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.094242945164397,
    "arrivals": 63755,
    "finished_requests": 63297,
    "scheduler_time": 44.48485148494784
}
#Debug simulation 
Total elapsed time: 8.194253301015124. Arrivals time: 0.17018488701432943 Scheduler time: 7.741517741931602 Scheduler overhead time: 0.10822041658684611 Adapter cache time: 0.026541183702647686 Engine time: 0.10121311247348785 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_128_slots_32_rate_0.1-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_128_slots_32_rate_0.1-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 270, 270, 1080, 270, 540, 540, 540, 270, 1080, 540, 270, 1080, 540, 270, 270, 270, 270, 540, 540, 1080, 540, 270, 540, 540, 540, 540, 1080, 540, 270, 540, 270, 1080, 1080, 270, 540, 540, 270, 540, 270, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 270, 540, 1080, 1080, 540, 270, 270, 270, 1080, 540, 540, 540, 540, 1080, 540, 1080, 270, 270, 540, 270, 1080, 1080, 270, 270, 540, 540, 540, 270, 1080, 270, 1080, 540, 270, 1080, 1080, 540, 540, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 270, 1080, 270, 270, 1080, 540, 1080, 1080, 540, 1080, 270, 540, 1080, 270, 1080, 540, 270, 540, 540, 1080, 1080, 270, 270, 1080, 270, 270, 270, 540, 270]
Prompts retrieved: 81000 . Total input tokens: 18039508 . Total output tokens: 16188378
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 2.702659334987402,
    "estimated_duration": 3599.9641158460363,
    "input_throughput": 1859.239088117137,
    "output_throughput": 1628.4098428081986,
    "total_throughput": 3487.6489309253357,
    "itl": 27.598041988387955,
    "ttft": 21771.05661141226,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10946,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 33.500098845090065,
    "arrivals": 27111,
    "finished_requests": 26995,
    "scheduler_time": 1.863578622486472
}
#Debug simulation 
Total elapsed time: 2.702748472103849. Arrivals time: 0.07905725296586752 Scheduler time: 2.2347158940974623 Scheduler overhead time: 0.12540688319131732 Adapter cache time: 0.08419147552922368 Engine time: 0.12100138701498508 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_128_slots_32_rate_0.1-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_128_slots_32_rate_0.1-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 270, 270, 1080, 270, 540, 540, 540, 270, 1080, 540, 270, 1080, 540, 270, 270, 270, 270, 540, 540, 1080, 540, 270, 540, 540, 540, 540, 1080, 540, 270, 540, 270, 1080, 1080, 270, 540, 540, 270, 540, 270, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 270, 540, 1080, 1080, 540, 270, 270, 270, 1080, 540, 540, 540, 540, 1080, 540, 1080, 270, 270, 540, 270, 1080, 1080, 270, 270, 540, 540, 540, 270, 1080, 270, 1080, 540, 270, 1080, 1080, 540, 540, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 270, 1080, 270, 270, 1080, 540, 1080, 1080, 540, 1080, 270, 540, 1080, 270, 1080, 540, 270, 540, 540, 1080, 1080, 270, 270, 1080, 270, 270, 270, 540, 270]
Prompts retrieved: 81000 . Total input tokens: 18039508 . Total output tokens: 16188378
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 2.7142674999777228,
    "estimated_duration": 3599.9715601901094,
    "input_throughput": 1859.2352434157958,
    "output_throughput": 1628.406475436274,
    "total_throughput": 3487.6417188520695,
    "itl": 27.61936117160398,
    "ttft": 21796.43896582541,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10919,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 35.65439492780042,
    "arrivals": 27111,
    "finished_requests": 26995,
    "scheduler_time": 1.874747796990334
}
#Debug simulation 
Total elapsed time: 2.7144008490722626. Arrivals time: 0.07962550269439816 Scheduler time: 2.231310620205477 Scheduler overhead time: 0.13282790943048894 Adapter cache time: 0.08593338960781693 Engine time: 0.12476358842104673 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-32/adapters_128_slots_32_rate_0.1-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-32/adapters_128_slots_32_rate_0.1-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 270, 270, 1080, 270, 540, 540, 540, 270, 1080, 540, 270, 1080, 540, 270, 270, 270, 270, 540, 540, 1080, 540, 270, 540, 540, 540, 540, 1080, 540, 270, 540, 270, 1080, 1080, 270, 540, 540, 270, 540, 270, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 270, 540, 1080, 1080, 540, 270, 270, 270, 1080, 540, 540, 540, 540, 1080, 540, 1080, 270, 270, 540, 270, 1080, 1080, 270, 270, 540, 540, 540, 270, 1080, 270, 1080, 540, 270, 1080, 1080, 540, 540, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 270, 1080, 270, 270, 1080, 540, 1080, 1080, 540, 1080, 270, 540, 1080, 270, 1080, 540, 270, 540, 540, 1080, 1080, 270, 270, 1080, 270, 270, 270, 540, 270]
Prompts retrieved: 81000 . Total input tokens: 18039508 . Total output tokens: 16188378
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 2.6776776269543916,
    "estimated_duration": 3599.9726152493977,
    "input_throughput": 1859.234698521814,
    "output_throughput": 1628.405998192261,
    "total_throughput": 3487.640696714075,
    "itl": 27.618516957021747,
    "ttft": 21791.548565536003,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10923,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 35.72717243984713,
    "arrivals": 27111,
    "finished_requests": 26995,
    "scheduler_time": 1.8764010582250514
}
#Debug simulation 
Total elapsed time: 2.6777621409855783. Arrivals time: 0.07806456508114934 Scheduler time: 2.211113641737029 Scheduler overhead time: 0.12459282204508781 Adapter cache time: 0.08417219622060657 Engine time: 0.12108939071185887 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_128_slots_32_rate_0.1-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_128_slots_32_rate_0.1-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 270, 270, 1080, 270, 540, 540, 540, 270, 1080, 540, 270, 1080, 540, 270, 270, 270, 270, 540, 540, 1080, 540, 270, 540, 540, 540, 540, 1080, 540, 270, 540, 270, 1080, 1080, 270, 540, 540, 270, 540, 270, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 270, 540, 1080, 1080, 540, 270, 270, 270, 1080, 540, 540, 540, 540, 1080, 540, 1080, 270, 270, 540, 270, 1080, 1080, 270, 270, 540, 540, 540, 270, 1080, 270, 1080, 540, 270, 1080, 1080, 540, 540, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 270, 1080, 270, 270, 1080, 540, 1080, 1080, 540, 1080, 270, 540, 1080, 270, 1080, 540, 270, 540, 540, 1080, 1080, 270, 270, 1080, 270, 270, 270, 540, 270]
Prompts retrieved: 81000 . Total input tokens: 18039508 . Total output tokens: 16188378
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 2.700814062030986,
    "estimated_duration": 3599.9746264251658,
    "input_throughput": 1859.5342175085068,
    "output_throughput": 1628.0867528836282,
    "total_throughput": 3487.620970392135,
    "itl": 27.58827660741613,
    "ttft": 22269.340420388166,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10400,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 32.62671253453805,
    "arrivals": 27111,
    "finished_requests": 26996,
    "scheduler_time": 1.9184170879728863
}
#Debug simulation 
Total elapsed time: 2.700899052899331. Arrivals time: 0.07915291865356266 Scheduler time: 2.237014559097588 Scheduler overhead time: 0.12395398481748998 Adapter cache time: 0.08200338948518038 Engine time: 0.12034111912362278 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-32/adapters_128_slots_32_rate_0.1-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-32/adapters_128_slots_32_rate_0.1-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 270, 270, 1080, 270, 540, 540, 540, 270, 1080, 540, 270, 1080, 540, 270, 270, 270, 270, 540, 540, 1080, 540, 270, 540, 540, 540, 540, 1080, 540, 270, 540, 270, 1080, 1080, 270, 540, 540, 270, 540, 270, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 270, 540, 1080, 1080, 540, 270, 270, 270, 1080, 540, 540, 540, 540, 1080, 540, 1080, 270, 270, 540, 270, 1080, 1080, 270, 270, 540, 540, 540, 270, 1080, 270, 1080, 540, 270, 1080, 1080, 540, 540, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 270, 1080, 270, 270, 1080, 540, 1080, 1080, 540, 1080, 270, 540, 1080, 270, 1080, 540, 270, 540, 540, 1080, 1080, 270, 270, 1080, 270, 270, 270, 540, 270]
Prompts retrieved: 81000 . Total input tokens: 18039508 . Total output tokens: 16188378
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 2.728767979191616,
    "estimated_duration": 3599.9697576355175,
    "input_throughput": 1859.236174360568,
    "output_throughput": 1628.407290801893,
    "total_throughput": 3487.643465162461,
    "itl": 27.62283992118077,
    "ttft": 21793.617508703315,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10924,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 36.16431802939752,
    "arrivals": 27111,
    "finished_requests": 26995,
    "scheduler_time": 1.8786133781726058
}
#Debug simulation 
Total elapsed time: 2.728899087989703. Arrivals time: 0.07947345660068095 Scheduler time: 2.260139021323994 Scheduler overhead time: 0.12332836352288723 Adapter cache time: 0.08559793187305331 Engine time: 0.12206275318749249 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_128_slots_32_rate_0.1-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_128_slots_32_rate_0.1-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 270, 270, 1080, 270, 540, 540, 540, 270, 1080, 540, 270, 1080, 540, 270, 270, 270, 270, 540, 540, 1080, 540, 270, 540, 540, 540, 540, 1080, 540, 270, 540, 270, 1080, 1080, 270, 540, 540, 270, 540, 270, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 270, 540, 1080, 1080, 540, 270, 270, 270, 1080, 540, 540, 540, 540, 1080, 540, 1080, 270, 270, 540, 270, 1080, 1080, 270, 270, 540, 540, 540, 270, 1080, 270, 1080, 540, 270, 1080, 1080, 540, 540, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 270, 1080, 270, 270, 1080, 540, 1080, 1080, 540, 1080, 270, 540, 1080, 270, 1080, 540, 270, 540, 540, 1080, 1080, 270, 270, 1080, 270, 270, 270, 540, 270]
Prompts retrieved: 81000 . Total input tokens: 18039508 . Total output tokens: 16188378
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 2.72537979320623,
    "estimated_duration": 3599.9684090308638,
    "input_throughput": 1859.2368708596123,
    "output_throughput": 1628.4079008288156,
    "total_throughput": 3487.644771688428,
    "itl": 27.592160473276216,
    "ttft": 21760.125122678382,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10960,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 32.77095123212502,
    "arrivals": 27111,
    "finished_requests": 26995,
    "scheduler_time": 1.8597586707087688
}
#Debug simulation 
Total elapsed time: 2.7254680590704083. Arrivals time: 0.07956088334321976 Scheduler time: 2.256665790453553 Scheduler overhead time: 0.12391559593379498 Adapter cache time: 0.08619089308194816 Engine time: 0.12042440474033356 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-32/adapters_128_slots_32_rate_0.1-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-32/adapters_128_slots_32_rate_0.1-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 270, 270, 1080, 270, 540, 540, 540, 270, 1080, 540, 270, 1080, 540, 270, 270, 270, 270, 540, 540, 1080, 540, 270, 540, 540, 540, 540, 1080, 540, 270, 540, 270, 1080, 1080, 270, 540, 540, 270, 540, 270, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 270, 540, 1080, 1080, 540, 270, 270, 270, 1080, 540, 540, 540, 540, 1080, 540, 1080, 270, 270, 540, 270, 1080, 1080, 270, 270, 540, 540, 540, 270, 1080, 270, 1080, 540, 270, 1080, 1080, 540, 540, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 270, 1080, 270, 270, 1080, 540, 1080, 1080, 540, 1080, 270, 540, 1080, 270, 1080, 540, 270, 540, 540, 1080, 1080, 270, 270, 1080, 270, 270, 270, 540, 270]
Prompts retrieved: 81000 . Total input tokens: 18039508 . Total output tokens: 16188378
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 2.7134938340168446,
    "estimated_duration": 3599.9710750722393,
    "input_throughput": 1859.235493958987,
    "output_throughput": 1628.4066948738928,
    "total_throughput": 3487.6421888328796,
    "itl": 27.627179389993472,
    "ttft": 21807.803005122172,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10922,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 36.65131730042244,
    "arrivals": 27111,
    "finished_requests": 26995,
    "scheduler_time": 1.8836862414941897
}
#Debug simulation 
Total elapsed time: 2.7135799310635775. Arrivals time: 0.07854105671867728 Scheduler time: 2.2495615750085562 Scheduler overhead time: 0.12368088704533875 Adapter cache time: 0.08496474497951567 Engine time: 0.11872199829667807 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_128_slots_32_rate_0.1-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_128_slots_32_rate_0.1-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 135, 135, 1080, 135, 540, 540, 540, 135, 1080, 540, 135, 1080, 540, 135, 135, 135, 135, 540, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 540, 135, 540, 135, 1080, 1080, 135, 540, 540, 135, 540, 135, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 135, 540, 1080, 1080, 540, 135, 135, 135, 1080, 540, 540, 540, 540, 1080, 540, 1080, 135, 135, 540, 135, 1080, 1080, 135, 135, 540, 540, 540, 135, 1080, 135, 1080, 540, 135, 1080, 1080, 540, 540, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 135, 1080, 135, 135, 1080, 540, 1080, 1080, 540, 1080, 135, 540, 1080, 135, 1080, 540, 135, 540, 540, 1080, 1080, 135, 135, 1080, 135, 135, 135, 540, 135]
Prompts retrieved: 75330 . Total input tokens: 16766095 . Total output tokens: 15046268
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 2.4357909820973873,
    "estimated_duration": 3600.0174694677157,
    "input_throughput": 1713.0569649462932,
    "output_throughput": 1531.0075705868537,
    "total_throughput": 3244.0645355331467,
    "itl": 27.257092570382675,
    "ttft": 17558.994811033248,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11719,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 35.865855871148106,
    "arrivals": 25189,
    "finished_requests": 25090,
    "scheduler_time": 0.5888774833225755
}
#Debug simulation 
Total elapsed time: 2.435877912910655. Arrivals time: 0.07483704527840018 Scheduler time: 1.9683721682522446 Scheduler overhead time: 0.12419106694869697 Adapter cache time: 0.08856007782742381 Engine time: 0.12126749218441546 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_128_slots_32_rate_0.1-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_128_slots_32_rate_0.1-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 135, 135, 1080, 135, 540, 540, 540, 135, 1080, 540, 135, 1080, 540, 135, 135, 135, 135, 540, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 540, 135, 540, 135, 1080, 1080, 135, 540, 540, 135, 540, 135, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 135, 540, 1080, 1080, 540, 135, 135, 135, 1080, 540, 540, 540, 540, 1080, 540, 1080, 135, 135, 540, 135, 1080, 1080, 135, 135, 540, 540, 540, 135, 1080, 135, 1080, 540, 135, 1080, 1080, 540, 540, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 135, 1080, 135, 135, 1080, 540, 1080, 1080, 540, 1080, 135, 540, 1080, 135, 1080, 540, 135, 540, 540, 1080, 1080, 135, 135, 1080, 135, 135, 135, 540, 135]
Prompts retrieved: 75330 . Total input tokens: 16766095 . Total output tokens: 15046268
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 2.4568244819529355,
    "estimated_duration": 3600.011499573106,
    "input_throughput": 1713.0598057065358,
    "output_throughput": 1531.0101094548113,
    "total_throughput": 3244.069915161347,
    "itl": 27.27745107184431,
    "ttft": 17574.139268076626,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11698,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 38.20510277012573,
    "arrivals": 25189,
    "finished_requests": 25090,
    "scheduler_time": 0.5948188127948191
}
#Debug simulation 
Total elapsed time: 2.456908536842093. Arrivals time: 0.07483152532950044 Scheduler time: 1.9887207737192512 Scheduler overhead time: 0.1253398978151381 Adapter cache time: 0.08816049015149474 Engine time: 0.12078309548087418 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-32/adapters_128_slots_32_rate_0.1-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-32/adapters_128_slots_32_rate_0.1-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 135, 135, 1080, 135, 540, 540, 540, 135, 1080, 540, 135, 1080, 540, 135, 135, 135, 135, 540, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 540, 135, 540, 135, 1080, 1080, 135, 540, 540, 135, 540, 135, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 135, 540, 1080, 1080, 540, 135, 135, 135, 1080, 540, 540, 540, 540, 1080, 540, 1080, 135, 135, 540, 135, 1080, 1080, 135, 135, 540, 540, 540, 135, 1080, 135, 1080, 540, 135, 1080, 1080, 540, 540, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 135, 1080, 135, 135, 1080, 540, 1080, 1080, 540, 1080, 135, 540, 1080, 135, 1080, 540, 135, 540, 540, 1080, 1080, 135, 135, 1080, 135, 135, 135, 540, 135]
Prompts retrieved: 75330 . Total input tokens: 16766095 . Total output tokens: 15046268
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 2.4950022019911557,
    "estimated_duration": 3600.0101769704174,
    "input_throughput": 1713.0604350651747,
    "output_throughput": 1531.0106719304674,
    "total_throughput": 3244.0711069956424,
    "itl": 27.277428887915864,
    "ttft": 17575.126761926702,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11704,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 38.287623297763496,
    "arrivals": 25189,
    "finished_requests": 25090,
    "scheduler_time": 0.5952547248027569
}
#Debug simulation 
Total elapsed time: 2.495096663944423. Arrivals time: 0.07584883086383343 Scheduler time: 2.0205458868294954 Scheduler overhead time: 0.12665764125995338 Adapter cache time: 0.08934683445841074 Engine time: 0.12298847083002329 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_128_slots_32_rate_0.1-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_128_slots_32_rate_0.1-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 135, 135, 1080, 135, 540, 540, 540, 135, 1080, 540, 135, 1080, 540, 135, 135, 135, 135, 540, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 540, 135, 540, 135, 1080, 1080, 135, 540, 540, 135, 540, 135, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 135, 540, 1080, 1080, 540, 135, 135, 135, 1080, 540, 540, 540, 540, 1080, 540, 1080, 135, 135, 540, 135, 1080, 1080, 135, 135, 540, 540, 540, 135, 1080, 135, 1080, 540, 135, 1080, 1080, 540, 540, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 135, 1080, 135, 135, 1080, 540, 1080, 1080, 540, 1080, 135, 540, 1080, 135, 1080, 540, 135, 540, 540, 1080, 1080, 135, 135, 1080, 135, 135, 135, 540, 135]
Prompts retrieved: 75330 . Total input tokens: 16766095 . Total output tokens: 15046268
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 2.484520578989759,
    "estimated_duration": 3600.020916843492,
    "input_throughput": 1713.0553245249675,
    "output_throughput": 1531.006104495813,
    "total_throughput": 3244.0614290207805,
    "itl": 27.264490340780576,
    "ttft": 17567.58731860714,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11712,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 36.786235210829894,
    "arrivals": 25189,
    "finished_requests": 25090,
    "scheduler_time": 0.5906941239015125
}
#Debug simulation 
Total elapsed time: 2.484610080020502. Arrivals time: 0.07525887317024171 Scheduler time: 2.0163465647492558 Scheduler overhead time: 0.12387678329832852 Adapter cache time: 0.0891898456029594 Engine time: 0.12080815574154258 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-32/adapters_128_slots_32_rate_0.1-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-32/adapters_128_slots_32_rate_0.1-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 135, 135, 1080, 135, 540, 540, 540, 135, 1080, 540, 135, 1080, 540, 135, 135, 135, 135, 540, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 540, 135, 540, 135, 1080, 1080, 135, 540, 540, 135, 540, 135, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 135, 540, 1080, 1080, 540, 135, 135, 135, 1080, 540, 540, 540, 540, 1080, 540, 1080, 135, 135, 540, 135, 1080, 1080, 135, 135, 540, 540, 540, 135, 1080, 135, 1080, 540, 135, 1080, 1080, 540, 540, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 135, 1080, 135, 135, 1080, 540, 1080, 1080, 540, 1080, 135, 540, 1080, 135, 1080, 540, 135, 540, 540, 1080, 1080, 135, 135, 1080, 135, 135, 135, 540, 135]
Prompts retrieved: 75330 . Total input tokens: 16766095 . Total output tokens: 15046268
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 2.4274319829419255,
    "estimated_duration": 3600.0038604295237,
    "input_throughput": 1713.0634407886992,
    "output_throughput": 1531.0133582307863,
    "total_throughput": 3244.0767990194854,
    "itl": 27.282306812553497,
    "ttft": 17575.548136884237,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11698,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 38.71715999370682,
    "arrivals": 25189,
    "finished_requests": 25090,
    "scheduler_time": 0.5958266886609079
}
#Debug simulation 
Total elapsed time: 2.427523462800309. Arrivals time: 0.07501340610906482 Scheduler time: 1.9605575441382825 Scheduler overhead time: 0.12350508756935596 Adapter cache time: 0.08836137433536351 Engine time: 0.12132239528000355 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_128_slots_32_rate_0.1-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_128_slots_32_rate_0.1-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 135, 135, 1080, 135, 540, 540, 540, 135, 1080, 540, 135, 1080, 540, 135, 135, 135, 135, 540, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 540, 135, 540, 135, 1080, 1080, 135, 540, 540, 135, 540, 135, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 135, 540, 1080, 1080, 540, 135, 135, 135, 1080, 540, 540, 540, 540, 1080, 540, 1080, 135, 135, 540, 135, 1080, 1080, 135, 135, 540, 540, 540, 135, 1080, 135, 1080, 540, 135, 1080, 1080, 540, 540, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 135, 1080, 135, 135, 1080, 540, 1080, 1080, 540, 1080, 135, 540, 1080, 135, 1080, 540, 135, 540, 540, 1080, 1080, 135, 135, 1080, 135, 135, 135, 540, 135]
Prompts retrieved: 75330 . Total input tokens: 16766095 . Total output tokens: 15046268
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 2.4400421609170735,
    "estimated_duration": 3600.0160552489124,
    "input_throughput": 1713.0576378981173,
    "output_throughput": 1531.0081720229753,
    "total_throughput": 3244.0658099210928,
    "itl": 27.248471903889616,
    "ttft": 17547.3566462206,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11726,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 35.06132975802205,
    "arrivals": 25189,
    "finished_requests": 25090,
    "scheduler_time": 0.5863255761916727
}
#Debug simulation 
Total elapsed time: 2.440127685898915. Arrivals time: 0.07462738617323339 Scheduler time: 1.9715377036482096 Scheduler overhead time: 0.12511048512533307 Adapter cache time: 0.08832722692750394 Engine time: 0.12145846174098551 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-32/adapters_128_slots_32_rate_0.1-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-32/adapters_128_slots_32_rate_0.1-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 135, 135, 1080, 135, 540, 540, 540, 135, 1080, 540, 135, 1080, 540, 135, 135, 135, 135, 540, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 540, 135, 540, 135, 1080, 1080, 135, 540, 540, 135, 540, 135, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 135, 540, 1080, 1080, 540, 135, 135, 135, 1080, 540, 540, 540, 540, 1080, 540, 1080, 135, 135, 540, 135, 1080, 1080, 135, 135, 540, 540, 540, 135, 1080, 135, 1080, 540, 135, 1080, 1080, 540, 540, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 135, 1080, 135, 135, 1080, 540, 1080, 1080, 540, 1080, 135, 540, 1080, 135, 1080, 540, 135, 540, 540, 1080, 1080, 135, 135, 1080, 135, 135, 135, 540, 135]
Prompts retrieved: 75330 . Total input tokens: 16766095 . Total output tokens: 15046268
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 2.499023713869974,
    "estimated_duration": 3600.014200914214,
    "input_throughput": 1713.058520278586,
    "output_throughput": 1531.0089606314136,
    "total_throughput": 3244.0674809099996,
    "itl": 27.286582304695305,
    "ttft": 17585.415655899746,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11694,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 39.24861953698008,
    "arrivals": 25189,
    "finished_requests": 25090,
    "scheduler_time": 0.5981670864461018
}
#Debug simulation 
Total elapsed time: 2.499117086874321. Arrivals time: 0.07559565221890807 Scheduler time: 2.0283476850017905 Scheduler overhead time: 0.12355194613337517 Adapter cache time: 0.08922321395948529 Engine time: 0.12348420172929764 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_128_slots_32_rate_0.1-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_128_slots_32_rate_0.1-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 66, 66, 1080, 66, 540, 540, 540, 66, 1080, 540, 66, 1080, 540, 66, 66, 66, 66, 540, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 540, 66, 540, 66, 1080, 1080, 66, 540, 540, 66, 540, 66, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 66, 540, 1080, 1080, 540, 66, 66, 66, 1080, 540, 540, 540, 540, 1080, 540, 1080, 66, 66, 540, 66, 1080, 1080, 66, 66, 540, 540, 540, 66, 1080, 66, 1080, 540, 66, 1080, 1080, 540, 540, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 540, 1080, 1080, 540, 1080, 66, 540, 1080, 66, 1080, 540, 66, 540, 540, 1080, 1080, 66, 66, 1080, 66, 66, 66, 540, 66]
Prompts retrieved: 72432 . Total input tokens: 16119817 . Total output tokens: 14474454
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 2.3286436141934246,
    "estimated_duration": 3599.935591915344,
    "input_throughput": 1658.3388362300423,
    "output_throughput": 1474.5811041512745,
    "total_throughput": 3132.919940381317,
    "itl": 26.9980370492788,
    "ttft": 10838.179288906153,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12235,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 37.44506754701609,
    "arrivals": 24288,
    "finished_requests": 24229,
    "scheduler_time": 0.24125306786817957
}
#Debug simulation 
Total elapsed time: 2.3287329140584916. Arrivals time: 0.07386829098686576 Scheduler time: 1.8530340420547873 Scheduler overhead time: 0.12598921195603907 Adapter cache time: 0.091475251596421 Engine time: 0.12524124258197844 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_128_slots_32_rate_0.1-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_128_slots_32_rate_0.1-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 66, 66, 1080, 66, 540, 540, 540, 66, 1080, 540, 66, 1080, 540, 66, 66, 66, 66, 540, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 540, 66, 540, 66, 1080, 1080, 66, 540, 540, 66, 540, 66, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 66, 540, 1080, 1080, 540, 66, 66, 66, 1080, 540, 540, 540, 540, 1080, 540, 1080, 66, 66, 540, 66, 1080, 1080, 66, 66, 540, 540, 540, 66, 1080, 66, 1080, 540, 66, 1080, 1080, 540, 540, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 540, 1080, 1080, 540, 1080, 66, 540, 1080, 66, 1080, 540, 66, 540, 540, 1080, 1080, 66, 66, 1080, 66, 66, 66, 540, 66]
Prompts retrieved: 72432 . Total input tokens: 16119817 . Total output tokens: 14474454
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 2.296648859977722,
    "estimated_duration": 3599.932823938154,
    "input_throughput": 1658.3401113216332,
    "output_throughput": 1474.582237952115,
    "total_throughput": 3132.9223492737483,
    "itl": 27.020119573365676,
    "ttft": 10853.659689275484,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12216,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 39.90267751879856,
    "arrivals": 24288,
    "finished_requests": 24229,
    "scheduler_time": 0.2446896798836304
}
#Debug simulation 
Total elapsed time: 2.296739424811676. Arrivals time: 0.07380034541711211 Scheduler time: 1.829150284640491 Scheduler overhead time: 0.1246427008882165 Adapter cache time: 0.09016855549998581 Engine time: 0.1195550006814301 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-32/adapters_128_slots_32_rate_0.1-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-32/adapters_128_slots_32_rate_0.1-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 66, 66, 1080, 66, 540, 540, 540, 66, 1080, 540, 66, 1080, 540, 66, 66, 66, 66, 540, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 540, 66, 540, 66, 1080, 1080, 66, 540, 540, 66, 540, 66, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 66, 540, 1080, 1080, 540, 66, 66, 66, 1080, 540, 540, 540, 540, 1080, 540, 1080, 66, 66, 540, 66, 1080, 1080, 66, 66, 540, 540, 540, 66, 1080, 66, 1080, 540, 66, 1080, 1080, 540, 540, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 540, 1080, 1080, 540, 1080, 66, 540, 1080, 66, 1080, 540, 66, 540, 540, 1080, 1080, 66, 66, 1080, 66, 66, 66, 540, 66]
Prompts retrieved: 72432 . Total input tokens: 16119817 . Total output tokens: 14474454
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 2.2803301599342376,
    "estimated_duration": 3599.936620553923,
    "input_throughput": 1658.338362379671,
    "output_throughput": 1474.5806828074644,
    "total_throughput": 3132.9190451871355,
    "itl": 27.02125287410269,
    "ttft": 10852.668963529815,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12211,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 39.949735719660644,
    "arrivals": 24288,
    "finished_requests": 24229,
    "scheduler_time": 0.24559850660949417
}
#Debug simulation 
Total elapsed time: 2.280413893982768. Arrivals time: 0.07147822924889624 Scheduler time: 1.816149395192042 Scheduler overhead time: 0.12387209013104439 Adapter cache time: 0.08966886228881776 Engine time: 0.12026180629618466 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_128_slots_32_rate_0.1-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_128_slots_32_rate_0.1-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 66, 66, 1080, 66, 540, 540, 540, 66, 1080, 540, 66, 1080, 540, 66, 66, 66, 66, 540, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 540, 66, 540, 66, 1080, 1080, 66, 540, 540, 66, 540, 66, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 66, 540, 1080, 1080, 540, 66, 66, 66, 1080, 540, 540, 540, 540, 1080, 540, 1080, 66, 66, 540, 66, 1080, 1080, 66, 66, 540, 540, 540, 66, 1080, 66, 1080, 540, 66, 1080, 1080, 540, 540, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 540, 1080, 1080, 540, 1080, 66, 540, 1080, 66, 1080, 540, 66, 540, 540, 1080, 1080, 66, 66, 1080, 66, 66, 66, 540, 66]
Prompts retrieved: 72432 . Total input tokens: 16119817 . Total output tokens: 14474454
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 2.3070982100907713,
    "estimated_duration": 3599.9416673266765,
    "input_throughput": 1658.3360375484274,
    "output_throughput": 1474.5786155868536,
    "total_throughput": 3132.9146531352812,
    "itl": 27.008191258493568,
    "ttft": 10842.98897709001,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12223,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 38.45470770106966,
    "arrivals": 24288,
    "finished_requests": 24229,
    "scheduler_time": 0.24386883497607958
}
#Debug simulation 
Total elapsed time: 2.3071873411536217. Arrivals time: 0.07306776335462928 Scheduler time: 1.8416345969308168 Scheduler overhead time: 0.12360157957300544 Adapter cache time: 0.09104404109530151 Engine time: 0.11897359369322658 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-32/adapters_128_slots_32_rate_0.1-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-32/adapters_128_slots_32_rate_0.1-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 66, 66, 1080, 66, 540, 540, 540, 66, 1080, 540, 66, 1080, 540, 66, 66, 66, 66, 540, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 540, 66, 540, 66, 1080, 1080, 66, 540, 540, 66, 540, 66, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 66, 540, 1080, 1080, 540, 66, 66, 66, 1080, 540, 540, 540, 540, 1080, 540, 1080, 66, 66, 540, 66, 1080, 1080, 66, 66, 540, 540, 540, 66, 1080, 66, 1080, 540, 66, 1080, 1080, 540, 540, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 540, 1080, 1080, 540, 1080, 66, 540, 1080, 66, 1080, 540, 66, 540, 540, 1080, 1080, 66, 66, 1080, 66, 66, 66, 540, 66]
Prompts retrieved: 72432 . Total input tokens: 16119817 . Total output tokens: 14474454
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 2.323254190851003,
    "estimated_duration": 3599.940613486324,
    "input_throughput": 1658.336523006834,
    "output_throughput": 1474.5790472524322,
    "total_throughput": 3132.9155702592666,
    "itl": 27.025157694366218,
    "ttft": 10855.113889237678,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12209,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 40.39527054284082,
    "arrivals": 24288,
    "finished_requests": 24229,
    "scheduler_time": 0.246228119343872
}
#Debug simulation 
Total elapsed time: 2.3233378268778324. Arrivals time: 0.07342330692335963 Scheduler time: 1.8517165938392282 Scheduler overhead time: 0.12421215511858463 Adapter cache time: 0.09144546394236386 Engine time: 0.12315829540602863 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_128_slots_32_rate_0.1-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_128_slots_32_rate_0.1-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 66, 66, 1080, 66, 540, 540, 540, 66, 1080, 540, 66, 1080, 540, 66, 66, 66, 66, 540, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 540, 66, 540, 66, 1080, 1080, 66, 540, 540, 66, 540, 66, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 66, 540, 1080, 1080, 540, 66, 66, 66, 1080, 540, 540, 540, 540, 1080, 540, 1080, 66, 66, 540, 66, 1080, 1080, 66, 66, 540, 540, 540, 66, 1080, 66, 1080, 540, 66, 1080, 1080, 540, 540, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 540, 1080, 1080, 540, 1080, 66, 540, 1080, 66, 1080, 540, 66, 540, 540, 1080, 1080, 66, 66, 1080, 66, 66, 66, 540, 66]
Prompts retrieved: 72432 . Total input tokens: 16119817 . Total output tokens: 14474454
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 2.345719319069758,
    "estimated_duration": 3599.9475235415366,
    "input_throughput": 1658.3333398501743,
    "output_throughput": 1474.5762168159981,
    "total_throughput": 3132.909556666172,
    "itl": 26.99098479182853,
    "ttft": 10830.222042356108,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12243,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 36.607185760487795,
    "arrivals": 24288,
    "finished_requests": 24229,
    "scheduler_time": 0.24097814202377707
}
#Debug simulation 
Total elapsed time: 2.345836455002427. Arrivals time: 0.0724014607258141 Scheduler time: 1.8753281934186816 Scheduler overhead time: 0.12527455482631922 Adapter cache time: 0.09079818078316748 Engine time: 0.12190092564560473 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-32/adapters_128_slots_32_rate_0.1-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-32/adapters_128_slots_32_rate_0.1-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 66, 66, 1080, 66, 540, 540, 540, 66, 1080, 540, 66, 1080, 540, 66, 66, 66, 66, 540, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 540, 66, 540, 66, 1080, 1080, 66, 540, 540, 66, 540, 66, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 66, 540, 1080, 1080, 540, 66, 66, 66, 1080, 540, 540, 540, 540, 1080, 540, 1080, 66, 66, 540, 66, 1080, 1080, 66, 66, 540, 540, 540, 66, 1080, 66, 1080, 540, 66, 1080, 1080, 540, 540, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 540, 1080, 1080, 540, 1080, 66, 540, 1080, 66, 1080, 540, 66, 540, 540, 1080, 1080, 66, 66, 1080, 66, 66, 66, 540, 66]
Prompts retrieved: 72432 . Total input tokens: 16119817 . Total output tokens: 14474454
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 2.361966726835817,
    "estimated_duration": 3599.9461193736083,
    "input_throughput": 1658.3339866872136,
    "output_throughput": 1474.5767919781151,
    "total_throughput": 3132.910778665329,
    "itl": 27.029116992036432,
    "ttft": 10859.11103809375,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12209,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 40.98132320139504,
    "arrivals": 24288,
    "finished_requests": 24229,
    "scheduler_time": 0.24732398448295315
}
#Debug simulation 
Total elapsed time: 2.3620493980124593. Arrivals time: 0.07287372788414359 Scheduler time: 1.8771469637285918 Scheduler overhead time: 0.13209657580591738 Adapter cache time: 0.09261446725577116 Engine time: 0.1261763994116336 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_128_slots_32_rate_0.1-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_128_slots_32_rate_0.1-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 33, 33, 1080, 33, 540, 540, 540, 33, 1080, 540, 33, 1080, 540, 33, 33, 33, 33, 540, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 540, 33, 540, 33, 1080, 1080, 33, 540, 540, 33, 540, 33, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 33, 540, 1080, 1080, 540, 33, 33, 33, 1080, 540, 540, 540, 540, 1080, 540, 1080, 33, 33, 540, 33, 1080, 1080, 33, 33, 540, 540, 540, 33, 1080, 33, 1080, 540, 33, 1080, 1080, 540, 540, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 540, 1080, 1080, 540, 1080, 33, 540, 1080, 33, 1080, 540, 33, 540, 540, 1080, 1080, 33, 33, 1080, 33, 33, 33, 540, 33]
Prompts retrieved: 71046 . Total input tokens: 15797628 . Total output tokens: 14189361
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 2.266751163173467,
    "estimated_duration": 3599.890931261725,
    "input_throughput": 1631.1158065952793,
    "output_throughput": 1449.205573062043,
    "total_throughput": 3080.3213796573223,
    "itl": 26.859238815283046,
    "ttft": 9946.194092485206,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12229,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 37.426704620552506,
    "arrivals": 23803,
    "finished_requests": 23747,
    "scheduler_time": 0.17280721529741178
}
#Debug simulation 
Total elapsed time: 2.2668525320477784. Arrivals time: 0.07368024298921227 Scheduler time: 1.7963329150807112 Scheduler overhead time: 0.1242276260163635 Adapter cache time: 0.09098312887363136 Engine time: 0.12234733835794032 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_128_slots_32_rate_0.1-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_128_slots_32_rate_0.1-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 33, 33, 1080, 33, 540, 540, 540, 33, 1080, 540, 33, 1080, 540, 33, 33, 33, 33, 540, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 540, 33, 540, 33, 1080, 1080, 33, 540, 540, 33, 540, 33, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 33, 540, 1080, 1080, 540, 33, 33, 33, 1080, 540, 540, 540, 540, 1080, 540, 1080, 33, 33, 540, 33, 1080, 1080, 33, 33, 540, 540, 540, 33, 1080, 33, 1080, 540, 33, 1080, 1080, 540, 540, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 540, 1080, 1080, 540, 1080, 33, 540, 1080, 33, 1080, 540, 33, 540, 540, 1080, 1080, 33, 33, 1080, 33, 33, 33, 540, 33]
Prompts retrieved: 71046 . Total input tokens: 15797628 . Total output tokens: 14189361
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 2.2828301440458745,
    "estimated_duration": 3599.884078762903,
    "input_throughput": 1630.809734856093,
    "output_throughput": 1449.089161168952,
    "total_throughput": 3079.898896025045,
    "itl": 26.90542873712004,
    "ttft": 10697.288783680417,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11771,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 38.522256508716325,
    "arrivals": 23803,
    "finished_requests": 23744,
    "scheduler_time": 0.17586376137029414
}
#Debug simulation 
Total elapsed time: 2.2829211479984224. Arrivals time: 0.07206556643359363 Scheduler time: 1.8153739389963448 Scheduler overhead time: 0.12358116172254086 Adapter cache time: 0.08886485290713608 Engine time: 0.1234503984451294 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-32/adapters_128_slots_32_rate_0.1-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-32/adapters_128_slots_32_rate_0.1-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 33, 33, 1080, 33, 540, 540, 540, 33, 1080, 540, 33, 1080, 540, 33, 33, 33, 33, 540, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 540, 33, 540, 33, 1080, 1080, 33, 540, 540, 33, 540, 33, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 33, 540, 1080, 1080, 540, 33, 33, 33, 1080, 540, 540, 540, 540, 1080, 540, 1080, 33, 33, 540, 33, 1080, 1080, 33, 33, 540, 540, 540, 33, 1080, 33, 1080, 540, 33, 1080, 1080, 540, 540, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 540, 1080, 1080, 540, 1080, 33, 540, 1080, 33, 1080, 540, 33, 540, 540, 1080, 1080, 33, 33, 1080, 33, 33, 33, 540, 33]
Prompts retrieved: 71046 . Total input tokens: 15797628 . Total output tokens: 14189361
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 2.252319880994037,
    "estimated_duration": 3599.8851462815187,
    "input_throughput": 1630.8092512518444,
    "output_throughput": 1449.0887314525603,
    "total_throughput": 3079.8979827044045,
    "itl": 26.906418145952323,
    "ttft": 10699.187759344659,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11770,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 38.56707420802267,
    "arrivals": 23803,
    "finished_requests": 23744,
    "scheduler_time": 0.17635354402717737
}
#Debug simulation 
Total elapsed time: 2.252406134037301. Arrivals time: 0.07117560273036361 Scheduler time: 1.7893626606091857 Scheduler overhead time: 0.12500430084764957 Adapter cache time: 0.08785079652443528 Engine time: 0.11991145415231586 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_128_slots_32_rate_0.1-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_128_slots_32_rate_0.1-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 33, 33, 1080, 33, 540, 540, 540, 33, 1080, 540, 33, 1080, 540, 33, 33, 33, 33, 540, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 540, 33, 540, 33, 1080, 1080, 33, 540, 540, 33, 540, 33, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 33, 540, 1080, 1080, 540, 33, 33, 33, 1080, 540, 540, 540, 540, 1080, 540, 1080, 33, 33, 540, 33, 1080, 1080, 33, 33, 540, 540, 540, 33, 1080, 33, 1080, 540, 33, 1080, 1080, 540, 540, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 540, 1080, 1080, 540, 1080, 33, 540, 1080, 33, 1080, 540, 33, 540, 540, 1080, 1080, 33, 33, 1080, 33, 33, 33, 540, 33]
Prompts retrieved: 71046 . Total input tokens: 15797628 . Total output tokens: 14189361
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 2.2313660620711744,
    "estimated_duration": 3599.902966948113,
    "input_throughput": 1631.1103532265383,
    "output_throughput": 1449.2007278803953,
    "total_throughput": 3080.3110811069337,
    "itl": 26.86909954750035,
    "ttft": 9952.057804184813,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12220,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 38.48700567734741,
    "arrivals": 23803,
    "finished_requests": 23747,
    "scheduler_time": 0.17431978484513827
}
#Debug simulation 
Total elapsed time: 2.231456883950159. Arrivals time: 0.07162203057669103 Scheduler time: 1.7676381799392402 Scheduler overhead time: 0.12363064219243824 Adapter cache time: 0.09044914785772562 Engine time: 0.11874900455586612 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-32/adapters_128_slots_32_rate_0.1-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-32/adapters_128_slots_32_rate_0.1-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 33, 33, 1080, 33, 540, 540, 540, 33, 1080, 540, 33, 1080, 540, 33, 33, 33, 33, 540, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 540, 33, 540, 33, 1080, 1080, 33, 540, 540, 33, 540, 33, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 33, 540, 1080, 1080, 540, 33, 33, 33, 1080, 540, 540, 540, 540, 1080, 540, 1080, 33, 33, 540, 33, 1080, 1080, 33, 33, 540, 540, 540, 33, 1080, 33, 1080, 540, 33, 1080, 1080, 540, 540, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 540, 1080, 1080, 540, 1080, 33, 540, 1080, 33, 1080, 540, 33, 540, 540, 1080, 1080, 33, 33, 1080, 33, 33, 33, 540, 33]
Prompts retrieved: 71046 . Total input tokens: 15797628 . Total output tokens: 14189361
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 2.266236142022535,
    "estimated_duration": 3599.9050761942126,
    "input_throughput": 1630.8002227121162,
    "output_throughput": 1449.080708959941,
    "total_throughput": 3079.880931672057,
    "itl": 26.910972383662315,
    "ttft": 10700.119984496323,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11768,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 38.99910764999946,
    "arrivals": 23803,
    "finished_requests": 23744,
    "scheduler_time": 0.176612032153396
}
#Debug simulation 
Total elapsed time: 2.266327539924532. Arrivals time: 0.07364685391075909 Scheduler time: 1.800743264844641 Scheduler overhead time: 0.12288586143404245 Adapter cache time: 0.08800425613299012 Engine time: 0.12192389206029475 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_128_slots_32_rate_0.1-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_128_slots_32_rate_0.1-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 33, 33, 1080, 33, 540, 540, 540, 33, 1080, 540, 33, 1080, 540, 33, 33, 33, 33, 540, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 540, 33, 540, 33, 1080, 1080, 33, 540, 540, 33, 540, 33, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 33, 540, 1080, 1080, 540, 33, 33, 33, 1080, 540, 540, 540, 540, 1080, 540, 1080, 33, 33, 540, 33, 1080, 1080, 33, 33, 540, 540, 540, 33, 1080, 33, 1080, 540, 33, 1080, 1080, 540, 540, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 540, 1080, 1080, 540, 1080, 33, 540, 1080, 33, 1080, 540, 33, 540, 540, 1080, 1080, 33, 33, 1080, 33, 33, 33, 540, 33]
Prompts retrieved: 71046 . Total input tokens: 15797628 . Total output tokens: 14189361
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 2.2599745800253004,
    "estimated_duration": 3599.9011646223153,
    "input_throughput": 1631.1111698579218,
    "output_throughput": 1449.201453436942,
    "total_throughput": 3080.312623294864,
    "itl": 26.850211830306876,
    "ttft": 9942.964367998276,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12241,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 36.601205659897985,
    "arrivals": 23803,
    "finished_requests": 23747,
    "scheduler_time": 0.172456741098447
}
#Debug simulation 
Total elapsed time: 2.260066949063912. Arrivals time: 0.07183921616524458 Scheduler time: 1.7917255843058228 Scheduler overhead time: 0.12401400762610137 Adapter cache time: 0.09082696586847305 Engine time: 0.12263602577149868 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-32/adapters_128_slots_32_rate_0.1-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-32/adapters_128_slots_32_rate_0.1-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 33, 33, 1080, 33, 540, 540, 540, 33, 1080, 540, 33, 1080, 540, 33, 33, 33, 33, 540, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 540, 33, 540, 33, 1080, 1080, 33, 540, 540, 33, 540, 33, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 33, 540, 1080, 1080, 540, 33, 33, 33, 1080, 540, 540, 540, 540, 1080, 540, 1080, 33, 33, 540, 33, 1080, 1080, 33, 33, 540, 540, 540, 33, 1080, 33, 1080, 540, 33, 1080, 1080, 540, 540, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 540, 1080, 1080, 540, 1080, 33, 540, 1080, 33, 1080, 540, 33, 540, 540, 1080, 1080, 33, 33, 1080, 33, 33, 33, 540, 33]
Prompts retrieved: 71046 . Total input tokens: 15797628 . Total output tokens: 14189361
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 2.266500695142895,
    "estimated_duration": 3599.8865632196844,
    "input_throughput": 1630.851666267276,
    "output_throughput": 1449.2056647846189,
    "total_throughput": 3080.057331051895,
    "itl": 26.893329526003914,
    "ttft": 10414.47074888108,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12207,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 41.00486824568302,
    "arrivals": 23803,
    "finished_requests": 23744,
    "scheduler_time": 0.17839994037119747
}
#Debug simulation 
Total elapsed time: 2.2665906220208853. Arrivals time: 0.07203765423037112 Scheduler time: 1.7956857497338206 Scheduler overhead time: 0.12402868457138538 Adapter cache time: 0.09141759434714913 Engine time: 0.12390404008328915 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_128_slots_32_rate_0.1-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_128_slots_32_rate_0.1-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 135, 135, 1080, 135, 270, 270, 270, 135, 1080, 270, 135, 1080, 270, 135, 135, 135, 135, 270, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 270, 135, 270, 135, 1080, 1080, 135, 270, 270, 135, 270, 135, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 135, 270, 1080, 1080, 270, 135, 135, 135, 1080, 270, 270, 270, 270, 1080, 270, 1080, 135, 135, 270, 135, 1080, 1080, 135, 135, 270, 270, 270, 135, 1080, 135, 1080, 270, 135, 1080, 1080, 270, 270, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 135, 1080, 135, 135, 1080, 270, 1080, 1080, 270, 1080, 135, 270, 1080, 135, 1080, 270, 135, 270, 270, 1080, 1080, 135, 135, 1080, 135, 135, 135, 270, 135]
Prompts retrieved: 63720 . Total input tokens: 14155558 . Total output tokens: 12743855
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 2.007684316020459,
    "estimated_duration": 3599.7344898334027,
    "input_throughput": 1441.4718681766292,
    "output_throughput": 1295.937801294867,
    "total_throughput": 2737.4096694714963,
    "itl": 25.865961580271083,
    "ttft": 8831.180590074537,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12210,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 37.36855535341783,
    "arrivals": 21290,
    "finished_requests": 21240,
    "scheduler_time": 0.019208151636665425
}
#Debug simulation 
Total elapsed time: 2.007765986956656. Arrivals time: 0.06428010133095086 Scheduler time: 1.5451772704254836 Scheduler overhead time: 0.12536967475898564 Adapter cache time: 0.09126626187935472 Engine time: 0.12123430497013032 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_128_slots_32_rate_0.1-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_128_slots_32_rate_0.1-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 135, 135, 1080, 135, 270, 270, 270, 135, 1080, 270, 135, 1080, 270, 135, 135, 135, 135, 270, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 270, 135, 270, 135, 1080, 1080, 135, 270, 270, 135, 270, 135, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 135, 270, 1080, 1080, 270, 135, 135, 135, 1080, 270, 270, 270, 270, 1080, 270, 1080, 135, 135, 270, 135, 1080, 1080, 135, 135, 270, 270, 270, 135, 1080, 135, 1080, 270, 135, 1080, 1080, 270, 270, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 135, 1080, 135, 135, 1080, 270, 1080, 1080, 270, 1080, 135, 270, 1080, 135, 1080, 270, 135, 270, 270, 1080, 1080, 135, 135, 1080, 135, 135, 135, 270, 135]
Prompts retrieved: 63720 . Total input tokens: 14155558 . Total output tokens: 12743855
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 2.0249405598733574,
    "estimated_duration": 3599.7432858874217,
    "input_throughput": 1441.211383139239,
    "output_throughput": 1295.8996321455713,
    "total_throughput": 2737.1110152848105,
    "itl": 26.04189444382778,
    "ttft": 9342.92500400785,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12163,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 39.76095726122469,
    "arrivals": 21290,
    "finished_requests": 21238,
    "scheduler_time": 0.01682353490232697
}
#Debug simulation 
Total elapsed time: 2.025030944030732. Arrivals time: 0.06537487078458071 Scheduler time: 1.5637942210305482 Scheduler overhead time: 0.12397175887599587 Adapter cache time: 0.09064159635454416 Engine time: 0.12135925353504717 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-32/adapters_128_slots_32_rate_0.1-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-32/adapters_128_slots_32_rate_0.1-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 135, 135, 1080, 135, 270, 270, 270, 135, 1080, 270, 135, 1080, 270, 135, 135, 135, 135, 270, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 270, 135, 270, 135, 1080, 1080, 135, 270, 270, 135, 270, 135, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 135, 270, 1080, 1080, 270, 135, 135, 135, 1080, 270, 270, 270, 270, 1080, 270, 1080, 135, 135, 270, 135, 1080, 1080, 135, 135, 270, 270, 270, 135, 1080, 135, 1080, 270, 135, 1080, 1080, 270, 270, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 135, 1080, 135, 135, 1080, 270, 1080, 1080, 270, 1080, 135, 270, 1080, 135, 1080, 270, 135, 270, 270, 1080, 1080, 135, 135, 1080, 135, 135, 135, 270, 135]
Prompts retrieved: 63720 . Total input tokens: 14155558 . Total output tokens: 12743855
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 2.042006686097011,
    "estimated_duration": 3599.728831728903,
    "input_throughput": 1441.2171701023033,
    "output_throughput": 1295.9048356316068,
    "total_throughput": 2737.12200573391,
    "itl": 26.042882234646285,
    "ttft": 9343.328495662834,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12159,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 39.8049626393117,
    "arrivals": 21290,
    "finished_requests": 21238,
    "scheduler_time": 0.01673712432586237
}
#Debug simulation 
Total elapsed time: 2.042087374953553. Arrivals time: 0.06534743565134704 Scheduler time: 1.57760283886455 Scheduler overhead time: 0.1253391094505787 Adapter cache time: 0.09097513742744923 Engine time: 0.1222556964494288 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_128_slots_32_rate_0.1-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_128_slots_32_rate_0.1-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 135, 135, 1080, 135, 270, 270, 270, 135, 1080, 270, 135, 1080, 270, 135, 135, 135, 135, 270, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 270, 135, 270, 135, 1080, 1080, 135, 270, 270, 135, 270, 135, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 135, 270, 1080, 1080, 270, 135, 135, 135, 1080, 270, 270, 270, 270, 1080, 270, 1080, 135, 135, 270, 135, 1080, 1080, 135, 135, 270, 270, 270, 135, 1080, 135, 1080, 270, 135, 1080, 1080, 270, 270, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 135, 1080, 135, 135, 1080, 270, 1080, 1080, 270, 1080, 135, 270, 1080, 135, 1080, 270, 135, 270, 270, 1080, 1080, 135, 135, 1080, 135, 135, 135, 270, 135]
Prompts retrieved: 63720 . Total input tokens: 14155558 . Total output tokens: 12743855
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 2.0011790848802775,
    "estimated_duration": 3599.741745557832,
    "input_throughput": 1441.4689627119076,
    "output_throughput": 1295.935189172046,
    "total_throughput": 2737.4041518839535,
    "itl": 25.87803454249186,
    "ttft": 8832.632515136678,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12213,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 38.45095729850079,
    "arrivals": 21290,
    "finished_requests": 21240,
    "scheduler_time": 0.019281949793315236
}
#Debug simulation 
Total elapsed time: 2.0012647369876504. Arrivals time: 0.06459716823883355 Scheduler time: 1.5379834063351154 Scheduler overhead time: 0.12459846120327711 Adapter cache time: 0.09065540344454348 Engine time: 0.12332544638775289 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-32/adapters_128_slots_32_rate_0.1-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-32/adapters_128_slots_32_rate_0.1-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 135, 135, 1080, 135, 270, 270, 270, 135, 1080, 270, 135, 1080, 270, 135, 135, 135, 135, 270, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 270, 135, 270, 135, 1080, 1080, 135, 270, 270, 135, 270, 135, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 135, 270, 1080, 1080, 270, 135, 135, 135, 1080, 270, 270, 270, 270, 1080, 270, 1080, 135, 135, 270, 135, 1080, 1080, 135, 135, 270, 270, 270, 135, 1080, 135, 1080, 270, 135, 1080, 1080, 270, 270, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 135, 1080, 135, 135, 1080, 270, 1080, 1080, 270, 1080, 135, 270, 1080, 135, 1080, 270, 135, 270, 270, 1080, 1080, 135, 135, 1080, 135, 135, 135, 270, 135]
Prompts retrieved: 63720 . Total input tokens: 14155558 . Total output tokens: 12743855
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 2.049462983151898,
    "estimated_duration": 3599.720845856091,
    "input_throughput": 1441.2203673994015,
    "output_throughput": 1295.9077105576462,
    "total_throughput": 2737.128077957048,
    "itl": 26.04862429575694,
    "ttft": 9344.052172414751,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12155,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 40.238328516989476,
    "arrivals": 21290,
    "finished_requests": 21238,
    "scheduler_time": 0.016932796036652258
}
#Debug simulation 
Total elapsed time: 2.0495522720739245. Arrivals time: 0.06653978349640965 Scheduler time: 1.5815656939521432 Scheduler overhead time: 0.12440099311061203 Adapter cache time: 0.09177882852964103 Engine time: 0.12520442064851522 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_128_slots_32_rate_0.1-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_128_slots_32_rate_0.1-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 135, 135, 1080, 135, 270, 270, 270, 135, 1080, 270, 135, 1080, 270, 135, 135, 135, 135, 270, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 270, 135, 270, 135, 1080, 1080, 135, 270, 270, 135, 270, 135, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 135, 270, 1080, 1080, 270, 135, 135, 135, 1080, 270, 270, 270, 270, 1080, 270, 1080, 135, 135, 270, 135, 1080, 1080, 135, 135, 270, 270, 270, 135, 1080, 135, 1080, 270, 135, 1080, 1080, 270, 270, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 135, 1080, 135, 135, 1080, 270, 1080, 1080, 270, 1080, 135, 270, 1080, 135, 1080, 270, 135, 270, 270, 1080, 1080, 135, 135, 1080, 135, 135, 135, 270, 135]
Prompts retrieved: 63720 . Total input tokens: 14155558 . Total output tokens: 12743855
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 2.027037038002163,
    "estimated_duration": 3599.7355187473845,
    "input_throughput": 1441.4714561600929,
    "output_throughput": 1295.937430876397,
    "total_throughput": 2737.40888703649,
    "itl": 25.85694559082941,
    "ttft": 8829.92974473014,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12215,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 36.52346435223046,
    "arrivals": 21290,
    "finished_requests": 21240,
    "scheduler_time": 0.01911137011366945
}
#Debug simulation 
Total elapsed time: 2.027125505032018. Arrivals time: 0.06603375403210521 Scheduler time: 1.5594326741993427 Scheduler overhead time: 0.12580870278179646 Adapter cache time: 0.09160148352384567 Engine time: 0.12376740854233503 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-32/adapters_128_slots_32_rate_0.1-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-32/adapters_128_slots_32_rate_0.1-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 135, 135, 1080, 135, 270, 270, 270, 135, 1080, 270, 135, 1080, 270, 135, 135, 135, 135, 270, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 270, 135, 270, 135, 1080, 1080, 135, 270, 270, 135, 270, 135, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 135, 270, 1080, 1080, 270, 135, 135, 135, 1080, 270, 270, 270, 270, 1080, 270, 1080, 135, 135, 270, 135, 1080, 1080, 135, 135, 270, 270, 270, 135, 1080, 135, 1080, 270, 135, 1080, 1080, 270, 270, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 135, 1080, 135, 135, 1080, 270, 1080, 1080, 270, 1080, 135, 270, 1080, 135, 1080, 270, 135, 270, 270, 1080, 1080, 135, 135, 1080, 135, 135, 135, 270, 135]
Prompts retrieved: 63720 . Total input tokens: 14155558 . Total output tokens: 12743855
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 2.0318586889188737,
    "estimated_duration": 3599.7435362666565,
    "input_throughput": 1441.2112828961524,
    "output_throughput": 1295.8995420096062,
    "total_throughput": 2737.1108249057584,
    "itl": 26.05300075048061,
    "ttft": 9345.201592305437,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12157,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 40.84204327378373,
    "arrivals": 21290,
    "finished_requests": 21238,
    "scheduler_time": 0.016893625432680134
}
#Debug simulation 
Total elapsed time: 2.0319718499667943. Arrivals time: 0.06564282439649105 Scheduler time: 1.5677796700038016 Scheduler overhead time: 0.12479964271187782 Adapter cache time: 0.0905887654516846 Engine time: 0.12313105631619692 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_128_slots_32_rate_0.1-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_128_slots_32_rate_0.1-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 66, 66, 1080, 66, 270, 270, 270, 66, 1080, 270, 66, 1080, 270, 66, 66, 66, 66, 270, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 270, 66, 270, 66, 1080, 1080, 66, 270, 270, 66, 270, 66, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 66, 270, 1080, 1080, 270, 66, 66, 66, 1080, 270, 270, 270, 270, 1080, 270, 1080, 66, 66, 270, 66, 1080, 1080, 66, 66, 270, 270, 270, 66, 1080, 66, 1080, 270, 66, 1080, 1080, 270, 270, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 270, 1080, 1080, 270, 1080, 66, 270, 1080, 66, 1080, 270, 66, 270, 270, 1080, 1080, 66, 66, 1080, 66, 66, 66, 270, 66]
Prompts retrieved: 60822 . Total input tokens: 13485301 . Total output tokens: 12173679
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.951967905042693,
    "estimated_duration": 3599.616494443342,
    "input_throughput": 1392.2794296938077,
    "output_throughput": 1259.3494354184047,
    "total_throughput": 2651.6288651122127,
    "itl": 25.472567662395573,
    "ttft": 4959.089562765462,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11071,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 33.88265981308134,
    "arrivals": 20438,
    "finished_requests": 20411,
    "scheduler_time": 0.004858003990060656
}
#Debug simulation 
Total elapsed time: 1.9520630571059883. Arrivals time: 0.06298636179417372 Scheduler time: 1.4910223090555519 Scheduler overhead time: 0.12817444023676217 Adapter cache time: 0.08590995473787189 Engine time: 0.12243083631619811 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_128_slots_32_rate_0.1-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_128_slots_32_rate_0.1-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 66, 66, 1080, 66, 270, 270, 270, 66, 1080, 270, 66, 1080, 270, 66, 66, 66, 66, 270, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 270, 66, 270, 66, 1080, 1080, 66, 270, 270, 66, 270, 66, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 66, 270, 1080, 1080, 270, 66, 66, 66, 1080, 270, 270, 270, 270, 1080, 270, 1080, 66, 66, 270, 66, 1080, 1080, 66, 66, 270, 270, 270, 66, 1080, 66, 1080, 270, 66, 1080, 1080, 270, 270, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 270, 1080, 1080, 270, 1080, 66, 270, 1080, 66, 1080, 270, 66, 270, 270, 1080, 1080, 66, 66, 1080, 66, 66, 66, 270, 66]
Prompts retrieved: 60822 . Total input tokens: 13485301 . Total output tokens: 12173679
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.9839535080827773,
    "estimated_duration": 3599.6041541149825,
    "input_throughput": 1392.2175287721705,
    "output_throughput": 1259.240962598136,
    "total_throughput": 2651.4584913703065,
    "itl": 25.49285773649585,
    "ttft": 5136.711249355293,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11071,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 36.19182742226931,
    "arrivals": 20438,
    "finished_requests": 20410,
    "scheduler_time": 0.00494127754928537
}
#Debug simulation 
Total elapsed time: 1.984045703196898. Arrivals time: 0.06397681450471282 Scheduler time: 1.5199430482462049 Scheduler overhead time: 0.12578975385986269 Adapter cache time: 0.08694081055000424 Engine time: 0.12608001078478992 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_128_slots_32_rate_0.1-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_128_slots_32_rate_0.1-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 66, 66, 1080, 66, 270, 270, 270, 66, 1080, 270, 66, 1080, 270, 66, 66, 66, 66, 270, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 270, 66, 270, 66, 1080, 1080, 66, 270, 270, 66, 270, 66, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 66, 270, 1080, 1080, 270, 66, 66, 66, 1080, 270, 270, 270, 270, 1080, 270, 1080, 66, 66, 270, 66, 1080, 1080, 66, 66, 270, 270, 270, 66, 1080, 66, 1080, 270, 66, 1080, 1080, 270, 270, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 270, 1080, 1080, 270, 1080, 66, 270, 1080, 66, 1080, 270, 66, 270, 270, 1080, 1080, 66, 66, 1080, 66, 66, 66, 270, 66]
Prompts retrieved: 60822 . Total input tokens: 13485301 . Total output tokens: 12173679
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.9786745398305357,
    "estimated_duration": 3599.608179771732,
    "input_throughput": 1392.215971772183,
    "output_throughput": 1259.239554313782,
    "total_throughput": 2651.4555260859647,
    "itl": 25.49451031227952,
    "ttft": 5137.019277399751,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11069,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 36.237963948198,
    "arrivals": 20438,
    "finished_requests": 20410,
    "scheduler_time": 0.0049403825629616895
}
#Debug simulation 
Total elapsed time: 1.978750507812947. Arrivals time: 0.06277611735276878 Scheduler time: 1.5165555425919592 Scheduler overhead time: 0.1267927256412804 Adapter cache time: 0.08688882854767144 Engine time: 0.12450178293511271 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_128_slots_32_rate_0.1-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_128_slots_32_rate_0.1-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 66, 66, 1080, 66, 270, 270, 270, 66, 1080, 270, 66, 1080, 270, 66, 66, 66, 66, 270, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 270, 66, 270, 66, 1080, 1080, 66, 270, 270, 66, 270, 66, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 66, 270, 1080, 1080, 270, 66, 66, 66, 1080, 270, 270, 270, 270, 1080, 270, 1080, 66, 66, 270, 66, 1080, 1080, 66, 66, 270, 270, 270, 66, 1080, 66, 1080, 270, 66, 1080, 1080, 270, 270, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 270, 1080, 1080, 270, 1080, 66, 270, 1080, 66, 1080, 270, 66, 270, 270, 1080, 1080, 66, 66, 1080, 66, 66, 66, 270, 66]
Prompts retrieved: 60822 . Total input tokens: 13485301 . Total output tokens: 12173679
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 1.961642649024725,
    "estimated_duration": 3599.626454331249,
    "input_throughput": 1392.2755773643423,
    "output_throughput": 1259.345950895949,
    "total_throughput": 2651.621528260291,
    "itl": 25.48099537641642,
    "ttft": 4959.722597775196,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11071,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 34.85817230287972,
    "arrivals": 20438,
    "finished_requests": 20411,
    "scheduler_time": 0.004886178833768221
}
#Debug simulation 
Total elapsed time: 1.9617311728652567. Arrivals time: 0.0628745942376554 Scheduler time: 1.495460890000686 Scheduler overhead time: 0.12838486372493207 Adapter cache time: 0.08645497937686741 Engine time: 0.1268092410173267 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_128_slots_32_rate_0.1-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_128_slots_32_rate_0.1-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 66, 66, 1080, 66, 270, 270, 270, 66, 1080, 270, 66, 1080, 270, 66, 66, 66, 66, 270, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 270, 66, 270, 66, 1080, 1080, 66, 270, 270, 66, 270, 66, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 66, 270, 1080, 1080, 270, 66, 66, 66, 1080, 270, 270, 270, 270, 1080, 270, 1080, 66, 66, 270, 66, 1080, 1080, 66, 66, 270, 270, 270, 66, 1080, 66, 1080, 270, 66, 1080, 1080, 270, 270, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 270, 1080, 1080, 270, 1080, 66, 270, 1080, 66, 1080, 270, 66, 270, 270, 1080, 1080, 66, 66, 1080, 66, 66, 66, 270, 66]
Prompts retrieved: 60822 . Total input tokens: 13485301 . Total output tokens: 12173679
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 1.9701437149196863,
    "estimated_duration": 3599.6163010025025,
    "input_throughput": 1392.2128307409607,
    "output_throughput": 1259.2367132956954,
    "total_throughput": 2651.4495440366563,
    "itl": 25.498320692982087,
    "ttft": 5137.162973383674,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11076,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 36.671540930254295,
    "arrivals": 20438,
    "finished_requests": 20410,
    "scheduler_time": 0.004947426133294446
}
#Debug simulation 
Total elapsed time: 1.9702331249136478. Arrivals time: 0.0632092454470694 Scheduler time: 1.5069384230300784 Scheduler overhead time: 0.12820818065665662 Adapter cache time: 0.08712811046279967 Engine time: 0.12313161324709654 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_128_slots_32_rate_0.1-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_128_slots_32_rate_0.1-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 66, 66, 1080, 66, 270, 270, 270, 66, 1080, 270, 66, 1080, 270, 66, 66, 66, 66, 270, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 270, 66, 270, 66, 1080, 1080, 66, 270, 270, 66, 270, 66, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 66, 270, 1080, 1080, 270, 66, 66, 66, 1080, 270, 270, 270, 270, 1080, 270, 1080, 66, 66, 270, 66, 1080, 1080, 66, 66, 270, 270, 270, 66, 1080, 66, 1080, 270, 66, 1080, 1080, 270, 270, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 270, 1080, 1080, 270, 1080, 66, 270, 1080, 66, 1080, 270, 66, 270, 270, 1080, 1080, 66, 66, 1080, 66, 66, 66, 270, 66]
Prompts retrieved: 60822 . Total input tokens: 13485301 . Total output tokens: 12173679
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.9564790420699865,
    "estimated_duration": 3599.6124060836696,
    "input_throughput": 1392.2810110138032,
    "output_throughput": 1259.3508657594705,
    "total_throughput": 2651.6318767732737,
    "itl": 25.464055946566972,
    "ttft": 4958.3429696062485,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11076,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 33.11779706633397,
    "arrivals": 20438,
    "finished_requests": 20411,
    "scheduler_time": 0.004782045059858838
}
#Debug simulation 
Total elapsed time: 1.9565979819744825. Arrivals time: 0.06288030184805393 Scheduler time: 1.4963178902398795 Scheduler overhead time: 0.12685563717968762 Adapter cache time: 0.08627149276435375 Engine time: 0.1232928759418428 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_128_slots_32_rate_0.1-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_128_slots_32_rate_0.1-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 66, 66, 1080, 66, 270, 270, 270, 66, 1080, 270, 66, 1080, 270, 66, 66, 66, 66, 270, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 270, 66, 270, 66, 1080, 1080, 66, 270, 270, 66, 270, 66, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 66, 270, 1080, 1080, 270, 66, 66, 66, 1080, 270, 270, 270, 270, 1080, 270, 1080, 66, 66, 270, 66, 1080, 1080, 66, 66, 270, 270, 270, 66, 1080, 66, 1080, 270, 66, 1080, 1080, 270, 270, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 270, 1080, 1080, 270, 1080, 66, 270, 1080, 66, 1080, 270, 66, 270, 270, 1080, 1080, 66, 66, 1080, 66, 66, 66, 270, 66]
Prompts retrieved: 60822 . Total input tokens: 13485301 . Total output tokens: 12173679
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.9361209911294281,
    "estimated_duration": 3599.609123044664,
    "input_throughput": 1392.2156069437815,
    "output_throughput": 1259.2392243316795,
    "total_throughput": 2651.454831275461,
    "itl": 25.503650022156187,
    "ttft": 5137.694928547742,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11072,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 37.19859337881063,
    "arrivals": 20438,
    "finished_requests": 20410,
    "scheduler_time": 0.005003949700926935
}
#Debug simulation 
Total elapsed time: 1.9362158051226288. Arrivals time: 0.0638131380546838 Scheduler time: 1.4741655841935426 Scheduler overhead time: 0.12796742166392505 Adapter cache time: 0.08630619780160487 Engine time: 0.12250027013942599 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_128_slots_32_rate_0.1-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_128_slots_32_rate_0.1-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 33, 33, 1080, 33, 270, 270, 270, 33, 1080, 270, 33, 1080, 270, 33, 33, 33, 33, 270, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 270, 33, 270, 33, 1080, 1080, 33, 270, 270, 33, 270, 33, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 33, 270, 1080, 1080, 270, 33, 33, 33, 1080, 270, 270, 270, 270, 1080, 270, 1080, 33, 33, 270, 33, 1080, 1080, 33, 33, 270, 270, 270, 33, 1080, 33, 1080, 270, 33, 1080, 1080, 270, 270, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 270, 1080, 1080, 270, 1080, 33, 270, 1080, 33, 1080, 270, 33, 270, 270, 1080, 1080, 33, 33, 1080, 33, 33, 33, 270, 33]
Prompts retrieved: 59436 . Total input tokens: 13178530 . Total output tokens: 11909268
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.9019525730982423,
    "estimated_duration": 3600.0245291970896,
    "input_throughput": 1375.1836855134288,
    "output_throughput": 1209.3548154159394,
    "total_throughput": 2584.538500929368,
    "itl": 25.050531335069522,
    "ttft": 6107.057027937211,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10471,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 32.04636716672322,
    "arrivals": 19983,
    "finished_requests": 19950,
    "scheduler_time": 0.009382400176450513
}
#Debug simulation 
Total elapsed time: 1.9020399239379913. Arrivals time: 0.06221666489727795 Scheduler time: 1.4380985300522298 Scheduler overhead time: 0.13048514956608415 Adapter cache time: 0.08390821563079953 Engine time: 0.1250718249939382 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_128_slots_32_rate_0.1-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_128_slots_32_rate_0.1-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 33, 33, 1080, 33, 270, 270, 270, 33, 1080, 270, 33, 1080, 270, 33, 33, 33, 33, 270, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 270, 33, 270, 33, 1080, 1080, 33, 270, 270, 33, 270, 33, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 33, 270, 1080, 1080, 270, 33, 33, 33, 1080, 270, 270, 270, 270, 1080, 270, 1080, 33, 33, 270, 33, 1080, 1080, 33, 33, 270, 270, 270, 33, 1080, 33, 1080, 270, 33, 1080, 1080, 270, 270, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 270, 1080, 1080, 270, 1080, 33, 270, 1080, 33, 1080, 270, 33, 270, 270, 1080, 1080, 33, 33, 1080, 33, 33, 33, 270, 33]
Prompts retrieved: 59436 . Total input tokens: 13178530 . Total output tokens: 11909268
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.9094996401108801,
    "estimated_duration": 3600.0089374965,
    "input_throughput": 1375.189641457609,
    "output_throughput": 1209.3600531524328,
    "total_throughput": 2584.5496946100416,
    "itl": 24.958521774419935,
    "ttft": 6084.584028310379,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10520,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 34.391903655998654,
    "arrivals": 19983,
    "finished_requests": 19950,
    "scheduler_time": 0.010781904479426806
}
#Debug simulation 
Total elapsed time: 1.9096012490335852. Arrivals time: 0.06357153411954641 Scheduler time: 1.4450876249466091 Scheduler overhead time: 0.12774413730949163 Adapter cache time: 0.08435008255764842 Engine time: 0.12508627003990114 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_128_slots_32_rate_0.1-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_128_slots_32_rate_0.1-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 33, 33, 1080, 33, 270, 270, 270, 33, 1080, 270, 33, 1080, 270, 33, 33, 33, 33, 270, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 270, 33, 270, 33, 1080, 1080, 33, 270, 270, 33, 270, 33, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 33, 270, 1080, 1080, 270, 33, 33, 33, 1080, 270, 270, 270, 270, 1080, 270, 1080, 33, 33, 270, 33, 1080, 1080, 33, 33, 270, 270, 270, 33, 1080, 33, 1080, 270, 33, 1080, 1080, 270, 270, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 270, 1080, 1080, 270, 1080, 33, 270, 1080, 33, 1080, 270, 33, 270, 270, 1080, 1080, 33, 33, 1080, 33, 33, 33, 270, 33]
Prompts retrieved: 59436 . Total input tokens: 13178530 . Total output tokens: 11909268
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.9065746320411563,
    "estimated_duration": 3600.0137054192387,
    "input_throughput": 1375.1878201317759,
    "output_throughput": 1209.3584514542813,
    "total_throughput": 2584.546271586057,
    "itl": 24.958390442489687,
    "ttft": 6084.796355649479,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10518,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 34.43451725207572,
    "arrivals": 19983,
    "finished_requests": 19950,
    "scheduler_time": 0.010817801259686795
}
#Debug simulation 
Total elapsed time: 1.9066628720611334. Arrivals time: 0.0621548832859844 Scheduler time: 1.443877801997587 Scheduler overhead time: 0.1271846133749932 Adapter cache time: 0.08491729549132288 Engine time: 0.12657496379688382 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_128_slots_32_rate_0.1-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_128_slots_32_rate_0.1-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 33, 33, 1080, 33, 270, 270, 270, 33, 1080, 270, 33, 1080, 270, 33, 33, 33, 33, 270, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 270, 33, 270, 33, 1080, 1080, 33, 270, 270, 33, 270, 33, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 33, 270, 1080, 1080, 270, 33, 33, 33, 1080, 270, 270, 270, 270, 1080, 270, 1080, 33, 33, 270, 33, 1080, 1080, 33, 33, 270, 270, 270, 33, 1080, 33, 1080, 270, 33, 1080, 1080, 270, 270, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 270, 1080, 1080, 270, 1080, 33, 270, 1080, 33, 1080, 270, 33, 270, 270, 1080, 1080, 33, 33, 1080, 33, 33, 33, 270, 33]
Prompts retrieved: 59436 . Total input tokens: 13178530 . Total output tokens: 11909268
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 1.9366104761138558,
    "estimated_duration": 3600.0021674584345,
    "input_throughput": 1375.1922275911131,
    "output_throughput": 1209.3623274326176,
    "total_throughput": 2584.5545550237307,
    "itl": 24.94646453400241,
    "ttft": 6084.206286705886,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10523,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 33.18979728302586,
    "arrivals": 19983,
    "finished_requests": 19950,
    "scheduler_time": 0.010757094076175581
}
#Debug simulation 
Total elapsed time: 1.9366990369744599. Arrivals time: 0.06291521922685206 Scheduler time: 1.4694636915810406 Scheduler overhead time: 0.12837268598377705 Adapter cache time: 0.08551432145759463 Engine time: 0.12830196390859783 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_128_slots_32_rate_0.1-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_128_slots_32_rate_0.1-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 33, 33, 1080, 33, 270, 270, 270, 33, 1080, 270, 33, 1080, 270, 33, 33, 33, 33, 270, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 270, 33, 270, 33, 1080, 1080, 33, 270, 270, 33, 270, 33, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 33, 270, 1080, 1080, 270, 33, 33, 33, 1080, 270, 270, 270, 270, 1080, 270, 1080, 33, 33, 270, 33, 1080, 1080, 33, 33, 270, 270, 270, 33, 1080, 33, 1080, 270, 33, 1080, 1080, 270, 270, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 270, 1080, 1080, 270, 1080, 33, 270, 1080, 33, 1080, 270, 33, 270, 270, 1080, 1080, 33, 33, 1080, 33, 33, 33, 270, 33]
Prompts retrieved: 59436 . Total input tokens: 13178530 . Total output tokens: 11909268
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 1.9032295409124345,
    "estimated_duration": 3600.006459154546,
    "input_throughput": 1375.1905881754058,
    "output_throughput": 1209.3608857086492,
    "total_throughput": 2584.5514738840548,
    "itl": 24.961500241279964,
    "ttft": 6084.851105141941,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10519,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 34.81130673633997,
    "arrivals": 19983,
    "finished_requests": 19950,
    "scheduler_time": 0.010831857902566844
}
#Debug simulation 
Total elapsed time: 1.9033168589230627. Arrivals time: 0.06177094695158303 Scheduler time: 1.4414529430214316 Scheduler overhead time: 0.12879201909527183 Adapter cache time: 0.08442484098486602 Engine time: 0.12473036930896342 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_128_slots_32_rate_0.1-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_128_slots_32_rate_0.1-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 33, 33, 1080, 33, 270, 270, 270, 33, 1080, 270, 33, 1080, 270, 33, 33, 33, 33, 270, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 270, 33, 270, 33, 1080, 1080, 33, 270, 270, 33, 270, 33, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 33, 270, 1080, 1080, 270, 33, 33, 33, 1080, 270, 270, 270, 270, 1080, 270, 1080, 33, 33, 270, 33, 1080, 1080, 33, 33, 270, 270, 270, 33, 1080, 33, 1080, 270, 33, 1080, 1080, 270, 270, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 270, 1080, 1080, 270, 1080, 33, 270, 1080, 33, 1080, 270, 33, 270, 270, 1080, 1080, 33, 33, 1080, 33, 33, 33, 270, 33]
Prompts retrieved: 59436 . Total input tokens: 13178530 . Total output tokens: 11909268
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.8950567790307105,
    "estimated_duration": 3600.0244577765184,
    "input_throughput": 1375.183712795578,
    "output_throughput": 1209.354839408224,
    "total_throughput": 2584.538552203802,
    "itl": 25.04562207605649,
    "ttft": 6106.974380528823,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10469,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 31.30283653732763,
    "arrivals": 19983,
    "finished_requests": 19950,
    "scheduler_time": 0.009363464739520194
}
#Debug simulation 
Total elapsed time: 1.8951592470984906. Arrivals time: 0.06090252264402807 Scheduler time: 1.4387998534366488 Scheduler overhead time: 0.12729803752154112 Adapter cache time: 0.08305902476422489 Engine time: 0.12329529877752066 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_128_slots_32_rate_0.1-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_128_slots_32_rate_0.1-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 33, 33, 1080, 33, 270, 270, 270, 33, 1080, 270, 33, 1080, 270, 33, 33, 33, 33, 270, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 270, 33, 270, 33, 1080, 1080, 33, 270, 270, 33, 270, 33, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 33, 270, 1080, 1080, 270, 33, 33, 33, 1080, 270, 270, 270, 270, 1080, 270, 1080, 33, 33, 270, 33, 1080, 1080, 33, 33, 270, 270, 270, 33, 1080, 33, 1080, 270, 33, 1080, 1080, 270, 270, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 270, 1080, 1080, 270, 1080, 33, 270, 1080, 33, 1080, 270, 33, 270, 270, 1080, 1080, 33, 33, 1080, 33, 33, 33, 270, 33]
Prompts retrieved: 59436 . Total input tokens: 13178530 . Total output tokens: 11909268
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.9181851299945265,
    "estimated_duration": 3600.029374865369,
    "input_throughput": 1375.1818345052093,
    "output_throughput": 1209.3531876147028,
    "total_throughput": 2584.5350221199124,
    "itl": 24.96735107103055,
    "ttft": 6085.137070063923,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10518,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 35.33793245367516,
    "arrivals": 19983,
    "finished_requests": 19950,
    "scheduler_time": 0.010808684411171679
}
#Debug simulation 
Total elapsed time: 1.9182876199483871. Arrivals time: 0.06418786896392703 Scheduler time: 1.4520246419124305 Scheduler overhead time: 0.1287593173328787 Adapter cache time: 0.08448574366047978 Engine time: 0.12601827271282673 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_128_slots_32_rate_0.1-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_128_slots_32_rate_0.1-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 66, 66, 1080, 66, 135, 135, 135, 66, 1080, 135, 66, 1080, 135, 66, 66, 66, 66, 135, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 1080, 66, 135, 135, 66, 135, 66, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 66, 135, 1080, 1080, 135, 66, 66, 66, 1080, 135, 135, 135, 135, 1080, 135, 1080, 66, 66, 135, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 1080, 1080, 135, 135, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 135, 1080, 1080, 135, 1080, 66, 135, 1080, 66, 1080, 135, 66, 135, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66]
Prompts retrieved: 55017 . Total input tokens: 12180588 . Total output tokens: 11013970
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.800456898054108,
    "estimated_duration": 3600.0251441217874,
    "input_throughput": 1277.5594102473883,
    "output_throughput": 1132.5012567362435,
    "total_throughput": 2410.0606669836316,
    "itl": 24.187360032771334,
    "ttft": 6442.435147592931,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8975,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.46787750179839,
    "arrivals": 18589,
    "finished_requests": 18556,
    "scheduler_time": 0.0034558868169965937
}
#Debug simulation 
Total elapsed time: 1.800544616067782. Arrivals time: 0.05804146407172084 Scheduler time: 1.3422275104094297 Scheduler overhead time: 0.1303657277021557 Adapter cache time: 0.07859006011858582 Engine time: 0.1279588348697871 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_128_slots_32_rate_0.1-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_128_slots_32_rate_0.1-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 66, 66, 1080, 66, 135, 135, 135, 66, 1080, 135, 66, 1080, 135, 66, 66, 66, 66, 135, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 1080, 66, 135, 135, 66, 135, 66, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 66, 135, 1080, 1080, 135, 66, 66, 66, 1080, 135, 135, 135, 135, 1080, 135, 1080, 66, 66, 135, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 1080, 1080, 135, 135, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 135, 1080, 1080, 135, 1080, 66, 135, 1080, 66, 1080, 135, 66, 135, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66]
Prompts retrieved: 55017 . Total input tokens: 12180588 . Total output tokens: 11013970
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.7887744260951877,
    "estimated_duration": 3600.001060710348,
    "input_throughput": 1277.5679569084577,
    "output_throughput": 1132.508832982267,
    "total_throughput": 2410.0767898907247,
    "itl": 24.334265882361528,
    "ttft": 6253.673587405505,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8943,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.229591062563465,
    "arrivals": 18589,
    "finished_requests": 18556,
    "scheduler_time": 0.0036537067260267843
}
#Debug simulation 
Total elapsed time: 1.788868882926181. Arrivals time: 0.058250671019777656 Scheduler time: 1.33181592496112 Scheduler overhead time: 0.13076470396481454 Adapter cache time: 0.07718798122368753 Engine time: 0.12763284868560731 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_128_slots_32_rate_0.1-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_128_slots_32_rate_0.1-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 66, 66, 1080, 66, 135, 135, 135, 66, 1080, 135, 66, 1080, 135, 66, 66, 66, 66, 135, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 1080, 66, 135, 135, 66, 135, 66, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 66, 135, 1080, 1080, 135, 66, 66, 66, 1080, 135, 135, 135, 135, 1080, 135, 1080, 66, 66, 135, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 1080, 1080, 135, 135, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 135, 1080, 1080, 135, 1080, 66, 135, 1080, 66, 1080, 135, 66, 135, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66]
Prompts retrieved: 55017 . Total input tokens: 12180588 . Total output tokens: 11013970
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.7961206759791821,
    "estimated_duration": 3600.010365603651,
    "input_throughput": 1277.5646547975416,
    "output_throughput": 1132.5059058035133,
    "total_throughput": 2410.070560601055,
    "itl": 24.33457291446127,
    "ttft": 6253.666464840391,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8944,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.276081567575485,
    "arrivals": 18589,
    "finished_requests": 18556,
    "scheduler_time": 0.003665680965254174
}
#Debug simulation 
Total elapsed time: 1.7962015690281987. Arrivals time: 0.05834576231427491 Scheduler time: 1.339265788672492 Scheduler overhead time: 0.13035682123154402 Adapter cache time: 0.07724270597100258 Engine time: 0.12794831162318587 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_128_slots_32_rate_0.1-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_128_slots_32_rate_0.1-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 66, 66, 1080, 66, 135, 135, 135, 66, 1080, 135, 66, 1080, 135, 66, 66, 66, 66, 135, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 1080, 66, 135, 135, 66, 135, 66, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 66, 135, 1080, 1080, 135, 66, 66, 66, 1080, 135, 135, 135, 135, 1080, 135, 1080, 66, 66, 135, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 1080, 1080, 135, 135, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 135, 1080, 1080, 135, 1080, 66, 135, 1080, 66, 1080, 135, 66, 135, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66]
Prompts retrieved: 55017 . Total input tokens: 12180588 . Total output tokens: 11013970
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 1.792679576901719,
    "estimated_duration": 3600.011319261055,
    "input_throughput": 1277.5643163655523,
    "output_throughput": 1132.5056057981672,
    "total_throughput": 2410.069922163719,
    "itl": 24.325577788063693,
    "ttft": 6253.349318998579,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8945,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.17690069307517,
    "arrivals": 18589,
    "finished_requests": 18556,
    "scheduler_time": 0.0036627905130146676
}
#Debug simulation 
Total elapsed time: 1.792768144980073. Arrivals time: 0.05772067210637033 Scheduler time: 1.3390526047442108 Scheduler overhead time: 0.13033019728027284 Adapter cache time: 0.07709035649895668 Engine time: 0.12567810318432748 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_128_slots_32_rate_0.1-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_128_slots_32_rate_0.1-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 66, 66, 1080, 66, 135, 135, 135, 66, 1080, 135, 66, 1080, 135, 66, 66, 66, 66, 135, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 1080, 66, 135, 135, 66, 135, 66, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 66, 135, 1080, 1080, 135, 66, 66, 66, 1080, 135, 135, 135, 135, 1080, 135, 1080, 66, 66, 135, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 1080, 1080, 135, 135, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 135, 1080, 1080, 135, 1080, 66, 135, 1080, 66, 1080, 135, 66, 135, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66]
Prompts retrieved: 55017 . Total input tokens: 12180588 . Total output tokens: 11013970
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 1.805088423192501,
    "estimated_duration": 3600.0196624820137,
    "input_throughput": 1277.561355548007,
    "output_throughput": 1132.5029811612508,
    "total_throughput": 2410.0643367092575,
    "itl": 24.33746515719653,
    "ttft": 6446.915741137846,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8943,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.598780369404334,
    "arrivals": 18589,
    "finished_requests": 18556,
    "scheduler_time": 0.0036716810535789572
}
#Debug simulation 
Total elapsed time: 1.8051679900381714. Arrivals time: 0.05818936228752136 Scheduler time: 1.3505489702802151 Scheduler overhead time: 0.13023887714371085 Adapter cache time: 0.07743485714308918 Engine time: 0.1256800377741456 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_128_slots_32_rate_0.1-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_128_slots_32_rate_0.1-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 66, 66, 1080, 66, 135, 135, 135, 66, 1080, 135, 66, 1080, 135, 66, 66, 66, 66, 135, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 1080, 66, 135, 135, 66, 135, 66, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 66, 135, 1080, 1080, 135, 66, 66, 66, 1080, 135, 135, 135, 135, 1080, 135, 1080, 66, 66, 135, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 1080, 1080, 135, 135, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 135, 1080, 1080, 135, 1080, 66, 135, 1080, 66, 1080, 135, 66, 135, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66]
Prompts retrieved: 55017 . Total input tokens: 12180588 . Total output tokens: 11013970
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.7968710020650178,
    "estimated_duration": 3600.0281555676524,
    "input_throughput": 1277.5583415610233,
    "output_throughput": 1132.5003093919229,
    "total_throughput": 2410.058650952946,
    "itl": 24.181083007818316,
    "ttft": 6442.384099200625,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8968,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.814771044680956,
    "arrivals": 18589,
    "finished_requests": 18556,
    "scheduler_time": 0.0034390337837189285
}
#Debug simulation 
Total elapsed time: 1.796958280960098. Arrivals time: 0.058621548814699054 Scheduler time: 1.3366051861084998 Scheduler overhead time: 0.1306200309190899 Adapter cache time: 0.07859148224815726 Engine time: 0.12926281616091728 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_128_slots_32_rate_0.1-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_128_slots_32_rate_0.1-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 66, 66, 1080, 66, 135, 135, 135, 66, 1080, 135, 66, 1080, 135, 66, 66, 66, 66, 135, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 1080, 66, 135, 135, 66, 135, 66, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 66, 135, 1080, 1080, 135, 66, 66, 66, 1080, 135, 135, 135, 135, 1080, 135, 1080, 66, 66, 135, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 1080, 1080, 135, 135, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 135, 1080, 1080, 135, 1080, 66, 135, 1080, 66, 1080, 135, 66, 135, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66]
Prompts retrieved: 55017 . Total input tokens: 12180588 . Total output tokens: 11013970
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.7983070749323815,
    "estimated_duration": 3600.0025526920535,
    "input_throughput": 1277.5674274343833,
    "output_throughput": 1132.508363626361,
    "total_throughput": 2410.0757910607445,
    "itl": 24.340962052733644,
    "ttft": 6253.7531254182095,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8944,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 30.04276238947858,
    "arrivals": 18589,
    "finished_requests": 18556,
    "scheduler_time": 0.0036878602857439544
}
#Debug simulation 
Total elapsed time: 1.7983948700129986. Arrivals time: 0.05793289397843182 Scheduler time: 1.3427521858830005 Scheduler overhead time: 0.13012342271395028 Adapter cache time: 0.07767831860110164 Engine time: 0.1266052615828812 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_128_slots_32_rate_0.1-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_128_slots_32_rate_0.1-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 33, 33, 1080, 33, 135, 135, 135, 33, 1080, 135, 33, 1080, 135, 33, 33, 33, 33, 135, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 1080, 33, 135, 135, 33, 135, 33, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 33, 135, 1080, 1080, 135, 33, 33, 33, 1080, 135, 135, 135, 135, 1080, 135, 1080, 33, 33, 135, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 1080, 1080, 135, 135, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 135, 1080, 1080, 135, 1080, 33, 135, 1080, 33, 1080, 135, 33, 135, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33]
Prompts retrieved: 53631 . Total input tokens: 11885169 . Total output tokens: 10748452
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.795367038110271,
    "estimated_duration": 3599.8246243084973,
    "input_throughput": 1234.5451414466313,
    "output_throughput": 1119.0181246048353,
    "total_throughput": 2353.5632660514666,
    "itl": 24.05285345161168,
    "ttft": 6017.247619812011,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8419,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.766246316171227,
    "arrivals": 18102,
    "finished_requests": 18072,
    "scheduler_time": 0.0015072655800585733
}
#Debug simulation 
Total elapsed time: 1.795454025035724. Arrivals time: 0.05672475858591497 Scheduler time: 1.3225057281088084 Scheduler overhead time: 0.1408185597974807 Adapter cache time: 0.0774812854360789 Engine time: 0.13246144470758736 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_128_slots_32_rate_0.1-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_128_slots_32_rate_0.1-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 33, 33, 1080, 33, 135, 135, 135, 33, 1080, 135, 33, 1080, 135, 33, 33, 33, 33, 135, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 1080, 33, 135, 135, 33, 135, 33, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 33, 135, 1080, 1080, 135, 33, 33, 33, 1080, 135, 135, 135, 135, 1080, 135, 1080, 33, 33, 135, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 1080, 1080, 135, 135, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 135, 1080, 1080, 135, 1080, 33, 135, 1080, 33, 1080, 135, 33, 135, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33]
Prompts retrieved: 53631 . Total input tokens: 11885169 . Total output tokens: 10748452
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.7653781480621547,
    "estimated_duration": 3599.8262287174985,
    "input_throughput": 1234.5445912213672,
    "output_throughput": 1119.017625868886,
    "total_throughput": 2353.562217090253,
    "itl": 24.06888174474587,
    "ttft": 6017.508852790936,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8429,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.57135240140757,
    "arrivals": 18102,
    "finished_requests": 18072,
    "scheduler_time": 0.001532208229418737
}
#Debug simulation 
Total elapsed time: 1.7654888569377363. Arrivals time: 0.0569170149974525 Scheduler time: 1.3116183867678046 Scheduler overhead time: 0.13073083572089672 Adapter cache time: 0.07593406038358808 Engine time: 0.1265516709536314 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_128_slots_32_rate_0.1-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_128_slots_32_rate_0.1-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 33, 33, 1080, 33, 135, 135, 135, 33, 1080, 135, 33, 1080, 135, 33, 33, 33, 33, 135, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 1080, 33, 135, 135, 33, 135, 33, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 33, 135, 1080, 1080, 135, 33, 33, 33, 1080, 135, 135, 135, 135, 1080, 135, 1080, 33, 33, 135, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 1080, 1080, 135, 135, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 135, 1080, 1080, 135, 1080, 33, 135, 1080, 33, 1080, 135, 33, 135, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33]
Prompts retrieved: 53631 . Total input tokens: 11885169 . Total output tokens: 10748452
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.777909193886444,
    "estimated_duration": 3599.8293923212723,
    "input_throughput": 1234.543506278304,
    "output_throughput": 1119.0166424532852,
    "total_throughput": 2353.5601487315894,
    "itl": 24.07001375713068,
    "ttft": 6017.344196314731,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8423,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.58855950402182,
    "arrivals": 18102,
    "finished_requests": 18072,
    "scheduler_time": 0.0015448232082315597
}
#Debug simulation 
Total elapsed time: 1.7779972448479384. Arrivals time: 0.0565307573415339 Scheduler time: 1.322122368728742 Scheduler overhead time: 0.13160903565585613 Adapter cache time: 0.07552509685046971 Engine time: 0.1278113150037825 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_128_slots_32_rate_0.1-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_128_slots_32_rate_0.1-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 33, 33, 1080, 33, 135, 135, 135, 33, 1080, 135, 33, 1080, 135, 33, 33, 33, 33, 135, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 1080, 33, 135, 135, 33, 135, 33, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 33, 135, 1080, 1080, 135, 33, 33, 33, 1080, 135, 135, 135, 135, 1080, 135, 1080, 33, 33, 135, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 1080, 1080, 135, 135, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 135, 1080, 1080, 135, 1080, 33, 135, 1080, 33, 1080, 135, 33, 135, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33]
Prompts retrieved: 53631 . Total input tokens: 11885169 . Total output tokens: 10748452
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 1.8187936609610915,
    "estimated_duration": 3599.831627342308,
    "input_throughput": 1234.5427397894814,
    "output_throughput": 1119.0159476914203,
    "total_throughput": 2353.5586874809014,
    "itl": 24.06112894653555,
    "ttft": 6017.243765012563,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8432,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.613586028863182,
    "arrivals": 18102,
    "finished_requests": 18072,
    "scheduler_time": 0.0015202339901913477
}
#Debug simulation 
Total elapsed time: 1.818880934966728. Arrivals time: 0.05720855598337948 Scheduler time: 1.3571005056146532 Scheduler overhead time: 0.1340223103761673 Adapter cache time: 0.0762694280128926 Engine time: 0.12954159267246723 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_128_slots_32_rate_0.1-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_128_slots_32_rate_0.1-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 33, 33, 1080, 33, 135, 135, 135, 33, 1080, 135, 33, 1080, 135, 33, 33, 33, 33, 135, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 1080, 33, 135, 135, 33, 135, 33, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 33, 135, 1080, 1080, 135, 33, 33, 33, 1080, 135, 135, 135, 135, 1080, 135, 1080, 33, 33, 135, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 1080, 1080, 135, 135, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 135, 1080, 1080, 135, 1080, 33, 135, 1080, 33, 1080, 135, 33, 135, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33]
Prompts retrieved: 53631 . Total input tokens: 11885169 . Total output tokens: 10748452
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 1.7716092930641025,
    "estimated_duration": 3599.8239762477037,
    "input_throughput": 1234.5453636964717,
    "output_throughput": 1119.0183260568447,
    "total_throughput": 2353.5636897533163,
    "itl": 24.072023271338715,
    "ttft": 6017.548183507055,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8429,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.90616606702988,
    "arrivals": 18102,
    "finished_requests": 18072,
    "scheduler_time": 0.0015490282011691673
}
#Debug simulation 
Total elapsed time: 1.7716990979388356. Arrivals time: 0.05697244731709361 Scheduler time: 1.3164323973469436 Scheduler overhead time: 0.13100300473161042 Adapter cache time: 0.07581414747983217 Engine time: 0.12803448410704732 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_128_slots_32_rate_0.1-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_128_slots_32_rate_0.1-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 33, 33, 1080, 33, 135, 135, 135, 33, 1080, 135, 33, 1080, 135, 33, 33, 33, 33, 135, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 1080, 33, 135, 135, 33, 135, 33, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 33, 135, 1080, 1080, 135, 33, 33, 33, 1080, 135, 135, 135, 135, 1080, 135, 1080, 33, 33, 135, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 1080, 1080, 135, 135, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 135, 1080, 1080, 135, 1080, 33, 135, 1080, 33, 1080, 135, 33, 135, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33]
Prompts retrieved: 53631 . Total input tokens: 11885169 . Total output tokens: 10748452
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.7968544799368829,
    "estimated_duration": 3599.828404762041,
    "input_throughput": 1234.5438449569017,
    "output_throughput": 1119.0169494388108,
    "total_throughput": 2353.5607943957125,
    "itl": 24.047775119250986,
    "ttft": 6017.187299456437,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8425,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.191173734549615,
    "arrivals": 18102,
    "finished_requests": 18072,
    "scheduler_time": 0.0015123045590052073
}
#Debug simulation 
Total elapsed time: 1.7969519719481468. Arrivals time: 0.05830700183287263 Scheduler time: 1.337188862496987 Scheduler overhead time: 0.13268052856437862 Adapter cache time: 0.07598145212978125 Engine time: 0.12840331345796585 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_128_slots_32_rate_0.1-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_128_slots_32_rate_0.1-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 33, 33, 1080, 33, 135, 135, 135, 33, 1080, 135, 33, 1080, 135, 33, 33, 33, 33, 135, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 1080, 33, 135, 135, 33, 135, 33, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 33, 135, 1080, 1080, 135, 33, 33, 33, 1080, 135, 135, 135, 135, 1080, 135, 1080, 33, 33, 135, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 1080, 1080, 135, 135, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 135, 1080, 1080, 135, 1080, 33, 135, 1080, 33, 1080, 135, 33, 135, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33]
Prompts retrieved: 53631 . Total input tokens: 11885169 . Total output tokens: 10748452
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.766574211185798,
    "estimated_duration": 3599.8387422446635,
    "input_throughput": 1234.540299777115,
    "output_throughput": 1119.0137360120166,
    "total_throughput": 2353.554035789132,
    "itl": 24.074996481998436,
    "ttft": 6017.548814904232,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8422,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.313293161017366,
    "arrivals": 18102,
    "finished_requests": 18072,
    "scheduler_time": 0.0015255933389306982
}
#Debug simulation 
Total elapsed time: 1.7666545351967216. Arrivals time: 0.05633600219152868 Scheduler time: 1.3118597210850567 Scheduler overhead time: 0.13132810033857822 Adapter cache time: 0.07541276584379375 Engine time: 0.12833405821584165 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_128_slots_32_rate_0.1-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_128_slots_32_rate_0.1-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 66, 1080, 1080, 33, 33, 1080, 33, 66, 66, 66, 33, 1080, 66, 33, 1080, 66, 33, 33, 33, 33, 66, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 1080, 33, 66, 66, 33, 66, 33, 66, 66, 1080, 1080, 1080, 1080, 66, 66, 33, 66, 1080, 1080, 66, 33, 33, 33, 1080, 66, 66, 66, 66, 1080, 66, 1080, 33, 33, 66, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 1080, 1080, 66, 66, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 66, 1080, 1080, 66, 1080, 33, 66, 1080, 33, 1080, 66, 33, 66, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33]
Prompts retrieved: 50664 . Total input tokens: 11220806 . Total output tokens: 10144425
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.6858827939722687,
    "estimated_duration": 3600.0029781215508,
    "input_throughput": 1192.6454022658404,
    "output_throughput": 1037.6263638396013,
    "total_throughput": 2230.2717661054417,
    "itl": 23.2408462839731,
    "ttft": 4446.328214319771,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6671,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.416513739775034,
    "arrivals": 17157,
    "finished_requests": 17135,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6859774459153414. Arrivals time: 0.05531366588547826 Scheduler time: 1.2308759556617588 Scheduler overhead time: 0.134728095959872 Adapter cache time: 0.06983270612545311 Engine time: 0.12992253061383963 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_128_slots_32_rate_0.1-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_128_slots_32_rate_0.1-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 66, 1080, 1080, 33, 33, 1080, 33, 66, 66, 66, 33, 1080, 66, 33, 1080, 66, 33, 33, 33, 33, 66, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 1080, 33, 66, 66, 33, 66, 33, 66, 66, 1080, 1080, 1080, 1080, 66, 66, 33, 66, 1080, 1080, 66, 33, 33, 33, 1080, 66, 66, 66, 66, 1080, 66, 1080, 33, 33, 66, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 1080, 1080, 66, 66, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 66, 1080, 1080, 66, 1080, 33, 66, 1080, 33, 1080, 66, 33, 66, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33]
Prompts retrieved: 50664 . Total input tokens: 11220806 . Total output tokens: 10144425
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.6945247668772936,
    "estimated_duration": 3600.023807905352,
    "input_throughput": 1192.6385016042875,
    "output_throughput": 1037.6203601201876,
    "total_throughput": 2230.258861724475,
    "itl": 23.252407660571095,
    "ttft": 4656.0562565864075,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6672,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.835691557506905,
    "arrivals": 17157,
    "finished_requests": 17135,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6945984628982842. Arrivals time: 0.054332135478034616 Scheduler time: 1.2385494653135538 Scheduler overhead time: 0.13562807836569846 Adapter cache time: 0.06983161182142794 Engine time: 0.13059143722057343 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_128_slots_32_rate_0.1-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_128_slots_32_rate_0.1-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 66, 1080, 1080, 33, 33, 1080, 33, 66, 66, 66, 33, 1080, 66, 33, 1080, 66, 33, 33, 33, 33, 66, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 1080, 33, 66, 66, 33, 66, 33, 66, 66, 1080, 1080, 1080, 1080, 66, 66, 33, 66, 1080, 1080, 66, 33, 33, 33, 1080, 66, 66, 66, 66, 1080, 66, 1080, 33, 33, 66, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 1080, 1080, 66, 66, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 66, 1080, 1080, 66, 1080, 33, 66, 1080, 33, 1080, 66, 33, 66, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33]
Prompts retrieved: 50664 . Total input tokens: 11220806 . Total output tokens: 10144425
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.6981834350153804,
    "estimated_duration": 3600.0041110428133,
    "input_throughput": 1192.6450269403426,
    "output_throughput": 1037.6260372985935,
    "total_throughput": 2230.271064238936,
    "itl": 23.253874000498314,
    "ttft": 4446.510320804694,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6672,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.864103936236088,
    "arrivals": 17157,
    "finished_requests": 17135,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6982731318566948. Arrivals time: 0.05480295792222023 Scheduler time: 1.2417076216079295 Scheduler overhead time: 0.13539378251880407 Adapter cache time: 0.06961152120493352 Engine time: 0.1311278473585844 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_128_slots_32_rate_0.1-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_128_slots_32_rate_0.1-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 66, 1080, 1080, 33, 33, 1080, 33, 66, 66, 66, 33, 1080, 66, 33, 1080, 66, 33, 33, 33, 33, 66, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 1080, 33, 66, 66, 33, 66, 33, 66, 66, 1080, 1080, 1080, 1080, 66, 66, 33, 66, 1080, 1080, 66, 33, 33, 33, 1080, 66, 66, 66, 66, 1080, 66, 1080, 33, 33, 66, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 1080, 1080, 66, 66, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 66, 1080, 1080, 66, 1080, 33, 66, 1080, 33, 1080, 66, 33, 66, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33]
Prompts retrieved: 50664 . Total input tokens: 11220806 . Total output tokens: 10144425
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 1.7097335681319237,
    "estimated_duration": 3600.015666788242,
    "input_throughput": 1192.6411986508033,
    "output_throughput": 1037.6227066068834,
    "total_throughput": 2230.263905257687,
    "itl": 23.245218246580006,
    "ttft": 4656.028522701408,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6669,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.077357592603228,
    "arrivals": 17157,
    "finished_requests": 17135,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.7098242661450058. Arrivals time: 0.055488240672275424 Scheduler time: 1.250449936836958 Scheduler overhead time: 0.13529705465771258 Adapter cache time: 0.07046509883366525 Engine time: 0.13214406254701316 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_128_slots_32_rate_0.1-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_128_slots_32_rate_0.1-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 66, 1080, 1080, 33, 33, 1080, 33, 66, 66, 66, 33, 1080, 66, 33, 1080, 66, 33, 33, 33, 33, 66, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 1080, 33, 66, 66, 33, 66, 33, 66, 66, 1080, 1080, 1080, 1080, 66, 66, 33, 66, 1080, 1080, 66, 33, 33, 33, 1080, 66, 66, 66, 66, 1080, 66, 1080, 33, 33, 66, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 1080, 1080, 66, 66, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 66, 1080, 1080, 66, 1080, 33, 66, 1080, 33, 1080, 66, 33, 66, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33]
Prompts retrieved: 50664 . Total input tokens: 11220806 . Total output tokens: 10144425
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 1.7070749159902334,
    "estimated_duration": 3600.016845936326,
    "input_throughput": 1192.6408080135802,
    "output_throughput": 1037.6223667443555,
    "total_throughput": 2230.2631747579358,
    "itl": 23.255920782812264,
    "ttft": 4656.109860684209,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6670,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.087300352844544,
    "arrivals": 17157,
    "finished_requests": 17135,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.7071638589259237. Arrivals time: 0.054880500305444 Scheduler time: 1.2485702654812485 Scheduler overhead time: 0.1358073027804494 Adapter cache time: 0.07001291727647185 Engine time: 0.13199305743910372 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_128_slots_32_rate_0.1-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_128_slots_32_rate_0.1-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 66, 1080, 1080, 33, 33, 1080, 33, 66, 66, 66, 33, 1080, 66, 33, 1080, 66, 33, 33, 33, 33, 66, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 1080, 33, 66, 66, 33, 66, 33, 66, 66, 1080, 1080, 1080, 1080, 66, 66, 33, 66, 1080, 1080, 66, 33, 33, 33, 1080, 66, 66, 66, 66, 1080, 66, 1080, 33, 33, 66, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 1080, 1080, 66, 66, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 66, 1080, 1080, 66, 1080, 33, 66, 1080, 33, 1080, 66, 33, 66, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33]
Prompts retrieved: 50664 . Total input tokens: 11220806 . Total output tokens: 10144425
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.7027707030065358,
    "estimated_duration": 3600.016200067879,
    "input_throughput": 1192.6410219818024,
    "output_throughput": 1037.6225529011695,
    "total_throughput": 2230.263574882972,
    "itl": 23.237409661928645,
    "ttft": 4655.8606924908145,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6671,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.946625517292944,
    "arrivals": 17157,
    "finished_requests": 17135,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.7028540519531816. Arrivals time: 0.05458664591424167 Scheduler time: 1.2459795703180134 Scheduler overhead time: 0.13478180509991944 Adapter cache time: 0.0697124123107642 Engine time: 0.1322247029747814 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_128_slots_32_rate_0.1-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_128_slots_32_rate_0.1-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 66, 1080, 1080, 33, 33, 1080, 33, 66, 66, 66, 33, 1080, 66, 33, 1080, 66, 33, 33, 33, 33, 66, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 1080, 33, 66, 66, 33, 66, 33, 66, 66, 1080, 1080, 1080, 1080, 66, 66, 33, 66, 1080, 1080, 66, 33, 33, 33, 1080, 66, 66, 66, 66, 1080, 66, 1080, 33, 33, 66, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 1080, 1080, 66, 66, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 66, 1080, 1080, 66, 1080, 33, 66, 1080, 33, 1080, 66, 33, 66, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33]
Prompts retrieved: 50664 . Total input tokens: 11220806 . Total output tokens: 10144425
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.695279668085277,
    "estimated_duration": 3600.022889071835,
    "input_throughput": 1192.6388060013046,
    "output_throughput": 1037.6206249519385,
    "total_throughput": 2230.259430953243,
    "itl": 23.258471568241244,
    "ttft": 4656.107554772091,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6671,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.4409911542741,
    "arrivals": 17157,
    "finished_requests": 17135,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6953698100987822. Arrivals time: 0.056493165669962764 Scheduler time: 1.2363443931099027 Scheduler overhead time: 0.13600270892493427 Adapter cache time: 0.06981089082546532 Engine time: 0.13115971186198294 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_128_slots_32_rate_0.05-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_128_slots_32_rate_0.05-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 135, 135, 540, 135, 270, 270, 270, 135, 540, 270, 135, 540, 270, 135, 135, 135, 135, 270, 270, 540, 270, 135, 270, 270, 270, 270, 540, 270, 135, 270, 135, 540, 540, 135, 270, 270, 135, 270, 135, 270, 270, 540, 540, 540, 540, 270, 270, 135, 270, 540, 540, 270, 135, 135, 135, 540, 270, 270, 270, 270, 540, 270, 540, 135, 135, 270, 135, 540, 540, 135, 135, 270, 270, 270, 135, 540, 135, 540, 270, 135, 540, 540, 270, 270, 135, 135, 135, 540, 540, 540, 540, 540, 540, 540, 540, 135, 540, 135, 135, 540, 270, 540, 540, 270, 540, 135, 270, 540, 135, 540, 270, 135, 270, 270, 540, 540, 135, 135, 540, 135, 135, 135, 270, 135]
Prompts retrieved: 40500 . Total input tokens: 8939661 . Total output tokens: 8106807
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.4812563720624894,
    "estimated_duration": 3599.5291262578867,
    "input_throughput": 922.9076591619707,
    "output_throughput": 839.2708862841309,
    "total_throughput": 1762.1785454461017,
    "itl": 22.49343266906247,
    "ttft": 5541.8854747816185,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9445,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.906306741447253,
    "arrivals": 13744,
    "finished_requests": 13723,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4813332890626043. Arrivals time: 0.04698540410026908 Scheduler time: 1.0199187833350152 Scheduler overhead time: 0.1369069388601929 Adapter cache time: 0.07626408082433045 Engine time: 0.1334437953773886 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_128_slots_32_rate_0.05-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_128_slots_32_rate_0.05-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 135, 135, 540, 135, 270, 270, 270, 135, 540, 270, 135, 540, 270, 135, 135, 135, 135, 270, 270, 540, 270, 135, 270, 270, 270, 270, 540, 270, 135, 270, 135, 540, 540, 135, 270, 270, 135, 270, 135, 270, 270, 540, 540, 540, 540, 270, 270, 135, 270, 540, 540, 270, 135, 135, 135, 540, 270, 270, 270, 270, 540, 270, 540, 135, 135, 270, 135, 540, 540, 135, 135, 270, 270, 270, 135, 540, 135, 540, 270, 135, 540, 540, 270, 270, 135, 135, 135, 540, 540, 540, 540, 540, 540, 540, 540, 135, 540, 135, 135, 540, 270, 540, 540, 270, 540, 135, 270, 540, 135, 540, 270, 135, 270, 270, 540, 540, 135, 135, 540, 135, 135, 135, 270, 135]
Prompts retrieved: 40500 . Total input tokens: 8939661 . Total output tokens: 8106807
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.4909460118506104,
    "estimated_duration": 3599.5302847493654,
    "input_throughput": 922.9073621285875,
    "output_throughput": 839.27061616884,
    "total_throughput": 1762.1779782974274,
    "itl": 22.508539943942097,
    "ttft": 5541.9829366166105,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9447,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 30.87386443818953,
    "arrivals": 13744,
    "finished_requests": 13723,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4910360008943826. Arrivals time: 0.04940535989589989 Scheduler time: 1.020500578917563 Scheduler overhead time: 0.1419244648423046 Adapter cache time: 0.07720129750669003 Engine time: 0.13379141758196056 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_128_slots_32_rate_0.05-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_128_slots_32_rate_0.05-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 135, 135, 540, 135, 270, 270, 270, 135, 540, 270, 135, 540, 270, 135, 135, 135, 135, 270, 270, 540, 270, 135, 270, 270, 270, 270, 540, 270, 135, 270, 135, 540, 540, 135, 270, 270, 135, 270, 135, 270, 270, 540, 540, 540, 540, 270, 270, 135, 270, 540, 540, 270, 135, 135, 135, 540, 270, 270, 270, 270, 540, 270, 540, 135, 135, 270, 135, 540, 540, 135, 135, 270, 270, 270, 135, 540, 135, 540, 270, 135, 540, 540, 270, 270, 135, 135, 135, 540, 540, 540, 540, 540, 540, 540, 540, 135, 540, 135, 135, 540, 270, 540, 540, 270, 540, 135, 270, 540, 135, 540, 270, 135, 270, 270, 540, 540, 135, 135, 540, 135, 135, 135, 270, 135]
Prompts retrieved: 40500 . Total input tokens: 8939661 . Total output tokens: 8106807
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.4993240491021425,
    "estimated_duration": 3599.5418170035514,
    "input_throughput": 922.9044053071831,
    "output_throughput": 839.2679273038209,
    "total_throughput": 1762.172332611004,
    "itl": 22.51072986642177,
    "ttft": 5542.0880435451445,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9446,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 30.91724318782017,
    "arrivals": 13744,
    "finished_requests": 13723,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.499411391094327. Arrivals time: 0.047753354301676154 Scheduler time: 1.0341385384090245 Scheduler overhead time: 0.13701625168323517 Adapter cache time: 0.07706424337811768 Engine time: 0.13659951416775584 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_128_slots_32_rate_0.05-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_128_slots_32_rate_0.05-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 135, 135, 540, 135, 270, 270, 270, 135, 540, 270, 135, 540, 270, 135, 135, 135, 135, 270, 270, 540, 270, 135, 270, 270, 270, 270, 540, 270, 135, 270, 135, 540, 540, 135, 270, 270, 135, 270, 135, 270, 270, 540, 540, 540, 540, 270, 270, 135, 270, 540, 540, 270, 135, 135, 135, 540, 270, 270, 270, 270, 540, 270, 540, 135, 135, 270, 135, 540, 540, 135, 135, 270, 270, 270, 135, 540, 135, 540, 270, 135, 540, 540, 270, 270, 135, 135, 135, 540, 540, 540, 540, 540, 540, 540, 540, 135, 540, 135, 135, 540, 270, 540, 540, 270, 540, 135, 270, 540, 135, 540, 270, 135, 270, 270, 540, 540, 135, 135, 540, 135, 135, 135, 270, 135]
Prompts retrieved: 40500 . Total input tokens: 8939661 . Total output tokens: 8106807
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 1.499012510990724,
    "estimated_duration": 3599.541883148917,
    "input_throughput": 922.9043883478446,
    "output_throughput": 839.2679118813907,
    "total_throughput": 1762.1723002292351,
    "itl": 22.50074297004679,
    "ttft": 5541.903366994887,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9447,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.688938014713454,
    "arrivals": 13744,
    "finished_requests": 13723,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4991118498146534. Arrivals time: 0.04771073395386338 Scheduler time: 1.0325420817825943 Scheduler overhead time: 0.1403247849084437 Adapter cache time: 0.0775939249433577 Engine time: 0.133447750704363 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_128_slots_32_rate_0.05-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_128_slots_32_rate_0.05-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 135, 135, 540, 135, 270, 270, 270, 135, 540, 270, 135, 540, 270, 135, 135, 135, 135, 270, 270, 540, 270, 135, 270, 270, 270, 270, 540, 270, 135, 270, 135, 540, 540, 135, 270, 270, 135, 270, 135, 270, 270, 540, 540, 540, 540, 270, 270, 135, 270, 540, 540, 270, 135, 135, 135, 540, 270, 270, 270, 270, 540, 270, 540, 135, 135, 270, 135, 540, 540, 135, 135, 270, 270, 270, 135, 540, 135, 540, 270, 135, 540, 540, 270, 270, 135, 135, 135, 540, 540, 540, 540, 540, 540, 540, 540, 135, 540, 135, 135, 540, 270, 540, 540, 270, 540, 135, 270, 540, 135, 540, 270, 135, 270, 270, 540, 540, 135, 135, 540, 135, 135, 135, 270, 135]
Prompts retrieved: 40500 . Total input tokens: 8939661 . Total output tokens: 8106807
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 1.4888205411843956,
    "estimated_duration": 3599.542655103007,
    "input_throughput": 922.904190422751,
    "output_throughput": 839.2677318928868,
    "total_throughput": 1762.1719223156376,
    "itl": 22.511782771617778,
    "ttft": 5542.071714621566,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9446,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 31.281466167140408,
    "arrivals": 13744,
    "finished_requests": 13723,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4889069481287152. Arrivals time: 0.049706366611644626 Scheduler time: 1.0236300071701407 Scheduler overhead time: 0.1391085721552372 Adapter cache time: 0.07674298458732665 Engine time: 0.13234496000222862 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_128_slots_32_rate_0.05-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_128_slots_32_rate_0.05-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 135, 135, 540, 135, 270, 270, 270, 135, 540, 270, 135, 540, 270, 135, 135, 135, 135, 270, 270, 540, 270, 135, 270, 270, 270, 270, 540, 270, 135, 270, 135, 540, 540, 135, 270, 270, 135, 270, 135, 270, 270, 540, 540, 540, 540, 270, 270, 135, 270, 540, 540, 270, 135, 135, 135, 540, 270, 270, 270, 270, 540, 270, 540, 135, 135, 270, 135, 540, 540, 135, 135, 270, 270, 270, 135, 540, 135, 540, 270, 135, 540, 540, 270, 270, 135, 135, 135, 540, 540, 540, 540, 540, 540, 540, 540, 135, 540, 135, 135, 540, 270, 540, 540, 270, 540, 135, 270, 540, 135, 540, 270, 135, 270, 270, 540, 540, 135, 135, 540, 135, 135, 135, 270, 135]
Prompts retrieved: 40500 . Total input tokens: 8939661 . Total output tokens: 8106807
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.4848159421235323,
    "estimated_duration": 3599.5343808739685,
    "input_throughput": 922.9063118973207,
    "output_throughput": 839.2696611128089,
    "total_throughput": 1762.1759730101296,
    "itl": 22.487080448360114,
    "ttft": 5541.84512190828,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9448,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.249995186233523,
    "arrivals": 13744,
    "finished_requests": 13723,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4848871191497892. Arrivals time: 0.04757401067763567 Scheduler time: 1.0228281836025417 Scheduler overhead time: 0.13797977566719055 Adapter cache time: 0.07695319736376405 Engine time: 0.13265742920339108 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_128_slots_32_rate_0.05-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_128_slots_32_rate_0.05-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 135, 135, 540, 135, 270, 270, 270, 135, 540, 270, 135, 540, 270, 135, 135, 135, 135, 270, 270, 540, 270, 135, 270, 270, 270, 270, 540, 270, 135, 270, 135, 540, 540, 135, 270, 270, 135, 270, 135, 270, 270, 540, 540, 540, 540, 270, 270, 135, 270, 540, 540, 270, 135, 135, 135, 540, 270, 270, 270, 270, 540, 270, 540, 135, 135, 270, 135, 540, 540, 135, 135, 270, 270, 270, 135, 540, 135, 540, 270, 135, 540, 540, 270, 270, 135, 135, 135, 540, 540, 540, 540, 540, 540, 540, 540, 135, 540, 135, 135, 540, 270, 540, 540, 270, 540, 135, 270, 540, 135, 540, 270, 135, 270, 270, 540, 540, 135, 135, 540, 135, 135, 135, 270, 135]
Prompts retrieved: 40500 . Total input tokens: 8939661 . Total output tokens: 8106807
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.512730540940538,
    "estimated_duration": 3599.5262041938986,
    "input_throughput": 922.9084083703616,
    "output_throughput": 839.2715675969188,
    "total_throughput": 1762.1799759672804,
    "itl": 22.516350989169734,
    "ttft": 5542.113399428202,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9446,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 31.72478827811512,
    "arrivals": 13744,
    "finished_requests": 13723,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5128185159992427. Arrivals time: 0.04794271080754697 Scheduler time: 1.0443999413400888 Scheduler overhead time: 0.14004055759869516 Adapter cache time: 0.0772889400832355 Engine time: 0.13569991616532207 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_128_slots_32_rate_0.05-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_128_slots_32_rate_0.05-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 66, 66, 540, 66, 270, 270, 270, 66, 540, 270, 66, 540, 270, 66, 66, 66, 66, 270, 270, 540, 270, 66, 270, 270, 270, 270, 540, 270, 66, 270, 66, 540, 540, 66, 270, 270, 66, 270, 66, 270, 270, 540, 540, 540, 540, 270, 270, 66, 270, 540, 540, 270, 66, 66, 66, 540, 270, 270, 270, 270, 540, 270, 540, 66, 66, 270, 66, 540, 540, 66, 66, 270, 270, 270, 66, 540, 66, 540, 270, 66, 540, 540, 270, 270, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 270, 540, 540, 270, 540, 66, 270, 540, 66, 540, 270, 66, 270, 270, 540, 540, 66, 66, 540, 66, 66, 66, 270, 66]
Prompts retrieved: 37602 . Total input tokens: 8311855 . Total output tokens: 7507822
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.4055852550081909,
    "estimated_duration": 3599.921991003199,
    "input_throughput": 863.8320518532694,
    "output_throughput": 768.6799899874667,
    "total_throughput": 1632.512041840736,
    "itl": 21.897308543576848,
    "ttft": 5694.923369733584,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8239,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.215358522263152,
    "arrivals": 12728,
    "finished_requests": 12708,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4056746331043541. Arrivals time: 0.04471947834827006 Scheduler time: 0.9447508072480559 Scheduler overhead time: 0.13946030056104064 Adapter cache time: 0.07117486163042486 Engine time: 0.13725743582472205 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_128_slots_32_rate_0.05-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_128_slots_32_rate_0.05-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 66, 66, 540, 66, 270, 270, 270, 66, 540, 270, 66, 540, 270, 66, 66, 66, 66, 270, 270, 540, 270, 66, 270, 270, 270, 270, 540, 270, 66, 270, 66, 540, 540, 66, 270, 270, 66, 270, 66, 270, 270, 540, 540, 540, 540, 270, 270, 66, 270, 540, 540, 270, 66, 66, 66, 540, 270, 270, 270, 270, 540, 270, 540, 66, 66, 270, 66, 540, 540, 66, 66, 270, 270, 270, 66, 540, 66, 540, 270, 66, 540, 540, 270, 270, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 270, 540, 540, 270, 540, 66, 270, 540, 66, 540, 270, 66, 270, 270, 540, 540, 66, 66, 540, 66, 66, 66, 270, 66]
Prompts retrieved: 37602 . Total input tokens: 8311855 . Total output tokens: 7507822
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.4025612538680434,
    "estimated_duration": 3599.9311340198046,
    "input_throughput": 863.8298579138576,
    "output_throughput": 768.6780377129227,
    "total_throughput": 1632.5078956267803,
    "itl": 21.90904316262497,
    "ttft": 5695.026220281815,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8236,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.907650486982334,
    "arrivals": 12728,
    "finished_requests": 12708,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.402647215873003. Arrivals time: 0.04472966562025249 Scheduler time: 0.9411464082077146 Scheduler overhead time: 0.14032721263356507 Adapter cache time: 0.07133422628976405 Engine time: 0.1365003779064864 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_128_slots_32_rate_0.05-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_128_slots_32_rate_0.05-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 66, 66, 540, 66, 270, 270, 270, 66, 540, 270, 66, 540, 270, 66, 66, 66, 66, 270, 270, 540, 270, 66, 270, 270, 270, 270, 540, 270, 66, 270, 66, 540, 540, 66, 270, 270, 66, 270, 66, 270, 270, 540, 540, 540, 540, 270, 270, 66, 270, 540, 540, 270, 66, 66, 66, 540, 270, 270, 270, 270, 540, 270, 540, 66, 66, 270, 66, 540, 540, 66, 66, 270, 270, 270, 66, 540, 66, 540, 270, 66, 540, 540, 270, 270, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 270, 540, 540, 270, 540, 66, 270, 540, 66, 540, 270, 66, 270, 270, 540, 540, 66, 66, 540, 66, 66, 66, 270, 66]
Prompts retrieved: 37602 . Total input tokens: 8311855 . Total output tokens: 7507822
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.4440160680096596,
    "estimated_duration": 3599.929280363218,
    "input_throughput": 863.8303027125692,
    "output_throughput": 768.6784335165612,
    "total_throughput": 1632.5087362291304,
    "itl": 21.911101560424424,
    "ttft": 5695.004745199209,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8239,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.959416299462994,
    "arrivals": 12728,
    "finished_requests": 12708,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.444128769915551. Arrivals time: 0.04493399150669575 Scheduler time: 0.9777851551771164 Scheduler overhead time: 0.1416119474451989 Adapter cache time: 0.07233751332387328 Engine time: 0.13859169837087393 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_128_slots_32_rate_0.05-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_128_slots_32_rate_0.05-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 66, 66, 540, 66, 270, 270, 270, 66, 540, 270, 66, 540, 270, 66, 66, 66, 66, 270, 270, 540, 270, 66, 270, 270, 270, 270, 540, 270, 66, 270, 66, 540, 540, 66, 270, 270, 66, 270, 66, 270, 270, 540, 540, 540, 540, 270, 270, 66, 270, 540, 540, 270, 66, 66, 66, 540, 270, 270, 270, 270, 540, 270, 540, 66, 66, 270, 66, 540, 540, 66, 66, 270, 270, 270, 66, 540, 66, 540, 270, 66, 540, 540, 270, 270, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 270, 540, 540, 270, 540, 66, 270, 540, 66, 540, 270, 66, 270, 270, 540, 540, 66, 66, 540, 66, 66, 66, 270, 66]
Prompts retrieved: 37602 . Total input tokens: 8311855 . Total output tokens: 7507822
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 1.4044884210452437,
    "estimated_duration": 3599.92114349206,
    "input_throughput": 863.8322552208591,
    "output_throughput": 768.6801709538901,
    "total_throughput": 1632.5124261747492,
    "itl": 21.901450250175664,
    "ttft": 5694.943224898995,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8241,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.91255311127313,
    "arrivals": 12728,
    "finished_requests": 12708,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4045695681124926. Arrivals time: 0.0442137117497623 Scheduler time: 0.9458111359272152 Scheduler overhead time: 0.1393503174185753 Adapter cache time: 0.07167537021450698 Engine time: 0.13495793216861784 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_128_slots_32_rate_0.05-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_128_slots_32_rate_0.05-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 66, 66, 540, 66, 270, 270, 270, 66, 540, 270, 66, 540, 270, 66, 66, 66, 66, 270, 270, 540, 270, 66, 270, 270, 270, 270, 540, 270, 66, 270, 66, 540, 540, 66, 270, 270, 66, 270, 66, 270, 270, 540, 540, 540, 540, 270, 270, 66, 270, 540, 540, 270, 66, 66, 66, 540, 270, 270, 270, 270, 540, 270, 540, 66, 66, 270, 66, 540, 540, 66, 66, 270, 270, 270, 66, 540, 66, 540, 270, 66, 540, 540, 270, 270, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 270, 540, 540, 270, 540, 66, 270, 540, 66, 540, 270, 66, 270, 270, 540, 540, 66, 66, 540, 66, 66, 66, 270, 66]
Prompts retrieved: 37602 . Total input tokens: 8311855 . Total output tokens: 7507822
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 1.410953669808805,
    "estimated_duration": 3599.923555896171,
    "input_throughput": 863.8316763439882,
    "output_throughput": 768.6796558409507,
    "total_throughput": 1632.5113321849387,
    "itl": 21.912789662085547,
    "ttft": 5695.015524499329,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8236,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.260388868022115,
    "arrivals": 12728,
    "finished_requests": 12708,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4110424229875207. Arrivals time: 0.044730640249326825 Scheduler time: 0.9472457515075803 Scheduler overhead time: 0.1409847850445658 Adapter cache time: 0.07140127359889448 Engine time: 0.1380126087460667 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_128_slots_32_rate_0.05-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_128_slots_32_rate_0.05-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 66, 66, 540, 66, 270, 270, 270, 66, 540, 270, 66, 540, 270, 66, 66, 66, 66, 270, 270, 540, 270, 66, 270, 270, 270, 270, 540, 270, 66, 270, 66, 540, 540, 66, 270, 270, 66, 270, 66, 270, 270, 540, 540, 540, 540, 270, 270, 66, 270, 540, 540, 270, 66, 66, 66, 540, 270, 270, 270, 270, 540, 270, 540, 66, 66, 270, 66, 540, 540, 66, 66, 270, 270, 270, 66, 540, 66, 540, 270, 66, 540, 540, 270, 270, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 270, 540, 540, 270, 540, 66, 270, 540, 66, 540, 270, 66, 270, 270, 540, 540, 66, 66, 540, 66, 66, 66, 270, 66]
Prompts retrieved: 37602 . Total input tokens: 8311855 . Total output tokens: 7507822
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.395496989833191,
    "estimated_duration": 3599.9256698650047,
    "input_throughput": 863.8311690798364,
    "output_throughput": 768.6792044525097,
    "total_throughput": 1632.5103735323462,
    "itl": 21.8924834046302,
    "ttft": 5694.801963716617,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8238,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.632034329403094,
    "arrivals": 12728,
    "finished_requests": 12708,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3955821529962122. Arrivals time: 0.04441638640128076 Scheduler time: 0.9362092949450016 Scheduler overhead time: 0.1401506515685469 Adapter cache time: 0.07105070212855935 Engine time: 0.13491661683656275 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_128_slots_32_rate_0.05-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_128_slots_32_rate_0.05-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 66, 66, 540, 66, 270, 270, 270, 66, 540, 270, 66, 540, 270, 66, 66, 66, 66, 270, 270, 540, 270, 66, 270, 270, 270, 270, 540, 270, 66, 270, 66, 540, 540, 66, 270, 270, 66, 270, 66, 270, 270, 540, 540, 540, 540, 270, 270, 66, 270, 540, 540, 270, 66, 66, 66, 540, 270, 270, 270, 270, 540, 270, 540, 66, 66, 270, 66, 540, 540, 66, 66, 270, 270, 270, 66, 540, 66, 540, 270, 66, 540, 540, 270, 270, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 270, 540, 540, 270, 540, 66, 270, 540, 66, 540, 270, 66, 270, 270, 540, 540, 66, 66, 540, 66, 66, 66, 270, 66]
Prompts retrieved: 37602 . Total input tokens: 8311855 . Total output tokens: 7507822
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.4273406360298395,
    "estimated_duration": 3599.933304635705,
    "input_throughput": 863.8293370589788,
    "output_throughput": 768.6775742307885,
    "total_throughput": 1632.5069112897672,
    "itl": 21.91523915167903,
    "ttft": 5695.220906973703,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8241,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.668426989351932,
    "arrivals": 12728,
    "finished_requests": 12708,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4274298269301653. Arrivals time: 0.044816619250923395 Scheduler time: 0.9623528965748847 Scheduler overhead time: 0.14182151551358402 Adapter cache time: 0.0716011852491647 Engine time: 0.1377428516279906 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_128_slots_32_rate_0.05-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_128_slots_32_rate_0.05-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 33, 33, 540, 33, 270, 270, 270, 33, 540, 270, 33, 540, 270, 33, 33, 33, 33, 270, 270, 540, 270, 33, 270, 270, 270, 270, 540, 270, 33, 270, 33, 540, 540, 33, 270, 270, 33, 270, 33, 270, 270, 540, 540, 540, 540, 270, 270, 33, 270, 540, 540, 270, 33, 33, 33, 540, 270, 270, 270, 270, 540, 270, 540, 33, 33, 270, 33, 540, 540, 33, 33, 270, 270, 270, 33, 540, 33, 540, 270, 33, 540, 540, 270, 270, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 270, 540, 540, 270, 540, 33, 270, 540, 33, 540, 270, 33, 270, 270, 540, 540, 33, 33, 540, 33, 33, 33, 270, 33]
Prompts retrieved: 36216 . Total input tokens: 7995821 . Total output tokens: 7231656
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.3852401908952743,
    "estimated_duration": 3599.9406527929377,
    "input_throughput": 839.4985616374905,
    "output_throughput": 733.1448639166794,
    "total_throughput": 1572.6434255541699,
    "itl": 21.522433285310758,
    "ttft": 6493.274289637674,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7674,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.486182946940584,
    "arrivals": 12269,
    "finished_requests": 12247,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3853256409056485. Arrivals time: 0.0443378877826035 Scheduler time: 0.9195993733592331 Scheduler overhead time: 0.14429222466424108 Adapter cache time: 0.06944598280824721 Engine time: 0.13840747438371181 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_128_slots_32_rate_0.05-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_128_slots_32_rate_0.05-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 33, 33, 540, 33, 270, 270, 270, 33, 540, 270, 33, 540, 270, 33, 33, 33, 33, 270, 270, 540, 270, 33, 270, 270, 270, 270, 540, 270, 33, 270, 33, 540, 540, 33, 270, 270, 33, 270, 33, 270, 270, 540, 540, 540, 540, 270, 270, 33, 270, 540, 540, 270, 33, 33, 33, 540, 270, 270, 270, 270, 540, 270, 540, 33, 33, 270, 33, 540, 540, 33, 33, 270, 270, 270, 33, 540, 33, 540, 270, 33, 540, 540, 270, 270, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 270, 540, 540, 270, 540, 33, 270, 540, 33, 540, 270, 33, 270, 270, 540, 540, 33, 33, 540, 33, 33, 33, 270, 33]
Prompts retrieved: 36216 . Total input tokens: 7995821 . Total output tokens: 7231656
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.4054976301267743,
    "estimated_duration": 3599.945608305705,
    "input_throughput": 839.4974060239639,
    "output_throughput": 733.143854704561,
    "total_throughput": 1572.641260728525,
    "itl": 21.533880841023077,
    "ttft": 6493.315447061415,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7671,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.06464023062972,
    "arrivals": 12269,
    "finished_requests": 12247,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4055814880412072. Arrivals time: 0.04394754418171942 Scheduler time: 0.921677422709763 Scheduler overhead time: 0.1540018473751843 Adapter cache time: 0.0710150187369436 Engine time: 0.14390991814434528 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-32/adapters_128_slots_32_rate_0.05-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-32/adapters_128_slots_32_rate_0.05-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 33, 33, 540, 33, 270, 270, 270, 33, 540, 270, 33, 540, 270, 33, 33, 33, 33, 270, 270, 540, 270, 33, 270, 270, 270, 270, 540, 270, 33, 270, 33, 540, 540, 33, 270, 270, 33, 270, 33, 270, 270, 540, 540, 540, 540, 270, 270, 33, 270, 540, 540, 270, 33, 33, 33, 540, 270, 270, 270, 270, 540, 270, 540, 33, 33, 270, 33, 540, 540, 33, 33, 270, 270, 270, 33, 540, 33, 540, 270, 33, 540, 540, 270, 270, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 270, 540, 540, 270, 540, 33, 270, 540, 33, 540, 270, 33, 270, 270, 540, 540, 33, 33, 540, 33, 33, 33, 270, 33]
Prompts retrieved: 36216 . Total input tokens: 7995821 . Total output tokens: 7231656
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.360646186163649,
    "estimated_duration": 3599.951753976159,
    "input_throughput": 839.4959728729782,
    "output_throughput": 733.1426031154191,
    "total_throughput": 1572.6385759883972,
    "itl": 21.534492296217582,
    "ttft": 6493.433189514637,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7673,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.10997957311604,
    "arrivals": 12269,
    "finished_requests": 12247,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3607305032201111. Arrivals time: 0.04286391427740455 Scheduler time: 0.9002518060151488 Scheduler overhead time: 0.14085358404554427 Adapter cache time: 0.06861387495882809 Engine time: 0.13930768892169 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_128_slots_32_rate_0.05-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_128_slots_32_rate_0.05-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 33, 33, 540, 33, 270, 270, 270, 33, 540, 270, 33, 540, 270, 33, 33, 33, 33, 270, 270, 540, 270, 33, 270, 270, 270, 270, 540, 270, 33, 270, 33, 540, 540, 33, 270, 270, 33, 270, 33, 270, 270, 540, 540, 540, 540, 270, 270, 33, 270, 540, 540, 270, 33, 33, 33, 540, 270, 270, 270, 270, 540, 270, 540, 33, 33, 270, 33, 540, 540, 33, 33, 270, 270, 270, 33, 540, 33, 540, 270, 33, 540, 540, 270, 270, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 270, 540, 540, 270, 540, 33, 270, 540, 33, 540, 270, 33, 270, 270, 540, 540, 33, 33, 540, 33, 33, 33, 270, 33]
Prompts retrieved: 36216 . Total input tokens: 7995821 . Total output tokens: 7231656
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 1.3815811141394079,
    "estimated_duration": 3599.939640772375,
    "input_throughput": 839.498797638616,
    "output_throughput": 733.1450700194899,
    "total_throughput": 1572.643867658106,
    "itl": 21.52748538540604,
    "ttft": 6493.386393292883,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7670,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.148848238939816,
    "arrivals": 12269,
    "finished_requests": 12247,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3816671611275524. Arrivals time: 0.044173737056553364 Scheduler time: 0.9178277321625501 Scheduler overhead time: 0.1440368911717087 Adapter cache time: 0.0697503515984863 Engine time: 0.1366434572264552 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-32/adapters_128_slots_32_rate_0.05-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-32/adapters_128_slots_32_rate_0.05-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 33, 33, 540, 33, 270, 270, 270, 33, 540, 270, 33, 540, 270, 33, 33, 33, 33, 270, 270, 540, 270, 33, 270, 270, 270, 270, 540, 270, 33, 270, 33, 540, 540, 33, 270, 270, 33, 270, 33, 270, 270, 540, 540, 540, 540, 270, 270, 33, 270, 540, 540, 270, 33, 33, 33, 540, 270, 270, 270, 270, 540, 270, 540, 33, 33, 270, 33, 540, 540, 33, 33, 270, 270, 270, 33, 540, 33, 540, 270, 33, 540, 540, 270, 270, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 270, 540, 540, 270, 540, 33, 270, 540, 33, 540, 270, 33, 270, 270, 540, 540, 33, 33, 540, 33, 33, 33, 270, 33]
Prompts retrieved: 36216 . Total input tokens: 7995821 . Total output tokens: 7231656
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 1.3654102850705385,
    "estimated_duration": 3599.93843389052,
    "input_throughput": 839.4990790811697,
    "output_throughput": 733.1453158068826,
    "total_throughput": 1572.6443948880524,
    "itl": 21.536952948747338,
    "ttft": 6493.5459614821475,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7675,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.39733781715787,
    "arrivals": 12269,
    "finished_requests": 12247,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.365493319928646. Arrivals time: 0.0434018918313086 Scheduler time: 0.9044176468160003 Scheduler overhead time: 0.14058838970959187 Adapter cache time: 0.07152031385339797 Engine time: 0.1362633954267949 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_128_slots_32_rate_0.05-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_128_slots_32_rate_0.05-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 33, 33, 540, 33, 270, 270, 270, 33, 540, 270, 33, 540, 270, 33, 33, 33, 33, 270, 270, 540, 270, 33, 270, 270, 270, 270, 540, 270, 33, 270, 33, 540, 540, 33, 270, 270, 33, 270, 33, 270, 270, 540, 540, 540, 540, 270, 270, 33, 270, 540, 540, 270, 33, 33, 33, 540, 270, 270, 270, 270, 540, 270, 540, 33, 33, 270, 33, 540, 540, 33, 33, 270, 270, 270, 33, 540, 33, 540, 270, 33, 540, 540, 270, 270, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 270, 540, 540, 270, 540, 33, 270, 540, 33, 540, 270, 33, 270, 270, 540, 540, 33, 33, 540, 33, 33, 33, 270, 33]
Prompts retrieved: 36216 . Total input tokens: 7995821 . Total output tokens: 7231656
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.3727686230558902,
    "estimated_duration": 3599.9379801806017,
    "input_throughput": 839.4991848855088,
    "output_throughput": 733.1454082071693,
    "total_throughput": 1572.6445930926782,
    "itl": 21.519523493159095,
    "ttft": 6493.138409610398,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7671,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.936675812194125,
    "arrivals": 12269,
    "finished_requests": 12247,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.372852051164955. Arrivals time: 0.043908718740567565 Scheduler time: 0.9114654089789838 Scheduler overhead time: 0.1407689938787371 Adapter cache time: 0.06894412497058511 Engine time: 0.13874424528330564 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-32/adapters_128_slots_32_rate_0.05-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-32/adapters_128_slots_32_rate_0.05-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 33, 33, 540, 33, 270, 270, 270, 33, 540, 270, 33, 540, 270, 33, 33, 33, 33, 270, 270, 540, 270, 33, 270, 270, 270, 270, 540, 270, 33, 270, 33, 540, 540, 33, 270, 270, 33, 270, 33, 270, 270, 540, 540, 540, 540, 270, 270, 33, 270, 540, 540, 270, 33, 33, 33, 540, 270, 270, 270, 270, 540, 270, 540, 33, 33, 270, 33, 540, 540, 33, 33, 270, 270, 270, 33, 540, 33, 540, 270, 33, 540, 540, 270, 270, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 270, 540, 540, 270, 540, 33, 270, 540, 33, 540, 270, 33, 270, 270, 540, 540, 33, 33, 540, 33, 33, 33, 270, 33]
Prompts retrieved: 36216 . Total input tokens: 7995821 . Total output tokens: 7231656
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.3664450808428228,
    "estimated_duration": 3599.9426296343813,
    "input_throughput": 839.4981006424916,
    "output_throughput": 733.1444613238326,
    "total_throughput": 1572.6425619663244,
    "itl": 21.537937840988768,
    "ttft": 6493.609437090634,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7674,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.76773731790275,
    "arrivals": 12269,
    "finished_requests": 12247,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3665336270350963. Arrivals time: 0.04364060936495662 Scheduler time: 0.9050600123591721 Scheduler overhead time: 0.14130121795460582 Adapter cache time: 0.06889337790198624 Engine time: 0.13831661990843713 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_128_slots_32_rate_0.05-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_128_slots_32_rate_0.05-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 66, 66, 540, 66, 135, 135, 135, 66, 540, 135, 66, 540, 135, 66, 66, 66, 66, 135, 135, 540, 135, 66, 135, 135, 135, 135, 540, 135, 66, 135, 66, 540, 540, 66, 135, 135, 66, 135, 66, 135, 135, 540, 540, 540, 540, 135, 135, 66, 135, 540, 540, 135, 66, 66, 66, 540, 135, 135, 135, 135, 540, 135, 540, 66, 66, 135, 66, 540, 540, 66, 66, 135, 135, 135, 66, 540, 66, 540, 135, 66, 540, 540, 135, 135, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 135, 540, 540, 135, 540, 66, 135, 540, 66, 540, 135, 66, 135, 135, 540, 540, 66, 66, 540, 66, 66, 66, 135, 66]
Prompts retrieved: 31797 . Total input tokens: 7021629 . Total output tokens: 6368784
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.289250052999705,
    "estimated_duration": 3600.013075743816,
    "input_throughput": 728.1681885164755,
    "output_throughput": 658.6495521297755,
    "total_throughput": 1386.817740646251,
    "itl": 21.15242549749608,
    "ttft": 5389.45701250687,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6403,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.59630302440079,
    "arrivals": 10761,
    "finished_requests": 10745,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2893256798852235. Arrivals time: 0.04018000001087785 Scheduler time: 0.8339863675646484 Scheduler overhead time: 0.14193811197765172 Adapter cache time: 0.06274302373640239 Engine time: 0.1401017375756055 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_128_slots_32_rate_0.05-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_128_slots_32_rate_0.05-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 66, 66, 540, 66, 135, 135, 135, 66, 540, 135, 66, 540, 135, 66, 66, 66, 66, 135, 135, 540, 135, 66, 135, 135, 135, 135, 540, 135, 66, 135, 66, 540, 540, 66, 135, 135, 66, 135, 66, 135, 135, 540, 540, 540, 540, 135, 135, 66, 135, 540, 540, 135, 66, 66, 66, 540, 135, 135, 135, 135, 540, 135, 540, 66, 66, 135, 66, 540, 540, 66, 66, 135, 135, 135, 66, 540, 66, 540, 135, 66, 540, 540, 135, 135, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 135, 540, 540, 135, 540, 66, 135, 540, 66, 540, 135, 66, 135, 135, 540, 540, 66, 66, 540, 66, 66, 66, 135, 66]
Prompts retrieved: 31797 . Total input tokens: 7021629 . Total output tokens: 6368784
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.2851808180566877,
    "estimated_duration": 3600.0113234248847,
    "input_throughput": 728.1685429550557,
    "output_throughput": 658.6498727299003,
    "total_throughput": 1386.8184156849559,
    "itl": 21.002504258455065,
    "ttft": 5389.360453975424,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6410,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.949740955314347,
    "arrivals": 10761,
    "finished_requests": 10745,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2852651509456336. Arrivals time: 0.0401525825727731 Scheduler time: 0.8294063413050026 Scheduler overhead time: 0.14193580648861825 Adapter cache time: 0.06269887229427695 Engine time: 0.14076493307948112 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-32/adapters_128_slots_32_rate_0.05-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-32/adapters_128_slots_32_rate_0.05-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 66, 66, 540, 66, 135, 135, 135, 66, 540, 135, 66, 540, 135, 66, 66, 66, 66, 135, 135, 540, 135, 66, 135, 135, 135, 135, 540, 135, 66, 135, 66, 540, 540, 66, 135, 135, 66, 135, 66, 135, 135, 540, 540, 540, 540, 135, 135, 66, 135, 540, 540, 135, 66, 66, 66, 540, 135, 135, 135, 135, 540, 135, 540, 66, 66, 135, 66, 540, 540, 66, 66, 135, 135, 135, 66, 540, 66, 540, 135, 66, 540, 540, 135, 135, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 135, 540, 540, 135, 540, 66, 135, 540, 66, 540, 135, 66, 135, 135, 540, 540, 66, 66, 540, 66, 66, 66, 135, 66]
Prompts retrieved: 31797 . Total input tokens: 7021629 . Total output tokens: 6368784
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.3161428379826248,
    "estimated_duration": 3599.9985802235033,
    "input_throughput": 728.1711205111785,
    "output_throughput": 658.6522042052553,
    "total_throughput": 1386.8233247164337,
    "itl": 21.0019640345391,
    "ttft": 5389.235193806521,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6409,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.9776603678982,
    "arrivals": 10761,
    "finished_requests": 10745,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3162562719080597. Arrivals time: 0.041376307839527726 Scheduler time: 0.8359665097668767 Scheduler overhead time: 0.15619035647250712 Adapter cache time: 0.06517866672948003 Engine time: 0.14538999903015792 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_128_slots_32_rate_0.05-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_128_slots_32_rate_0.05-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 66, 66, 540, 66, 135, 135, 135, 66, 540, 135, 66, 540, 135, 66, 66, 66, 66, 135, 135, 540, 135, 66, 135, 135, 135, 135, 540, 135, 66, 135, 66, 540, 540, 66, 135, 135, 66, 135, 66, 135, 135, 540, 540, 540, 540, 135, 135, 66, 135, 540, 540, 135, 66, 66, 66, 540, 135, 135, 135, 135, 540, 135, 540, 66, 66, 135, 66, 540, 540, 66, 66, 135, 135, 135, 66, 540, 66, 540, 135, 66, 540, 540, 135, 135, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 135, 540, 540, 135, 540, 66, 135, 540, 66, 540, 135, 66, 135, 135, 540, 540, 66, 66, 540, 66, 66, 66, 135, 66]
Prompts retrieved: 31797 . Total input tokens: 7021629 . Total output tokens: 6368784
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 1.2921160601545125,
    "estimated_duration": 3600.0042378372295,
    "input_throughput": 728.1699761483793,
    "output_throughput": 658.6511690954318,
    "total_throughput": 1386.821145243811,
    "itl": 21.15111956022644,
    "ttft": 5389.527351731229,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6401,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.115446153422784,
    "arrivals": 10761,
    "finished_requests": 10745,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2921820941846818. Arrivals time: 0.04027966712601483 Scheduler time: 0.8378448735456914 Scheduler overhead time: 0.14117808174341917 Adapter cache time: 0.06243758788332343 Engine time: 0.1404126943089068 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-32/adapters_128_slots_32_rate_0.05-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-32/adapters_128_slots_32_rate_0.05-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 66, 66, 540, 66, 135, 135, 135, 66, 540, 135, 66, 540, 135, 66, 66, 66, 66, 135, 135, 540, 135, 66, 135, 135, 135, 135, 540, 135, 66, 135, 66, 540, 540, 66, 135, 135, 66, 135, 66, 135, 135, 540, 540, 540, 540, 135, 135, 66, 135, 540, 540, 135, 66, 66, 66, 540, 135, 135, 135, 135, 540, 135, 540, 66, 66, 135, 66, 540, 540, 66, 66, 135, 135, 135, 66, 540, 66, 540, 135, 66, 540, 540, 135, 135, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 135, 540, 540, 135, 540, 66, 135, 540, 66, 540, 135, 66, 135, 135, 540, 540, 66, 66, 540, 66, 66, 66, 135, 66]
Prompts retrieved: 31797 . Total input tokens: 7021629 . Total output tokens: 6368784
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 1.2901447210460901,
    "estimated_duration": 3599.9927042613826,
    "input_throughput": 728.1723090430098,
    "output_throughput": 658.6532792672681,
    "total_throughput": 1386.825588310278,
    "itl": 21.003390481576893,
    "ttft": 5389.316658082651,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6408,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.215389623976293,
    "arrivals": 10761,
    "finished_requests": 10745,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2902218590024859. Arrivals time: 0.040220217080786824 Scheduler time: 0.8339475544635206 Scheduler overhead time: 0.1426096970681101 Adapter cache time: 0.06284575979225338 Engine time: 0.1400482712779194 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_128_slots_32_rate_0.05-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_128_slots_32_rate_0.05-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 66, 66, 540, 66, 135, 135, 135, 66, 540, 135, 66, 540, 135, 66, 66, 66, 66, 135, 135, 540, 135, 66, 135, 135, 135, 135, 540, 135, 66, 135, 66, 540, 540, 66, 135, 135, 66, 135, 66, 135, 135, 540, 540, 540, 540, 135, 135, 66, 135, 540, 540, 135, 66, 66, 66, 540, 135, 135, 135, 135, 540, 135, 540, 66, 66, 135, 66, 540, 540, 66, 66, 135, 135, 135, 66, 540, 66, 540, 135, 66, 540, 540, 135, 135, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 135, 540, 540, 135, 540, 66, 135, 540, 66, 540, 135, 66, 135, 135, 540, 540, 66, 66, 540, 66, 66, 66, 135, 66]
Prompts retrieved: 31797 . Total input tokens: 7021629 . Total output tokens: 6368784
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.2891305051743984,
    "estimated_duration": 3600.011435370164,
    "input_throughput": 728.1685203120635,
    "output_throughput": 658.6498522486476,
    "total_throughput": 1386.8183725607112,
    "itl": 21.148947044754422,
    "ttft": 5389.369265853023,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6406,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.15426218914413,
    "arrivals": 10761,
    "finished_requests": 10745,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.289207472000271. Arrivals time: 0.0406514850910753 Scheduler time: 0.8347968182060868 Scheduler overhead time: 0.14231200679205358 Adapter cache time: 0.06266453512944281 Engine time: 0.13878071471117437 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-32/adapters_128_slots_32_rate_0.05-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-32/adapters_128_slots_32_rate_0.05-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 66, 66, 540, 66, 135, 135, 135, 66, 540, 135, 66, 540, 135, 66, 66, 66, 66, 135, 135, 540, 135, 66, 135, 135, 135, 135, 540, 135, 66, 135, 66, 540, 540, 66, 135, 135, 66, 135, 66, 135, 135, 540, 540, 540, 540, 135, 135, 66, 135, 540, 540, 135, 66, 66, 66, 540, 135, 135, 135, 135, 540, 135, 540, 66, 66, 135, 66, 540, 540, 66, 66, 135, 135, 135, 66, 540, 66, 540, 135, 66, 540, 540, 135, 135, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 135, 540, 540, 135, 540, 66, 135, 540, 66, 540, 135, 66, 135, 135, 540, 540, 66, 66, 540, 66, 66, 66, 135, 66]
Prompts retrieved: 31797 . Total input tokens: 7021629 . Total output tokens: 6368784
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.2829375518485904,
    "estimated_duration": 3599.992635018475,
    "input_throughput": 728.1723230488072,
    "output_throughput": 658.653291935924,
    "total_throughput": 1386.8256149847314,
    "itl": 21.004792891628007,
    "ttft": 5389.213862559967,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6413,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.539086968487332,
    "arrivals": 10761,
    "finished_requests": 10745,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2830130909569561. Arrivals time: 0.040017781779170036 Scheduler time: 0.8286346183158457 Scheduler overhead time: 0.14174705371260643 Adapter cache time: 0.06286857696250081 Engine time: 0.13944797031581402 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_128_slots_32_rate_0.05-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_128_slots_32_rate_0.05-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 33, 33, 540, 33, 135, 135, 135, 33, 540, 135, 33, 540, 135, 33, 33, 33, 33, 135, 135, 540, 135, 33, 135, 135, 135, 135, 540, 135, 33, 135, 33, 540, 540, 33, 135, 135, 33, 135, 33, 135, 135, 540, 540, 540, 540, 135, 135, 33, 135, 540, 540, 135, 33, 33, 33, 540, 135, 135, 135, 135, 540, 135, 540, 33, 33, 135, 33, 540, 540, 33, 33, 135, 135, 135, 33, 540, 33, 540, 135, 33, 540, 540, 135, 135, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 135, 540, 540, 135, 540, 33, 135, 540, 33, 540, 135, 33, 135, 135, 540, 540, 33, 33, 540, 33, 33, 33, 135, 33]
Prompts retrieved: 30411 . Total input tokens: 6723561 . Total output tokens: 6097076
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.2544382228516042,
    "estimated_duration": 3600.01909655419,
    "input_throughput": 705.6073681474048,
    "output_throughput": 630.8024871794779,
    "total_throughput": 1336.4098553268827,
    "itl": 20.72208318721338,
    "ttft": 4596.0908753427975,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5694,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.426417213951762,
    "arrivals": 10263,
    "finished_requests": 10250,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.254516864893958. Arrivals time: 0.03898285422474146 Scheduler time: 0.7981523119378835 Scheduler overhead time: 0.14358059945516288 Adapter cache time: 0.059831063728779554 Engine time: 0.14279890432953835 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_128_slots_32_rate_0.05-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_128_slots_32_rate_0.05-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 33, 33, 540, 33, 135, 135, 135, 33, 540, 135, 33, 540, 135, 33, 33, 33, 33, 135, 135, 540, 135, 33, 135, 135, 135, 135, 540, 135, 33, 135, 33, 540, 540, 33, 135, 135, 33, 135, 33, 135, 135, 540, 540, 540, 540, 135, 135, 33, 135, 540, 540, 135, 33, 33, 33, 540, 135, 135, 135, 135, 540, 135, 540, 33, 33, 135, 33, 540, 540, 33, 33, 135, 135, 135, 33, 540, 33, 540, 135, 33, 540, 540, 135, 135, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 135, 540, 540, 135, 540, 33, 135, 540, 33, 540, 135, 33, 135, 135, 540, 540, 33, 33, 540, 33, 33, 33, 135, 33]
Prompts retrieved: 30411 . Total input tokens: 6723561 . Total output tokens: 6097076
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.2646566841285676,
    "estimated_duration": 3600.0050592981415,
    "input_throughput": 705.6101194744539,
    "output_throughput": 630.804946824918,
    "total_throughput": 1336.4150662993718,
    "itl": 20.730556432086253,
    "ttft": 4245.845483240939,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5693,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.609749141018973,
    "arrivals": 10263,
    "finished_requests": 10250,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2647422880399972. Arrivals time: 0.039398119784891605 Scheduler time: 0.8087181670125574 Scheduler overhead time: 0.1446855936665088 Adapter cache time: 0.05990533949807286 Engine time: 0.1408939186949283 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-32/adapters_128_slots_32_rate_0.05-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-32/adapters_128_slots_32_rate_0.05-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 33, 33, 540, 33, 135, 135, 135, 33, 540, 135, 33, 540, 135, 33, 33, 33, 33, 135, 135, 540, 135, 33, 135, 135, 135, 135, 540, 135, 33, 135, 33, 540, 540, 33, 135, 135, 33, 135, 33, 135, 135, 540, 540, 540, 540, 135, 135, 33, 135, 540, 540, 135, 33, 33, 33, 540, 135, 135, 135, 135, 540, 135, 540, 33, 33, 135, 33, 540, 540, 33, 33, 135, 135, 135, 33, 540, 33, 540, 135, 33, 540, 540, 135, 135, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 135, 540, 540, 135, 540, 33, 135, 540, 33, 540, 135, 33, 135, 135, 540, 540, 33, 33, 540, 33, 33, 33, 135, 33]
Prompts retrieved: 30411 . Total input tokens: 6723561 . Total output tokens: 6097076
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.260824296856299,
    "estimated_duration": 3600.010679752914,
    "input_throughput": 705.6090178527877,
    "output_throughput": 630.8039619915413,
    "total_throughput": 1336.4129798443291,
    "itl": 20.73014443258704,
    "ttft": 4245.820827328441,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5698,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.65318865902631,
    "arrivals": 10263,
    "finished_requests": 10250,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2609058329835534. Arrivals time: 0.03920017974451184 Scheduler time: 0.8013594977091998 Scheduler overhead time: 0.14643187075853348 Adapter cache time: 0.06002867128700018 Engine time: 0.1415884189773351 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-16/adapters_128_slots_32_rate_0.05-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-16/adapters_128_slots_32_rate_0.05-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 33, 33, 540, 33, 135, 135, 135, 33, 540, 135, 33, 540, 135, 33, 33, 33, 33, 135, 135, 540, 135, 33, 135, 135, 135, 135, 540, 135, 33, 135, 33, 540, 540, 33, 135, 135, 33, 135, 33, 135, 135, 540, 540, 540, 540, 135, 135, 33, 135, 540, 540, 135, 33, 33, 33, 540, 135, 135, 135, 135, 540, 135, 540, 33, 33, 135, 33, 540, 540, 33, 33, 135, 135, 135, 33, 540, 33, 540, 135, 33, 540, 540, 135, 135, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 135, 540, 540, 135, 540, 33, 135, 540, 33, 540, 135, 33, 135, 135, 540, 540, 33, 33, 540, 33, 33, 33, 135, 33]
Prompts retrieved: 30411 . Total input tokens: 6723561 . Total output tokens: 6097076
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 1.2645372299011797,
    "estimated_duration": 3600.0012599667666,
    "input_throughput": 705.6108641538225,
    "output_throughput": 630.8056125571923,
    "total_throughput": 1336.4164767110146,
    "itl": 20.725172494272496,
    "ttft": 4245.824889637274,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5693,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.938835628140485,
    "arrivals": 10263,
    "finished_requests": 10250,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2646080579143018. Arrivals time: 0.03905192366801202 Scheduler time: 0.8038883293047547 Scheduler overhead time: 0.143569651292637 Adapter cache time: 0.060127247357741 Engine time: 0.14711342798545957 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-32/adapters_128_slots_32_rate_0.05-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-32/adapters_128_slots_32_rate_0.05-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 33, 33, 540, 33, 135, 135, 135, 33, 540, 135, 33, 540, 135, 33, 33, 33, 33, 135, 135, 540, 135, 33, 135, 135, 135, 135, 540, 135, 33, 135, 33, 540, 540, 33, 135, 135, 33, 135, 33, 135, 135, 540, 540, 540, 540, 135, 135, 33, 135, 540, 540, 135, 33, 33, 33, 540, 135, 135, 135, 135, 540, 135, 540, 33, 33, 135, 33, 540, 540, 33, 33, 135, 135, 135, 33, 540, 33, 540, 135, 33, 540, 540, 135, 135, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 135, 540, 540, 135, 540, 33, 135, 540, 33, 540, 135, 33, 135, 135, 540, 540, 33, 33, 540, 33, 33, 33, 135, 33]
Prompts retrieved: 30411 . Total input tokens: 6723561 . Total output tokens: 6097076
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 1.2446062928065658,
    "estimated_duration": 3600.0211345383746,
    "input_throughput": 705.6069687006785,
    "output_throughput": 630.8021300800486,
    "total_throughput": 1336.4090987807272,
    "itl": 20.731328630571237,
    "ttft": 4596.170398497,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5695,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.849534077289352,
    "arrivals": 10263,
    "finished_requests": 10250,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2446785520296544. Arrivals time: 0.03912168159149587 Scheduler time: 0.7914135786704719 Scheduler overhead time: 0.14418751606717706 Adapter cache time: 0.06027150806039572 Engine time: 0.13893673988059163 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-16/adapters_128_slots_32_rate_0.05-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-16/adapters_128_slots_32_rate_0.05-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 33, 33, 540, 33, 135, 135, 135, 33, 540, 135, 33, 540, 135, 33, 33, 33, 33, 135, 135, 540, 135, 33, 135, 135, 135, 135, 540, 135, 33, 135, 33, 540, 540, 33, 135, 135, 33, 135, 33, 135, 135, 540, 540, 540, 540, 135, 135, 33, 135, 540, 540, 135, 33, 33, 33, 540, 135, 135, 135, 135, 540, 135, 540, 33, 33, 135, 33, 540, 540, 33, 33, 135, 135, 135, 33, 540, 33, 540, 135, 33, 540, 540, 135, 135, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 135, 540, 540, 135, 540, 33, 135, 540, 33, 540, 135, 33, 135, 135, 540, 540, 33, 33, 540, 33, 33, 33, 135, 33]
Prompts retrieved: 30411 . Total input tokens: 6723561 . Total output tokens: 6097076
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.2604010431095958,
    "estimated_duration": 3600.0125259858664,
    "input_throughput": 705.6086559877633,
    "output_throughput": 630.8036384895944,
    "total_throughput": 1336.4122944773576,
    "itl": 20.717711215281874,
    "ttft": 4595.978584929993,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5693,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.02235632887959,
    "arrivals": 10263,
    "finished_requests": 10250,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.260474951006472. Arrivals time: 0.03863019566051662 Scheduler time: 0.7971781303640455 Scheduler overhead time: 0.14925005822442472 Adapter cache time: 0.060990708880126476 Engine time: 0.14080239064060152 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-32/adapters_128_slots_32_rate_0.05-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-32/adapters_128_slots_32_rate_0.05-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 33, 33, 540, 33, 135, 135, 135, 33, 540, 135, 33, 540, 135, 33, 33, 33, 33, 135, 135, 540, 135, 33, 135, 135, 135, 135, 540, 135, 33, 135, 33, 540, 540, 33, 135, 135, 33, 135, 33, 135, 135, 540, 540, 540, 540, 135, 135, 33, 135, 540, 540, 135, 33, 33, 33, 540, 135, 135, 135, 135, 540, 135, 540, 33, 33, 135, 33, 540, 540, 33, 33, 135, 135, 135, 33, 540, 33, 540, 135, 33, 540, 540, 135, 135, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 135, 540, 540, 135, 540, 33, 135, 540, 33, 540, 135, 33, 135, 135, 540, 540, 33, 33, 540, 33, 33, 33, 135, 33]
Prompts retrieved: 30411 . Total input tokens: 6723561 . Total output tokens: 6097076
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.2591201250907034,
    "estimated_duration": 3600.013958996603,
    "input_throughput": 705.6083751153025,
    "output_throughput": 630.803387393794,
    "total_throughput": 1336.4117625090964,
    "itl": 20.73356807175638,
    "ttft": 4596.269707731327,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5695,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.132062821498582,
    "arrivals": 10263,
    "finished_requests": 10250,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.259197031147778. Arrivals time: 0.039228200213983655 Scheduler time: 0.8053180347196758 Scheduler overhead time: 0.1437296646181494 Adapter cache time: 0.05948242708109319 Engine time: 0.1408154214732349 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-8/adapters_128_slots_32_rate_0.05-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-8/adapters_128_slots_32_rate_0.05-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 66, 540, 540, 33, 33, 540, 33, 66, 66, 66, 33, 540, 66, 33, 540, 66, 33, 33, 33, 33, 66, 66, 540, 66, 33, 66, 66, 66, 66, 540, 66, 33, 66, 33, 540, 540, 33, 66, 66, 33, 66, 33, 66, 66, 540, 540, 540, 540, 66, 66, 33, 66, 540, 540, 66, 33, 33, 33, 540, 66, 66, 66, 66, 540, 66, 540, 33, 33, 66, 33, 540, 540, 33, 33, 66, 66, 66, 33, 540, 33, 540, 66, 33, 540, 540, 66, 66, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 66, 540, 540, 66, 540, 33, 66, 540, 33, 540, 66, 33, 66, 66, 540, 540, 33, 33, 540, 33, 33, 33, 66, 33]
Prompts retrieved: 27444 . Total input tokens: 6052346 . Total output tokens: 5499823
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.1752462638542056,
    "estimated_duration": 3599.9361656618653,
    "input_throughput": 644.1130879257365,
    "output_throughput": 556.9795984511171,
    "total_throughput": 1201.0926863768536,
    "itl": 20.169519154218456,
    "ttft": 3128.01065416426,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4582,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.023154842698581,
    "arrivals": 9311,
    "finished_requests": 9303,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1753308919724077. Arrivals time: 0.03711526468396187 Scheduler time: 0.7198946219868958 Scheduler overhead time: 0.14600655320100486 Adapter cache time: 0.05573230376467109 Engine time: 0.1437404965981841 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-16/adapters_128_slots_32_rate_0.05-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-16/adapters_128_slots_32_rate_0.05-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 66, 540, 540, 33, 33, 540, 33, 66, 66, 66, 33, 540, 66, 33, 540, 66, 33, 33, 33, 33, 66, 66, 540, 66, 33, 66, 66, 66, 66, 540, 66, 33, 66, 33, 540, 540, 33, 66, 66, 33, 66, 33, 66, 66, 540, 540, 540, 540, 66, 66, 33, 66, 540, 540, 66, 33, 33, 33, 540, 66, 66, 66, 66, 540, 66, 540, 33, 33, 66, 33, 540, 540, 33, 33, 66, 66, 66, 33, 540, 33, 540, 66, 33, 540, 540, 66, 66, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 66, 540, 540, 66, 540, 33, 66, 540, 33, 540, 66, 33, 66, 66, 540, 540, 33, 33, 540, 33, 33, 33, 66, 33]
Prompts retrieved: 27444 . Total input tokens: 6052346 . Total output tokens: 5499823
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.1780996231827885,
    "estimated_duration": 3599.931057128058,
    "input_throughput": 644.1140019636538,
    "output_throughput": 556.9803888410062,
    "total_throughput": 1201.09439080466,
    "itl": 20.17317610921734,
    "ttft": 3128.1706266534984,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4580,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.986000152242793,
    "arrivals": 9311,
    "finished_requests": 9303,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1781754191033542. Arrivals time: 0.03677348140627146 Scheduler time: 0.7224615276791155 Scheduler overhead time: 0.14551780023612082 Adapter cache time: 0.05543198203667998 Engine time: 0.14481421886011958 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-32/adapters_128_slots_32_rate_0.05-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-32/adapters_128_slots_32_rate_0.05-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 66, 540, 540, 33, 33, 540, 33, 66, 66, 66, 33, 540, 66, 33, 540, 66, 33, 33, 33, 33, 66, 66, 540, 66, 33, 66, 66, 66, 66, 540, 66, 33, 66, 33, 540, 540, 33, 66, 66, 33, 66, 33, 66, 66, 540, 540, 540, 540, 66, 66, 33, 66, 540, 540, 66, 33, 33, 33, 540, 66, 66, 66, 66, 540, 66, 540, 33, 33, 66, 33, 540, 540, 33, 33, 66, 66, 66, 33, 540, 33, 540, 66, 33, 540, 540, 66, 66, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 66, 540, 540, 66, 540, 33, 66, 540, 33, 540, 66, 33, 66, 66, 540, 540, 33, 33, 540, 33, 33, 33, 66, 33]
Prompts retrieved: 27444 . Total input tokens: 6052346 . Total output tokens: 5499823
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.193400525022298,
    "estimated_duration": 3599.9316436662143,
    "input_throughput": 644.1138970179279,
    "output_throughput": 556.9802980919912,
    "total_throughput": 1201.0941951099192,
    "itl": 20.175391498064723,
    "ttft": 3128.0554645862103,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4580,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.005355657579994,
    "arrivals": 9311,
    "finished_requests": 9303,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1934668850153685. Arrivals time: 0.037286253878846765 Scheduler time: 0.7345051232259721 Scheduler overhead time: 0.14721691189333797 Adapter cache time: 0.05594279803335667 Engine time: 0.14557686331681907 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-16/adapters_128_slots_32_rate_0.05-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-16/adapters_128_slots_32_rate_0.05-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 66, 540, 540, 33, 33, 540, 33, 66, 66, 66, 33, 540, 66, 33, 540, 66, 33, 33, 33, 33, 66, 66, 540, 66, 33, 66, 66, 66, 66, 540, 66, 33, 66, 33, 540, 540, 33, 66, 66, 33, 66, 33, 66, 66, 540, 540, 540, 540, 66, 66, 33, 66, 540, 540, 66, 33, 33, 33, 540, 66, 66, 66, 66, 540, 66, 540, 33, 33, 66, 33, 540, 540, 33, 33, 66, 66, 66, 33, 540, 33, 540, 66, 33, 540, 540, 66, 66, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 66, 540, 540, 66, 540, 33, 66, 540, 33, 540, 66, 33, 66, 66, 540, 540, 33, 33, 540, 33, 33, 33, 66, 33]
Prompts retrieved: 27444 . Total input tokens: 6052346 . Total output tokens: 5499823
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 1.1774085329379886,
    "estimated_duration": 3599.929653827288,
    "input_throughput": 644.1142530479142,
    "output_throughput": 556.9806059594179,
    "total_throughput": 1201.094859007332,
    "itl": 20.17085585085036,
    "ttft": 3128.0820387197077,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4582,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.45426881376526,
    "arrivals": 9311,
    "finished_requests": 9303,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1774767409078777. Arrivals time: 0.036962611600756645 Scheduler time: 0.7241962091065943 Scheduler overhead time: 0.14488139981403947 Adapter cache time: 0.055612888652831316 Engine time: 0.14326915726996958 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-32/adapters_128_slots_32_rate_0.05-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-32/adapters_128_slots_32_rate_0.05-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 66, 540, 540, 33, 33, 540, 33, 66, 66, 66, 33, 540, 66, 33, 540, 66, 33, 33, 33, 33, 66, 66, 540, 66, 33, 66, 66, 66, 66, 540, 66, 33, 66, 33, 540, 540, 33, 66, 66, 33, 66, 33, 66, 66, 540, 540, 540, 540, 66, 66, 33, 66, 540, 540, 66, 33, 33, 33, 540, 66, 66, 66, 66, 540, 66, 540, 33, 33, 66, 33, 540, 540, 33, 33, 66, 66, 66, 33, 540, 33, 540, 66, 33, 540, 540, 66, 66, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 66, 540, 540, 66, 540, 33, 66, 540, 33, 540, 66, 33, 66, 66, 540, 540, 33, 33, 540, 33, 33, 33, 66, 33]
Prompts retrieved: 27444 . Total input tokens: 6052346 . Total output tokens: 5499823
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 1.1821032401639968,
    "estimated_duration": 3599.925051268535,
    "input_throughput": 644.1150765577515,
    "output_throughput": 556.9813180675663,
    "total_throughput": 1201.096394625318,
    "itl": 20.1766893669114,
    "ttft": 3128.2396257837368,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4580,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.170636146793827,
    "arrivals": 9311,
    "finished_requests": 9303,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1821986781433225. Arrivals time: 0.03678004024550319 Scheduler time: 0.7263039157260209 Scheduler overhead time: 0.1459743354935199 Adapter cache time: 0.055321672931313515 Engine time: 0.14456633455120027 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-16/adapters_128_slots_32_rate_0.05-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-16/adapters_128_slots_32_rate_0.05-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 66, 540, 540, 33, 33, 540, 33, 66, 66, 66, 33, 540, 66, 33, 540, 66, 33, 33, 33, 33, 66, 66, 540, 66, 33, 66, 66, 66, 66, 540, 66, 33, 66, 33, 540, 540, 33, 66, 66, 33, 66, 33, 66, 66, 540, 540, 540, 540, 66, 66, 33, 66, 540, 540, 66, 33, 33, 33, 540, 66, 66, 66, 66, 540, 66, 540, 33, 33, 66, 33, 540, 540, 33, 33, 66, 66, 66, 33, 540, 33, 540, 66, 33, 540, 540, 66, 66, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 66, 540, 540, 66, 540, 33, 66, 540, 33, 540, 66, 33, 66, 66, 540, 540, 33, 33, 540, 33, 33, 33, 66, 33]
Prompts retrieved: 27444 . Total input tokens: 6052346 . Total output tokens: 5499823
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.1726427639368922,
    "estimated_duration": 3599.9272527734347,
    "input_throughput": 644.1146826546536,
    "output_throughput": 556.9809774503775,
    "total_throughput": 1201.0956601050311,
    "itl": 20.16662479584292,
    "ttft": 3128.048457901219,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4581,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.697420400948108,
    "arrivals": 9311,
    "finished_requests": 9303,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1727252430282533. Arrivals time: 0.036965722450986505 Scheduler time: 0.7197150744032115 Scheduler overhead time: 0.14609561394900084 Adapter cache time: 0.055433092871680856 Engine time: 0.1421798204537481 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-32/adapters_128_slots_32_rate_0.05-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-32/adapters_128_slots_32_rate_0.05-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 66, 540, 540, 33, 33, 540, 33, 66, 66, 66, 33, 540, 66, 33, 540, 66, 33, 33, 33, 33, 66, 66, 540, 66, 33, 66, 66, 66, 66, 540, 66, 33, 66, 33, 540, 540, 33, 66, 66, 33, 66, 33, 66, 66, 540, 540, 540, 540, 66, 66, 33, 66, 540, 540, 66, 33, 33, 33, 540, 66, 66, 66, 66, 540, 66, 540, 33, 33, 66, 33, 540, 540, 33, 33, 66, 66, 66, 33, 540, 33, 540, 66, 33, 540, 540, 66, 66, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 66, 540, 540, 66, 540, 33, 66, 540, 33, 540, 66, 33, 66, 66, 540, 540, 33, 33, 540, 33, 33, 33, 66, 33]
Prompts retrieved: 27444 . Total input tokens: 6052346 . Total output tokens: 5499823
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.1750963530503213,
    "estimated_duration": 3599.926867299182,
    "input_throughput": 644.1147516253953,
    "output_throughput": 556.9810370909852,
    "total_throughput": 1201.0957887163806,
    "itl": 20.176850316512176,
    "ttft": 3128.268411631366,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4579,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.399356856307831,
    "arrivals": 9311,
    "finished_requests": 9303,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1751741820480675. Arrivals time: 0.0366347695235163 Scheduler time: 0.7226153439842165 Scheduler overhead time: 0.14528482407331467 Adapter cache time: 0.05557742854580283 Engine time: 0.1427349871955812 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-8/adapters_128_slots_32_rate_0.025-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-8/adapters_128_slots_32_rate_0.025-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 66, 66, 270, 66, 135, 135, 135, 66, 270, 135, 66, 270, 135, 66, 66, 66, 66, 135, 135, 270, 135, 66, 135, 135, 135, 135, 270, 135, 66, 135, 66, 270, 270, 66, 135, 135, 66, 135, 66, 135, 135, 270, 270, 270, 270, 135, 135, 66, 135, 270, 270, 135, 66, 66, 66, 270, 135, 135, 135, 135, 270, 135, 270, 66, 66, 135, 66, 270, 270, 66, 66, 135, 135, 135, 66, 270, 66, 270, 135, 66, 270, 270, 135, 135, 66, 66, 66, 270, 270, 270, 270, 270, 270, 270, 270, 66, 270, 66, 66, 270, 135, 270, 270, 135, 270, 66, 135, 270, 66, 270, 135, 66, 135, 135, 270, 270, 66, 66, 270, 66, 66, 66, 135, 66]
Prompts retrieved: 20187 . Total input tokens: 4469012 . Total output tokens: 4045314
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.0299978151451796,
    "estimated_duration": 3598.5689870612305,
    "input_throughput": 458.9757778546366,
    "output_throughput": 415.034422118913,
    "total_throughput": 874.0101999735497,
    "itl": 19.616945171881945,
    "ttft": 3198.8179754196476,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4704,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.396534347458282,
    "arrivals": 6826,
    "finished_requests": 6820,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0300590700935572. Arrivals time: 0.03099892451427877 Scheduler time: 0.5752671132795513 Scheduler overhead time: 0.1488373859319836 Adapter cache time: 0.05064099421724677 Engine time: 0.1498877489939332 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-16/adapters_128_slots_32_rate_0.025-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-16/adapters_128_slots_32_rate_0.025-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 66, 66, 270, 66, 135, 135, 135, 66, 270, 135, 66, 270, 135, 66, 66, 66, 66, 135, 135, 270, 135, 66, 135, 135, 135, 135, 270, 135, 66, 135, 66, 270, 270, 66, 135, 135, 66, 135, 66, 135, 135, 270, 270, 270, 270, 135, 135, 66, 135, 270, 270, 135, 66, 66, 66, 270, 135, 135, 135, 135, 270, 135, 270, 66, 66, 135, 66, 270, 270, 66, 66, 135, 135, 135, 66, 270, 66, 270, 135, 66, 270, 270, 135, 135, 66, 66, 66, 270, 270, 270, 270, 270, 270, 270, 270, 66, 270, 66, 66, 270, 135, 270, 270, 135, 270, 66, 135, 270, 66, 270, 135, 66, 135, 135, 270, 270, 66, 66, 270, 66, 66, 66, 135, 66]
Prompts retrieved: 20187 . Total input tokens: 4469012 . Total output tokens: 4045314
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.0188505379483104,
    "estimated_duration": 3598.5727471499063,
    "input_throughput": 458.9752982784974,
    "output_throughput": 415.03398845636394,
    "total_throughput": 874.0092867348613,
    "itl": 19.62346946681565,
    "ttft": 3198.920688172247,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4704,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.375153178140561,
    "arrivals": 6826,
    "finished_requests": 6820,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0189357979688793. Arrivals time: 0.030892969574779272 Scheduler time: 0.5698040842544287 Scheduler overhead time: 0.14712101593613625 Adapter cache time: 0.05050536268390715 Engine time: 0.14657451678067446 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-32/adapters_128_slots_32_rate_0.025-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-32/adapters_128_slots_32_rate_0.025-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 66, 66, 270, 66, 135, 135, 135, 66, 270, 135, 66, 270, 135, 66, 66, 66, 66, 135, 135, 270, 135, 66, 135, 135, 135, 135, 270, 135, 66, 135, 66, 270, 270, 66, 135, 135, 66, 135, 66, 135, 135, 270, 270, 270, 270, 135, 135, 66, 135, 270, 270, 135, 66, 66, 66, 270, 135, 135, 135, 135, 270, 135, 270, 66, 66, 135, 66, 270, 270, 66, 66, 135, 135, 135, 66, 270, 66, 270, 135, 66, 270, 270, 135, 135, 66, 66, 66, 270, 270, 270, 270, 270, 270, 270, 270, 66, 270, 66, 66, 270, 135, 270, 270, 135, 270, 66, 135, 270, 66, 270, 135, 66, 135, 135, 270, 270, 66, 66, 270, 66, 66, 66, 135, 66]
Prompts retrieved: 20187 . Total input tokens: 4469012 . Total output tokens: 4045314
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.017598554957658,
    "estimated_duration": 3598.5586770608056,
    "input_throughput": 458.97709283679734,
    "output_throughput": 415.0356112075044,
    "total_throughput": 874.0127040443018,
    "itl": 19.62319367267995,
    "ttft": 3198.7648816090814,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4704,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.397928132078226,
    "arrivals": 6826,
    "finished_requests": 6820,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0176584811415523. Arrivals time: 0.030746851349249482 Scheduler time: 0.5695282150991261 Scheduler overhead time: 0.14706946001388133 Adapter cache time: 0.050609136931598186 Engine time: 0.14582043047994375 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-16/adapters_128_slots_32_rate_0.025-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-16/adapters_128_slots_32_rate_0.025-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 66, 66, 270, 66, 135, 135, 135, 66, 270, 135, 66, 270, 135, 66, 66, 66, 66, 135, 135, 270, 135, 66, 135, 135, 135, 135, 270, 135, 66, 135, 66, 270, 270, 66, 135, 135, 66, 135, 66, 135, 135, 270, 270, 270, 270, 135, 135, 66, 135, 270, 270, 135, 66, 66, 66, 270, 135, 135, 135, 135, 270, 135, 270, 66, 66, 135, 66, 270, 270, 66, 66, 135, 135, 135, 66, 270, 66, 270, 135, 66, 270, 270, 135, 135, 66, 66, 66, 270, 270, 270, 270, 270, 270, 270, 270, 66, 270, 66, 66, 270, 135, 270, 270, 135, 270, 66, 135, 270, 66, 270, 135, 66, 135, 135, 270, 270, 66, 66, 270, 66, 66, 66, 135, 66]
Prompts retrieved: 20187 . Total input tokens: 4469012 . Total output tokens: 4045314
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 1.0333215759601444,
    "estimated_duration": 3598.5659960301496,
    "input_throughput": 458.9761593429346,
    "output_throughput": 415.0347670843403,
    "total_throughput": 874.0109264272749,
    "itl": 19.61776931931642,
    "ttft": 3198.819615679216,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4705,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.779142491602096,
    "arrivals": 6826,
    "finished_requests": 6820,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.033397963969037. Arrivals time: 0.03091257158666849 Scheduler time: 0.5752901290543377 Scheduler overhead time: 0.15214562136679888 Adapter cache time: 0.05215060571208596 Engine time: 0.14612976275384426 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-32/adapters_128_slots_32_rate_0.025-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-32/adapters_128_slots_32_rate_0.025-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 66, 66, 270, 66, 135, 135, 135, 66, 270, 135, 66, 270, 135, 66, 66, 66, 66, 135, 135, 270, 135, 66, 135, 135, 135, 135, 270, 135, 66, 135, 66, 270, 270, 66, 135, 135, 66, 135, 66, 135, 135, 270, 270, 270, 270, 135, 135, 66, 135, 270, 270, 135, 66, 66, 66, 270, 135, 135, 135, 135, 270, 135, 270, 66, 66, 135, 66, 270, 270, 66, 66, 135, 135, 135, 66, 270, 66, 270, 135, 66, 270, 270, 135, 135, 66, 66, 66, 270, 270, 270, 270, 270, 270, 270, 270, 66, 270, 66, 66, 270, 135, 270, 270, 135, 270, 66, 135, 270, 66, 270, 135, 66, 135, 135, 270, 270, 66, 66, 270, 66, 66, 66, 135, 66]
Prompts retrieved: 20187 . Total input tokens: 4469012 . Total output tokens: 4045314
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 1.0139449569396675,
    "estimated_duration": 3598.5597213134074,
    "input_throughput": 458.97695964794946,
    "output_throughput": 415.03549076987093,
    "total_throughput": 874.0124504178203,
    "itl": 19.623036659805344,
    "ttft": 3198.8693241008327,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4705,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.58532670181123,
    "arrivals": 6826,
    "finished_requests": 6820,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0140270709525794. Arrivals time: 0.030961489770561457 Scheduler time: 0.5643756629433483 Scheduler overhead time: 0.14672142616473138 Adapter cache time: 0.0504721908364445 Engine time: 0.14697482134215534 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-16/adapters_128_slots_32_rate_0.025-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-16/adapters_128_slots_32_rate_0.025-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 66, 66, 270, 66, 135, 135, 135, 66, 270, 135, 66, 270, 135, 66, 66, 66, 66, 135, 135, 270, 135, 66, 135, 135, 135, 135, 270, 135, 66, 135, 66, 270, 270, 66, 135, 135, 66, 135, 66, 135, 135, 270, 270, 270, 270, 135, 135, 66, 135, 270, 270, 135, 66, 66, 66, 270, 135, 135, 135, 135, 270, 135, 270, 66, 66, 135, 66, 270, 270, 66, 66, 135, 135, 135, 66, 270, 66, 270, 135, 66, 270, 270, 135, 135, 66, 66, 66, 270, 270, 270, 270, 270, 270, 270, 270, 66, 270, 66, 66, 270, 135, 270, 270, 135, 270, 66, 135, 270, 66, 270, 135, 66, 135, 135, 270, 270, 66, 66, 270, 66, 66, 66, 135, 66]
Prompts retrieved: 20187 . Total input tokens: 4469012 . Total output tokens: 4045314
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.0175700429826975,
    "estimated_duration": 3598.563376575449,
    "input_throughput": 458.976493439387,
    "output_throughput": 415.0350691951155,
    "total_throughput": 874.0115626345025,
    "itl": 19.613362152663104,
    "ttft": 3198.5678440014744,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4705,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.068186637516074,
    "arrivals": 6826,
    "finished_requests": 6820,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.017643614904955. Arrivals time: 0.031217535492032766 Scheduler time: 0.5687488804105669 Scheduler overhead time: 0.14764883485622704 Adapter cache time: 0.0503016016446054 Engine time: 0.14583934703841805 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-32/adapters_128_slots_32_rate_0.025-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-32/adapters_128_slots_32_rate_0.025-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 66, 66, 270, 66, 135, 135, 135, 66, 270, 135, 66, 270, 135, 66, 66, 66, 66, 135, 135, 270, 135, 66, 135, 135, 135, 135, 270, 135, 66, 135, 66, 270, 270, 66, 135, 135, 66, 135, 66, 135, 135, 270, 270, 270, 270, 135, 135, 66, 135, 270, 270, 135, 66, 66, 66, 270, 135, 135, 135, 135, 270, 135, 270, 66, 66, 135, 66, 270, 270, 66, 66, 135, 135, 135, 66, 270, 66, 270, 135, 66, 270, 270, 135, 135, 66, 66, 66, 270, 270, 270, 270, 270, 270, 270, 270, 66, 270, 66, 66, 270, 135, 270, 270, 135, 270, 66, 135, 270, 66, 270, 135, 66, 135, 135, 270, 270, 66, 66, 270, 66, 66, 66, 135, 66]
Prompts retrieved: 20187 . Total input tokens: 4469012 . Total output tokens: 4045314
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.0344866479281336,
    "estimated_duration": 3598.5748851872804,
    "input_throughput": 458.97502558545284,
    "output_throughput": 415.0337418703661,
    "total_throughput": 874.0087674558189,
    "itl": 19.62530930058155,
    "ttft": 3198.845658612397,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4704,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.801094771324495,
    "arrivals": 6826,
    "finished_requests": 6820,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.034566568909213. Arrivals time: 0.03147327178157866 Scheduler time: 0.5706814785953611 Scheduler overhead time: 0.15635423851199448 Adapter cache time: 0.051963429199531674 Engine time: 0.14855439052917063 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-8/adapters_128_slots_32_rate_0.025-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-8/adapters_128_slots_32_rate_0.025-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 33, 33, 270, 33, 135, 135, 135, 33, 270, 135, 33, 270, 135, 33, 33, 33, 33, 135, 135, 270, 135, 33, 135, 135, 135, 135, 270, 135, 33, 135, 33, 270, 270, 33, 135, 135, 33, 135, 33, 135, 135, 270, 270, 270, 270, 135, 135, 33, 135, 270, 270, 135, 33, 33, 33, 270, 135, 135, 135, 135, 270, 135, 270, 33, 33, 135, 33, 270, 270, 33, 33, 135, 135, 135, 33, 270, 33, 270, 135, 33, 270, 270, 135, 135, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 135, 270, 270, 135, 270, 33, 135, 270, 33, 270, 135, 33, 135, 135, 270, 270, 33, 33, 270, 33, 33, 33, 135, 33]
Prompts retrieved: 18801 . Total input tokens: 4147914 . Total output tokens: 3764709
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 0.9900837079621851,
    "estimated_duration": 3600.013991827494,
    "input_throughput": 426.8116744790773,
    "output_throughput": 387.72849304716965,
    "total_throughput": 814.5401675262469,
    "itl": 19.2623687750784,
    "ttft": 5718.326478581971,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4107,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.569423164330894,
    "arrivals": 6333,
    "finished_requests": 6323,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9901448499877006. Arrivals time: 0.029795952374115586 Scheduler time: 0.541252767201513 Scheduler overhead time: 0.14848813926801085 Adapter cache time: 0.048044257098808885 Engine time: 0.1481792232953012 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-16/adapters_128_slots_32_rate_0.025-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-16/adapters_128_slots_32_rate_0.025-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 33, 33, 270, 33, 135, 135, 135, 33, 270, 135, 33, 270, 135, 33, 33, 33, 33, 135, 135, 270, 135, 33, 135, 135, 135, 135, 270, 135, 33, 135, 33, 270, 270, 33, 135, 135, 33, 135, 33, 135, 135, 270, 270, 270, 270, 135, 135, 33, 135, 270, 270, 135, 33, 33, 33, 270, 135, 135, 135, 135, 270, 135, 270, 33, 33, 135, 33, 270, 270, 33, 33, 135, 135, 135, 33, 270, 33, 270, 135, 33, 270, 270, 135, 135, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 135, 270, 270, 135, 270, 33, 135, 270, 33, 270, 135, 33, 135, 135, 270, 270, 33, 33, 270, 33, 33, 33, 135, 33]
Prompts retrieved: 18801 . Total input tokens: 4147914 . Total output tokens: 3764709
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 0.9924182940740138,
    "estimated_duration": 3600.0111953632895,
    "input_throughput": 426.8120060234823,
    "output_throughput": 387.7287942320252,
    "total_throughput": 814.5408002555075,
    "itl": 19.266716868354084,
    "ttft": 5718.5157517902835,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4107,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.434826931076275,
    "arrivals": 6333,
    "finished_requests": 6323,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.992492709076032. Arrivals time: 0.029712354764342308 Scheduler time: 0.5426610307767987 Scheduler overhead time: 0.1480264225974679 Adapter cache time: 0.04832241288386285 Engine time: 0.14922895980998874 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-32/adapters_128_slots_32_rate_0.025-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-32/adapters_128_slots_32_rate_0.025-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 33, 33, 270, 33, 135, 135, 135, 33, 270, 135, 33, 270, 135, 33, 33, 33, 33, 135, 135, 270, 135, 33, 135, 135, 135, 135, 270, 135, 33, 135, 33, 270, 270, 33, 135, 135, 33, 135, 33, 135, 135, 270, 270, 270, 270, 135, 135, 33, 135, 270, 270, 135, 33, 33, 33, 270, 135, 135, 135, 135, 270, 135, 270, 33, 33, 135, 33, 270, 270, 33, 33, 135, 135, 135, 33, 270, 33, 270, 135, 33, 270, 270, 135, 135, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 135, 270, 270, 135, 270, 33, 135, 270, 33, 270, 135, 33, 135, 135, 270, 270, 33, 33, 270, 33, 33, 33, 135, 33]
Prompts retrieved: 18801 . Total input tokens: 4147914 . Total output tokens: 3764709
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 0.9949116390198469,
    "estimated_duration": 3600.011989390373,
    "input_throughput": 426.81191188482575,
    "output_throughput": 387.7287087136535,
    "total_throughput": 814.5406205984792,
    "itl": 19.268563276082418,
    "ttft": 5718.584587007948,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4107,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.452793331443278,
    "arrivals": 6333,
    "finished_requests": 6323,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9949731319211423. Arrivals time: 0.029984153108671308 Scheduler time: 0.5437353819143027 Scheduler overhead time: 0.1478787767700851 Adapter cache time: 0.04869831586256623 Engine time: 0.14952421910129488 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-16/adapters_128_slots_32_rate_0.025-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-16/adapters_128_slots_32_rate_0.025-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 33, 33, 270, 33, 135, 135, 135, 33, 270, 135, 33, 270, 135, 33, 33, 33, 33, 135, 135, 270, 135, 33, 135, 135, 135, 135, 270, 135, 33, 135, 33, 270, 270, 33, 135, 135, 33, 135, 33, 135, 135, 270, 270, 270, 270, 135, 135, 33, 135, 270, 270, 135, 33, 33, 33, 270, 135, 135, 135, 135, 270, 135, 270, 33, 33, 135, 33, 270, 270, 33, 33, 135, 135, 135, 33, 270, 33, 270, 135, 33, 270, 270, 135, 135, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 135, 270, 270, 135, 270, 33, 135, 270, 33, 270, 135, 33, 135, 135, 270, 270, 33, 33, 270, 33, 33, 33, 135, 33]
Prompts retrieved: 18801 . Total input tokens: 4147914 . Total output tokens: 3764709
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 0.9919622370507568,
    "estimated_duration": 3600.014626849155,
    "input_throughput": 426.8115991919781,
    "output_throughput": 387.7284246541165,
    "total_throughput": 814.5400238460946,
    "itl": 19.26473634791413,
    "ttft": 5718.522091045276,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4107,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.928577331528809,
    "arrivals": 6333,
    "finished_requests": 6323,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9920473790261894. Arrivals time: 0.030209897318854928 Scheduler time: 0.5435885251499712 Scheduler overhead time: 0.14815231272950768 Adapter cache time: 0.04822644870728254 Engine time: 0.14744650572538376 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-32/adapters_128_slots_32_rate_0.025-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-32/adapters_128_slots_32_rate_0.025-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 33, 33, 270, 33, 135, 135, 135, 33, 270, 135, 33, 270, 135, 33, 33, 33, 33, 135, 135, 270, 135, 33, 135, 135, 135, 135, 270, 135, 33, 135, 33, 270, 270, 33, 135, 135, 33, 135, 33, 135, 135, 270, 270, 270, 270, 135, 135, 33, 135, 270, 270, 135, 33, 33, 33, 270, 135, 135, 135, 135, 270, 135, 270, 33, 33, 135, 33, 270, 270, 33, 33, 135, 135, 135, 33, 270, 33, 270, 135, 33, 270, 270, 135, 135, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 135, 270, 270, 135, 270, 33, 135, 270, 33, 270, 135, 33, 135, 135, 270, 270, 33, 33, 270, 33, 33, 33, 135, 33]
Prompts retrieved: 18801 . Total input tokens: 4147914 . Total output tokens: 3764709
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 0.9918677010573447,
    "estimated_duration": 3599.9960320806163,
    "input_throughput": 426.81380376743476,
    "output_throughput": 387.73042735641064,
    "total_throughput": 814.5442311238454,
    "itl": 19.269360020065157,
    "ttft": 5718.561509100206,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4107,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.608602272811327,
    "arrivals": 6333,
    "finished_requests": 6323,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9919249170925468. Arrivals time: 0.029437347082421184 Scheduler time: 0.5429805929306895 Scheduler overhead time: 0.1482590672094375 Adapter cache time: 0.04845957923680544 Engine time: 0.1481083461549133 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-16/adapters_128_slots_32_rate_0.025-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-16/adapters_128_slots_32_rate_0.025-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 33, 33, 270, 33, 135, 135, 135, 33, 270, 135, 33, 270, 135, 33, 33, 33, 33, 135, 135, 270, 135, 33, 135, 135, 135, 135, 270, 135, 33, 135, 33, 270, 270, 33, 135, 135, 33, 135, 33, 135, 135, 270, 270, 270, 270, 135, 135, 33, 135, 270, 270, 135, 33, 33, 33, 270, 135, 135, 135, 135, 270, 135, 270, 33, 33, 135, 33, 270, 270, 33, 33, 135, 135, 135, 33, 270, 33, 270, 135, 33, 270, 270, 135, 135, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 135, 270, 270, 135, 270, 33, 135, 270, 33, 270, 135, 33, 135, 135, 270, 270, 33, 33, 270, 33, 33, 33, 135, 33]
Prompts retrieved: 18801 . Total input tokens: 4147914 . Total output tokens: 3764709
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 0.9965050581377,
    "estimated_duration": 3600.0090147945734,
    "input_throughput": 426.8122645486427,
    "output_throughput": 387.7290290840146,
    "total_throughput": 814.5412936326574,
    "itl": 19.26056975833151,
    "ttft": 5718.338598530492,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4107,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.280136561164106,
    "arrivals": 6333,
    "finished_requests": 6323,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9965815159957856. Arrivals time: 0.029761288780719042 Scheduler time: 0.5433899252675474 Scheduler overhead time: 0.15010345471091568 Adapter cache time: 0.04830354871228337 Engine time: 0.14940494927577674 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-32/adapters_128_slots_32_rate_0.025-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-32/adapters_128_slots_32_rate_0.025-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 33, 33, 270, 33, 135, 135, 135, 33, 270, 135, 33, 270, 135, 33, 33, 33, 33, 135, 135, 270, 135, 33, 135, 135, 135, 135, 270, 135, 33, 135, 33, 270, 270, 33, 135, 135, 33, 135, 33, 135, 135, 270, 270, 270, 270, 135, 135, 33, 135, 270, 270, 135, 33, 33, 33, 270, 135, 135, 135, 135, 270, 135, 270, 33, 33, 135, 33, 270, 270, 33, 33, 135, 135, 135, 33, 270, 33, 270, 135, 33, 270, 270, 135, 135, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 135, 270, 270, 135, 270, 33, 135, 270, 33, 270, 135, 33, 135, 135, 270, 270, 33, 33, 270, 33, 33, 33, 135, 33]
Prompts retrieved: 18801 . Total input tokens: 4147914 . Total output tokens: 3764709
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 0.9881773320958018,
    "estimated_duration": 3600.0087992108233,
    "input_throughput": 426.8122901079659,
    "output_throughput": 387.72905230286847,
    "total_throughput": 814.5413424108344,
    "itl": 19.270712629762123,
    "ttft": 5718.730041723788,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4107,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.808173531851768,
    "arrivals": 6333,
    "finished_requests": 6323,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9882391660939902. Arrivals time: 0.02994810533709824 Scheduler time: 0.5407301329541951 Scheduler overhead time: 0.14796077087521553 Adapter cache time: 0.04821686586365104 Engine time: 0.14686288591474295 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-8/adapters_128_slots_32_rate_0.025-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-8/adapters_128_slots_32_rate_0.025-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 66, 270, 270, 33, 33, 270, 33, 66, 66, 66, 33, 270, 66, 33, 270, 66, 33, 33, 33, 33, 66, 66, 270, 66, 33, 66, 66, 66, 66, 270, 66, 33, 66, 33, 270, 270, 33, 66, 66, 33, 66, 33, 66, 66, 270, 270, 270, 270, 66, 66, 33, 66, 270, 270, 66, 33, 33, 33, 270, 66, 66, 66, 66, 270, 66, 270, 33, 33, 66, 33, 270, 270, 33, 33, 66, 66, 66, 33, 270, 33, 270, 66, 33, 270, 270, 66, 66, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 66, 270, 270, 66, 270, 33, 66, 270, 33, 270, 66, 33, 66, 66, 270, 270, 33, 33, 270, 33, 33, 33, 66, 33]
Prompts retrieved: 15834 . Total input tokens: 3478100 . Total output tokens: 3189536
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 0.9183985271956772,
    "estimated_duration": 3599.4311759867037,
    "input_throughput": 359.52903020718304,
    "output_throughput": 326.28794456058756,
    "total_throughput": 685.8169747677706,
    "itl": 18.97717170496791,
    "ttft": 6750.744231266599,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3159,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.668080783083385,
    "arrivals": 5359,
    "finished_requests": 5349,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9184810840524733. Arrivals time: 0.027643064968287945 Scheduler time: 0.4730014060623944 Scheduler overhead time: 0.14916743291541934 Adapter cache time: 0.04410182638093829 Engine time: 0.14947967254556715 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-16/adapters_128_slots_32_rate_0.025-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-16/adapters_128_slots_32_rate_0.025-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 66, 270, 270, 33, 33, 270, 33, 66, 66, 66, 33, 270, 66, 33, 270, 66, 33, 33, 33, 33, 66, 66, 270, 66, 33, 66, 66, 66, 66, 270, 66, 33, 66, 33, 270, 270, 33, 66, 66, 33, 66, 33, 66, 66, 270, 270, 270, 270, 66, 66, 33, 66, 270, 270, 66, 33, 33, 33, 270, 66, 66, 66, 66, 270, 66, 270, 33, 33, 66, 33, 270, 270, 33, 33, 66, 66, 66, 33, 270, 33, 270, 66, 33, 270, 270, 66, 66, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 66, 270, 270, 66, 270, 33, 66, 270, 33, 270, 66, 33, 66, 66, 270, 270, 33, 33, 270, 33, 33, 33, 66, 33]
Prompts retrieved: 15834 . Total input tokens: 3478100 . Total output tokens: 3189536
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 0.920005647931248,
    "estimated_duration": 3599.435819098899,
    "input_throughput": 359.52856643071675,
    "output_throughput": 326.28752366364404,
    "total_throughput": 685.8160900943608,
    "itl": 18.98129279763389,
    "ttft": 6750.933473422796,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3159,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.320371458376814,
    "arrivals": 5359,
    "finished_requests": 5349,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9200710409786552. Arrivals time: 0.02772817458026111 Scheduler time: 0.4749422452878207 Scheduler overhead time: 0.14878608752042055 Adapter cache time: 0.043966207187622786 Engine time: 0.14873845758847892 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-32/adapters_128_slots_32_rate_0.025-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-32/adapters_128_slots_32_rate_0.025-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 66, 270, 270, 33, 33, 270, 33, 66, 66, 66, 33, 270, 66, 33, 270, 66, 33, 33, 33, 33, 66, 66, 270, 66, 33, 66, 66, 66, 66, 270, 66, 33, 66, 33, 270, 270, 33, 66, 66, 33, 66, 33, 66, 66, 270, 270, 270, 270, 66, 66, 33, 66, 270, 270, 66, 33, 33, 33, 270, 66, 66, 66, 66, 270, 66, 270, 33, 33, 66, 33, 270, 270, 33, 33, 66, 66, 66, 33, 270, 33, 270, 66, 33, 270, 270, 66, 66, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 66, 270, 270, 66, 270, 33, 66, 270, 33, 270, 66, 33, 66, 66, 270, 270, 33, 33, 270, 33, 33, 33, 66, 33]
Prompts retrieved: 15834 . Total input tokens: 3478100 . Total output tokens: 3189536
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 0.9191890549845994,
    "estimated_duration": 3599.4370079505516,
    "input_throughput": 359.5284476826655,
    "output_throughput": 326.2874158947177,
    "total_throughput": 685.8158635773832,
    "itl": 18.980449852750233,
    "ttft": 6750.927138874374,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3159,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.336522929053325,
    "arrivals": 5359,
    "finished_requests": 5349,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9192861360497773. Arrivals time: 0.02702562022022903 Scheduler time: 0.4765703452285379 Scheduler overhead time: 0.14861208689399064 Adapter cache time: 0.044234908651560545 Engine time: 0.14766913768835366 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-16/adapters_128_slots_32_rate_0.025-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-16/adapters_128_slots_32_rate_0.025-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 66, 270, 270, 33, 33, 270, 33, 66, 66, 66, 33, 270, 66, 33, 270, 66, 33, 33, 33, 33, 66, 66, 270, 66, 33, 66, 66, 66, 66, 270, 66, 33, 66, 33, 270, 270, 33, 66, 66, 33, 66, 33, 66, 66, 270, 270, 270, 270, 66, 66, 33, 66, 270, 270, 66, 33, 33, 33, 270, 66, 66, 66, 66, 270, 66, 270, 33, 33, 66, 33, 270, 270, 33, 33, 66, 66, 66, 33, 270, 33, 270, 66, 33, 270, 270, 66, 66, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 66, 270, 270, 66, 270, 33, 66, 270, 33, 270, 66, 33, 66, 66, 270, 270, 33, 33, 270, 33, 33, 33, 66, 33]
Prompts retrieved: 15834 . Total input tokens: 3478100 . Total output tokens: 3189536
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 0.9209902510046959,
    "estimated_duration": 3599.42895885611,
    "input_throughput": 359.5292516653147,
    "output_throughput": 326.2881455432969,
    "total_throughput": 685.8173972086115,
    "itl": 18.978443345161317,
    "ttft": 6750.808485299013,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3161,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.932874267308614,
    "arrivals": 5359,
    "finished_requests": 5349,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.92104945005849. Arrivals time: 0.02787928795441985 Scheduler time: 0.4752211105078459 Scheduler overhead time: 0.14858549390919507 Adapter cache time: 0.04384855646640062 Engine time: 0.15045642270706594 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-32/adapters_128_slots_32_rate_0.025-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-32/adapters_128_slots_32_rate_0.025-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 66, 270, 270, 33, 33, 270, 33, 66, 66, 66, 33, 270, 66, 33, 270, 66, 33, 33, 33, 33, 66, 66, 270, 66, 33, 66, 66, 66, 66, 270, 66, 33, 66, 33, 270, 270, 33, 66, 66, 33, 66, 33, 66, 66, 270, 270, 270, 270, 66, 66, 33, 66, 270, 270, 66, 33, 33, 33, 270, 66, 66, 66, 66, 270, 66, 270, 33, 33, 66, 33, 270, 270, 33, 33, 66, 66, 66, 33, 270, 33, 270, 66, 33, 270, 270, 66, 66, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 66, 270, 270, 66, 270, 33, 66, 270, 33, 270, 66, 33, 66, 66, 270, 270, 33, 33, 270, 33, 33, 33, 66, 33]
Prompts retrieved: 15834 . Total input tokens: 3478100 . Total output tokens: 3189536
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 0.9223058039788157,
    "estimated_duration": 3599.445619079888,
    "input_throughput": 359.52758756522223,
    "output_throughput": 326.2866353014163,
    "total_throughput": 685.8142228666386,
    "itl": 18.980850169370562,
    "ttft": 6750.927666304999,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3161,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.464636865630233,
    "arrivals": 5359,
    "finished_requests": 5349,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9223738610744476. Arrivals time: 0.02740050503052771 Scheduler time: 0.4756604495923966 Scheduler overhead time: 0.14810100803151727 Adapter cache time: 0.04419624502770603 Engine time: 0.15120936511084437 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-16/adapters_128_slots_32_rate_0.025-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-16/adapters_128_slots_32_rate_0.025-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 66, 270, 270, 33, 33, 270, 33, 66, 66, 66, 33, 270, 66, 33, 270, 66, 33, 33, 33, 33, 66, 66, 270, 66, 33, 66, 66, 66, 66, 270, 66, 33, 66, 33, 270, 270, 33, 66, 66, 33, 66, 33, 66, 66, 270, 270, 270, 270, 66, 66, 33, 66, 270, 270, 66, 33, 33, 33, 270, 66, 66, 66, 66, 270, 66, 270, 33, 33, 66, 33, 270, 270, 33, 33, 66, 66, 66, 33, 270, 33, 270, 66, 33, 270, 270, 66, 66, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 66, 270, 270, 66, 270, 33, 66, 270, 33, 270, 66, 33, 66, 66, 270, 270, 33, 33, 270, 33, 33, 33, 66, 33]
Prompts retrieved: 15834 . Total input tokens: 3478100 . Total output tokens: 3189536
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 0.923647488001734,
    "estimated_duration": 3599.4370859575256,
    "input_throughput": 359.52843989096766,
    "output_throughput": 326.28740882341924,
    "total_throughput": 685.8158487143869,
    "itl": 18.97485783943646,
    "ttft": 6750.879733076372,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.448558931891005,
    "arrivals": 5359,
    "finished_requests": 5349,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9237387829925865. Arrivals time: 0.027341737411916256 Scheduler time: 0.4762096768245101 Scheduler overhead time: 0.1491222872864455 Adapter cache time: 0.04409661260433495 Engine time: 0.15148228337056935 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-32/adapters_128_slots_32_rate_0.025-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-32/adapters_128_slots_32_rate_0.025-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 66, 270, 270, 33, 33, 270, 33, 66, 66, 66, 33, 270, 66, 33, 270, 66, 33, 33, 33, 33, 66, 66, 270, 66, 33, 66, 66, 66, 66, 270, 66, 33, 66, 33, 270, 270, 33, 66, 66, 33, 66, 33, 66, 66, 270, 270, 270, 270, 66, 66, 33, 66, 270, 270, 66, 33, 33, 33, 270, 66, 66, 66, 66, 270, 66, 270, 33, 33, 66, 33, 270, 270, 33, 33, 66, 66, 66, 33, 270, 33, 270, 66, 33, 270, 270, 66, 66, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 66, 270, 270, 66, 270, 33, 66, 270, 33, 270, 66, 33, 66, 66, 270, 270, 33, 33, 270, 33, 33, 33, 66, 33]
Prompts retrieved: 15834 . Total input tokens: 3478100 . Total output tokens: 3189536
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 0.9259502829518169,
    "estimated_duration": 3599.435816566741,
    "input_throughput": 359.52856668364063,
    "output_throughput": 326.2875238931832,
    "total_throughput": 685.8160905768239,
    "itl": 18.982581789427773,
    "ttft": 6750.918047408473,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3161,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.612774826026868,
    "arrivals": 5359,
    "finished_requests": 5349,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9260344391223043. Arrivals time: 0.027580394642427564 Scheduler time: 0.47837539785541594 Scheduler overhead time: 0.14936525071971118 Adapter cache time: 0.04399929032661021 Engine time: 0.15043955692090094 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-8/adapters_128_slots_32_rate_0.0125-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-8/adapters_128_slots_32_rate_0.0125-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [42 43 43]
Adapter prompts. [135, 66, 135, 135, 33, 33, 135, 33, 66, 66, 66, 33, 135, 66, 33, 135, 66, 33, 33, 33, 33, 66, 66, 135, 66, 33, 66, 66, 66, 66, 135, 66, 33, 66, 33, 135, 135, 33, 66, 66, 33, 66, 33, 66, 66, 135, 135, 135, 135, 66, 66, 33, 66, 135, 135, 66, 33, 33, 33, 135, 66, 66, 66, 66, 135, 66, 135, 33, 33, 66, 33, 135, 135, 33, 33, 66, 66, 66, 33, 135, 33, 135, 66, 33, 135, 135, 66, 66, 33, 33, 33, 135, 135, 135, 135, 135, 135, 135, 135, 33, 135, 33, 33, 135, 66, 135, 135, 66, 135, 33, 66, 135, 33, 135, 66, 33, 66, 66, 135, 135, 33, 33, 135, 33, 33, 33, 66, 33]
Prompts retrieved: 10029 . Total input tokens: 2205085 . Total output tokens: 2017823
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 0.7846288741566241,
    "estimated_duration": 3598.3591464896167,
    "input_throughput": 219.70680741283292,
    "output_throughput": 202.529811597866,
    "total_throughput": 422.2366190106989,
    "itl": 18.401212210871037,
    "ttft": 3307.8368182999684,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2268,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.941186203239691,
    "arrivals": 3297,
    "finished_requests": 3294,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7846841481514275. Arrivals time: 0.022643950302153826 Scheduler time: 0.3469932465814054 Scheduler overhead time: 0.14843569765798748 Adapter cache time: 0.03654939658008516 Engine time: 0.15390667575411499 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-16/adapters_128_slots_32_rate_0.0125-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-16/adapters_128_slots_32_rate_0.0125-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [42 43 43]
Adapter prompts. [135, 66, 135, 135, 33, 33, 135, 33, 66, 66, 66, 33, 135, 66, 33, 135, 66, 33, 33, 33, 33, 66, 66, 135, 66, 33, 66, 66, 66, 66, 135, 66, 33, 66, 33, 135, 135, 33, 66, 66, 33, 66, 33, 66, 66, 135, 135, 135, 135, 66, 66, 33, 66, 135, 135, 66, 33, 33, 33, 135, 66, 66, 66, 66, 135, 66, 135, 33, 33, 66, 33, 135, 135, 33, 33, 66, 66, 66, 33, 135, 33, 135, 66, 33, 135, 135, 66, 66, 33, 33, 33, 135, 135, 135, 135, 135, 135, 135, 135, 33, 135, 33, 33, 135, 66, 135, 135, 66, 135, 33, 66, 135, 33, 135, 66, 33, 66, 66, 135, 135, 33, 33, 135, 33, 33, 33, 66, 33]
Prompts retrieved: 10029 . Total input tokens: 2205085 . Total output tokens: 2017823
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 0.7785537620075047,
    "estimated_duration": 3598.3514593695354,
    "input_throughput": 219.70727677015677,
    "output_throughput": 202.53024426015577,
    "total_throughput": 422.2375210303125,
    "itl": 18.404106276265104,
    "ttft": 3308.219453168155,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2268,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.40413333414092,
    "arrivals": 3297,
    "finished_requests": 3294,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.778651149943471. Arrivals time: 0.022468385053798556 Scheduler time: 0.3454512390308082 Scheduler overhead time: 0.14777748147025704 Adapter cache time: 0.03684712899848819 Engine time: 0.15016398369334638 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-32/adapters_128_slots_32_rate_0.0125-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-32/adapters_128_slots_32_rate_0.0125-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [42 43 43]
Adapter prompts. [135, 66, 135, 135, 33, 33, 135, 33, 66, 66, 66, 33, 135, 66, 33, 135, 66, 33, 33, 33, 33, 66, 66, 135, 66, 33, 66, 66, 66, 66, 135, 66, 33, 66, 33, 135, 135, 33, 66, 66, 33, 66, 33, 66, 66, 135, 135, 135, 135, 66, 66, 33, 66, 135, 135, 66, 33, 33, 33, 135, 66, 66, 66, 66, 135, 66, 135, 33, 33, 66, 33, 135, 135, 33, 33, 66, 66, 66, 33, 135, 33, 135, 66, 33, 135, 135, 66, 66, 33, 33, 33, 135, 135, 135, 135, 135, 135, 135, 135, 33, 135, 33, 33, 135, 66, 135, 135, 66, 135, 33, 66, 135, 33, 135, 66, 33, 66, 66, 135, 135, 33, 33, 135, 33, 33, 33, 66, 33]
Prompts retrieved: 10029 . Total input tokens: 2205085 . Total output tokens: 2017823
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 0.7834441808518022,
    "estimated_duration": 3598.3520632025725,
    "input_throughput": 219.70723990147079,
    "output_throughput": 202.53021027391696,
    "total_throughput": 422.2374501753878,
    "itl": 18.404725718735538,
    "ttft": 3308.1642366406068,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2268,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.416665930673444,
    "arrivals": 3297,
    "finished_requests": 3294,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7835154877975583. Arrivals time: 0.022579222451895475 Scheduler time: 0.33879739698022604 Scheduler overhead time: 0.15528133953921497 Adapter cache time: 0.0384809544775635 Engine time: 0.15145976841449738 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-16/adapters_128_slots_32_rate_0.0125-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-16/adapters_128_slots_32_rate_0.0125-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [42 43 43]
Adapter prompts. [135, 66, 135, 135, 33, 33, 135, 33, 66, 66, 66, 33, 135, 66, 33, 135, 66, 33, 33, 33, 33, 66, 66, 135, 66, 33, 66, 66, 66, 66, 135, 66, 33, 66, 33, 135, 135, 33, 66, 66, 33, 66, 33, 66, 66, 135, 135, 135, 135, 66, 66, 33, 66, 135, 135, 66, 33, 33, 33, 135, 66, 66, 66, 66, 135, 66, 135, 33, 33, 66, 33, 135, 135, 33, 33, 66, 66, 66, 33, 135, 33, 135, 66, 33, 135, 135, 66, 66, 33, 33, 33, 135, 135, 135, 135, 135, 135, 135, 135, 33, 135, 33, 33, 135, 66, 135, 135, 66, 135, 33, 66, 135, 33, 135, 66, 33, 66, 66, 135, 135, 33, 33, 135, 33, 33, 33, 66, 33]
Prompts retrieved: 10029 . Total input tokens: 2205085 . Total output tokens: 2017823
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 0.7774156250525266,
    "estimated_duration": 3598.365121235284,
    "input_throughput": 219.7064426104153,
    "output_throughput": 202.52947531622877,
    "total_throughput": 422.2359179266441,
    "itl": 18.40271098785196,
    "ttft": 3308.032312793829,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2268,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.122611159735571,
    "arrivals": 3297,
    "finished_requests": 3294,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7774729679804295. Arrivals time: 0.02252373844385147 Scheduler time: 0.3428253650199622 Scheduler overhead time: 0.14767677173949778 Adapter cache time: 0.03649830189533532 Engine time: 0.1516517789568752 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-32/adapters_128_slots_32_rate_0.0125-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-32/adapters_128_slots_32_rate_0.0125-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [42 43 43]
Adapter prompts. [135, 66, 135, 135, 33, 33, 135, 33, 66, 66, 66, 33, 135, 66, 33, 135, 66, 33, 33, 33, 33, 66, 66, 135, 66, 33, 66, 66, 66, 66, 135, 66, 33, 66, 33, 135, 135, 33, 66, 66, 33, 66, 33, 66, 66, 135, 135, 135, 135, 66, 66, 33, 66, 135, 135, 66, 33, 33, 33, 135, 66, 66, 66, 66, 135, 66, 135, 33, 33, 66, 33, 135, 135, 33, 33, 66, 66, 66, 33, 135, 33, 135, 66, 33, 135, 135, 66, 66, 33, 33, 33, 135, 135, 135, 135, 135, 135, 135, 135, 33, 135, 33, 33, 135, 66, 135, 135, 66, 135, 33, 66, 135, 33, 135, 66, 33, 66, 66, 135, 135, 33, 33, 135, 33, 33, 33, 66, 33]
Prompts retrieved: 10029 . Total input tokens: 2205085 . Total output tokens: 2017823
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 0.7751383159775287,
    "estimated_duration": 3598.3538270221907,
    "input_throughput": 219.70713220668628,
    "output_throughput": 202.5301109988664,
    "total_throughput": 422.2372432055527,
    "itl": 18.404071379942074,
    "ttft": 3307.941142247814,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2268,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.503310289513176,
    "arrivals": 3297,
    "finished_requests": 3294,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7752279799897224. Arrivals time: 0.022520302096381783 Scheduler time: 0.34229777473956347 Scheduler overhead time: 0.14754674793221056 Adapter cache time: 0.036700001219287515 Engine time: 0.15039508510380983 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-16/adapters_128_slots_32_rate_0.0125-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-16/adapters_128_slots_32_rate_0.0125-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [42 43 43]
Adapter prompts. [135, 66, 135, 135, 33, 33, 135, 33, 66, 66, 66, 33, 135, 66, 33, 135, 66, 33, 33, 33, 33, 66, 66, 135, 66, 33, 66, 66, 66, 66, 135, 66, 33, 66, 33, 135, 135, 33, 66, 66, 33, 66, 33, 66, 66, 135, 135, 135, 135, 66, 66, 33, 66, 135, 135, 66, 33, 33, 33, 135, 66, 66, 66, 66, 135, 66, 135, 33, 33, 66, 33, 135, 135, 33, 33, 66, 66, 66, 33, 135, 33, 135, 66, 33, 135, 135, 66, 66, 33, 33, 33, 135, 135, 135, 135, 135, 135, 135, 135, 33, 135, 33, 33, 135, 66, 135, 135, 66, 135, 33, 66, 135, 33, 135, 66, 33, 66, 66, 135, 135, 33, 33, 135, 33, 33, 33, 66, 33]
Prompts retrieved: 10029 . Total input tokens: 2205085 . Total output tokens: 2017823
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 0.7711632461287081,
    "estimated_duration": 3598.354769567952,
    "input_throughput": 219.70707465704498,
    "output_throughput": 202.53005794853925,
    "total_throughput": 422.23713260558424,
    "itl": 18.400312366859744,
    "ttft": 3307.8289493094894,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2268,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.78143406883793,
    "arrivals": 3297,
    "finished_requests": 3294,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7712307539768517. Arrivals time: 0.02243619505316019 Scheduler time: 0.3385549420490861 Scheduler overhead time: 0.1476984927430749 Adapter cache time: 0.03657230664975941 Engine time: 0.1502114140894264 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-32/adapters_128_slots_32_rate_0.0125-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-32/adapters_128_slots_32_rate_0.0125-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [42 43 43]
Adapter prompts. [135, 66, 135, 135, 33, 33, 135, 33, 66, 66, 66, 33, 135, 66, 33, 135, 66, 33, 33, 33, 33, 66, 66, 135, 66, 33, 66, 66, 66, 66, 135, 66, 33, 66, 33, 135, 135, 33, 66, 66, 33, 66, 33, 66, 66, 135, 135, 135, 135, 66, 66, 33, 66, 135, 135, 66, 33, 33, 33, 135, 66, 66, 66, 66, 135, 66, 135, 33, 33, 66, 33, 135, 135, 33, 33, 66, 66, 66, 33, 135, 33, 135, 66, 33, 135, 135, 66, 66, 33, 33, 33, 135, 135, 135, 135, 135, 135, 135, 135, 33, 135, 33, 33, 135, 66, 135, 135, 66, 135, 33, 66, 135, 33, 135, 66, 33, 66, 66, 135, 135, 33, 33, 135, 33, 33, 33, 66, 33]
Prompts retrieved: 10029 . Total input tokens: 2205085 . Total output tokens: 2017823
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 0.7746064581442624,
    "estimated_duration": 3598.356844296403,
    "input_throughput": 219.70694797908104,
    "output_throughput": 202.52994117444166,
    "total_throughput": 422.2368891535227,
    "itl": 18.405660147052817,
    "ttft": 3308.1082749380407,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2268,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.608314701169437,
    "arrivals": 3297,
    "finished_requests": 3294,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7746630869805813. Arrivals time: 0.02257920033298433 Scheduler time: 0.3415252526756376 Scheduler overhead time: 0.14731270587071776 Adapter cache time: 0.03651231504045427 Engine time: 0.1506961341947317 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-8/adapters_128_slots_64_rate_3.2-1.6-0.8_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-8/adapters_128_slots_64_rate_3.2-1.6-0.8_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [42 43 43]
Adapter prompts. [34560, 17280, 34560, 34560, 8640, 8640, 34560, 8640, 17280, 17280, 17280, 8640, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 34560, 17280, 8640, 17280, 17280, 17280, 17280, 34560, 17280, 8640, 17280, 8640, 34560, 34560, 8640, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 8640, 8640, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 8640, 8640, 17280, 8640, 34560, 34560, 8640, 8640, 17280, 17280, 17280, 8640, 34560, 8640, 34560, 17280, 8640, 34560, 34560, 17280, 17280, 8640, 8640, 8640, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 34560, 17280, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 17280, 17280, 34560, 34560, 8640, 8640, 34560, 8640, 8640, 8640, 17280, 8640]
Prompts retrieved: 2592000 . Total input tokens: 577126872 . Total output tokens: 517998278
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 62.338838218012825,
    "estimated_duration": 3600.1012732628164,
    "input_throughput": 6382.759610307914,
    "output_throughput": 5624.617604617524,
    "total_throughput": 12007.377214925438,
    "itl": 152.12176044575386,
    "ttft": 2021912.690112885,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 212,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.648823401713743,
    "arrivals": 863203,
    "finished_requests": 93009,
    "scheduler_time": 128.3945920499142
}
#Debug simulation 
Total elapsed time: 62.33900159201585. Arrivals time: 0.5241541094146669 Scheduler time: 61.674125898163766 Scheduler overhead time: 0.05359156639315188 Adapter cache time: 0.011889905901625752 Engine time: 0.05467435996979475 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-16/adapters_128_slots_64_rate_3.2-1.6-0.8_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-16/adapters_128_slots_64_rate_3.2-1.6-0.8_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [42 43 43]
Adapter prompts. [34560, 17280, 34560, 34560, 8640, 8640, 34560, 8640, 17280, 17280, 17280, 8640, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 34560, 17280, 8640, 17280, 17280, 17280, 17280, 34560, 17280, 8640, 17280, 8640, 34560, 34560, 8640, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 8640, 8640, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 8640, 8640, 17280, 8640, 34560, 34560, 8640, 8640, 17280, 17280, 17280, 8640, 34560, 8640, 34560, 17280, 8640, 34560, 34560, 17280, 17280, 8640, 8640, 8640, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 34560, 17280, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 17280, 17280, 34560, 34560, 8640, 8640, 34560, 8640, 8640, 8640, 17280, 8640]
Prompts retrieved: 2592000 . Total input tokens: 577126872 . Total output tokens: 517998278
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 63.09435345698148,
    "estimated_duration": 3600.069500605393,
    "input_throughput": 6374.372493681302,
    "output_throughput": 5618.658194403887,
    "total_throughput": 11993.03068808519,
    "itl": 152.34218383146543,
    "ttft": 2021988.6482306225,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 218,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7127116667362886,
    "arrivals": 863203,
    "finished_requests": 92877,
    "scheduler_time": 128.219249339614
}
#Debug simulation 
Total elapsed time: 63.094518238911405. Arrivals time: 0.5368510945700109 Scheduler time: 62.416050439700484 Scheduler overhead time: 0.0541613542009145 Adapter cache time: 0.011859304271638393 Engine time: 0.05495372461155057 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-32/adapters_128_slots_64_rate_3.2-1.6-0.8_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-32/adapters_128_slots_64_rate_3.2-1.6-0.8_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [42 43 43]
Adapter prompts. [34560, 17280, 34560, 34560, 8640, 8640, 34560, 8640, 17280, 17280, 17280, 8640, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 34560, 17280, 8640, 17280, 17280, 17280, 17280, 34560, 17280, 8640, 17280, 8640, 34560, 34560, 8640, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 8640, 8640, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 8640, 8640, 17280, 8640, 34560, 34560, 8640, 8640, 17280, 17280, 17280, 8640, 34560, 8640, 34560, 17280, 8640, 34560, 34560, 17280, 17280, 8640, 8640, 8640, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 34560, 17280, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 17280, 17280, 34560, 34560, 8640, 8640, 34560, 8640, 8640, 8640, 17280, 8640]
Prompts retrieved: 2592000 . Total input tokens: 577126872 . Total output tokens: 517998278
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 63.74613700597547,
    "estimated_duration": 3600.0705279732783,
    "input_throughput": 6374.370674598721,
    "output_throughput": 5618.656590982803,
    "total_throughput": 11993.027265581524,
    "itl": 152.34222646772875,
    "ttft": 2021989.139081899,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 218,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.713736985716972,
    "arrivals": 863203,
    "finished_requests": 92877,
    "scheduler_time": 128.21925138850975
}
#Debug simulation 
Total elapsed time: 63.74630360910669. Arrivals time: 0.5465279549825937 Scheduler time: 63.05747217917815 Scheduler overhead time: 0.054361676098778844 Adapter cache time: 0.011801728513091803 Engine time: 0.05510678724385798 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-16/adapters_128_slots_64_rate_3.2-1.6-0.8_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-16/adapters_128_slots_64_rate_3.2-1.6-0.8_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [42 43 43]
Adapter prompts. [34560, 17280, 34560, 34560, 8640, 8640, 34560, 8640, 17280, 17280, 17280, 8640, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 34560, 17280, 8640, 17280, 17280, 17280, 17280, 34560, 17280, 8640, 17280, 8640, 34560, 34560, 8640, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 8640, 8640, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 8640, 8640, 17280, 8640, 34560, 34560, 8640, 8640, 17280, 17280, 17280, 8640, 34560, 8640, 34560, 17280, 8640, 34560, 34560, 17280, 17280, 8640, 8640, 8640, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 34560, 17280, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 17280, 17280, 34560, 34560, 8640, 8640, 34560, 8640, 8640, 8640, 17280, 8640]
Prompts retrieved: 2592000 . Total input tokens: 577126872 . Total output tokens: 517998278
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 64.16830718610436,
    "estimated_duration": 3600.0511245494486,
    "input_throughput": 6375.969175402392,
    "output_throughput": 5622.215712987437,
    "total_throughput": 11998.184888389827,
    "itl": 152.29109370858902,
    "ttft": 2021352.2074022426,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 216,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6756783219450168,
    "arrivals": 863203,
    "finished_requests": 92901,
    "scheduler_time": 128.28459879491388
}
#Debug simulation 
Total elapsed time: 64.16848533693701. Arrivals time: 0.5570505999494344 Scheduler time: 63.469326488440856 Scheduler overhead time: 0.05379388923756778 Adapter cache time: 0.011988764395937324 Engine time: 0.05554438731633127 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-32/adapters_128_slots_64_rate_3.2-1.6-0.8_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-32/adapters_128_slots_64_rate_3.2-1.6-0.8_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [42 43 43]
Adapter prompts. [34560, 17280, 34560, 34560, 8640, 8640, 34560, 8640, 17280, 17280, 17280, 8640, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 34560, 17280, 8640, 17280, 17280, 17280, 17280, 34560, 17280, 8640, 17280, 8640, 34560, 34560, 8640, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 8640, 8640, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 8640, 8640, 17280, 8640, 34560, 34560, 8640, 8640, 17280, 17280, 17280, 8640, 34560, 8640, 34560, 17280, 8640, 34560, 34560, 17280, 17280, 8640, 8640, 8640, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 34560, 17280, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 17280, 17280, 34560, 34560, 8640, 8640, 34560, 8640, 8640, 8640, 17280, 8640]
Prompts retrieved: 2592000 . Total input tokens: 577126872 . Total output tokens: 517998278
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 63.4419709991198,
    "estimated_duration": 3600.080018087046,
    "input_throughput": 6374.353871221409,
    "output_throughput": 5618.641779731386,
    "total_throughput": 11992.995650952795,
    "itl": 152.34252879442542,
    "ttft": 2021993.8564375266,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 218,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.723168519698086,
    "arrivals": 863203,
    "finished_requests": 92877,
    "scheduler_time": 128.21930996830184
}
#Debug simulation 
Total elapsed time: 63.44213240221143. Arrivals time: 0.5396523277740926 Scheduler time: 62.7599099711515 Scheduler overhead time: 0.05475390050560236 Adapter cache time: 0.01203312142752111 Engine time: 0.055253804894164205 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-16/adapters_128_slots_64_rate_3.2-1.6-0.8_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-16/adapters_128_slots_64_rate_3.2-1.6-0.8_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [42 43 43]
Adapter prompts. [34560, 17280, 34560, 34560, 8640, 8640, 34560, 8640, 17280, 17280, 17280, 8640, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 34560, 17280, 8640, 17280, 17280, 17280, 17280, 34560, 17280, 8640, 17280, 8640, 34560, 34560, 8640, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 8640, 8640, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 8640, 8640, 17280, 8640, 34560, 34560, 8640, 8640, 17280, 17280, 17280, 8640, 34560, 8640, 34560, 17280, 8640, 34560, 34560, 17280, 17280, 8640, 8640, 8640, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 34560, 17280, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 17280, 17280, 34560, 34560, 8640, 8640, 34560, 8640, 8640, 8640, 17280, 8640]
Prompts retrieved: 2592000 . Total input tokens: 577126872 . Total output tokens: 517998278
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 62.90052060014568,
    "estimated_duration": 3600.0862448774697,
    "input_throughput": 6382.786254828205,
    "output_throughput": 5624.641084310798,
    "total_throughput": 12007.427339139003,
    "itl": 152.1212893110215,
    "ttft": 2021905.1747420842,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 212,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6338906625192621,
    "arrivals": 863203,
    "finished_requests": 93009,
    "scheduler_time": 128.3944964037354
}
#Debug simulation 
Total elapsed time: 62.900683840038255. Arrivals time: 0.5371422488242388 Scheduler time: 62.220477625960484 Scheduler overhead time: 0.05412892671301961 Adapter cache time: 0.012219206662848592 Engine time: 0.05571080418303609 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-32/adapters_128_slots_64_rate_3.2-1.6-0.8_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-32/adapters_128_slots_64_rate_3.2-1.6-0.8_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [42 43 43]
Adapter prompts. [34560, 17280, 34560, 34560, 8640, 8640, 34560, 8640, 17280, 17280, 17280, 8640, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 34560, 17280, 8640, 17280, 17280, 17280, 17280, 34560, 17280, 8640, 17280, 8640, 34560, 34560, 8640, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 8640, 8640, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 8640, 8640, 17280, 8640, 34560, 34560, 8640, 8640, 17280, 17280, 17280, 8640, 34560, 8640, 34560, 17280, 8640, 34560, 34560, 17280, 17280, 8640, 8640, 8640, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 34560, 17280, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 17280, 17280, 34560, 34560, 8640, 8640, 34560, 8640, 8640, 8640, 17280, 8640]
Prompts retrieved: 2592000 . Total input tokens: 577126872 . Total output tokens: 517998278
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 63.561452221823856,
    "estimated_duration": 3600.089383098946,
    "input_throughput": 6374.337289438706,
    "output_throughput": 5618.62716380341,
    "total_throughput": 11992.964453242115,
    "itl": 152.34280044356586,
    "ttft": 2021998.3795209941,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 218,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7324742998927858,
    "arrivals": 863203,
    "finished_requests": 92877,
    "scheduler_time": 128.21936920001528
}
#Debug simulation 
Total elapsed time: 63.56161509291269. Arrivals time: 0.5400140911806375 Scheduler time: 62.88048688462004 Scheduler overhead time: 0.05372735555283725 Adapter cache time: 0.011915694223716855 Engine time: 0.05460295523516834 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-8/adapters_128_slots_64_rate_3.2-1.6-0.4_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-8/adapters_128_slots_64_rate_3.2-1.6-0.4_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [42 43 43]
Adapter prompts. [34560, 17280, 34560, 34560, 4320, 4320, 34560, 4320, 17280, 17280, 17280, 4320, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 34560, 17280, 4320, 17280, 17280, 17280, 17280, 34560, 17280, 4320, 17280, 4320, 34560, 34560, 4320, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 4320, 4320, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 4320, 4320, 17280, 4320, 34560, 34560, 4320, 4320, 17280, 17280, 17280, 4320, 34560, 4320, 34560, 17280, 4320, 34560, 34560, 17280, 17280, 4320, 4320, 4320, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 34560, 17280, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 4320, 17280, 17280, 34560, 34560, 4320, 4320, 34560, 4320, 4320, 4320, 17280, 4320]
Prompts retrieved: 2410560 . Total input tokens: 536675938 . Total output tokens: 481710298
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 98.78399052401073,
    "estimated_duration": 3600.001646877774,
    "input_throughput": 6323.535996085865,
    "output_throughput": 5584.9860561696105,
    "total_throughput": 11908.522052255476,
    "itl": 153.252167205852,
    "ttft": 2012574.9747439865,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 144,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.440710235126316,
    "arrivals": 802767,
    "finished_requests": 92357,
    "scheduler_time": 127.46468530664734
}
#Debug simulation 
Total elapsed time: 98.7842431620229. Arrivals time: 0.47610089951194823 Scheduler time: 98.15161246154457 Scheduler overhead time: 0.06058756774291396 Adapter cache time: 0.012619302375242114 Engine time: 0.06123318779282272 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-16/adapters_128_slots_64_rate_3.2-1.6-0.4_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-16/adapters_128_slots_64_rate_3.2-1.6-0.4_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [42 43 43]
Adapter prompts. [34560, 17280, 34560, 34560, 4320, 4320, 34560, 4320, 17280, 17280, 17280, 4320, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 34560, 17280, 4320, 17280, 17280, 17280, 17280, 34560, 17280, 4320, 17280, 4320, 34560, 34560, 4320, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 4320, 4320, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 4320, 4320, 17280, 4320, 34560, 34560, 4320, 4320, 17280, 17280, 17280, 4320, 34560, 4320, 34560, 17280, 4320, 34560, 34560, 17280, 17280, 4320, 4320, 4320, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 34560, 17280, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 4320, 17280, 17280, 34560, 34560, 4320, 4320, 34560, 4320, 4320, 4320, 17280, 4320]
Prompts retrieved: 2410560 . Total input tokens: 536675938 . Total output tokens: 481710298
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 99.33889990788884,
    "estimated_duration": 3600.033176370943,
    "input_throughput": 6323.480613850418,
    "output_throughput": 5584.937142237132,
    "total_throughput": 11908.41775608755,
    "itl": 153.252777216254,
    "ttft": 2012590.76362135,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 144,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.47020098835462704,
    "arrivals": 802767,
    "finished_requests": 92357,
    "scheduler_time": 127.46511580280836
}
#Debug simulation 
Total elapsed time: 99.33905988978222. Arrivals time: 0.4822662118822336 Scheduler time: 98.69929948099889 Scheduler overhead time: 0.061662742868065834 Adapter cache time: 0.012176318326964974 Engine time: 0.06136287306435406 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-32/adapters_128_slots_64_rate_3.2-1.6-0.4_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-32/adapters_128_slots_64_rate_3.2-1.6-0.4_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [42 43 43]
Adapter prompts. [34560, 17280, 34560, 34560, 4320, 4320, 34560, 4320, 17280, 17280, 17280, 4320, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 34560, 17280, 4320, 17280, 17280, 17280, 17280, 34560, 17280, 4320, 17280, 4320, 34560, 34560, 4320, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 4320, 4320, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 4320, 4320, 17280, 4320, 34560, 34560, 4320, 4320, 17280, 17280, 17280, 4320, 34560, 4320, 34560, 17280, 4320, 34560, 34560, 17280, 17280, 4320, 4320, 4320, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 34560, 17280, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 4320, 17280, 17280, 34560, 34560, 4320, 4320, 34560, 4320, 4320, 4320, 17280, 4320]
Prompts retrieved: 2410560 . Total input tokens: 536675938 . Total output tokens: 481710298
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 98.89166321395896,
    "estimated_duration": 3600.033957897735,
    "input_throughput": 6323.479241094056,
    "output_throughput": 5584.935929810233,
    "total_throughput": 11908.415170904289,
    "itl": 153.25280069411494,
    "ttft": 2012591.0693903046,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 144,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.470979721192272,
    "arrivals": 802767,
    "finished_requests": 92357,
    "scheduler_time": 127.4651185967571
}
#Debug simulation 
Total elapsed time: 98.89181925007142. Arrivals time: 0.48694904264993966 Scheduler time: 98.24862553994171 Scheduler overhead time: 0.060478543397039175 Adapter cache time: 0.01246629236266017 Engine time: 0.06148776854388416 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-16-16/adapters_128_slots_64_rate_3.2-1.6-0.4_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-16-16/adapters_128_slots_64_rate_3.2-1.6-0.4_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [42 43 43]
Adapter prompts. [34560, 17280, 34560, 34560, 4320, 4320, 34560, 4320, 17280, 17280, 17280, 4320, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 34560, 17280, 4320, 17280, 17280, 17280, 17280, 34560, 17280, 4320, 17280, 4320, 34560, 34560, 4320, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 4320, 4320, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 4320, 4320, 17280, 4320, 34560, 34560, 4320, 4320, 17280, 17280, 17280, 4320, 34560, 4320, 34560, 17280, 4320, 34560, 34560, 17280, 17280, 4320, 4320, 4320, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 34560, 17280, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 4320, 17280, 17280, 34560, 34560, 4320, 4320, 34560, 4320, 4320, 4320, 17280, 4320]
Prompts retrieved: 2410560 . Total input tokens: 536675938 . Total output tokens: 481710298
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 99.01541391317733,
    "estimated_duration": 3600.013005910349,
    "input_throughput": 6323.516043588124,
    "output_throughput": 5584.968434000346,
    "total_throughput": 11908.48447758847,
    "itl": 153.25220167169874,
    "ttft": 2012581.5548878962,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 144,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4501798177510502,
    "arrivals": 802767,
    "finished_requests": 92357,
    "scheduler_time": 127.4649665128136
}
#Debug simulation 
Total elapsed time: 99.0155760711059. Arrivals time: 0.4905531001277268 Scheduler time: 98.36724042100832 Scheduler overhead time: 0.06188208283856511 Adapter cache time: 0.012642190558835864 Engine time: 0.06132484902627766 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-16-32/adapters_128_slots_64_rate_3.2-1.6-0.4_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-16-32/adapters_128_slots_64_rate_3.2-1.6-0.4_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [42 43 43]
Adapter prompts. [34560, 17280, 34560, 34560, 4320, 4320, 34560, 4320, 17280, 17280, 17280, 4320, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 34560, 17280, 4320, 17280, 17280, 17280, 17280, 34560, 17280, 4320, 17280, 4320, 34560, 34560, 4320, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 4320, 4320, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 4320, 4320, 17280, 4320, 34560, 34560, 4320, 4320, 17280, 17280, 17280, 4320, 34560, 4320, 34560, 17280, 4320, 34560, 34560, 17280, 17280, 4320, 4320, 4320, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 34560, 17280, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 4320, 17280, 17280, 34560, 34560, 4320, 4320, 34560, 4320, 4320, 4320, 17280, 4320]
Prompts retrieved: 2410560 . Total input tokens: 536675938 . Total output tokens: 481710298
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 98.82759909401648,
    "estimated_duration": 3600.04017012434,
    "input_throughput": 6323.468329303042,
    "output_throughput": 5584.926292449,
    "total_throughput": 11908.394621752042,
    "itl": 153.25297799318164,
    "ttft": 2012593.9068877632,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 144,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.47714165672659925,
    "arrivals": 802767,
    "finished_requests": 92357,
    "scheduler_time": 127.46516888783457
}
#Debug simulation 
Total elapsed time: 98.82775818905793. Arrivals time: 0.4820580061059445 Scheduler time: 98.18874806934036 Scheduler overhead time: 0.06050676410086453 Adapter cache time: 0.012564934091642499 Engine time: 0.061694731237366796 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_16-16-16/adapters_128_slots_64_rate_3.2-1.6-0.4_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_16-16-16/adapters_128_slots_64_rate_3.2-1.6-0.4_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [42 43 43]
Adapter prompts. [34560, 17280, 34560, 34560, 4320, 4320, 34560, 4320, 17280, 17280, 17280, 4320, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 34560, 17280, 4320, 17280, 17280, 17280, 17280, 34560, 17280, 4320, 17280, 4320, 34560, 34560, 4320, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 4320, 4320, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 4320, 4320, 17280, 4320, 34560, 34560, 4320, 4320, 17280, 17280, 17280, 4320, 34560, 4320, 34560, 17280, 4320, 34560, 34560, 17280, 17280, 4320, 4320, 4320, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 34560, 17280, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 4320, 17280, 17280, 34560, 34560, 4320, 4320, 34560, 4320, 4320, 4320, 17280, 4320]
Prompts retrieved: 2410560 . Total input tokens: 536675938 . Total output tokens: 481710298
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 98.73543981113471,
    "estimated_duration": 3600.168790879624,
    "input_throughput": 6323.360465118031,
    "output_throughput": 5585.028971679762,
    "total_throughput": 11908.389436797794,
    "itl": 153.2528537927067,
    "ttft": 2012635.6869143483,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 144,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4305672424659138,
    "arrivals": 802767,
    "finished_requests": 92361,
    "scheduler_time": 127.47086096669204
}
#Debug simulation 
Total elapsed time: 98.7355979771819. Arrivals time: 0.4813469967339188 Scheduler time: 98.09745865873992 Scheduler overhead time: 0.060561046935617924 Adapter cache time: 0.012294359738007188 Engine time: 0.061765511985868216 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_16-16-32/adapters_128_slots_64_rate_3.2-1.6-0.4_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_16-16-32/adapters_128_slots_64_rate_3.2-1.6-0.4_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [42 43 43]
Adapter prompts. [34560, 17280, 34560, 34560, 4320, 4320, 34560, 4320, 17280, 17280, 17280, 4320, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 34560, 17280, 4320, 17280, 17280, 17280, 17280, 34560, 17280, 4320, 17280, 4320, 34560, 34560, 4320, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 4320, 4320, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 4320, 4320, 17280, 4320, 34560, 34560, 4320, 4320, 17280, 17280, 17280, 4320, 34560, 4320, 34560, 17280, 4320, 34560, 34560, 17280, 17280, 4320, 4320, 4320, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 34560, 17280, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 4320, 17280, 17280, 34560, 34560, 4320, 4320, 34560, 4320, 4320, 4320, 17280, 4320]
Prompts retrieved: 2410560 . Total input tokens: 536675938 . Total output tokens: 481710298
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 98.88221805309877,
    "estimated_duration": 3600.0462815564365,
    "input_throughput": 6323.457594594573,
    "output_throughput": 5584.916811488166,
    "total_throughput": 11908.374406082738,
    "itl": 153.25310310632773,
    "ttft": 2012597.5199436399,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 144,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.48317783847451196,
    "arrivals": 802767,
    "finished_requests": 92357,
    "scheduler_time": 127.4652441381875
}
#Debug simulation 
Total elapsed time: 98.88237790996209. Arrivals time: 0.4741599813569337 Scheduler time: 98.2517849355936 Scheduler overhead time: 0.06015486968681216 Adapter cache time: 0.01252127648331225 Engine time: 0.06197946658357978 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-8/adapters_128_slots_64_rate_3.2-1.6-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-8/adapters_128_slots_64_rate_3.2-1.6-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [42 43 43]
Adapter prompts. [34560, 17280, 34560, 34560, 1080, 1080, 34560, 1080, 17280, 17280, 17280, 1080, 34560, 17280, 1080, 34560, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 34560, 17280, 1080, 17280, 17280, 17280, 17280, 34560, 17280, 1080, 17280, 1080, 34560, 34560, 1080, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 1080, 17280, 34560, 34560, 17280, 1080, 1080, 1080, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 1080, 1080, 17280, 1080, 34560, 34560, 1080, 1080, 17280, 17280, 17280, 1080, 34560, 1080, 34560, 17280, 1080, 34560, 34560, 17280, 17280, 1080, 1080, 1080, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 34560, 17280, 34560, 1080, 17280, 34560, 1080, 34560, 17280, 1080, 17280, 17280, 34560, 34560, 1080, 1080, 34560, 1080, 1080, 1080, 17280, 1080]
Prompts retrieved: 2274480 . Total input tokens: 506350051 . Total output tokens: 454613738
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 128.44905720790848,
    "estimated_duration": 3600.112005370955,
    "input_throughput": 6390.230905504705,
    "output_throughput": 5585.365391410393,
    "total_throughput": 11975.596296915099,
    "itl": 152.77757547155807,
    "ttft": 1964744.1665038744,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 146,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4468312106141815,
    "arrivals": 757465,
    "finished_requests": 92533,
    "scheduler_time": 127.40911436886887
}
#Debug simulation 
Total elapsed time: 128.44921114691533. Arrivals time: 0.5128616553265601 Scheduler time: 127.76032856386155 Scheduler overhead time: 0.06947976467199624 Adapter cache time: 0.013808086980134249 Engine time: 0.06872204365208745 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-16/adapters_128_slots_64_rate_3.2-1.6-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-16/adapters_128_slots_64_rate_3.2-1.6-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [42 43 43]
Adapter prompts. [34560, 17280, 34560, 34560, 1080, 1080, 34560, 1080, 17280, 17280, 17280, 1080, 34560, 17280, 1080, 34560, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 34560, 17280, 1080, 17280, 17280, 17280, 17280, 34560, 17280, 1080, 17280, 1080, 34560, 34560, 1080, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 1080, 17280, 34560, 34560, 17280, 1080, 1080, 1080, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 1080, 1080, 17280, 1080, 34560, 34560, 1080, 1080, 17280, 17280, 17280, 1080, 34560, 1080, 34560, 17280, 1080, 34560, 34560, 17280, 17280, 1080, 1080, 1080, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 34560, 17280, 34560, 1080, 17280, 34560, 1080, 34560, 17280, 1080, 17280, 17280, 34560, 34560, 1080, 1080, 34560, 1080, 1080, 1080, 17280, 1080]
Prompts retrieved: 2274480 . Total input tokens: 506350051 . Total output tokens: 454613738
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 129.24560576700605,
    "estimated_duration": 3600.1104914837224,
    "input_throughput": 6390.103041120513,
    "output_throughput": 5585.290520267609,
    "total_throughput": 11975.393561388122,
    "itl": 152.77931567698957,
    "ttft": 1964749.4083336208,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 146,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4769982795813121,
    "arrivals": 757465,
    "finished_requests": 92532,
    "scheduler_time": 127.40804112494959
}
#Debug simulation 
Total elapsed time: 129.24576124595478. Arrivals time: 0.5562952351756394 Scheduler time: 128.51330171106383 Scheduler overhead time: 0.06942698662169278 Adapter cache time: 0.014246063306927681 Engine time: 0.06825761403888464 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-32/adapters_128_slots_64_rate_3.2-1.6-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-32/adapters_128_slots_64_rate_3.2-1.6-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [42 43 43]
Adapter prompts. [34560, 17280, 34560, 34560, 1080, 1080, 34560, 1080, 17280, 17280, 17280, 1080, 34560, 17280, 1080, 34560, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 34560, 17280, 1080, 17280, 17280, 17280, 17280, 34560, 17280, 1080, 17280, 1080, 34560, 34560, 1080, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 1080, 17280, 34560, 34560, 17280, 1080, 1080, 1080, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 1080, 1080, 17280, 1080, 34560, 34560, 1080, 1080, 17280, 17280, 17280, 1080, 34560, 1080, 34560, 17280, 1080, 34560, 34560, 17280, 17280, 1080, 1080, 1080, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 34560, 17280, 34560, 1080, 17280, 34560, 1080, 34560, 17280, 1080, 17280, 17280, 34560, 34560, 1080, 1080, 34560, 1080, 1080, 1080, 17280, 1080]
Prompts retrieved: 2274480 . Total input tokens: 506350051 . Total output tokens: 454613738
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 128.9580944450572,
    "estimated_duration": 3600.1112440505854,
    "input_throughput": 6390.101705334068,
    "output_throughput": 5585.289352719086,
    "total_throughput": 11975.391058053156,
    "itl": 152.77933309685207,
    "ttft": 1964749.8641244906,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 146,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.47774125387892274,
    "arrivals": 757465,
    "finished_requests": 92532,
    "scheduler_time": 127.40805071750695
}
#Debug simulation 
Total elapsed time: 128.95824675494805. Arrivals time: 0.5065308683551848 Scheduler time: 128.27740492718294 Scheduler overhead time: 0.06726331007666886 Adapter cache time: 0.013934166869148612 Engine time: 0.06948976079002023 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-16-16/adapters_128_slots_64_rate_3.2-1.6-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-16-16/adapters_128_slots_64_rate_3.2-1.6-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [42 43 43]
Adapter prompts. [34560, 17280, 34560, 34560, 1080, 1080, 34560, 1080, 17280, 17280, 17280, 1080, 34560, 17280, 1080, 34560, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 34560, 17280, 1080, 17280, 17280, 17280, 17280, 34560, 17280, 1080, 17280, 1080, 34560, 34560, 1080, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 1080, 17280, 34560, 34560, 17280, 1080, 1080, 1080, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 1080, 1080, 17280, 1080, 34560, 34560, 1080, 1080, 17280, 17280, 17280, 1080, 34560, 1080, 34560, 17280, 1080, 34560, 34560, 17280, 17280, 1080, 1080, 1080, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 34560, 17280, 34560, 1080, 17280, 34560, 1080, 34560, 17280, 1080, 17280, 17280, 34560, 34560, 1080, 1080, 34560, 1080, 1080, 1080, 17280, 1080]
Prompts retrieved: 2274480 . Total input tokens: 506350051 . Total output tokens: 454613738
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 128.70864100311883,
    "estimated_duration": 3600.009903195938,
    "input_throughput": 6390.056310561195,
    "output_throughput": 5585.448523946907,
    "total_throughput": 11975.504834508101,
    "itl": 152.77914171198583,
    "ttft": 1964711.5210129686,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 146,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.456568513659295,
    "arrivals": 757465,
    "finished_requests": 92530,
    "scheduler_time": 127.40515209533189
}
#Debug simulation 
Total elapsed time: 128.70879439613782. Arrivals time: 0.5104930205270648 Scheduler time: 128.02152994833887 Scheduler overhead time: 0.06949533382430673 Adapter cache time: 0.014181374106556177 Engine time: 0.06874197418801486 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-16-32/adapters_128_slots_64_rate_3.2-1.6-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-16-32/adapters_128_slots_64_rate_3.2-1.6-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [42 43 43]
Adapter prompts. [34560, 17280, 34560, 34560, 1080, 1080, 34560, 1080, 17280, 17280, 17280, 1080, 34560, 17280, 1080, 34560, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 34560, 17280, 1080, 17280, 17280, 17280, 17280, 34560, 17280, 1080, 17280, 1080, 34560, 34560, 1080, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 1080, 17280, 34560, 34560, 17280, 1080, 1080, 1080, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 1080, 1080, 17280, 1080, 34560, 34560, 1080, 1080, 17280, 17280, 17280, 1080, 34560, 1080, 34560, 17280, 1080, 34560, 34560, 17280, 17280, 1080, 1080, 1080, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 34560, 17280, 34560, 1080, 17280, 34560, 1080, 34560, 17280, 1080, 17280, 17280, 34560, 34560, 1080, 1080, 34560, 1080, 1080, 1080, 17280, 1080]
Prompts retrieved: 2274480 . Total input tokens: 506350051 . Total output tokens: 454613738
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 128.24567803018726,
    "estimated_duration": 3600.117576070553,
    "input_throughput": 6390.090466186808,
    "output_throughput": 5585.279529105564,
    "total_throughput": 11975.36999529237,
    "itl": 152.77951586688783,
    "ttft": 1964751.8389094144,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 146,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.48402894319966483,
    "arrivals": 757465,
    "finished_requests": 92532,
    "scheduler_time": 127.40809504816042
}
#Debug simulation 
Total elapsed time: 128.24591565597802. Arrivals time: 0.5211068296339363 Scheduler time: 127.5490053575486 Scheduler overhead time: 0.06941908854059875 Adapter cache time: 0.013978918315842748 Engine time: 0.06867110496386886 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_16-16-16/adapters_128_slots_64_rate_3.2-1.6-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_16-16-16/adapters_128_slots_64_rate_3.2-1.6-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [42 43 43]
Adapter prompts. [34560, 17280, 34560, 34560, 1080, 1080, 34560, 1080, 17280, 17280, 17280, 1080, 34560, 17280, 1080, 34560, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 34560, 17280, 1080, 17280, 17280, 17280, 17280, 34560, 17280, 1080, 17280, 1080, 34560, 34560, 1080, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 1080, 17280, 34560, 34560, 17280, 1080, 1080, 1080, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 1080, 1080, 17280, 1080, 34560, 34560, 1080, 1080, 17280, 17280, 17280, 1080, 34560, 1080, 34560, 17280, 1080, 34560, 34560, 17280, 17280, 1080, 1080, 1080, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 34560, 17280, 34560, 1080, 17280, 34560, 1080, 34560, 17280, 1080, 17280, 17280, 34560, 34560, 1080, 1080, 34560, 1080, 1080, 1080, 17280, 1080]
Prompts retrieved: 2274480 . Total input tokens: 506350051 . Total output tokens: 454613738
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 128.33335630898364,
    "estimated_duration": 3600.1014657895776,
    "input_throughput": 6390.249613410383,
    "output_throughput": 5585.381743008709,
    "total_throughput": 11975.631356419091,
    "itl": 152.77731321372252,
    "ttft": 1964740.0055162678,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 146,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4365473430557182,
    "arrivals": 757465,
    "finished_requests": 92533,
    "scheduler_time": 127.409017831522
}
#Debug simulation 
Total elapsed time: 128.33350420813076. Arrivals time: 0.5101105971261859 Scheduler time: 127.64934640214778 Scheduler overhead time: 0.06812613713555038 Adapter cache time: 0.013782270019873977 Engine time: 0.06801818148232996 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_16-16-32/adapters_128_slots_64_rate_3.2-1.6-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_16-16-32/adapters_128_slots_64_rate_3.2-1.6-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [42 43 43]
Adapter prompts. [34560, 17280, 34560, 34560, 1080, 1080, 34560, 1080, 17280, 17280, 17280, 1080, 34560, 17280, 1080, 34560, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 34560, 17280, 1080, 17280, 17280, 17280, 17280, 34560, 17280, 1080, 17280, 1080, 34560, 34560, 1080, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 1080, 17280, 34560, 34560, 17280, 1080, 1080, 1080, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 1080, 1080, 17280, 1080, 34560, 34560, 1080, 1080, 17280, 17280, 17280, 1080, 34560, 1080, 34560, 17280, 1080, 34560, 34560, 17280, 17280, 1080, 1080, 1080, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 34560, 17280, 34560, 1080, 17280, 34560, 1080, 34560, 17280, 1080, 17280, 17280, 34560, 34560, 1080, 1080, 34560, 1080, 1080, 1080, 17280, 1080]
Prompts retrieved: 2274480 . Total input tokens: 506350051 . Total output tokens: 454613738
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 128.81810935214162,
    "estimated_duration": 3600.1224563830697,
    "input_throughput": 6390.081803804107,
    "output_throughput": 5585.271957721555,
    "total_throughput": 11975.353761525663,
    "itl": 152.77942929904097,
    "ttft": 1964754.0308049058,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 146,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.49019087873399225,
    "arrivals": 757465,
    "finished_requests": 92532,
    "scheduler_time": 127.40813605010399
}
#Debug simulation 
Total elapsed time: 128.8182598759886. Arrivals time: 0.5731524708680809 Scheduler time: 128.06940235197544 Scheduler overhead time: 0.06974685983732343 Adapter cache time: 0.013952851062640548 Engine time: 0.06834635068662465 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-8/adapters_128_slots_64_rate_3.2-1.6-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-8/adapters_128_slots_64_rate_3.2-1.6-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [42 43 43]
Adapter prompts. [34560, 17280, 34560, 34560, 540, 540, 34560, 540, 17280, 17280, 17280, 540, 34560, 17280, 540, 34560, 17280, 540, 540, 540, 540, 17280, 17280, 34560, 17280, 540, 17280, 17280, 17280, 17280, 34560, 17280, 540, 17280, 540, 34560, 34560, 540, 17280, 17280, 540, 17280, 540, 17280, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 540, 17280, 34560, 34560, 17280, 540, 540, 540, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 540, 540, 17280, 540, 34560, 34560, 540, 540, 17280, 17280, 17280, 540, 34560, 540, 34560, 17280, 540, 34560, 34560, 17280, 17280, 540, 540, 540, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 540, 34560, 540, 540, 34560, 17280, 34560, 34560, 17280, 34560, 540, 17280, 34560, 540, 34560, 17280, 540, 17280, 17280, 34560, 34560, 540, 540, 34560, 540, 540, 540, 17280, 540]
Prompts retrieved: 2251800 . Total input tokens: 501261240 . Total output tokens: 450084141
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 63.78445117897354,
    "estimated_duration": 3600.04882763696,
    "input_throughput": 6416.177698112412,
    "output_throughput": 5646.1184203832045,
    "total_throughput": 12062.296118495617,
    "itl": 152.0189361470725,
    "ttft": 2005815.8339787396,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 196,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.599855597810819,
    "arrivals": 749804,
    "finished_requests": 93341,
    "scheduler_time": 128.36843821625172
}
#Debug simulation 
Total elapsed time: 63.78462834400125. Arrivals time: 0.4716426592785865 Scheduler time: 63.15739136352204 Scheduler overhead time: 0.0588734729681164 Adapter cache time: 0.014431539457291365 Engine time: 0.05996410548686981 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-16/adapters_128_slots_64_rate_3.2-1.6-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-16/adapters_128_slots_64_rate_3.2-1.6-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [42 43 43]
Adapter prompts. [34560, 17280, 34560, 34560, 540, 540, 34560, 540, 17280, 17280, 17280, 540, 34560, 17280, 540, 34560, 17280, 540, 540, 540, 540, 17280, 17280, 34560, 17280, 540, 17280, 17280, 17280, 17280, 34560, 17280, 540, 17280, 540, 34560, 34560, 540, 17280, 17280, 540, 17280, 540, 17280, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 540, 17280, 34560, 34560, 17280, 540, 540, 540, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 540, 540, 17280, 540, 34560, 34560, 540, 540, 17280, 17280, 17280, 540, 34560, 540, 34560, 17280, 540, 34560, 34560, 17280, 17280, 540, 540, 540, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 540, 34560, 540, 540, 34560, 17280, 34560, 34560, 17280, 34560, 540, 17280, 34560, 540, 34560, 17280, 540, 17280, 17280, 34560, 34560, 540, 540, 34560, 540, 540, 540, 17280, 540]
Prompts retrieved: 2251800 . Total input tokens: 501261240 . Total output tokens: 450084141
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 63.48040928784758,
    "estimated_duration": 3600.0955097360893,
    "input_throughput": 6417.268635657276,
    "output_throughput": 5647.207399086576,
    "total_throughput": 12064.476034743851,
    "itl": 151.9753756643222,
    "ttft": 2005914.8249309575,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 196,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6399844398349539,
    "arrivals": 749804,
    "finished_requests": 93361,
    "scheduler_time": 128.40472682034616
}
#Debug simulation 
Total elapsed time: 63.48058075993322. Arrivals time: 0.45566615648567677 Scheduler time: 62.87012621178292 Scheduler overhead time: 0.05960278841666877 Adapter cache time: 0.01374828745611012 Engine time: 0.05964175728149712 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-32/adapters_128_slots_64_rate_3.2-1.6-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-32/adapters_128_slots_64_rate_3.2-1.6-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [42 43 43]
Adapter prompts. [34560, 17280, 34560, 34560, 540, 540, 34560, 540, 17280, 17280, 17280, 540, 34560, 17280, 540, 34560, 17280, 540, 540, 540, 540, 17280, 17280, 34560, 17280, 540, 17280, 17280, 17280, 17280, 34560, 17280, 540, 17280, 540, 34560, 34560, 540, 17280, 17280, 540, 17280, 540, 17280, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 540, 17280, 34560, 34560, 17280, 540, 540, 540, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 540, 540, 17280, 540, 34560, 34560, 540, 540, 17280, 17280, 17280, 540, 34560, 540, 34560, 17280, 540, 34560, 34560, 17280, 17280, 540, 540, 540, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 540, 34560, 540, 540, 34560, 17280, 34560, 34560, 17280, 34560, 540, 17280, 34560, 540, 34560, 17280, 540, 17280, 17280, 34560, 34560, 540, 540, 34560, 540, 540, 540, 17280, 540]
Prompts retrieved: 2251800 . Total input tokens: 501261240 . Total output tokens: 450084141
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 63.75129931489937,
    "estimated_duration": 3600.0965792966967,
    "input_throughput": 6417.266729136829,
    "output_throughput": 5647.2057213453145,
    "total_throughput": 12064.472450482142,
    "itl": 151.97540901583827,
    "ttft": 2005915.2348059535,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 196,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.641046363636854,
    "arrivals": 749804,
    "finished_requests": 93361,
    "scheduler_time": 128.4047344571394
}
#Debug simulation 
Total elapsed time: 63.751468929927796. Arrivals time: 0.45540796336717904 Scheduler time: 63.14083209238015 Scheduler overhead time: 0.059495596680790186 Adapter cache time: 0.0143052046187222 Engine time: 0.05985409882850945 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-16-16/adapters_128_slots_64_rate_3.2-1.6-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-16-16/adapters_128_slots_64_rate_3.2-1.6-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [42 43 43]
Adapter prompts. [34560, 17280, 34560, 34560, 540, 540, 34560, 540, 17280, 17280, 17280, 540, 34560, 17280, 540, 34560, 17280, 540, 540, 540, 540, 17280, 17280, 34560, 17280, 540, 17280, 17280, 17280, 17280, 34560, 17280, 540, 17280, 540, 34560, 34560, 540, 17280, 17280, 540, 17280, 540, 17280, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 540, 17280, 34560, 34560, 17280, 540, 540, 540, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 540, 540, 17280, 540, 34560, 34560, 540, 540, 17280, 17280, 17280, 540, 34560, 540, 34560, 17280, 540, 34560, 34560, 17280, 17280, 540, 540, 540, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 540, 34560, 540, 540, 34560, 17280, 34560, 34560, 17280, 34560, 540, 17280, 34560, 540, 34560, 17280, 540, 17280, 17280, 34560, 34560, 540, 540, 34560, 540, 540, 540, 17280, 540]
Prompts retrieved: 2251800 . Total input tokens: 501261240 . Total output tokens: 450084141
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 63.66807590913959,
    "estimated_duration": 3600.0653819087247,
    "input_throughput": 6416.1481944401075,
    "output_throughput": 5646.092457693967,
    "total_throughput": 12062.240652134074,
    "itl": 152.01938530815823,
    "ttft": 2005823.0806334673,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 196,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6162859113654133,
    "arrivals": 749804,
    "finished_requests": 93341,
    "scheduler_time": 128.3685621744445
}
#Debug simulation 
Total elapsed time: 63.6682407730259. Arrivals time: 0.4607779923826456 Scheduler time: 63.05289228167385 Scheduler overhead time: 0.059038038132712245 Adapter cache time: 0.014080163789913058 Engine time: 0.05939515493810177 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-16-32/adapters_128_slots_64_rate_3.2-1.6-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-16-32/adapters_128_slots_64_rate_3.2-1.6-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [42 43 43]
Adapter prompts. [34560, 17280, 34560, 34560, 540, 540, 34560, 540, 17280, 17280, 17280, 540, 34560, 17280, 540, 34560, 17280, 540, 540, 540, 540, 17280, 17280, 34560, 17280, 540, 17280, 17280, 17280, 17280, 34560, 17280, 540, 17280, 540, 34560, 34560, 540, 17280, 17280, 540, 17280, 540, 17280, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 540, 17280, 34560, 34560, 17280, 540, 540, 540, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 540, 540, 17280, 540, 34560, 34560, 540, 540, 17280, 17280, 17280, 540, 34560, 540, 34560, 17280, 540, 34560, 34560, 17280, 17280, 540, 540, 540, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 540, 34560, 540, 540, 34560, 17280, 34560, 34560, 17280, 34560, 540, 17280, 34560, 540, 34560, 17280, 540, 17280, 17280, 34560, 34560, 540, 540, 34560, 540, 540, 540, 17280, 540]
Prompts retrieved: 2251800 . Total input tokens: 501261240 . Total output tokens: 450084141
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 63.545356535119936,
    "estimated_duration": 3600.103923214242,
    "input_throughput": 6417.25363843758,
    "output_throughput": 5647.1942015075365,
    "total_throughput": 12064.447839945116,
    "itl": 151.97563378133725,
    "ttft": 2005918.2392057711,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 196,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6483400832489152,
    "arrivals": 749804,
    "finished_requests": 93361,
    "scheduler_time": 128.40478465508522
}
#Debug simulation 
Total elapsed time: 63.54552610218525. Arrivals time: 0.4524543860461563 Scheduler time: 62.93625230086036 Scheduler overhead time: 0.06012480752542615 Adapter cache time: 0.014654632890596986 Engine time: 0.06006979360245168 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_16-16-16/adapters_128_slots_64_rate_3.2-1.6-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_16-16-16/adapters_128_slots_64_rate_3.2-1.6-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [42 43 43]
Adapter prompts. [34560, 17280, 34560, 34560, 540, 540, 34560, 540, 17280, 17280, 17280, 540, 34560, 17280, 540, 34560, 17280, 540, 540, 540, 540, 17280, 17280, 34560, 17280, 540, 17280, 17280, 17280, 17280, 34560, 17280, 540, 17280, 540, 34560, 34560, 540, 17280, 17280, 540, 17280, 540, 17280, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 540, 17280, 34560, 34560, 17280, 540, 540, 540, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 540, 540, 17280, 540, 34560, 34560, 540, 540, 17280, 17280, 17280, 540, 34560, 540, 34560, 17280, 540, 34560, 34560, 17280, 17280, 540, 540, 540, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 540, 34560, 540, 540, 34560, 17280, 34560, 34560, 17280, 34560, 540, 17280, 34560, 540, 34560, 17280, 540, 17280, 17280, 34560, 34560, 540, 540, 34560, 540, 540, 540, 17280, 540]
Prompts retrieved: 2251800 . Total input tokens: 501261240 . Total output tokens: 450084141
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 63.84204354300164,
    "estimated_duration": 3600.0349261576625,
    "input_throughput": 6416.202474083554,
    "output_throughput": 5646.140222782332,
    "total_throughput": 12062.342696865886,
    "itl": 152.0185267750011,
    "ttft": 2005810.0543021497,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 196,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5860498578008272,
    "arrivals": 749804,
    "finished_requests": 93341,
    "scheduler_time": 128.3683424769413
}
#Debug simulation 
Total elapsed time: 63.84221105813049. Arrivals time: 0.46547144930809736 Scheduler time: 63.22279458283447 Scheduler overhead time: 0.05920252576470375 Adapter cache time: 0.014125151094049215 Engine time: 0.05913128983229399 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_16-16-32/adapters_128_slots_64_rate_3.2-1.6-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_16-16-32/adapters_128_slots_64_rate_3.2-1.6-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [42 43 43]
Adapter prompts. [34560, 17280, 34560, 34560, 540, 540, 34560, 540, 17280, 17280, 17280, 540, 34560, 17280, 540, 34560, 17280, 540, 540, 540, 540, 17280, 17280, 34560, 17280, 540, 17280, 17280, 17280, 17280, 34560, 17280, 540, 17280, 540, 34560, 34560, 540, 17280, 17280, 540, 17280, 540, 17280, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 540, 17280, 34560, 34560, 17280, 540, 540, 540, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 540, 540, 17280, 540, 34560, 34560, 540, 540, 17280, 17280, 17280, 540, 34560, 540, 34560, 17280, 540, 34560, 34560, 17280, 17280, 540, 540, 540, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 540, 34560, 540, 540, 34560, 17280, 34560, 34560, 17280, 34560, 540, 17280, 34560, 540, 34560, 17280, 540, 17280, 17280, 34560, 34560, 540, 540, 34560, 540, 540, 540, 17280, 540]
Prompts retrieved: 2251800 . Total input tokens: 501261240 . Total output tokens: 450084141
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 63.46184155996889,
    "estimated_duration": 3600.1132971667753,
    "input_throughput": 6417.236929232609,
    "output_throughput": 5647.179497378521,
    "total_throughput": 12064.41642661113,
    "itl": 151.9758979686735,
    "ttft": 2005922.2494306238,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 196,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6576458634436146,
    "arrivals": 749804,
    "finished_requests": 93361,
    "scheduler_time": 128.40485282743467
}
#Debug simulation 
Total elapsed time: 63.46200779802166. Arrivals time: 0.452950996812433 Scheduler time: 62.85368342977017 Scheduler overhead time: 0.06003634678199887 Adapter cache time: 0.01421867054887116 Engine time: 0.059566636104136705 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-8/adapters_128_slots_64_rate_3.2-1.6-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-8/adapters_128_slots_64_rate_3.2-1.6-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [42 43 43]
Adapter prompts. [34560, 17280, 34560, 34560, 270, 270, 34560, 270, 17280, 17280, 17280, 270, 34560, 17280, 270, 34560, 17280, 270, 270, 270, 270, 17280, 17280, 34560, 17280, 270, 17280, 17280, 17280, 17280, 34560, 17280, 270, 17280, 270, 34560, 34560, 270, 17280, 17280, 270, 17280, 270, 17280, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 270, 17280, 34560, 34560, 17280, 270, 270, 270, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 270, 270, 17280, 270, 34560, 34560, 270, 270, 17280, 17280, 17280, 270, 34560, 270, 34560, 17280, 270, 34560, 34560, 17280, 17280, 270, 270, 270, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 270, 34560, 270, 270, 34560, 17280, 34560, 34560, 17280, 34560, 270, 17280, 34560, 270, 34560, 17280, 270, 17280, 17280, 34560, 34560, 270, 270, 34560, 270, 270, 270, 17280, 270]
Prompts retrieved: 2240460 . Total input tokens: 498739200 . Total output tokens: 447846647
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 70.88234972697683,
    "estimated_duration": 3600.142173510152,
    "input_throughput": 6381.332984302826,
    "output_throughput": 5652.657594952233,
    "total_throughput": 12033.990579255058,
    "itl": 152.63020485303,
    "ttft": 1974548.132853371,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 184,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.563129744883626,
    "arrivals": 746017,
    "finished_requests": 92977,
    "scheduler_time": 128.4097766196992
}
#Debug simulation 
Total elapsed time: 70.88252572808415. Arrivals time: 0.9016384040005505 Scheduler time: 69.81787412171252 Scheduler overhead time: 0.06430186657235026 Adapter cache time: 0.013079310301691294 Engine time: 0.06283851293846965 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-16/adapters_128_slots_64_rate_3.2-1.6-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-16/adapters_128_slots_64_rate_3.2-1.6-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [42 43 43]
Adapter prompts. [34560, 17280, 34560, 34560, 270, 270, 34560, 270, 17280, 17280, 17280, 270, 34560, 17280, 270, 34560, 17280, 270, 270, 270, 270, 17280, 17280, 34560, 17280, 270, 17280, 17280, 17280, 17280, 34560, 17280, 270, 17280, 270, 34560, 34560, 270, 17280, 17280, 270, 17280, 270, 17280, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 270, 17280, 34560, 34560, 17280, 270, 270, 270, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 270, 270, 17280, 270, 34560, 34560, 270, 270, 17280, 17280, 17280, 270, 34560, 270, 34560, 17280, 270, 34560, 34560, 17280, 17280, 270, 270, 270, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 270, 34560, 270, 270, 34560, 17280, 34560, 34560, 17280, 34560, 270, 17280, 34560, 270, 34560, 17280, 270, 17280, 17280, 34560, 34560, 270, 270, 34560, 270, 270, 270, 17280, 270]
Prompts retrieved: 2240460 . Total input tokens: 498739200 . Total output tokens: 447846647
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 70.84428315213881,
    "estimated_duration": 3600.0087792411546,
    "input_throughput": 6381.244438198947,
    "output_throughput": 5652.525659753916,
    "total_throughput": 12033.770097952864,
    "itl": 152.6318808334551,
    "ttft": 1974509.1483557925,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 184,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6000178831117239,
    "arrivals": 746017,
    "finished_requests": 92970,
    "scheduler_time": 128.40396588652771
}
#Debug simulation 
Total elapsed time: 70.844464719994. Arrivals time: 0.47662856010720134 Scheduler time: 70.20461171562783 Scheduler overhead time: 0.06336582754738629 Adapter cache time: 0.013558828737586737 Engine time: 0.06359487446025014 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-32/adapters_128_slots_64_rate_3.2-1.6-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-32/adapters_128_slots_64_rate_3.2-1.6-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [42 43 43]
Adapter prompts. [34560, 17280, 34560, 34560, 270, 270, 34560, 270, 17280, 17280, 17280, 270, 34560, 17280, 270, 34560, 17280, 270, 270, 270, 270, 17280, 17280, 34560, 17280, 270, 17280, 17280, 17280, 17280, 34560, 17280, 270, 17280, 270, 34560, 34560, 270, 17280, 17280, 270, 17280, 270, 17280, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 270, 17280, 34560, 34560, 17280, 270, 270, 270, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 270, 270, 17280, 270, 34560, 34560, 270, 270, 17280, 17280, 17280, 270, 34560, 270, 34560, 17280, 270, 34560, 34560, 17280, 17280, 270, 270, 270, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 270, 34560, 270, 270, 34560, 17280, 34560, 34560, 17280, 34560, 270, 17280, 34560, 270, 34560, 17280, 270, 17280, 17280, 34560, 34560, 270, 270, 34560, 270, 270, 270, 17280, 270]
Prompts retrieved: 2240460 . Total input tokens: 498739200 . Total output tokens: 447846647
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 70.54967611120082,
    "estimated_duration": 3600.0099166526793,
    "input_throughput": 6381.242422065344,
    "output_throughput": 5652.523873856661,
    "total_throughput": 12033.766295922005,
    "itl": 152.63192362603215,
    "ttft": 1974509.778634817,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 184,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6011516625061655,
    "arrivals": 746017,
    "finished_requests": 92970,
    "scheduler_time": 128.40396951866109
}
#Debug simulation 
Total elapsed time: 70.54985680407844. Arrivals time: 0.5458947415463626 Scheduler time: 69.84227699553594 Scheduler overhead time: 0.06263865949586034 Adapter cache time: 0.013551801443099976 Engine time: 0.06275008548982441 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-16-16/adapters_128_slots_64_rate_3.2-1.6-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-16-16/adapters_128_slots_64_rate_3.2-1.6-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [42 43 43]
Adapter prompts. [34560, 17280, 34560, 34560, 270, 270, 34560, 270, 17280, 17280, 17280, 270, 34560, 17280, 270, 34560, 17280, 270, 270, 270, 270, 17280, 17280, 34560, 17280, 270, 17280, 17280, 17280, 17280, 34560, 17280, 270, 17280, 270, 34560, 34560, 270, 17280, 17280, 270, 17280, 270, 17280, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 270, 17280, 34560, 34560, 17280, 270, 270, 270, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 270, 270, 17280, 270, 34560, 34560, 270, 270, 17280, 17280, 17280, 270, 34560, 270, 34560, 17280, 270, 34560, 34560, 17280, 17280, 270, 270, 270, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 270, 34560, 270, 270, 34560, 17280, 34560, 34560, 17280, 34560, 270, 17280, 34560, 270, 34560, 17280, 270, 17280, 17280, 34560, 34560, 270, 270, 34560, 270, 270, 270, 17280, 270]
Prompts retrieved: 2240460 . Total input tokens: 498739200 . Total output tokens: 447846647
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 70.61596373398788,
    "estimated_duration": 3600.1571329145795,
    "input_throughput": 6381.30646853216,
    "output_throughput": 5652.634106979922,
    "total_throughput": 12033.94057551208,
    "itl": 152.63060730002746,
    "ttft": 1974557.8806044045,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 184,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5779537359159448,
    "arrivals": 746017,
    "finished_requests": 92977,
    "scheduler_time": 128.40991203308184
}
#Debug simulation 
Total elapsed time: 70.61615363997407. Arrivals time: 0.5431343305390328 Scheduler time: 69.9108816056978 Scheduler overhead time: 0.06313807237893343 Adapter cache time: 0.013332412810996175 Engine time: 0.06352855172008276 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-16-32/adapters_128_slots_64_rate_3.2-1.6-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-16-32/adapters_128_slots_64_rate_3.2-1.6-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [42 43 43]
Adapter prompts. [34560, 17280, 34560, 34560, 270, 270, 34560, 270, 17280, 17280, 17280, 270, 34560, 17280, 270, 34560, 17280, 270, 270, 270, 270, 17280, 17280, 34560, 17280, 270, 17280, 17280, 17280, 17280, 34560, 17280, 270, 17280, 270, 34560, 34560, 270, 17280, 17280, 270, 17280, 270, 17280, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 270, 17280, 34560, 34560, 17280, 270, 270, 270, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 270, 270, 17280, 270, 34560, 34560, 270, 270, 17280, 17280, 17280, 270, 34560, 270, 34560, 17280, 270, 34560, 34560, 17280, 17280, 270, 270, 270, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 270, 34560, 270, 270, 34560, 17280, 34560, 34560, 17280, 34560, 270, 17280, 34560, 270, 34560, 17280, 270, 17280, 17280, 34560, 34560, 270, 270, 34560, 270, 270, 270, 17280, 270]
Prompts retrieved: 2240460 . Total input tokens: 498739200 . Total output tokens: 447846647
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 70.71606635884382,
    "estimated_duration": 3600.060509642064,
    "input_throughput": 6381.354407369146,
    "output_throughput": 5652.684988348515,
    "total_throughput": 12034.039395717662,
    "itl": 152.63224668979723,
    "ttft": 1974537.013244644,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 184,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6079423669725673,
    "arrivals": 746017,
    "finished_requests": 92973,
    "scheduler_time": 128.40538072726588
}
#Debug simulation 
Total elapsed time: 70.71624645683914. Arrivals time: 0.5631836580578238 Scheduler time: 69.99217060045339 Scheduler overhead time: 0.06258380855433643 Adapter cache time: 0.013212023302912712 Engine time: 0.06312734214589 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_16-16-16/adapters_128_slots_64_rate_3.2-1.6-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_16-16-16/adapters_128_slots_64_rate_3.2-1.6-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [42 43 43]
Adapter prompts. [34560, 17280, 34560, 34560, 270, 270, 34560, 270, 17280, 17280, 17280, 270, 34560, 17280, 270, 34560, 17280, 270, 270, 270, 270, 17280, 17280, 34560, 17280, 270, 17280, 17280, 17280, 17280, 34560, 17280, 270, 17280, 270, 34560, 34560, 270, 17280, 17280, 270, 17280, 270, 17280, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 270, 17280, 34560, 34560, 17280, 270, 270, 270, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 270, 270, 17280, 270, 34560, 34560, 270, 270, 17280, 17280, 17280, 270, 34560, 270, 34560, 17280, 270, 34560, 34560, 17280, 17280, 270, 270, 270, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 270, 34560, 270, 270, 34560, 17280, 34560, 34560, 17280, 34560, 270, 17280, 34560, 270, 34560, 17280, 270, 17280, 17280, 34560, 34560, 270, 270, 34560, 270, 270, 270, 17280, 270]
Prompts retrieved: 2240460 . Total input tokens: 498739200 . Total output tokens: 447846647
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 71.08413502015173,
    "estimated_duration": 3600.1113465756766,
    "input_throughput": 6381.387626205488,
    "output_throughput": 5652.705997373301,
    "total_throughput": 12034.09362357879,
    "itl": 152.6299256854699,
    "ttft": 1974543.2329511598,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 184,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.550169254262001,
    "arrivals": 746017,
    "finished_requests": 92977,
    "scheduler_time": 128.4090186642296
}
#Debug simulation 
Total elapsed time: 71.08431459008716. Arrivals time: 0.8863950518425554 Scheduler time: 70.03755132923834 Scheduler overhead time: 0.06157006905414164 Adapter cache time: 0.013455654494464397 Engine time: 0.06306981923989952 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_16-16-32/adapters_128_slots_64_rate_3.2-1.6-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_16-16-32/adapters_128_slots_64_rate_3.2-1.6-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [42 43 43]
Adapter prompts. [34560, 17280, 34560, 34560, 270, 270, 34560, 270, 17280, 17280, 17280, 270, 34560, 17280, 270, 34560, 17280, 270, 270, 270, 270, 17280, 17280, 34560, 17280, 270, 17280, 17280, 17280, 17280, 34560, 17280, 270, 17280, 270, 34560, 34560, 270, 17280, 17280, 270, 17280, 270, 17280, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 270, 17280, 34560, 34560, 17280, 270, 270, 270, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 270, 270, 17280, 270, 34560, 34560, 270, 270, 17280, 17280, 17280, 270, 34560, 270, 34560, 17280, 270, 34560, 34560, 17280, 17280, 270, 270, 270, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 270, 34560, 270, 270, 34560, 17280, 34560, 34560, 17280, 34560, 270, 17280, 34560, 270, 34560, 17280, 270, 17280, 17280, 34560, 34560, 270, 270, 34560, 270, 270, 270, 17280, 270]
Prompts retrieved: 2240460 . Total input tokens: 498739200 . Total output tokens: 447846647
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 70.68438994814642,
    "estimated_duration": 3600.0691312139193,
    "input_throughput": 6381.339125077737,
    "output_throughput": 5652.671451100194,
    "total_throughput": 12034.01057617793,
    "itl": 152.63248560796575,
    "ttft": 1974542.505996532,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 184,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6164936244487773,
    "arrivals": 746017,
    "finished_requests": 92973,
    "scheduler_time": 128.4054510416427
}
#Debug simulation 
Total elapsed time: 70.6845719490666. Arrivals time: 0.5521653331816196 Scheduler time: 69.9725636751391 Scheduler overhead time: 0.06182373478077352 Adapter cache time: 0.01302402839064598 Engine time: 0.0631391869392246 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-8/adapters_128_slots_64_rate_3.2-1.6-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-8/adapters_128_slots_64_rate_3.2-1.6-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [42 43 43]
Adapter prompts. [34560, 17280, 34560, 34560, 135, 135, 34560, 135, 17280, 17280, 17280, 135, 34560, 17280, 135, 34560, 17280, 135, 135, 135, 135, 17280, 17280, 34560, 17280, 135, 17280, 17280, 17280, 17280, 34560, 17280, 135, 17280, 135, 34560, 34560, 135, 17280, 17280, 135, 17280, 135, 17280, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 135, 17280, 34560, 34560, 17280, 135, 135, 135, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 135, 135, 17280, 135, 34560, 34560, 135, 135, 17280, 17280, 17280, 135, 34560, 135, 34560, 17280, 135, 34560, 34560, 17280, 17280, 135, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 135, 34560, 135, 135, 34560, 17280, 34560, 34560, 17280, 34560, 135, 17280, 34560, 135, 34560, 17280, 135, 17280, 17280, 34560, 34560, 135, 135, 34560, 135, 135, 135, 17280, 135]
Prompts retrieved: 2234790 . Total input tokens: 497488897 . Total output tokens: 446728565
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 59.90087956702337,
    "estimated_duration": 3600.000924238445,
    "input_throughput": 6482.228058021005,
    "output_throughput": 5716.279921331759,
    "total_throughput": 12198.507979352766,
    "itl": 150.27452727898006,
    "ttft": 1998476.5426743536,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 181,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5539482816518277,
    "arrivals": 744176,
    "finished_requests": 94316,
    "scheduler_time": 129.98355020156336
}
#Debug simulation 
Total elapsed time: 59.90117712202482. Arrivals time: 0.46590535598807037 Scheduler time: 59.279137204168364 Scheduler overhead time: 0.0606557906139642 Adapter cache time: 0.013257843209430575 Engine time: 0.06046930351294577 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-16/adapters_128_slots_64_rate_3.2-1.6-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-16/adapters_128_slots_64_rate_3.2-1.6-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [42 43 43]
Adapter prompts. [34560, 17280, 34560, 34560, 135, 135, 34560, 135, 17280, 17280, 17280, 135, 34560, 17280, 135, 34560, 17280, 135, 135, 135, 135, 17280, 17280, 34560, 17280, 135, 17280, 17280, 17280, 17280, 34560, 17280, 135, 17280, 135, 34560, 34560, 135, 17280, 17280, 135, 17280, 135, 17280, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 135, 17280, 34560, 34560, 17280, 135, 135, 135, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 135, 135, 17280, 135, 34560, 34560, 135, 135, 17280, 17280, 17280, 135, 34560, 135, 34560, 17280, 135, 34560, 34560, 17280, 17280, 135, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 135, 34560, 135, 135, 34560, 17280, 34560, 34560, 17280, 34560, 135, 17280, 34560, 135, 34560, 17280, 135, 17280, 17280, 34560, 34560, 135, 135, 34560, 135, 135, 135, 17280, 135]
Prompts retrieved: 2234790 . Total input tokens: 497488897 . Total output tokens: 446728565
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 59.942745924927294,
    "estimated_duration": 3600.107325987489,
    "input_throughput": 6483.698647400024,
    "output_throughput": 5717.169277544902,
    "total_throughput": 12200.867924944927,
    "itl": 150.23570494959014,
    "ttft": 1998597.2822857478,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 181,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5906391369085771,
    "arrivals": 744176,
    "finished_requests": 94336,
    "scheduler_time": 130.02027033806593
}
#Debug simulation 
Total elapsed time: 59.94292382290587. Arrivals time: 0.47364690457470715 Scheduler time: 59.31241606804542 Scheduler overhead time: 0.06038264627568424 Adapter cache time: 0.013291568495333195 Engine time: 0.060961825773119926 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-32/adapters_128_slots_64_rate_3.2-1.6-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-32/adapters_128_slots_64_rate_3.2-1.6-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [42 43 43]
Adapter prompts. [34560, 17280, 34560, 34560, 135, 135, 34560, 135, 17280, 17280, 17280, 135, 34560, 17280, 135, 34560, 17280, 135, 135, 135, 135, 17280, 17280, 34560, 17280, 135, 17280, 17280, 17280, 17280, 34560, 17280, 135, 17280, 135, 34560, 34560, 135, 17280, 17280, 135, 17280, 135, 17280, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 135, 17280, 34560, 34560, 17280, 135, 135, 135, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 135, 135, 17280, 135, 34560, 34560, 135, 135, 17280, 17280, 17280, 135, 34560, 135, 34560, 17280, 135, 34560, 34560, 17280, 17280, 135, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 135, 34560, 135, 135, 34560, 17280, 34560, 34560, 17280, 34560, 135, 17280, 34560, 135, 34560, 17280, 135, 17280, 17280, 34560, 34560, 135, 135, 34560, 135, 135, 135, 17280, 135]
Prompts retrieved: 2234790 . Total input tokens: 497488897 . Total output tokens: 446728565
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 59.691277178004384,
    "estimated_duration": 3600.108375831295,
    "input_throughput": 6483.696756659481,
    "output_throughput": 5717.167610335438,
    "total_throughput": 12200.86436699492,
    "itl": 150.23573738231192,
    "ttft": 1998597.737753751,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 181,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5916838584654056,
    "arrivals": 744176,
    "finished_requests": 94336,
    "scheduler_time": 130.0202754603053
}
#Debug simulation 
Total elapsed time: 59.691450919024646. Arrivals time: 0.46879506506957114 Scheduler time: 59.06443164101802 Scheduler overhead time: 0.061682007974013686 Adapter cache time: 0.01344082853756845 Engine time: 0.06119465152733028 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-16/adapters_128_slots_64_rate_3.2-1.6-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-16/adapters_128_slots_64_rate_3.2-1.6-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [42 43 43]
Adapter prompts. [34560, 17280, 34560, 34560, 135, 135, 34560, 135, 17280, 17280, 17280, 135, 34560, 17280, 135, 34560, 17280, 135, 135, 135, 135, 17280, 17280, 34560, 17280, 135, 17280, 17280, 17280, 17280, 34560, 17280, 135, 17280, 135, 34560, 34560, 135, 17280, 17280, 135, 17280, 135, 17280, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 135, 17280, 34560, 34560, 17280, 135, 135, 135, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 135, 135, 17280, 135, 34560, 34560, 135, 135, 17280, 17280, 17280, 135, 34560, 135, 34560, 17280, 135, 34560, 34560, 17280, 17280, 135, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 135, 34560, 135, 135, 34560, 17280, 34560, 34560, 17280, 34560, 135, 17280, 34560, 135, 34560, 17280, 135, 17280, 17280, 34560, 34560, 135, 135, 34560, 135, 135, 135, 17280, 135]
Prompts retrieved: 2234790 . Total input tokens: 497488897 . Total output tokens: 446728565
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 59.68613663315773,
    "estimated_duration": 3600.0156671747886,
    "input_throughput": 6482.201511726639,
    "output_throughput": 5716.256511780582,
    "total_throughput": 12198.45802350722,
    "itl": 150.27495680170134,
    "ttft": 1998483.2902094063,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 181,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.568574989712798,
    "arrivals": 744176,
    "finished_requests": 94316,
    "scheduler_time": 129.9836664298313
}
#Debug simulation 
Total elapsed time: 59.686303708003834. Arrivals time: 0.454993155086413 Scheduler time: 59.075902501819655 Scheduler overhead time: 0.0597247495315969 Adapter cache time: 0.013210047269240022 Engine time: 0.06054038321599364 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-32/adapters_128_slots_64_rate_3.2-1.6-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-32/adapters_128_slots_64_rate_3.2-1.6-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [42 43 43]
Adapter prompts. [34560, 17280, 34560, 34560, 135, 135, 34560, 135, 17280, 17280, 17280, 135, 34560, 17280, 135, 34560, 17280, 135, 135, 135, 135, 17280, 17280, 34560, 17280, 135, 17280, 17280, 17280, 17280, 34560, 17280, 135, 17280, 135, 34560, 34560, 135, 17280, 17280, 135, 17280, 135, 17280, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 135, 17280, 34560, 34560, 17280, 135, 135, 135, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 135, 135, 17280, 135, 34560, 34560, 135, 135, 17280, 17280, 17280, 135, 34560, 135, 34560, 17280, 135, 34560, 34560, 17280, 17280, 135, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 135, 34560, 135, 135, 34560, 17280, 34560, 34560, 17280, 34560, 135, 17280, 34560, 135, 34560, 17280, 135, 17280, 17280, 34560, 34560, 135, 135, 34560, 135, 135, 135, 17280, 135]
Prompts retrieved: 2234790 . Total input tokens: 497488897 . Total output tokens: 446728565
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 59.61153746792115,
    "estimated_duration": 3600.1152117045895,
    "input_throughput": 6483.6844454619495,
    "output_throughput": 5717.156754618027,
    "total_throughput": 12200.841200079976,
    "itl": 150.23594978293937,
    "ttft": 1998600.6816866563,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 181,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5984745629318076,
    "arrivals": 744176,
    "finished_requests": 94336,
    "scheduler_time": 130.02032062914338
}
#Debug simulation 
Total elapsed time: 59.61171017005108. Arrivals time: 0.4747739585582167 Scheduler time: 58.979142520111054 Scheduler overhead time: 0.06093744281679392 Adapter cache time: 0.013519400963559747 Engine time: 0.06123750447295606 
