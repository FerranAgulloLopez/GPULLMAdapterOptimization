INFO 06-01 00:47:07 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:47:08 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-32/adapters_160_slots_96_rate_0.1-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-32/adapters_160_slots_96_rate_0.1-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [53 53 54]
Adapter prompts. [270, 1080, 270, 270, 540, 270, 270, 270, 1080, 270, 540, 1080, 540, 270, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 270, 1080, 540, 1080, 1080, 1080, 540, 1080, 270, 540, 540, 540, 1080, 270, 270, 1080, 270, 1080, 270, 270, 540, 270, 540, 1080, 270, 270, 540, 270, 270, 270, 270, 270, 1080, 540, 540, 1080, 540, 270, 1080, 1080, 1080, 540, 540, 270, 270, 270, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 270, 270, 1080, 540, 1080, 1080, 270, 1080, 270, 540, 270, 270, 540, 540, 1080, 1080, 1080, 270, 1080, 540, 540, 270, 270, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 1080, 270, 540, 540, 1080, 540, 1080, 270, 270, 270, 540, 540, 540, 1080, 1080, 540, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 270, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 540, 540, 1080, 540, 270, 270]
Prompts retrieved: 101250 . Total input tokens: 22534809 . Total output tokens: 20221767
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 2.773477364331484,
    "estimated_duration": 3599.8030095402996,
    "input_throughput": 2322.087619196547,
    "output_throughput": 2057.982056342037,
    "total_throughput": 4380.069675538584,
    "itl": 39.955147607664024,
    "ttft": 10886.642923384094,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10078,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 33.35808638241134,
    "arrivals": 33938,
    "finished_requests": 33836,
    "scheduler_time": 13.689489807889307
}
#Debug simulation 
Total elapsed time: 2.773587013129145. Arrivals time: 0.09136709105223417 Scheduler time: 2.2838669414632022 Scheduler overhead time: 0.08999579213559628 Adapter cache time: 0.1752290795557201 Engine time: 0.08993628202006221 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_160_slots_96_rate_0.1-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_160_slots_96_rate_0.1-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [53 53 54]
Adapter prompts. [270, 1080, 270, 270, 540, 270, 270, 270, 1080, 270, 540, 1080, 540, 270, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 270, 1080, 540, 1080, 1080, 1080, 540, 1080, 270, 540, 540, 540, 1080, 270, 270, 1080, 270, 1080, 270, 270, 540, 270, 540, 1080, 270, 270, 540, 270, 270, 270, 270, 270, 1080, 540, 540, 1080, 540, 270, 1080, 1080, 1080, 540, 540, 270, 270, 270, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 270, 270, 1080, 540, 1080, 1080, 270, 1080, 270, 540, 270, 270, 540, 540, 1080, 1080, 1080, 270, 1080, 540, 540, 270, 270, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 1080, 270, 540, 540, 1080, 540, 1080, 270, 270, 270, 540, 540, 540, 1080, 1080, 540, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 270, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 540, 540, 1080, 540, 270, 270]
Prompts retrieved: 101250 . Total input tokens: 22534809 . Total output tokens: 20221767
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.7529187533073127,
    "estimated_duration": 3599.801896992064,
    "input_throughput": 2322.088336856729,
    "output_throughput": 2057.9826923782334,
    "total_throughput": 4380.071029234962,
    "itl": 39.873506816594826,
    "ttft": 10886.366258999487,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10086,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 30.157647274380476,
    "arrivals": 33938,
    "finished_requests": 33836,
    "scheduler_time": 13.656244905952368
}
#Debug simulation 
Total elapsed time: 2.7530502369627357. Arrivals time: 0.08979429071769118 Scheduler time: 2.2695502545684576 Scheduler overhead time: 0.09068165300413966 Adapter cache time: 0.1751564582809806 Engine time: 0.08489399962127209 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-32/adapters_160_slots_96_rate_0.1-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-32/adapters_160_slots_96_rate_0.1-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [53 53 54]
Adapter prompts. [270, 1080, 270, 270, 540, 270, 270, 270, 1080, 270, 540, 1080, 540, 270, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 270, 1080, 540, 1080, 1080, 1080, 540, 1080, 270, 540, 540, 540, 1080, 270, 270, 1080, 270, 1080, 270, 270, 540, 270, 540, 1080, 270, 270, 540, 270, 270, 270, 270, 270, 1080, 540, 540, 1080, 540, 270, 1080, 1080, 1080, 540, 540, 270, 270, 270, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 270, 270, 1080, 540, 1080, 1080, 270, 1080, 270, 540, 270, 270, 540, 540, 1080, 1080, 1080, 270, 1080, 540, 540, 270, 270, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 1080, 270, 540, 540, 1080, 540, 1080, 270, 270, 270, 540, 540, 540, 1080, 1080, 540, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 270, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 540, 540, 1080, 540, 270, 270]
Prompts retrieved: 101250 . Total input tokens: 22534809 . Total output tokens: 20221767
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.8075089720077813,
    "estimated_duration": 3599.820235400019,
    "input_throughput": 2322.0765075429176,
    "output_throughput": 2057.972208486342,
    "total_throughput": 4380.04871602926,
    "itl": 39.96742769477878,
    "ttft": 10886.638771473683,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10085,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 33.802478190099436,
    "arrivals": 33938,
    "finished_requests": 33836,
    "scheduler_time": 13.694146490617102
}
#Debug simulation 
Total elapsed time: 2.807599978055805. Arrivals time: 0.09098873334005475 Scheduler time: 2.3183622383512557 Scheduler overhead time: 0.09062291728332639 Adapter cache time: 0.1767685106024146 Engine time: 0.0877118962816894 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_160_slots_96_rate_0.1-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_160_slots_96_rate_0.1-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 540, 135, 135, 135, 1080, 135, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 135, 1080, 540, 1080, 1080, 1080, 540, 1080, 135, 540, 540, 540, 1080, 135, 135, 1080, 135, 1080, 135, 135, 540, 135, 540, 1080, 135, 135, 540, 135, 135, 135, 135, 135, 1080, 540, 540, 1080, 540, 135, 1080, 1080, 1080, 540, 540, 135, 135, 135, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 135, 135, 1080, 540, 1080, 1080, 135, 1080, 135, 540, 135, 135, 540, 540, 1080, 1080, 1080, 135, 1080, 540, 540, 135, 135, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 1080, 135, 540, 540, 1080, 540, 1080, 135, 135, 135, 540, 540, 540, 1080, 1080, 540, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 135, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 540, 540, 1080, 540, 135, 135]
Prompts retrieved: 94095 . Total input tokens: 20974801 . Total output tokens: 18811600
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.655765778850764,
    "estimated_duration": 3599.7439264192362,
    "input_throughput": 2145.4837226942614,
    "output_throughput": 1940.048554216704,
    "total_throughput": 4085.5322769109653,
    "itl": 36.118388731076756,
    "ttft": 9535.82915108796,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7285,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.295653214550356,
    "arrivals": 31534,
    "finished_requests": 31451,
    "scheduler_time": 10.2653257670462
}
#Debug simulation 
Total elapsed time: 2.655852126888931. Arrivals time: 0.08624777151271701 Scheduler time: 2.170394410379231 Scheduler overhead time: 0.09702887712046504 Adapter cache time: 0.15991462115198374 Engine time: 0.09581498522311449 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_160_slots_96_rate_0.1-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_160_slots_96_rate_0.1-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 540, 135, 135, 135, 1080, 135, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 135, 1080, 540, 1080, 1080, 1080, 540, 1080, 135, 540, 540, 540, 1080, 135, 135, 1080, 135, 1080, 135, 135, 540, 135, 540, 1080, 135, 135, 540, 135, 135, 135, 135, 135, 1080, 540, 540, 1080, 540, 135, 1080, 1080, 1080, 540, 540, 135, 135, 135, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 135, 135, 1080, 540, 1080, 1080, 135, 1080, 135, 540, 135, 135, 540, 540, 1080, 1080, 1080, 135, 1080, 540, 540, 135, 135, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 1080, 135, 540, 540, 1080, 540, 1080, 135, 135, 135, 540, 540, 540, 1080, 1080, 540, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 135, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 540, 540, 1080, 540, 135, 135]
Prompts retrieved: 94095 . Total input tokens: 20974801 . Total output tokens: 18811600
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.6967479470185935,
    "estimated_duration": 3599.7340622593993,
    "input_throughput": 2145.489601849222,
    "output_throughput": 1940.053870428596,
    "total_throughput": 4085.5434722778177,
    "itl": 36.14954500032794,
    "ttft": 9535.80791740456,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7282,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.755642137230055,
    "arrivals": 31534,
    "finished_requests": 31451,
    "scheduler_time": 10.280196774505761
}
#Debug simulation 
Total elapsed time: 2.696835999377072. Arrivals time: 0.08773922501131892 Scheduler time: 2.203660454135388 Scheduler overhead time: 0.10008158208802342 Adapter cache time: 0.16242599580436945 Engine time: 0.09626333648338914 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-32/adapters_160_slots_96_rate_0.1-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-32/adapters_160_slots_96_rate_0.1-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 540, 135, 135, 135, 1080, 135, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 135, 1080, 540, 1080, 1080, 1080, 540, 1080, 135, 540, 540, 540, 1080, 135, 135, 1080, 135, 1080, 135, 135, 540, 135, 540, 1080, 135, 135, 540, 135, 135, 135, 135, 135, 1080, 540, 540, 1080, 540, 135, 1080, 1080, 1080, 540, 540, 135, 135, 135, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 135, 135, 1080, 540, 1080, 1080, 135, 1080, 135, 540, 135, 135, 540, 540, 1080, 1080, 1080, 135, 1080, 540, 540, 135, 135, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 1080, 135, 540, 540, 1080, 540, 1080, 135, 135, 135, 540, 540, 540, 1080, 1080, 540, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 135, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 540, 540, 1080, 540, 135, 135]
Prompts retrieved: 94095 . Total input tokens: 20974801 . Total output tokens: 18811600
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.663660279940814,
    "estimated_duration": 3599.768773639983,
    "input_throughput": 2145.4689136020615,
    "output_throughput": 1940.0351631302988,
    "total_throughput": 4085.5040767323603,
    "itl": 36.149876404304734,
    "ttft": 9535.8603475241,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7284,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.805653385389657,
    "arrivals": 31534,
    "finished_requests": 31451,
    "scheduler_time": 10.280877069932384
}
#Debug simulation 
Total elapsed time: 2.6637452649883926. Arrivals time: 0.0858159582130611 Scheduler time: 2.178411750588566 Scheduler overhead time: 0.09763362864032388 Adapter cache time: 0.1603667181916535 Engine time: 0.09521142952144146 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_160_slots_96_rate_0.1-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_160_slots_96_rate_0.1-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 540, 135, 135, 135, 1080, 135, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 135, 1080, 540, 1080, 1080, 1080, 540, 1080, 135, 540, 540, 540, 1080, 135, 135, 1080, 135, 1080, 135, 135, 540, 135, 540, 1080, 135, 135, 540, 135, 135, 135, 135, 135, 1080, 540, 540, 1080, 540, 135, 1080, 1080, 1080, 540, 540, 135, 135, 135, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 135, 135, 1080, 540, 1080, 1080, 135, 1080, 135, 540, 135, 135, 540, 540, 1080, 1080, 1080, 135, 1080, 540, 540, 135, 135, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 1080, 135, 540, 540, 1080, 540, 1080, 135, 135, 135, 540, 540, 540, 1080, 1080, 540, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 135, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 540, 540, 1080, 540, 135, 135]
Prompts retrieved: 94095 . Total input tokens: 20974801 . Total output tokens: 18811600
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 2.726347069721669,
    "estimated_duration": 3599.75656812624,
    "input_throughput": 2145.476188135718,
    "output_throughput": 1940.0417411100586,
    "total_throughput": 4085.517929245777,
    "itl": 36.12862599348042,
    "ttft": 9535.842219463513,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7283,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.779229209224248,
    "arrivals": 31534,
    "finished_requests": 31451,
    "scheduler_time": 10.270028478013739
}
#Debug simulation 
Total elapsed time: 2.7264582877978683. Arrivals time: 0.08717157365754247 Scheduler time: 2.232680466491729 Scheduler overhead time: 0.09783102106302977 Adapter cache time: 0.16559307044371963 Engine time: 0.09660639706999063 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-32/adapters_160_slots_96_rate_0.1-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-32/adapters_160_slots_96_rate_0.1-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 540, 135, 135, 135, 1080, 135, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 135, 1080, 540, 1080, 1080, 1080, 540, 1080, 135, 540, 540, 540, 1080, 135, 135, 1080, 135, 1080, 135, 135, 540, 135, 540, 1080, 135, 135, 540, 135, 135, 135, 135, 135, 1080, 540, 540, 1080, 540, 135, 1080, 1080, 1080, 540, 540, 135, 135, 135, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 135, 135, 1080, 540, 1080, 1080, 135, 1080, 135, 540, 135, 135, 540, 540, 1080, 1080, 1080, 135, 1080, 540, 540, 135, 135, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 1080, 135, 540, 540, 1080, 540, 1080, 135, 135, 135, 540, 540, 540, 1080, 1080, 540, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 135, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 540, 540, 1080, 540, 135, 135]
Prompts retrieved: 94095 . Total input tokens: 20974801 . Total output tokens: 18811600
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 2.741989690810442,
    "estimated_duration": 3599.7337047317546,
    "input_throughput": 2145.4898149404967,
    "output_throughput": 1940.0540631158744,
    "total_throughput": 4085.543878056371,
    "itl": 36.15512447886675,
    "ttft": 9535.904766388547,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7287,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.117856279387166,
    "arrivals": 31534,
    "finished_requests": 31451,
    "scheduler_time": 10.283687836155051
}
#Debug simulation 
Total elapsed time: 2.7420779676176608. Arrivals time: 0.08724719565361738 Scheduler time: 2.249433333519846 Scheduler overhead time: 0.09757882496342063 Adapter cache time: 0.1649180594831705 Engine time: 0.09646186232566833 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_160_slots_96_rate_0.1-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_160_slots_96_rate_0.1-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 540, 135, 135, 135, 1080, 135, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 135, 1080, 540, 1080, 1080, 1080, 540, 1080, 135, 540, 540, 540, 1080, 135, 135, 1080, 135, 1080, 135, 135, 540, 135, 540, 1080, 135, 135, 540, 135, 135, 135, 135, 135, 1080, 540, 540, 1080, 540, 135, 1080, 1080, 1080, 540, 540, 135, 135, 135, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 135, 135, 1080, 540, 1080, 1080, 135, 1080, 135, 540, 135, 135, 540, 540, 1080, 1080, 1080, 135, 1080, 540, 540, 135, 135, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 1080, 135, 540, 540, 1080, 540, 1080, 135, 135, 135, 540, 540, 540, 1080, 1080, 540, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 135, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 540, 540, 1080, 540, 135, 135]
Prompts retrieved: 94095 . Total input tokens: 20974801 . Total output tokens: 18811600
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.728279196191579,
    "estimated_duration": 3599.7480350243886,
    "input_throughput": 2145.4812739269055,
    "output_throughput": 1940.0463399246455,
    "total_throughput": 4085.527613851551,
    "itl": 36.10738124951771,
    "ttft": 9535.663255005944,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7277,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.75859599600306,
    "arrivals": 31534,
    "finished_requests": 31451,
    "scheduler_time": 10.259674895526269
}
#Debug simulation 
Total elapsed time: 2.728367348201573. Arrivals time: 0.08745559398084879 Scheduler time: 2.234482705593109 Scheduler overhead time: 0.0969700557179749 Adapter cache time: 0.16584119061008096 Engine time: 0.09728533960878849 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-32/adapters_160_slots_96_rate_0.1-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-32/adapters_160_slots_96_rate_0.1-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 540, 135, 135, 135, 1080, 135, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 135, 1080, 540, 1080, 1080, 1080, 540, 1080, 135, 540, 540, 540, 1080, 135, 135, 1080, 135, 1080, 135, 135, 540, 135, 540, 1080, 135, 135, 540, 135, 135, 135, 135, 135, 1080, 540, 540, 1080, 540, 135, 1080, 1080, 1080, 540, 540, 135, 135, 135, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 135, 135, 1080, 540, 1080, 1080, 135, 1080, 135, 540, 135, 135, 540, 540, 1080, 1080, 1080, 135, 1080, 540, 540, 135, 135, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 1080, 135, 540, 540, 1080, 540, 1080, 135, 135, 135, 540, 540, 540, 1080, 1080, 540, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 135, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 540, 540, 1080, 540, 135, 135]
Prompts retrieved: 94095 . Total input tokens: 20974801 . Total output tokens: 18811600
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.7272438602522016,
    "estimated_duration": 3599.7497074500925,
    "input_throughput": 2145.48027714704,
    "output_throughput": 1940.0454385888224,
    "total_throughput": 4085.5257157358624,
    "itl": 36.16284634705691,
    "ttft": 9536.03842408707,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7278,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.396286393923592,
    "arrivals": 31534,
    "finished_requests": 31451,
    "scheduler_time": 10.286739622888048
}
#Debug simulation 
Total elapsed time: 2.727338762022555. Arrivals time: 0.08891509100794792 Scheduler time: 2.2344825929030776 Scheduler overhead time: 0.09724113997071981 Adapter cache time: 0.16522474586963654 Engine time: 0.09497116273269057 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_160_slots_96_rate_0.1-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_160_slots_96_rate_0.1-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 540, 66, 66, 66, 1080, 66, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 66, 1080, 540, 1080, 1080, 1080, 540, 1080, 66, 540, 540, 540, 1080, 66, 66, 1080, 66, 1080, 66, 66, 540, 66, 540, 1080, 66, 66, 540, 66, 66, 66, 66, 66, 1080, 540, 540, 1080, 540, 66, 1080, 1080, 1080, 540, 540, 66, 66, 66, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 66, 66, 1080, 540, 1080, 1080, 66, 1080, 66, 540, 66, 66, 540, 540, 1080, 1080, 1080, 66, 1080, 540, 540, 66, 66, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 1080, 66, 540, 540, 1080, 540, 1080, 66, 66, 66, 540, 540, 540, 1080, 1080, 540, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 66, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 540, 540, 1080, 540, 66, 66]
Prompts retrieved: 90438 . Total input tokens: 20159241 . Total output tokens: 18070510
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.6277235341258347,
    "estimated_duration": 3599.9949379198783,
    "input_throughput": 2077.313754313517,
    "output_throughput": 1832.9817440834584,
    "total_throughput": 3910.2954983969757,
    "itl": 33.46923088581376,
    "ttft": 7764.17394753843,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5069,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.513612373993451,
    "arrivals": 30357,
    "finished_requests": 30292,
    "scheduler_time": 7.386039450917695
}
#Debug simulation 
Total elapsed time: 2.6278526401147246. Arrivals time: 0.08447503950446844 Scheduler time: 2.133459401782602 Scheduler overhead time: 0.10312084201723337 Adapter cache time: 0.15712899528443813 Engine time: 0.10022567538544536 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_160_slots_96_rate_0.1-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_160_slots_96_rate_0.1-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 540, 66, 66, 66, 1080, 66, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 66, 1080, 540, 1080, 1080, 1080, 540, 1080, 66, 540, 540, 540, 1080, 66, 66, 1080, 66, 1080, 66, 66, 540, 66, 540, 1080, 66, 66, 540, 66, 66, 66, 66, 66, 1080, 540, 540, 1080, 540, 66, 1080, 1080, 1080, 540, 540, 66, 66, 66, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 66, 66, 1080, 540, 1080, 1080, 66, 1080, 66, 540, 66, 66, 540, 540, 1080, 1080, 1080, 66, 1080, 540, 540, 66, 66, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 1080, 66, 540, 540, 1080, 540, 1080, 66, 66, 66, 540, 540, 540, 1080, 1080, 540, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 66, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 540, 540, 1080, 540, 66, 66]
Prompts retrieved: 90438 . Total input tokens: 20159241 . Total output tokens: 18070510
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.6247706855647266,
    "estimated_duration": 3599.983201980224,
    "input_throughput": 2077.1671923043264,
    "output_throughput": 1832.8321633197015,
    "total_throughput": 3909.999355624028,
    "itl": 33.48714635914258,
    "ttft": 7882.762302944019,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5068,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.564454529139628,
    "arrivals": 30357,
    "finished_requests": 30291,
    "scheduler_time": 7.396232700679644
}
#Debug simulation 
Total elapsed time: 2.6248585376888514. Arrivals time: 0.08375699492171407 Scheduler time: 2.131132125854492 Scheduler overhead time: 0.10300868796184659 Adapter cache time: 0.15688157733529806 Engine time: 0.10081472434103489 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-32/adapters_160_slots_96_rate_0.1-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-32/adapters_160_slots_96_rate_0.1-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 540, 66, 66, 66, 1080, 66, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 66, 1080, 540, 1080, 1080, 1080, 540, 1080, 66, 540, 540, 540, 1080, 66, 66, 1080, 66, 1080, 66, 66, 540, 66, 540, 1080, 66, 66, 540, 66, 66, 66, 66, 66, 1080, 540, 540, 1080, 540, 66, 1080, 1080, 1080, 540, 540, 66, 66, 66, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 66, 66, 1080, 540, 1080, 1080, 66, 1080, 66, 540, 66, 66, 540, 540, 1080, 1080, 1080, 66, 1080, 540, 540, 66, 66, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 1080, 66, 540, 540, 1080, 540, 1080, 66, 66, 66, 540, 540, 540, 1080, 1080, 540, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 66, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 540, 540, 1080, 540, 66, 66]
Prompts retrieved: 90438 . Total input tokens: 20159241 . Total output tokens: 18070510
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.6240177238360047,
    "estimated_duration": 3599.9713532779847,
    "input_throughput": 2077.1740289519403,
    "output_throughput": 1832.838195779526,
    "total_throughput": 3910.012224731466,
    "itl": 33.48800274590753,
    "ttft": 7882.682002781357,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5063,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.572839787452097,
    "arrivals": 30357,
    "finished_requests": 30291,
    "scheduler_time": 7.396468341908035
}
#Debug simulation 
Total elapsed time: 2.624105079099536. Arrivals time: 0.08461586432531476 Scheduler time: 2.127060830593109 Scheduler overhead time: 0.10335785895586014 Adapter cache time: 0.15738900424912572 Engine time: 0.10246663866564631 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_160_slots_96_rate_0.1-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_160_slots_96_rate_0.1-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 540, 66, 66, 66, 1080, 66, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 66, 1080, 540, 1080, 1080, 1080, 540, 1080, 66, 540, 540, 540, 1080, 66, 66, 1080, 66, 1080, 66, 66, 540, 66, 540, 1080, 66, 66, 540, 66, 66, 66, 66, 66, 1080, 540, 540, 1080, 540, 66, 1080, 1080, 1080, 540, 540, 66, 66, 66, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 66, 66, 1080, 540, 1080, 1080, 66, 1080, 66, 540, 66, 66, 540, 540, 1080, 1080, 1080, 66, 1080, 540, 540, 66, 66, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 1080, 66, 540, 540, 1080, 540, 1080, 66, 66, 66, 540, 540, 540, 1080, 1080, 540, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 66, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 540, 540, 1080, 540, 66, 66]
Prompts retrieved: 90438 . Total input tokens: 20159241 . Total output tokens: 18070510
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 2.6308837989345193,
    "estimated_duration": 3599.971628466026,
    "input_throughput": 2077.1738701691743,
    "output_throughput": 1832.8380556742127,
    "total_throughput": 3910.011925843387,
    "itl": 33.47318349757954,
    "ttft": 7882.727156724249,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5067,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.852960196669702,
    "arrivals": 30357,
    "finished_requests": 30291,
    "scheduler_time": 7.389292518944825
}
#Debug simulation 
Total elapsed time: 2.6309714298695326. Arrivals time: 0.08402753062546253 Scheduler time: 2.135238436050713 Scheduler overhead time: 0.10408701747655869 Adapter cache time: 0.15637400653213263 Engine time: 0.10164078650996089 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-32/adapters_160_slots_96_rate_0.1-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-32/adapters_160_slots_96_rate_0.1-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 540, 66, 66, 66, 1080, 66, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 66, 1080, 540, 1080, 1080, 1080, 540, 1080, 66, 540, 540, 540, 1080, 66, 66, 1080, 66, 1080, 66, 66, 540, 66, 540, 1080, 66, 66, 540, 66, 66, 66, 66, 66, 1080, 540, 540, 1080, 540, 66, 1080, 1080, 1080, 540, 540, 66, 66, 66, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 66, 66, 1080, 540, 1080, 1080, 66, 1080, 66, 540, 66, 66, 540, 540, 1080, 1080, 1080, 66, 1080, 540, 540, 66, 66, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 1080, 66, 540, 540, 1080, 540, 1080, 66, 66, 66, 540, 540, 540, 1080, 1080, 540, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 66, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 540, 540, 1080, 540, 66, 66]
Prompts retrieved: 90438 . Total input tokens: 20159241 . Total output tokens: 18070510
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 2.6353276749141514,
    "estimated_duration": 3599.9800223777643,
    "input_throughput": 2077.16902691615,
    "output_throughput": 1832.8337821280334,
    "total_throughput": 3910.0028090441833,
    "itl": 33.49246231494754,
    "ttft": 7882.719212632004,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5066,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.800576150844503,
    "arrivals": 30357,
    "finished_requests": 30291,
    "scheduler_time": 7.39842853095802
}
#Debug simulation 
Total elapsed time: 2.63540713628754. Arrivals time: 0.08464322704821825 Scheduler time: 2.137792390305549 Scheduler overhead time: 0.10463715484365821 Adapter cache time: 0.15682663582265377 Engine time: 0.10201273253187537 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_160_slots_96_rate_0.1-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_160_slots_96_rate_0.1-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 540, 66, 66, 66, 1080, 66, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 66, 1080, 540, 1080, 1080, 1080, 540, 1080, 66, 540, 540, 540, 1080, 66, 66, 1080, 66, 1080, 66, 66, 540, 66, 540, 1080, 66, 66, 540, 66, 66, 66, 66, 66, 1080, 540, 540, 1080, 540, 66, 1080, 1080, 1080, 540, 540, 66, 66, 66, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 66, 66, 1080, 540, 1080, 1080, 66, 1080, 66, 540, 66, 66, 540, 540, 1080, 1080, 1080, 66, 1080, 540, 540, 66, 66, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 1080, 66, 540, 540, 1080, 540, 1080, 66, 66, 66, 540, 540, 540, 1080, 1080, 540, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 66, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 540, 540, 1080, 540, 66, 66]
Prompts retrieved: 90438 . Total input tokens: 20159241 . Total output tokens: 18070510
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.5862390850670636,
    "estimated_duration": 3599.9638612055155,
    "input_throughput": 2077.178351867102,
    "output_throughput": 1832.842010194647,
    "total_throughput": 3910.0203620617485,
    "itl": 33.46307245232602,
    "ttft": 7882.552902295144,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5069,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.156564944860751,
    "arrivals": 30357,
    "finished_requests": 30291,
    "scheduler_time": 7.382514296521745
}
#Debug simulation 
Total elapsed time: 2.586371389683336. Arrivals time: 0.08505819644778967 Scheduler time: 2.090798947494477 Scheduler overhead time: 0.10423203138634562 Adapter cache time: 0.15443743718788028 Engine time: 0.10244769090786576 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-32/adapters_160_slots_96_rate_0.1-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-32/adapters_160_slots_96_rate_0.1-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 540, 66, 66, 66, 1080, 66, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 66, 1080, 540, 1080, 1080, 1080, 540, 1080, 66, 540, 540, 540, 1080, 66, 66, 1080, 66, 1080, 66, 66, 540, 66, 540, 1080, 66, 66, 540, 66, 66, 66, 66, 66, 1080, 540, 540, 1080, 540, 66, 1080, 1080, 1080, 540, 540, 66, 66, 66, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 66, 66, 1080, 540, 1080, 1080, 66, 1080, 66, 540, 66, 66, 540, 540, 1080, 1080, 1080, 66, 1080, 540, 540, 66, 66, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 1080, 66, 540, 540, 1080, 540, 1080, 66, 66, 66, 540, 540, 540, 1080, 1080, 540, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 66, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 540, 540, 1080, 540, 66, 66]
Prompts retrieved: 90438 . Total input tokens: 20159241 . Total output tokens: 18070510
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.6142262988723814,
    "estimated_duration": 3599.9942670918244,
    "input_throughput": 2077.160807825605,
    "output_throughput": 1832.8265298406104,
    "total_throughput": 3909.987337666215,
    "itl": 33.496658230063,
    "ttft": 7882.736157295153,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5066,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.016746909691665,
    "arrivals": 30357,
    "finished_requests": 30291,
    "scheduler_time": 7.400603678576202
}
#Debug simulation 
Total elapsed time: 2.6143046086654067. Arrivals time: 0.08600433683022857 Scheduler time: 2.1174036636948586 Scheduler overhead time: 0.10356407845392823 Adapter cache time: 0.15632907394319773 Engine time: 0.10178164392709732 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_160_slots_96_rate_0.1-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_160_slots_96_rate_0.1-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 540, 33, 33, 33, 1080, 33, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 33, 1080, 540, 1080, 1080, 1080, 540, 1080, 33, 540, 540, 540, 1080, 33, 33, 1080, 33, 1080, 33, 33, 540, 33, 540, 1080, 33, 33, 540, 33, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 33, 1080, 1080, 1080, 540, 540, 33, 33, 33, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 33, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 540, 33, 33, 540, 540, 1080, 1080, 1080, 33, 1080, 540, 540, 33, 33, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 1080, 540, 1080, 33, 33, 33, 540, 540, 540, 1080, 1080, 540, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 540, 540, 1080, 540, 33, 33]
Prompts retrieved: 88689 . Total input tokens: 19774958 . Total output tokens: 17728710
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.5603438830003142,
    "estimated_duration": 3600.030392033575,
    "input_throughput": 2033.2939455728163,
    "output_throughput": 1803.9706037957892,
    "total_throughput": 3837.2645493686055,
    "itl": 32.66076072692555,
    "ttft": 5997.592988129854,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3916,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.984870005239888,
    "arrivals": 29680,
    "finished_requests": 29631,
    "scheduler_time": 6.485378084265268
}
#Debug simulation 
Total elapsed time: 2.560439335182309. Arrivals time: 0.08625701861456037 Scheduler time: 2.066922288388014 Scheduler overhead time: 0.10524210846051574 Adapter cache time: 0.1471382169984281 Engine time: 0.10490204859524965 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_160_slots_96_rate_0.1-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_160_slots_96_rate_0.1-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 540, 33, 33, 33, 1080, 33, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 33, 1080, 540, 1080, 1080, 1080, 540, 1080, 33, 540, 540, 540, 1080, 33, 33, 1080, 33, 1080, 33, 33, 540, 33, 540, 1080, 33, 33, 540, 33, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 33, 1080, 1080, 1080, 540, 540, 33, 33, 33, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 33, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 540, 33, 33, 540, 540, 1080, 1080, 1080, 33, 1080, 540, 540, 33, 33, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 1080, 540, 1080, 33, 33, 33, 540, 540, 540, 1080, 1080, 540, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 540, 540, 1080, 540, 33, 33]
Prompts retrieved: 88689 . Total input tokens: 19774958 . Total output tokens: 17728710
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.5357073596678674,
    "estimated_duration": 3600.007543777735,
    "input_throughput": 2033.3068503291818,
    "output_throughput": 1803.9820531000983,
    "total_throughput": 3837.28890342928,
    "itl": 32.67439475906084,
    "ttft": 5997.762580102866,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3916,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.787728595519948,
    "arrivals": 29680,
    "finished_requests": 29631,
    "scheduler_time": 6.493085570175844
}
#Debug simulation 
Total elapsed time: 2.5357959158718586. Arrivals time: 0.08387430664151907 Scheduler time: 2.0433102431707084 Scheduler overhead time: 0.10686577437445521 Adapter cache time: 0.14812693232670426 Engine time: 0.10344804544001818 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-32/adapters_160_slots_96_rate_0.1-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-32/adapters_160_slots_96_rate_0.1-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 540, 33, 33, 33, 1080, 33, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 33, 1080, 540, 1080, 1080, 1080, 540, 1080, 33, 540, 540, 540, 1080, 33, 33, 1080, 33, 1080, 33, 33, 540, 33, 540, 1080, 33, 33, 540, 33, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 33, 1080, 1080, 1080, 540, 540, 33, 33, 33, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 33, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 540, 33, 33, 540, 540, 1080, 1080, 1080, 33, 1080, 540, 540, 33, 33, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 1080, 540, 1080, 33, 33, 33, 540, 540, 540, 1080, 1080, 540, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 540, 540, 1080, 540, 33, 33]
Prompts retrieved: 88689 . Total input tokens: 19774958 . Total output tokens: 17728710
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.53150331415236,
    "estimated_duration": 3600.0115174048137,
    "input_throughput": 2033.3046060021509,
    "output_throughput": 1803.9800618975976,
    "total_throughput": 3837.2846678997485,
    "itl": 32.6741752798774,
    "ttft": 5997.758061345238,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3913,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.798610898311319,
    "arrivals": 29680,
    "finished_requests": 29631,
    "scheduler_time": 6.493089281485909
}
#Debug simulation 
Total elapsed time: 2.531589322257787. Arrivals time: 0.08247686270624399 Scheduler time: 2.0435035373084247 Scheduler overhead time: 0.10506193293258548 Adapter cache time: 0.1483917124569416 Engine time: 0.10208137473091483 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_160_slots_96_rate_0.1-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_160_slots_96_rate_0.1-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 540, 33, 33, 33, 1080, 33, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 33, 1080, 540, 1080, 1080, 1080, 540, 1080, 33, 540, 540, 540, 1080, 33, 33, 1080, 33, 1080, 33, 33, 540, 33, 540, 1080, 33, 33, 540, 33, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 33, 1080, 1080, 1080, 540, 540, 33, 33, 33, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 33, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 540, 33, 33, 540, 540, 1080, 1080, 1080, 33, 1080, 540, 540, 33, 33, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 1080, 540, 1080, 33, 33, 33, 540, 540, 540, 1080, 1080, 540, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 540, 540, 1080, 540, 33, 33]
Prompts retrieved: 88689 . Total input tokens: 19774958 . Total output tokens: 17728710
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 2.6167074255645275,
    "estimated_duration": 3600.014097840106,
    "input_throughput": 2033.303148560368,
    "output_throughput": 1803.9787688321562,
    "total_throughput": 3837.281917392524,
    "itl": 32.665175098606504,
    "ttft": 5997.673939365492,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3913,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.235735266428136,
    "arrivals": 29680,
    "finished_requests": 29631,
    "scheduler_time": 6.48789729081095
}
#Debug simulation 
Total elapsed time: 2.6168169658631086. Arrivals time: 0.08283816697075963 Scheduler time: 2.1199289415962994 Scheduler overhead time: 0.10643311403691769 Adapter cache time: 0.15055397246032953 Engine time: 0.10664515662938356 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-32/adapters_160_slots_96_rate_0.1-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-32/adapters_160_slots_96_rate_0.1-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 540, 33, 33, 33, 1080, 33, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 33, 1080, 540, 1080, 1080, 1080, 540, 1080, 33, 540, 540, 540, 1080, 33, 33, 1080, 33, 1080, 33, 33, 540, 33, 540, 1080, 33, 33, 540, 33, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 33, 1080, 1080, 1080, 540, 540, 33, 33, 33, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 33, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 540, 33, 33, 540, 540, 1080, 1080, 1080, 33, 1080, 540, 540, 33, 33, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 1080, 540, 1080, 33, 33, 33, 540, 540, 540, 1080, 1080, 540, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 540, 540, 1080, 540, 33, 33]
Prompts retrieved: 88689 . Total input tokens: 19774958 . Total output tokens: 17728710
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 2.5349595500156283,
    "estimated_duration": 3600.0246527991058,
    "input_throughput": 2033.297187092479,
    "output_throughput": 1803.9734797233923,
    "total_throughput": 3837.270666815871,
    "itl": 32.67836206296247,
    "ttft": 5997.82579865711,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3912,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.961728145181281,
    "arrivals": 29680,
    "finished_requests": 29631,
    "scheduler_time": 6.494821626811542
}
#Debug simulation 
Total elapsed time: 2.53509700903669. Arrivals time: 0.08213462587445974 Scheduler time: 2.0454922528006136 Scheduler overhead time: 0.10579990642145276 Adapter cache time: 0.14875301625579596 Engine time: 0.10280686104670167 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_160_slots_96_rate_0.1-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_160_slots_96_rate_0.1-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 540, 33, 33, 33, 1080, 33, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 33, 1080, 540, 1080, 1080, 1080, 540, 1080, 33, 540, 540, 540, 1080, 33, 33, 1080, 33, 1080, 33, 33, 540, 33, 540, 1080, 33, 33, 540, 33, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 33, 1080, 1080, 1080, 540, 540, 33, 33, 33, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 33, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 540, 33, 33, 540, 540, 1080, 1080, 1080, 33, 1080, 540, 540, 33, 33, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 1080, 540, 1080, 33, 33, 33, 540, 540, 540, 1080, 1080, 540, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 540, 540, 1080, 540, 33, 33]
Prompts retrieved: 88689 . Total input tokens: 19774958 . Total output tokens: 17728710
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.5242503760382533,
    "estimated_duration": 3600.0278134699556,
    "input_throughput": 2033.2954019442852,
    "output_throughput": 1803.9718959116312,
    "total_throughput": 3837.2672978559167,
    "itl": 32.65613607940887,
    "ttft": 5997.78611677929,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3916,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.709036954837641,
    "arrivals": 29680,
    "finished_requests": 29631,
    "scheduler_time": 6.482888150483903
}
#Debug simulation 
Total elapsed time: 2.524341491982341. Arrivals time: 0.08202171931043267 Scheduler time: 2.038229200989008 Scheduler overhead time: 0.10530605353415012 Adapter cache time: 0.14749433379620314 Engine time: 0.10137481847777963 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-32/adapters_160_slots_96_rate_0.1-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-32/adapters_160_slots_96_rate_0.1-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 540, 33, 33, 33, 1080, 33, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 33, 1080, 540, 1080, 1080, 1080, 540, 1080, 33, 540, 540, 540, 1080, 33, 33, 1080, 33, 1080, 33, 33, 540, 33, 540, 1080, 33, 33, 540, 33, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 33, 1080, 1080, 1080, 540, 540, 33, 33, 33, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 33, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 540, 33, 33, 540, 540, 1080, 1080, 1080, 33, 1080, 540, 540, 33, 33, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 1080, 540, 1080, 33, 33, 33, 540, 540, 540, 1080, 1080, 540, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 540, 540, 1080, 540, 33, 33]
Prompts retrieved: 88689 . Total input tokens: 19774958 . Total output tokens: 17728710
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.5374617390334606,
    "estimated_duration": 3600.016873135971,
    "input_throughput": 2033.3015810627646,
    "output_throughput": 1803.9773781234474,
    "total_throughput": 3837.278959186212,
    "itl": 32.680746200552946,
    "ttft": 5997.716615687615,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3916,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.140280192195531,
    "arrivals": 29680,
    "finished_requests": 29631,
    "scheduler_time": 6.496371872521369
}
#Debug simulation 
Total elapsed time: 2.5375553788617253. Arrivals time: 0.08395838970318437 Scheduler time: 2.0461880792863667 Scheduler overhead time: 0.10707311518490314 Adapter cache time: 0.14767082314938307 Engine time: 0.10240754531696439 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_160_slots_96_rate_0.1-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_160_slots_96_rate_0.1-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 270, 135, 135, 135, 1080, 135, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 135, 1080, 270, 1080, 1080, 1080, 270, 1080, 135, 270, 270, 270, 1080, 135, 135, 1080, 135, 1080, 135, 135, 270, 135, 270, 1080, 135, 135, 270, 135, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 135, 1080, 1080, 1080, 270, 270, 135, 135, 135, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 135, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 270, 135, 135, 270, 270, 1080, 1080, 1080, 135, 1080, 270, 270, 135, 135, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 1080, 270, 1080, 135, 135, 135, 270, 270, 270, 1080, 1080, 270, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 270, 270, 1080, 270, 135, 135]
Prompts retrieved: 79785 . Total input tokens: 17763858 . Total output tokens: 15946259
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.347528667189181,
    "estimated_duration": 3599.961254263808,
    "input_throughput": 1820.0243106060561,
    "output_throughput": 1617.060181718669,
    "total_throughput": 3437.084492324725,
    "itl": 29.849351388720574,
    "ttft": 8133.022553595474,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4859,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.870909947767737,
    "arrivals": 26722,
    "finished_requests": 26662,
    "scheduler_time": 2.628561468668742
}
#Debug simulation 
Total elapsed time: 2.3476121220737696. Arrivals time: 0.0760473539121449 Scheduler time: 1.8517542066983879 Scheduler overhead time: 0.11304636811837554 Adapter cache time: 0.1431130152195692 Engine time: 0.1098899389617145 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_160_slots_96_rate_0.1-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_160_slots_96_rate_0.1-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 270, 135, 135, 135, 1080, 135, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 135, 1080, 270, 1080, 1080, 1080, 270, 1080, 135, 270, 270, 270, 1080, 135, 135, 1080, 135, 1080, 135, 135, 270, 135, 270, 1080, 135, 135, 270, 135, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 135, 1080, 1080, 1080, 270, 270, 135, 135, 135, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 135, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 270, 135, 135, 270, 270, 1080, 1080, 1080, 135, 1080, 270, 270, 135, 135, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 1080, 270, 1080, 135, 135, 135, 270, 270, 270, 1080, 1080, 270, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 270, 270, 1080, 270, 135, 135]
Prompts retrieved: 79785 . Total input tokens: 17763858 . Total output tokens: 15946259
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.336181676015258,
    "estimated_duration": 3599.975623715785,
    "input_throughput": 1820.0170459035521,
    "output_throughput": 1617.0537271559012,
    "total_throughput": 3437.070773059453,
    "itl": 29.861390455219986,
    "ttft": 8132.944614365833,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4860,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.846912763285117,
    "arrivals": 26722,
    "finished_requests": 26662,
    "scheduler_time": 2.6351062357492085
}
#Debug simulation 
Total elapsed time: 2.3362671798095107. Arrivals time: 0.07666991511359811 Scheduler time: 1.842561456374824 Scheduler overhead time: 0.11218341905623674 Adapter cache time: 0.14241016656160355 Engine time: 0.10873771784827113 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-32/adapters_160_slots_96_rate_0.1-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-32/adapters_160_slots_96_rate_0.1-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 270, 135, 135, 135, 1080, 135, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 135, 1080, 270, 1080, 1080, 1080, 270, 1080, 135, 270, 270, 270, 1080, 135, 135, 1080, 135, 1080, 135, 135, 270, 135, 270, 1080, 135, 135, 270, 135, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 135, 1080, 1080, 1080, 270, 270, 135, 135, 135, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 135, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 270, 135, 135, 270, 270, 1080, 1080, 1080, 135, 1080, 270, 270, 135, 135, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 1080, 270, 1080, 135, 135, 135, 270, 270, 270, 1080, 1080, 270, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 270, 270, 1080, 270, 135, 135]
Prompts retrieved: 79785 . Total input tokens: 17763858 . Total output tokens: 15946259
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.31816213298589,
    "estimated_duration": 3599.972918539434,
    "input_throughput": 1820.0184135435823,
    "output_throughput": 1617.054942280459,
    "total_throughput": 3437.0733558240413,
    "itl": 29.86102348768553,
    "ttft": 8133.065278811465,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4860,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.877438537402526,
    "arrivals": 26722,
    "finished_requests": 26662,
    "scheduler_time": 2.6353790309819916
}
#Debug simulation 
Total elapsed time: 2.3182536670938134. Arrivals time: 0.07647747360169888 Scheduler time: 1.8242231258191168 Scheduler overhead time: 0.1129641504958272 Adapter cache time: 0.14179420471191406 Engine time: 0.10883785830810666 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_160_slots_96_rate_0.1-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_160_slots_96_rate_0.1-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 270, 135, 135, 135, 1080, 135, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 135, 1080, 270, 1080, 1080, 1080, 270, 1080, 135, 270, 270, 270, 1080, 135, 135, 1080, 135, 1080, 135, 135, 270, 135, 270, 1080, 135, 135, 270, 135, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 135, 1080, 1080, 1080, 270, 270, 135, 135, 135, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 135, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 270, 135, 135, 270, 270, 1080, 1080, 1080, 135, 1080, 270, 270, 135, 135, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 1080, 270, 1080, 135, 135, 135, 270, 270, 270, 1080, 1080, 270, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 270, 270, 1080, 270, 135, 135]
Prompts retrieved: 79785 . Total input tokens: 17763858 . Total output tokens: 15946259
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 2.314662795048207,
    "estimated_duration": 3599.956722235855,
    "input_throughput": 1820.0013237744538,
    "output_throughput": 1617.0019389523711,
    "total_throughput": 3437.0032627268247,
    "itl": 29.85296683447181,
    "ttft": 8267.709532328363,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4861,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.203096424489155,
    "arrivals": 26722,
    "finished_requests": 26661,
    "scheduler_time": 2.6307938028991926
}
#Debug simulation 
Total elapsed time: 2.3147490699775517. Arrivals time: 0.07614903477951884 Scheduler time: 1.8236011597327888 Scheduler overhead time: 0.11123810708522797 Adapter cache time: 0.14049376314505935 Engine time: 0.10977055830881 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-32/adapters_160_slots_96_rate_0.1-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-32/adapters_160_slots_96_rate_0.1-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 270, 135, 135, 135, 1080, 135, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 135, 1080, 270, 1080, 1080, 1080, 270, 1080, 135, 270, 270, 270, 1080, 135, 135, 1080, 135, 1080, 135, 135, 270, 135, 270, 1080, 135, 135, 270, 135, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 135, 1080, 1080, 1080, 270, 270, 135, 135, 135, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 135, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 270, 135, 135, 270, 270, 1080, 1080, 1080, 135, 1080, 270, 270, 135, 135, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 1080, 270, 1080, 135, 135, 135, 270, 270, 270, 1080, 1080, 270, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 270, 270, 1080, 270, 135, 135]
Prompts retrieved: 79785 . Total input tokens: 17763858 . Total output tokens: 15946259
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 2.3063756530173123,
    "estimated_duration": 3599.972352526599,
    "input_throughput": 1819.9934217276991,
    "output_throughput": 1616.9949182844425,
    "total_throughput": 3436.9883400121416,
    "itl": 30.02861136616642,
    "ttft": 8268.119396355174,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4859,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.075612501202748,
    "arrivals": 26722,
    "finished_requests": 26661,
    "scheduler_time": 2.710961777975244
}
#Debug simulation 
Total elapsed time: 2.3064602171070874. Arrivals time: 0.07428453909233212 Scheduler time: 1.823764315340668 Scheduler overhead time: 0.11065281415358186 Adapter cache time: 0.13942796224728227 Engine time: 0.10578897409141064 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_160_slots_96_rate_0.1-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_160_slots_96_rate_0.1-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 270, 135, 135, 135, 1080, 135, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 135, 1080, 270, 1080, 1080, 1080, 270, 1080, 135, 270, 270, 270, 1080, 135, 135, 1080, 135, 1080, 135, 135, 270, 135, 270, 1080, 135, 135, 270, 135, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 135, 1080, 1080, 1080, 270, 270, 135, 135, 135, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 135, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 270, 135, 135, 270, 270, 1080, 1080, 1080, 135, 1080, 270, 270, 135, 135, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 1080, 270, 1080, 135, 135, 135, 270, 270, 270, 1080, 1080, 270, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 270, 270, 1080, 270, 135, 135]
Prompts retrieved: 79785 . Total input tokens: 17763858 . Total output tokens: 15946259
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.321798802819103,
    "estimated_duration": 3599.969306443434,
    "input_throughput": 1820.0202396928273,
    "output_throughput": 1617.0565647825392,
    "total_throughput": 3437.0768044753663,
    "itl": 29.843624165111706,
    "ttft": 8132.9927863055855,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4861,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.534634483520936,
    "arrivals": 26722,
    "finished_requests": 26662,
    "scheduler_time": 2.626464089643338
}
#Debug simulation 
Total elapsed time: 2.3218837468884885. Arrivals time: 0.07455936912447214 Scheduler time: 1.8337702928110957 Scheduler overhead time: 0.1117803924717009 Adapter cache time: 0.14109766017645597 Engine time: 0.10735808173194528 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-32/adapters_160_slots_96_rate_0.1-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-32/adapters_160_slots_96_rate_0.1-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 270, 135, 135, 135, 1080, 135, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 135, 1080, 270, 1080, 1080, 1080, 270, 1080, 135, 270, 270, 270, 1080, 135, 135, 1080, 135, 1080, 135, 135, 270, 135, 270, 1080, 135, 135, 270, 135, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 135, 1080, 1080, 1080, 270, 270, 135, 135, 135, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 135, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 270, 135, 135, 270, 270, 1080, 1080, 1080, 135, 1080, 270, 270, 135, 135, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 1080, 270, 1080, 135, 135, 135, 270, 270, 270, 1080, 1080, 270, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 270, 270, 1080, 270, 135, 135]
Prompts retrieved: 79785 . Total input tokens: 17763858 . Total output tokens: 15946259
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.3028807970695198,
    "estimated_duration": 3599.964802027856,
    "input_throughput": 1819.9972389478107,
    "output_throughput": 1616.9983097392953,
    "total_throughput": 3436.9955486871063,
    "itl": 29.869022343113844,
    "ttft": 8267.769434002175,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4862,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.2889157686371,
    "arrivals": 26722,
    "finished_requests": 26661,
    "scheduler_time": 2.638208770506863
}
#Debug simulation 
Total elapsed time: 2.3029700429178774. Arrivals time: 0.07487025810405612 Scheduler time: 1.8141109347343445 Scheduler overhead time: 0.11233768332749605 Adapter cache time: 0.14079269487410784 Engine time: 0.10742430668324232 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_160_slots_96_rate_0.1-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_160_slots_96_rate_0.1-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 270, 66, 66, 66, 1080, 66, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 66, 1080, 270, 1080, 1080, 1080, 270, 1080, 66, 270, 270, 270, 1080, 66, 66, 1080, 66, 1080, 66, 66, 270, 66, 270, 1080, 66, 66, 270, 66, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 66, 1080, 1080, 1080, 270, 270, 66, 66, 66, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 66, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 270, 66, 66, 270, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 1080, 270, 1080, 66, 66, 66, 270, 270, 270, 1080, 1080, 270, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 270, 270, 1080, 270, 66, 66]
Prompts retrieved: 76128 . Total input tokens: 16944546 . Total output tokens: 15219954
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.264600737951696,
    "estimated_duration": 3600.0201663117546,
    "input_throughput": 1741.8702424726816,
    "output_throughput": 1554.388792697505,
    "total_throughput": 3296.259035170187,
    "itl": 28.710445897823163,
    "ttft": 4985.813142237683,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3325,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.176121748576092,
    "arrivals": 25517,
    "finished_requests": 25481,
    "scheduler_time": 1.6117689190517628
}
#Debug simulation 
Total elapsed time: 2.264684755820781. Arrivals time: 0.07267258875072002 Scheduler time: 1.7773557296022773 Scheduler overhead time: 0.11537130502983928 Adapter cache time: 0.13241965370252728 Engine time: 0.11121811671182513 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_160_slots_96_rate_0.1-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_160_slots_96_rate_0.1-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 270, 66, 66, 66, 1080, 66, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 66, 1080, 270, 1080, 1080, 1080, 270, 1080, 66, 270, 270, 270, 1080, 66, 66, 1080, 66, 1080, 66, 66, 270, 66, 270, 1080, 66, 66, 270, 66, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 66, 1080, 1080, 1080, 270, 270, 66, 66, 66, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 66, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 270, 66, 66, 270, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 1080, 270, 1080, 66, 66, 66, 270, 270, 270, 1080, 1080, 270, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 270, 270, 1080, 270, 66, 66]
Prompts retrieved: 76128 . Total input tokens: 16944546 . Total output tokens: 15219954
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.259099662769586,
    "estimated_duration": 3600.001678024841,
    "input_throughput": 1741.8791880787367,
    "output_throughput": 1554.396775467666,
    "total_throughput": 3296.2759635464026,
    "itl": 28.719678929472135,
    "ttft": 4985.888594592039,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3325,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.841235526437103,
    "arrivals": 25517,
    "finished_requests": 25481,
    "scheduler_time": 1.6149372968361102
}
#Debug simulation 
Total elapsed time: 2.2592283841222525. Arrivals time: 0.07255287934094667 Scheduler time: 1.7716693272814155 Scheduler overhead time: 0.11501974891871214 Adapter cache time: 0.13266301481053233 Engine time: 0.11259391624480486 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_160_slots_96_rate_0.1-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_160_slots_96_rate_0.1-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 270, 66, 66, 66, 1080, 66, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 66, 1080, 270, 1080, 1080, 1080, 270, 1080, 66, 270, 270, 270, 1080, 66, 66, 1080, 66, 1080, 66, 66, 270, 66, 270, 1080, 66, 66, 270, 66, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 66, 1080, 1080, 1080, 270, 270, 66, 66, 66, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 66, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 270, 66, 66, 270, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 1080, 270, 1080, 66, 66, 66, 270, 270, 270, 1080, 1080, 270, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 270, 270, 1080, 270, 66, 66]
Prompts retrieved: 76128 . Total input tokens: 16944546 . Total output tokens: 15219954
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.252819176763296,
    "estimated_duration": 3600.009978105671,
    "input_throughput": 1741.8751720515188,
    "output_throughput": 1554.3931916945776,
    "total_throughput": 3296.2683637460964,
    "itl": 28.71967446393279,
    "ttft": 4985.868434364451,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3325,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.861981907616759,
    "arrivals": 25517,
    "finished_requests": 25481,
    "scheduler_time": 1.615062310519379
}
#Debug simulation 
Total elapsed time: 2.252929537091404. Arrivals time: 0.07250026194378734 Scheduler time: 1.765591727104038 Scheduler overhead time: 0.11465712822973728 Adapter cache time: 0.13313774997368455 Engine time: 0.11229664133861661 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_160_slots_96_rate_0.1-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_160_slots_96_rate_0.1-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 270, 66, 66, 66, 1080, 66, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 66, 1080, 270, 1080, 1080, 1080, 270, 1080, 66, 270, 270, 270, 1080, 66, 66, 1080, 66, 1080, 66, 66, 270, 66, 270, 1080, 66, 66, 270, 66, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 66, 1080, 1080, 1080, 270, 270, 66, 66, 66, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 66, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 270, 66, 66, 270, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 1080, 270, 1080, 66, 66, 66, 270, 270, 270, 1080, 1080, 270, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 270, 270, 1080, 270, 66, 66]
Prompts retrieved: 76128 . Total input tokens: 16944546 . Total output tokens: 15219954
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 2.2273670420981944,
    "estimated_duration": 3600.0028142493384,
    "input_throughput": 1741.8786383108875,
    "output_throughput": 1554.396284872579,
    "total_throughput": 3296.2749231834664,
    "itl": 28.71378591848672,
    "ttft": 4985.849378712679,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3326,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.396405107721437,
    "arrivals": 25517,
    "finished_requests": 25481,
    "scheduler_time": 1.6132485266768641
}
#Debug simulation 
Total elapsed time: 2.227457850240171. Arrivals time: 0.07225767429918051 Scheduler time: 1.7442009435035288 Scheduler overhead time: 0.11486268695443869 Adapter cache time: 0.13141080550849438 Engine time: 0.11004414549097419 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_160_slots_96_rate_0.1-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_160_slots_96_rate_0.1-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 270, 66, 66, 66, 1080, 66, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 66, 1080, 270, 1080, 1080, 1080, 270, 1080, 66, 270, 270, 270, 1080, 66, 66, 1080, 66, 1080, 66, 66, 270, 66, 270, 1080, 66, 66, 270, 66, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 66, 1080, 1080, 1080, 270, 270, 66, 66, 66, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 66, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 270, 66, 66, 270, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 1080, 270, 1080, 66, 66, 66, 270, 270, 270, 1080, 1080, 270, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 270, 270, 1080, 270, 66, 66]
Prompts retrieved: 76128 . Total input tokens: 16944546 . Total output tokens: 15219954
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 2.264761261641979,
    "estimated_duration": 3600.012582757145,
    "input_throughput": 1741.8739117843306,
    "output_throughput": 1554.392067072809,
    "total_throughput": 3296.2659788571395,
    "itl": 28.722405695141937,
    "ttft": 4985.93531616855,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3325,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.999933811313808,
    "arrivals": 25517,
    "finished_requests": 25481,
    "scheduler_time": 1.6159237295101674
}
#Debug simulation 
Total elapsed time: 2.2648540339432657. Arrivals time: 0.0742343133315444 Scheduler time: 1.768900397233665 Scheduler overhead time: 0.11472870269790292 Adapter cache time: 0.1337391627021134 Engine time: 0.11536104837432504 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_160_slots_96_rate_0.1-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_160_slots_96_rate_0.1-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 270, 66, 66, 66, 1080, 66, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 66, 1080, 270, 1080, 1080, 1080, 270, 1080, 66, 270, 270, 270, 1080, 66, 66, 1080, 66, 1080, 66, 66, 270, 66, 270, 1080, 66, 66, 270, 66, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 66, 1080, 1080, 1080, 270, 270, 66, 66, 66, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 66, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 270, 66, 66, 270, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 1080, 270, 1080, 66, 66, 66, 270, 270, 270, 1080, 1080, 270, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 270, 270, 1080, 270, 66, 66]
Prompts retrieved: 76128 . Total input tokens: 16944546 . Total output tokens: 15219954
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.2813739366829395,
    "estimated_duration": 3600.002362044053,
    "input_throughput": 1741.8788571126124,
    "output_throughput": 1554.3964801241773,
    "total_throughput": 3296.2753372367897,
    "itl": 28.707479148811174,
    "ttft": 4985.874879465993,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3326,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.944907280844896,
    "arrivals": 25517,
    "finished_requests": 25481,
    "scheduler_time": 1.6108399058082772
}
#Debug simulation 
Total elapsed time: 2.281458724755794. Arrivals time: 0.07288699923083186 Scheduler time: 1.788801949005574 Scheduler overhead time: 0.11681818356737494 Adapter cache time: 0.13340153824537992 Engine time: 0.1141114542260766 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_160_slots_96_rate_0.1-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_160_slots_96_rate_0.1-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 270, 66, 66, 66, 1080, 66, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 66, 1080, 270, 1080, 1080, 1080, 270, 1080, 66, 270, 270, 270, 1080, 66, 66, 1080, 66, 1080, 66, 66, 270, 66, 270, 1080, 66, 66, 270, 66, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 66, 1080, 1080, 1080, 270, 270, 66, 66, 66, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 66, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 270, 66, 66, 270, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 1080, 270, 1080, 66, 66, 66, 270, 270, 270, 1080, 1080, 270, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 270, 270, 1080, 270, 66, 66]
Prompts retrieved: 76128 . Total input tokens: 16944546 . Total output tokens: 15219954
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.2467667581513524,
    "estimated_duration": 3600.015758179138,
    "input_throughput": 1741.8723753508536,
    "output_throughput": 1554.390696009156,
    "total_throughput": 3296.2630713600097,
    "itl": 28.88295493192877,
    "ttft": 4986.2595562150045,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3323,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.131752951256283,
    "arrivals": 25517,
    "finished_requests": 25481,
    "scheduler_time": 1.6718349498589071
}
#Debug simulation 
Total elapsed time: 2.246844454202801. Arrivals time: 0.0725565804168582 Scheduler time: 1.7632941119372845 Scheduler overhead time: 0.11431271117180586 Adapter cache time: 0.13222025148570538 Engine time: 0.10987450182437897 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_160_slots_96_rate_0.1-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_160_slots_96_rate_0.1-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 270, 33, 33, 33, 1080, 33, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 33, 1080, 270, 1080, 1080, 1080, 270, 1080, 33, 270, 270, 270, 1080, 33, 33, 1080, 33, 1080, 33, 33, 270, 33, 270, 1080, 33, 33, 270, 33, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 33, 1080, 1080, 1080, 270, 270, 33, 33, 33, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 33, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 270, 33, 33, 270, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 1080, 270, 1080, 33, 33, 33, 270, 270, 270, 1080, 1080, 270, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 270, 270, 1080, 270, 33, 33]
Prompts retrieved: 74379 . Total input tokens: 16563634 . Total output tokens: 14864978
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.197760430164635,
    "estimated_duration": 3599.9405207751797,
    "input_throughput": 1709.3704644528211,
    "output_throughput": 1527.4255139126494,
    "total_throughput": 3236.7959783654705,
    "itl": 28.339587692239615,
    "ttft": 7839.648959950997,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2416,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.394138389341754,
    "arrivals": 24947,
    "finished_requests": 24893,
    "scheduler_time": 1.3346384542869267
}
#Debug simulation 
Total elapsed time: 2.1978563899174333. Arrivals time: 0.06980796344578266 Scheduler time: 1.7204805188812315 Scheduler overhead time: 0.11586464336141944 Adapter cache time: 0.12596162781119347 Engine time: 0.11054259305819869 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_160_slots_96_rate_0.1-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_160_slots_96_rate_0.1-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 270, 33, 33, 33, 1080, 33, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 33, 1080, 270, 1080, 1080, 1080, 270, 1080, 33, 270, 270, 270, 1080, 33, 33, 1080, 33, 1080, 33, 33, 270, 33, 270, 1080, 33, 33, 270, 33, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 33, 1080, 1080, 1080, 270, 270, 33, 33, 33, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 33, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 270, 33, 33, 270, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 1080, 270, 1080, 33, 33, 33, 270, 270, 270, 1080, 1080, 270, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 270, 270, 1080, 270, 33, 33]
Prompts retrieved: 74379 . Total input tokens: 16563634 . Total output tokens: 14864978
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.2373261312022805,
    "estimated_duration": 3599.9366153782844,
    "input_throughput": 1709.3723188660563,
    "output_throughput": 1527.427170942619,
    "total_throughput": 3236.7994898086754,
    "itl": 28.346084222388942,
    "ttft": 7839.587342636796,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2414,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.875819874582465,
    "arrivals": 24947,
    "finished_requests": 24893,
    "scheduler_time": 1.3365803793807574
}
#Debug simulation 
Total elapsed time: 2.2374095381237566. Arrivals time: 0.07065325696021318 Scheduler time: 1.7562201316468418 Scheduler overhead time: 0.11521360231563449 Adapter cache time: 0.12704836204648018 Engine time: 0.11301636090502143 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_160_slots_96_rate_0.1-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_160_slots_96_rate_0.1-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 270, 33, 33, 33, 1080, 33, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 33, 1080, 270, 1080, 1080, 1080, 270, 1080, 33, 270, 270, 270, 1080, 33, 33, 1080, 33, 1080, 33, 33, 270, 33, 270, 1080, 33, 33, 270, 33, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 33, 1080, 1080, 1080, 270, 270, 33, 33, 33, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 33, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 270, 33, 33, 270, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 1080, 270, 1080, 33, 33, 33, 270, 270, 270, 1080, 1080, 270, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 270, 270, 1080, 270, 33, 33]
Prompts retrieved: 74379 . Total input tokens: 16563634 . Total output tokens: 14864978
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.2146059591323137,
    "estimated_duration": 3599.947619446332,
    "input_throughput": 1709.3670937763318,
    "output_throughput": 1527.4225020100946,
    "total_throughput": 3236.789595786426,
    "itl": 28.34631715167886,
    "ttft": 7839.574779519272,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2413,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.886979448273744,
    "arrivals": 24947,
    "finished_requests": 24893,
    "scheduler_time": 1.3367732375607293
}
#Debug simulation 
Total elapsed time: 2.214682042133063. Arrivals time: 0.0708812135271728 Scheduler time: 1.7338462565094233 Scheduler overhead time: 0.11591386841610074 Adapter cache time: 0.12780147697776556 Engine time: 0.11092854710295796 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_160_slots_96_rate_0.1-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_160_slots_96_rate_0.1-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 270, 33, 33, 33, 1080, 33, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 33, 1080, 270, 1080, 1080, 1080, 270, 1080, 33, 270, 270, 270, 1080, 33, 33, 1080, 33, 1080, 33, 33, 270, 33, 270, 1080, 33, 33, 270, 33, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 33, 1080, 1080, 1080, 270, 270, 33, 33, 33, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 33, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 270, 33, 33, 270, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 1080, 270, 1080, 33, 33, 33, 270, 270, 270, 1080, 1080, 270, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 270, 270, 1080, 270, 33, 33]
Prompts retrieved: 74379 . Total input tokens: 16563634 . Total output tokens: 14864978
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 2.2171978261321783,
    "estimated_duration": 3599.930313457948,
    "input_throughput": 1709.3753112373636,
    "output_throughput": 1527.4298448066977,
    "total_throughput": 3236.8051560440613,
    "itl": 28.342139394423004,
    "ttft": 7839.516214372284,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2414,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.5603842887465875,
    "arrivals": 24947,
    "finished_requests": 24893,
    "scheduler_time": 1.3352791186754773
}
#Debug simulation 
Total elapsed time: 2.217287850100547. Arrivals time: 0.07066094409674406 Scheduler time: 1.7346992366947234 Scheduler overhead time: 0.11629855958744884 Adapter cache time: 0.12604128289967775 Engine time: 0.11408440116792917 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_160_slots_96_rate_0.1-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_160_slots_96_rate_0.1-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 270, 33, 33, 33, 1080, 33, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 33, 1080, 270, 1080, 1080, 1080, 270, 1080, 33, 270, 270, 270, 1080, 33, 33, 1080, 33, 1080, 33, 33, 270, 33, 270, 1080, 33, 33, 270, 33, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 33, 1080, 1080, 1080, 270, 270, 33, 33, 33, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 33, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 270, 33, 33, 270, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 1080, 270, 1080, 33, 33, 33, 270, 270, 270, 1080, 1080, 270, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 270, 270, 1080, 270, 33, 33]
Prompts retrieved: 74379 . Total input tokens: 16563634 . Total output tokens: 14864978
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 2.224726688116789,
    "estimated_duration": 3599.9252518759417,
    "input_throughput": 1709.3777146604104,
    "output_throughput": 1527.4319924100164,
    "total_throughput": 3236.809707070427,
    "itl": 28.347880066780785,
    "ttft": 7839.61930650061,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2416,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.993654929213039,
    "arrivals": 24947,
    "finished_requests": 24893,
    "scheduler_time": 1.3372347210434419
}
#Debug simulation 
Total elapsed time: 2.2248120522126555. Arrivals time: 0.07162232231348753 Scheduler time: 1.739948755595833 Scheduler overhead time: 0.1158885913901031 Adapter cache time: 0.128130660392344 Engine time: 0.11369001818820834 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_160_slots_96_rate_0.1-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_160_slots_96_rate_0.1-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 270, 33, 33, 33, 1080, 33, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 33, 1080, 270, 1080, 1080, 1080, 270, 1080, 33, 270, 270, 270, 1080, 33, 33, 1080, 33, 1080, 33, 33, 270, 33, 270, 1080, 33, 33, 270, 33, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 33, 1080, 1080, 1080, 270, 270, 33, 33, 33, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 33, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 270, 33, 33, 270, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 1080, 270, 1080, 33, 33, 33, 270, 270, 270, 1080, 1080, 270, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 270, 270, 1080, 270, 33, 33]
Prompts retrieved: 74379 . Total input tokens: 16563634 . Total output tokens: 14864978
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.228793458081782,
    "estimated_duration": 3599.941379109197,
    "input_throughput": 1709.370056887624,
    "output_throughput": 1527.4251497285866,
    "total_throughput": 3236.7952066162106,
    "itl": 28.33763109985111,
    "ttft": 7839.45810940348,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2417,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.226951562778338,
    "arrivals": 24947,
    "finished_requests": 24893,
    "scheduler_time": 1.3341126292415657
}
#Debug simulation 
Total elapsed time: 2.2289031827822328. Arrivals time: 0.07083287229761481 Scheduler time: 1.7411189870908856 Scheduler overhead time: 0.11710849311202765 Adapter cache time: 0.126558696385473 Engine time: 0.11788210738450289 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_160_slots_96_rate_0.1-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_160_slots_96_rate_0.1-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 270, 33, 33, 33, 1080, 33, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 33, 1080, 270, 1080, 1080, 1080, 270, 1080, 33, 270, 270, 270, 1080, 33, 33, 1080, 33, 1080, 33, 33, 270, 33, 270, 1080, 33, 33, 270, 33, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 33, 1080, 1080, 1080, 270, 270, 33, 33, 33, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 33, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 270, 33, 33, 270, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 1080, 270, 1080, 33, 33, 33, 270, 270, 270, 1080, 1080, 270, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 270, 270, 1080, 270, 33, 33]
Prompts retrieved: 74379 . Total input tokens: 16563634 . Total output tokens: 14864978
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.2314593559131026,
    "estimated_duration": 3599.922769813692,
    "input_throughput": 1709.378893236221,
    "output_throughput": 1527.4330455385223,
    "total_throughput": 3236.8119387747433,
    "itl": 28.34939848127009,
    "ttft": 7839.531242037414,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2415,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.096456084660844,
    "arrivals": 24947,
    "finished_requests": 24893,
    "scheduler_time": 1.3377001242121929
}
#Debug simulation 
Total elapsed time: 2.2315401970408857. Arrivals time: 0.07092619687318802 Scheduler time: 1.7485197633504868 Scheduler overhead time: 0.11577458633109927 Adapter cache time: 0.12750926660373807 Engine time: 0.11326208431273699 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_160_slots_96_rate_0.1-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_160_slots_96_rate_0.1-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 135, 66, 66, 66, 1080, 66, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 66, 1080, 135, 1080, 1080, 1080, 135, 1080, 66, 135, 135, 135, 1080, 66, 66, 1080, 66, 1080, 66, 66, 135, 66, 135, 1080, 66, 66, 135, 66, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 66, 1080, 1080, 1080, 135, 135, 66, 66, 66, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 66, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 135, 66, 66, 135, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 1080, 135, 1080, 66, 66, 66, 135, 135, 135, 1080, 1080, 135, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 135, 135, 1080, 135, 66, 66]
Prompts retrieved: 68973 . Total input tokens: 15331429 . Total output tokens: 13800853
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.0893255886621773,
    "estimated_duration": 3599.2572573757884,
    "input_throughput": 1574.182281188477,
    "output_throughput": 1407.3981484983683,
    "total_throughput": 2981.5804296868455,
    "itl": 26.798243660506415,
    "ttft": 7041.3747584703515,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2129,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.515778406833023,
    "arrivals": 23153,
    "finished_requests": 23108,
    "scheduler_time": 0.4041733016914776
}
#Debug simulation 
Total elapsed time: 2.0894057657569647. Arrivals time: 0.06637804349884391 Scheduler time: 1.6068685096688569 Scheduler overhead time: 0.12231252482160926 Adapter cache time: 0.1180975092574954 Engine time: 0.11771617643535137 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_160_slots_96_rate_0.1-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_160_slots_96_rate_0.1-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 135, 66, 66, 66, 1080, 66, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 66, 1080, 135, 1080, 1080, 1080, 135, 1080, 66, 135, 135, 135, 1080, 66, 66, 1080, 66, 1080, 66, 66, 135, 66, 135, 1080, 66, 66, 135, 66, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 66, 1080, 1080, 1080, 135, 135, 66, 66, 66, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 66, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 135, 66, 66, 135, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 1080, 135, 1080, 66, 66, 66, 135, 135, 135, 1080, 1080, 135, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 135, 135, 1080, 135, 66, 66]
Prompts retrieved: 68973 . Total input tokens: 15331429 . Total output tokens: 13800853
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.081035953015089,
    "estimated_duration": 3599.2413058629845,
    "input_throughput": 1574.1892578223508,
    "output_throughput": 1407.4043859600106,
    "total_throughput": 2981.593643782361,
    "itl": 26.802188306847373,
    "ttft": 7041.501733242959,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2129,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.940710690892041,
    "arrivals": 23153,
    "finished_requests": 23108,
    "scheduler_time": 0.40512658378320515
}
#Debug simulation 
Total elapsed time: 2.081117674242705. Arrivals time: 0.06631331099197268 Scheduler time: 1.6041039545089006 Scheduler overhead time: 0.12007159553468227 Adapter cache time: 0.11766200046986341 Engine time: 0.11541334772482514 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_160_slots_96_rate_0.1-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_160_slots_96_rate_0.1-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 135, 66, 66, 66, 1080, 66, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 66, 1080, 135, 1080, 1080, 1080, 135, 1080, 66, 135, 135, 135, 1080, 66, 66, 1080, 66, 1080, 66, 66, 135, 66, 135, 1080, 66, 66, 135, 66, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 66, 1080, 1080, 1080, 135, 135, 66, 66, 66, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 66, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 135, 66, 66, 135, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 1080, 135, 1080, 66, 66, 66, 135, 135, 135, 1080, 1080, 135, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 135, 135, 1080, 135, 66, 66]
Prompts retrieved: 68973 . Total input tokens: 15331429 . Total output tokens: 13800853
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.0696493261493742,
    "estimated_duration": 3599.2406384978835,
    "input_throughput": 1574.1895497058558,
    "output_throughput": 1407.404646918547,
    "total_throughput": 2981.5941966244027,
    "itl": 26.80300892888297,
    "ttft": 7041.441743333205,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2129,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.954158853832587,
    "arrivals": 23153,
    "finished_requests": 23108,
    "scheduler_time": 0.40504293542034486
}
#Debug simulation 
Total elapsed time: 2.0697318371385336. Arrivals time: 0.06547295115888119 Scheduler time: 1.5934012779034674 Scheduler overhead time: 0.12089614244177938 Adapter cache time: 0.11744594015181065 Engine time: 0.11474828282371163 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_160_slots_96_rate_0.1-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_160_slots_96_rate_0.1-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 135, 66, 66, 66, 1080, 66, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 66, 1080, 135, 1080, 1080, 1080, 135, 1080, 66, 135, 135, 135, 1080, 66, 66, 1080, 66, 1080, 66, 66, 135, 66, 135, 1080, 66, 66, 135, 66, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 66, 1080, 1080, 1080, 135, 135, 66, 66, 66, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 66, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 135, 66, 66, 135, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 1080, 135, 1080, 66, 66, 66, 135, 135, 135, 1080, 1080, 135, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 135, 135, 1080, 135, 66, 66]
Prompts retrieved: 68973 . Total input tokens: 15331429 . Total output tokens: 13800853
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 2.082569341175258,
    "estimated_duration": 3599.246102826053,
    "input_throughput": 1574.187159791953,
    "output_throughput": 1407.4025102152937,
    "total_throughput": 2981.5896700072467,
    "itl": 26.799301560132456,
    "ttft": 7041.384651620537,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2129,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.666951827537051,
    "arrivals": 23153,
    "finished_requests": 23108,
    "scheduler_time": 0.4047133877529788
}
#Debug simulation 
Total elapsed time: 2.0826501292176545. Arrivals time: 0.06632471596822143 Scheduler time: 1.603129668161273 Scheduler overhead time: 0.11886302195489407 Adapter cache time: 0.11822558846324682 Engine time: 0.11837483989074826 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_160_slots_96_rate_0.1-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_160_slots_96_rate_0.1-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 135, 66, 66, 66, 1080, 66, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 66, 1080, 135, 1080, 1080, 1080, 135, 1080, 66, 135, 135, 135, 1080, 66, 66, 1080, 66, 1080, 66, 66, 135, 66, 135, 1080, 66, 66, 135, 66, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 66, 1080, 1080, 1080, 135, 135, 66, 66, 66, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 66, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 135, 66, 66, 135, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 1080, 135, 1080, 66, 66, 66, 135, 135, 135, 1080, 1080, 135, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 135, 135, 1080, 135, 66, 66]
Prompts retrieved: 68973 . Total input tokens: 15331429 . Total output tokens: 13800853
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 2.07758651021868,
    "estimated_duration": 3599.248807145404,
    "input_throughput": 1574.1859770160388,
    "output_throughput": 1407.401452754127,
    "total_throughput": 2981.5874297701657,
    "itl": 26.803977678930927,
    "ttft": 7041.402415741994,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2129,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.038413890730445,
    "arrivals": 23153,
    "finished_requests": 23108,
    "scheduler_time": 0.4050648274325694
}
#Debug simulation 
Total elapsed time: 2.077668799087405. Arrivals time: 0.06650161556899548 Scheduler time: 1.5964083010330796 Scheduler overhead time: 0.1213640053756535 Adapter cache time: 0.11949131870642304 Engine time: 0.11607129452750087 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_160_slots_96_rate_0.1-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_160_slots_96_rate_0.1-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 135, 66, 66, 66, 1080, 66, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 66, 1080, 135, 1080, 1080, 1080, 135, 1080, 66, 135, 135, 135, 1080, 66, 66, 1080, 66, 1080, 66, 66, 135, 66, 135, 1080, 66, 66, 135, 66, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 66, 1080, 1080, 1080, 135, 135, 66, 66, 66, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 66, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 135, 66, 66, 135, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 1080, 135, 1080, 66, 66, 66, 135, 135, 135, 1080, 1080, 135, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 135, 135, 1080, 135, 66, 66]
Prompts retrieved: 68973 . Total input tokens: 15331429 . Total output tokens: 13800853
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.094755924772471,
    "estimated_duration": 3599.2414852031993,
    "input_throughput": 1574.1891793848686,
    "output_throughput": 1407.4043158329557,
    "total_throughput": 2981.593495217824,
    "itl": 26.795515043432513,
    "ttft": 7041.426689148075,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2129,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.365817077846542,
    "arrivals": 23153,
    "finished_requests": 23108,
    "scheduler_time": 0.40403181666401894
}
#Debug simulation 
Total elapsed time: 2.094840355683118. Arrivals time: 0.0670522809959948 Scheduler time: 1.6103153410367668 Scheduler overhead time: 0.12298588966950774 Adapter cache time: 0.11776733351871371 Engine time: 0.11819031881168485 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_160_slots_96_rate_0.1-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_160_slots_96_rate_0.1-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 135, 66, 66, 66, 1080, 66, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 66, 1080, 135, 1080, 1080, 1080, 135, 1080, 66, 135, 135, 135, 1080, 66, 66, 1080, 66, 1080, 66, 66, 135, 66, 135, 1080, 66, 66, 135, 66, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 66, 1080, 1080, 1080, 135, 135, 66, 66, 66, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 66, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 135, 66, 66, 135, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 1080, 135, 1080, 66, 66, 66, 135, 135, 135, 1080, 1080, 135, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 135, 135, 1080, 135, 66, 66]
Prompts retrieved: 68973 . Total input tokens: 15331429 . Total output tokens: 13800853
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.092439955100417,
    "estimated_duration": 3599.261486546809,
    "input_throughput": 1574.1804315073384,
    "output_throughput": 1407.3964947903823,
    "total_throughput": 2981.5769262977205,
    "itl": 26.804842276274027,
    "ttft": 7041.3887801800665,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2129,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.131094431318093,
    "arrivals": 23153,
    "finished_requests": 23108,
    "scheduler_time": 0.40531906659716727
}
#Debug simulation 
Total elapsed time: 2.092524679377675. Arrivals time: 0.0666262423619628 Scheduler time: 1.612458640243858 Scheduler overhead time: 0.1202169549651444 Adapter cache time: 0.11851380905136466 Engine time: 0.11711526149883866 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_160_slots_96_rate_0.1-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_160_slots_96_rate_0.1-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 135, 33, 33, 33, 1080, 33, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 33, 1080, 135, 1080, 1080, 1080, 135, 1080, 33, 135, 135, 135, 1080, 33, 33, 1080, 33, 1080, 33, 33, 135, 33, 135, 1080, 33, 33, 135, 33, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 33, 1080, 1080, 1080, 135, 135, 33, 33, 33, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 33, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 135, 33, 33, 135, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 1080, 135, 1080, 33, 33, 33, 135, 135, 135, 1080, 1080, 135, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 135, 135, 1080, 135, 33, 33]
Prompts retrieved: 67224 . Total input tokens: 14934282 . Total output tokens: 13460039
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.0382715477608144,
    "estimated_duration": 3600.0200600510716,
    "input_throughput": 1543.9100080795522,
    "output_throughput": 1353.3844030665987,
    "total_throughput": 2897.2944111461507,
    "itl": 26.09147414852965,
    "ttft": 7384.597749303521,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1465,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.483614544861604,
    "arrivals": 22557,
    "finished_requests": 22511,
    "scheduler_time": 0.20291798908176492
}
#Debug simulation 
Total elapsed time: 2.038353999145329. Arrivals time: 0.06537967268377542 Scheduler time: 1.5607241755351424 Scheduler overhead time: 0.12203978188335896 Adapter cache time: 0.11282940302044153 Engine time: 0.11823702184483409 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_160_slots_96_rate_0.1-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_160_slots_96_rate_0.1-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 135, 33, 33, 33, 1080, 33, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 33, 1080, 135, 1080, 1080, 1080, 135, 1080, 33, 135, 135, 135, 1080, 33, 33, 1080, 33, 1080, 33, 33, 135, 33, 135, 1080, 33, 33, 135, 33, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 33, 1080, 1080, 1080, 135, 135, 33, 33, 33, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 33, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 135, 33, 33, 135, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 1080, 135, 1080, 33, 33, 33, 135, 135, 135, 1080, 1080, 135, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 135, 135, 1080, 135, 33, 33]
Prompts retrieved: 67224 . Total input tokens: 14934282 . Total output tokens: 13460039
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.0336559801362455,
    "estimated_duration": 3600.026646049408,
    "input_throughput": 1543.9071836035846,
    "output_throughput": 1353.3819271439727,
    "total_throughput": 2897.289110747557,
    "itl": 26.093949776240624,
    "ttft": 7384.628439990164,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1465,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.784115856650685,
    "arrivals": 22557,
    "finished_requests": 22511,
    "scheduler_time": 0.203239113635056
}
#Debug simulation 
Total elapsed time: 2.0337403253652155. Arrivals time: 0.06584442406892776 Scheduler time: 1.5548768187873065 Scheduler overhead time: 0.12151683261618018 Adapter cache time: 0.11242475407198071 Engine time: 0.119584905449301 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_160_slots_96_rate_0.1-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_160_slots_96_rate_0.1-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 135, 33, 33, 33, 1080, 33, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 33, 1080, 135, 1080, 1080, 1080, 135, 1080, 33, 135, 135, 135, 1080, 33, 33, 1080, 33, 1080, 33, 33, 135, 33, 135, 1080, 33, 33, 135, 33, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 33, 1080, 1080, 1080, 135, 135, 33, 33, 33, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 33, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 135, 33, 33, 135, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 1080, 135, 1080, 33, 33, 33, 135, 135, 135, 1080, 1080, 135, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 135, 135, 1080, 135, 33, 33]
Prompts retrieved: 67224 . Total input tokens: 14934282 . Total output tokens: 13460039
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.0269305729307234,
    "estimated_duration": 3600.0275297303774,
    "input_throughput": 1543.9068046283169,
    "output_throughput": 1353.3815949359982,
    "total_throughput": 2897.288399564315,
    "itl": 26.09476607752955,
    "ttft": 7384.685473933885,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1465,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.791955638043526,
    "arrivals": 22557,
    "finished_requests": 22511,
    "scheduler_time": 0.20332226150990018
}
#Debug simulation 
Total elapsed time: 2.027071479242295. Arrivals time: 0.06517506157979369 Scheduler time: 1.5471121044829488 Scheduler overhead time: 0.12225459516048431 Adapter cache time: 0.11300243018195033 Engine time: 0.12053482653573155 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_160_slots_96_rate_0.1-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_160_slots_96_rate_0.1-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 135, 33, 33, 33, 1080, 33, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 33, 1080, 135, 1080, 1080, 1080, 135, 1080, 33, 135, 135, 135, 1080, 33, 33, 1080, 33, 1080, 33, 33, 135, 33, 135, 1080, 33, 33, 135, 33, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 33, 1080, 1080, 1080, 135, 135, 33, 33, 33, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 33, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 135, 33, 33, 135, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 1080, 135, 1080, 33, 33, 33, 135, 135, 135, 1080, 1080, 135, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 135, 135, 1080, 135, 33, 33]
Prompts retrieved: 67224 . Total input tokens: 14934282 . Total output tokens: 13460039
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 2.032409510575235,
    "estimated_duration": 3600.013454431291,
    "input_throughput": 1543.9128409807672,
    "output_throughput": 1353.3868863747575,
    "total_throughput": 2897.2997273555247,
    "itl": 26.092430383661217,
    "ttft": 7384.549926773603,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1465,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.589215889754623,
    "arrivals": 22557,
    "finished_requests": 22511,
    "scheduler_time": 0.2031554652721961
}
#Debug simulation 
Total elapsed time: 2.0324916755780578. Arrivals time: 0.06486492045223713 Scheduler time: 1.5563850468024611 Scheduler overhead time: 0.1215791767463088 Adapter cache time: 0.11222029523923993 Engine time: 0.1189713953062892 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_160_slots_96_rate_0.1-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_160_slots_96_rate_0.1-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 135, 33, 33, 33, 1080, 33, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 33, 1080, 135, 1080, 1080, 1080, 135, 1080, 33, 135, 135, 135, 1080, 33, 33, 1080, 33, 1080, 33, 33, 135, 33, 135, 1080, 33, 33, 135, 33, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 33, 1080, 1080, 1080, 135, 135, 33, 33, 33, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 33, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 135, 33, 33, 135, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 1080, 135, 1080, 33, 33, 33, 135, 135, 135, 1080, 1080, 135, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 135, 135, 1080, 135, 33, 33]
Prompts retrieved: 67224 . Total input tokens: 14934282 . Total output tokens: 13460039
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 2.044647225178778,
    "estimated_duration": 3600.0144554760673,
    "input_throughput": 1543.9124116697453,
    "output_throughput": 1353.3865100426929,
    "total_throughput": 2897.298921712438,
    "itl": 26.09410047814873,
    "ttft": 7384.5857666494885,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1465,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.851940194163433,
    "arrivals": 22557,
    "finished_requests": 22511,
    "scheduler_time": 0.20335307712421585
}
#Debug simulation 
Total elapsed time: 2.044727087020874. Arrivals time: 0.06554387742653489 Scheduler time: 1.566048638895154 Scheduler overhead time: 0.12152395863085985 Adapter cache time: 0.11382023990154266 Engine time: 0.11915123369544744 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_160_slots_96_rate_0.1-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_160_slots_96_rate_0.1-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 135, 33, 33, 33, 1080, 33, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 33, 1080, 135, 1080, 1080, 1080, 135, 1080, 33, 135, 135, 135, 1080, 33, 33, 1080, 33, 1080, 33, 33, 135, 33, 135, 1080, 33, 33, 135, 33, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 33, 1080, 1080, 1080, 135, 135, 33, 33, 33, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 33, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 135, 33, 33, 135, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 1080, 135, 1080, 33, 33, 33, 135, 135, 135, 1080, 1080, 135, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 135, 135, 1080, 135, 33, 33]
Prompts retrieved: 67224 . Total input tokens: 14934282 . Total output tokens: 13460039
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.03659347910434,
    "estimated_duration": 3600.0236200123727,
    "input_throughput": 1543.9084813507134,
    "output_throughput": 1353.3830647431294,
    "total_throughput": 2897.291546093843,
    "itl": 26.089969466783923,
    "ttft": 7384.620215478075,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1465,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.3804236820315685,
    "arrivals": 22557,
    "finished_requests": 22511,
    "scheduler_time": 0.20288800745345803
}
#Debug simulation 
Total elapsed time: 2.036677314899862. Arrivals time: 0.06540895579382777 Scheduler time: 1.5584424533881247 Scheduler overhead time: 0.12325167050585151 Adapter cache time: 0.11201320681720972 Engine time: 0.11864115996286273 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_160_slots_96_rate_0.1-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_160_slots_96_rate_0.1-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 135, 33, 33, 33, 1080, 33, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 33, 1080, 135, 1080, 1080, 1080, 135, 1080, 33, 135, 135, 135, 1080, 33, 33, 1080, 33, 1080, 33, 33, 135, 33, 135, 1080, 33, 33, 135, 33, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 33, 1080, 1080, 1080, 135, 135, 33, 33, 33, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 33, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 135, 33, 33, 135, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 1080, 135, 1080, 33, 33, 33, 135, 135, 135, 1080, 1080, 135, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 135, 135, 1080, 135, 33, 33]
Prompts retrieved: 67224 . Total input tokens: 14934282 . Total output tokens: 13460039
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.0203731628134847,
    "estimated_duration": 3600.0041093097298,
    "input_throughput": 1543.916848768742,
    "output_throughput": 1353.3903995832397,
    "total_throughput": 2897.307248351982,
    "itl": 26.095478092433453,
    "ttft": 7384.656998614521,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1465,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.916200379021439,
    "arrivals": 22557,
    "finished_requests": 22511,
    "scheduler_time": 0.20334319441411147
}
#Debug simulation 
Total elapsed time: 2.0204648370854557. Arrivals time: 0.0654845735989511 Scheduler time: 1.5427736132405698 Scheduler overhead time: 0.12303785467520356 Adapter cache time: 0.11286931810900569 Engine time: 0.11785119725391269 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_160_slots_96_rate_0.1-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_160_slots_96_rate_0.1-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 66, 33, 33, 33, 1080, 33, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 1080, 1080, 66, 66, 66, 1080, 1080, 33, 1080, 66, 1080, 1080, 1080, 66, 1080, 33, 66, 66, 66, 1080, 33, 33, 1080, 33, 1080, 33, 33, 66, 33, 66, 1080, 33, 33, 66, 33, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 33, 1080, 1080, 1080, 66, 66, 33, 33, 33, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 33, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 66, 33, 33, 66, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 1080, 66, 1080, 33, 33, 33, 66, 66, 66, 1080, 1080, 66, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 1080, 1080, 1080, 66, 66, 66, 66, 66, 1080, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 63567 . Total input tokens: 14132716 . Total output tokens: 12724378
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.9840739541687071,
    "estimated_duration": 3599.882405304127,
    "input_throughput": 1451.4251888621295,
    "output_throughput": 1307.8338317560272,
    "total_throughput": 2759.2590206181567,
    "itl": 25.501916350909912,
    "ttft": 3599.5359544129024,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1043,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.192088716921937,
    "arrivals": 21252,
    "finished_requests": 21231,
    "scheduler_time": 0.09734222189472722
}
#Debug simulation 
Total elapsed time: 1.9841514742001891. Arrivals time: 0.06213622400537133 Scheduler time: 1.5101170954294503 Scheduler overhead time: 0.12396566430106759 Adapter cache time: 0.10362350661307573 Engine time: 0.12438913248479366 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_160_slots_96_rate_0.1-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_160_slots_96_rate_0.1-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 66, 33, 33, 33, 1080, 33, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 1080, 1080, 66, 66, 66, 1080, 1080, 33, 1080, 66, 1080, 1080, 1080, 66, 1080, 33, 66, 66, 66, 1080, 33, 33, 1080, 33, 1080, 33, 33, 66, 33, 66, 1080, 33, 33, 66, 33, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 33, 1080, 1080, 1080, 66, 66, 33, 33, 33, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 33, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 66, 33, 33, 66, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 1080, 66, 1080, 33, 33, 33, 66, 66, 66, 1080, 1080, 66, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 1080, 1080, 1080, 66, 66, 66, 66, 66, 1080, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 63567 . Total input tokens: 14132716 . Total output tokens: 12724378
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.9620522879995406,
    "estimated_duration": 3599.8699914953736,
    "input_throughput": 1451.4301939636352,
    "output_throughput": 1307.838341696416,
    "total_throughput": 2759.268535660051,
    "itl": 25.504678386357504,
    "ttft": 3599.590157821385,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1043,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.397284464759291,
    "arrivals": 21252,
    "finished_requests": 21231,
    "scheduler_time": 0.09750355559637977
}
#Debug simulation 
Total elapsed time: 1.9621339673176408. Arrivals time: 0.061448374297469854 Scheduler time: 1.4919005022384226 Scheduler overhead time: 0.1250105150975287 Adapter cache time: 0.10404500411823392 Engine time: 0.12029650341719389 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_160_slots_96_rate_0.1-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_160_slots_96_rate_0.1-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 66, 33, 33, 33, 1080, 33, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 1080, 1080, 66, 66, 66, 1080, 1080, 33, 1080, 66, 1080, 1080, 1080, 66, 1080, 33, 66, 66, 66, 1080, 33, 33, 1080, 33, 1080, 33, 33, 66, 33, 66, 1080, 33, 33, 66, 33, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 33, 1080, 1080, 1080, 66, 66, 33, 33, 33, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 33, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 66, 33, 33, 66, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 1080, 66, 1080, 33, 33, 33, 66, 66, 66, 1080, 1080, 66, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 1080, 1080, 1080, 66, 66, 66, 66, 66, 1080, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 63567 . Total input tokens: 14132716 . Total output tokens: 12724378
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.003660028334707,
    "estimated_duration": 3599.8760909861435,
    "input_throughput": 1451.4277347164702,
    "output_throughput": 1307.8361257457298,
    "total_throughput": 2759.2638604622,
    "itl": 25.505091887949593,
    "ttft": 3599.585152886215,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1043,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4043929505347794,
    "arrivals": 21252,
    "finished_requests": 21231,
    "scheduler_time": 0.09741657128948387
}
#Debug simulation 
Total elapsed time: 2.0037384061142802. Arrivals time: 0.06228066701442003 Scheduler time: 1.5320102805271745 Scheduler overhead time: 0.12290766183286905 Adapter cache time: 0.10381145076826215 Engine time: 0.12294852780178189 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_160_slots_96_rate_0.1-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_160_slots_96_rate_0.1-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 66, 33, 33, 33, 1080, 33, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 1080, 1080, 66, 66, 66, 1080, 1080, 33, 1080, 66, 1080, 1080, 1080, 66, 1080, 33, 66, 66, 66, 1080, 33, 33, 1080, 33, 1080, 33, 33, 66, 33, 66, 1080, 33, 33, 66, 33, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 33, 1080, 1080, 1080, 66, 66, 33, 33, 33, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 33, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 66, 33, 33, 66, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 1080, 66, 1080, 33, 33, 33, 66, 66, 66, 1080, 1080, 66, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 1080, 1080, 1080, 66, 66, 66, 66, 66, 1080, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 63567 . Total input tokens: 14132716 . Total output tokens: 12724378
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 1.9985190005972981,
    "estimated_duration": 3599.8776579024375,
    "input_throughput": 1451.4271029545096,
    "output_throughput": 1307.835556484791,
    "total_throughput": 2759.2626594393005,
    "itl": 25.50312501528292,
    "ttft": 3599.593270145829,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1043,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.26367379562926,
    "arrivals": 21252,
    "finished_requests": 21231,
    "scheduler_time": 0.09730857082439072
}
#Debug simulation 
Total elapsed time: 1.9986022766679525. Arrivals time: 0.0619693617336452 Scheduler time: 1.5236444119364023 Scheduler overhead time: 0.12685393635183573 Adapter cache time: 0.1042370144277811 Engine time: 0.12171852216124535 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_160_slots_96_rate_0.1-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_160_slots_96_rate_0.1-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 66, 33, 33, 33, 1080, 33, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 1080, 1080, 66, 66, 66, 1080, 1080, 33, 1080, 66, 1080, 1080, 1080, 66, 1080, 33, 66, 66, 66, 1080, 33, 33, 1080, 33, 1080, 33, 33, 66, 33, 66, 1080, 33, 33, 66, 33, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 33, 1080, 1080, 1080, 66, 66, 33, 33, 33, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 33, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 66, 33, 33, 66, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 1080, 66, 1080, 33, 33, 33, 66, 66, 66, 1080, 1080, 66, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 1080, 1080, 1080, 66, 66, 66, 66, 66, 1080, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 63567 . Total input tokens: 14132716 . Total output tokens: 12724378
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 2.010145344771445,
    "estimated_duration": 3599.8789414111134,
    "input_throughput": 1451.42658545953,
    "output_throughput": 1307.835090186254,
    "total_throughput": 2759.261675645784,
    "itl": 25.505270840370553,
    "ttft": 3599.470773893529,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1043,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.445514438692479,
    "arrivals": 21252,
    "finished_requests": 21231,
    "scheduler_time": 0.09758566110922531
}
#Debug simulation 
Total elapsed time: 2.010224954690784. Arrivals time: 0.06209860322996974 Scheduler time: 1.5317687708884478 Scheduler overhead time: 0.12530415365472436 Adapter cache time: 0.1045498545281589 Engine time: 0.12597602931782603 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_160_slots_96_rate_0.1-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_160_slots_96_rate_0.1-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 66, 33, 33, 33, 1080, 33, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 1080, 1080, 66, 66, 66, 1080, 1080, 33, 1080, 66, 1080, 1080, 1080, 66, 1080, 33, 66, 66, 66, 1080, 33, 33, 1080, 33, 1080, 33, 33, 66, 33, 66, 1080, 33, 33, 66, 33, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 33, 1080, 1080, 1080, 66, 66, 33, 33, 33, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 33, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 66, 33, 33, 66, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 1080, 66, 1080, 33, 33, 33, 66, 66, 66, 1080, 1080, 66, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 1080, 1080, 1080, 66, 66, 66, 66, 66, 1080, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 63567 . Total input tokens: 14132716 . Total output tokens: 12724378
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.0091331130824983,
    "estimated_duration": 3599.862762009978,
    "input_throughput": 1451.4331088229185,
    "output_throughput": 1307.8409681849284,
    "total_throughput": 2759.2740770078467,
    "itl": 25.502032448514598,
    "ttft": 3599.595599776113,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1043,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1186224575828954,
    "arrivals": 21252,
    "finished_requests": 21231,
    "scheduler_time": 0.09722362985552456
}
#Debug simulation 
Total elapsed time: 2.009217631071806. Arrivals time: 0.06205166969448328 Scheduler time: 1.5355601101182401 Scheduler overhead time: 0.12324589863419533 Adapter cache time: 0.1055279984138906 Engine time: 0.12299238936975598 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_160_slots_96_rate_0.1-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_160_slots_96_rate_0.1-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 66, 33, 33, 33, 1080, 33, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 1080, 1080, 66, 66, 66, 1080, 1080, 33, 1080, 66, 1080, 1080, 1080, 66, 1080, 33, 66, 66, 66, 1080, 33, 33, 1080, 33, 1080, 33, 33, 66, 33, 66, 1080, 33, 33, 66, 33, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 33, 1080, 1080, 1080, 66, 66, 33, 33, 33, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 33, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 66, 33, 33, 66, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 1080, 66, 1080, 33, 33, 33, 66, 66, 66, 1080, 1080, 66, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 1080, 1080, 1080, 66, 66, 66, 66, 66, 1080, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 63567 . Total input tokens: 14132716 . Total output tokens: 12724378
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.964183047413826,
    "estimated_duration": 3599.877021129729,
    "input_throughput": 1451.4273596936043,
    "output_throughput": 1307.8357878243573,
    "total_throughput": 2759.2631475179614,
    "itl": 25.505318304032386,
    "ttft": 3599.5815070452454,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1043,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4901570328698015,
    "arrivals": 21252,
    "finished_requests": 21231,
    "scheduler_time": 0.0974819138281633
}
#Debug simulation 
Total elapsed time: 1.9642659700475633. Arrivals time: 0.060748760122805834 Scheduler time: 1.4975404157303274 Scheduler overhead time: 0.12329647596925497 Adapter cache time: 0.10300555359572172 Engine time: 0.12010956555604935 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_160_slots_96_rate_0.05-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_160_slots_96_rate_0.05-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [53 53 54]
Adapter prompts. [135, 540, 135, 135, 270, 135, 135, 135, 540, 135, 270, 540, 270, 135, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 135, 540, 270, 540, 540, 540, 270, 540, 135, 270, 270, 270, 540, 135, 135, 540, 135, 540, 135, 135, 270, 135, 270, 540, 135, 135, 270, 135, 135, 135, 135, 135, 540, 270, 270, 540, 270, 135, 540, 540, 540, 270, 270, 135, 135, 135, 540, 135, 270, 270, 135, 540, 540, 540, 135, 135, 540, 270, 540, 540, 135, 540, 135, 270, 135, 135, 270, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 135, 540, 270, 540, 270, 540, 540, 540, 135, 270, 270, 540, 270, 540, 135, 135, 135, 270, 270, 270, 540, 540, 270, 540, 135, 270, 270, 135, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 50625 . Total input tokens: 11246464 . Total output tokens: 10123844
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.7163523058407009,
    "estimated_duration": 3599.575882275259,
    "input_throughput": 1189.4337388697388,
    "output_throughput": 1036.9502191576719,
    "total_throughput": 2226.3839580274107,
    "itl": 24.08355743970947,
    "ttft": 6752.050692805651,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5061,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.489128472041996,
    "arrivals": 17165,
    "finished_requests": 17133,
    "scheduler_time": 0.003297479107782848
}
#Debug simulation 
Total elapsed time: 1.7164315418340266. Arrivals time: 0.053948388900607824 Scheduler time: 1.2212423272430897 Scheduler overhead time: 0.1308593419380486 Adapter cache time: 0.12116180872544646 Engine time: 0.12555007450282574 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_160_slots_96_rate_0.05-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_160_slots_96_rate_0.05-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [53 53 54]
Adapter prompts. [135, 540, 135, 135, 270, 135, 135, 135, 540, 135, 270, 540, 270, 135, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 135, 540, 270, 540, 540, 540, 270, 540, 135, 270, 270, 270, 540, 135, 135, 540, 135, 540, 135, 135, 270, 135, 270, 540, 135, 135, 270, 135, 135, 135, 135, 135, 540, 270, 270, 540, 270, 135, 540, 540, 540, 270, 270, 135, 135, 135, 540, 135, 270, 270, 135, 540, 540, 540, 135, 135, 540, 270, 540, 540, 135, 540, 135, 270, 135, 135, 270, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 135, 540, 270, 540, 270, 540, 540, 540, 135, 270, 270, 540, 270, 540, 135, 135, 135, 270, 270, 270, 540, 540, 270, 540, 135, 270, 270, 135, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 50625 . Total input tokens: 11246464 . Total output tokens: 10123844
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.7072432073764503,
    "estimated_duration": 3599.5725330718947,
    "input_throughput": 1189.434845572116,
    "output_throughput": 1036.9511839825589,
    "total_throughput": 2226.386029554675,
    "itl": 24.09276458778244,
    "ttft": 6751.992724999382,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5055,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.509240062568306,
    "arrivals": 17165,
    "finished_requests": 17133,
    "scheduler_time": 0.0033282947220986733
}
#Debug simulation 
Total elapsed time: 1.7073206780478358. Arrivals time: 0.053581700660288334 Scheduler time: 1.2166971205733716 Scheduler overhead time: 0.12823028350248933 Adapter cache time: 0.11982936644926667 Engine time: 0.12625988898798823 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_160_slots_96_rate_0.05-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_160_slots_96_rate_0.05-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [53 53 54]
Adapter prompts. [135, 540, 135, 135, 270, 135, 135, 135, 540, 135, 270, 540, 270, 135, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 135, 540, 270, 540, 540, 540, 270, 540, 135, 270, 270, 270, 540, 135, 135, 540, 135, 540, 135, 135, 270, 135, 270, 540, 135, 135, 270, 135, 135, 135, 135, 135, 540, 270, 270, 540, 270, 135, 540, 540, 540, 270, 270, 135, 135, 135, 540, 135, 270, 270, 135, 540, 540, 540, 135, 135, 540, 270, 540, 540, 135, 540, 135, 270, 135, 135, 270, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 135, 540, 270, 540, 270, 540, 540, 540, 135, 270, 270, 540, 270, 540, 135, 135, 135, 270, 270, 270, 540, 540, 270, 540, 135, 270, 270, 135, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 50625 . Total input tokens: 11246464 . Total output tokens: 10123844
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.6976887499913573,
    "estimated_duration": 3599.5755569075086,
    "input_throughput": 1189.4338463833535,
    "output_throughput": 1036.9503128882118,
    "total_throughput": 2226.3841592715653,
    "itl": 24.093868392086456,
    "ttft": 6752.058148049206,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5058,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.546155778391824,
    "arrivals": 17165,
    "finished_requests": 17133,
    "scheduler_time": 0.0033234159280483974
}
#Debug simulation 
Total elapsed time: 1.6977674895897508. Arrivals time: 0.05339980125427246 Scheduler time: 1.2077369522303343 Scheduler overhead time: 0.1284916209988296 Adapter cache time: 0.121080475859344 Engine time: 0.12478441372513771 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_160_slots_96_rate_0.05-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_160_slots_96_rate_0.05-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [53 53 54]
Adapter prompts. [135, 540, 135, 135, 270, 135, 135, 135, 540, 135, 270, 540, 270, 135, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 135, 540, 270, 540, 540, 540, 270, 540, 135, 270, 270, 270, 540, 135, 135, 540, 135, 540, 135, 135, 270, 135, 270, 540, 135, 135, 270, 135, 135, 135, 135, 135, 540, 270, 270, 540, 270, 135, 540, 540, 540, 270, 270, 135, 135, 135, 540, 135, 270, 270, 135, 540, 540, 540, 135, 135, 540, 270, 540, 540, 135, 540, 135, 270, 135, 135, 270, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 135, 540, 270, 540, 270, 540, 540, 540, 135, 270, 270, 540, 270, 540, 135, 135, 135, 270, 270, 270, 540, 540, 270, 540, 135, 270, 270, 135, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 50625 . Total input tokens: 11246464 . Total output tokens: 10123844
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 1.700028158724308,
    "estimated_duration": 3599.5735291698556,
    "input_throughput": 1189.4345164237839,
    "output_throughput": 1036.950897030521,
    "total_throughput": 2226.385413454305,
    "itl": 24.0863356283636,
    "ttft": 6751.934652281621,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5058,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.828909911244649,
    "arrivals": 17165,
    "finished_requests": 17133,
    "scheduler_time": 0.0032983130937918746
}
#Debug simulation 
Total elapsed time: 1.7001102869398892. Arrivals time: 0.05378449382260442 Scheduler time: 1.2040603375062346 Scheduler overhead time: 0.12840158911421895 Adapter cache time: 0.12072388408705592 Engine time: 0.13085922971367836 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_160_slots_96_rate_0.05-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_160_slots_96_rate_0.05-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [53 53 54]
Adapter prompts. [135, 540, 135, 135, 270, 135, 135, 135, 540, 135, 270, 540, 270, 135, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 135, 540, 270, 540, 540, 540, 270, 540, 135, 270, 270, 270, 540, 135, 135, 540, 135, 540, 135, 135, 270, 135, 270, 540, 135, 135, 270, 135, 135, 135, 135, 135, 540, 270, 270, 540, 270, 135, 540, 540, 540, 270, 270, 135, 135, 135, 540, 135, 270, 270, 135, 540, 540, 540, 135, 135, 540, 270, 540, 540, 135, 540, 135, 270, 135, 135, 270, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 135, 540, 270, 540, 270, 540, 540, 540, 135, 270, 270, 540, 270, 540, 135, 135, 135, 270, 270, 270, 540, 540, 270, 540, 135, 270, 270, 135, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 50625 . Total input tokens: 11246464 . Total output tokens: 10123844
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 1.7107161688618362,
    "estimated_duration": 3599.5787385990425,
    "input_throughput": 1189.4327950348836,
    "output_throughput": 1036.9493963209488,
    "total_throughput": 2226.3821913558327,
    "itl": 24.094315943329004,
    "ttft": 6752.046732106577,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5054,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.745242351981496,
    "arrivals": 17165,
    "finished_requests": 17133,
    "scheduler_time": 0.003302357901833124
}
#Debug simulation 
Total elapsed time: 1.710835725069046. Arrivals time: 0.05433616600930691 Scheduler time: 1.2196308737620711 Scheduler overhead time: 0.12866469845175743 Adapter cache time: 0.12156861601397395 Engine time: 0.12445949297398329 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_160_slots_96_rate_0.05-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_160_slots_96_rate_0.05-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [53 53 54]
Adapter prompts. [135, 540, 135, 135, 270, 135, 135, 135, 540, 135, 270, 540, 270, 135, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 135, 540, 270, 540, 540, 540, 270, 540, 135, 270, 270, 270, 540, 135, 135, 540, 135, 540, 135, 135, 270, 135, 270, 540, 135, 135, 270, 135, 135, 135, 135, 135, 540, 270, 270, 540, 270, 135, 540, 540, 540, 270, 270, 135, 135, 135, 540, 135, 270, 270, 135, 540, 540, 540, 135, 135, 540, 270, 540, 540, 135, 540, 135, 270, 135, 135, 270, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 135, 540, 270, 540, 270, 540, 540, 540, 135, 270, 270, 540, 270, 540, 135, 135, 135, 270, 270, 270, 540, 540, 270, 540, 135, 270, 270, 135, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 50625 . Total input tokens: 11246464 . Total output tokens: 10123844
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.7044247146695852,
    "estimated_duration": 3599.5550227474437,
    "input_throughput": 1189.4406316734335,
    "output_throughput": 1036.9562283148603,
    "total_throughput": 2226.3968599882937,
    "itl": 24.07829458993561,
    "ttft": 6751.9246283786415,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5058,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.123674391616818,
    "arrivals": 17165,
    "finished_requests": 17133,
    "scheduler_time": 0.003293434299741599
}
#Debug simulation 
Total elapsed time: 1.704525952693075. Arrivals time: 0.054002339486032724 Scheduler time: 1.2078839791938663 Scheduler overhead time: 0.12846974143758416 Adapter cache time: 0.12152094533666968 Engine time: 0.13037936994805932 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_160_slots_96_rate_0.05-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_160_slots_96_rate_0.05-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [53 53 54]
Adapter prompts. [135, 540, 135, 135, 270, 135, 135, 135, 540, 135, 270, 540, 270, 135, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 135, 540, 270, 540, 540, 540, 270, 540, 135, 270, 270, 270, 540, 135, 135, 540, 135, 540, 135, 135, 270, 135, 270, 540, 135, 135, 270, 135, 135, 135, 135, 135, 540, 270, 270, 540, 270, 135, 540, 540, 540, 270, 270, 135, 135, 135, 540, 135, 270, 270, 135, 540, 540, 540, 135, 135, 540, 270, 540, 540, 135, 540, 135, 270, 135, 135, 270, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 135, 540, 270, 540, 270, 540, 540, 540, 135, 270, 270, 540, 270, 540, 135, 135, 135, 270, 270, 270, 540, 540, 270, 540, 135, 270, 270, 135, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 50625 . Total input tokens: 11246464 . Total output tokens: 10123844
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.6966416561044753,
    "estimated_duration": 3599.56412033611,
    "input_throughput": 1189.437625464557,
    "output_throughput": 1036.953607497196,
    "total_throughput": 2226.391232961753,
    "itl": 24.09671031636686,
    "ttft": 6751.946868487043,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5058,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.97526771150408,
    "arrivals": 17165,
    "finished_requests": 17133,
    "scheduler_time": 0.0033064027098743736
}
#Debug simulation 
Total elapsed time: 1.696730701252818. Arrivals time: 0.05395960249006748 Scheduler time: 1.2055067201144993 Scheduler overhead time: 0.12842957489192486 Adapter cache time: 0.12047107936814427 Engine time: 0.12602179730311036 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_160_slots_96_rate_0.05-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_160_slots_96_rate_0.05-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [53 53 54]
Adapter prompts. [66, 540, 66, 66, 270, 66, 66, 66, 540, 66, 270, 540, 270, 66, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 66, 540, 270, 540, 540, 540, 270, 540, 66, 270, 270, 270, 540, 66, 66, 540, 66, 540, 66, 66, 270, 66, 270, 540, 66, 66, 270, 66, 66, 66, 66, 66, 540, 270, 270, 540, 270, 66, 540, 540, 540, 270, 270, 66, 66, 66, 540, 66, 270, 270, 66, 540, 540, 540, 66, 66, 540, 270, 540, 540, 66, 540, 66, 270, 66, 66, 270, 270, 540, 540, 540, 66, 540, 270, 270, 66, 66, 66, 66, 540, 270, 540, 270, 540, 540, 540, 66, 270, 270, 540, 270, 540, 66, 66, 66, 270, 270, 270, 540, 540, 270, 540, 66, 270, 270, 66, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 66, 540, 66, 540, 270, 66, 270, 66, 66, 270, 270, 270, 540, 270, 66, 66]
Prompts retrieved: 46968 . Total input tokens: 10413330 . Total output tokens: 9394576
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.628895322792232,
    "estimated_duration": 3599.6099725894633,
    "input_throughput": 1093.4534657843894,
    "output_throughput": 982.747582915271,
    "total_throughput": 2076.2010486996605,
    "itl": 23.590162244140146,
    "ttft": 5924.130878944096,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3573,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.935122709071221,
    "arrivals": 15906,
    "finished_requests": 15880,
    "scheduler_time": 8.339860090264041e-07
}
#Debug simulation 
Total elapsed time: 1.6289786049164832. Arrivals time: 0.05002214154228568 Scheduler time: 1.1453350251540542 Scheduler overhead time: 0.1322740837931633 Adapter cache time: 0.11058502132073045 Engine time: 0.1271005542948842 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_160_slots_96_rate_0.05-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_160_slots_96_rate_0.05-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [53 53 54]
Adapter prompts. [66, 540, 66, 66, 270, 66, 66, 66, 540, 66, 270, 540, 270, 66, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 66, 540, 270, 540, 540, 540, 270, 540, 66, 270, 270, 270, 540, 66, 66, 540, 66, 540, 66, 66, 270, 66, 270, 540, 66, 66, 270, 66, 66, 66, 66, 66, 540, 270, 270, 540, 270, 66, 540, 540, 540, 270, 270, 66, 66, 66, 540, 66, 270, 270, 66, 540, 540, 540, 66, 66, 540, 270, 540, 540, 66, 540, 66, 270, 66, 66, 270, 270, 540, 540, 540, 66, 540, 270, 270, 66, 66, 66, 66, 540, 270, 540, 270, 540, 540, 540, 66, 270, 270, 540, 270, 540, 66, 66, 66, 270, 270, 270, 540, 540, 270, 540, 66, 270, 270, 66, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 66, 540, 66, 540, 270, 66, 270, 66, 66, 270, 270, 270, 540, 270, 66, 66]
Prompts retrieved: 46968 . Total input tokens: 10413330 . Total output tokens: 9394576
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.6348748137243092,
    "estimated_duration": 3599.6193506148106,
    "input_throughput": 1093.4506170291963,
    "output_throughput": 982.7450225801787,
    "total_throughput": 2076.195639609375,
    "itl": 23.596893356334835,
    "ttft": 5924.129739786003,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3572,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.65863684573707,
    "arrivals": 15906,
    "finished_requests": 15880,
    "scheduler_time": 8.339860090264041e-07
}
#Debug simulation 
Total elapsed time: 1.6349801397882402. Arrivals time: 0.052772389724850655 Scheduler time: 1.1471522944048047 Scheduler overhead time: 0.1310312026180327 Adapter cache time: 0.11330200312659144 Engine time: 0.12720866268500686 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_160_slots_96_rate_0.05-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_160_slots_96_rate_0.05-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [53 53 54]
Adapter prompts. [66, 540, 66, 66, 270, 66, 66, 66, 540, 66, 270, 540, 270, 66, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 66, 540, 270, 540, 540, 540, 270, 540, 66, 270, 270, 270, 540, 66, 66, 540, 66, 540, 66, 66, 270, 66, 270, 540, 66, 66, 270, 66, 66, 66, 66, 66, 540, 270, 270, 540, 270, 66, 540, 540, 540, 270, 270, 66, 66, 66, 540, 66, 270, 270, 66, 540, 540, 540, 66, 66, 540, 270, 540, 540, 66, 540, 66, 270, 66, 66, 270, 270, 540, 540, 540, 66, 540, 270, 270, 66, 66, 66, 66, 540, 270, 540, 270, 540, 540, 540, 66, 270, 270, 540, 270, 540, 66, 66, 66, 270, 270, 270, 540, 540, 270, 540, 66, 270, 270, 66, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 66, 540, 66, 540, 270, 66, 270, 66, 66, 270, 270, 270, 540, 270, 66, 66]
Prompts retrieved: 46968 . Total input tokens: 10413330 . Total output tokens: 9394576
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.6180318999104202,
    "estimated_duration": 3599.6218936481278,
    "input_throughput": 1093.449844536576,
    "output_throughput": 982.7443282979989,
    "total_throughput": 2076.1941728345746,
    "itl": 23.595757236538642,
    "ttft": 5924.097136108574,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3573,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.68220059605248,
    "arrivals": 15906,
    "finished_requests": 15880,
    "scheduler_time": 8.339860090264041e-07
}
#Debug simulation 
Total elapsed time: 1.6181127722375095. Arrivals time: 0.04997157584875822 Scheduler time: 1.138521478511393 Scheduler overhead time: 0.12874897476285696 Adapter cache time: 0.11180308600887656 Engine time: 0.1260323324240744 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_160_slots_96_rate_0.05-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_160_slots_96_rate_0.05-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [53 53 54]
Adapter prompts. [66, 540, 66, 66, 270, 66, 66, 66, 540, 66, 270, 540, 270, 66, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 66, 540, 270, 540, 540, 540, 270, 540, 66, 270, 270, 270, 540, 66, 66, 540, 66, 540, 66, 66, 270, 66, 270, 540, 66, 66, 270, 66, 66, 66, 66, 66, 540, 270, 270, 540, 270, 66, 540, 540, 540, 270, 270, 66, 66, 66, 540, 66, 270, 270, 66, 540, 540, 540, 66, 66, 540, 270, 540, 540, 66, 540, 66, 270, 66, 66, 270, 270, 540, 540, 540, 66, 540, 270, 270, 66, 66, 66, 66, 540, 270, 540, 270, 540, 540, 540, 66, 270, 270, 540, 270, 540, 66, 66, 66, 270, 270, 270, 540, 540, 270, 540, 66, 270, 270, 66, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 66, 540, 66, 540, 270, 66, 270, 66, 66, 270, 270, 270, 540, 270, 66, 66]
Prompts retrieved: 46968 . Total input tokens: 10413330 . Total output tokens: 9394576
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 1.6401043883524835,
    "estimated_duration": 3599.6008419071163,
    "input_throughput": 1093.4562394186605,
    "output_throughput": 982.7500757350033,
    "total_throughput": 2076.206315153664,
    "itl": 23.591710585676218,
    "ttft": 5924.119868611108,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3573,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.178258634317132,
    "arrivals": 15906,
    "finished_requests": 15880,
    "scheduler_time": 8.339860090264041e-07
}
#Debug simulation 
Total elapsed time: 1.6401903270743787. Arrivals time: 0.0504141659475863 Scheduler time: 1.156330938450992 Scheduler overhead time: 0.130043123383075 Adapter cache time: 0.11114912200719118 Engine time: 0.12899220921099186 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_160_slots_96_rate_0.05-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_160_slots_96_rate_0.05-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [53 53 54]
Adapter prompts. [66, 540, 66, 66, 270, 66, 66, 66, 540, 66, 270, 540, 270, 66, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 66, 540, 270, 540, 540, 540, 270, 540, 66, 270, 270, 270, 540, 66, 66, 540, 66, 540, 66, 66, 270, 66, 270, 540, 66, 66, 270, 66, 66, 66, 66, 66, 540, 270, 270, 540, 270, 66, 540, 540, 540, 270, 270, 66, 66, 66, 540, 66, 270, 270, 66, 540, 540, 540, 66, 66, 540, 270, 540, 540, 66, 540, 66, 270, 66, 66, 270, 270, 540, 540, 540, 66, 540, 270, 270, 66, 66, 66, 66, 540, 270, 540, 270, 540, 540, 540, 66, 270, 270, 540, 270, 540, 66, 66, 66, 270, 270, 270, 540, 540, 270, 540, 66, 270, 270, 66, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 66, 540, 66, 540, 270, 66, 270, 66, 66, 270, 270, 270, 540, 270, 66, 66]
Prompts retrieved: 46968 . Total input tokens: 10413330 . Total output tokens: 9394576
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 1.6409222637303174,
    "estimated_duration": 3599.605574033673,
    "input_throughput": 1093.4548019352467,
    "output_throughput": 982.7487837885285,
    "total_throughput": 2076.203585723775,
    "itl": 23.597645422911324,
    "ttft": 5924.037503111371,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3571,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.824331546480995,
    "arrivals": 15906,
    "finished_requests": 15880,
    "scheduler_time": 8.339860090264041e-07
}
#Debug simulation 
Total elapsed time: 1.6410097358748317. Arrivals time: 0.05032904539257288 Scheduler time: 1.1571266106329858 Scheduler overhead time: 0.13054302986711264 Adapter cache time: 0.11206695716828108 Engine time: 0.12748898286372423 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_160_slots_96_rate_0.05-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_160_slots_96_rate_0.05-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [53 53 54]
Adapter prompts. [66, 540, 66, 66, 270, 66, 66, 66, 540, 66, 270, 540, 270, 66, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 66, 540, 270, 540, 540, 540, 270, 540, 66, 270, 270, 270, 540, 66, 66, 540, 66, 540, 66, 66, 270, 66, 270, 540, 66, 66, 270, 66, 66, 66, 66, 66, 540, 270, 270, 540, 270, 66, 540, 540, 540, 270, 270, 66, 66, 66, 540, 66, 270, 270, 66, 540, 540, 540, 66, 66, 540, 270, 540, 540, 66, 540, 66, 270, 66, 66, 270, 270, 540, 540, 540, 66, 540, 270, 270, 66, 66, 66, 66, 540, 270, 540, 270, 540, 540, 540, 66, 270, 270, 540, 270, 540, 66, 66, 66, 270, 270, 270, 540, 540, 270, 540, 66, 270, 270, 66, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 66, 540, 66, 540, 270, 66, 270, 66, 66, 270, 270, 270, 540, 270, 66, 66]
Prompts retrieved: 46968 . Total input tokens: 10413330 . Total output tokens: 9394576
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.6506889159791172,
    "estimated_duration": 3599.6233713181778,
    "input_throughput": 1093.4493956679248,
    "output_throughput": 982.7439248747206,
    "total_throughput": 2076.193320542646,
    "itl": 23.586986421990844,
    "ttft": 5924.17574558736,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3572,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.680459653391024,
    "arrivals": 15906,
    "finished_requests": 15880,
    "scheduler_time": 1.6679720180528082e-06
}
#Debug simulation 
Total elapsed time: 1.6507719978690147. Arrivals time: 0.05067045334726572 Scheduler time: 1.1632155920378864 Scheduler overhead time: 0.13247066922485828 Adapter cache time: 0.11200983077287674 Engine time: 0.12851114431396127 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_160_slots_96_rate_0.05-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_160_slots_96_rate_0.05-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [53 53 54]
Adapter prompts. [66, 540, 66, 66, 270, 66, 66, 66, 540, 66, 270, 540, 270, 66, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 66, 540, 270, 540, 540, 540, 270, 540, 66, 270, 270, 270, 540, 66, 66, 540, 66, 540, 66, 66, 270, 66, 270, 540, 66, 66, 270, 66, 66, 66, 66, 66, 540, 270, 270, 540, 270, 66, 540, 540, 540, 270, 270, 66, 66, 66, 540, 66, 270, 270, 66, 540, 540, 540, 66, 66, 540, 270, 540, 540, 66, 540, 66, 270, 66, 66, 270, 270, 540, 540, 540, 66, 540, 270, 270, 66, 66, 66, 66, 540, 270, 540, 270, 540, 540, 540, 66, 270, 270, 540, 270, 540, 66, 66, 66, 270, 270, 270, 540, 540, 270, 540, 66, 270, 270, 66, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 66, 540, 66, 540, 270, 66, 270, 66, 66, 270, 270, 270, 540, 270, 66, 66]
Prompts retrieved: 46968 . Total input tokens: 10413330 . Total output tokens: 9394576
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.6379451188258827,
    "estimated_duration": 3599.6030953122204,
    "input_throughput": 1093.4555548987828,
    "output_throughput": 982.7494605188314,
    "total_throughput": 2076.205015417614,
    "itl": 23.598628956613265,
    "ttft": 5924.197810431522,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3573,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.98338091451602,
    "arrivals": 15906,
    "finished_requests": 15880,
    "scheduler_time": 1.6679720180528082e-06
}
#Debug simulation 
Total elapsed time: 1.6380297197028995. Arrivals time: 0.04999559419229627 Scheduler time: 1.1501722689718008 Scheduler overhead time: 0.131170101929456 Adapter cache time: 0.11179420398548245 Engine time: 0.13117736484855413 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_160_slots_96_rate_0.05-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_160_slots_96_rate_0.05-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [53 53 54]
Adapter prompts. [33, 540, 33, 33, 270, 33, 33, 33, 540, 33, 270, 540, 270, 33, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 33, 540, 270, 540, 540, 540, 270, 540, 33, 270, 270, 270, 540, 33, 33, 540, 33, 540, 33, 33, 270, 33, 270, 540, 33, 33, 270, 33, 33, 33, 33, 33, 540, 270, 270, 540, 270, 33, 540, 540, 540, 270, 270, 33, 33, 33, 540, 33, 270, 270, 33, 540, 540, 540, 33, 33, 540, 270, 540, 540, 33, 540, 33, 270, 33, 33, 270, 270, 540, 540, 540, 33, 540, 270, 270, 33, 33, 33, 33, 540, 270, 540, 270, 540, 540, 540, 33, 270, 270, 540, 270, 540, 33, 33, 33, 270, 270, 270, 540, 540, 270, 540, 33, 270, 270, 33, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 33, 540, 33, 540, 270, 33, 270, 33, 33, 270, 270, 270, 540, 270, 33, 33]
Prompts retrieved: 45219 . Total input tokens: 10025903 . Total output tokens: 9036130
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.5703184772282839,
    "estimated_duration": 3599.679975246437,
    "input_throughput": 1045.5071078207025,
    "output_throughput": 940.5991708382913,
    "total_throughput": 1986.1062786589937,
    "itl": 23.166144092751814,
    "ttft": 6389.176911892489,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2756,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.4347042222788,
    "arrivals": 15306,
    "finished_requests": 15279,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5703984471037984. Arrivals time: 0.04838366713374853 Scheduler time: 1.0913346195593476 Scheduler overhead time: 0.13049046602100134 Adapter cache time: 0.10585834691300988 Engine time: 0.12990238424390554 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_160_slots_96_rate_0.05-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_160_slots_96_rate_0.05-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [53 53 54]
Adapter prompts. [33, 540, 33, 33, 270, 33, 33, 33, 540, 33, 270, 540, 270, 33, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 33, 540, 270, 540, 540, 540, 270, 540, 33, 270, 270, 270, 540, 33, 33, 540, 33, 540, 33, 33, 270, 33, 270, 540, 33, 33, 270, 33, 33, 33, 33, 33, 540, 270, 270, 540, 270, 33, 540, 540, 540, 270, 270, 33, 33, 33, 540, 33, 270, 270, 33, 540, 540, 540, 33, 33, 540, 270, 540, 540, 33, 540, 33, 270, 33, 33, 270, 270, 540, 540, 540, 33, 540, 270, 270, 33, 33, 33, 33, 540, 270, 540, 270, 540, 540, 540, 33, 270, 270, 540, 270, 540, 33, 33, 33, 270, 270, 270, 540, 540, 270, 540, 33, 270, 270, 33, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 33, 540, 33, 540, 270, 33, 270, 33, 33, 270, 270, 270, 540, 270, 33, 33]
Prompts retrieved: 45219 . Total input tokens: 10025903 . Total output tokens: 9036130
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.6031150631606579,
    "estimated_duration": 3599.6728083503076,
    "input_throughput": 1045.5064113798621,
    "output_throughput": 940.4049146209427,
    "total_throughput": 1985.9113260008048,
    "itl": 23.17095604062154,
    "ttft": 6624.323811196889,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2756,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.001383095686151,
    "arrivals": 15306,
    "finished_requests": 15278,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6031892872415483. Arrivals time: 0.049481195863336325 Scheduler time: 1.120130093768239 Scheduler overhead time: 0.1330369939096272 Adapter cache time: 0.10567922331392765 Engine time: 0.13043950172141194 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-32/adapters_160_slots_96_rate_0.05-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-32/adapters_160_slots_96_rate_0.05-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [53 53 54]
Adapter prompts. [33, 540, 33, 33, 270, 33, 33, 33, 540, 33, 270, 540, 270, 33, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 33, 540, 270, 540, 540, 540, 270, 540, 33, 270, 270, 270, 540, 33, 33, 540, 33, 540, 33, 33, 270, 33, 270, 540, 33, 33, 270, 33, 33, 33, 33, 33, 540, 270, 270, 540, 270, 33, 540, 540, 540, 270, 270, 33, 33, 33, 540, 33, 270, 270, 33, 540, 540, 540, 33, 33, 540, 270, 540, 540, 33, 540, 33, 270, 33, 33, 270, 270, 540, 540, 540, 33, 540, 270, 270, 33, 33, 33, 33, 540, 270, 540, 270, 540, 540, 540, 33, 270, 270, 540, 270, 540, 33, 33, 33, 270, 270, 270, 540, 540, 270, 540, 33, 270, 270, 33, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 33, 540, 33, 540, 270, 33, 270, 33, 33, 270, 270, 270, 540, 270, 33, 33]
Prompts retrieved: 45219 . Total input tokens: 10025903 . Total output tokens: 9036130
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.583948994986713,
    "estimated_duration": 3599.671000868137,
    "input_throughput": 1045.5069363540047,
    "output_throughput": 940.4053868210732,
    "total_throughput": 1985.912323175078,
    "itl": 23.17177955700513,
    "ttft": 6624.310278647483,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2755,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.012849263176117,
    "arrivals": 15306,
    "finished_requests": 15278,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5840277788229287. Arrivals time: 0.04891560971736908 Scheduler time: 1.1037446628324687 Scheduler overhead time: 0.1314200726337731 Adapter cache time: 0.10547743923962116 Engine time: 0.13028178876265883 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_160_slots_96_rate_0.05-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_160_slots_96_rate_0.05-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [53 53 54]
Adapter prompts. [33, 540, 33, 33, 270, 33, 33, 33, 540, 33, 270, 540, 270, 33, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 33, 540, 270, 540, 540, 540, 270, 540, 33, 270, 270, 270, 540, 33, 33, 540, 33, 540, 33, 33, 270, 33, 270, 540, 33, 33, 270, 33, 33, 33, 33, 33, 540, 270, 270, 540, 270, 33, 540, 540, 540, 270, 270, 33, 33, 33, 540, 33, 270, 270, 33, 540, 540, 540, 33, 33, 540, 270, 540, 540, 33, 540, 33, 270, 33, 33, 270, 270, 540, 540, 540, 33, 540, 270, 270, 33, 33, 33, 33, 540, 270, 540, 270, 540, 540, 540, 33, 270, 270, 540, 270, 540, 33, 33, 33, 270, 270, 270, 540, 540, 270, 540, 33, 270, 270, 33, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 33, 540, 33, 540, 270, 33, 270, 33, 33, 270, 270, 270, 540, 270, 33, 33]
Prompts retrieved: 45219 . Total input tokens: 10025903 . Total output tokens: 9036130
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 1.6162803233601153,
    "estimated_duration": 3599.6749736303486,
    "input_throughput": 1045.505782485814,
    "output_throughput": 940.4043489476508,
    "total_throughput": 1985.9101314334648,
    "itl": 23.168202869807974,
    "ttft": 6624.355141013897,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2757,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.64113190788759,
    "arrivals": 15306,
    "finished_requests": 15278,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6163595654070377. Arrivals time: 0.04969476442784071 Scheduler time: 1.1328104981221259 Scheduler overhead time: 0.13260312424972653 Adapter cache time: 0.1062905858270824 Engine time: 0.13063150877133012 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-32/adapters_160_slots_96_rate_0.05-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-32/adapters_160_slots_96_rate_0.05-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [53 53 54]
Adapter prompts. [33, 540, 33, 33, 270, 33, 33, 33, 540, 33, 270, 540, 270, 33, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 33, 540, 270, 540, 540, 540, 270, 540, 33, 270, 270, 270, 540, 33, 33, 540, 33, 540, 33, 33, 270, 33, 270, 540, 33, 33, 270, 33, 33, 33, 33, 33, 540, 270, 270, 540, 270, 33, 540, 540, 540, 270, 270, 33, 33, 33, 540, 33, 270, 270, 33, 540, 540, 540, 33, 33, 540, 270, 540, 540, 33, 540, 33, 270, 33, 33, 270, 270, 540, 540, 540, 33, 540, 270, 270, 33, 33, 33, 33, 540, 270, 540, 270, 540, 540, 540, 33, 270, 270, 540, 270, 540, 33, 33, 33, 270, 270, 270, 540, 540, 270, 540, 33, 270, 270, 33, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 33, 540, 33, 540, 270, 33, 270, 33, 33, 270, 270, 270, 540, 270, 33, 33]
Prompts retrieved: 45219 . Total input tokens: 10025903 . Total output tokens: 9036130
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 1.6310603790916502,
    "estimated_duration": 3599.6739028748275,
    "input_throughput": 1045.506093480954,
    "output_throughput": 940.4046286794198,
    "total_throughput": 1985.9107221603738,
    "itl": 23.17204955787206,
    "ttft": 6624.279660851572,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2755,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.124770133085212,
    "arrivals": 15306,
    "finished_requests": 15278,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6311367801390588. Arrivals time: 0.0504426178522408 Scheduler time: 1.1291595110669732 Scheduler overhead time: 0.138926908839494 Adapter cache time: 0.11017777165398002 Engine time: 0.13671253994107246 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_160_slots_96_rate_0.05-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_160_slots_96_rate_0.05-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [53 53 54]
Adapter prompts. [33, 540, 33, 33, 270, 33, 33, 33, 540, 33, 270, 540, 270, 33, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 33, 540, 270, 540, 540, 540, 270, 540, 33, 270, 270, 270, 540, 33, 33, 540, 33, 540, 33, 33, 270, 33, 270, 540, 33, 33, 270, 33, 33, 33, 33, 33, 540, 270, 270, 540, 270, 33, 540, 540, 540, 270, 270, 33, 33, 33, 540, 33, 270, 270, 33, 540, 540, 540, 33, 33, 540, 270, 540, 540, 33, 540, 33, 270, 33, 33, 270, 270, 540, 540, 540, 33, 540, 270, 270, 33, 33, 33, 33, 540, 270, 540, 270, 540, 540, 540, 33, 270, 270, 540, 270, 540, 33, 33, 33, 270, 270, 270, 540, 540, 270, 540, 33, 270, 270, 33, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 33, 540, 33, 540, 270, 33, 270, 33, 33, 270, 270, 270, 540, 270, 33, 33]
Prompts retrieved: 45219 . Total input tokens: 10025903 . Total output tokens: 9036130
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.6337660537101328,
    "estimated_duration": 3599.673787283604,
    "input_throughput": 1045.5061270538097,
    "output_throughput": 940.4046588773011,
    "total_throughput": 1985.910785931111,
    "itl": 23.165035713222764,
    "ttft": 6624.225311580716,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2756,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.24057861275021,
    "arrivals": 15306,
    "finished_requests": 15278,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6338506448082626. Arrivals time: 0.04994742479175329 Scheduler time: 1.1476227454841137 Scheduler overhead time: 0.13263802509754896 Adapter cache time: 0.1067937626503408 Engine time: 0.13248076383024454 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-32/adapters_160_slots_96_rate_0.05-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-32/adapters_160_slots_96_rate_0.05-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [53 53 54]
Adapter prompts. [33, 540, 33, 33, 270, 33, 33, 33, 540, 33, 270, 540, 270, 33, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 33, 540, 270, 540, 540, 540, 270, 540, 33, 270, 270, 270, 540, 33, 33, 540, 33, 540, 33, 33, 270, 33, 270, 540, 33, 33, 270, 33, 33, 33, 33, 33, 540, 270, 270, 540, 270, 33, 540, 540, 540, 270, 270, 33, 33, 33, 540, 33, 270, 270, 33, 540, 540, 540, 33, 33, 540, 270, 540, 540, 33, 540, 33, 270, 33, 33, 270, 270, 540, 540, 540, 33, 540, 270, 270, 33, 33, 33, 33, 540, 270, 540, 270, 540, 540, 540, 33, 270, 270, 540, 270, 540, 33, 33, 33, 270, 270, 270, 540, 540, 270, 540, 33, 270, 270, 33, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 33, 540, 33, 540, 270, 33, 270, 33, 33, 270, 270, 270, 540, 270, 33, 33]
Prompts retrieved: 45219 . Total input tokens: 10025903 . Total output tokens: 9036130
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.5790513991378248,
    "estimated_duration": 3599.6848177347647,
    "input_throughput": 1045.5057013486853,
    "output_throughput": 940.5979054940359,
    "total_throughput": 1986.1036068427213,
    "itl": 23.173977339934936,
    "ttft": 6389.210770795463,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2756,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.250046332329054,
    "arrivals": 15306,
    "finished_requests": 15279,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5791290742345154. Arrivals time: 0.04874323680996895 Scheduler time: 1.0994041115045547 Scheduler overhead time: 0.1323363482952118 Adapter cache time: 0.10518706403672695 Engine time: 0.12930716993287206 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_160_slots_96_rate_0.05-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_160_slots_96_rate_0.05-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [53 53 54]
Adapter prompts. [66, 540, 66, 66, 135, 66, 66, 66, 540, 66, 135, 540, 135, 66, 135, 135, 135, 135, 540, 540, 540, 135, 135, 135, 540, 540, 66, 540, 135, 540, 540, 540, 135, 540, 66, 135, 135, 135, 540, 66, 66, 540, 66, 540, 66, 66, 135, 66, 135, 540, 66, 66, 135, 66, 66, 66, 66, 66, 540, 135, 135, 540, 135, 66, 540, 540, 540, 135, 135, 66, 66, 66, 540, 66, 135, 135, 66, 540, 540, 540, 66, 66, 540, 135, 540, 540, 66, 540, 66, 135, 66, 66, 135, 135, 540, 540, 540, 66, 540, 135, 135, 66, 66, 66, 66, 540, 135, 540, 135, 540, 540, 540, 66, 135, 135, 540, 135, 540, 66, 66, 66, 135, 135, 135, 540, 540, 135, 540, 66, 135, 135, 66, 540, 540, 540, 540, 540, 540, 135, 135, 135, 135, 135, 540, 66, 540, 66, 540, 135, 66, 135, 66, 66, 135, 135, 135, 540, 135, 66, 66]
Prompts retrieved: 39813 . Total input tokens: 8823958 . Total output tokens: 7944526
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.4383696718141437,
    "estimated_duration": 3599.875302486249,
    "input_throughput": 920.4938286921837,
    "output_throughput": 810.9555900405113,
    "total_throughput": 1731.449418732695,
    "itl": 22.08141088978443,
    "ttft": 6442.666865320612,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2560,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.834848624468086,
    "arrivals": 13488,
    "finished_requests": 13464,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.438445049803704. Arrivals time: 0.04462682316079736 Scheduler time: 0.959277821239084 Scheduler overhead time: 0.13622849620878696 Adapter cache time: 0.0969858355820179 Engine time: 0.13479832326993346 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_160_slots_96_rate_0.05-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_160_slots_96_rate_0.05-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [53 53 54]
Adapter prompts. [66, 540, 66, 66, 135, 66, 66, 66, 540, 66, 135, 540, 135, 66, 135, 135, 135, 135, 540, 540, 540, 135, 135, 135, 540, 540, 66, 540, 135, 540, 540, 540, 135, 540, 66, 135, 135, 135, 540, 66, 66, 540, 66, 540, 66, 66, 135, 66, 135, 540, 66, 66, 135, 66, 66, 66, 66, 66, 540, 135, 135, 540, 135, 66, 540, 540, 540, 135, 135, 66, 66, 66, 540, 66, 135, 135, 66, 540, 540, 540, 66, 66, 540, 135, 540, 540, 66, 540, 66, 135, 66, 66, 135, 135, 540, 540, 540, 66, 540, 135, 135, 66, 66, 66, 66, 540, 135, 540, 135, 540, 540, 540, 66, 135, 135, 540, 135, 540, 66, 66, 66, 135, 135, 135, 540, 540, 135, 540, 66, 135, 135, 66, 540, 540, 540, 540, 540, 540, 135, 135, 135, 135, 135, 540, 66, 540, 66, 540, 135, 66, 135, 66, 66, 135, 135, 135, 540, 135, 66, 66]
Prompts retrieved: 39813 . Total input tokens: 8823958 . Total output tokens: 7944526
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.4472541720606387,
    "estimated_duration": 3599.862526385933,
    "input_throughput": 920.4970955729074,
    "output_throughput": 810.9584681642991,
    "total_throughput": 1731.4555637372064,
    "itl": 22.084938640089568,
    "ttft": 6442.709077302374,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2560,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.348732200979429,
    "arrivals": 13488,
    "finished_requests": 13464,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4473341829143465. Arrivals time: 0.04491841187700629 Scheduler time: 0.9704236164689064 Scheduler overhead time: 0.1357245994731784 Adapter cache time: 0.09734183456748724 Engine time: 0.13257029745727777 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-32/adapters_160_slots_96_rate_0.05-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-32/adapters_160_slots_96_rate_0.05-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [53 53 54]
Adapter prompts. [66, 540, 66, 66, 135, 66, 66, 66, 540, 66, 135, 540, 135, 66, 135, 135, 135, 135, 540, 540, 540, 135, 135, 135, 540, 540, 66, 540, 135, 540, 540, 540, 135, 540, 66, 135, 135, 135, 540, 66, 66, 540, 66, 540, 66, 66, 135, 66, 135, 540, 66, 66, 135, 66, 66, 66, 66, 66, 540, 135, 135, 540, 135, 66, 540, 540, 540, 135, 135, 66, 66, 66, 540, 66, 135, 135, 66, 540, 540, 540, 66, 66, 540, 135, 540, 540, 66, 540, 66, 135, 66, 66, 135, 135, 540, 540, 540, 66, 540, 135, 135, 66, 66, 66, 66, 540, 135, 540, 135, 540, 540, 540, 66, 135, 135, 540, 135, 540, 66, 66, 66, 135, 135, 135, 540, 540, 135, 540, 66, 135, 135, 66, 540, 540, 540, 540, 540, 540, 135, 135, 135, 135, 135, 540, 66, 540, 66, 540, 135, 66, 135, 66, 66, 135, 135, 135, 540, 135, 66, 66]
Prompts retrieved: 39813 . Total input tokens: 8823958 . Total output tokens: 7944526
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.4544512908905745,
    "estimated_duration": 3599.8588134260585,
    "input_throughput": 920.4980449903588,
    "output_throughput": 810.9593046016174,
    "total_throughput": 1731.4573495919763,
    "itl": 22.08631995540298,
    "ttft": 6442.688721906857,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2561,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.36777251239856,
    "arrivals": 13488,
    "finished_requests": 13464,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4545237221755087. Arrivals time: 0.04507895838469267 Scheduler time: 0.9738323139026761 Scheduler overhead time: 0.13583718379959464 Adapter cache time: 0.09721814002841711 Engine time: 0.1352966921404004 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_160_slots_96_rate_0.05-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_160_slots_96_rate_0.05-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [53 53 54]
Adapter prompts. [66, 540, 66, 66, 135, 66, 66, 66, 540, 66, 135, 540, 135, 66, 135, 135, 135, 135, 540, 540, 540, 135, 135, 135, 540, 540, 66, 540, 135, 540, 540, 540, 135, 540, 66, 135, 135, 135, 540, 66, 66, 540, 66, 540, 66, 66, 135, 66, 135, 540, 66, 66, 135, 66, 66, 66, 66, 66, 540, 135, 135, 540, 135, 66, 540, 540, 540, 135, 135, 66, 66, 66, 540, 66, 135, 135, 66, 540, 540, 540, 66, 66, 540, 135, 540, 540, 66, 540, 66, 135, 66, 66, 135, 135, 540, 540, 540, 66, 540, 135, 135, 66, 66, 66, 66, 540, 135, 540, 135, 540, 540, 540, 66, 135, 135, 540, 135, 540, 66, 66, 66, 135, 135, 135, 540, 540, 135, 540, 66, 135, 135, 66, 540, 540, 540, 540, 540, 540, 135, 135, 135, 135, 135, 540, 66, 540, 66, 540, 135, 66, 135, 66, 66, 135, 135, 135, 540, 135, 66, 66]
Prompts retrieved: 39813 . Total input tokens: 8823958 . Total output tokens: 7944526
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 1.4732362958602607,
    "estimated_duration": 3599.865296734312,
    "input_throughput": 920.4963871859467,
    "output_throughput": 810.9578440749812,
    "total_throughput": 1731.4542312609278,
    "itl": 22.083048541905555,
    "ttft": 6442.571641707723,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2561,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.014222518242594,
    "arrivals": 13488,
    "finished_requests": 13464,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4733129870146513. Arrivals time: 0.04534074943512678 Scheduler time: 0.9878184339031577 Scheduler overhead time: 0.13851010287180543 Adapter cache time: 0.09760154504328966 Engine time: 0.13631752040237188 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-32/adapters_160_slots_96_rate_0.05-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-32/adapters_160_slots_96_rate_0.05-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [53 53 54]
Adapter prompts. [66, 540, 66, 66, 135, 66, 66, 66, 540, 66, 135, 540, 135, 66, 135, 135, 135, 135, 540, 540, 540, 135, 135, 135, 540, 540, 66, 540, 135, 540, 540, 540, 135, 540, 66, 135, 135, 135, 540, 66, 66, 540, 66, 540, 66, 66, 135, 66, 135, 540, 66, 66, 135, 66, 66, 66, 66, 66, 540, 135, 135, 540, 135, 66, 540, 540, 540, 135, 135, 66, 66, 66, 540, 66, 135, 135, 66, 540, 540, 540, 66, 66, 540, 135, 540, 540, 66, 540, 66, 135, 66, 66, 135, 135, 540, 540, 540, 66, 540, 135, 135, 66, 66, 66, 66, 540, 135, 540, 135, 540, 540, 540, 66, 135, 135, 540, 135, 540, 66, 66, 66, 135, 135, 135, 540, 540, 135, 540, 66, 135, 135, 66, 540, 540, 540, 540, 540, 540, 135, 135, 135, 135, 135, 540, 66, 540, 66, 540, 135, 66, 135, 66, 66, 135, 135, 135, 540, 135, 66, 66]
Prompts retrieved: 39813 . Total input tokens: 8823958 . Total output tokens: 7944526
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 1.4565509939566255,
    "estimated_duration": 3599.8699754545514,
    "input_throughput": 920.4951908246596,
    "output_throughput": 810.9567900800024,
    "total_throughput": 1731.451980904662,
    "itl": 22.08723803819805,
    "ttft": 6442.642635599496,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2561,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.471770893763496,
    "arrivals": 13488,
    "finished_requests": 13464,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.45662686182186. Arrivals time: 0.04534355504438281 Scheduler time: 0.9758113697171211 Scheduler overhead time: 0.1359922895208001 Adapter cache time: 0.09703964041545987 Engine time: 0.1358449519611895 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_160_slots_96_rate_0.05-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_160_slots_96_rate_0.05-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [53 53 54]
Adapter prompts. [66, 540, 66, 66, 135, 66, 66, 66, 540, 66, 135, 540, 135, 66, 135, 135, 135, 135, 540, 540, 540, 135, 135, 135, 540, 540, 66, 540, 135, 540, 540, 540, 135, 540, 66, 135, 135, 135, 540, 66, 66, 540, 66, 540, 66, 66, 135, 66, 135, 540, 66, 66, 135, 66, 66, 66, 66, 66, 540, 135, 135, 540, 135, 66, 540, 540, 540, 135, 135, 66, 66, 66, 540, 66, 135, 135, 66, 540, 540, 540, 66, 66, 540, 135, 540, 540, 66, 540, 66, 135, 66, 66, 135, 135, 540, 540, 540, 66, 540, 135, 135, 66, 66, 66, 66, 540, 135, 540, 135, 540, 540, 540, 66, 135, 135, 540, 135, 540, 66, 66, 66, 135, 135, 135, 540, 540, 135, 540, 66, 135, 135, 66, 540, 540, 540, 540, 540, 540, 135, 135, 135, 135, 135, 540, 66, 540, 66, 540, 135, 66, 135, 66, 66, 135, 135, 135, 540, 135, 66, 66]
Prompts retrieved: 39813 . Total input tokens: 8823958 . Total output tokens: 7944526
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.4532976588234305,
    "estimated_duration": 3599.87347904264,
    "input_throughput": 920.4942949498449,
    "output_throughput": 810.9560008137777,
    "total_throughput": 1731.4502957636225,
    "itl": 22.080573719908006,
    "ttft": 6442.519377364361,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2561,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.657518805244236,
    "arrivals": 13488,
    "finished_requests": 13464,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.45336736086756. Arrivals time: 0.0445526042021811 Scheduler time: 0.9742898833937943 Scheduler overhead time: 0.1375149693340063 Adapter cache time: 0.096864462364465 Engine time: 0.1329023470170796 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-32/adapters_160_slots_96_rate_0.05-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-32/adapters_160_slots_96_rate_0.05-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [53 53 54]
Adapter prompts. [66, 540, 66, 66, 135, 66, 66, 66, 540, 66, 135, 540, 135, 66, 135, 135, 135, 135, 540, 540, 540, 135, 135, 135, 540, 540, 66, 540, 135, 540, 540, 540, 135, 540, 66, 135, 135, 135, 540, 66, 66, 540, 66, 540, 66, 66, 135, 66, 135, 540, 66, 66, 135, 66, 66, 66, 66, 66, 540, 135, 135, 540, 135, 66, 540, 540, 540, 135, 135, 66, 66, 66, 540, 66, 135, 135, 66, 540, 540, 540, 66, 66, 540, 135, 540, 540, 66, 540, 66, 135, 66, 66, 135, 135, 540, 540, 540, 66, 540, 135, 135, 66, 66, 66, 66, 540, 135, 540, 135, 540, 540, 540, 66, 135, 135, 540, 135, 540, 66, 66, 66, 135, 135, 135, 540, 540, 135, 540, 66, 135, 135, 66, 540, 540, 540, 540, 540, 540, 135, 135, 135, 135, 135, 540, 66, 540, 66, 540, 135, 66, 135, 66, 66, 135, 135, 135, 540, 135, 66, 66]
Prompts retrieved: 39813 . Total input tokens: 8823958 . Total output tokens: 7944526
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.4570426139980555,
    "estimated_duration": 3599.856455146333,
    "input_throughput": 920.4986480121472,
    "output_throughput": 810.9598358641581,
    "total_throughput": 1731.4584838763053,
    "itl": 22.08692694992671,
    "ttft": 6442.739101751879,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2560,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.578047429173793,
    "arrivals": 13488,
    "finished_requests": 13464,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4571165391243994. Arrivals time: 0.045106619130820036 Scheduler time: 0.9770277966745198 Scheduler overhead time: 0.135916480794549 Adapter cache time: 0.09715465409681201 Engine time: 0.13487094221636653 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_160_slots_96_rate_0.05-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_160_slots_96_rate_0.05-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [53 53 54]
Adapter prompts. [33, 540, 33, 33, 135, 33, 33, 33, 540, 33, 135, 540, 135, 33, 135, 135, 135, 135, 540, 540, 540, 135, 135, 135, 540, 540, 33, 540, 135, 540, 540, 540, 135, 540, 33, 135, 135, 135, 540, 33, 33, 540, 33, 540, 33, 33, 135, 33, 135, 540, 33, 33, 135, 33, 33, 33, 33, 33, 540, 135, 135, 540, 135, 33, 540, 540, 540, 135, 135, 33, 33, 33, 540, 33, 135, 135, 33, 540, 540, 540, 33, 33, 540, 135, 540, 540, 33, 540, 33, 135, 33, 33, 135, 135, 540, 540, 540, 33, 540, 135, 135, 33, 33, 33, 33, 540, 135, 540, 135, 540, 540, 540, 33, 135, 135, 540, 135, 540, 33, 33, 33, 135, 135, 135, 540, 540, 135, 540, 33, 135, 135, 33, 540, 540, 540, 540, 540, 540, 135, 135, 135, 135, 135, 540, 33, 540, 33, 540, 135, 33, 135, 33, 33, 135, 135, 135, 540, 135, 33, 33]
Prompts retrieved: 38064 . Total input tokens: 8436520 . Total output tokens: 7585704
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.466462877113372,
    "estimated_duration": 3599.616278515594,
    "input_throughput": 880.6963728109683,
    "output_throughput": 786.6674614461223,
    "total_throughput": 1667.3638342570905,
    "itl": 21.849395055318606,
    "ttft": 4229.563403785939,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1730,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.294643797003812,
    "arrivals": 12878,
    "finished_requests": 12863,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4665446979925036. Arrivals time: 0.044159711338579655 Scheduler time: 0.9851084416732192 Scheduler overhead time: 0.140430998057127 Adapter cache time: 0.09256967576220632 Engine time: 0.13589713163673878 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_160_slots_96_rate_0.05-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_160_slots_96_rate_0.05-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [53 53 54]
Adapter prompts. [33, 540, 33, 33, 135, 33, 33, 33, 540, 33, 135, 540, 135, 33, 135, 135, 135, 135, 540, 540, 540, 135, 135, 135, 540, 540, 33, 540, 135, 540, 540, 540, 135, 540, 33, 135, 135, 135, 540, 33, 33, 540, 33, 540, 33, 33, 135, 33, 135, 540, 33, 33, 135, 33, 33, 33, 33, 33, 540, 135, 135, 540, 135, 33, 540, 540, 540, 135, 135, 33, 33, 33, 540, 33, 135, 135, 33, 540, 540, 540, 33, 33, 540, 135, 540, 540, 33, 540, 33, 135, 33, 33, 135, 135, 540, 540, 540, 33, 540, 135, 135, 33, 33, 33, 33, 540, 135, 540, 135, 540, 540, 540, 33, 135, 135, 540, 135, 540, 33, 33, 33, 135, 135, 135, 540, 540, 135, 540, 33, 135, 135, 33, 540, 540, 540, 540, 540, 540, 135, 135, 135, 135, 135, 540, 33, 540, 33, 540, 135, 33, 135, 33, 33, 135, 135, 135, 540, 135, 33, 33]
Prompts retrieved: 38064 . Total input tokens: 8436520 . Total output tokens: 7585704
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.4327094578184187,
    "estimated_duration": 3599.606645169651,
    "input_throughput": 880.6987297498415,
    "output_throughput": 786.6695667427686,
    "total_throughput": 1667.36829649261,
    "itl": 21.851387045579745,
    "ttft": 4229.6610231667155,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1732,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.646200155066183,
    "arrivals": 12878,
    "finished_requests": 12863,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4327881927601993. Arrivals time: 0.04345533763989806 Scheduler time: 0.9570094142109156 Scheduler overhead time: 0.13680837955325842 Adapter cache time: 0.09195055766031146 Engine time: 0.13652103766798973 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-32/adapters_160_slots_96_rate_0.05-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-32/adapters_160_slots_96_rate_0.05-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [53 53 54]
Adapter prompts. [33, 540, 33, 33, 135, 33, 33, 33, 540, 33, 135, 540, 135, 33, 135, 135, 135, 135, 540, 540, 540, 135, 135, 135, 540, 540, 33, 540, 135, 540, 540, 540, 135, 540, 33, 135, 135, 135, 540, 33, 33, 540, 33, 540, 33, 33, 135, 33, 135, 540, 33, 33, 135, 33, 33, 33, 33, 33, 540, 135, 135, 540, 135, 33, 540, 540, 540, 135, 135, 33, 33, 33, 540, 33, 135, 135, 33, 540, 540, 540, 33, 33, 540, 135, 540, 540, 33, 540, 33, 135, 33, 33, 135, 135, 540, 540, 540, 33, 540, 135, 135, 33, 33, 33, 33, 540, 135, 540, 135, 540, 540, 540, 33, 135, 135, 540, 135, 540, 33, 33, 33, 135, 135, 135, 540, 540, 135, 540, 33, 135, 135, 33, 540, 540, 540, 540, 540, 540, 135, 135, 135, 135, 135, 540, 33, 540, 33, 540, 135, 33, 135, 33, 33, 135, 135, 135, 540, 135, 33, 33]
Prompts retrieved: 38064 . Total input tokens: 8436520 . Total output tokens: 7585704
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.4275773628614843,
    "estimated_duration": 3599.6155008486553,
    "input_throughput": 880.6965630780821,
    "output_throughput": 786.6676313990731,
    "total_throughput": 1667.3641944771553,
    "itl": 21.85179169680861,
    "ttft": 4229.690735522546,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1731,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.653805013466571,
    "arrivals": 12878,
    "finished_requests": 12863,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4276536139659584. Arrivals time: 0.04398933332413435 Scheduler time: 0.9495210652239621 Scheduler overhead time: 0.13832760648801923 Adapter cache time: 0.09215225605294108 Engine time: 0.136572090908885 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-16/adapters_160_slots_96_rate_0.05-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-16/adapters_160_slots_96_rate_0.05-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [53 53 54]
Adapter prompts. [33, 540, 33, 33, 135, 33, 33, 33, 540, 33, 135, 540, 135, 33, 135, 135, 135, 135, 540, 540, 540, 135, 135, 135, 540, 540, 33, 540, 135, 540, 540, 540, 135, 540, 33, 135, 135, 135, 540, 33, 33, 540, 33, 540, 33, 33, 135, 33, 135, 540, 33, 33, 135, 33, 33, 33, 33, 33, 540, 135, 135, 540, 135, 33, 540, 540, 540, 135, 135, 33, 33, 33, 540, 33, 135, 135, 33, 540, 540, 540, 33, 33, 540, 135, 540, 540, 33, 540, 33, 135, 33, 33, 135, 135, 540, 540, 540, 33, 540, 135, 135, 33, 33, 33, 33, 540, 135, 540, 135, 540, 540, 540, 33, 135, 135, 540, 135, 540, 33, 33, 33, 135, 135, 135, 540, 540, 135, 540, 33, 135, 135, 33, 540, 540, 540, 540, 540, 540, 135, 135, 135, 135, 135, 540, 33, 540, 33, 540, 135, 33, 135, 33, 33, 135, 135, 135, 540, 135, 33, 33]
Prompts retrieved: 38064 . Total input tokens: 8436520 . Total output tokens: 7585704
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 1.4290542853996158,
    "estimated_duration": 3599.611943894525,
    "input_throughput": 880.6974333378007,
    "output_throughput": 786.668408744166,
    "total_throughput": 1667.3658420819668,
    "itl": 21.8505344872669,
    "ttft": 4229.580501720704,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1731,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.420525656221299,
    "arrivals": 12878,
    "finished_requests": 12863,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4291377170011401. Arrivals time: 0.043726242147386074 Scheduler time: 0.9538133810274303 Scheduler overhead time: 0.13784141279757023 Adapter cache time: 0.09190510818734765 Engine time: 0.13486542087048292 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-32/adapters_160_slots_96_rate_0.05-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-32/adapters_160_slots_96_rate_0.05-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [53 53 54]
Adapter prompts. [33, 540, 33, 33, 135, 33, 33, 33, 540, 33, 135, 540, 135, 33, 135, 135, 135, 135, 540, 540, 540, 135, 135, 135, 540, 540, 33, 540, 135, 540, 540, 540, 135, 540, 33, 135, 135, 135, 540, 33, 33, 540, 33, 540, 33, 33, 135, 33, 135, 540, 33, 33, 135, 33, 33, 33, 33, 33, 540, 135, 135, 540, 135, 33, 540, 540, 540, 135, 135, 33, 33, 33, 540, 33, 135, 135, 33, 540, 540, 540, 33, 33, 540, 135, 540, 540, 33, 540, 33, 135, 33, 33, 135, 135, 540, 540, 540, 33, 540, 135, 135, 33, 33, 33, 33, 540, 135, 540, 135, 540, 540, 540, 33, 135, 135, 540, 135, 540, 33, 33, 33, 135, 135, 135, 540, 540, 135, 540, 33, 135, 135, 33, 540, 540, 540, 540, 540, 540, 135, 135, 135, 135, 135, 540, 33, 540, 33, 540, 135, 33, 135, 33, 33, 135, 135, 135, 540, 135, 33, 33]
Prompts retrieved: 38064 . Total input tokens: 8436520 . Total output tokens: 7585704
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 1.4439666043035686,
    "estimated_duration": 3599.6133918956325,
    "input_throughput": 880.6970790634052,
    "output_throughput": 786.6680922944246,
    "total_throughput": 1667.3651713578297,
    "itl": 21.852841382542906,
    "ttft": 4229.7156492558615,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1731,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.72221507327623,
    "arrivals": 12878,
    "finished_requests": 12863,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4440408451482654. Arrivals time: 0.044248541351407766 Scheduler time: 0.9615524159744382 Scheduler overhead time: 0.13891478162258863 Adapter cache time: 0.09272279543802142 Engine time: 0.13889335887506604 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-16/adapters_160_slots_96_rate_0.05-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-16/adapters_160_slots_96_rate_0.05-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [53 53 54]
Adapter prompts. [33, 540, 33, 33, 135, 33, 33, 33, 540, 33, 135, 540, 135, 33, 135, 135, 135, 135, 540, 540, 540, 135, 135, 135, 540, 540, 33, 540, 135, 540, 540, 540, 135, 540, 33, 135, 135, 135, 540, 33, 33, 540, 33, 540, 33, 33, 135, 33, 135, 540, 33, 33, 135, 33, 33, 33, 33, 33, 540, 135, 135, 540, 135, 33, 540, 540, 540, 135, 135, 33, 33, 33, 540, 33, 135, 135, 33, 540, 540, 540, 33, 33, 540, 135, 540, 540, 33, 540, 33, 135, 33, 33, 135, 135, 540, 540, 540, 33, 540, 135, 135, 33, 33, 33, 33, 540, 135, 540, 135, 540, 540, 540, 33, 135, 135, 540, 135, 540, 33, 33, 33, 135, 135, 135, 540, 540, 135, 540, 33, 135, 135, 33, 540, 540, 540, 540, 540, 540, 135, 135, 135, 135, 135, 540, 33, 540, 33, 540, 135, 33, 135, 33, 33, 135, 135, 135, 540, 135, 33, 33]
Prompts retrieved: 38064 . Total input tokens: 8436520 . Total output tokens: 7585704
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.4445781060494483,
    "estimated_duration": 3599.6076965321627,
    "input_throughput": 880.6984725180245,
    "output_throughput": 786.6693369747046,
    "total_throughput": 1667.367809492729,
    "itl": 21.84870608755701,
    "ttft": 4229.536717351524,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1730,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.172787010180617,
    "arrivals": 12878,
    "finished_requests": 12863,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4446506397798657. Arrivals time: 0.04339046869426966 Scheduler time: 0.9588318187743425 Scheduler overhead time: 0.14562902133911848 Adapter cache time: 0.09244924271479249 Engine time: 0.13615367421880364 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-32/adapters_160_slots_96_rate_0.05-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-32/adapters_160_slots_96_rate_0.05-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [53 53 54]
Adapter prompts. [33, 540, 33, 33, 135, 33, 33, 33, 540, 33, 135, 540, 135, 33, 135, 135, 135, 135, 540, 540, 540, 135, 135, 135, 540, 540, 33, 540, 135, 540, 540, 540, 135, 540, 33, 135, 135, 135, 540, 33, 33, 540, 33, 540, 33, 33, 135, 33, 135, 540, 33, 33, 135, 33, 33, 33, 33, 33, 540, 135, 135, 540, 135, 33, 540, 540, 540, 135, 135, 33, 33, 33, 540, 33, 135, 135, 33, 540, 540, 540, 33, 33, 540, 135, 540, 540, 33, 540, 33, 135, 33, 33, 135, 135, 540, 540, 540, 33, 540, 135, 135, 33, 33, 33, 33, 540, 135, 540, 135, 540, 540, 540, 33, 135, 135, 540, 135, 540, 33, 33, 33, 135, 135, 135, 540, 540, 135, 540, 33, 135, 135, 33, 540, 540, 540, 540, 540, 540, 135, 135, 135, 135, 135, 540, 33, 540, 33, 540, 135, 33, 135, 33, 33, 135, 135, 135, 540, 135, 33, 33]
Prompts retrieved: 38064 . Total input tokens: 8436520 . Total output tokens: 7585704
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.4189547430723906,
    "estimated_duration": 3599.626320863367,
    "input_throughput": 880.6939158172502,
    "output_throughput": 786.6652667771413,
    "total_throughput": 1667.3591825943915,
    "itl": 21.852885153792286,
    "ttft": 4229.687054807961,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1731,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.797541591338696,
    "arrivals": 12878,
    "finished_requests": 12863,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4190321392379701. Arrivals time: 0.04362163878977299 Scheduler time: 0.9428022284992039 Scheduler overhead time: 0.13713450729846954 Adapter cache time: 0.09120099572464824 Engine time: 0.13707156106829643 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-8/adapters_160_slots_96_rate_0.05-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-8/adapters_160_slots_96_rate_0.05-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [53 53 54]
Adapter prompts. [33, 540, 33, 33, 66, 33, 33, 33, 540, 33, 66, 540, 66, 33, 66, 66, 66, 66, 540, 540, 540, 66, 66, 66, 540, 540, 33, 540, 66, 540, 540, 540, 66, 540, 33, 66, 66, 66, 540, 33, 33, 540, 33, 540, 33, 33, 66, 33, 66, 540, 33, 33, 66, 33, 33, 33, 33, 33, 540, 66, 66, 540, 66, 33, 540, 540, 540, 66, 66, 33, 33, 33, 540, 33, 66, 66, 33, 540, 540, 540, 33, 33, 540, 66, 540, 540, 33, 540, 33, 66, 33, 33, 66, 66, 540, 540, 540, 33, 540, 66, 66, 33, 33, 33, 33, 540, 66, 540, 66, 540, 540, 540, 33, 66, 66, 540, 66, 540, 33, 33, 33, 66, 66, 66, 540, 540, 66, 540, 33, 66, 66, 33, 540, 540, 540, 540, 540, 540, 66, 66, 66, 66, 66, 540, 33, 540, 33, 540, 66, 33, 66, 33, 33, 66, 66, 66, 540, 66, 33, 33]
Prompts retrieved: 34407 . Total input tokens: 7613207 . Total output tokens: 6870626
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.335654296912253,
    "estimated_duration": 3599.8721124206845,
    "input_throughput": 797.1741524090679,
    "output_throughput": 700.3582130879238,
    "total_throughput": 1497.5323654969916,
    "itl": 21.26629498257141,
    "ttft": 5910.45235549624,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1121,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4308067609487,
    "arrivals": 11642,
    "finished_requests": 11623,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3357175569981337. Arrivals time: 0.04036673437803984 Scheduler time: 0.8650224916636944 Scheduler overhead time: 0.1397923994809389 Adapter cache time: 0.0838985275477171 Engine time: 0.13811265118420124 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-16/adapters_160_slots_96_rate_0.05-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-16/adapters_160_slots_96_rate_0.05-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [53 53 54]
Adapter prompts. [33, 540, 33, 33, 66, 33, 33, 33, 540, 33, 66, 540, 66, 33, 66, 66, 66, 66, 540, 540, 540, 66, 66, 66, 540, 540, 33, 540, 66, 540, 540, 540, 66, 540, 33, 66, 66, 66, 540, 33, 33, 540, 33, 540, 33, 33, 66, 33, 66, 540, 33, 33, 66, 33, 33, 33, 33, 33, 540, 66, 66, 540, 66, 33, 540, 540, 540, 66, 66, 33, 33, 33, 540, 33, 66, 66, 33, 540, 540, 540, 33, 33, 540, 66, 540, 540, 33, 540, 33, 66, 33, 33, 66, 66, 540, 540, 540, 33, 540, 66, 66, 33, 33, 33, 33, 540, 66, 540, 66, 540, 540, 540, 33, 66, 66, 540, 66, 540, 33, 33, 33, 66, 66, 66, 540, 540, 66, 540, 33, 66, 66, 33, 540, 540, 540, 540, 540, 540, 66, 66, 66, 66, 66, 540, 33, 540, 33, 540, 66, 33, 66, 33, 33, 66, 66, 66, 540, 66, 33, 33]
Prompts retrieved: 34407 . Total input tokens: 7613207 . Total output tokens: 6870626
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.3349132682196796,
    "estimated_duration": 3599.8776409817738,
    "input_throughput": 797.1729281380121,
    "output_throughput": 700.3571375032647,
    "total_throughput": 1497.5300656412767,
    "itl": 21.26749256184424,
    "ttft": 5910.639817958216,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1122,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.659648538436746,
    "arrivals": 11642,
    "finished_requests": 11623,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3349844152107835. Arrivals time: 0.040642072446644306 Scheduler time: 0.8630392733030021 Scheduler overhead time: 0.14146936824545264 Adapter cache time: 0.08440722897648811 Engine time: 0.13653758820146322 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-32/adapters_160_slots_96_rate_0.05-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-32/adapters_160_slots_96_rate_0.05-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [53 53 54]
Adapter prompts. [33, 540, 33, 33, 66, 33, 33, 33, 540, 33, 66, 540, 66, 33, 66, 66, 66, 66, 540, 540, 540, 66, 66, 66, 540, 540, 33, 540, 66, 540, 540, 540, 66, 540, 33, 66, 66, 66, 540, 33, 33, 540, 33, 540, 33, 33, 66, 33, 66, 540, 33, 33, 66, 33, 33, 33, 33, 33, 540, 66, 66, 540, 66, 33, 540, 540, 540, 66, 66, 33, 33, 33, 540, 33, 66, 66, 33, 540, 540, 540, 33, 33, 540, 66, 540, 540, 33, 540, 33, 66, 33, 33, 66, 66, 540, 540, 540, 33, 540, 66, 66, 33, 33, 33, 33, 540, 66, 540, 66, 540, 540, 540, 33, 66, 66, 540, 66, 540, 33, 33, 33, 66, 66, 66, 540, 540, 66, 540, 33, 66, 66, 33, 540, 540, 540, 540, 540, 540, 66, 66, 66, 66, 66, 540, 33, 540, 33, 540, 66, 33, 66, 33, 33, 66, 66, 66, 540, 66, 33, 33]
Prompts retrieved: 34407 . Total input tokens: 7613207 . Total output tokens: 6870626
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.334025191143155,
    "estimated_duration": 3599.859361401424,
    "input_throughput": 797.1769760702032,
    "output_throughput": 700.3606938184656,
    "total_throughput": 1497.537669888669,
    "itl": 21.267773315634376,
    "ttft": 5910.466039285468,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1121,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.663034012895026,
    "arrivals": 11642,
    "finished_requests": 11623,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.33410335611552. Arrivals time: 0.040956408716738224 Scheduler time: 0.8624739800579846 Scheduler overhead time: 0.13930549658834934 Adapter cache time: 0.08395798690617085 Engine time: 0.13919512834399939 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-16/adapters_160_slots_96_rate_0.05-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-16/adapters_160_slots_96_rate_0.05-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [53 53 54]
Adapter prompts. [33, 540, 33, 33, 66, 33, 33, 33, 540, 33, 66, 540, 66, 33, 66, 66, 66, 66, 540, 540, 540, 66, 66, 66, 540, 540, 33, 540, 66, 540, 540, 540, 66, 540, 33, 66, 66, 66, 540, 33, 33, 540, 33, 540, 33, 33, 66, 33, 66, 540, 33, 33, 66, 33, 33, 33, 33, 33, 540, 66, 66, 540, 66, 33, 540, 540, 540, 66, 66, 33, 33, 33, 540, 33, 66, 66, 33, 540, 540, 540, 33, 33, 540, 66, 540, 540, 33, 540, 33, 66, 33, 33, 66, 66, 540, 540, 540, 33, 540, 66, 66, 33, 33, 33, 33, 540, 66, 540, 66, 540, 540, 540, 33, 66, 66, 540, 66, 540, 33, 33, 33, 66, 66, 66, 540, 540, 66, 540, 33, 66, 66, 33, 540, 540, 540, 540, 540, 540, 66, 66, 66, 66, 66, 540, 33, 540, 33, 540, 66, 33, 66, 33, 33, 66, 66, 66, 540, 66, 33, 33]
Prompts retrieved: 34407 . Total input tokens: 7613207 . Total output tokens: 6870626
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 1.3416304169222713,
    "estimated_duration": 3599.8791578191694,
    "input_throughput": 797.1725922429291,
    "output_throughput": 700.3568424022765,
    "total_throughput": 1497.5294346452056,
    "itl": 21.266591809842755,
    "ttft": 5910.478753514101,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1122,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.512145628479737,
    "arrivals": 11642,
    "finished_requests": 11623,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3417138932272792. Arrivals time: 0.04077533446252346 Scheduler time: 0.8692683121189475 Scheduler overhead time: 0.14033624157309532 Adapter cache time: 0.08401432679966092 Engine time: 0.13880287297070026 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-32/adapters_160_slots_96_rate_0.05-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-32/adapters_160_slots_96_rate_0.05-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [53 53 54]
Adapter prompts. [33, 540, 33, 33, 66, 33, 33, 33, 540, 33, 66, 540, 66, 33, 66, 66, 66, 66, 540, 540, 540, 66, 66, 66, 540, 540, 33, 540, 66, 540, 540, 540, 66, 540, 33, 66, 66, 66, 540, 33, 33, 540, 33, 540, 33, 33, 66, 33, 66, 540, 33, 33, 66, 33, 33, 33, 33, 33, 540, 66, 66, 540, 66, 33, 540, 540, 540, 66, 66, 33, 33, 33, 540, 33, 66, 66, 33, 540, 540, 540, 33, 33, 540, 66, 540, 540, 33, 540, 33, 66, 33, 33, 66, 66, 540, 540, 540, 33, 540, 66, 66, 33, 33, 33, 33, 540, 66, 540, 66, 540, 540, 540, 33, 66, 66, 540, 66, 540, 33, 33, 33, 66, 66, 66, 540, 540, 66, 540, 33, 66, 66, 33, 540, 540, 540, 540, 540, 540, 66, 66, 66, 66, 66, 540, 33, 540, 33, 540, 66, 33, 66, 33, 33, 66, 66, 66, 540, 66, 33, 33]
Prompts retrieved: 34407 . Total input tokens: 7613207 . Total output tokens: 6870626
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 1.3458594707772136,
    "estimated_duration": 3599.8643900500183,
    "input_throughput": 797.175862494122,
    "output_throughput": 700.3597154849962,
    "total_throughput": 1497.5355779791182,
    "itl": 21.267562365909843,
    "ttft": 5910.591077469471,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1121,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7083053760044264,
    "arrivals": 11642,
    "finished_requests": 11623,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3459415836259723. Arrivals time: 0.04116601776331663 Scheduler time: 0.8715189667418599 Scheduler overhead time: 0.1400057408027351 Adapter cache time: 0.08468065736815333 Engine time: 0.14025118621066213 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-16/adapters_160_slots_96_rate_0.05-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-16/adapters_160_slots_96_rate_0.05-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [53 53 54]
Adapter prompts. [33, 540, 33, 33, 66, 33, 33, 33, 540, 33, 66, 540, 66, 33, 66, 66, 66, 66, 540, 540, 540, 66, 66, 66, 540, 540, 33, 540, 66, 540, 540, 540, 66, 540, 33, 66, 66, 66, 540, 33, 33, 540, 33, 540, 33, 33, 66, 33, 66, 540, 33, 33, 66, 33, 33, 33, 33, 33, 540, 66, 66, 540, 66, 33, 540, 540, 540, 66, 66, 33, 33, 33, 540, 33, 66, 66, 33, 540, 540, 540, 33, 33, 540, 66, 540, 540, 33, 540, 33, 66, 33, 33, 66, 66, 540, 540, 540, 33, 540, 66, 66, 33, 33, 33, 33, 540, 66, 540, 66, 540, 540, 540, 33, 66, 66, 540, 66, 540, 33, 33, 33, 66, 66, 66, 540, 540, 66, 540, 33, 66, 66, 33, 540, 540, 540, 540, 540, 540, 66, 66, 66, 66, 66, 540, 33, 540, 33, 540, 66, 33, 66, 33, 33, 66, 66, 66, 540, 66, 33, 33]
Prompts retrieved: 34407 . Total input tokens: 7613207 . Total output tokens: 6870626
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.3283927482552826,
    "estimated_duration": 3599.8759328354377,
    "input_throughput": 797.1733063977193,
    "output_throughput": 700.3574698237392,
    "total_throughput": 1497.5307762214586,
    "itl": 21.26486310244402,
    "ttft": 5910.5461962451,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1122,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.354836430880159,
    "arrivals": 11642,
    "finished_requests": 11623,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3284651972353458. Arrivals time: 0.04063742747530341 Scheduler time: 0.8578471634536982 Scheduler overhead time: 0.13996592769399285 Adapter cache time: 0.08372522797435522 Engine time: 0.13766789296641946 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-32/adapters_160_slots_96_rate_0.05-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-32/adapters_160_slots_96_rate_0.05-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [53 53 54]
Adapter prompts. [33, 540, 33, 33, 66, 33, 33, 33, 540, 33, 66, 540, 66, 33, 66, 66, 66, 66, 540, 540, 540, 66, 66, 66, 540, 540, 33, 540, 66, 540, 540, 540, 66, 540, 33, 66, 66, 66, 540, 33, 33, 540, 33, 540, 33, 33, 66, 33, 66, 540, 33, 33, 66, 33, 33, 33, 33, 33, 540, 66, 66, 540, 66, 33, 540, 540, 540, 66, 66, 33, 33, 33, 540, 33, 66, 66, 33, 540, 540, 540, 33, 33, 540, 66, 540, 540, 33, 540, 33, 66, 33, 33, 66, 66, 540, 540, 540, 33, 540, 66, 66, 33, 33, 33, 33, 540, 66, 540, 66, 540, 540, 540, 33, 66, 66, 540, 66, 540, 33, 33, 33, 66, 66, 66, 540, 540, 66, 540, 33, 66, 66, 33, 540, 540, 540, 540, 540, 540, 66, 66, 66, 66, 66, 540, 33, 540, 33, 540, 66, 33, 66, 33, 33, 66, 66, 66, 540, 66, 33, 33]
Prompts retrieved: 34407 . Total input tokens: 7613207 . Total output tokens: 6870626
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.3169744657352567,
    "estimated_duration": 3599.8596707938727,
    "input_throughput": 797.1769075562723,
    "output_throughput": 700.3606336254776,
    "total_throughput": 1497.53754118175,
    "itl": 21.2681893180617,
    "ttft": 5910.496665296804,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1121,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7567205837742033,
    "arrivals": 11642,
    "finished_requests": 11623,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.317047856748104. Arrivals time: 0.040078950114548206 Scheduler time: 0.8421424180269241 Scheduler overhead time: 0.14359488850459456 Adapter cache time: 0.08366340259090066 Engine time: 0.137877750210464 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-8/adapters_160_slots_96_rate_0.025-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-8/adapters_160_slots_96_rate_0.025-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [53 53 54]
Adapter prompts. [66, 270, 66, 66, 135, 66, 66, 66, 270, 66, 135, 270, 135, 66, 135, 135, 135, 135, 270, 270, 270, 135, 135, 135, 270, 270, 66, 270, 135, 270, 270, 270, 135, 270, 66, 135, 135, 135, 270, 66, 66, 270, 66, 270, 66, 66, 135, 66, 135, 270, 66, 66, 135, 66, 66, 66, 66, 66, 270, 135, 135, 270, 135, 66, 270, 270, 270, 135, 135, 66, 66, 66, 270, 66, 135, 135, 66, 270, 270, 270, 66, 66, 270, 135, 270, 270, 66, 270, 66, 135, 66, 66, 135, 135, 270, 270, 270, 66, 270, 135, 135, 66, 66, 66, 66, 270, 135, 270, 135, 270, 270, 270, 66, 135, 135, 270, 135, 270, 66, 66, 66, 135, 135, 135, 270, 270, 135, 270, 66, 135, 135, 66, 270, 270, 270, 270, 270, 270, 135, 135, 135, 135, 135, 270, 66, 270, 66, 270, 135, 66, 135, 66, 66, 135, 135, 135, 270, 135, 66, 66]
Prompts retrieved: 25233 . Total input tokens: 5554084 . Total output tokens: 5037594
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.127349501941353,
    "estimated_duration": 3599.9707950755533,
    "input_throughput": 573.2010389702878,
    "output_throughput": 518.367538579111,
    "total_throughput": 1091.568577549399,
    "itl": 20.030385317612836,
    "ttft": 4663.996392262345,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2597,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.948086670993602,
    "arrivals": 8553,
    "finished_requests": 8542,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1274223159998655. Arrivals time: 0.03376096161082387 Scheduler time: 0.6603180035017431 Scheduler overhead time: 0.14492279198020697 Adapter cache time: 0.07618237286806107 Engine time: 0.14088515285402536 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-16/adapters_160_slots_96_rate_0.025-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-16/adapters_160_slots_96_rate_0.025-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [53 53 54]
Adapter prompts. [66, 270, 66, 66, 135, 66, 66, 66, 270, 66, 135, 270, 135, 66, 135, 135, 135, 135, 270, 270, 270, 135, 135, 135, 270, 270, 66, 270, 135, 270, 270, 270, 135, 270, 66, 135, 135, 135, 270, 66, 66, 270, 66, 270, 66, 66, 135, 66, 135, 270, 66, 66, 135, 66, 66, 66, 66, 66, 270, 135, 135, 270, 135, 66, 270, 270, 270, 135, 135, 66, 66, 66, 270, 66, 135, 135, 66, 270, 270, 270, 66, 66, 270, 135, 270, 270, 66, 270, 66, 135, 66, 66, 135, 135, 270, 270, 270, 66, 270, 135, 135, 66, 66, 66, 66, 270, 135, 270, 135, 270, 270, 270, 66, 135, 135, 270, 135, 270, 66, 66, 66, 135, 135, 135, 270, 270, 135, 270, 66, 135, 135, 66, 270, 270, 270, 270, 270, 270, 135, 135, 135, 135, 135, 270, 66, 270, 66, 270, 135, 66, 135, 66, 66, 135, 135, 135, 270, 135, 66, 66]
Prompts retrieved: 25233 . Total input tokens: 5554084 . Total output tokens: 5037594
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.1484220456331968,
    "estimated_duration": 3599.971989744908,
    "input_throughput": 573.2008487505534,
    "output_throughput": 518.3673665561579,
    "total_throughput": 1091.5682153067114,
    "itl": 20.21876165421665,
    "ttft": 4664.403951146307,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2593,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.459253124945995,
    "arrivals": 8553,
    "finished_requests": 8542,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.148491813801229. Arrivals time: 0.03440151736140251 Scheduler time: 0.6812509577721357 Scheduler overhead time: 0.1434174943715334 Adapter cache time: 0.07647007377818227 Engine time: 0.14212781703099608 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-32/adapters_160_slots_96_rate_0.025-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-32/adapters_160_slots_96_rate_0.025-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [53 53 54]
Adapter prompts. [66, 270, 66, 66, 135, 66, 66, 66, 270, 66, 135, 270, 135, 66, 135, 135, 135, 135, 270, 270, 270, 135, 135, 135, 270, 270, 66, 270, 135, 270, 270, 270, 135, 270, 66, 135, 135, 135, 270, 66, 66, 270, 66, 270, 66, 66, 135, 66, 135, 270, 66, 66, 135, 66, 66, 66, 66, 66, 270, 135, 135, 270, 135, 66, 270, 270, 270, 135, 135, 66, 66, 66, 270, 66, 135, 135, 66, 270, 270, 270, 66, 66, 270, 135, 270, 270, 66, 270, 66, 135, 66, 66, 135, 135, 270, 270, 270, 66, 270, 135, 135, 66, 66, 66, 66, 270, 135, 270, 135, 270, 270, 270, 66, 135, 135, 270, 135, 270, 66, 66, 66, 135, 135, 135, 270, 270, 135, 270, 66, 135, 135, 66, 270, 270, 270, 270, 270, 270, 135, 135, 135, 135, 135, 270, 66, 270, 66, 270, 135, 66, 135, 66, 66, 135, 135, 135, 270, 135, 66, 66]
Prompts retrieved: 25233 . Total input tokens: 5554084 . Total output tokens: 5037594
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.140419863164425,
    "estimated_duration": 3599.9875505642403,
    "input_throughput": 573.1983711100829,
    "output_throughput": 518.365125931482,
    "total_throughput": 1091.563497041565,
    "itl": 20.21979280655356,
    "ttft": 4664.380157547776,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2592,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.471564526557799,
    "arrivals": 8553,
    "finished_requests": 8542,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1405197121202946. Arrivals time: 0.03533954778686166 Scheduler time: 0.6712364042177796 Scheduler overhead time: 0.1428036531433463 Adapter cache time: 0.07577167451381683 Engine time: 0.14438291219994426 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-16/adapters_160_slots_96_rate_0.025-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-16/adapters_160_slots_96_rate_0.025-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [53 53 54]
Adapter prompts. [66, 270, 66, 66, 135, 66, 66, 66, 270, 66, 135, 270, 135, 66, 135, 135, 135, 135, 270, 270, 270, 135, 135, 135, 270, 270, 66, 270, 135, 270, 270, 270, 135, 270, 66, 135, 135, 135, 270, 66, 66, 270, 66, 270, 66, 66, 135, 66, 135, 270, 66, 66, 135, 66, 66, 66, 66, 66, 270, 135, 135, 270, 135, 66, 270, 270, 270, 135, 135, 66, 66, 66, 270, 66, 135, 135, 66, 270, 270, 270, 66, 66, 270, 135, 270, 270, 66, 270, 66, 135, 66, 66, 135, 135, 270, 270, 270, 66, 270, 135, 135, 66, 66, 66, 66, 270, 135, 270, 135, 270, 270, 270, 66, 135, 135, 270, 135, 270, 66, 66, 66, 135, 135, 135, 270, 270, 135, 270, 66, 135, 135, 66, 270, 270, 270, 270, 270, 270, 135, 135, 135, 135, 135, 270, 66, 270, 66, 270, 135, 66, 135, 66, 66, 135, 135, 135, 270, 135, 66, 66]
Prompts retrieved: 25233 . Total input tokens: 5554084 . Total output tokens: 5037594
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 1.136736461892724,
    "estimated_duration": 3599.9823199531543,
    "input_throughput": 573.1992039413271,
    "output_throughput": 518.3658790925072,
    "total_throughput": 1091.5650830338343,
    "itl": 20.03176737538461,
    "ttft": 4664.164842132473,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2596,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.111519562832267,
    "arrivals": 8553,
    "finished_requests": 8542,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.136888761073351. Arrivals time: 0.03434086870402098 Scheduler time: 0.6699499571695924 Scheduler overhead time: 0.14351573958992958 Adapter cache time: 0.0757375149987638 Engine time: 0.14225484523922205 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-32/adapters_160_slots_96_rate_0.025-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-32/adapters_160_slots_96_rate_0.025-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [53 53 54]
Adapter prompts. [66, 270, 66, 66, 135, 66, 66, 66, 270, 66, 135, 270, 135, 66, 135, 135, 135, 135, 270, 270, 270, 135, 135, 135, 270, 270, 66, 270, 135, 270, 270, 270, 135, 270, 66, 135, 135, 135, 270, 66, 66, 270, 66, 270, 66, 66, 135, 66, 135, 270, 66, 66, 135, 66, 66, 66, 66, 66, 270, 135, 135, 270, 135, 66, 270, 270, 270, 135, 135, 66, 66, 66, 270, 66, 135, 135, 66, 270, 270, 270, 66, 66, 270, 135, 270, 270, 66, 270, 66, 135, 66, 66, 135, 135, 270, 270, 270, 66, 270, 135, 135, 66, 66, 66, 66, 270, 135, 270, 135, 270, 270, 270, 66, 135, 135, 270, 135, 270, 66, 66, 66, 135, 135, 135, 270, 270, 135, 270, 66, 135, 135, 66, 270, 270, 270, 270, 270, 270, 135, 135, 135, 135, 135, 270, 66, 270, 66, 270, 135, 66, 135, 66, 66, 135, 135, 135, 270, 135, 66, 66]
Prompts retrieved: 25233 . Total input tokens: 5554084 . Total output tokens: 5037594
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 1.1403394271619618,
    "estimated_duration": 3599.9724373063746,
    "input_throughput": 573.2007774881711,
    "output_throughput": 518.3673021108705,
    "total_throughput": 1091.5680795990415,
    "itl": 20.035896220134532,
    "ttft": 4664.1714253828995,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2597,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.59366141486886,
    "arrivals": 8553,
    "finished_requests": 8542,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.140410739928484. Arrivals time: 0.034080824349075556 Scheduler time: 0.6706318971700966 Scheduler overhead time: 0.14471788797527552 Adapter cache time: 0.07596693886443973 Engine time: 0.14367451006546617 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-16/adapters_160_slots_96_rate_0.025-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-16/adapters_160_slots_96_rate_0.025-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [53 53 54]
Adapter prompts. [66, 270, 66, 66, 135, 66, 66, 66, 270, 66, 135, 270, 135, 66, 135, 135, 135, 135, 270, 270, 270, 135, 135, 135, 270, 270, 66, 270, 135, 270, 270, 270, 135, 270, 66, 135, 135, 135, 270, 66, 66, 270, 66, 270, 66, 66, 135, 66, 135, 270, 66, 66, 135, 66, 66, 66, 66, 66, 270, 135, 135, 270, 135, 66, 270, 270, 270, 135, 135, 66, 66, 66, 270, 66, 135, 135, 66, 270, 270, 270, 66, 66, 270, 135, 270, 270, 66, 270, 66, 135, 66, 66, 135, 135, 270, 270, 270, 66, 270, 135, 135, 66, 66, 66, 66, 270, 135, 270, 135, 270, 270, 270, 66, 135, 135, 270, 135, 270, 66, 66, 66, 135, 135, 135, 270, 270, 135, 270, 66, 135, 135, 66, 270, 270, 270, 270, 270, 270, 135, 135, 135, 135, 135, 270, 66, 270, 66, 270, 135, 66, 135, 66, 66, 135, 135, 135, 270, 135, 66, 66]
Prompts retrieved: 25233 . Total input tokens: 5554084 . Total output tokens: 5037594
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.1382318511605263,
    "estimated_duration": 3599.9756744072483,
    "input_throughput": 573.2002620655945,
    "output_throughput": 518.3668359945967,
    "total_throughput": 1091.5670980601913,
    "itl": 20.0300774370642,
    "ttft": 4664.110428646222,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2597,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.765160615860711,
    "arrivals": 8553,
    "finished_requests": 8542,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1383030288852751. Arrivals time: 0.03416077280417085 Scheduler time: 0.6692684153094888 Scheduler overhead time: 0.14411548152565956 Adapter cache time: 0.07563039334490895 Engine time: 0.1439962494187057 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-32/adapters_160_slots_96_rate_0.025-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-32/adapters_160_slots_96_rate_0.025-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [53 53 54]
Adapter prompts. [66, 270, 66, 66, 135, 66, 66, 66, 270, 66, 135, 270, 135, 66, 135, 135, 135, 135, 270, 270, 270, 135, 135, 135, 270, 270, 66, 270, 135, 270, 270, 270, 135, 270, 66, 135, 135, 135, 270, 66, 66, 270, 66, 270, 66, 66, 135, 66, 135, 270, 66, 66, 135, 66, 66, 66, 66, 66, 270, 135, 135, 270, 135, 66, 270, 270, 270, 135, 135, 66, 66, 66, 270, 66, 135, 135, 66, 270, 270, 270, 66, 66, 270, 135, 270, 270, 66, 270, 66, 135, 66, 66, 135, 135, 270, 270, 270, 66, 270, 135, 135, 66, 66, 66, 66, 270, 135, 270, 135, 270, 270, 270, 66, 135, 135, 270, 135, 270, 66, 66, 66, 135, 135, 135, 270, 270, 135, 270, 66, 135, 135, 66, 270, 270, 270, 270, 270, 270, 135, 135, 135, 135, 135, 270, 66, 270, 66, 270, 135, 66, 135, 66, 66, 135, 135, 135, 270, 135, 66, 66]
Prompts retrieved: 25233 . Total input tokens: 5554084 . Total output tokens: 5037594
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.1554159889928997,
    "estimated_duration": 3599.9859584717947,
    "input_throughput": 573.1986246068485,
    "output_throughput": 518.3653551782654,
    "total_throughput": 1091.5639797851138,
    "itl": 20.035675929281027,
    "ttft": 4664.059912331957,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2596,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.697800135910104,
    "arrivals": 8553,
    "finished_requests": 8542,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1554944687522948. Arrivals time: 0.03442443208768964 Scheduler time: 0.6768042491748929 Scheduler overhead time: 0.15093905432149768 Adapter cache time: 0.07588266115635633 Engine time: 0.14532952150329947 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-8/adapters_160_slots_96_rate_0.025-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-8/adapters_160_slots_96_rate_0.025-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [53 53 54]
Adapter prompts. [33, 270, 33, 33, 135, 33, 33, 33, 270, 33, 135, 270, 135, 33, 135, 135, 135, 135, 270, 270, 270, 135, 135, 135, 270, 270, 33, 270, 135, 270, 270, 270, 135, 270, 33, 135, 135, 135, 270, 33, 33, 270, 33, 270, 33, 33, 135, 33, 135, 270, 33, 33, 135, 33, 33, 33, 33, 33, 270, 135, 135, 270, 135, 33, 270, 270, 270, 135, 135, 33, 33, 33, 270, 33, 135, 135, 33, 270, 270, 270, 33, 33, 270, 135, 270, 270, 33, 270, 33, 135, 33, 33, 135, 135, 270, 270, 270, 33, 270, 135, 135, 33, 33, 33, 33, 270, 135, 270, 135, 270, 270, 270, 33, 135, 135, 270, 135, 270, 33, 33, 33, 135, 135, 135, 270, 270, 135, 270, 33, 135, 135, 33, 270, 270, 270, 270, 270, 270, 135, 135, 135, 135, 135, 270, 33, 270, 33, 270, 135, 33, 135, 33, 33, 135, 135, 135, 270, 135, 33, 33]
Prompts retrieved: 23484 . Total input tokens: 5172175 . Total output tokens: 4691996
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.0970270880497992,
    "estimated_duration": 3598.517108999459,
    "input_throughput": 538.7513637635706,
    "output_throughput": 483.0056235256491,
    "total_throughput": 1021.7569872892196,
    "itl": 19.817361804813114,
    "ttft": 2750.848668329722,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1856,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.6802652527393525,
    "arrivals": 7949,
    "finished_requests": 7943,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0971500212326646. Arrivals time: 0.03247135039418936 Scheduler time: 0.6329662525095046 Scheduler overhead time: 0.14427230274304748 Adapter cache time: 0.07096422929316759 Engine time: 0.14451226871460676 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-16/adapters_160_slots_96_rate_0.025-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-16/adapters_160_slots_96_rate_0.025-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [53 53 54]
Adapter prompts. [33, 270, 33, 33, 135, 33, 33, 33, 270, 33, 135, 270, 135, 33, 135, 135, 135, 135, 270, 270, 270, 135, 135, 135, 270, 270, 33, 270, 135, 270, 270, 270, 135, 270, 33, 135, 135, 135, 270, 33, 33, 270, 33, 270, 33, 33, 135, 33, 135, 270, 33, 33, 135, 33, 33, 33, 33, 33, 270, 135, 135, 270, 135, 33, 270, 270, 270, 135, 135, 33, 33, 33, 270, 33, 135, 135, 33, 270, 270, 270, 33, 33, 270, 135, 270, 270, 33, 270, 33, 135, 33, 33, 135, 135, 270, 270, 270, 33, 270, 135, 135, 33, 33, 33, 33, 270, 135, 270, 135, 270, 270, 270, 33, 135, 135, 270, 135, 270, 33, 33, 33, 135, 135, 135, 270, 270, 135, 270, 33, 135, 135, 33, 270, 270, 270, 270, 270, 270, 135, 135, 135, 135, 135, 270, 33, 270, 33, 270, 135, 33, 135, 33, 33, 135, 135, 135, 270, 135, 33, 33]
Prompts retrieved: 23484 . Total input tokens: 5172175 . Total output tokens: 4691996
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.1093070739880204,
    "estimated_duration": 3598.513864085441,
    "input_throughput": 538.7518495757471,
    "output_throughput": 483.0060590698148,
    "total_throughput": 1021.7579086455619,
    "itl": 19.81957199469832,
    "ttft": 2750.8724605864522,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1856,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.057008732841168,
    "arrivals": 7949,
    "finished_requests": 7943,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1093733902089298. Arrivals time: 0.03276464669033885 Scheduler time: 0.6401513046585023 Scheduler overhead time: 0.14807557733729482 Adapter cache time: 0.07129974290728569 Engine time: 0.14459665026515722 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-32/adapters_160_slots_96_rate_0.025-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-32/adapters_160_slots_96_rate_0.025-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [53 53 54]
Adapter prompts. [33, 270, 33, 33, 135, 33, 33, 33, 270, 33, 135, 270, 135, 33, 135, 135, 135, 135, 270, 270, 270, 135, 135, 135, 270, 270, 33, 270, 135, 270, 270, 270, 135, 270, 33, 135, 135, 135, 270, 33, 33, 270, 33, 270, 33, 33, 135, 33, 135, 270, 33, 33, 135, 33, 33, 33, 33, 33, 270, 135, 135, 270, 135, 33, 270, 270, 270, 135, 135, 33, 33, 33, 270, 33, 135, 135, 33, 270, 270, 270, 33, 33, 270, 135, 270, 270, 33, 270, 33, 135, 33, 33, 135, 135, 270, 270, 270, 33, 270, 135, 135, 33, 33, 33, 33, 270, 135, 270, 135, 270, 270, 270, 33, 135, 135, 270, 135, 270, 33, 33, 33, 135, 135, 135, 270, 270, 135, 270, 33, 135, 135, 33, 270, 270, 270, 270, 270, 270, 135, 135, 135, 135, 135, 270, 33, 270, 33, 270, 135, 33, 135, 33, 33, 135, 135, 135, 270, 135, 33, 33]
Prompts retrieved: 23484 . Total input tokens: 5172175 . Total output tokens: 4691996
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.112884550821036,
    "estimated_duration": 3598.524709031481,
    "input_throughput": 538.7502259285,
    "output_throughput": 483.0046034247738,
    "total_throughput": 1021.7548293532737,
    "itl": 19.81915186559354,
    "ttft": 2750.9460256245634,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1856,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.067632371522441,
    "arrivals": 7949,
    "finished_requests": 7943,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1129386969842017. Arrivals time: 0.03294251626357436 Scheduler time: 0.6408964693546295 Scheduler overhead time: 0.14821641007438302 Adapter cache time: 0.07198060257360339 Engine time: 0.14445314975455403 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-16/adapters_160_slots_96_rate_0.025-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-16/adapters_160_slots_96_rate_0.025-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [53 53 54]
Adapter prompts. [33, 270, 33, 33, 135, 33, 33, 33, 270, 33, 135, 270, 135, 33, 135, 135, 135, 135, 270, 270, 270, 135, 135, 135, 270, 270, 33, 270, 135, 270, 270, 270, 135, 270, 33, 135, 135, 135, 270, 33, 33, 270, 33, 270, 33, 33, 135, 33, 135, 270, 33, 33, 135, 33, 33, 33, 33, 33, 270, 135, 135, 270, 135, 33, 270, 270, 270, 135, 135, 33, 33, 33, 270, 33, 135, 135, 33, 270, 270, 270, 33, 33, 270, 135, 270, 270, 33, 270, 33, 135, 33, 33, 135, 135, 270, 270, 270, 33, 270, 135, 135, 33, 33, 33, 33, 270, 135, 270, 135, 270, 270, 270, 33, 135, 135, 270, 135, 270, 33, 33, 33, 135, 135, 135, 270, 270, 135, 270, 33, 135, 135, 33, 270, 270, 270, 270, 270, 270, 135, 135, 135, 135, 135, 270, 33, 270, 33, 270, 135, 33, 135, 33, 33, 135, 135, 135, 270, 135, 33, 33]
Prompts retrieved: 23484 . Total input tokens: 5172175 . Total output tokens: 4691996
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 1.094558252952993,
    "estimated_duration": 3598.509475892854,
    "input_throughput": 538.7525065552238,
    "output_throughput": 483.006648070239,
    "total_throughput": 1021.7591546254629,
    "itl": 19.817206402679282,
    "ttft": 2750.8055682526333,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1856,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.804905421363496,
    "arrivals": 7949,
    "finished_requests": 7943,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0946309701539576. Arrivals time: 0.03264434076845646 Scheduler time: 0.6304762824438512 Scheduler overhead time: 0.14367874478921294 Adapter cache time: 0.07109938422217965 Engine time: 0.14484985591843724 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-32/adapters_160_slots_96_rate_0.025-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-32/adapters_160_slots_96_rate_0.025-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [53 53 54]
Adapter prompts. [33, 270, 33, 33, 135, 33, 33, 33, 270, 33, 135, 270, 135, 33, 135, 135, 135, 135, 270, 270, 270, 135, 135, 135, 270, 270, 33, 270, 135, 270, 270, 270, 135, 270, 33, 135, 135, 135, 270, 33, 33, 270, 33, 270, 33, 33, 135, 33, 135, 270, 33, 33, 135, 33, 33, 33, 33, 33, 270, 135, 135, 270, 135, 33, 270, 270, 270, 135, 135, 33, 33, 33, 270, 33, 135, 135, 33, 270, 270, 270, 33, 33, 270, 135, 270, 270, 33, 270, 33, 135, 33, 33, 135, 135, 270, 270, 270, 33, 270, 135, 135, 33, 33, 33, 33, 270, 135, 270, 135, 270, 270, 270, 33, 135, 135, 270, 135, 270, 33, 33, 33, 135, 135, 135, 270, 270, 135, 270, 33, 135, 135, 33, 270, 270, 270, 270, 270, 270, 135, 135, 135, 135, 135, 270, 33, 270, 33, 270, 135, 33, 135, 33, 33, 135, 135, 135, 270, 135, 33, 33]
Prompts retrieved: 23484 . Total input tokens: 5172175 . Total output tokens: 4691996
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 1.0886225970461965,
    "estimated_duration": 3598.508764864086,
    "input_throughput": 538.7526130072449,
    "output_throughput": 483.0067435074449,
    "total_throughput": 1021.7593565146899,
    "itl": 19.820451975214834,
    "ttft": 2750.9254299029203,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1856,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.145222457740351,
    "arrivals": 7949,
    "finished_requests": 7943,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0886835157871246. Arrivals time: 0.03248639311641455 Scheduler time: 0.6252718945033848 Scheduler overhead time: 0.1442310749553144 Adapter cache time: 0.07133684307336807 Engine time: 0.14379999181255698 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-16/adapters_160_slots_96_rate_0.025-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-16/adapters_160_slots_96_rate_0.025-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [53 53 54]
Adapter prompts. [33, 270, 33, 33, 135, 33, 33, 33, 270, 33, 135, 270, 135, 33, 135, 135, 135, 135, 270, 270, 270, 135, 135, 135, 270, 270, 33, 270, 135, 270, 270, 270, 135, 270, 33, 135, 135, 135, 270, 33, 33, 270, 33, 270, 33, 33, 135, 33, 135, 270, 33, 33, 135, 33, 33, 33, 33, 33, 270, 135, 135, 270, 135, 33, 270, 270, 270, 135, 135, 33, 33, 33, 270, 33, 135, 135, 33, 270, 270, 270, 33, 33, 270, 135, 270, 270, 33, 270, 33, 135, 33, 33, 135, 135, 270, 270, 270, 33, 270, 135, 135, 33, 33, 33, 33, 270, 135, 270, 135, 270, 270, 270, 33, 135, 135, 270, 135, 270, 33, 33, 33, 135, 135, 135, 270, 270, 135, 270, 33, 135, 135, 33, 270, 270, 270, 270, 270, 270, 135, 135, 135, 135, 135, 270, 33, 270, 33, 270, 135, 33, 135, 33, 33, 135, 135, 135, 270, 135, 33, 33]
Prompts retrieved: 23484 . Total input tokens: 5172175 . Total output tokens: 4691996
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.1048055831342936,
    "estimated_duration": 3598.5159770229025,
    "input_throughput": 538.7515332372974,
    "output_throughput": 483.00577546357187,
    "total_throughput": 1021.7573087008693,
    "itl": 19.81523335493638,
    "ttft": 2750.839982373213,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1856,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.5495333473382775,
    "arrivals": 7949,
    "finished_requests": 7943,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.104870478156954. Arrivals time: 0.03281191689893603 Scheduler time: 0.638547136913985 Scheduler overhead time: 0.14639756781980395 Adapter cache time: 0.07129989564418793 Engine time: 0.14348439872264862 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-32/adapters_160_slots_96_rate_0.025-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-32/adapters_160_slots_96_rate_0.025-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [53 53 54]
Adapter prompts. [33, 270, 33, 33, 135, 33, 33, 33, 270, 33, 135, 270, 135, 33, 135, 135, 135, 135, 270, 270, 270, 135, 135, 135, 270, 270, 33, 270, 135, 270, 270, 270, 135, 270, 33, 135, 135, 135, 270, 33, 33, 270, 33, 270, 33, 33, 135, 33, 135, 270, 33, 33, 135, 33, 33, 33, 33, 33, 270, 135, 135, 270, 135, 33, 270, 270, 270, 135, 135, 33, 33, 33, 270, 33, 135, 135, 33, 270, 270, 270, 33, 33, 270, 135, 270, 270, 33, 270, 33, 135, 33, 33, 135, 135, 270, 270, 270, 33, 270, 135, 135, 33, 33, 33, 33, 270, 135, 270, 135, 270, 270, 270, 33, 135, 135, 270, 135, 270, 33, 33, 33, 135, 135, 135, 270, 270, 135, 270, 33, 135, 135, 33, 270, 270, 270, 270, 270, 270, 135, 135, 135, 135, 135, 270, 33, 270, 33, 270, 135, 33, 135, 33, 33, 135, 135, 135, 270, 135, 33, 33]
Prompts retrieved: 23484 . Total input tokens: 5172175 . Total output tokens: 4691996
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.1036254120990634,
    "estimated_duration": 3598.5127522889566,
    "input_throughput": 538.7520160285162,
    "output_throughput": 483.00620829936474,
    "total_throughput": 1021.758224327881,
    "itl": 19.82056306656148,
    "ttft": 2750.9544578145474,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1856,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.223818574249589,
    "arrivals": 7949,
    "finished_requests": 7943,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1037126979790628. Arrivals time: 0.03270057635381818 Scheduler time: 0.6376075190491974 Scheduler overhead time: 0.1457365876995027 Adapter cache time: 0.07112917955964804 Engine time: 0.14414516696706414 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-8/adapters_160_slots_96_rate_0.025-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-8/adapters_160_slots_96_rate_0.025-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [53 53 54]
Adapter prompts. [33, 270, 33, 33, 66, 33, 33, 33, 270, 33, 66, 270, 66, 33, 66, 66, 66, 66, 270, 270, 270, 66, 66, 66, 270, 270, 33, 270, 66, 270, 270, 270, 66, 270, 33, 66, 66, 66, 270, 33, 33, 270, 33, 270, 33, 33, 66, 33, 66, 270, 33, 33, 66, 33, 33, 33, 33, 33, 270, 66, 66, 270, 66, 33, 270, 270, 270, 66, 66, 33, 33, 33, 270, 33, 66, 66, 33, 270, 270, 270, 33, 33, 270, 66, 270, 270, 33, 270, 33, 66, 33, 33, 66, 66, 270, 270, 270, 33, 270, 66, 66, 33, 33, 33, 33, 270, 66, 270, 66, 270, 270, 270, 33, 66, 66, 270, 66, 270, 33, 33, 33, 66, 66, 66, 270, 270, 66, 270, 33, 66, 66, 33, 270, 270, 270, 270, 270, 270, 66, 66, 66, 66, 66, 270, 33, 270, 33, 270, 66, 33, 66, 33, 33, 66, 66, 66, 270, 66, 33, 33]
Prompts retrieved: 19827 . Total input tokens: 4360331 . Total output tokens: 3963665
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.0291632558219135,
    "estimated_duration": 3597.5210127830233,
    "input_throughput": 445.26744786427537,
    "output_throughput": 404.23975143789124,
    "total_throughput": 849.5071993021666,
    "itl": 19.302189063760366,
    "ttft": 7529.1867556247225,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1262,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.8623355328432334,
    "arrivals": 6723,
    "finished_requests": 6709,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0292134610936046. Arrivals time: 0.02971328003332019 Scheduler time: 0.5595374442636967 Scheduler overhead time: 0.1547200120985508 Adapter cache time: 0.06345815397799015 Engine time: 0.14867045730352402 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-16/adapters_160_slots_96_rate_0.025-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-16/adapters_160_slots_96_rate_0.025-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [53 53 54]
Adapter prompts. [33, 270, 33, 33, 66, 33, 33, 33, 270, 33, 66, 270, 66, 33, 66, 66, 66, 66, 270, 270, 270, 66, 66, 66, 270, 270, 33, 270, 66, 270, 270, 270, 66, 270, 33, 66, 66, 66, 270, 33, 33, 270, 33, 270, 33, 33, 66, 33, 66, 270, 33, 33, 66, 33, 33, 33, 33, 33, 270, 66, 66, 270, 66, 33, 270, 270, 270, 66, 66, 33, 33, 33, 270, 33, 66, 66, 33, 270, 270, 270, 33, 33, 270, 66, 270, 270, 33, 270, 33, 66, 33, 33, 66, 66, 270, 270, 270, 33, 270, 66, 66, 33, 33, 33, 33, 270, 66, 270, 66, 270, 270, 270, 33, 66, 66, 270, 66, 270, 33, 33, 33, 66, 66, 66, 270, 270, 66, 270, 33, 66, 66, 33, 270, 270, 270, 270, 270, 270, 66, 66, 66, 66, 66, 270, 33, 270, 33, 270, 66, 33, 66, 33, 33, 66, 66, 66, 270, 66, 33, 33]
Prompts retrieved: 19827 . Total input tokens: 4360331 . Total output tokens: 3963665
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.0104222688823938,
    "estimated_duration": 3597.520013856702,
    "input_throughput": 445.2675715020514,
    "output_throughput": 404.23986368347323,
    "total_throughput": 849.5074351855246,
    "itl": 19.302548246772087,
    "ttft": 7529.274113523321,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1262,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.11421196774579,
    "arrivals": 6723,
    "finished_requests": 6709,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0105033991858363. Arrivals time: 0.029314031824469566 Scheduler time: 0.5500995353795588 Scheduler overhead time: 0.14779789745807648 Adapter cache time: 0.062368160113692284 Engine time: 0.14756365166977048 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-32/adapters_160_slots_96_rate_0.025-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-32/adapters_160_slots_96_rate_0.025-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [53 53 54]
Adapter prompts. [33, 270, 33, 33, 66, 33, 33, 33, 270, 33, 66, 270, 66, 33, 66, 66, 66, 66, 270, 270, 270, 66, 66, 66, 270, 270, 33, 270, 66, 270, 270, 270, 66, 270, 33, 66, 66, 66, 270, 33, 33, 270, 33, 270, 33, 33, 66, 33, 66, 270, 33, 33, 66, 33, 33, 33, 33, 33, 270, 66, 66, 270, 66, 33, 270, 270, 270, 66, 66, 33, 33, 33, 270, 33, 66, 66, 33, 270, 270, 270, 33, 33, 270, 66, 270, 270, 33, 270, 33, 66, 33, 33, 66, 66, 270, 270, 270, 33, 270, 66, 66, 33, 33, 33, 33, 270, 66, 270, 66, 270, 270, 270, 33, 66, 66, 270, 66, 270, 33, 33, 33, 66, 66, 66, 270, 270, 66, 270, 33, 66, 66, 33, 270, 270, 270, 270, 270, 270, 66, 66, 66, 66, 66, 270, 33, 270, 33, 270, 66, 33, 66, 33, 33, 66, 66, 66, 270, 66, 33, 33]
Prompts retrieved: 19827 . Total input tokens: 4360331 . Total output tokens: 3963665
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.0148907699622214,
    "estimated_duration": 3597.5218604941974,
    "input_throughput": 445.2673429425527,
    "output_throughput": 404.2396561838337,
    "total_throughput": 849.5069991263864,
    "itl": 19.302187628647353,
    "ttft": 7529.123764639209,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1262,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.122185197584268,
    "arrivals": 6723,
    "finished_requests": 6709,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0149451019242406. Arrivals time: 0.030149300582706928 Scheduler time: 0.5500622880645096 Scheduler overhead time: 0.14579482143744826 Adapter cache time: 0.06355169136077166 Engine time: 0.1522444961592555 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-16/adapters_160_slots_96_rate_0.025-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-16/adapters_160_slots_96_rate_0.025-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [53 53 54]
Adapter prompts. [33, 270, 33, 33, 66, 33, 33, 33, 270, 33, 66, 270, 66, 33, 66, 66, 66, 66, 270, 270, 270, 66, 66, 66, 270, 270, 33, 270, 66, 270, 270, 270, 66, 270, 33, 66, 66, 66, 270, 33, 33, 270, 33, 270, 33, 33, 66, 33, 66, 270, 33, 33, 66, 33, 33, 33, 33, 33, 270, 66, 66, 270, 66, 33, 270, 270, 270, 66, 66, 33, 33, 33, 270, 33, 66, 66, 33, 270, 270, 270, 33, 33, 270, 66, 270, 270, 33, 270, 33, 66, 33, 33, 66, 66, 270, 270, 270, 33, 270, 66, 66, 33, 33, 33, 33, 270, 66, 270, 66, 270, 270, 270, 33, 66, 66, 270, 66, 270, 33, 33, 33, 66, 66, 66, 270, 270, 66, 270, 33, 66, 66, 33, 270, 270, 270, 270, 270, 270, 66, 66, 66, 66, 66, 270, 33, 270, 33, 270, 66, 33, 66, 33, 33, 66, 66, 66, 270, 66, 33, 33]
Prompts retrieved: 19827 . Total input tokens: 4360331 . Total output tokens: 3963665
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 1.0120871849358082,
    "estimated_duration": 3597.5125849581696,
    "input_throughput": 445.26849098392404,
    "output_throughput": 404.2406984427296,
    "total_throughput": 849.5091894266536,
    "itl": 19.30162929278115,
    "ttft": 7529.2146957063005,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1262,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.948322268458968,
    "arrivals": 6723,
    "finished_requests": 6709,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0121648306958377. Arrivals time: 0.029930385760962963 Scheduler time: 0.5531565775163472 Scheduler overhead time: 0.14602430677041411 Adapter cache time: 0.06355685368180275 Engine time: 0.14651181967929006 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-32/adapters_160_slots_96_rate_0.025-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-32/adapters_160_slots_96_rate_0.025-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [53 53 54]
Adapter prompts. [33, 270, 33, 33, 66, 33, 33, 33, 270, 33, 66, 270, 66, 33, 66, 66, 66, 66, 270, 270, 270, 66, 66, 66, 270, 270, 33, 270, 66, 270, 270, 270, 66, 270, 33, 66, 66, 66, 270, 33, 33, 270, 33, 270, 33, 33, 66, 33, 66, 270, 33, 33, 66, 33, 33, 33, 33, 33, 270, 66, 66, 270, 66, 33, 270, 270, 270, 66, 66, 33, 33, 33, 270, 33, 66, 66, 33, 270, 270, 270, 33, 33, 270, 66, 270, 270, 33, 270, 33, 66, 33, 33, 66, 66, 270, 270, 270, 33, 270, 66, 66, 33, 33, 33, 33, 270, 66, 270, 66, 270, 270, 270, 33, 66, 66, 270, 66, 270, 33, 33, 33, 66, 66, 66, 270, 270, 66, 270, 33, 66, 66, 33, 270, 270, 270, 270, 270, 270, 66, 66, 66, 66, 66, 270, 33, 270, 33, 270, 66, 33, 66, 33, 33, 66, 66, 66, 270, 66, 33, 33]
Prompts retrieved: 19827 . Total input tokens: 4360331 . Total output tokens: 3963665
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 1.0062103397212923,
    "estimated_duration": 3597.510073728023,
    "input_throughput": 445.26880180213857,
    "output_throughput": 404.2409806216276,
    "total_throughput": 849.5097824237662,
    "itl": 19.302751053154786,
    "ttft": 7529.13530643498,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1262,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.173241234868753,
    "arrivals": 6723,
    "finished_requests": 6709,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0062681939452887. Arrivals time: 0.029538081027567387 Scheduler time: 0.5480094593949616 Scheduler overhead time: 0.14668606128543615 Adapter cache time: 0.06339722871780396 Engine time: 0.14586741058155894 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-16/adapters_160_slots_96_rate_0.025-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-16/adapters_160_slots_96_rate_0.025-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [53 53 54]
Adapter prompts. [33, 270, 33, 33, 66, 33, 33, 33, 270, 33, 66, 270, 66, 33, 66, 66, 66, 66, 270, 270, 270, 66, 66, 66, 270, 270, 33, 270, 66, 270, 270, 270, 66, 270, 33, 66, 66, 66, 270, 33, 33, 270, 33, 270, 33, 33, 66, 33, 66, 270, 33, 33, 66, 33, 33, 33, 33, 33, 270, 66, 66, 270, 66, 33, 270, 270, 270, 66, 66, 33, 33, 33, 270, 33, 66, 66, 33, 270, 270, 270, 33, 33, 270, 66, 270, 270, 33, 270, 33, 66, 33, 33, 66, 66, 270, 270, 270, 33, 270, 66, 66, 33, 33, 33, 33, 270, 66, 270, 66, 270, 270, 270, 33, 66, 66, 270, 66, 270, 33, 33, 33, 66, 66, 66, 270, 270, 66, 270, 33, 66, 66, 33, 270, 270, 270, 270, 270, 270, 66, 66, 66, 66, 66, 270, 33, 270, 33, 270, 66, 33, 66, 33, 33, 66, 66, 66, 270, 66, 33, 33]
Prompts retrieved: 19827 . Total input tokens: 4360331 . Total output tokens: 3963665
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.0150992474518716,
    "estimated_duration": 3597.5063100430634,
    "input_throughput": 445.26926763912337,
    "output_throughput": 404.2414035356041,
    "total_throughput": 849.5106711747275,
    "itl": 19.300601178722484,
    "ttft": 7529.20145336406,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1262,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7734434721664485,
    "arrivals": 6723,
    "finished_requests": 6709,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0151649904437363. Arrivals time: 0.029771252535283566 Scheduler time: 0.5544430851005018 Scheduler overhead time: 0.14710371615365148 Adapter cache time: 0.06319019477814436 Engine time: 0.14788936031982303 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-32/adapters_160_slots_96_rate_0.025-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-32/adapters_160_slots_96_rate_0.025-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [53 53 54]
Adapter prompts. [33, 270, 33, 33, 66, 33, 33, 33, 270, 33, 66, 270, 66, 33, 66, 66, 66, 66, 270, 270, 270, 66, 66, 66, 270, 270, 33, 270, 66, 270, 270, 270, 66, 270, 33, 66, 66, 66, 270, 33, 33, 270, 33, 270, 33, 33, 66, 33, 66, 270, 33, 33, 66, 33, 33, 33, 33, 33, 270, 66, 66, 270, 66, 33, 270, 270, 270, 66, 66, 33, 33, 33, 270, 33, 66, 66, 33, 270, 270, 270, 33, 33, 270, 66, 270, 270, 33, 270, 33, 66, 33, 33, 66, 66, 270, 270, 270, 33, 270, 66, 66, 33, 33, 33, 33, 270, 66, 270, 66, 270, 270, 270, 33, 66, 66, 270, 66, 270, 33, 33, 33, 66, 66, 66, 270, 270, 66, 270, 33, 66, 66, 33, 270, 270, 270, 270, 270, 270, 66, 66, 66, 66, 66, 270, 33, 270, 33, 270, 66, 33, 66, 33, 33, 66, 66, 66, 270, 66, 33, 33]
Prompts retrieved: 19827 . Total input tokens: 4360331 . Total output tokens: 3963665
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.0205099852755666,
    "estimated_duration": 3597.5182252233817,
    "input_throughput": 445.2677928825601,
    "output_throughput": 404.2400646656071,
    "total_throughput": 849.5078575481673,
    "itl": 19.303129055203044,
    "ttft": 7529.278698739648,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1262,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.2270638554543645,
    "arrivals": 6723,
    "finished_requests": 6709,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.020581582095474. Arrivals time: 0.029840607661753893 Scheduler time: 0.5500690857879817 Scheduler overhead time: 0.15260592009872198 Adapter cache time: 0.06376782432198524 Engine time: 0.14780610892921686 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-8/adapters_160_slots_96_rate_0.0125-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-8/adapters_160_slots_96_rate_0.0125-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [53 53 54]
Adapter prompts. [33, 135, 33, 33, 66, 33, 33, 33, 135, 33, 66, 135, 66, 33, 66, 66, 66, 66, 135, 135, 135, 66, 66, 66, 135, 135, 33, 135, 66, 135, 135, 135, 66, 135, 33, 66, 66, 66, 135, 33, 33, 135, 33, 135, 33, 33, 66, 33, 66, 135, 33, 33, 66, 33, 33, 33, 33, 33, 135, 66, 66, 135, 66, 33, 135, 135, 135, 66, 66, 33, 33, 33, 135, 33, 66, 66, 33, 135, 135, 135, 33, 33, 135, 66, 135, 135, 33, 135, 33, 66, 33, 33, 66, 66, 135, 135, 135, 33, 135, 66, 66, 33, 33, 33, 33, 135, 66, 135, 66, 135, 135, 135, 33, 66, 66, 135, 66, 135, 33, 33, 33, 66, 66, 66, 135, 135, 66, 135, 33, 66, 66, 33, 135, 135, 135, 135, 135, 135, 66, 66, 66, 66, 66, 135, 33, 135, 33, 135, 66, 33, 66, 33, 33, 66, 66, 66, 135, 66, 33, 33]
Prompts retrieved: 12537 . Total input tokens: 2760590 . Total output tokens: 2526223
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 0.8435153658501804,
    "estimated_duration": 3599.6481493726433,
    "input_throughput": 293.2394934721511,
    "output_throughput": 249.432156350193,
    "total_throughput": 542.6716498223441,
    "itl": 18.5187018020307,
    "ttft": 4278.686540592609,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1242,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.801125777964576,
    "arrivals": 4238,
    "finished_requests": 4233,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8435903051868081. Arrivals time: 0.02425727155059576 Scheduler time: 0.3950042244978249 Scheduler overhead time: 0.14957480132579803 Adapter cache time: 0.05017958441749215 Engine time: 0.14962280774489045 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-16/adapters_160_slots_96_rate_0.0125-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-16/adapters_160_slots_96_rate_0.0125-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [53 53 54]
Adapter prompts. [33, 135, 33, 33, 66, 33, 33, 33, 135, 33, 66, 135, 66, 33, 66, 66, 66, 66, 135, 135, 135, 66, 66, 66, 135, 135, 33, 135, 66, 135, 135, 135, 66, 135, 33, 66, 66, 66, 135, 33, 33, 135, 33, 135, 33, 33, 66, 33, 66, 135, 33, 33, 66, 33, 33, 33, 33, 33, 135, 66, 66, 135, 66, 33, 135, 135, 135, 66, 66, 33, 33, 33, 135, 33, 66, 66, 33, 135, 135, 135, 33, 33, 135, 66, 135, 135, 33, 135, 33, 66, 33, 33, 66, 66, 135, 135, 135, 33, 135, 66, 66, 33, 33, 33, 33, 135, 66, 135, 66, 135, 135, 135, 33, 66, 66, 135, 66, 135, 33, 33, 33, 66, 66, 66, 135, 135, 66, 135, 33, 66, 66, 33, 135, 135, 135, 135, 135, 135, 66, 66, 66, 66, 66, 135, 33, 135, 33, 135, 66, 33, 66, 33, 33, 66, 66, 66, 135, 66, 33, 33]
Prompts retrieved: 12537 . Total input tokens: 2760590 . Total output tokens: 2526223
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 0.8313034176826477,
    "estimated_duration": 3599.6447079226677,
    "input_throughput": 293.23977382455513,
    "output_throughput": 249.4323948204749,
    "total_throughput": 542.6721686450301,
    "itl": 18.5194361230766,
    "ttft": 4278.941656955487,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1242,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.056045343121515,
    "arrivals": 4238,
    "finished_requests": 4233,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.831364898942411. Arrivals time: 0.024241049773991108 Scheduler time: 0.38759490475058556 Scheduler overhead time: 0.14850775990635157 Adapter cache time: 0.0496257939375937 Engine time: 0.1472911755554378 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-32/adapters_160_slots_96_rate_0.0125-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-32/adapters_160_slots_96_rate_0.0125-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [53 53 54]
Adapter prompts. [33, 135, 33, 33, 66, 33, 33, 33, 135, 33, 66, 135, 66, 33, 66, 66, 66, 66, 135, 135, 135, 66, 66, 66, 135, 135, 33, 135, 66, 135, 135, 135, 66, 135, 33, 66, 66, 66, 135, 33, 33, 135, 33, 135, 33, 33, 66, 33, 66, 135, 33, 33, 66, 33, 33, 33, 33, 33, 135, 66, 66, 135, 66, 33, 135, 135, 135, 66, 66, 33, 33, 33, 135, 33, 66, 66, 33, 135, 135, 135, 33, 33, 135, 66, 135, 135, 33, 135, 33, 66, 33, 33, 66, 66, 135, 135, 135, 33, 135, 66, 66, 33, 33, 33, 33, 135, 66, 135, 66, 135, 135, 135, 33, 66, 66, 135, 66, 135, 33, 33, 33, 66, 66, 66, 135, 135, 66, 135, 33, 66, 66, 33, 135, 135, 135, 135, 135, 135, 66, 66, 66, 66, 66, 135, 33, 135, 33, 135, 66, 33, 66, 33, 33, 66, 66, 66, 135, 66, 33, 33]
Prompts retrieved: 12537 . Total input tokens: 2760590 . Total output tokens: 2526223
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 0.8362410641275346,
    "estimated_duration": 3599.644702035066,
    "input_throughput": 293.23977430418,
    "output_throughput": 249.43239522844812,
    "total_throughput": 542.6721695326281,
    "itl": 18.519479293387082,
    "ttft": 4279.011465048412,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1242,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.062663810588354,
    "arrivals": 4238,
    "finished_requests": 4233,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8362995348870754. Arrivals time: 0.024114950094372034 Scheduler time: 0.3885222440585494 Scheduler overhead time: 0.14863190380856395 Adapter cache time: 0.04997448530048132 Engine time: 0.15032342076301575 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-16/adapters_160_slots_96_rate_0.0125-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-16/adapters_160_slots_96_rate_0.0125-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [53 53 54]
Adapter prompts. [33, 135, 33, 33, 66, 33, 33, 33, 135, 33, 66, 135, 66, 33, 66, 66, 66, 66, 135, 135, 135, 66, 66, 66, 135, 135, 33, 135, 66, 135, 135, 135, 66, 135, 33, 66, 66, 66, 135, 33, 33, 135, 33, 135, 33, 33, 66, 33, 66, 135, 33, 33, 66, 33, 33, 33, 33, 33, 135, 66, 66, 135, 66, 33, 135, 135, 135, 66, 66, 33, 33, 33, 135, 33, 66, 66, 33, 135, 135, 135, 33, 33, 135, 66, 135, 135, 33, 135, 33, 66, 33, 33, 66, 66, 135, 135, 135, 33, 135, 66, 66, 33, 33, 33, 33, 135, 66, 135, 66, 135, 135, 135, 33, 66, 66, 135, 66, 135, 33, 33, 33, 66, 66, 66, 135, 135, 66, 135, 33, 66, 66, 33, 135, 135, 135, 135, 135, 135, 66, 66, 66, 66, 66, 135, 33, 135, 33, 135, 66, 33, 66, 33, 33, 66, 66, 66, 135, 66, 33, 33]
Prompts retrieved: 12537 . Total input tokens: 2760590 . Total output tokens: 2526223
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 0.8398457299917936,
    "estimated_duration": 3599.633038600933,
    "input_throughput": 293.24072445180786,
    "output_throughput": 249.43320343258483,
    "total_throughput": 542.6739278843927,
    "itl": 18.519042238352164,
    "ttft": 4278.687855350415,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1242,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.889747048516249,
    "arrivals": 4238,
    "finished_requests": 4233,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8399262609891593. Arrivals time: 0.024245168082416058 Scheduler time: 0.38970412127673626 Scheduler overhead time: 0.14799995347857475 Adapter cache time: 0.05038484465330839 Engine time: 0.15300002368167043 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-32/adapters_160_slots_96_rate_0.0125-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-32/adapters_160_slots_96_rate_0.0125-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [53 53 54]
Adapter prompts. [33, 135, 33, 33, 66, 33, 33, 33, 135, 33, 66, 135, 66, 33, 66, 66, 66, 66, 135, 135, 135, 66, 66, 66, 135, 135, 33, 135, 66, 135, 135, 135, 66, 135, 33, 66, 66, 66, 135, 33, 33, 135, 33, 135, 33, 33, 66, 33, 66, 135, 33, 33, 66, 33, 33, 33, 33, 33, 135, 66, 66, 135, 66, 33, 135, 135, 135, 66, 66, 33, 33, 33, 135, 33, 66, 66, 33, 135, 135, 135, 33, 33, 135, 66, 135, 135, 33, 135, 33, 66, 33, 33, 66, 66, 135, 135, 135, 33, 135, 66, 66, 33, 33, 33, 33, 135, 66, 135, 66, 135, 135, 135, 33, 66, 66, 135, 66, 135, 33, 33, 33, 66, 66, 66, 135, 135, 66, 135, 33, 66, 66, 33, 135, 135, 135, 135, 135, 135, 66, 66, 66, 66, 66, 135, 33, 135, 33, 135, 66, 33, 66, 33, 33, 66, 66, 66, 135, 66, 33, 33]
Prompts retrieved: 12537 . Total input tokens: 2760590 . Total output tokens: 2526223
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 0.8353662951849401,
    "estimated_duration": 3599.6479577503997,
    "input_throughput": 293.23950908234696,
    "output_throughput": 249.4321696283663,
    "total_throughput": 542.6716787107133,
    "itl": 18.52037263802232,
    "ttft": 4278.897578407682,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1242,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.113845601659262,
    "arrivals": 4238,
    "finished_requests": 4233,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8354269890114665. Arrivals time: 0.02480308711528778 Scheduler time: 0.3890957715921104 Scheduler overhead time: 0.14862026181071997 Adapter cache time: 0.04974802862852812 Engine time: 0.1489063431508839 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-16/adapters_160_slots_96_rate_0.0125-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-16/adapters_160_slots_96_rate_0.0125-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [53 53 54]
Adapter prompts. [33, 135, 33, 33, 66, 33, 33, 33, 135, 33, 66, 135, 66, 33, 66, 66, 66, 66, 135, 135, 135, 66, 66, 66, 135, 135, 33, 135, 66, 135, 135, 135, 66, 135, 33, 66, 66, 66, 135, 33, 33, 135, 33, 135, 33, 33, 66, 33, 66, 135, 33, 33, 66, 33, 33, 33, 33, 33, 135, 66, 66, 135, 66, 33, 135, 135, 135, 66, 66, 33, 33, 33, 135, 33, 66, 66, 33, 135, 135, 135, 33, 33, 135, 66, 135, 135, 33, 135, 33, 66, 33, 33, 66, 66, 135, 135, 135, 33, 135, 66, 66, 33, 33, 33, 33, 135, 66, 135, 66, 135, 135, 135, 33, 66, 66, 135, 66, 135, 33, 33, 33, 66, 66, 66, 135, 135, 66, 135, 33, 66, 66, 33, 135, 135, 135, 135, 135, 135, 66, 66, 66, 66, 66, 135, 33, 135, 33, 135, 66, 33, 66, 33, 33, 66, 66, 66, 135, 66, 33, 33]
Prompts retrieved: 12537 . Total input tokens: 2760590 . Total output tokens: 2526223
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 0.855764505919069,
    "estimated_duration": 3599.643282323887,
    "input_throughput": 293.2398899589138,
    "output_throughput": 249.43249360540722,
    "total_throughput": 542.6723835643211,
    "itl": 18.518420970088762,
    "ttft": 4278.7001656838775,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1242,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.713642466268407,
    "arrivals": 4238,
    "finished_requests": 4233,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8558240500278771. Arrivals time: 0.024495276156812906 Scheduler time: 0.3968134173192084 Scheduler overhead time: 0.15833937842398882 Adapter cache time: 0.05064560240134597 Engine time: 0.14946171641349792 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-32/adapters_160_slots_96_rate_0.0125-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-32/adapters_160_slots_96_rate_0.0125-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [53 53 54]
Adapter prompts. [33, 135, 33, 33, 66, 33, 33, 33, 135, 33, 66, 135, 66, 33, 66, 66, 66, 66, 135, 135, 135, 66, 66, 66, 135, 135, 33, 135, 66, 135, 135, 135, 66, 135, 33, 66, 66, 66, 135, 33, 33, 135, 33, 135, 33, 33, 66, 33, 66, 135, 33, 33, 66, 33, 33, 33, 33, 33, 135, 66, 66, 135, 66, 33, 135, 135, 135, 66, 66, 33, 33, 33, 135, 33, 66, 66, 33, 135, 135, 135, 33, 33, 135, 66, 135, 135, 33, 135, 33, 66, 33, 33, 66, 66, 135, 135, 135, 33, 135, 66, 66, 33, 33, 33, 33, 135, 66, 135, 66, 135, 135, 135, 33, 66, 66, 135, 66, 135, 33, 33, 33, 66, 66, 66, 135, 135, 66, 135, 33, 66, 66, 33, 135, 135, 135, 135, 135, 135, 66, 66, 66, 66, 66, 135, 33, 135, 33, 135, 66, 33, 66, 33, 33, 66, 66, 66, 135, 66, 33, 33]
Prompts retrieved: 12537 . Total input tokens: 2760590 . Total output tokens: 2526223
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 0.8372647762298584,
    "estimated_duration": 3599.65086315393,
    "input_throughput": 293.2392723985303,
    "output_throughput": 249.43196830297842,
    "total_throughput": 542.6712407015087,
    "itl": 18.52086306783482,
    "ttft": 4278.831275238456,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1242,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.168045483604119,
    "arrivals": 4238,
    "finished_requests": 4233,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8373299953527749. Arrivals time: 0.024273866787552834 Scheduler time: 0.38934235321357846 Scheduler overhead time: 0.15024244505912066 Adapter cache time: 0.05006301123648882 Engine time: 0.14881346700713038 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-8/adapters_160_slots_128_rate_3.2-1.6-0.8_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-8/adapters_160_slots_128_rate_3.2-1.6-0.8_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [53 53 54]
Adapter prompts. [8640, 34560, 8640, 8640, 17280, 8640, 8640, 8640, 34560, 8640, 17280, 34560, 17280, 8640, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 8640, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 8640, 17280, 17280, 17280, 34560, 8640, 8640, 34560, 8640, 34560, 8640, 8640, 17280, 8640, 17280, 34560, 8640, 8640, 17280, 8640, 8640, 8640, 8640, 8640, 34560, 17280, 17280, 34560, 17280, 8640, 34560, 34560, 34560, 17280, 17280, 8640, 8640, 8640, 34560, 8640, 17280, 17280, 8640, 34560, 34560, 34560, 8640, 8640, 34560, 17280, 34560, 34560, 8640, 34560, 8640, 17280, 8640, 8640, 17280, 17280, 34560, 34560, 34560, 8640, 34560, 17280, 17280, 8640, 8640, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 8640, 17280, 17280, 34560, 17280, 34560, 8640, 8640, 8640, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 8640, 17280, 17280, 8640, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 8640, 34560, 8640, 34560, 17280, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 8640]
Prompts retrieved: 3240000 . Total input tokens: 721625136 . Total output tokens: 648199760
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 6.962727682199329,
    "estimated_duration": 3600.0018144258015,
    "input_throughput": 4688.655414661845,
    "output_throughput": 4130.634862574869,
    "total_throughput": 8819.290277236714,
    "itl": 207.49788072598759,
    "ttft": 2191093.25895128,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 437,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3374331440986238,
    "arrivals": 1078565,
    "finished_requests": 68054,
    "scheduler_time": 62.79946557049788
}
#Debug simulation 
Total elapsed time: 6.962831255048513. Arrivals time: 0.2719128015451133 Scheduler time: 6.606550338212401 Scheduler overhead time: 0.02892445120960474 Adapter cache time: 0.012251434847712517 Engine time: 0.03006994817405939 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-16/adapters_160_slots_128_rate_3.2-1.6-0.8_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-16/adapters_160_slots_128_rate_3.2-1.6-0.8_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [53 53 54]
Adapter prompts. [8640, 34560, 8640, 8640, 17280, 8640, 8640, 8640, 34560, 8640, 17280, 34560, 17280, 8640, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 8640, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 8640, 17280, 17280, 17280, 34560, 8640, 8640, 34560, 8640, 34560, 8640, 8640, 17280, 8640, 17280, 34560, 8640, 8640, 17280, 8640, 8640, 8640, 8640, 8640, 34560, 17280, 17280, 34560, 17280, 8640, 34560, 34560, 34560, 17280, 17280, 8640, 8640, 8640, 34560, 8640, 17280, 17280, 8640, 34560, 34560, 34560, 8640, 8640, 34560, 17280, 34560, 34560, 8640, 34560, 8640, 17280, 8640, 8640, 17280, 17280, 34560, 34560, 34560, 8640, 34560, 17280, 17280, 8640, 8640, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 8640, 17280, 17280, 34560, 17280, 34560, 8640, 8640, 8640, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 8640, 17280, 17280, 8640, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 8640, 34560, 8640, 34560, 17280, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 8640]
Prompts retrieved: 3240000 . Total input tokens: 721625136 . Total output tokens: 648199760
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.958510406315327,
    "estimated_duration": 3600.0908029170746,
    "input_throughput": 4688.539518593026,
    "output_throughput": 4130.532759882314,
    "total_throughput": 8819.07227847534,
    "itl": 207.50202024442245,
    "ttft": 2191135.473248666,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 437,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4263704071752785,
    "arrivals": 1078565,
    "finished_requests": 68054,
    "scheduler_time": 62.79951679867349
}
#Debug simulation 
Total elapsed time: 6.958605010993779. Arrivals time: 0.25969891622662544 Scheduler time: 6.615139765664935 Scheduler overhead time: 0.028811891097575426 Adapter cache time: 0.01222437946125865 Engine time: 0.029549953527748585 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-32/adapters_160_slots_128_rate_3.2-1.6-0.8_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-32/adapters_160_slots_128_rate_3.2-1.6-0.8_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [53 53 54]
Adapter prompts. [8640, 34560, 8640, 8640, 17280, 8640, 8640, 8640, 34560, 8640, 17280, 34560, 17280, 8640, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 8640, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 8640, 17280, 17280, 17280, 34560, 8640, 8640, 34560, 8640, 34560, 8640, 8640, 17280, 8640, 17280, 34560, 8640, 8640, 17280, 8640, 8640, 8640, 8640, 8640, 34560, 17280, 17280, 34560, 17280, 8640, 34560, 34560, 34560, 17280, 17280, 8640, 8640, 8640, 34560, 8640, 17280, 17280, 8640, 34560, 34560, 34560, 8640, 8640, 34560, 17280, 34560, 34560, 8640, 34560, 8640, 17280, 8640, 8640, 17280, 17280, 34560, 34560, 34560, 8640, 34560, 17280, 17280, 8640, 8640, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 8640, 17280, 17280, 34560, 17280, 34560, 8640, 8640, 8640, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 8640, 17280, 17280, 8640, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 8640, 34560, 8640, 34560, 17280, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 8640]
Prompts retrieved: 3240000 . Total input tokens: 721625136 . Total output tokens: 648199760
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.718712138943374,
    "estimated_duration": 3600.1665336235587,
    "input_throughput": 4506.097106477986,
    "output_throughput": 3971.567389025416,
    "total_throughput": 8477.664495503403,
    "itl": 175.95935693605458,
    "ttft": 2212274.023838865,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 749,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4451841375417964,
    "arrivals": 1078565,
    "finished_requests": 65357,
    "scheduler_time": 60.70730277695023
}
#Debug simulation 
Total elapsed time: 5.718798670917749. Arrivals time: 0.24376319348812103 Scheduler time: 5.374804299324751 Scheduler overhead time: 0.03282244969159365 Adapter cache time: 0.018881432712078094 Engine time: 0.03353310422971845 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-16/adapters_160_slots_128_rate_3.2-1.6-0.8_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-16/adapters_160_slots_128_rate_3.2-1.6-0.8_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [53 53 54]
Adapter prompts. [8640, 34560, 8640, 8640, 17280, 8640, 8640, 8640, 34560, 8640, 17280, 34560, 17280, 8640, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 8640, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 8640, 17280, 17280, 17280, 34560, 8640, 8640, 34560, 8640, 34560, 8640, 8640, 17280, 8640, 17280, 34560, 8640, 8640, 17280, 8640, 8640, 8640, 8640, 8640, 34560, 17280, 17280, 34560, 17280, 8640, 34560, 34560, 34560, 17280, 17280, 8640, 8640, 8640, 34560, 8640, 17280, 17280, 8640, 34560, 34560, 34560, 8640, 8640, 34560, 17280, 34560, 34560, 8640, 34560, 8640, 17280, 8640, 8640, 17280, 17280, 34560, 34560, 34560, 8640, 34560, 17280, 17280, 8640, 8640, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 8640, 17280, 17280, 34560, 17280, 34560, 8640, 8640, 8640, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 8640, 17280, 17280, 8640, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 8640, 34560, 8640, 34560, 17280, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 8640]
Prompts retrieved: 3240000 . Total input tokens: 721625136 . Total output tokens: 648199760
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 6.981168715283275,
    "estimated_duration": 3600.0331556849765,
    "input_throughput": 4688.614596047632,
    "output_throughput": 4130.598901990012,
    "total_throughput": 8819.213498037645,
    "itl": 207.49938975106016,
    "ttft": 2191108.0062068524,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 437,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3687584672751816,
    "arrivals": 1078565,
    "finished_requests": 68054,
    "scheduler_time": 62.799481506463486
}
#Debug simulation 
Total elapsed time: 6.981261366978288. Arrivals time: 0.26287042861804366 Scheduler time: 6.634194495622069 Scheduler overhead time: 0.02900140779092908 Adapter cache time: 0.01193054486066103 Engine time: 0.03004124714061618 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-32/adapters_160_slots_128_rate_3.2-1.6-0.8_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-32/adapters_160_slots_128_rate_3.2-1.6-0.8_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [53 53 54]
Adapter prompts. [8640, 34560, 8640, 8640, 17280, 8640, 8640, 8640, 34560, 8640, 17280, 34560, 17280, 8640, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 8640, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 8640, 17280, 17280, 17280, 34560, 8640, 8640, 34560, 8640, 34560, 8640, 8640, 17280, 8640, 17280, 34560, 8640, 8640, 17280, 8640, 8640, 8640, 8640, 8640, 34560, 17280, 17280, 34560, 17280, 8640, 34560, 34560, 34560, 17280, 17280, 8640, 8640, 8640, 34560, 8640, 17280, 17280, 8640, 34560, 34560, 34560, 8640, 8640, 34560, 17280, 34560, 34560, 8640, 34560, 8640, 17280, 8640, 8640, 17280, 17280, 34560, 34560, 34560, 8640, 34560, 17280, 17280, 8640, 8640, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 8640, 17280, 17280, 34560, 17280, 34560, 8640, 8640, 8640, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 8640, 17280, 17280, 8640, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 8640, 34560, 8640, 34560, 17280, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 8640]
Prompts retrieved: 3240000 . Total input tokens: 721625136 . Total output tokens: 648199760
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.706520716194063,
    "estimated_duration": 3600.195846467432,
    "input_throughput": 4506.06041777365,
    "output_throughput": 3971.5350524693586,
    "total_throughput": 8477.59547024301,
    "itl": 175.96062771285347,
    "ttft": 2212286.190034253,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 749,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.474484769776466,
    "arrivals": 1078565,
    "finished_requests": 65357,
    "scheduler_time": 60.70731498861227
}
#Debug simulation 
Total elapsed time: 5.706611861940473. Arrivals time: 0.24700664915144444 Scheduler time: 5.35842953575775 Scheduler overhead time: 0.032925115432590246 Adapter cache time: 0.019212046172469854 Engine time: 0.034001532942056656 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-16/adapters_160_slots_128_rate_3.2-1.6-0.8_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-16/adapters_160_slots_128_rate_3.2-1.6-0.8_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [53 53 54]
Adapter prompts. [8640, 34560, 8640, 8640, 17280, 8640, 8640, 8640, 34560, 8640, 17280, 34560, 17280, 8640, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 8640, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 8640, 17280, 17280, 17280, 34560, 8640, 8640, 34560, 8640, 34560, 8640, 8640, 17280, 8640, 17280, 34560, 8640, 8640, 17280, 8640, 8640, 8640, 8640, 8640, 34560, 17280, 17280, 34560, 17280, 8640, 34560, 34560, 34560, 17280, 17280, 8640, 8640, 8640, 34560, 8640, 17280, 17280, 8640, 34560, 34560, 34560, 8640, 8640, 34560, 17280, 34560, 34560, 8640, 34560, 8640, 17280, 8640, 8640, 17280, 17280, 34560, 34560, 34560, 8640, 34560, 17280, 17280, 8640, 8640, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 8640, 17280, 17280, 34560, 17280, 34560, 8640, 8640, 8640, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 8640, 17280, 17280, 8640, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 8640, 34560, 8640, 34560, 17280, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 8640]
Prompts retrieved: 3240000 . Total input tokens: 721625136 . Total output tokens: 648199760
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 6.942459382116795,
    "estimated_duration": 3600.2035360058403,
    "input_throughput": 4688.789350706481,
    "output_throughput": 4130.7786771686215,
    "total_throughput": 8819.568027875102,
    "itl": 207.49832481142573,
    "ttft": 2191123.135022593,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 437,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3066519788722413,
    "arrivals": 1078565,
    "finished_requests": 68059,
    "scheduler_time": 62.80352097973509
}
#Debug simulation 
Total elapsed time: 6.942554754205048. Arrivals time: 0.26374207297340035 Scheduler time: 6.594970882870257 Scheduler overhead time: 0.029034082777798176 Adapter cache time: 0.012061206623911858 Engine time: 0.029730239417403936 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-32/adapters_160_slots_128_rate_3.2-1.6-0.8_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-32/adapters_160_slots_128_rate_3.2-1.6-0.8_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [53 53 54]
Adapter prompts. [8640, 34560, 8640, 8640, 17280, 8640, 8640, 8640, 34560, 8640, 17280, 34560, 17280, 8640, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 8640, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 8640, 17280, 17280, 17280, 34560, 8640, 8640, 34560, 8640, 34560, 8640, 8640, 17280, 8640, 17280, 34560, 8640, 8640, 17280, 8640, 8640, 8640, 8640, 8640, 34560, 17280, 17280, 34560, 17280, 8640, 34560, 34560, 34560, 17280, 17280, 8640, 8640, 8640, 34560, 8640, 17280, 17280, 8640, 34560, 34560, 34560, 8640, 8640, 34560, 17280, 34560, 34560, 8640, 34560, 8640, 17280, 8640, 8640, 17280, 17280, 34560, 34560, 34560, 8640, 34560, 17280, 17280, 8640, 8640, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 8640, 17280, 17280, 34560, 17280, 34560, 8640, 8640, 8640, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 8640, 17280, 17280, 8640, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 8640, 34560, 8640, 34560, 17280, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 8640]
Prompts retrieved: 3240000 . Total input tokens: 721625136 . Total output tokens: 648199760
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.7594205108471215,
    "estimated_duration": 3600.029415948849,
    "input_throughput": 4506.174290724322,
    "output_throughput": 3971.675324833833,
    "total_throughput": 8477.849615558156,
    "itl": 175.96177490134457,
    "ttft": 2212302.257263886,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 749,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5069292466715103,
    "arrivals": 1078565,
    "finished_requests": 65356,
    "scheduler_time": 60.70394868648687
}
#Debug simulation 
Total elapsed time: 5.759510801639408. Arrivals time: 0.25026954198256135 Scheduler time: 5.4080919935368 Scheduler overhead time: 0.0329462606459856 Adapter cache time: 0.01942088594660163 Engine time: 0.03371929656714201 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-8/adapters_160_slots_128_rate_3.2-1.6-0.4_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-8/adapters_160_slots_128_rate_3.2-1.6-0.4_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [53 53 54]
Adapter prompts. [4320, 34560, 4320, 4320, 17280, 4320, 4320, 4320, 34560, 4320, 17280, 34560, 17280, 4320, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 4320, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 4320, 17280, 17280, 17280, 34560, 4320, 4320, 34560, 4320, 34560, 4320, 4320, 17280, 4320, 17280, 34560, 4320, 4320, 17280, 4320, 4320, 4320, 4320, 4320, 34560, 17280, 17280, 34560, 17280, 4320, 34560, 34560, 34560, 17280, 17280, 4320, 4320, 4320, 34560, 4320, 17280, 17280, 4320, 34560, 34560, 34560, 4320, 4320, 34560, 17280, 34560, 34560, 4320, 34560, 4320, 17280, 4320, 4320, 17280, 17280, 34560, 34560, 34560, 4320, 34560, 17280, 17280, 4320, 4320, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 4320, 17280, 17280, 34560, 17280, 34560, 4320, 4320, 4320, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 4320, 17280, 17280, 4320, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 4320, 34560, 4320, 34560, 17280, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 34560, 17280, 4320, 4320]
Prompts retrieved: 3011040 . Total input tokens: 670651597 . Total output tokens: 602378110
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 6.007689816877246,
    "estimated_duration": 3600.1492325927975,
    "input_throughput": 4684.768022200386,
    "output_throughput": 4129.436320419753,
    "total_throughput": 8814.20434262014,
    "itl": 207.597727125482,
    "ttft": 2182304.5074979737,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 637,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9495306928851959,
    "arrivals": 1002554,
    "finished_requests": 68174,
    "scheduler_time": 62.788052233601285
}
#Debug simulation 
Total elapsed time: 6.00780936004594. Arrivals time: 0.2537097870372236 Scheduler time: 5.666840186342597 Scheduler overhead time: 0.028946570120751858 Adapter cache time: 0.015679921489208937 Engine time: 0.029579465277493 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-16/adapters_160_slots_128_rate_3.2-1.6-0.4_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-16/adapters_160_slots_128_rate_3.2-1.6-0.4_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [53 53 54]
Adapter prompts. [4320, 34560, 4320, 4320, 17280, 4320, 4320, 4320, 34560, 4320, 17280, 34560, 17280, 4320, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 4320, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 4320, 17280, 17280, 17280, 34560, 4320, 4320, 34560, 4320, 34560, 4320, 4320, 17280, 4320, 17280, 34560, 4320, 4320, 17280, 4320, 4320, 4320, 4320, 4320, 34560, 17280, 17280, 34560, 17280, 4320, 34560, 34560, 34560, 17280, 17280, 4320, 4320, 4320, 34560, 4320, 17280, 17280, 4320, 34560, 34560, 34560, 4320, 4320, 34560, 17280, 34560, 34560, 4320, 34560, 4320, 17280, 4320, 4320, 17280, 17280, 34560, 34560, 34560, 4320, 34560, 17280, 17280, 4320, 4320, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 4320, 17280, 17280, 34560, 17280, 34560, 4320, 4320, 4320, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 4320, 17280, 17280, 4320, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 4320, 34560, 4320, 34560, 17280, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 34560, 17280, 4320, 4320]
Prompts retrieved: 3011040 . Total input tokens: 670651597 . Total output tokens: 602378110
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.831316403113306,
    "estimated_duration": 3600.0413934476833,
    "input_throughput": 4684.849743865895,
    "output_throughput": 4129.559462026793,
    "total_throughput": 8814.409205892687,
    "itl": 207.6051341377817,
    "ttft": 2182286.7415801883,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 637,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.072594713731673,
    "arrivals": 1002554,
    "finished_requests": 68173,
    "scheduler_time": 62.78406437369681
}
#Debug simulation 
Total elapsed time: 5.831458081956953. Arrivals time: 0.3596269991248846 Scheduler time: 5.385351343546063 Scheduler overhead time: 0.028570302296429873 Adapter cache time: 0.01571960747241974 Engine time: 0.029174003284424543 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-32/adapters_160_slots_128_rate_3.2-1.6-0.4_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-32/adapters_160_slots_128_rate_3.2-1.6-0.4_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [53 53 54]
Adapter prompts. [4320, 34560, 4320, 4320, 17280, 4320, 4320, 4320, 34560, 4320, 17280, 34560, 17280, 4320, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 4320, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 4320, 17280, 17280, 17280, 34560, 4320, 4320, 34560, 4320, 34560, 4320, 4320, 17280, 4320, 17280, 34560, 4320, 4320, 17280, 4320, 4320, 4320, 4320, 4320, 34560, 17280, 17280, 34560, 17280, 4320, 34560, 34560, 34560, 17280, 17280, 4320, 4320, 4320, 34560, 4320, 17280, 17280, 4320, 34560, 34560, 34560, 4320, 4320, 34560, 17280, 34560, 34560, 4320, 34560, 4320, 17280, 4320, 4320, 17280, 17280, 34560, 34560, 34560, 4320, 34560, 17280, 17280, 4320, 4320, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 4320, 17280, 17280, 34560, 17280, 34560, 4320, 4320, 4320, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 4320, 17280, 17280, 4320, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 4320, 34560, 4320, 34560, 17280, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 34560, 17280, 4320, 4320]
Prompts retrieved: 3011040 . Total input tokens: 670651597 . Total output tokens: 602378110
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.465168532915413,
    "estimated_duration": 3600.1097462925486,
    "input_throughput": 4499.709214887811,
    "output_throughput": 3967.009343175578,
    "total_throughput": 8466.718558063389,
    "itl": 175.6052527476063,
    "ttft": 2204370.6197918127,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1004,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.270182330682841,
    "arrivals": 1002554,
    "finished_requests": 65425,
    "scheduler_time": 60.65645326348525
}
#Debug simulation 
Total elapsed time: 5.465261788107455. Arrivals time: 0.3050212417729199 Scheduler time: 5.054542168509215 Scheduler overhead time: 0.03307725302875042 Adapter cache time: 0.023751820903271437 Engine time: 0.03368331445381045 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-16-16/adapters_160_slots_128_rate_3.2-1.6-0.4_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-16-16/adapters_160_slots_128_rate_3.2-1.6-0.4_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [53 53 54]
Adapter prompts. [4320, 34560, 4320, 4320, 17280, 4320, 4320, 4320, 34560, 4320, 17280, 34560, 17280, 4320, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 4320, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 4320, 17280, 17280, 17280, 34560, 4320, 4320, 34560, 4320, 34560, 4320, 4320, 17280, 4320, 17280, 34560, 4320, 4320, 17280, 4320, 4320, 4320, 4320, 4320, 34560, 17280, 17280, 34560, 17280, 4320, 34560, 34560, 34560, 17280, 17280, 4320, 4320, 4320, 34560, 4320, 17280, 17280, 4320, 34560, 34560, 34560, 4320, 4320, 34560, 17280, 34560, 34560, 4320, 34560, 4320, 17280, 4320, 4320, 17280, 17280, 34560, 34560, 34560, 4320, 34560, 17280, 17280, 4320, 4320, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 4320, 17280, 17280, 34560, 17280, 34560, 4320, 4320, 4320, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 4320, 17280, 17280, 4320, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 4320, 34560, 4320, 34560, 17280, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 34560, 17280, 4320, 4320]
Prompts retrieved: 3011040 . Total input tokens: 670651597 . Total output tokens: 602378110
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.864823380019516,
    "estimated_duration": 3600.1946826060835,
    "input_throughput": 4684.708880185129,
    "output_throughput": 4129.384189090152,
    "total_throughput": 8814.09306927528,
    "itl": 207.59997488959337,
    "ttft": 2182324.1246931297,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 637,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9949616032279904,
    "arrivals": 1002554,
    "finished_requests": 68174,
    "scheduler_time": 62.7880713364917
}
#Debug simulation 
Total elapsed time: 5.864918377716094. Arrivals time: 0.2567731630988419 Scheduler time: 5.521758635062724 Scheduler overhead time: 0.028496915474534035 Adapter cache time: 0.01560980686917901 Engine time: 0.02936445875093341 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-16-32/adapters_160_slots_128_rate_3.2-1.6-0.4_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-16-32/adapters_160_slots_128_rate_3.2-1.6-0.4_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [53 53 54]
Adapter prompts. [4320, 34560, 4320, 4320, 17280, 4320, 4320, 4320, 34560, 4320, 17280, 34560, 17280, 4320, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 4320, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 4320, 17280, 17280, 17280, 34560, 4320, 4320, 34560, 4320, 34560, 4320, 4320, 17280, 4320, 17280, 34560, 4320, 4320, 17280, 4320, 4320, 4320, 4320, 4320, 34560, 17280, 17280, 34560, 17280, 4320, 34560, 34560, 34560, 17280, 17280, 4320, 4320, 4320, 34560, 4320, 17280, 17280, 4320, 34560, 34560, 34560, 4320, 4320, 34560, 17280, 34560, 34560, 4320, 34560, 4320, 17280, 4320, 4320, 17280, 17280, 34560, 34560, 34560, 4320, 34560, 17280, 17280, 4320, 4320, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 4320, 17280, 17280, 34560, 17280, 34560, 4320, 4320, 4320, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 4320, 17280, 17280, 4320, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 4320, 34560, 4320, 34560, 17280, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 34560, 17280, 4320, 4320]
Prompts retrieved: 3011040 . Total input tokens: 670651597 . Total output tokens: 602378110
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.375589440111071,
    "estimated_duration": 3600.14798761725,
    "input_throughput": 4499.661418285633,
    "output_throughput": 3966.967204993229,
    "total_throughput": 8466.628623278863,
    "itl": 175.6069347883411,
    "ttft": 2204386.6352058114,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1004,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3084114817529913,
    "arrivals": 1002554,
    "finished_requests": 65425,
    "scheduler_time": 60.65646543714419
}
#Debug simulation 
Total elapsed time: 5.375699462834746. Arrivals time: 0.2513177255168557 Scheduler time: 5.0198731743730605 Scheduler overhead time: 0.032705001533031464 Adapter cache time: 0.0234661134891212 Engine time: 0.033297182992100716 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_16-16-16/adapters_160_slots_128_rate_3.2-1.6-0.4_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_16-16-16/adapters_160_slots_128_rate_3.2-1.6-0.4_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [53 53 54]
Adapter prompts. [4320, 34560, 4320, 4320, 17280, 4320, 4320, 4320, 34560, 4320, 17280, 34560, 17280, 4320, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 4320, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 4320, 17280, 17280, 17280, 34560, 4320, 4320, 34560, 4320, 34560, 4320, 4320, 17280, 4320, 17280, 34560, 4320, 4320, 17280, 4320, 4320, 4320, 4320, 4320, 34560, 17280, 17280, 34560, 17280, 4320, 34560, 34560, 34560, 17280, 17280, 4320, 4320, 4320, 34560, 4320, 17280, 17280, 4320, 34560, 34560, 34560, 4320, 4320, 34560, 17280, 34560, 34560, 4320, 34560, 4320, 17280, 4320, 4320, 17280, 17280, 34560, 34560, 34560, 4320, 34560, 17280, 17280, 4320, 4320, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 4320, 17280, 17280, 34560, 17280, 34560, 4320, 4320, 4320, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 4320, 17280, 17280, 4320, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 4320, 34560, 4320, 34560, 17280, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 34560, 17280, 4320, 4320]
Prompts retrieved: 3011040 . Total input tokens: 670651597 . Total output tokens: 602378110
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.849947014823556,
    "estimated_duration": 3600.2129942579754,
    "input_throughput": 4686.3280108451945,
    "output_throughput": 4129.870933668041,
    "total_throughput": 8816.198944513237,
    "itl": 207.56891606673537,
    "ttft": 2182381.4607226024,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 636,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.901671987557753,
    "arrivals": 1002554,
    "finished_requests": 68187,
    "scheduler_time": 62.78891233911571
}
#Debug simulation 
Total elapsed time: 5.850042217876762. Arrivals time: 0.36155049595981836 Scheduler time: 5.402693302370608 Scheduler overhead time: 0.028618987649679184 Adapter cache time: 0.01511828787624836 Engine time: 0.029035239480435848 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_16-16-32/adapters_160_slots_128_rate_3.2-1.6-0.4_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_16-16-32/adapters_160_slots_128_rate_3.2-1.6-0.4_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [53 53 54]
Adapter prompts. [4320, 34560, 4320, 4320, 17280, 4320, 4320, 4320, 34560, 4320, 17280, 34560, 17280, 4320, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 4320, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 4320, 17280, 17280, 17280, 34560, 4320, 4320, 34560, 4320, 34560, 4320, 4320, 17280, 4320, 17280, 34560, 4320, 4320, 17280, 4320, 4320, 4320, 4320, 4320, 34560, 17280, 17280, 34560, 17280, 4320, 34560, 34560, 34560, 17280, 17280, 4320, 4320, 4320, 34560, 4320, 17280, 17280, 4320, 34560, 34560, 34560, 4320, 4320, 34560, 17280, 34560, 34560, 4320, 34560, 4320, 17280, 4320, 4320, 17280, 17280, 34560, 34560, 34560, 4320, 34560, 17280, 17280, 4320, 4320, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 4320, 17280, 17280, 34560, 17280, 34560, 4320, 4320, 4320, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 4320, 17280, 17280, 4320, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 4320, 34560, 4320, 34560, 17280, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 34560, 17280, 4320, 4320]
Prompts retrieved: 3011040 . Total input tokens: 670651597 . Total output tokens: 602378110
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.343834426254034,
    "estimated_duration": 3600.1897503646564,
    "input_throughput": 4499.60922153039,
    "output_throughput": 3966.921187571693,
    "total_throughput": 8466.530409102083,
    "itl": 175.60880546930431,
    "ttft": 2204404.141279944,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1004,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3501617388427642,
    "arrivals": 1002554,
    "finished_requests": 65425,
    "scheduler_time": 60.65647792749561
}
#Debug simulation 
Total elapsed time: 5.343931616283953. Arrivals time: 0.24167472030967474 Scheduler time: 4.997148602735251 Scheduler overhead time: 0.03268446167930961 Adapter cache time: 0.023612404242157936 Engine time: 0.03376766759902239 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-8/adapters_160_slots_128_rate_3.2-1.6-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-8/adapters_160_slots_128_rate_3.2-1.6-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [53 53 54]
Adapter prompts. [1080, 34560, 1080, 1080, 17280, 1080, 1080, 1080, 34560, 1080, 17280, 34560, 17280, 1080, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 1080, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 1080, 17280, 17280, 17280, 34560, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 17280, 1080, 17280, 34560, 1080, 1080, 17280, 1080, 1080, 1080, 1080, 1080, 34560, 17280, 17280, 34560, 17280, 1080, 34560, 34560, 34560, 17280, 17280, 1080, 1080, 1080, 34560, 1080, 17280, 17280, 1080, 34560, 34560, 34560, 1080, 1080, 34560, 17280, 34560, 34560, 1080, 34560, 1080, 17280, 1080, 1080, 17280, 17280, 34560, 34560, 34560, 1080, 34560, 17280, 17280, 1080, 1080, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 17280, 34560, 17280, 34560, 1080, 1080, 1080, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 1080, 17280, 17280, 1080, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 1080, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 34560, 17280, 1080, 1080]
Prompts retrieved: 2839320 . Total input tokens: 632348578 . Total output tokens: 567998722
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.082431341055781,
    "estimated_duration": 3600.1834565766135,
    "input_throughput": 4758.375290210838,
    "output_throughput": 4210.572095238284,
    "total_throughput": 8968.947385449123,
    "itl": 204.18737177940827,
    "ttft": 2168790.3661328084,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 968,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9625521361269724,
    "arrivals": 945185,
    "finished_requests": 69378,
    "scheduler_time": 63.99555857258542
}
#Debug simulation 
Total elapsed time: 5.082522383425385. Arrivals time: 0.24989478616043925 Scheduler time: 4.740405110642314 Scheduler overhead time: 0.027618209831416607 Adapter cache time: 0.02272054646164179 Engine time: 0.029151644092053175 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-16/adapters_160_slots_128_rate_3.2-1.6-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-16/adapters_160_slots_128_rate_3.2-1.6-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [53 53 54]
Adapter prompts. [1080, 34560, 1080, 1080, 17280, 1080, 1080, 1080, 34560, 1080, 17280, 34560, 17280, 1080, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 1080, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 1080, 17280, 17280, 17280, 34560, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 17280, 1080, 17280, 34560, 1080, 1080, 17280, 1080, 1080, 1080, 1080, 1080, 34560, 17280, 17280, 34560, 17280, 1080, 34560, 34560, 34560, 17280, 17280, 1080, 1080, 1080, 34560, 1080, 17280, 17280, 1080, 34560, 34560, 34560, 1080, 1080, 34560, 17280, 34560, 34560, 1080, 34560, 1080, 17280, 1080, 1080, 17280, 17280, 34560, 34560, 34560, 1080, 34560, 17280, 17280, 1080, 1080, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 17280, 34560, 17280, 34560, 1080, 1080, 1080, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 1080, 17280, 17280, 1080, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 1080, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 34560, 17280, 1080, 1080]
Prompts retrieved: 2839320 . Total input tokens: 632348578 . Total output tokens: 567998722
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.115509353112429,
    "estimated_duration": 3600.1451792477574,
    "input_throughput": 4758.34977398868,
    "output_throughput": 4210.554920778878,
    "total_throughput": 8968.904694767558,
    "itl": 204.1964667280186,
    "ttft": 2168821.618606052,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 968,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1415688531217167,
    "arrivals": 945185,
    "finished_requests": 69377,
    "scheduler_time": 63.99165312010998
}
#Debug simulation 
Total elapsed time: 5.115602608304471. Arrivals time: 0.25177196552976966 Scheduler time: 4.771568066440523 Scheduler overhead time: 0.027860896196216345 Adapter cache time: 0.022906607016921043 Engine time: 0.02874802378937602 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-32/adapters_160_slots_128_rate_3.2-1.6-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-32/adapters_160_slots_128_rate_3.2-1.6-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [53 53 54]
Adapter prompts. [1080, 34560, 1080, 1080, 17280, 1080, 1080, 1080, 34560, 1080, 17280, 34560, 17280, 1080, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 1080, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 1080, 17280, 17280, 17280, 34560, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 17280, 1080, 17280, 34560, 1080, 1080, 17280, 1080, 1080, 1080, 1080, 1080, 34560, 17280, 17280, 34560, 17280, 1080, 34560, 34560, 34560, 17280, 17280, 1080, 1080, 1080, 34560, 1080, 17280, 17280, 1080, 34560, 34560, 34560, 1080, 1080, 34560, 17280, 34560, 34560, 1080, 34560, 1080, 17280, 1080, 1080, 17280, 17280, 34560, 34560, 34560, 1080, 34560, 17280, 17280, 1080, 1080, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 17280, 34560, 17280, 34560, 1080, 1080, 1080, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 1080, 17280, 17280, 1080, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 1080, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 34560, 17280, 1080, 1080]
Prompts retrieved: 2839320 . Total input tokens: 632348578 . Total output tokens: 567998722
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.051301893312484,
    "estimated_duration": 3600.12115655257,
    "input_throughput": 4623.884107261689,
    "output_throughput": 4100.092846357088,
    "total_throughput": 8723.976953618778,
    "itl": 170.54277373301915,
    "ttft": 2184255.7798165143,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 951,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.096397674400332,
    "arrivals": 945185,
    "finished_requests": 67422,
    "scheduler_time": 62.63393225288903
}
#Debug simulation 
Total elapsed time: 5.051454714965075. Arrivals time: 0.24274851055815816 Scheduler time: 4.698697394225746 Scheduler overhead time: 0.03260244335979223 Adapter cache time: 0.028290268033742905 Engine time: 0.03397968644276261 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-16-16/adapters_160_slots_128_rate_3.2-1.6-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-16-16/adapters_160_slots_128_rate_3.2-1.6-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [53 53 54]
Adapter prompts. [1080, 34560, 1080, 1080, 17280, 1080, 1080, 1080, 34560, 1080, 17280, 34560, 17280, 1080, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 1080, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 1080, 17280, 17280, 17280, 34560, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 17280, 1080, 17280, 34560, 1080, 1080, 17280, 1080, 1080, 1080, 1080, 1080, 34560, 17280, 17280, 34560, 17280, 1080, 34560, 34560, 34560, 17280, 17280, 1080, 1080, 1080, 34560, 1080, 17280, 17280, 1080, 34560, 34560, 34560, 1080, 1080, 34560, 17280, 34560, 34560, 1080, 34560, 1080, 17280, 1080, 1080, 17280, 17280, 34560, 34560, 34560, 1080, 34560, 17280, 17280, 1080, 1080, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 17280, 34560, 17280, 34560, 1080, 1080, 1080, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 1080, 17280, 17280, 1080, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 1080, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 34560, 17280, 1080, 1080]
Prompts retrieved: 2839320 . Total input tokens: 632348578 . Total output tokens: 567998722
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.149790474679321,
    "estimated_duration": 3600.033189560382,
    "input_throughput": 4758.497796541681,
    "output_throughput": 4210.685902551663,
    "total_throughput": 8969.183699093344,
    "itl": 204.1906983426633,
    "ttft": 2168775.4034012416,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 968,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.029613735869031,
    "arrivals": 945185,
    "finished_requests": 69377,
    "scheduler_time": 63.99161854995884
}
#Debug simulation 
Total elapsed time: 5.149907800834626. Arrivals time: 0.31022015074267983 Scheduler time: 4.746790608856827 Scheduler overhead time: 0.027900672983378172 Adapter cache time: 0.0231908755376935 Engine time: 0.029021526221185923 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-16-32/adapters_160_slots_128_rate_3.2-1.6-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-16-32/adapters_160_slots_128_rate_3.2-1.6-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [53 53 54]
Adapter prompts. [1080, 34560, 1080, 1080, 17280, 1080, 1080, 1080, 34560, 1080, 17280, 34560, 17280, 1080, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 1080, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 1080, 17280, 17280, 17280, 34560, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 17280, 1080, 17280, 34560, 1080, 1080, 17280, 1080, 1080, 1080, 1080, 1080, 34560, 17280, 17280, 34560, 17280, 1080, 34560, 34560, 34560, 17280, 17280, 1080, 1080, 1080, 34560, 1080, 17280, 17280, 1080, 34560, 34560, 34560, 1080, 1080, 34560, 17280, 34560, 34560, 1080, 34560, 1080, 17280, 1080, 1080, 17280, 17280, 34560, 34560, 34560, 1080, 34560, 17280, 17280, 1080, 1080, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 17280, 34560, 17280, 34560, 1080, 1080, 1080, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 1080, 17280, 17280, 1080, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 1080, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 34560, 17280, 1080, 1080]
Prompts retrieved: 2839320 . Total input tokens: 632348578 . Total output tokens: 567998722
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.014448058791459,
    "estimated_duration": 3600.1554986231536,
    "input_throughput": 4623.839999790653,
    "output_throughput": 4100.053735358138,
    "total_throughput": 8723.893735148791,
    "itl": 170.5443054211253,
    "ttft": 2184269.8998754295,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 951,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1307284580916135,
    "arrivals": 945185,
    "finished_requests": 67422,
    "scheduler_time": 62.633943539809025
}
#Debug simulation 
Total elapsed time: 5.0145414168946445. Arrivals time: 0.24227315885946155 Scheduler time: 4.662934745661914 Scheduler overhead time: 0.03254469996318221 Adapter cache time: 0.028065599966794252 Engine time: 0.03361077280715108 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_16-16-16/adapters_160_slots_128_rate_3.2-1.6-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_16-16-16/adapters_160_slots_128_rate_3.2-1.6-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [53 53 54]
Adapter prompts. [1080, 34560, 1080, 1080, 17280, 1080, 1080, 1080, 34560, 1080, 17280, 34560, 17280, 1080, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 1080, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 1080, 17280, 17280, 17280, 34560, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 17280, 1080, 17280, 34560, 1080, 1080, 17280, 1080, 1080, 1080, 1080, 1080, 34560, 17280, 17280, 34560, 17280, 1080, 34560, 34560, 34560, 17280, 17280, 1080, 1080, 1080, 34560, 1080, 17280, 17280, 1080, 34560, 34560, 34560, 1080, 1080, 34560, 17280, 34560, 34560, 1080, 34560, 1080, 17280, 1080, 1080, 17280, 17280, 34560, 34560, 34560, 1080, 34560, 17280, 17280, 1080, 1080, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 17280, 34560, 17280, 34560, 1080, 1080, 1080, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 1080, 17280, 17280, 1080, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 1080, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 34560, 17280, 1080, 1080]
Prompts retrieved: 2839320 . Total input tokens: 632348578 . Total output tokens: 567998722
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.1220848597586155,
    "estimated_duration": 3600.1152548465875,
    "input_throughput": 4758.46543438788,
    "output_throughput": 4210.651861657126,
    "total_throughput": 8969.117296045006,
    "itl": 204.18377639802435,
    "ttft": 2168762.9784754324,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 968,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.89436868546524,
    "arrivals": 945185,
    "finished_requests": 69378,
    "scheduler_time": 63.995540293095466
}
#Debug simulation 
Total elapsed time: 5.122175669763237. Arrivals time: 0.2501501771621406 Scheduler time: 4.779477460775524 Scheduler overhead time: 0.028010977897793055 Adapter cache time: 0.022866767831146717 Engine time: 0.02886917209252715 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_16-16-32/adapters_160_slots_128_rate_3.2-1.6-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_16-16-32/adapters_160_slots_128_rate_3.2-1.6-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [53 53 54]
Adapter prompts. [1080, 34560, 1080, 1080, 17280, 1080, 1080, 1080, 34560, 1080, 17280, 34560, 17280, 1080, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 1080, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 1080, 17280, 17280, 17280, 34560, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 17280, 1080, 17280, 34560, 1080, 1080, 17280, 1080, 1080, 1080, 1080, 1080, 34560, 17280, 17280, 34560, 17280, 1080, 34560, 34560, 34560, 17280, 17280, 1080, 1080, 1080, 34560, 1080, 17280, 17280, 1080, 34560, 34560, 34560, 1080, 1080, 34560, 17280, 34560, 34560, 1080, 34560, 1080, 17280, 1080, 1080, 17280, 17280, 34560, 34560, 34560, 1080, 34560, 17280, 17280, 1080, 1080, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 17280, 34560, 17280, 34560, 1080, 1080, 1080, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 1080, 17280, 17280, 1080, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 1080, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 34560, 17280, 1080, 1080]
Prompts retrieved: 2839320 . Total input tokens: 632348578 . Total output tokens: 567998722
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.058224129024893,
    "estimated_duration": 3600.0079096543395,
    "input_throughput": 4624.029284868528,
    "output_throughput": 4100.22126907418,
    "total_throughput": 8724.250553942707,
    "itl": 170.5472774554987,
    "ttft": 2184213.435635834,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 951,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.171724192462895,
    "arrivals": 945185,
    "finished_requests": 67421,
    "scheduler_time": 62.630601354519484
}
#Debug simulation 
Total elapsed time: 5.058327587787062. Arrivals time: 0.24865382676944137 Scheduler time: 4.699976876378059 Scheduler overhead time: 0.03255066787824035 Adapter cache time: 0.02817842224612832 Engine time: 0.033888249192386866 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-8/adapters_160_slots_128_rate_3.2-1.6-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-8/adapters_160_slots_128_rate_3.2-1.6-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [53 53 54]
Adapter prompts. [540, 34560, 540, 540, 17280, 540, 540, 540, 34560, 540, 17280, 34560, 17280, 540, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 540, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 540, 17280, 17280, 17280, 34560, 540, 540, 34560, 540, 34560, 540, 540, 17280, 540, 17280, 34560, 540, 540, 17280, 540, 540, 540, 540, 540, 34560, 17280, 17280, 34560, 17280, 540, 34560, 34560, 34560, 17280, 17280, 540, 540, 540, 34560, 540, 17280, 17280, 540, 34560, 34560, 34560, 540, 540, 34560, 17280, 34560, 34560, 540, 34560, 540, 17280, 540, 540, 17280, 17280, 34560, 34560, 34560, 540, 34560, 17280, 17280, 540, 540, 540, 540, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 540, 17280, 17280, 34560, 17280, 34560, 540, 540, 540, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 540, 17280, 17280, 540, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 540, 34560, 540, 34560, 17280, 540, 17280, 540, 540, 17280, 17280, 17280, 34560, 17280, 540, 540]
Prompts retrieved: 2810700 . Total input tokens: 625934726 . Total output tokens: 562216680
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.285596730653197,
    "estimated_duration": 3600.2140072221882,
    "input_throughput": 4958.538010292862,
    "output_throughput": 4352.341546521004,
    "total_throughput": 9310.879556813867,
    "itl": 196.48957419466888,
    "ttft": 2148654.5217864844,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 595,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8209902076400157,
    "arrivals": 935737,
    "finished_requests": 72046,
    "scheduler_time": 66.16211721558426
}
#Debug simulation 
Total elapsed time: 5.28569190390408. Arrivals time: 0.257680949755013 Scheduler time: 4.938193498644978 Scheduler overhead time: 0.02874596882611513 Adapter cache time: 0.01775547955185175 Engine time: 0.03016337240114808 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-16/adapters_160_slots_128_rate_3.2-1.6-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-16/adapters_160_slots_128_rate_3.2-1.6-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [53 53 54]
Adapter prompts. [540, 34560, 540, 540, 17280, 540, 540, 540, 34560, 540, 17280, 34560, 17280, 540, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 540, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 540, 17280, 17280, 17280, 34560, 540, 540, 34560, 540, 34560, 540, 540, 17280, 540, 17280, 34560, 540, 540, 17280, 540, 540, 540, 540, 540, 34560, 17280, 17280, 34560, 17280, 540, 34560, 34560, 34560, 17280, 17280, 540, 540, 540, 34560, 540, 17280, 17280, 540, 34560, 34560, 34560, 540, 540, 34560, 17280, 34560, 34560, 540, 34560, 540, 17280, 540, 540, 17280, 17280, 34560, 34560, 34560, 540, 34560, 17280, 17280, 540, 540, 540, 540, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 540, 17280, 17280, 34560, 17280, 34560, 540, 540, 540, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 540, 17280, 17280, 540, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 540, 34560, 540, 34560, 17280, 540, 17280, 540, 540, 17280, 17280, 17280, 34560, 17280, 540, 540]
Prompts retrieved: 2810700 . Total input tokens: 625934726 . Total output tokens: 562216680
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.237089205998927,
    "estimated_duration": 3600.1079377413043,
    "input_throughput": 4958.126064186536,
    "output_throughput": 4352.078124032587,
    "total_throughput": 9310.204188219122,
    "itl": 196.49374839689264,
    "ttft": 2148674.247442315,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 595,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9351633371110109,
    "arrivals": 935737,
    "finished_requests": 72042,
    "scheduler_time": 66.15803929696045
}
#Debug simulation 
Total elapsed time: 5.237210552208126. Arrivals time: 0.25225359247997403 Scheduler time: 4.89515364728868 Scheduler overhead time: 0.02880788128823042 Adapter cache time: 0.0177616230212152 Engine time: 0.030078884679824114 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-32/adapters_160_slots_128_rate_3.2-1.6-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-32/adapters_160_slots_128_rate_3.2-1.6-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [53 53 54]
Adapter prompts. [540, 34560, 540, 540, 17280, 540, 540, 540, 34560, 540, 17280, 34560, 17280, 540, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 540, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 540, 17280, 17280, 17280, 34560, 540, 540, 34560, 540, 34560, 540, 540, 17280, 540, 17280, 34560, 540, 540, 17280, 540, 540, 540, 540, 540, 34560, 17280, 17280, 34560, 17280, 540, 34560, 34560, 34560, 17280, 17280, 540, 540, 540, 34560, 540, 17280, 17280, 540, 34560, 34560, 34560, 540, 540, 34560, 17280, 34560, 34560, 540, 34560, 540, 17280, 540, 540, 17280, 17280, 34560, 34560, 34560, 540, 34560, 17280, 17280, 540, 540, 540, 540, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 540, 17280, 17280, 34560, 17280, 34560, 540, 540, 540, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 540, 17280, 17280, 540, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 540, 34560, 540, 34560, 17280, 540, 17280, 540, 540, 17280, 17280, 17280, 34560, 17280, 540, 540]
Prompts retrieved: 2810700 . Total input tokens: 625934726 . Total output tokens: 562216680
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.174403457902372,
    "estimated_duration": 3600.057154036434,
    "input_throughput": 4804.302337424769,
    "output_throughput": 4225.167365175131,
    "total_throughput": 9029.4697025999,
    "itl": 166.1769953368085,
    "ttft": 2165574.655424099,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 582,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.898133027926099,
    "arrivals": 935737,
    "finished_requests": 69814,
    "scheduler_time": 64.52288540456031
}
#Debug simulation 
Total elapsed time: 5.174498266540468. Arrivals time: 0.24670916562899947 Scheduler time: 4.8234079191461205 Scheduler overhead time: 0.03336882125586271 Adapter cache time: 0.020898588001728058 Engine time: 0.03470676578581333 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-16-16/adapters_160_slots_128_rate_3.2-1.6-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-16-16/adapters_160_slots_128_rate_3.2-1.6-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [53 53 54]
Adapter prompts. [540, 34560, 540, 540, 17280, 540, 540, 540, 34560, 540, 17280, 34560, 17280, 540, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 540, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 540, 17280, 17280, 17280, 34560, 540, 540, 34560, 540, 34560, 540, 540, 17280, 540, 17280, 34560, 540, 540, 17280, 540, 540, 540, 540, 540, 34560, 17280, 17280, 34560, 17280, 540, 34560, 34560, 34560, 17280, 17280, 540, 540, 540, 34560, 540, 17280, 17280, 540, 34560, 34560, 34560, 540, 540, 34560, 17280, 34560, 34560, 540, 34560, 540, 17280, 540, 540, 17280, 17280, 34560, 34560, 34560, 540, 34560, 17280, 17280, 540, 540, 540, 540, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 540, 17280, 17280, 34560, 17280, 34560, 540, 540, 540, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 540, 17280, 17280, 540, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 540, 34560, 540, 34560, 17280, 540, 17280, 540, 540, 17280, 17280, 17280, 34560, 17280, 540, 540]
Prompts retrieved: 2810700 . Total input tokens: 625934726 . Total output tokens: 562216680
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.269495657645166,
    "estimated_duration": 3600.0331308612817,
    "input_throughput": 4958.22909155549,
    "output_throughput": 4352.168558029786,
    "total_throughput": 9310.397649585277,
    "itl": 196.49018841423768,
    "ttft": 2148641.649781033,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 595,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.860390393836412,
    "arrivals": 935737,
    "finished_requests": 72042,
    "scheduler_time": 66.15800536019427
}
#Debug simulation 
Total elapsed time: 5.269609262701124. Arrivals time: 0.26197140105068684 Scheduler time: 4.917429639957845 Scheduler overhead time: 0.028716576285660267 Adapter cache time: 0.01786049921065569 Engine time: 0.030491937417536974 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-16-32/adapters_160_slots_128_rate_3.2-1.6-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-16-32/adapters_160_slots_128_rate_3.2-1.6-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [53 53 54]
Adapter prompts. [540, 34560, 540, 540, 17280, 540, 540, 540, 34560, 540, 17280, 34560, 17280, 540, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 540, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 540, 17280, 17280, 17280, 34560, 540, 540, 34560, 540, 34560, 540, 540, 17280, 540, 17280, 34560, 540, 540, 17280, 540, 540, 540, 540, 540, 34560, 17280, 17280, 34560, 17280, 540, 34560, 34560, 34560, 17280, 17280, 540, 540, 540, 34560, 540, 17280, 17280, 540, 34560, 34560, 34560, 540, 540, 34560, 17280, 34560, 34560, 540, 34560, 540, 17280, 540, 540, 17280, 17280, 34560, 34560, 34560, 540, 34560, 17280, 17280, 540, 540, 540, 540, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 540, 17280, 17280, 34560, 17280, 34560, 540, 540, 540, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 540, 17280, 17280, 540, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 540, 34560, 540, 34560, 17280, 540, 17280, 540, 540, 17280, 17280, 17280, 34560, 17280, 540, 540]
Prompts retrieved: 2810700 . Total input tokens: 625934726 . Total output tokens: 562216680
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.4448449541814625,
    "estimated_duration": 3600.0805558823026,
    "input_throughput": 4804.271107695027,
    "output_throughput": 4225.139900035417,
    "total_throughput": 9029.411007730445,
    "itl": 166.1779562842977,
    "ttft": 2165584.783452192,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 582,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9215232321992557,
    "arrivals": 935737,
    "finished_requests": 69814,
    "scheduler_time": 64.52289704617588
}
#Debug simulation 
Total elapsed time: 5.444910505320877. Arrivals time: 0.2471107100136578 Scheduler time: 5.09377089003101 Scheduler overhead time: 0.033415738958865404 Adapter cache time: 0.02061332017183304 Engine time: 0.03461995208635926 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_16-16-16/adapters_160_slots_128_rate_3.2-1.6-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_16-16-16/adapters_160_slots_128_rate_3.2-1.6-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [53 53 54]
Adapter prompts. [540, 34560, 540, 540, 17280, 540, 540, 540, 34560, 540, 17280, 34560, 17280, 540, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 540, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 540, 17280, 17280, 17280, 34560, 540, 540, 34560, 540, 34560, 540, 540, 17280, 540, 17280, 34560, 540, 540, 17280, 540, 540, 540, 540, 540, 34560, 17280, 17280, 34560, 17280, 540, 34560, 34560, 34560, 17280, 17280, 540, 540, 540, 34560, 540, 17280, 17280, 540, 34560, 34560, 34560, 540, 540, 34560, 17280, 34560, 34560, 540, 34560, 540, 17280, 540, 540, 17280, 17280, 34560, 34560, 34560, 540, 34560, 17280, 17280, 540, 540, 540, 540, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 540, 17280, 17280, 34560, 17280, 34560, 540, 540, 540, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 540, 17280, 17280, 540, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 540, 34560, 540, 34560, 17280, 540, 17280, 540, 540, 17280, 17280, 17280, 34560, 17280, 540, 540]
Prompts retrieved: 2810700 . Total input tokens: 625934726 . Total output tokens: 562216680
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.275373557116836,
    "estimated_duration": 3600.172080826776,
    "input_throughput": 4958.595755761861,
    "output_throughput": 4352.392232429497,
    "total_throughput": 9310.987988191358,
    "itl": 196.48755444750242,
    "ttft": 2148636.736372635,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 595,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7790799254667682,
    "arrivals": 935737,
    "finished_requests": 72046,
    "scheduler_time": 66.16210110227087
}
#Debug simulation 
Total elapsed time: 5.27546824188903. Arrivals time: 0.25610949378460646 Scheduler time: 4.929295056965202 Scheduler overhead time: 0.028804891742765903 Adapter cache time: 0.017953532747924328 Engine time: 0.03006146987900138 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_16-16-32/adapters_160_slots_128_rate_3.2-1.6-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_16-16-32/adapters_160_slots_128_rate_3.2-1.6-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [53 53 54]
Adapter prompts. [540, 34560, 540, 540, 17280, 540, 540, 540, 34560, 540, 17280, 34560, 17280, 540, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 540, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 540, 17280, 17280, 17280, 34560, 540, 540, 34560, 540, 34560, 540, 540, 17280, 540, 17280, 34560, 540, 540, 17280, 540, 540, 540, 540, 540, 34560, 17280, 17280, 34560, 17280, 540, 34560, 34560, 34560, 17280, 17280, 540, 540, 540, 34560, 540, 17280, 17280, 540, 34560, 34560, 34560, 540, 540, 34560, 17280, 34560, 34560, 540, 34560, 540, 17280, 540, 540, 17280, 17280, 34560, 34560, 34560, 540, 34560, 17280, 17280, 540, 540, 540, 540, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 540, 17280, 17280, 34560, 17280, 34560, 540, 540, 540, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 540, 17280, 17280, 540, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 540, 34560, 540, 34560, 17280, 540, 17280, 540, 540, 17280, 17280, 17280, 34560, 17280, 540, 540]
Prompts retrieved: 2810700 . Total input tokens: 625934726 . Total output tokens: 562216680
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.190824366174638,
    "estimated_duration": 3600.1044594132095,
    "input_throughput": 4804.239208886478,
    "output_throughput": 4225.111846471048,
    "total_throughput": 9029.351055357527,
    "itl": 166.17894276449147,
    "ttft": 2165595.146053849,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 582,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9454164516180719,
    "arrivals": 935737,
    "finished_requests": 69814,
    "scheduler_time": 64.52290735768304
}
#Debug simulation 
Total elapsed time: 5.190914295148104. Arrivals time: 0.25205443426966667 Scheduler time: 4.834449952933937 Scheduler overhead time: 0.033214065711945295 Adapter cache time: 0.020817336160689592 Engine time: 0.034911829978227615 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-8/adapters_160_slots_128_rate_3.2-1.6-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-8/adapters_160_slots_128_rate_3.2-1.6-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [53 53 54]
Adapter prompts. [270, 34560, 270, 270, 17280, 270, 270, 270, 34560, 270, 17280, 34560, 17280, 270, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 270, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 270, 17280, 17280, 17280, 34560, 270, 270, 34560, 270, 34560, 270, 270, 17280, 270, 17280, 34560, 270, 270, 17280, 270, 270, 270, 270, 270, 34560, 17280, 17280, 34560, 17280, 270, 34560, 34560, 34560, 17280, 17280, 270, 270, 270, 34560, 270, 17280, 17280, 270, 34560, 34560, 34560, 270, 270, 34560, 17280, 34560, 34560, 270, 34560, 270, 17280, 270, 270, 17280, 17280, 34560, 34560, 34560, 270, 34560, 17280, 17280, 270, 270, 270, 270, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 270, 17280, 17280, 34560, 17280, 34560, 270, 270, 270, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 270, 17280, 17280, 270, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 270, 34560, 270, 34560, 17280, 270, 17280, 270, 270, 17280, 17280, 17280, 34560, 17280, 270, 270]
Prompts retrieved: 2796390 . Total input tokens: 622717176 . Total output tokens: 559314112
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.3929043668322265,
    "estimated_duration": 3600.0717175672125,
    "input_throughput": 5018.186974399549,
    "output_throughput": 4438.076308878895,
    "total_throughput": 9456.263283278446,
    "itl": 193.43593112594388,
    "ttft": 2142926.308963258,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 335,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.025263394217472,
    "arrivals": 931056,
    "finished_requests": 73088,
    "scheduler_time": 67.45184871239462
}
#Debug simulation 
Total elapsed time: 5.393011853098869. Arrivals time: 0.2706774608232081 Scheduler time: 5.035903125535697 Scheduler overhead time: 0.029165541287511587 Adapter cache time: 0.013237740844488144 Engine time: 0.03058720612898469 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-16/adapters_160_slots_128_rate_3.2-1.6-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-16/adapters_160_slots_128_rate_3.2-1.6-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [53 53 54]
Adapter prompts. [270, 34560, 270, 270, 17280, 270, 270, 270, 34560, 270, 17280, 34560, 17280, 270, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 270, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 270, 17280, 17280, 17280, 34560, 270, 270, 34560, 270, 34560, 270, 270, 17280, 270, 17280, 34560, 270, 270, 17280, 270, 270, 270, 270, 270, 34560, 17280, 17280, 34560, 17280, 270, 34560, 34560, 34560, 17280, 17280, 270, 270, 270, 34560, 270, 17280, 17280, 270, 34560, 34560, 34560, 270, 270, 34560, 17280, 34560, 34560, 270, 34560, 270, 17280, 270, 270, 17280, 17280, 34560, 34560, 34560, 270, 34560, 17280, 17280, 270, 270, 270, 270, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 270, 17280, 17280, 34560, 17280, 34560, 270, 270, 270, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 270, 17280, 17280, 270, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 270, 34560, 270, 34560, 17280, 270, 17280, 270, 270, 17280, 17280, 17280, 34560, 17280, 270, 270]
Prompts retrieved: 2796390 . Total input tokens: 622717176 . Total output tokens: 559314112
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.347894893027842,
    "estimated_duration": 3600.137649278949,
    "input_throughput": 5018.095073008751,
    "output_throughput": 4437.995031439984,
    "total_throughput": 9456.090104448735,
    "itl": 193.43862931336696,
    "ttft": 2142959.306991937,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 335,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0911492235306703,
    "arrivals": 931056,
    "finished_requests": 73088,
    "scheduler_time": 67.45189459480116
}
#Debug simulation 
Total elapsed time: 5.347989502828568. Arrivals time: 0.2565911775454879 Scheduler time: 5.0047706682235 Scheduler overhead time: 0.02926797978579998 Adapter cache time: 0.013151674065738916 Engine time: 0.030815957579761744 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-32/adapters_160_slots_128_rate_3.2-1.6-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-32/adapters_160_slots_128_rate_3.2-1.6-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [53 53 54]
Adapter prompts. [270, 34560, 270, 270, 17280, 270, 270, 270, 34560, 270, 17280, 34560, 17280, 270, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 270, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 270, 17280, 17280, 17280, 34560, 270, 270, 34560, 270, 34560, 270, 270, 17280, 270, 17280, 34560, 270, 270, 17280, 270, 270, 270, 270, 270, 34560, 17280, 17280, 34560, 17280, 270, 34560, 34560, 34560, 17280, 17280, 270, 270, 270, 34560, 270, 17280, 17280, 270, 34560, 34560, 34560, 270, 270, 34560, 17280, 34560, 34560, 270, 34560, 270, 17280, 270, 270, 17280, 17280, 34560, 34560, 34560, 270, 34560, 17280, 17280, 270, 270, 270, 270, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 270, 17280, 17280, 34560, 17280, 34560, 270, 270, 270, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 270, 17280, 17280, 270, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 270, 34560, 270, 34560, 17280, 270, 17280, 270, 270, 17280, 17280, 17280, 34560, 17280, 270, 270]
Prompts retrieved: 2796390 . Total input tokens: 622717176 . Total output tokens: 559314112
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.2028875523246825,
    "estimated_duration": 3600.052204804918,
    "input_throughput": 4847.107766023516,
    "output_throughput": 4293.544960089709,
    "total_throughput": 9140.652726113225,
    "itl": 163.49003412286302,
    "ttft": 2161328.8579468913,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 331,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0799129502661584,
    "arrivals": 931056,
    "finished_requests": 70602,
    "scheduler_time": 65.55874794327336
}
#Debug simulation 
Total elapsed time: 5.2029809933155775. Arrivals time: 0.24419504683464766 Scheduler time: 4.857329559512436 Scheduler overhead time: 0.03386910958215594 Adapter cache time: 0.016596486791968346 Engine time: 0.035375893115997314 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-16-16/adapters_160_slots_128_rate_3.2-1.6-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-16-16/adapters_160_slots_128_rate_3.2-1.6-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [53 53 54]
Adapter prompts. [270, 34560, 270, 270, 17280, 270, 270, 270, 34560, 270, 17280, 34560, 17280, 270, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 270, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 270, 17280, 17280, 17280, 34560, 270, 270, 34560, 270, 34560, 270, 270, 17280, 270, 17280, 34560, 270, 270, 17280, 270, 270, 270, 270, 270, 34560, 17280, 17280, 34560, 17280, 270, 34560, 34560, 34560, 17280, 17280, 270, 270, 270, 34560, 270, 17280, 17280, 270, 34560, 34560, 34560, 270, 270, 34560, 17280, 34560, 34560, 270, 34560, 270, 17280, 270, 270, 17280, 17280, 34560, 34560, 34560, 270, 34560, 17280, 17280, 270, 270, 270, 270, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 270, 17280, 17280, 34560, 17280, 34560, 270, 270, 270, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 270, 17280, 17280, 270, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 270, 34560, 270, 34560, 17280, 270, 17280, 270, 270, 17280, 17280, 17280, 34560, 17280, 270, 270]
Prompts retrieved: 2796390 . Total input tokens: 622717176 . Total output tokens: 559314112
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.393139706924558,
    "estimated_duration": 3600.095939557119,
    "input_throughput": 5018.15321127871,
    "output_throughput": 4438.0464488303405,
    "total_throughput": 9456.19966010905,
    "itl": 193.43694987671213,
    "ttft": 2142937.765462083,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 335,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0494725010497528,
    "arrivals": 931056,
    "finished_requests": 73088,
    "scheduler_time": 67.45186159544473
}
#Debug simulation 
Total elapsed time: 5.393233235925436. Arrivals time: 0.315506037324667 Scheduler time: 4.991725174244493 Scheduler overhead time: 0.029127038549631834 Adapter cache time: 0.013195779640227556 Engine time: 0.030325498897582293 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-16-32/adapters_160_slots_128_rate_3.2-1.6-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-16-32/adapters_160_slots_128_rate_3.2-1.6-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [53 53 54]
Adapter prompts. [270, 34560, 270, 270, 17280, 270, 270, 270, 34560, 270, 17280, 34560, 17280, 270, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 270, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 270, 17280, 17280, 17280, 34560, 270, 270, 34560, 270, 34560, 270, 270, 17280, 270, 17280, 34560, 270, 270, 17280, 270, 270, 270, 270, 270, 34560, 17280, 17280, 34560, 17280, 270, 34560, 34560, 34560, 17280, 17280, 270, 270, 270, 34560, 270, 17280, 17280, 270, 34560, 34560, 34560, 270, 270, 34560, 17280, 34560, 34560, 270, 34560, 270, 17280, 270, 270, 17280, 17280, 34560, 34560, 34560, 270, 34560, 17280, 17280, 270, 270, 270, 270, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 270, 17280, 17280, 34560, 17280, 34560, 270, 270, 270, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 270, 17280, 17280, 270, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 270, 34560, 270, 34560, 17280, 270, 17280, 270, 270, 17280, 17280, 17280, 34560, 17280, 270, 270]
Prompts retrieved: 2796390 . Total input tokens: 622717176 . Total output tokens: 559314112
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.2067582360468805,
    "estimated_duration": 3600.064916717549,
    "input_throughput": 4847.090650773692,
    "output_throughput": 4293.529799482978,
    "total_throughput": 9140.620450256669,
    "itl": 163.49049271820468,
    "ttft": 2161335.34472341,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 331,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0926140826940585,
    "arrivals": 931056,
    "finished_requests": 70602,
    "scheduler_time": 65.55875872348538
}
#Debug simulation 
Total elapsed time: 5.206881334073842. Arrivals time: 0.24716544384136796 Scheduler time: 4.8588386992923915 Scheduler overhead time: 0.03372680023312569 Adapter cache time: 0.016558766830712557 Engine time: 0.03500868333503604 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_16-16-16/adapters_160_slots_128_rate_3.2-1.6-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_16-16-16/adapters_160_slots_128_rate_3.2-1.6-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [53 53 54]
Adapter prompts. [270, 34560, 270, 270, 17280, 270, 270, 270, 34560, 270, 17280, 34560, 17280, 270, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 270, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 270, 17280, 17280, 17280, 34560, 270, 270, 34560, 270, 34560, 270, 270, 17280, 270, 17280, 34560, 270, 270, 17280, 270, 270, 270, 270, 270, 34560, 17280, 17280, 34560, 17280, 270, 34560, 34560, 34560, 17280, 17280, 270, 270, 270, 34560, 270, 17280, 17280, 270, 34560, 34560, 34560, 270, 270, 34560, 17280, 34560, 34560, 270, 34560, 270, 17280, 270, 270, 17280, 17280, 34560, 34560, 34560, 270, 34560, 17280, 17280, 270, 270, 270, 270, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 270, 17280, 17280, 34560, 17280, 34560, 270, 270, 270, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 270, 17280, 17280, 270, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 270, 34560, 270, 34560, 17280, 270, 17280, 270, 270, 17280, 17280, 17280, 34560, 17280, 270, 270]
Prompts retrieved: 2796390 . Total input tokens: 622717176 . Total output tokens: 559314112
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.344830383080989,
    "estimated_duration": 3600.0481055038895,
    "input_throughput": 5018.219887778797,
    "output_throughput": 4438.105417417383,
    "total_throughput": 9456.32530519618,
    "itl": 193.4349417018174,
    "ttft": 2142914.8466499075,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 335,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0016668487922302,
    "arrivals": 931056,
    "finished_requests": 73088,
    "scheduler_time": 67.45183319446309
}
#Debug simulation 
Total elapsed time: 5.344947579782456. Arrivals time: 0.26146094035357237 Scheduler time: 4.997198975179344 Scheduler overhead time: 0.02910908032208681 Adapter cache time: 0.0132800810970366 Engine time: 0.030554901342839003 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_16-16-32/adapters_160_slots_128_rate_3.2-1.6-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_16-16-32/adapters_160_slots_128_rate_3.2-1.6-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [53 53 54]
Adapter prompts. [270, 34560, 270, 270, 17280, 270, 270, 270, 34560, 270, 17280, 34560, 17280, 270, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 270, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 270, 17280, 17280, 17280, 34560, 270, 270, 34560, 270, 34560, 270, 270, 17280, 270, 17280, 34560, 270, 270, 17280, 270, 270, 270, 270, 270, 34560, 17280, 17280, 34560, 17280, 270, 34560, 34560, 34560, 17280, 17280, 270, 270, 270, 34560, 270, 17280, 17280, 270, 34560, 34560, 34560, 270, 270, 34560, 17280, 34560, 34560, 270, 34560, 270, 17280, 270, 270, 17280, 17280, 34560, 34560, 34560, 270, 34560, 17280, 17280, 270, 270, 270, 270, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 270, 17280, 17280, 34560, 17280, 34560, 270, 270, 270, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 270, 17280, 17280, 270, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 270, 34560, 270, 34560, 17280, 270, 17280, 270, 270, 17280, 17280, 17280, 34560, 17280, 270, 270]
Prompts retrieved: 2796390 . Total input tokens: 622717176 . Total output tokens: 559314112
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.187257817015052,
    "estimated_duration": 3600.0792625299946,
    "input_throughput": 4847.071335795239,
    "output_throughput": 4293.512690367111,
    "total_throughput": 9140.584026162349,
    "itl": 163.4910149372772,
    "ttft": 2161342.2257215725,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 331,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1069500143453521,
    "arrivals": 931056,
    "finished_requests": 70602,
    "scheduler_time": 65.55876860429078
}
#Debug simulation 
Total elapsed time: 5.187372747808695. Arrivals time: 0.2477696775458753 Scheduler time: 4.838968955446035 Scheduler overhead time: 0.03362663136795163 Adapter cache time: 0.016483113635331392 Engine time: 0.03496417263522744 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-8/adapters_160_slots_128_rate_3.2-1.6-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-8/adapters_160_slots_128_rate_3.2-1.6-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [53 53 54]
Adapter prompts. [135, 34560, 135, 135, 17280, 135, 135, 135, 34560, 135, 17280, 34560, 17280, 135, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 135, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 135, 17280, 17280, 17280, 34560, 135, 135, 34560, 135, 34560, 135, 135, 17280, 135, 17280, 34560, 135, 135, 17280, 135, 135, 135, 135, 135, 34560, 17280, 17280, 34560, 17280, 135, 34560, 34560, 34560, 17280, 17280, 135, 135, 135, 34560, 135, 17280, 17280, 135, 34560, 34560, 34560, 135, 135, 34560, 17280, 34560, 34560, 135, 34560, 135, 17280, 135, 135, 17280, 17280, 34560, 34560, 34560, 135, 34560, 17280, 17280, 135, 135, 135, 135, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 135, 17280, 17280, 34560, 17280, 34560, 135, 135, 135, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 135, 17280, 17280, 135, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 135, 34560, 135, 34560, 17280, 135, 17280, 135, 135, 17280, 17280, 17280, 34560, 17280, 135, 135]
Prompts retrieved: 2789235 . Total input tokens: 621133368 . Total output tokens: 557879875
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.493977366946638,
    "estimated_duration": 3600.020559911323,
    "input_throughput": 5111.483863429177,
    "output_throughput": 4488.912141212345,
    "total_throughput": 9600.396004641523,
    "itl": 190.743313487297,
    "ttft": 2137528.141038,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 226,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6916702301288015,
    "arrivals": 928543,
    "finished_requests": 74204,
    "scheduler_time": 68.19515496976719
}
#Debug simulation 
Total elapsed time: 5.494069322943687. Arrivals time: 0.35952184349298477 Scheduler time: 5.050139653496444 Scheduler overhead time: 0.029813489876687527 Adapter cache time: 0.01001697639003396 Engine time: 0.03099696198478341 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-16/adapters_160_slots_128_rate_3.2-1.6-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-16/adapters_160_slots_128_rate_3.2-1.6-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [53 53 54]
Adapter prompts. [135, 34560, 135, 135, 17280, 135, 135, 135, 34560, 135, 17280, 34560, 17280, 135, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 135, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 135, 17280, 17280, 17280, 34560, 135, 135, 34560, 135, 34560, 135, 135, 17280, 135, 17280, 34560, 135, 135, 17280, 135, 135, 135, 135, 135, 34560, 17280, 17280, 34560, 17280, 135, 34560, 34560, 34560, 17280, 17280, 135, 135, 135, 34560, 135, 17280, 17280, 135, 34560, 34560, 34560, 135, 135, 34560, 17280, 34560, 34560, 135, 34560, 135, 17280, 135, 135, 17280, 17280, 34560, 34560, 34560, 135, 34560, 17280, 17280, 135, 135, 135, 135, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 135, 17280, 17280, 34560, 17280, 34560, 135, 135, 135, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 135, 17280, 17280, 135, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 135, 34560, 135, 34560, 17280, 135, 17280, 135, 135, 17280, 17280, 17280, 34560, 17280, 135, 135]
Prompts retrieved: 2789235 . Total input tokens: 621133368 . Total output tokens: 557879875
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.579829841386527,
    "estimated_duration": 3600.0647512654677,
    "input_throughput": 5111.42111917061,
    "output_throughput": 4488.857039118393,
    "total_throughput": 9600.278158289002,
    "itl": 190.74486282707878,
    "ttft": 2137553.257940485,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 226,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7358148784586254,
    "arrivals": 928543,
    "finished_requests": 74204,
    "scheduler_time": 68.19520167557417
}
#Debug simulation 
Total elapsed time: 5.5799234812147915. Arrivals time: 0.42034708289429545 Scheduler time: 5.075151378754526 Scheduler overhead time: 0.0296517014503479 Adapter cache time: 0.0101225427351892 Engine time: 0.031020440626889467 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-32/adapters_160_slots_128_rate_3.2-1.6-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-32/adapters_160_slots_128_rate_3.2-1.6-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [53 53 54]
Adapter prompts. [135, 34560, 135, 135, 17280, 135, 135, 135, 34560, 135, 17280, 34560, 17280, 135, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 135, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 135, 17280, 17280, 17280, 34560, 135, 135, 34560, 135, 34560, 135, 135, 17280, 135, 17280, 34560, 135, 135, 17280, 135, 135, 135, 135, 135, 34560, 17280, 17280, 34560, 17280, 135, 34560, 34560, 34560, 17280, 17280, 135, 135, 135, 34560, 135, 17280, 17280, 135, 34560, 34560, 34560, 135, 135, 34560, 17280, 34560, 34560, 135, 34560, 135, 17280, 135, 135, 17280, 17280, 34560, 34560, 34560, 135, 34560, 17280, 17280, 135, 135, 135, 135, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 135, 17280, 17280, 34560, 17280, 34560, 135, 135, 135, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 135, 17280, 17280, 135, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 135, 34560, 135, 34560, 17280, 135, 17280, 135, 135, 17280, 17280, 17280, 34560, 17280, 135, 135]
Prompts retrieved: 2789235 . Total input tokens: 621133368 . Total output tokens: 557879875
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.466022138018161,
    "estimated_duration": 3600.0365421268666,
    "input_throughput": 4930.944670220636,
    "output_throughput": 4332.8576856013215,
    "total_throughput": 9263.802355821957,
    "itl": 161.4748696323263,
    "ttft": 2158270.041799475,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 220,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7181377859413656,
    "arrivals": 928543,
    "finished_requests": 71529,
    "scheduler_time": 66.18319162662408
}
#Debug simulation 
Total elapsed time: 5.466121809091419. Arrivals time: 0.3754208516329527 Scheduler time: 4.991109834983945 Scheduler overhead time: 0.03439380694180727 Adapter cache time: 0.013476055581122637 Engine time: 0.03578035347163677 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-16/adapters_160_slots_128_rate_3.2-1.6-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-16/adapters_160_slots_128_rate_3.2-1.6-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [53 53 54]
Adapter prompts. [135, 34560, 135, 135, 17280, 135, 135, 135, 34560, 135, 17280, 34560, 17280, 135, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 135, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 135, 17280, 17280, 17280, 34560, 135, 135, 34560, 135, 34560, 135, 135, 17280, 135, 17280, 34560, 135, 135, 17280, 135, 135, 135, 135, 135, 34560, 17280, 17280, 34560, 17280, 135, 34560, 34560, 34560, 17280, 17280, 135, 135, 135, 34560, 135, 17280, 17280, 135, 34560, 34560, 34560, 135, 135, 34560, 17280, 34560, 34560, 135, 34560, 135, 17280, 135, 135, 17280, 17280, 34560, 34560, 34560, 135, 34560, 17280, 17280, 135, 135, 135, 135, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 135, 17280, 17280, 34560, 17280, 34560, 135, 135, 135, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 135, 17280, 17280, 135, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 135, 34560, 135, 34560, 17280, 135, 17280, 135, 135, 17280, 17280, 17280, 34560, 17280, 135, 135]
Prompts retrieved: 2789235 . Total input tokens: 621133368 . Total output tokens: 557879875
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.483976638875902,
    "estimated_duration": 3600.0361180632776,
    "input_throughput": 5111.461773305619,
    "output_throughput": 4488.892741635531,
    "total_throughput": 9600.354514941151,
    "itl": 190.74389130874263,
    "ttft": 2137536.848513631,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 226,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7072132061677999,
    "arrivals": 928543,
    "finished_requests": 74204,
    "scheduler_time": 68.19517014567084
}
#Debug simulation 
Total elapsed time: 5.4840892711654305. Arrivals time: 0.35730342101305723 Scheduler time: 5.042383262421936 Scheduler overhead time: 0.029577619396150112 Adapter cache time: 0.009956639260053635 Engine time: 0.031299187801778316 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-32/adapters_160_slots_128_rate_3.2-1.6-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-32/adapters_160_slots_128_rate_3.2-1.6-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [53 53 54]
Adapter prompts. [135, 34560, 135, 135, 17280, 135, 135, 135, 34560, 135, 17280, 34560, 17280, 135, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 135, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 135, 17280, 17280, 17280, 34560, 135, 135, 34560, 135, 34560, 135, 135, 17280, 135, 17280, 34560, 135, 135, 17280, 135, 135, 135, 135, 135, 34560, 17280, 17280, 34560, 17280, 135, 34560, 34560, 34560, 17280, 17280, 135, 135, 135, 34560, 135, 17280, 17280, 135, 34560, 34560, 34560, 135, 135, 34560, 17280, 34560, 34560, 135, 34560, 135, 17280, 135, 135, 17280, 17280, 34560, 34560, 34560, 135, 34560, 17280, 17280, 135, 135, 135, 135, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 135, 17280, 17280, 34560, 17280, 34560, 135, 135, 135, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 135, 17280, 17280, 135, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 135, 34560, 135, 34560, 17280, 135, 17280, 135, 135, 17280, 17280, 17280, 34560, 17280, 135, 135]
Prompts retrieved: 2789235 . Total input tokens: 621133368 . Total output tokens: 557879875
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.37329491507262,
    "estimated_duration": 3600.0453555834492,
    "input_throughput": 4930.932598520846,
    "output_throughput": 4332.847078109105,
    "total_throughput": 9263.77967662995,
    "itl": 161.47514631600615,
    "ttft": 2158274.9979258184,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 220,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7269405509904057,
    "arrivals": 928543,
    "finished_requests": 71529,
    "scheduler_time": 66.1832023181622
}
#Debug simulation 
Total elapsed time: 5.373386970255524. Arrivals time: 0.34726979583501816 Scheduler time: 4.927164637017995 Scheduler overhead time: 0.034054463263601065 Adapter cache time: 0.013478423468768597 Engine time: 0.03550748620182276 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-16/adapters_160_slots_128_rate_3.2-1.6-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-16/adapters_160_slots_128_rate_3.2-1.6-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [53 53 54]
Adapter prompts. [135, 34560, 135, 135, 17280, 135, 135, 135, 34560, 135, 17280, 34560, 17280, 135, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 135, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 135, 17280, 17280, 17280, 34560, 135, 135, 34560, 135, 34560, 135, 135, 17280, 135, 17280, 34560, 135, 135, 17280, 135, 135, 135, 135, 135, 34560, 17280, 17280, 34560, 17280, 135, 34560, 34560, 34560, 17280, 17280, 135, 135, 135, 34560, 135, 17280, 17280, 135, 34560, 34560, 34560, 135, 135, 34560, 17280, 34560, 34560, 135, 34560, 135, 17280, 135, 135, 17280, 17280, 34560, 34560, 34560, 135, 34560, 17280, 17280, 135, 135, 135, 135, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 135, 17280, 17280, 34560, 17280, 34560, 135, 135, 135, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 135, 17280, 17280, 135, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 135, 34560, 135, 34560, 17280, 135, 17280, 135, 135, 17280, 17280, 17280, 34560, 17280, 135, 135]
Prompts retrieved: 2789235 . Total input tokens: 621133368 . Total output tokens: 557879875
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.568352749105543,
    "estimated_duration": 3600.00462589729,
    "input_throughput": 5111.506487415553,
    "output_throughput": 4488.932009628217,
    "total_throughput": 9600.43849704377,
    "itl": 190.7427395288416,
    "ttft": 2137519.3594160723,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 226,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6757513666478926,
    "arrivals": 928543,
    "finished_requests": 74204,
    "scheduler_time": 68.19513981919893
}
#Debug simulation 
Total elapsed time: 5.568463907111436. Arrivals time: 0.4186931666918099 Scheduler time: 5.065944610629231 Scheduler overhead time: 0.029376584105193615 Adapter cache time: 0.010092601180076599 Engine time: 0.030788343399763107 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-32/adapters_160_slots_128_rate_3.2-1.6-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-32/adapters_160_slots_128_rate_3.2-1.6-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [53 53 54]
Adapter prompts. [135, 34560, 135, 135, 17280, 135, 135, 135, 34560, 135, 17280, 34560, 17280, 135, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 135, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 135, 17280, 17280, 17280, 34560, 135, 135, 34560, 135, 34560, 135, 135, 17280, 135, 17280, 34560, 135, 135, 17280, 135, 135, 135, 135, 135, 34560, 17280, 17280, 34560, 17280, 135, 34560, 34560, 34560, 17280, 17280, 135, 135, 135, 34560, 135, 17280, 17280, 135, 34560, 34560, 34560, 135, 135, 34560, 17280, 34560, 34560, 135, 34560, 135, 17280, 135, 135, 17280, 17280, 34560, 34560, 34560, 135, 34560, 17280, 17280, 135, 135, 135, 135, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 135, 17280, 17280, 34560, 17280, 34560, 135, 135, 135, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 135, 17280, 17280, 135, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 135, 34560, 135, 34560, 17280, 135, 17280, 135, 135, 17280, 17280, 17280, 34560, 17280, 135, 135]
Prompts retrieved: 2789235 . Total input tokens: 621133368 . Total output tokens: 557879875
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.3884826032444835,
    "estimated_duration": 3600.0546716244753,
    "input_throughput": 4930.919838500631,
    "output_throughput": 4332.83586578462,
    "total_throughput": 9263.755704285251,
    "itl": 161.47545596587548,
    "ttft": 2158280.2804959053,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 220,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7362463311851049,
    "arrivals": 928543,
    "finished_requests": 71529,
    "scheduler_time": 66.18321257899856
}
#Debug simulation 
Total elapsed time: 5.388583144173026. Arrivals time: 0.3552947291173041 Scheduler time: 4.934392160736024 Scheduler overhead time: 0.03427162952721119 Adapter cache time: 0.013433108106255531 Engine time: 0.03535600192844868 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-8/adapters_160_slots_128_rate_3.2-1.6-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-8/adapters_160_slots_128_rate_3.2-1.6-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [53 53 54]
Adapter prompts. [66, 34560, 66, 66, 17280, 66, 66, 66, 34560, 66, 17280, 34560, 17280, 66, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 66, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 66, 17280, 17280, 17280, 34560, 66, 66, 34560, 66, 34560, 66, 66, 17280, 66, 17280, 34560, 66, 66, 17280, 66, 66, 66, 66, 66, 34560, 17280, 17280, 34560, 17280, 66, 34560, 34560, 34560, 17280, 17280, 66, 66, 66, 34560, 66, 17280, 17280, 66, 34560, 34560, 34560, 66, 66, 34560, 17280, 34560, 34560, 66, 34560, 66, 17280, 66, 66, 17280, 17280, 34560, 34560, 34560, 66, 34560, 17280, 17280, 66, 66, 66, 66, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 66, 17280, 17280, 34560, 17280, 34560, 66, 66, 66, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 66, 17280, 17280, 66, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 66, 34560, 66, 34560, 17280, 66, 17280, 66, 66, 17280, 17280, 17280, 34560, 17280, 66, 66]
Prompts retrieved: 2785578 . Total input tokens: 620302199 . Total output tokens: 557146111
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.5164984511211514,
    "estimated_duration": 3600.0857881341917,
    "input_throughput": 5127.318649138801,
    "output_throughput": 4513.640773105462,
    "total_throughput": 9640.959422244263,
    "itl": 189.67734320099856,
    "ttft": 2130523.1763143684,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 159,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.48661755128530726,
    "arrivals": 927414,
    "finished_requests": 74749,
    "scheduler_time": 68.58784920258766
}
#Debug simulation 
Total elapsed time: 5.5166262509301305. Arrivals time: 0.2596791028045118 Scheduler time: 5.1746892696246505 Scheduler overhead time: 0.02953358180820942 Adapter cache time: 0.00842461222782731 Engine time: 0.03069684561342001 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-16/adapters_160_slots_128_rate_3.2-1.6-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-16/adapters_160_slots_128_rate_3.2-1.6-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [53 53 54]
Adapter prompts. [66, 34560, 66, 66, 17280, 66, 66, 66, 34560, 66, 17280, 34560, 17280, 66, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 66, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 66, 17280, 17280, 17280, 34560, 66, 66, 34560, 66, 34560, 66, 66, 17280, 66, 17280, 34560, 66, 66, 17280, 66, 66, 66, 66, 66, 34560, 17280, 17280, 34560, 17280, 66, 34560, 34560, 34560, 17280, 17280, 66, 66, 66, 34560, 66, 17280, 17280, 66, 34560, 34560, 34560, 66, 66, 34560, 17280, 34560, 34560, 66, 34560, 66, 17280, 66, 66, 17280, 17280, 34560, 34560, 34560, 66, 34560, 17280, 17280, 66, 66, 66, 66, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 66, 17280, 17280, 34560, 17280, 34560, 66, 66, 66, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 66, 17280, 17280, 66, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 66, 34560, 66, 34560, 17280, 66, 17280, 66, 66, 17280, 17280, 17280, 34560, 17280, 66, 66]
Prompts retrieved: 2785578 . Total input tokens: 620302199 . Total output tokens: 557146111
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.525962793733925,
    "estimated_duration": 3600.1203974165605,
    "input_throughput": 5127.2693583375685,
    "output_throughput": 4513.59738181551,
    "total_throughput": 9640.866740153078,
    "itl": 189.67836506023838,
    "ttft": 2130545.0795097467,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 159,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5211806725547651,
    "arrivals": 927414,
    "finished_requests": 74749,
    "scheduler_time": 68.58789536368359
}
#Debug simulation 
Total elapsed time: 5.526056742761284. Arrivals time: 0.3650129595771432 Scheduler time: 5.07864768570289 Scheduler overhead time: 0.029515290167182684 Adapter cache time: 0.008365068584680557 Engine time: 0.030875643715262413 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-32/adapters_160_slots_128_rate_3.2-1.6-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-32/adapters_160_slots_128_rate_3.2-1.6-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [53 53 54]
Adapter prompts. [66, 34560, 66, 66, 17280, 66, 66, 66, 34560, 66, 17280, 34560, 17280, 66, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 66, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 66, 17280, 17280, 17280, 34560, 66, 66, 34560, 66, 34560, 66, 66, 17280, 66, 17280, 34560, 66, 66, 17280, 66, 66, 66, 66, 66, 34560, 17280, 17280, 34560, 17280, 66, 34560, 34560, 34560, 17280, 17280, 66, 66, 66, 34560, 66, 17280, 17280, 66, 34560, 34560, 34560, 66, 66, 34560, 17280, 34560, 34560, 66, 34560, 66, 17280, 66, 66, 17280, 17280, 34560, 34560, 34560, 66, 34560, 17280, 17280, 66, 66, 66, 66, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 66, 17280, 17280, 34560, 17280, 34560, 66, 66, 66, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 66, 17280, 17280, 66, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 66, 34560, 66, 34560, 17280, 66, 17280, 66, 66, 17280, 17280, 17280, 34560, 17280, 66, 66]
Prompts retrieved: 2785578 . Total input tokens: 620302199 . Total output tokens: 557146111
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.713267175015062,
    "estimated_duration": 3600.123780369925,
    "input_throughput": 4935.400303979068,
    "output_throughput": 4351.169280738007,
    "total_throughput": 9286.569584717075,
    "itl": 160.40795379936588,
    "ttft": 2151452.3816278786,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 156,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5115489173121768,
    "arrivals": 927414,
    "finished_requests": 71994,
    "scheduler_time": 66.44524466301047
}
#Debug simulation 
Total elapsed time: 5.713334573898464. Arrivals time: 0.6685065650381148 Scheduler time: 4.947487110737711 Scheduler overhead time: 0.03437102446332574 Adapter cache time: 0.01171890739351511 Engine time: 0.03531091054901481 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-16/adapters_160_slots_128_rate_3.2-1.6-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-16/adapters_160_slots_128_rate_3.2-1.6-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [53 53 54]
Adapter prompts. [66, 34560, 66, 66, 17280, 66, 66, 66, 34560, 66, 17280, 34560, 17280, 66, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 66, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 66, 17280, 17280, 17280, 34560, 66, 66, 34560, 66, 34560, 66, 66, 17280, 66, 17280, 34560, 66, 66, 17280, 66, 66, 66, 66, 66, 34560, 17280, 17280, 34560, 17280, 66, 34560, 34560, 34560, 17280, 17280, 66, 66, 66, 34560, 66, 17280, 17280, 66, 34560, 34560, 34560, 66, 66, 34560, 17280, 34560, 34560, 66, 34560, 66, 17280, 66, 66, 17280, 17280, 34560, 34560, 34560, 66, 34560, 17280, 17280, 66, 66, 66, 66, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 66, 17280, 17280, 34560, 17280, 34560, 66, 66, 66, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 66, 17280, 17280, 66, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 66, 34560, 66, 34560, 17280, 66, 17280, 66, 66, 17280, 17280, 17280, 34560, 17280, 66, 66]
Prompts retrieved: 2785578 . Total input tokens: 620302199 . Total output tokens: 557146111
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.54932060604915,
    "estimated_duration": 3600.0966670288294,
    "input_throughput": 5127.303155232799,
    "output_throughput": 4513.627133632152,
    "total_throughput": 9640.93028886495,
    "itl": 189.67768067599374,
    "ttft": 2130530.234364347,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 159,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.497482144085225,
    "arrivals": 927414,
    "finished_requests": 74749,
    "scheduler_time": 68.58786350442007
}
#Debug simulation 
Total elapsed time: 5.549411491956562. Arrivals time: 0.3633923646993935 Scheduler time: 5.103446580003947 Scheduler overhead time: 0.02955539897084236 Adapter cache time: 0.008415800053626299 Engine time: 0.030938610434532166 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-32/adapters_160_slots_128_rate_3.2-1.6-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-32/adapters_160_slots_128_rate_3.2-1.6-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [53 53 54]
Adapter prompts. [66, 34560, 66, 66, 17280, 66, 66, 66, 34560, 66, 17280, 34560, 17280, 66, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 66, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 66, 17280, 17280, 17280, 34560, 66, 66, 34560, 66, 34560, 66, 66, 17280, 66, 17280, 34560, 66, 66, 17280, 66, 66, 66, 66, 66, 34560, 17280, 17280, 34560, 17280, 66, 34560, 34560, 34560, 17280, 17280, 66, 66, 66, 34560, 66, 17280, 17280, 66, 34560, 34560, 34560, 66, 66, 34560, 17280, 34560, 34560, 66, 34560, 66, 17280, 66, 66, 17280, 17280, 34560, 34560, 34560, 66, 34560, 17280, 17280, 66, 66, 66, 66, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 66, 17280, 17280, 34560, 17280, 34560, 66, 66, 66, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 66, 17280, 17280, 66, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 66, 34560, 66, 34560, 17280, 66, 17280, 66, 66, 17280, 17280, 17280, 34560, 17280, 66, 66]
Prompts retrieved: 2785578 . Total input tokens: 620302199 . Total output tokens: 557146111
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.385352221317589,
    "estimated_duration": 3600.1307072410254,
    "input_throughput": 4935.390807967808,
    "output_throughput": 4351.160908822875,
    "total_throughput": 9286.551716790684,
    "itl": 160.4081362722518,
    "ttft": 2151456.891715668,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 156,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5184653755649932,
    "arrivals": 927414,
    "finished_requests": 71994,
    "scheduler_time": 66.44525507585921
}
#Debug simulation 
Total elapsed time: 5.38545196224004. Arrivals time: 0.3519830657169223 Scheduler time: 4.936017330735922 Scheduler overhead time: 0.034343122504651546 Adapter cache time: 0.011647386476397514 Engine time: 0.0355376279912889 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-16/adapters_160_slots_128_rate_3.2-1.6-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-16/adapters_160_slots_128_rate_3.2-1.6-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [53 53 54]
Adapter prompts. [66, 34560, 66, 66, 17280, 66, 66, 66, 34560, 66, 17280, 34560, 17280, 66, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 66, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 66, 17280, 17280, 17280, 34560, 66, 66, 34560, 66, 34560, 66, 66, 17280, 66, 17280, 34560, 66, 66, 17280, 66, 66, 66, 66, 66, 34560, 17280, 17280, 34560, 17280, 66, 34560, 34560, 34560, 17280, 17280, 66, 66, 66, 34560, 66, 17280, 17280, 66, 34560, 34560, 34560, 66, 66, 34560, 17280, 34560, 34560, 66, 34560, 66, 17280, 66, 66, 17280, 17280, 34560, 34560, 34560, 66, 34560, 17280, 17280, 66, 66, 66, 66, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 66, 17280, 17280, 34560, 17280, 34560, 66, 66, 66, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 66, 17280, 17280, 66, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 66, 34560, 66, 34560, 17280, 66, 17280, 66, 66, 17280, 17280, 17280, 34560, 17280, 66, 66]
Prompts retrieved: 2785578 . Total input tokens: 620302199 . Total output tokens: 557146111
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.527899314183742,
    "estimated_duration": 3600.074573745927,
    "input_throughput": 5127.334620958526,
    "output_throughput": 4513.6548332920165,
    "total_throughput": 9640.989454250543,
    "itl": 189.67702313758295,
    "ttft": 2130516.1181939645,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 159,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4754179968894465,
    "arrivals": 927414,
    "finished_requests": 74749,
    "scheduler_time": 68.58783436871188
}
#Debug simulation 
Total elapsed time: 5.527992773801088. Arrivals time: 0.36000578897073865 Scheduler time: 5.085395730566233 Scheduler overhead time: 0.02963498467579484 Adapter cache time: 0.0084044118411839 Engine time: 0.03094285074621439 
