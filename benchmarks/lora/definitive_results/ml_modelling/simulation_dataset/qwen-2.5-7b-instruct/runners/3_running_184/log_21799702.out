INFO 06-01 00:46:59 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:47:00 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-32/adapters_16_slots_16_rate_0.8-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-32/adapters_16_slots_16_rate_0.8-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [5 5 6]
Adapter prompts. [540, 33, 33, 540, 8640, 33, 8640, 33, 540, 540, 33, 540, 8640, 8640, 8640, 8640]
Prompts retrieved: 54705 . Total input tokens: 12122728 . Total output tokens: 10961139
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.724683100823313,
    "estimated_duration": 3599.03052671833,
    "input_throughput": 1272.811098986967,
    "output_throughput": 1123.8951628699447,
    "total_throughput": 2396.7062618569116,
    "itl": 20.46982526542944,
    "ttft": 7051.69959151808,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072867,
    "arrivals": 18467,
    "finished_requests": 18431,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.7247954937629402. Arrivals time: 0.05627867626026273 Scheduler time: 1.2665238482877612 Scheduler overhead time: 0.15063902409747243 Adapter cache time: 0.0271736946888268 Engine time: 0.14817283675074577 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-8/adapters_16_slots_16_rate_0.8-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-8/adapters_16_slots_16_rate_0.8-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [5 5 6]
Adapter prompts. [270, 135, 135, 270, 8640, 135, 8640, 135, 270, 270, 135, 270, 8640, 8640, 8640, 8640]
Prompts retrieved: 53865 . Total input tokens: 11941603 . Total output tokens: 10790651
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 1.6981862811371684,
    "estimated_duration": 3599.964409490168,
    "input_throughput": 1241.039491452284,
    "output_throughput": 1108.2865123561153,
    "total_throughput": 2349.3260038083995,
    "itl": 20.381875547508105,
    "ttft": 5770.2426895181225,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 18199,
    "finished_requests": 18170,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.698298784904182. Arrivals time: 0.054760114289820194 Scheduler time: 1.2469317433424294 Scheduler overhead time: 0.14908907702192664 Adapter cache time: 0.026789939496666193 Engine time: 0.14515419071540236 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-16/adapters_16_slots_16_rate_0.8-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-16/adapters_16_slots_16_rate_0.8-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [5 5 6]
Adapter prompts. [270, 135, 135, 270, 8640, 135, 8640, 135, 270, 270, 135, 270, 8640, 8640, 8640, 8640]
Prompts retrieved: 53865 . Total input tokens: 11941603 . Total output tokens: 10790651
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.6937464629299939,
    "estimated_duration": 3599.944375196041,
    "input_throughput": 1241.0463980451652,
    "output_throughput": 1108.2926801564063,
    "total_throughput": 2349.3390782015717,
    "itl": 20.38184934634566,
    "ttft": 5770.206265526857,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 18199,
    "finished_requests": 18170,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.693845541216433. Arrivals time: 0.054849361069500446 Scheduler time: 1.2423163983039558 Scheduler overhead time: 0.14947564620524645 Adapter cache time: 0.026440381538122892 Engine time: 0.14525030879303813 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-32/adapters_16_slots_16_rate_0.8-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-32/adapters_16_slots_16_rate_0.8-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [5 5 6]
Adapter prompts. [270, 135, 135, 270, 8640, 135, 8640, 135, 270, 270, 135, 270, 8640, 8640, 8640, 8640]
Prompts retrieved: 53865 . Total input tokens: 11941603 . Total output tokens: 10790651
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.6940713501535356,
    "estimated_duration": 3599.9441458191113,
    "input_throughput": 1241.0464771206734,
    "output_throughput": 1108.292750773272,
    "total_throughput": 2349.3392278939455,
    "itl": 20.381843651185378,
    "ttft": 5770.214903768557,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 18199,
    "finished_requests": 18170,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6941693844273686. Arrivals time: 0.055222881492227316 Scheduler time: 1.2417345698922873 Scheduler overhead time: 0.1503618680872023 Adapter cache time: 0.026677479036152363 Engine time: 0.14440673356875777 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-16/adapters_16_slots_16_rate_0.8-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-16/adapters_16_slots_16_rate_0.8-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [5 5 6]
Adapter prompts. [270, 135, 135, 270, 8640, 135, 8640, 135, 270, 270, 135, 270, 8640, 8640, 8640, 8640]
Prompts retrieved: 53865 . Total input tokens: 11941603 . Total output tokens: 10790651
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 1.6901552812196314,
    "estimated_duration": 3599.9649218445184,
    "input_throughput": 1241.0393148250123,
    "output_throughput": 1108.2863546225183,
    "total_throughput": 2349.3256694475303,
    "itl": 20.381886884885404,
    "ttft": 5770.210744358048,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 18199,
    "finished_requests": 18170,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6902619991451502. Arrivals time: 0.054257681127637625 Scheduler time: 1.2369455941952765 Scheduler overhead time: 0.1503018639050424 Adapter cache time: 0.02671594638377428 Engine time: 0.1463383212685585 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-32/adapters_16_slots_16_rate_0.8-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-32/adapters_16_slots_16_rate_0.8-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [5 5 6]
Adapter prompts. [270, 135, 135, 270, 8640, 135, 8640, 135, 270, 270, 135, 270, 8640, 8640, 8640, 8640]
Prompts retrieved: 53865 . Total input tokens: 11941603 . Total output tokens: 10790651
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 1.708016850054264,
    "estimated_duration": 3599.9448566602537,
    "input_throughput": 1241.0462320650045,
    "output_throughput": 1108.2925319310075,
    "total_throughput": 2349.338763996012,
    "itl": 20.381817912411968,
    "ttft": 5770.19416209642,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.0530347929522395,
    "arrivals": 18199,
    "finished_requests": 18170,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.7081191949546337. Arrivals time: 0.05550731159746647 Scheduler time: 1.2494848812930286 Scheduler overhead time: 0.15066806599497795 Adapter cache time: 0.026855061762034893 Engine time: 0.1493960078805685 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-16/adapters_16_slots_16_rate_0.8-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-16/adapters_16_slots_16_rate_0.8-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [5 5 6]
Adapter prompts. [270, 135, 135, 270, 8640, 135, 8640, 135, 270, 270, 135, 270, 8640, 8640, 8640, 8640]
Prompts retrieved: 53865 . Total input tokens: 11941603 . Total output tokens: 10790651
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 1.6849035588093102,
    "estimated_duration": 3599.9644253801453,
    "input_throughput": 1241.0394859744274,
    "output_throughput": 1108.2865074642202,
    "total_throughput": 2349.3259934386474,
    "itl": 20.381877590277703,
    "ttft": 5770.2173080482025,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 18199,
    "finished_requests": 18170,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6850024876184762. Arrivals time: 0.05549936043098569 Scheduler time: 1.2338749608024955 Scheduler overhead time: 0.14891285821795464 Adapter cache time: 0.026689402759075165 Engine time: 0.14425740204751492 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-32/adapters_16_slots_16_rate_0.8-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-32/adapters_16_slots_16_rate_0.8-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [5 5 6]
Adapter prompts. [270, 135, 135, 270, 8640, 135, 8640, 135, 270, 270, 135, 270, 8640, 8640, 8640, 8640]
Prompts retrieved: 53865 . Total input tokens: 11941603 . Total output tokens: 10790651
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.695794709958136,
    "estimated_duration": 3599.944878111939,
    "input_throughput": 1241.046224669743,
    "output_throughput": 1108.292525326811,
    "total_throughput": 2349.3387499965543,
    "itl": 20.38182222321242,
    "ttft": 5770.1974655777485,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072867,
    "arrivals": 18199,
    "finished_requests": 18170,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6958952718414366. Arrivals time: 0.05543334875255823 Scheduler time: 1.2400023923255503 Scheduler overhead time: 0.15250971214845777 Adapter cache time: 0.026505743619054556 Engine time: 0.1451339186169207 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-8/adapters_16_slots_16_rate_0.8-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-8/adapters_16_slots_16_rate_0.8-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [5 5 6]
Adapter prompts. [270, 66, 66, 270, 8640, 66, 8640, 66, 270, 270, 66, 270, 8640, 8640, 8640, 8640]
Prompts retrieved: 53520 . Total input tokens: 11871903 . Total output tokens: 10720087
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 1.6877788938581944,
    "estimated_duration": 3599.999664780897,
    "input_throughput": 1249.5692830220817,
    "output_throughput": 1101.2706581019338,
    "total_throughput": 2350.8399411240157,
    "itl": 20.311355072372695,
    "ttft": 5011.679218728459,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 18079,
    "finished_requests": 18054,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.687886139843613. Arrivals time: 0.05465070903301239 Scheduler time: 1.2376823774538934 Scheduler overhead time: 0.149359202478081 Adapter cache time: 0.026204437017440796 Engine time: 0.1443057917058468 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-16/adapters_16_slots_16_rate_0.8-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-16/adapters_16_slots_16_rate_0.8-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [5 5 6]
Adapter prompts. [270, 66, 66, 270, 8640, 66, 8640, 66, 270, 270, 66, 270, 8640, 8640, 8640, 8640]
Prompts retrieved: 53520 . Total input tokens: 11871903 . Total output tokens: 10720087
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.6799784428440034,
    "estimated_duration": 3600.001647033939,
    "input_throughput": 1249.5685949772542,
    "output_throughput": 1101.2700517141245,
    "total_throughput": 2350.8386466913785,
    "itl": 20.311386302923914,
    "ttft": 5011.750686472539,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 18079,
    "finished_requests": 18054,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6800736491568387. Arrivals time: 0.055819966830313206 Scheduler time: 1.2248968267813325 Scheduler overhead time: 0.15156498504802585 Adapter cache time: 0.02638275781646371 Engine time: 0.14530262676998973 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-32/adapters_16_slots_16_rate_0.8-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-32/adapters_16_slots_16_rate_0.8-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [5 5 6]
Adapter prompts. [270, 66, 66, 270, 8640, 66, 8640, 66, 270, 270, 66, 270, 8640, 8640, 8640, 8640]
Prompts retrieved: 53520 . Total input tokens: 11871903 . Total output tokens: 10720087
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.6953018689528108,
    "estimated_duration": 3600.0017217880027,
    "input_throughput": 1249.5685690299526,
    "output_throughput": 1101.2700288462436,
    "total_throughput": 2350.838597876196,
    "itl": 20.31137275916445,
    "ttft": 5011.767783143202,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 18079,
    "finished_requests": 18054,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6953996662050486. Arrivals time: 0.05348933441564441 Scheduler time: 1.239524282515049 Scheduler overhead time: 0.15607627667486668 Adapter cache time: 0.026284352876245975 Engine time: 0.14376474590972066 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-16/adapters_16_slots_16_rate_0.8-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-16/adapters_16_slots_16_rate_0.8-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [5 5 6]
Adapter prompts. [270, 66, 66, 270, 8640, 66, 8640, 66, 270, 270, 66, 270, 8640, 8640, 8640, 8640]
Prompts retrieved: 53520 . Total input tokens: 11871903 . Total output tokens: 10720087
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 1.6860870006494224,
    "estimated_duration": 3600.000570620313,
    "input_throughput": 1249.5689686029345,
    "output_throughput": 1101.2703809979862,
    "total_throughput": 2350.8393496009207,
    "itl": 20.311391928292295,
    "ttft": 5011.75351614381,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 18079,
    "finished_requests": 18054,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6861873948946595. Arrivals time: 0.054644339717924595 Scheduler time: 1.2359607359394431 Scheduler overhead time: 0.14890283439308405 Adapter cache time: 0.026174386497586966 Engine time: 0.14447528822347522 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-32/adapters_16_slots_16_rate_0.8-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-32/adapters_16_slots_16_rate_0.8-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [5 5 6]
Adapter prompts. [270, 66, 66, 270, 8640, 66, 8640, 66, 270, 270, 66, 270, 8640, 8640, 8640, 8640]
Prompts retrieved: 53520 . Total input tokens: 11871903 . Total output tokens: 10720087
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 1.696304902434349,
    "estimated_duration": 3600.00356415318,
    "input_throughput": 1249.5679295412474,
    "output_throughput": 1101.269465251926,
    "total_throughput": 2350.837394793173,
    "itl": 20.311342506224918,
    "ttft": 5011.771913694056,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05303479295223951,
    "arrivals": 18079,
    "finished_requests": 18054,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6964049362577498. Arrivals time: 0.05487830238416791 Scheduler time: 1.2421126468107104 Scheduler overhead time: 0.151497311424464 Adapter cache time: 0.02646038495004177 Engine time: 0.14540268061682582 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-16/adapters_16_slots_16_rate_0.8-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-16/adapters_16_slots_16_rate_0.8-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [5 5 6]
Adapter prompts. [270, 66, 66, 270, 8640, 66, 8640, 66, 270, 270, 66, 270, 8640, 8640, 8640, 8640]
Prompts retrieved: 53520 . Total input tokens: 11871903 . Total output tokens: 10720087
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 1.7260802793316543,
    "estimated_duration": 3599.9954131091963,
    "input_throughput": 1249.5707587901727,
    "output_throughput": 1101.2719587261722,
    "total_throughput": 2350.842717516345,
    "itl": 20.31133365766163,
    "ttft": 5011.620353362856,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 18079,
    "finished_requests": 18054,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.726185493171215. Arrivals time: 0.055515910033136606 Scheduler time: 1.270130552817136 Scheduler overhead time: 0.15080380672588944 Adapter cache time: 0.026518631260842085 Engine time: 0.14708529226481915 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-32/adapters_16_slots_16_rate_0.8-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-32/adapters_16_slots_16_rate_0.8-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [5 5 6]
Adapter prompts. [270, 66, 66, 270, 8640, 66, 8640, 66, 270, 270, 66, 270, 8640, 8640, 8640, 8640]
Prompts retrieved: 53520 . Total input tokens: 11871903 . Total output tokens: 10720087
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.788522555027157,
    "estimated_duration": 3600.0055673882202,
    "input_throughput": 1249.5672342150278,
    "output_throughput": 1101.2688524468788,
    "total_throughput": 2350.8360866619064,
    "itl": 20.31133704749808,
    "ttft": 5011.705796396639,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072868,
    "arrivals": 18079,
    "finished_requests": 18054,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.788616314996034. Arrivals time: 0.05717673245817423 Scheduler time: 1.3178546307608485 Scheduler overhead time: 0.15902987541630864 Adapter cache time: 0.02684852574020624 Engine time: 0.15024419175460935 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-8/adapters_16_slots_16_rate_0.8-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-8/adapters_16_slots_16_rate_0.8-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [5 5 6]
Adapter prompts. [270, 33, 33, 270, 8640, 33, 8640, 33, 270, 270, 33, 270, 8640, 8640, 8640, 8640]
Prompts retrieved: 53355 . Total input tokens: 11834879 . Total output tokens: 10690242
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 1.7457233741879463,
    "estimated_duration": 3599.858022376286,
    "input_throughput": 1228.9195775225978,
    "output_throughput": 1101.827620796484,
    "total_throughput": 2330.747198319082,
    "itl": 20.304189094876495,
    "ttft": 5629.797544954496,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 18012,
    "finished_requests": 17984,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.7458242140710354. Arrivals time: 0.05646160198375583 Scheduler time: 1.289363294839859 Scheduler overhead time: 0.1505941040813923 Adapter cache time: 0.02625656919553876 Engine time: 0.14685693616047502 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-16/adapters_16_slots_16_rate_0.8-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-16/adapters_16_slots_16_rate_0.8-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [5 5 6]
Adapter prompts. [270, 33, 33, 270, 8640, 33, 8640, 33, 270, 270, 33, 270, 8640, 8640, 8640, 8640]
Prompts retrieved: 53355 . Total input tokens: 11834879 . Total output tokens: 10690242
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.7191164051182568,
    "estimated_duration": 3599.860491212868,
    "input_throughput": 1228.918734711712,
    "output_throughput": 1101.8268651471071,
    "total_throughput": 2330.7455998588193,
    "itl": 20.30420381969545,
    "ttft": 5629.773567837676,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 18012,
    "finished_requests": 17984,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.7192418649792671. Arrivals time: 0.05653823772445321 Scheduler time: 1.2628468391485512 Scheduler overhead time: 0.15022301208227873 Adapter cache time: 0.026228013448417187 Engine time: 0.14727736124768853 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-32/adapters_16_slots_16_rate_0.8-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-32/adapters_16_slots_16_rate_0.8-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [5 5 6]
Adapter prompts. [270, 33, 33, 270, 8640, 33, 8640, 33, 270, 270, 33, 270, 8640, 8640, 8640, 8640]
Prompts retrieved: 53355 . Total input tokens: 11834879 . Total output tokens: 10690242
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.686911639291793,
    "estimated_duration": 3599.8605520838273,
    "input_throughput": 1228.918713931612,
    "output_throughput": 1101.826846516036,
    "total_throughput": 2330.745560447648,
    "itl": 20.304201949943792,
    "ttft": 5629.774377423777,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 18012,
    "finished_requests": 17984,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.687010289169848. Arrivals time: 0.05353009421378374 Scheduler time: 1.2368644406087697 Scheduler overhead time: 0.14957324089482427 Adapter cache time: 0.025967677123844624 Engine time: 0.1453393865376711 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-16-16/adapters_16_slots_16_rate_0.8-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-16-16/adapters_16_slots_16_rate_0.8-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [5 5 6]
Adapter prompts. [270, 33, 33, 270, 8640, 33, 8640, 33, 270, 270, 33, 270, 8640, 8640, 8640, 8640]
Prompts retrieved: 53355 . Total input tokens: 11834879 . Total output tokens: 10690242
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 1.7636466859839857,
    "estimated_duration": 3599.859037579226,
    "input_throughput": 1228.919230952703,
    "output_throughput": 1101.8273100680283,
    "total_throughput": 2330.7465410207315,
    "itl": 20.30417257555177,
    "ttft": 5629.777379525837,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 18012,
    "finished_requests": 17984,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.7637471468187869. Arrivals time: 0.05635896138846874 Scheduler time: 1.2901205094531178 Scheduler overhead time: 0.16512145707383752 Adapter cache time: 0.02631103526800871 Engine time: 0.14808406680822372 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-16-32/adapters_16_slots_16_rate_0.8-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-16-32/adapters_16_slots_16_rate_0.8-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [5 5 6]
Adapter prompts. [270, 33, 33, 270, 8640, 33, 8640, 33, 270, 270, 33, 270, 8640, 8640, 8640, 8640]
Prompts retrieved: 53355 . Total input tokens: 11834879 . Total output tokens: 10690242
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 1.739234569016844,
    "estimated_duration": 3599.8611703042793,
    "input_throughput": 1228.9185028838392,
    "output_throughput": 1101.8266572943248,
    "total_throughput": 2330.745160178164,
    "itl": 20.30422079073883,
    "ttft": 5629.764002461005,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05303479295223951,
    "arrivals": 18012,
    "finished_requests": 17984,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.7393465088680387. Arrivals time: 0.057035424280911684 Scheduler time: 1.2806045948527753 Scheduler overhead time: 0.15125784557312727 Adapter cache time: 0.026417252141982317 Engine time: 0.147360619623214 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_16-16-16/adapters_16_slots_16_rate_0.8-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_16-16-16/adapters_16_slots_16_rate_0.8-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [5 5 6]
Adapter prompts. [270, 33, 33, 270, 8640, 33, 8640, 33, 270, 270, 33, 270, 8640, 8640, 8640, 8640]
Prompts retrieved: 53355 . Total input tokens: 11834879 . Total output tokens: 10690242
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 1.7137952581979334,
    "estimated_duration": 3599.85598591185,
    "input_throughput": 1228.9202727312463,
    "output_throughput": 1101.8282441082981,
    "total_throughput": 2330.748516839544,
    "itl": 20.30422854710863,
    "ttft": 5629.790299437919,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 18012,
    "finished_requests": 17984,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.7138936091214418. Arrivals time: 0.05543835135176778 Scheduler time: 1.2609312660060823 Scheduler overhead time: 0.14997980510815978 Adapter cache time: 0.026195780374109745 Engine time: 0.1455986057408154 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_16-16-32/adapters_16_slots_16_rate_0.8-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_16-16-32/adapters_16_slots_16_rate_0.8-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [5 5 6]
Adapter prompts. [270, 33, 33, 270, 8640, 33, 8640, 33, 270, 270, 33, 270, 8640, 8640, 8640, 8640]
Prompts retrieved: 53355 . Total input tokens: 11834879 . Total output tokens: 10690242
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.7232360397465527,
    "estimated_duration": 3599.861358282336,
    "input_throughput": 1228.9184387120033,
    "output_throughput": 1101.8265997589886,
    "total_throughput": 2330.745038470992,
    "itl": 20.30423054327368,
    "ttft": 5629.783394301705,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072868,
    "arrivals": 18012,
    "finished_requests": 17984,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.7233422677963972. Arrivals time: 0.05574042908847332 Scheduler time: 1.2636848003603518 Scheduler overhead time: 0.15399670507758856 Adapter cache time: 0.026143123395740986 Engine time: 0.14701223885640502 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-8/adapters_16_slots_16_rate_0.8-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-8/adapters_16_slots_16_rate_0.8-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [5 5 6]
Adapter prompts. [135, 66, 66, 135, 8640, 66, 8640, 66, 135, 135, 66, 135, 8640, 8640, 8640, 8640]
Prompts retrieved: 52845 . Total input tokens: 11722985 . Total output tokens: 10591372
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 1.701260433997959,
    "estimated_duration": 3599.9451882630715,
    "input_throughput": 1223.7711325059377,
    "output_throughput": 1070.7463026290714,
    "total_throughput": 2294.5174351350092,
    "itl": 20.169851805437666,
    "ttft": 6085.478949972531,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 17845,
    "finished_requests": 17815,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.7013584841042757. Arrivals time: 0.05621482711285353 Scheduler time: 1.2367577883414924 Scheduler overhead time: 0.15525421779602766 Adapter cache time: 0.026420867070555687 Engine time: 0.14930666983127594 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-16/adapters_16_slots_16_rate_0.8-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-16/adapters_16_slots_16_rate_0.8-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [5 5 6]
Adapter prompts. [135, 66, 66, 135, 8640, 66, 8640, 66, 135, 135, 66, 135, 8640, 8640, 8640, 8640]
Prompts retrieved: 52845 . Total input tokens: 11722985 . Total output tokens: 10591372
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.7113836389034986,
    "estimated_duration": 3599.9509157684524,
    "input_throughput": 1223.7691854916836,
    "output_throughput": 1070.7445990766194,
    "total_throughput": 2294.513784568303,
    "itl": 20.16986389552087,
    "ttft": 6085.464862747628,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 17845,
    "finished_requests": 17815,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.7114771017804742. Arrivals time: 0.05534402746707201 Scheduler time: 1.2484160354360938 Scheduler overhead time: 0.15389602864161134 Adapter cache time: 0.02629144210368395 Engine time: 0.15053711598739028 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-32/adapters_16_slots_16_rate_0.8-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-32/adapters_16_slots_16_rate_0.8-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [5 5 6]
Adapter prompts. [135, 66, 66, 135, 8640, 66, 8640, 66, 135, 135, 66, 135, 8640, 8640, 8640, 8640]
Prompts retrieved: 52845 . Total input tokens: 11722985 . Total output tokens: 10591372
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.678789412137121,
    "estimated_duration": 3599.950788880062,
    "input_throughput": 1223.7692286261906,
    "output_throughput": 1070.7446368174292,
    "total_throughput": 2294.51386544362,
    "itl": 20.169865521517558,
    "ttft": 6085.456133959732,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 17845,
    "finished_requests": 17815,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.678893892094493. Arrivals time: 0.054849689826369286 Scheduler time: 1.2225531288422644 Scheduler overhead time: 0.1505972556769848 Adapter cache time: 0.02632227260619402 Engine time: 0.1481566121801734 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-16-16/adapters_16_slots_16_rate_0.8-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-16-16/adapters_16_slots_16_rate_0.8-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [5 5 6]
Adapter prompts. [135, 66, 66, 135, 8640, 66, 8640, 66, 135, 135, 66, 135, 8640, 8640, 8640, 8640]
Prompts retrieved: 52845 . Total input tokens: 11722985 . Total output tokens: 10591372
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 1.6989230532199144,
    "estimated_duration": 3599.938559789602,
    "input_throughput": 1223.773385803973,
    "output_throughput": 1070.7482741664578,
    "total_throughput": 2294.521659970431,
    "itl": 20.173262172924037,
    "ttft": 6085.421471526273,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 17845,
    "finished_requests": 17815,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6990233124233782. Arrivals time: 0.056347380857914686 Scheduler time: 1.239645411260426 Scheduler overhead time: 0.15208191704005003 Adapter cache time: 0.026080424431711435 Engine time: 0.148044403642416 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-16-32/adapters_16_slots_16_rate_0.8-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-16-32/adapters_16_slots_16_rate_0.8-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [5 5 6]
Adapter prompts. [135, 66, 66, 135, 8640, 66, 8640, 66, 135, 135, 66, 135, 8640, 8640, 8640, 8640]
Prompts retrieved: 52845 . Total input tokens: 11722985 . Total output tokens: 10591372
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 1.7085967478342354,
    "estimated_duration": 3599.951266229283,
    "input_throughput": 1223.7690663558583,
    "output_throughput": 1070.7444948379743,
    "total_throughput": 2294.5135611938326,
    "itl": 20.169865468458216,
    "ttft": 6085.464918640665,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05303479295223951,
    "arrivals": 17845,
    "finished_requests": 17815,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.708712412044406. Arrivals time: 0.0560356006026268 Scheduler time: 1.244364668149501 Scheduler overhead time: 0.15557390917092562 Adapter cache time: 0.026485275477170944 Engine time: 0.14870261354371905 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_16-16-16/adapters_16_slots_16_rate_0.8-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_16-16-16/adapters_16_slots_16_rate_0.8-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [5 5 6]
Adapter prompts. [135, 66, 66, 135, 8640, 66, 8640, 66, 135, 135, 66, 135, 8640, 8640, 8640, 8640]
Prompts retrieved: 52845 . Total input tokens: 11722985 . Total output tokens: 10591372
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 1.6768235061317682,
    "estimated_duration": 3599.94443514928,
    "input_throughput": 1223.7713885206997,
    "output_throughput": 1070.7465266308088,
    "total_throughput": 2294.5179151515085,
    "itl": 20.1698189147429,
    "ttft": 6085.427733028891,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 17845,
    "finished_requests": 17815,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6769257271662354. Arrivals time: 0.056106995325535536 Scheduler time: 1.2162208426743746 Scheduler overhead time: 0.15137555683031678 Adapter cache time: 0.026440624613314867 Engine time: 0.15001733461394906 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_16-16-32/adapters_16_slots_16_rate_0.8-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_16-16-32/adapters_16_slots_16_rate_0.8-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [5 5 6]
Adapter prompts. [135, 66, 66, 135, 8640, 66, 8640, 66, 135, 135, 66, 135, 8640, 8640, 8640, 8640]
Prompts retrieved: 52845 . Total input tokens: 11722985 . Total output tokens: 10591372
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.675731975119561,
    "estimated_duration": 3599.953171195078,
    "input_throughput": 1223.7684187812647,
    "output_throughput": 1070.7439282384823,
    "total_throughput": 2294.5123470197473,
    "itl": 20.16988785229385,
    "ttft": 6085.482495297671,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072868,
    "arrivals": 17845,
    "finished_requests": 17815,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6758326990529895. Arrivals time: 0.05508728418499231 Scheduler time: 1.2169905384071171 Scheduler overhead time: 0.15321083180606365 Adapter cache time: 0.026436018757522106 Engine time: 0.14666040986776352 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-8/adapters_16_slots_16_rate_0.8-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-8/adapters_16_slots_16_rate_0.8-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [5 5 6]
Adapter prompts. [135, 33, 33, 135, 8640, 33, 8640, 33, 135, 135, 33, 135, 8640, 8640, 8640, 8640]
Prompts retrieved: 52680 . Total input tokens: 11683887 . Total output tokens: 10558489
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 1.683717377949506,
    "estimated_duration": 3599.746078458051,
    "input_throughput": 1222.0114708435988,
    "output_throughput": 1077.6754569482634,
    "total_throughput": 2299.686927791862,
    "itl": 20.36834130907332,
    "ttft": 4283.94235342907,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 17787,
    "finished_requests": 17766,
    "scheduler_time": 0.00022167232427783835
}
#Debug simulation 
Total elapsed time: 1.6838153349235654. Arrivals time: 0.05401647090911865 Scheduler time: 1.2291816603392363 Scheduler overhead time: 0.15258757956326008 Adapter cache time: 0.025757168885320425 Engine time: 0.14581088721752167 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-16/adapters_16_slots_16_rate_0.8-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-16/adapters_16_slots_16_rate_0.8-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [5 5 6]
Adapter prompts. [135, 33, 33, 135, 8640, 33, 8640, 33, 135, 135, 33, 135, 8640, 8640, 8640, 8640]
Prompts retrieved: 52680 . Total input tokens: 11683887 . Total output tokens: 10558489
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.6821726839989424,
    "estimated_duration": 3599.752088779268,
    "input_throughput": 1222.0094305137957,
    "output_throughput": 1077.6736576088913,
    "total_throughput": 2299.683088122687,
    "itl": 20.18586065256971,
    "ttft": 4283.589220877088,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 17787,
    "finished_requests": 17766,
    "scheduler_time": 0.00018193310787048892
}
#Debug simulation 
Total elapsed time: 1.6823005238547921. Arrivals time: 0.05525579350069165 Scheduler time: 1.2220128257758915 Scheduler overhead time: 0.15479455050081015 Adapter cache time: 0.0258231065236032 Engine time: 0.14770501013845205 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-32/adapters_16_slots_16_rate_0.8-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-32/adapters_16_slots_16_rate_0.8-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [5 5 6]
Adapter prompts. [135, 33, 33, 135, 8640, 33, 8640, 33, 135, 135, 33, 135, 8640, 8640, 8640, 8640]
Prompts retrieved: 52680 . Total input tokens: 11683887 . Total output tokens: 10558489
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.6767165060155094,
    "estimated_duration": 3599.752370892357,
    "input_throughput": 1222.0093347447485,
    "output_throughput": 1077.6735731514584,
    "total_throughput": 2299.682907896207,
    "itl": 20.18585367185303,
    "ttft": 4283.6032699639145,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.0524060240201652,
    "arrivals": 17787,
    "finished_requests": 17766,
    "scheduler_time": 0.00018193310787048892
}
#Debug simulation 
Total elapsed time: 1.6768182632513344. Arrivals time: 0.05427870061248541 Scheduler time: 1.2227267208509147 Scheduler overhead time: 0.15109745739027858 Adapter cache time: 0.025689213536679745 Engine time: 0.1465814202092588 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-16/adapters_16_slots_16_rate_0.8-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-16/adapters_16_slots_16_rate_0.8-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [5 5 6]
Adapter prompts. [135, 33, 33, 135, 8640, 33, 8640, 33, 135, 135, 33, 135, 8640, 8640, 8640, 8640]
Prompts retrieved: 52680 . Total input tokens: 11683887 . Total output tokens: 10558489
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 1.706146975979209,
    "estimated_duration": 3599.745226346463,
    "input_throughput": 1222.0117601113302,
    "output_throughput": 1077.6757120495797,
    "total_throughput": 2299.68747216091,
    "itl": 20.180206883496485,
    "ttft": 4283.638425125459,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 17787,
    "finished_requests": 17766,
    "scheduler_time": 0.00018193310787048892
}
#Debug simulation 
Total elapsed time: 1.7062459560111165. Arrivals time: 0.056299997959285975 Scheduler time: 1.2455246821045876 Scheduler overhead time: 0.15165997156873345 Adapter cache time: 0.02604772849008441 Engine time: 0.15021119453012943 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-32/adapters_16_slots_16_rate_0.8-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-32/adapters_16_slots_16_rate_0.8-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [5 5 6]
Adapter prompts. [135, 33, 33, 135, 8640, 33, 8640, 33, 135, 135, 33, 135, 8640, 8640, 8640, 8640]
Prompts retrieved: 52680 . Total input tokens: 11683887 . Total output tokens: 10558489
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 1.67893351521343,
    "estimated_duration": 3599.752596376382,
    "input_throughput": 1222.0092581996037,
    "output_throughput": 1077.6735056473262,
    "total_throughput": 2299.68276384693,
    "itl": 20.18583595406897,
    "ttft": 4283.634496052332,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.053034792952239514,
    "arrivals": 17787,
    "finished_requests": 17766,
    "scheduler_time": 0.00018193310787048892
}
#Debug simulation 
Total elapsed time: 1.679037906229496. Arrivals time: 0.05489024892449379 Scheduler time: 1.2256893049925566 Scheduler overhead time: 0.15014830837026238 Adapter cache time: 0.02573717711493373 Engine time: 0.14617713214829564 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-16/adapters_16_slots_16_rate_0.8-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-16/adapters_16_slots_16_rate_0.8-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [5 5 6]
Adapter prompts. [135, 33, 33, 135, 8640, 33, 8640, 33, 135, 135, 33, 135, 8640, 8640, 8640, 8640]
Prompts retrieved: 52680 . Total input tokens: 11683887 . Total output tokens: 10558489
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 1.6852064351551235,
    "estimated_duration": 3599.745225378809,
    "input_throughput": 1222.0117604398213,
    "output_throughput": 1077.6757123392715,
    "total_throughput": 2299.687472779093,
    "itl": 20.368362115766608,
    "ttft": 4283.943943892652,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 17787,
    "finished_requests": 17766,
    "scheduler_time": 0.00021929548825464184
}
#Debug simulation 
Total elapsed time: 1.6853003562428057. Arrivals time: 0.05465795611962676 Scheduler time: 1.2275921334512532 Scheduler overhead time: 0.1551773357205093 Adapter cache time: 0.02596270153298974 Engine time: 0.14531536167487502 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-32/adapters_16_slots_16_rate_0.8-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-32/adapters_16_slots_16_rate_0.8-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [5 5 6]
Adapter prompts. [135, 33, 33, 135, 8640, 33, 8640, 33, 135, 135, 33, 135, 8640, 8640, 8640, 8640]
Prompts retrieved: 52680 . Total input tokens: 11683887 . Total output tokens: 10558489
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.6672630598768592,
    "estimated_duration": 3599.7529860326117,
    "input_throughput": 1222.009125922883,
    "output_throughput": 1077.673388994268,
    "total_throughput": 2299.682514917151,
    "itl": 20.180244827824964,
    "ttft": 4283.632479694283,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072868,
    "arrivals": 17787,
    "finished_requests": 17766,
    "scheduler_time": 0.00018276709387951532
}
#Debug simulation 
Total elapsed time: 1.6673678010702133. Arrivals time: 0.05533710494637489 Scheduler time: 1.2126542394980788 Scheduler overhead time: 0.15085222944617271 Adapter cache time: 0.025967665016651154 Engine time: 0.14627047162503004 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-8/adapters_16_slots_16_rate_0.8-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-8/adapters_16_slots_16_rate_0.8-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [5 5 6]
Adapter prompts. [66, 33, 33, 66, 8640, 33, 8640, 33, 66, 66, 33, 66, 8640, 8640, 8640, 8640]
Prompts retrieved: 52335 . Total input tokens: 11604721 . Total output tokens: 10492912
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 1.654125118162483,
    "estimated_duration": 3599.969827087065,
    "input_throughput": 1212.730442113901,
    "output_throughput": 1059.4752687375112,
    "total_throughput": 2272.2057108514123,
    "itl": 20.120438362833575,
    "ttft": 2882.8804528528894,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 17687,
    "finished_requests": 17673,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6542233182117343. Arrivals time: 0.054904500022530556 Scheduler time: 1.1995736085809767 Scheduler overhead time: 0.14990224922075868 Adapter cache time: 0.025626899674534798 Engine time: 0.14734947169199586 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-16/adapters_16_slots_16_rate_0.8-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-16/adapters_16_slots_16_rate_0.8-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [5 5 6]
Adapter prompts. [66, 33, 33, 66, 8640, 33, 8640, 33, 66, 66, 33, 66, 8640, 8640, 8640, 8640]
Prompts retrieved: 52335 . Total input tokens: 11604721 . Total output tokens: 10492912
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.6566388849169016,
    "estimated_duration": 3599.9717199180227,
    "input_throughput": 1212.7298044717463,
    "output_throughput": 1059.474711675472,
    "total_throughput": 2272.2045161472183,
    "itl": 20.120445185024654,
    "ttft": 2882.7898953739996,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 17687,
    "finished_requests": 17673,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.656742992810905. Arrivals time: 0.05519839143380523 Scheduler time: 1.1975002470426261 Scheduler overhead time: 0.15210149995982647 Adapter cache time: 0.025754372123628855 Engine time: 0.14903583517298102 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-32/adapters_16_slots_16_rate_0.8-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-32/adapters_16_slots_16_rate_0.8-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [5 5 6]
Adapter prompts. [66, 33, 33, 66, 8640, 33, 8640, 33, 66, 66, 33, 66, 8640, 8640, 8640, 8640]
Prompts retrieved: 52335 . Total input tokens: 11604721 . Total output tokens: 10492912
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.6719500343315303,
    "estimated_duration": 3599.971788955515,
    "input_throughput": 1212.7297812149461,
    "output_throughput": 1059.4746913576803,
    "total_throughput": 2272.2044725726264,
    "itl": 20.120444489318384,
    "ttft": 2882.798574105174,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 17687,
    "finished_requests": 17673,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6720504332333803. Arrivals time: 0.054810944478958845 Scheduler time: 1.2070046430453658 Scheduler overhead time: 0.15990234725177288 Adapter cache time: 0.025840177666395903 Engine time: 0.14694799575954676 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-16/adapters_16_slots_16_rate_0.8-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-16/adapters_16_slots_16_rate_0.8-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [5 5 6]
Adapter prompts. [66, 33, 33, 66, 8640, 33, 8640, 33, 66, 66, 33, 66, 8640, 8640, 8640, 8640]
Prompts retrieved: 52335 . Total input tokens: 11604721 . Total output tokens: 10492912
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 1.6684829648584127,
    "estimated_duration": 3599.9716182338775,
    "input_throughput": 1212.7298387262924,
    "output_throughput": 1059.4747416012024,
    "total_throughput": 2272.204580327495,
    "itl": 20.120464982609963,
    "ttft": 2882.8601822791315,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 17687,
    "finished_requests": 17673,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6685848790220916. Arrivals time: 0.05539668025448918 Scheduler time: 1.2110935794189572 Scheduler overhead time: 0.1508851582184434 Adapter cache time: 0.025899104308336973 Engine time: 0.14850068697705865 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-32/adapters_16_slots_16_rate_0.8-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-32/adapters_16_slots_16_rate_0.8-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [5 5 6]
Adapter prompts. [66, 33, 33, 66, 8640, 33, 8640, 33, 66, 66, 33, 66, 8640, 8640, 8640, 8640]
Prompts retrieved: 52335 . Total input tokens: 11604721 . Total output tokens: 10492912
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 1.651164405979216,
    "estimated_duration": 3599.9718168803524,
    "input_throughput": 1212.7297718078498,
    "output_throughput": 1059.4746831393772,
    "total_throughput": 2272.204454947227,
    "itl": 20.120428914345187,
    "ttft": 2882.7828406118865,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05303479295223951,
    "arrivals": 17687,
    "finished_requests": 17673,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6512943711131811. Arrivals time: 0.054912098217755556 Scheduler time: 1.1949238451197743 Scheduler overhead time: 0.1515177246183157 Adapter cache time: 0.025710607413202524 Engine time: 0.1473459443077445 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-16/adapters_16_slots_16_rate_0.8-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-16/adapters_16_slots_16_rate_0.8-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [5 5 6]
Adapter prompts. [66, 33, 33, 66, 8640, 33, 8640, 33, 66, 66, 33, 66, 8640, 8640, 8640, 8640]
Prompts retrieved: 52335 . Total input tokens: 11604721 . Total output tokens: 10492912
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 1.683779302984476,
    "estimated_duration": 3599.9690625401345,
    "input_throughput": 1212.730699668708,
    "output_throughput": 1059.4754937446016,
    "total_throughput": 2272.20619341331,
    "itl": 20.12044799449662,
    "ttft": 2882.874274197721,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 17687,
    "finished_requests": 17673,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6838719258084893. Arrivals time: 0.055101577658206224 Scheduler time: 1.2234904360957444 Scheduler overhead time: 0.15521385939791799 Adapter cache time: 0.025803421158343554 Engine time: 0.14750627800822258 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-32/adapters_16_slots_16_rate_0.8-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-32/adapters_16_slots_16_rate_0.8-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [5 5 6]
Adapter prompts. [66, 33, 33, 66, 8640, 33, 8640, 33, 66, 66, 33, 66, 8640, 8640, 8640, 8640]
Prompts retrieved: 52335 . Total input tokens: 11604721 . Total output tokens: 10492912
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.6586981220170856,
    "estimated_duration": 3599.952090140922,
    "input_throughput": 1212.7364172307912,
    "output_throughput": 1059.4804887669202,
    "total_throughput": 2272.2169059977114,
    "itl": 20.120430285512146,
    "ttft": 2882.765075939779,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072868,
    "arrivals": 17687,
    "finished_requests": 17673,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6587999118492007. Arrivals time: 0.05479260440915823 Scheduler time: 1.198884314391762 Scheduler overhead time: 0.1536534121260047 Adapter cache time: 0.025865127332508564 Engine time: 0.1485632541589439 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-8/adapters_16_slots_16_rate_0.4-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-8/adapters_16_slots_16_rate_0.4-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [5 5 6]
Adapter prompts. [1080, 540, 540, 1080, 4320, 540, 4320, 540, 1080, 1080, 540, 1080, 4320, 4320, 4320, 4320]
Prompts retrieved: 34020 . Total input tokens: 7522942 . Total output tokens: 6832077
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 1.3113544266670942,
    "estimated_duration": 3599.818537284869,
    "input_throughput": 771.8055705373287,
    "output_throughput": 701.8323212218265,
    "total_throughput": 1473.6378917591553,
    "itl": 19.82158241704976,
    "ttft": 8510.684217248989,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 11465,
    "finished_requests": 11438,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3114708857610822. Arrivals time: 0.041729012969881296 Scheduler time: 0.8570864629000425 Scheduler overhead time: 0.15309496456757188 Adapter cache time: 0.033661861438304186 Engine time: 0.14855463849380612 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-16/adapters_16_slots_16_rate_0.4-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-16/adapters_16_slots_16_rate_0.4-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [5 5 6]
Adapter prompts. [1080, 540, 540, 1080, 4320, 540, 4320, 540, 1080, 1080, 540, 1080, 4320, 4320, 4320, 4320]
Prompts retrieved: 34020 . Total input tokens: 7522942 . Total output tokens: 6832077
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.3022028780542314,
    "estimated_duration": 3599.806860700398,
    "input_throughput": 771.8080740196788,
    "output_throughput": 701.8345977340674,
    "total_throughput": 1473.642671753746,
    "itl": 19.82155903916145,
    "ttft": 8510.77784468584,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 11465,
    "finished_requests": 11438,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3022996298968792. Arrivals time: 0.04166617291048169 Scheduler time: 0.8534613423980772 Scheduler overhead time: 0.1511395457200706 Adapter cache time: 0.032521487679332495 Engine time: 0.14672981528565288 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-32/adapters_16_slots_16_rate_0.4-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-32/adapters_16_slots_16_rate_0.4-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [5 5 6]
Adapter prompts. [1080, 540, 540, 1080, 4320, 540, 4320, 540, 1080, 1080, 540, 1080, 4320, 4320, 4320, 4320]
Prompts retrieved: 34020 . Total input tokens: 7522942 . Total output tokens: 6832077
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.2947842027060688,
    "estimated_duration": 3599.8066019239527,
    "input_throughput": 771.8081295020343,
    "output_throughput": 701.8346481862951,
    "total_throughput": 1473.6427776883295,
    "itl": 19.821552917076414,
    "ttft": 8510.768306306083,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 11465,
    "finished_requests": 11438,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2949030376039445. Arrivals time: 0.041534217074513435 Scheduler time: 0.8473937907256186 Scheduler overhead time: 0.15013777371495962 Adapter cache time: 0.03240019083023071 Engine time: 0.14708496257662773 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-16-16/adapters_16_slots_16_rate_0.4-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-16-16/adapters_16_slots_16_rate_0.4-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [5 5 6]
Adapter prompts. [1080, 540, 540, 1080, 4320, 540, 4320, 540, 1080, 1080, 540, 1080, 4320, 4320, 4320, 4320]
Prompts retrieved: 34020 . Total input tokens: 7522942 . Total output tokens: 6832077
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 1.30336524406448,
    "estimated_duration": 3599.8049433494957,
    "input_throughput": 771.8084851049821,
    "output_throughput": 701.8349715496548,
    "total_throughput": 1473.6434566546368,
    "itl": 19.821608780161945,
    "ttft": 8510.77452761992,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 11465,
    "finished_requests": 11438,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3034910107962787. Arrivals time: 0.041616170201450586 Scheduler time: 0.8521942957304418 Scheduler overhead time: 0.15124649740755558 Adapter cache time: 0.03374955430626869 Engine time: 0.14795975340530276 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-16-32/adapters_16_slots_16_rate_0.4-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-16-32/adapters_16_slots_16_rate_0.4-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [5 5 6]
Adapter prompts. [1080, 540, 540, 1080, 4320, 540, 4320, 540, 1080, 1080, 540, 1080, 4320, 4320, 4320, 4320]
Prompts retrieved: 34020 . Total input tokens: 7522942 . Total output tokens: 6832077
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 1.3004544330760837,
    "estimated_duration": 3599.806829519059,
    "input_throughput": 771.80808070504,
    "output_throughput": 701.8346038133221,
    "total_throughput": 1473.642684518362,
    "itl": 19.821583901723045,
    "ttft": 8510.830741122109,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05303479295223951,
    "arrivals": 11465,
    "finished_requests": 11438,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3006599019281566. Arrivals time: 0.04133081762120128 Scheduler time: 0.8511269679293036 Scheduler overhead time: 0.15099970996379852 Adapter cache time: 0.03259994648396969 Engine time: 0.14779263688251376 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_16-16-16/adapters_16_slots_16_rate_0.4-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_16-16-16/adapters_16_slots_16_rate_0.4-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [5 5 6]
Adapter prompts. [1080, 540, 540, 1080, 4320, 540, 4320, 540, 1080, 1080, 540, 1080, 4320, 4320, 4320, 4320]
Prompts retrieved: 34020 . Total input tokens: 7522942 . Total output tokens: 6832077
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 1.304733444005251,
    "estimated_duration": 3599.8185866576287,
    "input_throughput": 771.8055599517477,
    "output_throughput": 701.832311595953,
    "total_throughput": 1473.6378715477006,
    "itl": 19.821597308591482,
    "ttft": 8510.673298812746,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 11465,
    "finished_requests": 11438,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.30483401985839. Arrivals time: 0.041896428912878036 Scheduler time: 0.852939204312861 Scheduler overhead time: 0.1517656771466136 Adapter cache time: 0.03269938239827752 Engine time: 0.1484932005405426 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_16-16-32/adapters_16_slots_16_rate_0.4-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_16-16-32/adapters_16_slots_16_rate_0.4-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [5 5 6]
Adapter prompts. [1080, 540, 540, 1080, 4320, 540, 4320, 540, 1080, 1080, 540, 1080, 4320, 4320, 4320, 4320]
Prompts retrieved: 34020 . Total input tokens: 7522942 . Total output tokens: 6832077
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.3100762381218374,
    "estimated_duration": 3599.806632517455,
    "input_throughput": 771.8081229427058,
    "output_throughput": 701.8346422216471,
    "total_throughput": 1473.642765164353,
    "itl": 19.82149146803054,
    "ttft": 8510.732963258999,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072868,
    "arrivals": 11465,
    "finished_requests": 11438,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3101769611239433. Arrivals time: 0.04092296399176121 Scheduler time: 0.8557841088622808 Scheduler overhead time: 0.1525546871125698 Adapter cache time: 0.03260087640956044 Engine time: 0.15151371620595455 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-8/adapters_16_slots_16_rate_0.4-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-8/adapters_16_slots_16_rate_0.4-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [5 5 6]
Adapter prompts. [1080, 270, 270, 1080, 4320, 270, 4320, 270, 1080, 1080, 270, 1080, 4320, 4320, 4320, 4320]
Prompts retrieved: 32670 . Total input tokens: 7221525 . Total output tokens: 6567261
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 1.267150071915239,
    "estimated_duration": 3600.010586968291,
    "input_throughput": 746.822248171261,
    "output_throughput": 672.4621890733687,
    "total_throughput": 1419.2844372446298,
    "itl": 19.623401320485307,
    "ttft": 6232.635471234012,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 11033,
    "finished_requests": 11013,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.267247384879738. Arrivals time: 0.04056710563600063 Scheduler time: 0.8195072640664876 Scheduler overhead time: 0.15129329776391387 Adapter cache time: 0.03190041705965996 Engine time: 0.14680558163672686 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-16/adapters_16_slots_16_rate_0.4-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-16/adapters_16_slots_16_rate_0.4-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [5 5 6]
Adapter prompts. [1080, 270, 270, 1080, 4320, 270, 4320, 270, 1080, 1080, 270, 1080, 4320, 4320, 4320, 4320]
Prompts retrieved: 32670 . Total input tokens: 7221525 . Total output tokens: 6567261
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.262798682320863,
    "estimated_duration": 3600.0111381946986,
    "input_throughput": 746.8221338193523,
    "output_throughput": 672.4620861073215,
    "total_throughput": 1419.2842199266738,
    "itl": 19.623437075887317,
    "ttft": 6232.658325241673,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 11033,
    "finished_requests": 11013,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2628974840044975. Arrivals time: 0.0403272514231503 Scheduler time: 0.814158437307924 Scheduler overhead time: 0.15030933124944568 Adapter cache time: 0.03216730058193207 Engine time: 0.1487427344545722 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-32/adapters_16_slots_16_rate_0.4-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-32/adapters_16_slots_16_rate_0.4-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [5 5 6]
Adapter prompts. [1080, 270, 270, 1080, 4320, 270, 4320, 270, 1080, 1080, 270, 1080, 4320, 4320, 4320, 4320]
Prompts retrieved: 32670 . Total input tokens: 7221525 . Total output tokens: 6567261
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.2736365739256144,
    "estimated_duration": 3600.015244462369,
    "input_throughput": 746.8212819752973,
    "output_throughput": 672.4613190802019,
    "total_throughput": 1419.2826010554993,
    "itl": 19.623496857206888,
    "ttft": 6558.354913118706,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 11033,
    "finished_requests": 11013,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2737392107956111. Arrivals time: 0.04114790726453066 Scheduler time: 0.8259538193233311 Scheduler overhead time: 0.15182615350931883 Adapter cache time: 0.03181810304522514 Engine time: 0.14645918644964695 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-16-16/adapters_16_slots_16_rate_0.4-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-16-16/adapters_16_slots_16_rate_0.4-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [5 5 6]
Adapter prompts. [1080, 270, 270, 1080, 4320, 270, 4320, 270, 1080, 1080, 270, 1080, 4320, 4320, 4320, 4320]
Prompts retrieved: 32670 . Total input tokens: 7221525 . Total output tokens: 6567261
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 1.271695317234844,
    "estimated_duration": 3600.010516447841,
    "input_throughput": 746.8222628007296,
    "output_throughput": 672.4622022462014,
    "total_throughput": 1419.284465046931,
    "itl": 19.623449615218917,
    "ttft": 6232.62098346026,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 11033,
    "finished_requests": 11013,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2718215328641236. Arrivals time: 0.03992400597780943 Scheduler time: 0.8219771818257868 Scheduler overhead time: 0.15173440193757415 Adapter cache time: 0.03196821315214038 Engine time: 0.14918909687548876 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-16-32/adapters_16_slots_16_rate_0.4-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-16-32/adapters_16_slots_16_rate_0.4-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [5 5 6]
Adapter prompts. [1080, 270, 270, 1080, 4320, 270, 4320, 270, 1080, 1080, 270, 1080, 4320, 4320, 4320, 4320]
Prompts retrieved: 32670 . Total input tokens: 7221525 . Total output tokens: 6567261
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 1.2590137589722872,
    "estimated_duration": 3600.015117233907,
    "input_throughput": 746.8213083687763,
    "output_throughput": 672.4613428457186,
    "total_throughput": 1419.2826512144948,
    "itl": 19.623475415916193,
    "ttft": 6558.3356991078535,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.0530347929522395,
    "arrivals": 11033,
    "finished_requests": 11013,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2591464696452022. Arrivals time: 0.039814851712435484 Scheduler time: 0.8116910574026406 Scheduler overhead time: 0.15176028572022915 Adapter cache time: 0.031770655419677496 Engine time: 0.14691758900880814 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_16-16-16/adapters_16_slots_16_rate_0.4-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_16-16-16/adapters_16_slots_16_rate_0.4-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [5 5 6]
Adapter prompts. [1080, 270, 270, 1080, 4320, 270, 4320, 270, 1080, 1080, 270, 1080, 4320, 4320, 4320, 4320]
Prompts retrieved: 32670 . Total input tokens: 7221525 . Total output tokens: 6567261
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 1.2942913849838078,
    "estimated_duration": 3600.011135175168,
    "input_throughput": 746.8221344457538,
    "output_throughput": 672.4620866713531,
    "total_throughput": 1419.2842211171069,
    "itl": 19.623420298572345,
    "ttft": 6232.620193897585,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 11033,
    "finished_requests": 11013,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2944192220456898. Arrivals time: 0.040767195634543896 Scheduler time: 0.8341075778007507 Scheduler overhead time: 0.15924841538071632 Adapter cache time: 0.03216519672423601 Engine time: 0.149670435115695 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_16-16-32/adapters_16_slots_16_rate_0.4-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_16-16-32/adapters_16_slots_16_rate_0.4-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [5 5 6]
Adapter prompts. [1080, 270, 270, 1080, 4320, 270, 4320, 270, 1080, 1080, 270, 1080, 4320, 4320, 4320, 4320]
Prompts retrieved: 32670 . Total input tokens: 7221525 . Total output tokens: 6567261
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.2675967840477824,
    "estimated_duration": 3600.0151704749933,
    "input_throughput": 746.8212973239401,
    "output_throughput": 672.4613329006015,
    "total_throughput": 1419.2826302245417,
    "itl": 19.623489053185217,
    "ttft": 6558.3077780944095,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072868,
    "arrivals": 11033,
    "finished_requests": 11013,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2676934953778982. Arrivals time: 0.03954632766544819 Scheduler time: 0.818490116391331 Scheduler overhead time: 0.15171455964446068 Adapter cache time: 0.03182695806026459 Engine time: 0.14893008302897215 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-8/adapters_16_slots_16_rate_0.4-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-8/adapters_16_slots_16_rate_0.4-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [5 5 6]
Adapter prompts. [1080, 135, 135, 1080, 4320, 135, 4320, 135, 1080, 1080, 135, 1080, 4320, 4320, 4320, 4320]
Prompts retrieved: 31995 . Total input tokens: 7076680 . Total output tokens: 6432818
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 1.2653576079756021,
    "estimated_duration": 3600.0049492329354,
    "input_throughput": 737.3309307715203,
    "output_throughput": 655.9202093605825,
    "total_throughput": 1393.2511401321028,
    "itl": 19.666921011532054,
    "ttft": 5030.468200530325,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 10804,
    "finished_requests": 10789,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2654581777751446. Arrivals time: 0.0400418508797884 Scheduler time: 0.8049394534900784 Scheduler overhead time: 0.16157597862184048 Adapter cache time: 0.03174872091040015 Engine time: 0.14858429925516248 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-16/adapters_16_slots_16_rate_0.4-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-16/adapters_16_slots_16_rate_0.4-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [5 5 6]
Adapter prompts. [1080, 135, 135, 1080, 4320, 135, 4320, 135, 1080, 1080, 135, 1080, 4320, 4320, 4320, 4320]
Prompts retrieved: 31995 . Total input tokens: 7076680 . Total output tokens: 6432818
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.2411525771021843,
    "estimated_duration": 3600.01009406636,
    "input_throughput": 737.3298770398033,
    "output_throughput": 655.9192719742616,
    "total_throughput": 1393.2491490140649,
    "itl": 19.66706363644009,
    "ttft": 5030.590608285492,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 10804,
    "finished_requests": 10789,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2413195329718292. Arrivals time: 0.039024046156555414 Scheduler time: 0.7951808949001133 Scheduler overhead time: 0.15145073598250747 Adapter cache time: 0.03118633246049285 Engine time: 0.14706144528463483 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-32/adapters_16_slots_16_rate_0.4-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-32/adapters_16_slots_16_rate_0.4-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [5 5 6]
Adapter prompts. [1080, 135, 135, 1080, 4320, 135, 4320, 135, 1080, 1080, 135, 1080, 4320, 4320, 4320, 4320]
Prompts retrieved: 31995 . Total input tokens: 7076680 . Total output tokens: 6432818
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.2476007314398885,
    "estimated_duration": 3600.0101177147308,
    "input_throughput": 737.329872196303,
    "output_throughput": 655.9192676655454,
    "total_throughput": 1393.2491398618483,
    "itl": 19.667051927317992,
    "ttft": 5030.597238530372,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.052406024020165184,
    "arrivals": 10804,
    "finished_requests": 10789,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2476979922503233. Arrivals time: 0.03966598818078637 Scheduler time: 0.8027236042544246 Scheduler overhead time: 0.15115008130669594 Adapter cache time: 0.03129974473267794 Engine time: 0.1461434313096106 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-16/adapters_16_slots_16_rate_0.4-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-16/adapters_16_slots_16_rate_0.4-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [5 5 6]
Adapter prompts. [1080, 135, 135, 1080, 4320, 135, 4320, 135, 1080, 1080, 135, 1080, 4320, 4320, 4320, 4320]
Prompts retrieved: 31995 . Total input tokens: 7076680 . Total output tokens: 6432818
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 1.2464077067561448,
    "estimated_duration": 3600.0091964288863,
    "input_throughput": 737.3300608879248,
    "output_throughput": 655.91943552321,
    "total_throughput": 1393.249496411135,
    "itl": 19.666970862005197,
    "ttft": 5030.505515352601,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 10804,
    "finished_requests": 10789,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.24653130909428. Arrivals time: 0.04006665479391813 Scheduler time: 0.7990088569931686 Scheduler overhead time: 0.15030617080628872 Adapter cache time: 0.031119888182729483 Engine time: 0.14858518121764064 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-32/adapters_16_slots_16_rate_0.4-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-32/adapters_16_slots_16_rate_0.4-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [5 5 6]
Adapter prompts. [1080, 135, 135, 1080, 4320, 135, 4320, 135, 1080, 1080, 135, 1080, 4320, 4320, 4320, 4320]
Prompts retrieved: 31995 . Total input tokens: 7076680 . Total output tokens: 6432818
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 1.2510366649366915,
    "estimated_duration": 3600.0105358580236,
    "input_throughput": 737.3297865550145,
    "output_throughput": 655.9191914801454,
    "total_throughput": 1393.24897803516,
    "itl": 19.667014877310724,
    "ttft": 5030.589872867067,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.0530347929522395,
    "arrivals": 10804,
    "finished_requests": 10789,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2511259098537266. Arrivals time: 0.03977474616840482 Scheduler time: 0.8028568276204169 Scheduler overhead time: 0.1517865345813334 Adapter cache time: 0.031110703013837337 Engine time: 0.14818231482058764 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-16/adapters_16_slots_16_rate_0.4-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-16/adapters_16_slots_16_rate_0.4-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [5 5 6]
Adapter prompts. [1080, 135, 135, 1080, 4320, 135, 4320, 135, 1080, 1080, 135, 1080, 4320, 4320, 4320, 4320]
Prompts retrieved: 31995 . Total input tokens: 7076680 . Total output tokens: 6432818
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 1.2487008827738464,
    "estimated_duration": 3600.0042467552994,
    "input_throughput": 737.3310746487087,
    "output_throughput": 655.9203373518976,
    "total_throughput": 1393.2514120006063,
    "itl": 19.666906780563306,
    "ttft": 5030.4820201617495,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 10804,
    "finished_requests": 10789,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2488020989112556. Arrivals time: 0.0389878754504025 Scheduler time: 0.8000847557559609 Scheduler overhead time: 0.15185330621898174 Adapter cache time: 0.03134132083505392 Engine time: 0.14889512723311782 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-32/adapters_16_slots_16_rate_0.4-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-32/adapters_16_slots_16_rate_0.4-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [5 5 6]
Adapter prompts. [1080, 135, 135, 1080, 4320, 135, 4320, 135, 1080, 1080, 135, 1080, 4320, 4320, 4320, 4320]
Prompts retrieved: 31995 . Total input tokens: 7076680 . Total output tokens: 6432818
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.2449549022130668,
    "estimated_duration": 3600.0112916150915,
    "input_throughput": 737.3296317660007,
    "output_throughput": 655.9190537818093,
    "total_throughput": 1393.24868554781,
    "itl": 19.667070321033826,
    "ttft": 5030.58030168106,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072867,
    "arrivals": 10804,
    "finished_requests": 10789,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2450774041935802. Arrivals time: 0.03912319568917155 Scheduler time: 0.7979986839927733 Scheduler overhead time: 0.15204857755452394 Adapter cache time: 0.031267324462533 Engine time: 0.14744881354272366 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-8/adapters_16_slots_16_rate_0.4-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-8/adapters_16_slots_16_rate_0.4-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [5 5 6]
Adapter prompts. [1080, 66, 66, 1080, 4320, 66, 4320, 66, 1080, 1080, 66, 1080, 4320, 4320, 4320, 4320]
Prompts retrieved: 31650 . Total input tokens: 7001453 . Total output tokens: 6363302
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 1.238780985120684,
    "estimated_duration": 3600.0140988881853,
    "input_throughput": 728.1715926639265,
    "output_throughput": 646.5094124822451,
    "total_throughput": 1374.6810051461716,
    "itl": 19.599669437822826,
    "ttft": 7443.835149196861,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 10686,
    "finished_requests": 10664,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.238890497945249. Arrivals time: 0.03919327259063721 Scheduler time: 0.7905025570653379 Scheduler overhead time: 0.1526623130775988 Adapter cache time: 0.030781612265855074 Engine time: 0.14788398705422878 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-16/adapters_16_slots_16_rate_0.4-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-16/adapters_16_slots_16_rate_0.4-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [5 5 6]
Adapter prompts. [1080, 66, 66, 1080, 4320, 66, 4320, 66, 1080, 1080, 66, 1080, 4320, 4320, 4320, 4320]
Prompts retrieved: 31650 . Total input tokens: 7001453 . Total output tokens: 6363302
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.2387979230843484,
    "estimated_duration": 3599.9984230082882,
    "input_throughput": 728.1747634237685,
    "output_throughput": 646.5122276512291,
    "total_throughput": 1374.6869910749976,
    "itl": 19.59972201479924,
    "ttft": 7443.902709901136,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 10686,
    "finished_requests": 10664,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2388952663168311. Arrivals time: 0.03894866909831762 Scheduler time: 0.7908617570064962 Scheduler overhead time: 0.15294272499158978 Adapter cache time: 0.03101929696276784 Engine time: 0.14740259246900678 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-32/adapters_16_slots_16_rate_0.4-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-32/adapters_16_slots_16_rate_0.4-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [5 5 6]
Adapter prompts. [1080, 66, 66, 1080, 4320, 66, 4320, 66, 1080, 1080, 66, 1080, 4320, 4320, 4320, 4320]
Prompts retrieved: 31650 . Total input tokens: 7001453 . Total output tokens: 6363302
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.2444531340152025,
    "estimated_duration": 3599.998473262756,
    "input_throughput": 728.1747532587544,
    "output_throughput": 646.5122186261897,
    "total_throughput": 1374.6869718849441,
    "itl": 19.599706561024874,
    "ttft": 7443.874351440555,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 10686,
    "finished_requests": 10664,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2445471920073032. Arrivals time: 0.039803360123187304 Scheduler time: 0.7938512503169477 Scheduler overhead time: 0.1516266269609332 Adapter cache time: 0.031100815627723932 Engine time: 0.1507907542400062 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-16/adapters_16_slots_16_rate_0.4-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-16/adapters_16_slots_16_rate_0.4-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [5 5 6]
Adapter prompts. [1080, 66, 66, 1080, 4320, 66, 4320, 66, 1080, 1080, 66, 1080, 4320, 4320, 4320, 4320]
Prompts retrieved: 31650 . Total input tokens: 7001453 . Total output tokens: 6363302
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 1.2375801457092166,
    "estimated_duration": 3600.014129561789,
    "input_throughput": 728.1715864596044,
    "output_throughput": 646.5094069737186,
    "total_throughput": 1374.680993433323,
    "itl": 19.599720078447024,
    "ttft": 7443.828297176193,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 10686,
    "finished_requests": 10664,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2377031166106462. Arrivals time: 0.03925579786300659 Scheduler time: 0.7914130380377173 Scheduler overhead time: 0.1505351010710001 Adapter cache time: 0.031214230228215456 Engine time: 0.14783168770372868 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-32/adapters_16_slots_16_rate_0.4-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-32/adapters_16_slots_16_rate_0.4-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [5 5 6]
Adapter prompts. [1080, 66, 66, 1080, 4320, 66, 4320, 66, 1080, 1080, 66, 1080, 4320, 4320, 4320, 4320]
Prompts retrieved: 31650 . Total input tokens: 7001453 . Total output tokens: 6363302
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 1.2358211181126535,
    "estimated_duration": 3600.0084266402973,
    "input_throughput": 728.1727399861794,
    "output_throughput": 646.5104311358746,
    "total_throughput": 1374.6831711220539,
    "itl": 19.599763241819396,
    "ttft": 7443.760209630878,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05303479295223951,
    "arrivals": 10686,
    "finished_requests": 10664,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2359130578115582. Arrivals time: 0.03952843463048339 Scheduler time: 0.7868308234028518 Scheduler overhead time: 0.15147844795137644 Adapter cache time: 0.031268004793673754 Engine time: 0.14895464107394218 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-16/adapters_16_slots_16_rate_0.4-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-16/adapters_16_slots_16_rate_0.4-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [5 5 6]
Adapter prompts. [1080, 66, 66, 1080, 4320, 66, 4320, 66, 1080, 1080, 66, 1080, 4320, 4320, 4320, 4320]
Prompts retrieved: 31650 . Total input tokens: 7001453 . Total output tokens: 6363302
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 1.2492135972715914,
    "estimated_duration": 3600.0140878286093,
    "input_throughput": 728.171594900937,
    "output_throughput": 646.5094144683818,
    "total_throughput": 1374.6810093693189,
    "itl": 19.5996650340504,
    "ttft": 7443.817369057145,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 10686,
    "finished_requests": 10664,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2493163142353296. Arrivals time: 0.039759792387485504 Scheduler time: 0.7989770569838583 Scheduler overhead time: 0.1524507086724043 Adapter cache time: 0.03116842918097973 Engine time: 0.14934301609173417 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-32/adapters_16_slots_16_rate_0.4-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-32/adapters_16_slots_16_rate_0.4-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [5 5 6]
Adapter prompts. [1080, 66, 66, 1080, 4320, 66, 4320, 66, 1080, 1080, 66, 1080, 4320, 4320, 4320, 4320]
Prompts retrieved: 31650 . Total input tokens: 7001453 . Total output tokens: 6363302
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.2320593041367829,
    "estimated_duration": 3600.00840807598,
    "input_throughput": 728.1727437411789,
    "output_throughput": 646.5104344697626,
    "total_throughput": 1374.6831782109416,
    "itl": 19.59976481066279,
    "ttft": 7443.770082982202,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072868,
    "arrivals": 10686,
    "finished_requests": 10664,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.232162922155112. Arrivals time: 0.039373391307890415 Scheduler time: 0.7864165049977601 Scheduler overhead time: 0.15153549099341035 Adapter cache time: 0.03093906119465828 Engine time: 0.1468496206216514 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-8/adapters_16_slots_16_rate_0.4-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-8/adapters_16_slots_16_rate_0.4-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [5 5 6]
Adapter prompts. [1080, 33, 33, 1080, 4320, 33, 4320, 33, 1080, 1080, 33, 1080, 4320, 4320, 4320, 4320]
Prompts retrieved: 31485 . Total input tokens: 6963516 . Total output tokens: 6329556
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 1.236494000069797,
    "estimated_duration": 3599.23128883652,
    "input_throughput": 717.1384089724271,
    "output_throughput": 646.191037295586,
    "total_throughput": 1363.329446268013,
    "itl": 19.61281017021496,
    "ttft": 3089.436906171577,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 10598,
    "finished_requests": 10589,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2365745319984853. Arrivals time: 0.03929612273350358 Scheduler time: 0.7846096651628613 Scheduler overhead time: 0.15135568287223577 Adapter cache time: 0.031229231040924788 Engine time: 0.15279809851199389 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-16/adapters_16_slots_16_rate_0.4-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-16/adapters_16_slots_16_rate_0.4-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [5 5 6]
Adapter prompts. [1080, 33, 33, 1080, 4320, 33, 4320, 33, 1080, 1080, 33, 1080, 4320, 4320, 4320, 4320]
Prompts retrieved: 31485 . Total input tokens: 6963516 . Total output tokens: 6329556
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.229767546057701,
    "estimated_duration": 3599.2329728796926,
    "input_throughput": 717.138073430924,
    "output_throughput": 646.1907349496105,
    "total_throughput": 1363.3288083805346,
    "itl": 19.6128361213744,
    "ttft": 3089.475510476497,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 10598,
    "finished_requests": 10589,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2298442828468978. Arrivals time: 0.03941344656050205 Scheduler time: 0.786411196924746 Scheduler overhead time: 0.15032574394717813 Adapter cache time: 0.030857546254992485 Engine time: 0.14636606257408857 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-32/adapters_16_slots_16_rate_0.4-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-32/adapters_16_slots_16_rate_0.4-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [5 5 6]
Adapter prompts. [1080, 33, 33, 1080, 4320, 33, 4320, 33, 1080, 1080, 33, 1080, 4320, 4320, 4320, 4320]
Prompts retrieved: 31485 . Total input tokens: 6963516 . Total output tokens: 6329556
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.2566224047914147,
    "estimated_duration": 3599.2328785703316,
    "input_throughput": 717.1380922218264,
    "output_throughput": 646.190751881506,
    "total_throughput": 1363.3288441033324,
    "itl": 19.612836530625927,
    "ttft": 3089.470598574473,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.0524060240201652,
    "arrivals": 10598,
    "finished_requests": 10589,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2567037879489362. Arrivals time: 0.03927290253341198 Scheduler time: 0.79635010054335 Scheduler overhead time: 0.16075893631204963 Adapter cache time: 0.03146430430933833 Engine time: 0.15051430324092507 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-16/adapters_16_slots_16_rate_0.4-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-16/adapters_16_slots_16_rate_0.4-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [5 5 6]
Adapter prompts. [1080, 33, 33, 1080, 4320, 33, 4320, 33, 1080, 1080, 33, 1080, 4320, 4320, 4320, 4320]
Prompts retrieved: 31485 . Total input tokens: 6963516 . Total output tokens: 6329556
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 1.2564911022782326,
    "estimated_duration": 3599.232841389872,
    "input_throughput": 717.1380996299393,
    "output_throughput": 646.1907585567255,
    "total_throughput": 1363.328858186665,
    "itl": 19.61283646169538,
    "ttft": 3089.4545967141416,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 10598,
    "finished_requests": 10589,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2565957750193775. Arrivals time: 0.04047612752765417 Scheduler time: 0.8058069697581232 Scheduler overhead time: 0.15265401965007186 Adapter cache time: 0.030943712685257196 Engine time: 0.14935517124831676 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-32/adapters_16_slots_16_rate_0.4-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-32/adapters_16_slots_16_rate_0.4-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [5 5 6]
Adapter prompts. [1080, 33, 33, 1080, 4320, 33, 4320, 33, 1080, 1080, 33, 1080, 4320, 4320, 4320, 4320]
Prompts retrieved: 31485 . Total input tokens: 6963516 . Total output tokens: 6329556
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 1.240087870042771,
    "estimated_duration": 3599.2330093333967,
    "input_throughput": 717.1380661676156,
    "output_throughput": 646.19072840487,
    "total_throughput": 1363.3287945724858,
    "itl": 19.612822360445172,
    "ttft": 3089.477510462958,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05303479295223951,
    "arrivals": 10598,
    "finished_requests": 10589,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.240271985065192. Arrivals time: 0.04002285562455654 Scheduler time: 0.7920293039642274 Scheduler overhead time: 0.15069939335808158 Adapter cache time: 0.03153234580531716 Engine time: 0.14866832364350557 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-16/adapters_16_slots_16_rate_0.4-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-16/adapters_16_slots_16_rate_0.4-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [5 5 6]
Adapter prompts. [1080, 33, 33, 1080, 4320, 33, 4320, 33, 1080, 1080, 33, 1080, 4320, 4320, 4320, 4320]
Prompts retrieved: 31485 . Total input tokens: 6963516 . Total output tokens: 6329556
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 1.239143314305693,
    "estimated_duration": 3599.2328225229776,
    "input_throughput": 717.1381033891207,
    "output_throughput": 646.1907619440065,
    "total_throughput": 1363.3288653331272,
    "itl": 19.612818552856258,
    "ttft": 3089.439293296201,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 10598,
    "finished_requests": 10589,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2392459521070123. Arrivals time: 0.03950265282765031 Scheduler time: 0.7910021762363613 Scheduler overhead time: 0.1515789064578712 Adapter cache time: 0.031090914271771908 Engine time: 0.1486446801573038 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-32/adapters_16_slots_16_rate_0.4-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-32/adapters_16_slots_16_rate_0.4-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [5 5 6]
Adapter prompts. [1080, 33, 33, 1080, 4320, 33, 4320, 33, 1080, 1080, 33, 1080, 4320, 4320, 4320, 4320]
Prompts retrieved: 31485 . Total input tokens: 6963516 . Total output tokens: 6329556
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.2506748838350177,
    "estimated_duration": 3599.23300628549,
    "input_throughput": 717.1380667749035,
    "output_throughput": 646.1907289520781,
    "total_throughput": 1363.3287957269815,
    "itl": 19.612826205439823,
    "ttft": 3089.471466419704,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072868,
    "arrivals": 10598,
    "finished_requests": 10589,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2507736259140074. Arrivals time: 0.03897355264052749 Scheduler time: 0.7929207910783589 Scheduler overhead time: 0.15996196353808045 Adapter cache time: 0.031406115274876356 Engine time: 0.14888265682384372 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-8/adapters_16_slots_16_rate_0.4-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-8/adapters_16_slots_16_rate_0.4-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [5 5 6]
Adapter prompts. [540, 270, 270, 540, 4320, 270, 4320, 270, 540, 540, 270, 540, 4320, 4320, 4320, 4320]
Prompts retrieved: 29970 . Total input tokens: 6616954 . Total output tokens: 6023719
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 1.219064223114401,
    "estimated_duration": 3599.2733574519402,
    "input_throughput": 684.5920704795764,
    "output_throughput": 614.8460481386344,
    "total_throughput": 1299.4381186182109,
    "itl": 19.512231493962283,
    "ttft": 2535.373774703844,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 10066,
    "finished_requests": 10059,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.219164818059653. Arrivals time: 0.03845557011663914 Scheduler time: 0.7696164892986417 Scheduler overhead time: 0.1522714509628713 Adapter cache time: 0.031131724826991558 Engine time: 0.15055999252945185 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-16/adapters_16_slots_16_rate_0.4-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-16/adapters_16_slots_16_rate_0.4-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [5 5 6]
Adapter prompts. [540, 270, 270, 540, 4320, 270, 4320, 270, 540, 540, 270, 540, 4320, 4320, 4320, 4320]
Prompts retrieved: 29970 . Total input tokens: 6616954 . Total output tokens: 6023719
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.199893840122968,
    "estimated_duration": 3599.278106618281,
    "input_throughput": 684.5911671757688,
    "output_throughput": 614.8452368631314,
    "total_throughput": 1299.4364040389,
    "itl": 19.512214677297735,
    "ttft": 2535.6704558797733,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 10066,
    "finished_requests": 10059,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1999918092042208. Arrivals time: 0.037873812951147556 Scheduler time: 0.752798028755933 Scheduler overhead time: 0.1523433830589056 Adapter cache time: 0.031068154610693455 Engine time: 0.14860835997387767 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-32/adapters_16_slots_16_rate_0.4-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-32/adapters_16_slots_16_rate_0.4-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [5 5 6]
Adapter prompts. [540, 270, 270, 540, 4320, 270, 4320, 270, 540, 540, 270, 540, 4320, 4320, 4320, 4320]
Prompts retrieved: 29970 . Total input tokens: 6616954 . Total output tokens: 6023719
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.2040147073566914,
    "estimated_duration": 3599.2781732058133,
    "input_throughput": 684.5911545106636,
    "output_throughput": 614.8452254883431,
    "total_throughput": 1299.4363799990067,
    "itl": 19.51219133820617,
    "ttft": 2535.6846681292577,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.052406024020165184,
    "arrivals": 10066,
    "finished_requests": 10059,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.204405918251723. Arrivals time: 0.038153143133968115 Scheduler time: 0.7561853397637606 Scheduler overhead time: 0.1528048967011273 Adapter cache time: 0.031126301735639572 Engine time: 0.1482627489604056 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-16/adapters_16_slots_16_rate_0.4-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-16/adapters_16_slots_16_rate_0.4-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [5 5 6]
Adapter prompts. [540, 270, 270, 540, 4320, 270, 4320, 270, 540, 540, 270, 540, 4320, 4320, 4320, 4320]
Prompts retrieved: 29970 . Total input tokens: 6616954 . Total output tokens: 6023719
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 1.2220701351761818,
    "estimated_duration": 3599.274215040814,
    "input_throughput": 684.5919073637625,
    "output_throughput": 614.8459016410078,
    "total_throughput": 1299.4378090047703,
    "itl": 19.512198915217468,
    "ttft": 2535.405272832956,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 10066,
    "finished_requests": 10059,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.222201604861766. Arrivals time: 0.03837348008528352 Scheduler time: 0.763337800744921 Scheduler overhead time: 0.16062025353312492 Adapter cache time: 0.03144805924966931 Engine time: 0.14932263595983386 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-32/adapters_16_slots_16_rate_0.4-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-32/adapters_16_slots_16_rate_0.4-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [5 5 6]
Adapter prompts. [540, 270, 270, 540, 4320, 270, 4320, 270, 540, 540, 270, 540, 4320, 4320, 4320, 4320]
Prompts retrieved: 29970 . Total input tokens: 6616954 . Total output tokens: 6023719
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 1.2129712398163974,
    "estimated_duration": 3599.277705634813,
    "input_throughput": 684.5912434437765,
    "output_throughput": 614.8453053609788,
    "total_throughput": 1299.4365488047554,
    "itl": 19.512229549433783,
    "ttft": 2535.6699190592535,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.0530347929522395,
    "arrivals": 10066,
    "finished_requests": 10059,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2130593131296337. Arrivals time: 0.038645724300295115 Scheduler time: 0.762920799665153 Scheduler overhead time: 0.15201638592407107 Adapter cache time: 0.03135168878361583 Engine time: 0.1503686443902552 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-16/adapters_16_slots_16_rate_0.4-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-16/adapters_16_slots_16_rate_0.4-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [5 5 6]
Adapter prompts. [540, 270, 270, 540, 4320, 270, 4320, 270, 540, 540, 270, 540, 4320, 4320, 4320, 4320]
Prompts retrieved: 29970 . Total input tokens: 6616954 . Total output tokens: 6023719
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 1.2141607478260994,
    "estimated_duration": 3599.270734433413,
    "input_throughput": 684.5925693855539,
    "output_throughput": 614.8464962162298,
    "total_throughput": 1299.4390656017838,
    "itl": 19.512195280338897,
    "ttft": 2535.4341091044394,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 10066,
    "finished_requests": 10059,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2142599849030375. Arrivals time: 0.03756072884425521 Scheduler time: 0.7680311957374215 Scheduler overhead time: 0.1525511764921248 Adapter cache time: 0.031146672554314137 Engine time: 0.14738360233604908 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-32/adapters_16_slots_16_rate_0.4-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-32/adapters_16_slots_16_rate_0.4-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [5 5 6]
Adapter prompts. [540, 270, 270, 540, 4320, 270, 4320, 270, 540, 540, 270, 540, 4320, 4320, 4320, 4320]
Prompts retrieved: 29970 . Total input tokens: 6616954 . Total output tokens: 6023719
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.2088163178414106,
    "estimated_duration": 3599.2779034127075,
    "input_throughput": 684.5912058259493,
    "output_throughput": 614.8452715756438,
    "total_throughput": 1299.436477401593,
    "itl": 19.512226483631228,
    "ttft": 2535.6730016729234,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072867,
    "arrivals": 10066,
    "finished_requests": 10059,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.208896964788437. Arrivals time: 0.03841696726158261 Scheduler time: 0.7568675610236824 Scheduler overhead time: 0.15238032583147287 Adapter cache time: 0.031395595986396074 Engine time: 0.15194866992533207 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-8/adapters_16_slots_16_rate_0.4-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-8/adapters_16_slots_16_rate_0.4-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [5 5 6]
Adapter prompts. [540, 135, 135, 540, 4320, 135, 4320, 135, 540, 540, 135, 540, 4320, 4320, 4320, 4320]
Prompts retrieved: 29295 . Total input tokens: 6472927 . Total output tokens: 5885876
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 1.195996338967234,
    "estimated_duration": 3599.8990719612652,
    "input_throughput": 669.6023837931467,
    "output_throughput": 609.4295857035645,
    "total_throughput": 1279.0319694967113,
    "itl": 19.454237651509573,
    "ttft": 2950.4279161875525,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 9868,
    "finished_requests": 9860,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1960999029688537. Arrivals time: 0.03732769610360265 Scheduler time: 0.7504613199271262 Scheduler overhead time: 0.15281554032117128 Adapter cache time: 0.02999914437532425 Engine time: 0.14794303104281425 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-16/adapters_16_slots_16_rate_0.4-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-16/adapters_16_slots_16_rate_0.4-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [5 5 6]
Adapter prompts. [540, 135, 135, 540, 4320, 135, 4320, 135, 540, 540, 135, 540, 4320, 4320, 4320, 4320]
Prompts retrieved: 29295 . Total input tokens: 6472927 . Total output tokens: 5885876
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.194705419242382,
    "estimated_duration": 3599.8955999424247,
    "input_throughput": 669.6030296096789,
    "output_throughput": 609.4301734847778,
    "total_throughput": 1279.0332030944567,
    "itl": 19.472094875570402,
    "ttft": 2950.4818560522162,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 9868,
    "finished_requests": 9860,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.194807433988899. Arrivals time: 0.037485053297132254 Scheduler time: 0.7481439635157585 Scheduler overhead time: 0.15281040640547872 Adapter cache time: 0.029578628949820995 Engine time: 0.14879174577072263 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-32/adapters_16_slots_16_rate_0.4-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-32/adapters_16_slots_16_rate_0.4-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [5 5 6]
Adapter prompts. [540, 135, 135, 540, 4320, 135, 4320, 135, 540, 540, 135, 540, 4320, 4320, 4320, 4320]
Prompts retrieved: 29295 . Total input tokens: 6472927 . Total output tokens: 5885876
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.2081081331707537,
    "estimated_duration": 3599.8956755131403,
    "input_throughput": 669.6030155530548,
    "output_throughput": 609.4301606913308,
    "total_throughput": 1279.0331762443857,
    "itl": 19.47207768535046,
    "ttft": 2950.480645364539,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 9868,
    "finished_requests": 9860,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2082728031091392. Arrivals time: 0.03715274203568697 Scheduler time: 0.7555224345996976 Scheduler overhead time: 0.15674768341705203 Adapter cache time: 0.02988902758806944 Engine time: 0.15070707025006413 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-16/adapters_16_slots_16_rate_0.4-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-16/adapters_16_slots_16_rate_0.4-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [5 5 6]
Adapter prompts. [540, 135, 135, 540, 4320, 135, 4320, 135, 540, 540, 135, 540, 4320, 4320, 4320, 4320]
Prompts retrieved: 29295 . Total input tokens: 6472927 . Total output tokens: 5885876
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 1.2111329520121217,
    "estimated_duration": 3599.9052460887287,
    "input_throughput": 669.6012353711232,
    "output_throughput": 609.4285404827364,
    "total_throughput": 1279.0297758538595,
    "itl": 19.454230479834006,
    "ttft": 2950.535930057228,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 9868,
    "finished_requests": 9860,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.21122902398929. Arrivals time: 0.03776576975360513 Scheduler time: 0.7541123698465526 Scheduler overhead time: 0.16036914568394423 Adapter cache time: 0.030404641292989254 Engine time: 0.14983393298462033 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-32/adapters_16_slots_16_rate_0.4-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-32/adapters_16_slots_16_rate_0.4-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [5 5 6]
Adapter prompts. [540, 135, 135, 540, 4320, 135, 4320, 135, 540, 540, 135, 540, 4320, 4320, 4320, 4320]
Prompts retrieved: 29295 . Total input tokens: 6472927 . Total output tokens: 5885876
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 1.2112161093391478,
    "estimated_duration": 3599.8981663591594,
    "input_throughput": 669.602552240503,
    "output_throughput": 609.4297390136556,
    "total_throughput": 1279.0322912541587,
    "itl": 19.47209399862493,
    "ttft": 2950.4577718956275,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.0530347929522395,
    "arrivals": 9868,
    "finished_requests": 9860,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2113125533796847. Arrivals time: 0.03770151734352112 Scheduler time: 0.7530303229577839 Scheduler overhead time: 0.1601541554555297 Adapter cache time: 0.030251136049628258 Engine time: 0.1513312514871359 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-16/adapters_16_slots_16_rate_0.4-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-16/adapters_16_slots_16_rate_0.4-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [5 5 6]
Adapter prompts. [540, 135, 135, 540, 4320, 135, 4320, 135, 540, 540, 135, 540, 4320, 4320, 4320, 4320]
Prompts retrieved: 29295 . Total input tokens: 6472927 . Total output tokens: 5885876
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 1.1990228309296072,
    "estimated_duration": 3599.898316736394,
    "input_throughput": 669.6025242694407,
    "output_throughput": 609.4297135561702,
    "total_throughput": 1279.032237825611,
    "itl": 19.45418080404053,
    "ttft": 2950.5157077108133,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 9868,
    "finished_requests": 9860,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.199109278153628. Arrivals time: 0.03738615242764354 Scheduler time: 0.7509528817608953 Scheduler overhead time: 0.1523927766829729 Adapter cache time: 0.03018871322274208 Engine time: 0.14979963144287467 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-32/adapters_16_slots_16_rate_0.4-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-32/adapters_16_slots_16_rate_0.4-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [5 5 6]
Adapter prompts. [540, 135, 135, 540, 4320, 135, 4320, 135, 540, 540, 135, 540, 4320, 4320, 4320, 4320]
Prompts retrieved: 29295 . Total input tokens: 6472927 . Total output tokens: 5885876
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.2111656749621034,
    "estimated_duration": 3599.8981347283916,
    "input_throughput": 669.6025581240148,
    "output_throughput": 609.4297443684545,
    "total_throughput": 1279.0323024924692,
    "itl": 19.472089334536495,
    "ttft": 2950.4451360764497,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072868,
    "arrivals": 9868,
    "finished_requests": 9860,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2112496150657535. Arrivals time: 0.03796001058071852 Scheduler time: 0.7592728519812226 Scheduler overhead time: 0.15360745228827 Adapter cache time: 0.03029368259012699 Engine time: 0.151457279920578 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-8/adapters_16_slots_16_rate_0.4-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-8/adapters_16_slots_16_rate_0.4-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [5 5 6]
Adapter prompts. [540, 66, 66, 540, 4320, 66, 4320, 66, 540, 540, 66, 540, 4320, 4320, 4320, 4320]
Prompts retrieved: 28950 . Total input tokens: 6396325 . Total output tokens: 5819215
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 1.1949874400161207,
    "estimated_duration": 3599.757977290643,
    "input_throughput": 669.6805771965825,
    "output_throughput": 588.1609300838436,
    "total_throughput": 1257.841507280426,
    "itl": 19.160619781407593,
    "ttft": 3347.7788533777525,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 9771,
    "finished_requests": 9762,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1950659099966288. Arrivals time: 0.037482794374227524 Scheduler time: 0.7280767345800996 Scheduler overhead time: 0.16733728582039475 Adapter cache time: 0.03174325730651617 Engine time: 0.15091074258089066 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-16/adapters_16_slots_16_rate_0.4-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-16/adapters_16_slots_16_rate_0.4-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [5 5 6]
Adapter prompts. [540, 66, 66, 540, 4320, 66, 4320, 66, 540, 540, 66, 540, 4320, 4320, 4320, 4320]
Prompts retrieved: 28950 . Total input tokens: 6396325 . Total output tokens: 5819215
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.179952329955995,
    "estimated_duration": 3599.7605669210197,
    "input_throughput": 669.6800954353283,
    "output_throughput": 588.1605069669771,
    "total_throughput": 1257.8406024023054,
    "itl": 19.16063202688526,
    "ttft": 3347.7563268910058,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 9771,
    "finished_requests": 9762,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.18005402199924. Arrivals time: 0.0365616069175303 Scheduler time: 0.7315489994361997 Scheduler overhead time: 0.1537301680073142 Adapter cache time: 0.029930737800896168 Engine time: 0.15022477880120277 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-32/adapters_16_slots_16_rate_0.4-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-32/adapters_16_slots_16_rate_0.4-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [5 5 6]
Adapter prompts. [540, 66, 66, 540, 4320, 66, 4320, 66, 540, 540, 66, 540, 4320, 4320, 4320, 4320]
Prompts retrieved: 28950 . Total input tokens: 6396325 . Total output tokens: 5819215
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.171378277707845,
    "estimated_duration": 3599.7604481991634,
    "input_throughput": 669.6801175217047,
    "output_throughput": 588.1605263647976,
    "total_throughput": 1257.8406438865024,
    "itl": 19.16060412035538,
    "ttft": 3347.77648059794,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 9771,
    "finished_requests": 9762,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.171479661948979. Arrivals time: 0.03679396025836468 Scheduler time: 0.7254085526801646 Scheduler overhead time: 0.15199559228494763 Adapter cache time: 0.029838101472705603 Engine time: 0.14952250430360436 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-16/adapters_16_slots_16_rate_0.4-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-16/adapters_16_slots_16_rate_0.4-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [5 5 6]
Adapter prompts. [540, 66, 66, 540, 4320, 66, 4320, 66, 540, 540, 66, 540, 4320, 4320, 4320, 4320]
Prompts retrieved: 28950 . Total input tokens: 6396325 . Total output tokens: 5819215
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 1.1740920902229846,
    "estimated_duration": 3599.7605100819187,
    "input_throughput": 669.6801060093691,
    "output_throughput": 588.160516253849,
    "total_throughput": 1257.8406222632182,
    "itl": 19.16059698698199,
    "ttft": 3347.7896020668336,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 9771,
    "finished_requests": 9762,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.17419469403103. Arrivals time: 0.0364510896615684 Scheduler time: 0.7277818038128316 Scheduler overhead time: 0.15214832313358784 Adapter cache time: 0.030196961481124163 Engine time: 0.1493899328634143 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-32/adapters_16_slots_16_rate_0.4-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-32/adapters_16_slots_16_rate_0.4-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [5 5 6]
Adapter prompts. [540, 66, 66, 540, 4320, 66, 4320, 66, 540, 540, 66, 540, 4320, 4320, 4320, 4320]
Prompts retrieved: 28950 . Total input tokens: 6396325 . Total output tokens: 5819215
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 1.1792871681973338,
    "estimated_duration": 3599.7604834738786,
    "input_throughput": 669.680110959386,
    "output_throughput": 588.1605206013045,
    "total_throughput": 1257.8406315606906,
    "itl": 19.16058278699258,
    "ttft": 3347.7633822381135,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05303479295223951,
    "arrivals": 9771,
    "finished_requests": 9762,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.179386688861996. Arrivals time: 0.03699004417285323 Scheduler time: 0.7306769909337163 Scheduler overhead time: 0.15370684256777167 Adapter cache time: 0.02999510010704398 Engine time: 0.15001615602523088 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-16/adapters_16_slots_16_rate_0.4-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-16/adapters_16_slots_16_rate_0.4-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [5 5 6]
Adapter prompts. [540, 66, 66, 540, 4320, 66, 4320, 66, 540, 540, 66, 540, 4320, 4320, 4320, 4320]
Prompts retrieved: 28950 . Total input tokens: 6396325 . Total output tokens: 5819215
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 1.1743548288941383,
    "estimated_duration": 3599.7552094565003,
    "input_throughput": 669.681092110697,
    "output_throughput": 588.1613823179009,
    "total_throughput": 1257.8424744285978,
    "itl": 19.1606456125285,
    "ttft": 3347.7429943734387,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 9771,
    "finished_requests": 9762,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.174533215817064. Arrivals time: 0.0368552808649838 Scheduler time: 0.7266369364224374 Scheduler overhead time: 0.15321723697707057 Adapter cache time: 0.029848343692719936 Engine time: 0.14968370646238327 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-32/adapters_16_slots_16_rate_0.4-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-32/adapters_16_slots_16_rate_0.4-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [5 5 6]
Adapter prompts. [540, 66, 66, 540, 4320, 66, 4320, 66, 540, 540, 66, 540, 4320, 4320, 4320, 4320]
Prompts retrieved: 28950 . Total input tokens: 6396325 . Total output tokens: 5819215
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.1887133601121604,
    "estimated_duration": 3599.7629743799725,
    "input_throughput": 669.6796475649122,
    "output_throughput": 588.1601136154459,
    "total_throughput": 1257.839761180358,
    "itl": 19.16063855953115,
    "ttft": 3347.7567097732644,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072868,
    "arrivals": 9771,
    "finished_requests": 9762,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.188842938747257. Arrivals time: 0.036768838763237 Scheduler time: 0.7341711344197392 Scheduler overhead time: 0.15884914295747876 Adapter cache time: 0.030013578478246927 Engine time: 0.15029591461643577 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-8/adapters_16_slots_16_rate_0.4-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-8/adapters_16_slots_16_rate_0.4-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [5 5 6]
Adapter prompts. [540, 33, 33, 540, 4320, 33, 4320, 33, 540, 540, 33, 540, 4320, 4320, 4320, 4320]
Prompts retrieved: 28785 . Total input tokens: 6361921 . Total output tokens: 5788698
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 1.17850106023252,
    "estimated_duration": 3599.6285536567966,
    "input_throughput": 658.6243454457391,
    "output_throughput": 597.4610902047675,
    "total_throughput": 1256.0854356505065,
    "itl": 19.357767338490223,
    "ttft": 2253.5508196217006,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 9722,
    "finished_requests": 9716,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1785839470103383. Arrivals time: 0.037082412745803595 Scheduler time: 0.7329256180673838 Scheduler overhead time: 0.15233720373362303 Adapter cache time: 0.02955058543011546 Engine time: 0.14877669280394912 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-16/adapters_16_slots_16_rate_0.4-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-16/adapters_16_slots_16_rate_0.4-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [5 5 6]
Adapter prompts. [540, 33, 33, 540, 4320, 33, 4320, 33, 540, 540, 33, 540, 4320, 4320, 4320, 4320]
Prompts retrieved: 28785 . Total input tokens: 6361921 . Total output tokens: 5788698
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.1823316542431712,
    "estimated_duration": 3599.6364491412864,
    "input_throughput": 658.6229008114329,
    "output_throughput": 597.4597797266573,
    "total_throughput": 1256.0826805380902,
    "itl": 19.35779278949609,
    "ttft": 2253.630796706032,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 9722,
    "finished_requests": 9716,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1824124460108578. Arrivals time: 0.03675317717716098 Scheduler time: 0.7352270679548383 Scheduler overhead time: 0.15164961433038116 Adapter cache time: 0.02954682568088174 Engine time: 0.15088201593607664 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-32/adapters_16_slots_16_rate_0.4-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-32/adapters_16_slots_16_rate_0.4-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [5 5 6]
Adapter prompts. [540, 33, 33, 540, 4320, 33, 4320, 33, 540, 540, 33, 540, 4320, 4320, 4320, 4320]
Prompts retrieved: 28785 . Total input tokens: 6361921 . Total output tokens: 5788698
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.183094086125493,
    "estimated_duration": 3599.6365630947034,
    "input_throughput": 658.6228799614586,
    "output_throughput": 597.4597608129192,
    "total_throughput": 1256.0826407743778,
    "itl": 19.357789311869677,
    "ttft": 2253.610291427156,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 9722,
    "finished_requests": 9716,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1832546410150826. Arrivals time: 0.036564966663718224 Scheduler time: 0.7358587048947811 Scheduler overhead time: 0.15316849015653133 Adapter cache time: 0.02973370859399438 Engine time: 0.14985227538272738 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-16/adapters_16_slots_16_rate_0.4-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-16/adapters_16_slots_16_rate_0.4-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [5 5 6]
Adapter prompts. [540, 33, 33, 540, 4320, 33, 4320, 33, 540, 540, 33, 540, 4320, 4320, 4320, 4320]
Prompts retrieved: 28785 . Total input tokens: 6361921 . Total output tokens: 5788698
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 1.183028760831803,
    "estimated_duration": 3599.6291647581747,
    "input_throughput": 658.6242336324864,
    "output_throughput": 597.4609887750704,
    "total_throughput": 1256.0852224075568,
    "itl": 19.357744203969485,
    "ttft": 2253.5045302864028,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 9722,
    "finished_requests": 9716,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1831263690255582. Arrivals time: 0.036951170302927494 Scheduler time: 0.7358012376353145 Scheduler overhead time: 0.15174047695472836 Adapter cache time: 0.02991211088374257 Engine time: 0.15062995674088597 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-32/adapters_16_slots_16_rate_0.4-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-32/adapters_16_slots_16_rate_0.4-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [5 5 6]
Adapter prompts. [540, 33, 33, 540, 4320, 33, 4320, 33, 540, 540, 33, 540, 4320, 4320, 4320, 4320]
Prompts retrieved: 28785 . Total input tokens: 6361921 . Total output tokens: 5788698
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 1.1863858830183744,
    "estimated_duration": 3599.636654718488,
    "input_throughput": 658.6228631971219,
    "output_throughput": 597.4597456054053,
    "total_throughput": 1256.0826088025271,
    "itl": 19.35778378077028,
    "ttft": 2253.613764616695,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05303479295223951,
    "arrivals": 9722,
    "finished_requests": 9716,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1864873450249434. Arrivals time: 0.03673610324040055 Scheduler time: 0.7386822402477264 Scheduler overhead time: 0.15250245900824666 Adapter cache time: 0.029905986040830612 Engine time: 0.15035452600568533 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-16/adapters_16_slots_16_rate_0.4-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-16/adapters_16_slots_16_rate_0.4-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [5 5 6]
Adapter prompts. [540, 33, 33, 540, 4320, 33, 4320, 33, 540, 540, 33, 540, 4320, 4320, 4320, 4320]
Prompts retrieved: 28785 . Total input tokens: 6361921 . Total output tokens: 5788698
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 1.1866450011730194,
    "estimated_duration": 3599.6267221014346,
    "input_throughput": 658.6246805657514,
    "output_throughput": 597.4613942038062,
    "total_throughput": 1256.0860747695576,
    "itl": 19.35768557443641,
    "ttft": 2253.5629347377712,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 9722,
    "finished_requests": 9716,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1867352952249348. Arrivals time: 0.03688159538432956 Scheduler time: 0.7392057282850146 Scheduler overhead time: 0.1527168550528586 Adapter cache time: 0.029807085171341896 Engine time: 0.149444033857435 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-32/adapters_16_slots_16_rate_0.4-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-32/adapters_16_slots_16_rate_0.4-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [5 5 6]
Adapter prompts. [540, 33, 33, 540, 4320, 33, 4320, 33, 540, 540, 33, 540, 4320, 4320, 4320, 4320]
Prompts retrieved: 28785 . Total input tokens: 6361921 . Total output tokens: 5788698
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.184908420778811,
    "estimated_duration": 3599.6366459540086,
    "input_throughput": 658.6228648007522,
    "output_throughput": 597.4597470601143,
    "total_throughput": 1256.0826118608663,
    "itl": 19.357785929284578,
    "ttft": 2253.6219170873787,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072868,
    "arrivals": 9722,
    "finished_requests": 9716,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.18498949194327. Arrivals time: 0.03727137064561248 Scheduler time: 0.7365003838203847 Scheduler overhead time: 0.1527125840075314 Adapter cache time: 0.029657777398824692 Engine time: 0.15056932717561722 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-8/adapters_16_slots_16_rate_0.4-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-8/adapters_16_slots_16_rate_0.4-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [5 5 6]
Adapter prompts. [270, 135, 135, 270, 4320, 135, 4320, 135, 270, 270, 135, 270, 4320, 4320, 4320, 4320]
Prompts retrieved: 27945 . Total input tokens: 6176792 . Total output tokens: 5618647
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 1.1577319470234215,
    "estimated_duration": 3599.283996781887,
    "input_throughput": 638.5369984849443,
    "output_throughput": 565.0515496466519,
    "total_throughput": 1203.5885481315963,
    "itl": 19.2457513556099,
    "ttft": 6134.527023877256,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 9438,
    "finished_requests": 9422,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1578197567723691. Arrivals time: 0.036038100719451904 Scheduler time: 0.7092069792561233 Scheduler overhead time: 0.15308829862624407 Adapter cache time: 0.02970783831551671 Engine time: 0.15064387023448944 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-16/adapters_16_slots_16_rate_0.4-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-16/adapters_16_slots_16_rate_0.4-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [5 5 6]
Adapter prompts. [270, 135, 135, 270, 4320, 135, 4320, 135, 270, 270, 135, 270, 4320, 4320, 4320, 4320]
Prompts retrieved: 27945 . Total input tokens: 6176792 . Total output tokens: 5618647
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.161867715884,
    "estimated_duration": 3599.2889460962724,
    "input_throughput": 638.5361204447537,
    "output_throughput": 565.0507726549168,
    "total_throughput": 1203.5868930996705,
    "itl": 19.245851471275216,
    "ttft": 6134.571450715868,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 9438,
    "finished_requests": 9422,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1619508620351553. Arrivals time: 0.03604720579460263 Scheduler time: 0.7122996374964714 Scheduler overhead time: 0.15356586454436183 Adapter cache time: 0.029601440764963627 Engine time: 0.1518745431676507 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-32/adapters_16_slots_16_rate_0.4-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-32/adapters_16_slots_16_rate_0.4-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [5 5 6]
Adapter prompts. [270, 135, 135, 270, 4320, 135, 4320, 135, 270, 270, 135, 270, 4320, 4320, 4320, 4320]
Prompts retrieved: 27945 . Total input tokens: 6176792 . Total output tokens: 5618647
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.1673398278653622,
    "estimated_duration": 3599.288822474494,
    "input_throughput": 638.5361423760226,
    "output_throughput": 565.0507920622456,
    "total_throughput": 1203.5869344382681,
    "itl": 19.24582976924054,
    "ttft": 6134.586620932561,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 9438,
    "finished_requests": 9422,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1674165520817041. Arrivals time: 0.03606478776782751 Scheduler time: 0.7105731684714556 Scheduler overhead time: 0.1599867856130004 Adapter cache time: 0.029753827955573797 Engine time: 0.15178839629516006 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-16/adapters_16_slots_16_rate_0.4-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-16/adapters_16_slots_16_rate_0.4-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [5 5 6]
Adapter prompts. [270, 135, 135, 270, 4320, 135, 4320, 135, 270, 270, 135, 270, 4320, 4320, 4320, 4320]
Prompts retrieved: 27945 . Total input tokens: 6176792 . Total output tokens: 5618647
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 1.1568809328600764,
    "estimated_duration": 3599.28898153898,
    "input_throughput": 638.5361141569982,
    "output_throughput": 565.050767090782,
    "total_throughput": 1203.5868812477802,
    "itl": 19.24582179708871,
    "ttft": 6134.46436006987,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 9438,
    "finished_requests": 9422,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.156997222919017. Arrivals time: 0.03577503329142928 Scheduler time: 0.708560211583972 Scheduler overhead time: 0.15439069690182805 Adapter cache time: 0.029431840404868126 Engine time: 0.1502163214609027 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-32/adapters_16_slots_16_rate_0.4-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-32/adapters_16_slots_16_rate_0.4-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [5 5 6]
Adapter prompts. [270, 135, 135, 270, 4320, 135, 4320, 135, 270, 270, 135, 270, 4320, 4320, 4320, 4320]
Prompts retrieved: 27945 . Total input tokens: 6176792 . Total output tokens: 5618647
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 1.1539412382990122,
    "estimated_duration": 3599.2888961319086,
    "input_throughput": 638.536129308741,
    "output_throughput": 565.0507804988002,
    "total_throughput": 1203.5869098075411,
    "itl": 19.245845890507617,
    "ttft": 6134.583037829473,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.0530347929522395,
    "arrivals": 9438,
    "finished_requests": 9422,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.15404410706833. Arrivals time: 0.03643323900178075 Scheduler time: 0.70594667410478 Scheduler overhead time: 0.15325560281053185 Adapter cache time: 0.0296981749124825 Engine time: 0.15026037395000458 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-16/adapters_16_slots_16_rate_0.4-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-16/adapters_16_slots_16_rate_0.4-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [5 5 6]
Adapter prompts. [270, 135, 135, 270, 4320, 135, 4320, 135, 270, 270, 135, 270, 4320, 4320, 4320, 4320]
Prompts retrieved: 27945 . Total input tokens: 6176792 . Total output tokens: 5618647
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 1.1491242940537632,
    "estimated_duration": 3599.2830730584537,
    "input_throughput": 638.5371623596873,
    "output_throughput": 565.0516946620194,
    "total_throughput": 1203.5888570217066,
    "itl": 19.24581600607067,
    "ttft": 6134.594787271816,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 9438,
    "finished_requests": 9422,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1492138551548123. Arrivals time: 0.03585889283567667 Scheduler time: 0.70376101648435 Scheduler overhead time: 0.15289244335144758 Adapter cache time: 0.029575205873697996 Engine time: 0.14874662971124053 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-32/adapters_16_slots_16_rate_0.4-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-32/adapters_16_slots_16_rate_0.4-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [5 5 6]
Adapter prompts. [270, 135, 135, 270, 4320, 135, 4320, 135, 270, 270, 135, 270, 4320, 4320, 4320, 4320]
Prompts retrieved: 27945 . Total input tokens: 6176792 . Total output tokens: 5618647
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.1526876669377089,
    "estimated_duration": 3599.2745302303256,
    "input_throughput": 638.5386779187772,
    "output_throughput": 565.0530358043719,
    "total_throughput": 1203.591713723149,
    "itl": 19.245887459903823,
    "ttft": 6134.720803381218,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072867,
    "arrivals": 9438,
    "finished_requests": 9422,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1527691772207618. Arrivals time: 0.03573031397536397 Scheduler time: 0.7067979881539941 Scheduler overhead time: 0.15290770027786493 Adapter cache time: 0.029618844389915466 Engine time: 0.14923747163265944 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_16_slots_16_rate_0.4-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_16_slots_16_rate_0.4-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [5 5 6]
Adapter prompts. [270, 66, 66, 270, 4320, 66, 4320, 66, 270, 270, 66, 270, 4320, 4320, 4320, 4320]
Prompts retrieved: 27600 . Total input tokens: 6104713 . Total output tokens: 5548111
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 1.1527034207247198,
    "estimated_duration": 3599.5533334111556,
    "input_throughput": 640.7558900688052,
    "output_throughput": 559.0235269810779,
    "total_throughput": 1199.7794170498833,
    "itl": 19.046002494137227,
    "ttft": 3512.6828471959575,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 9307,
    "finished_requests": 9298,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1528020487166941. Arrivals time: 0.03624390717595816 Scheduler time: 0.7049556411802769 Scheduler overhead time: 0.15450847474858165 Adapter cache time: 0.029425985645502806 Engine time: 0.1492939628660679 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_16_slots_16_rate_0.4-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_16_slots_16_rate_0.4-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [5 5 6]
Adapter prompts. [270, 66, 66, 270, 4320, 66, 4320, 66, 270, 270, 66, 270, 4320, 4320, 4320, 4320]
Prompts retrieved: 27600 . Total input tokens: 6104713 . Total output tokens: 5548111
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.1427900940179825,
    "estimated_duration": 3599.550776012996,
    "input_throughput": 640.7563453111497,
    "output_throughput": 559.0239241544554,
    "total_throughput": 1199.780269465605,
    "itl": 19.076369117782832,
    "ttft": 3512.7927920962293,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 9307,
    "finished_requests": 9298,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1428933460265398. Arrivals time: 0.0360000585205853 Scheduler time: 0.6988447727635503 Scheduler overhead time: 0.1525931074284017 Adapter cache time: 0.028693247586488724 Engine time: 0.14871698571369052 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-32/adapters_16_slots_16_rate_0.4-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-32/adapters_16_slots_16_rate_0.4-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [5 5 6]
Adapter prompts. [270, 66, 66, 270, 4320, 66, 4320, 66, 270, 270, 66, 270, 4320, 4320, 4320, 4320]
Prompts retrieved: 27600 . Total input tokens: 6104713 . Total output tokens: 5548111
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.1527938349172473,
    "estimated_duration": 3599.5497355760926,
    "input_throughput": 640.7565305194664,
    "output_throughput": 559.0240857383099,
    "total_throughput": 1199.7806162577763,
    "itl": 19.076371021022783,
    "ttft": 3512.783361008318,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 9307,
    "finished_requests": 9298,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1528948061168194. Arrivals time: 0.036395876202732325 Scheduler time: 0.7068848786875606 Scheduler overhead time: 0.1536496365442872 Adapter cache time: 0.028878324199467897 Engine time: 0.14912947919219732 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_16_slots_16_rate_0.4-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_16_slots_16_rate_0.4-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [5 5 6]
Adapter prompts. [270, 66, 66, 270, 4320, 66, 4320, 66, 270, 270, 66, 270, 4320, 4320, 4320, 4320]
Prompts retrieved: 27600 . Total input tokens: 6104713 . Total output tokens: 5548111
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 1.1445407578721642,
    "estimated_duration": 3599.5533698013337,
    "input_throughput": 640.7558835909958,
    "output_throughput": 559.023521329553,
    "total_throughput": 1199.7794049205488,
    "itl": 19.04602210229071,
    "ttft": 3512.6847163891716,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 9307,
    "finished_requests": 9298,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1446444089524448. Arrivals time: 0.03595467051491141 Scheduler time: 0.6980034993030131 Scheduler overhead time: 0.15343567868694663 Adapter cache time: 0.029399139806628227 Engine time: 0.14935944136232138 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-32/adapters_16_slots_16_rate_0.4-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-32/adapters_16_slots_16_rate_0.4-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [5 5 6]
Adapter prompts. [270, 66, 66, 270, 4320, 66, 4320, 66, 270, 270, 66, 270, 4320, 4320, 4320, 4320]
Prompts retrieved: 27600 . Total input tokens: 6104713 . Total output tokens: 5548111
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 1.1586579317227006,
    "estimated_duration": 3599.5507374817776,
    "input_throughput": 640.7563521700953,
    "output_throughput": 559.0239301385002,
    "total_throughput": 1199.7802823085954,
    "itl": 19.076383034510652,
    "ttft": 3512.7847857676775,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.0530347929522395,
    "arrivals": 9307,
    "finished_requests": 9298,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1587394047528505. Arrivals time: 0.03596831765025854 Scheduler time: 0.7031376496888697 Scheduler overhead time: 0.16129144048318267 Adapter cache time: 0.029115093406289816 Engine time: 0.14960456965491176 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_16_slots_16_rate_0.4-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_16_slots_16_rate_0.4-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [5 5 6]
Adapter prompts. [270, 66, 66, 270, 4320, 66, 4320, 66, 270, 270, 66, 270, 4320, 4320, 4320, 4320]
Prompts retrieved: 27600 . Total input tokens: 6104713 . Total output tokens: 5548111
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 1.1546553247608244,
    "estimated_duration": 3599.553325618194,
    "input_throughput": 640.7558914560291,
    "output_throughput": 559.0235281913527,
    "total_throughput": 1199.779419647382,
    "itl": 19.04602567347312,
    "ttft": 3512.6864624987356,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 9307,
    "finished_requests": 9298,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1547433319501579. Arrivals time: 0.03554569277912378 Scheduler time: 0.7044925689697266 Scheduler overhead time: 0.15476441802456975 Adapter cache time: 0.029487887397408485 Engine time: 0.15126125002279878 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-32/adapters_16_slots_16_rate_0.4-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-32/adapters_16_slots_16_rate_0.4-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [5 5 6]
Adapter prompts. [270, 66, 66, 270, 4320, 66, 4320, 66, 270, 270, 66, 270, 4320, 4320, 4320, 4320]
Prompts retrieved: 27600 . Total input tokens: 6104713 . Total output tokens: 5548111
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.1466555139049888,
    "estimated_duration": 3599.5507213674196,
    "input_throughput": 640.7563550386136,
    "output_throughput": 559.0239326411213,
    "total_throughput": 1199.780287679735,
    "itl": 19.07637957944935,
    "ttft": 3512.783944543695,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072867,
    "arrivals": 9307,
    "finished_requests": 9298,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1468863631598651. Arrivals time: 0.03600467136129737 Scheduler time: 0.7016589436680079 Scheduler overhead time: 0.15283914422616363 Adapter cache time: 0.028700644616037607 Engine time: 0.14944596774876118 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_16_slots_16_rate_0.4-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_16_slots_16_rate_0.4-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [5 5 6]
Adapter prompts. [270, 33, 33, 270, 4320, 33, 4320, 33, 270, 270, 33, 270, 4320, 4320, 4320, 4320]
Prompts retrieved: 27435 . Total input tokens: 6062288 . Total output tokens: 5520111
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 1.1594051639549434,
    "estimated_duration": 3599.2025523538878,
    "input_throughput": 627.1811511479635,
    "output_throughput": 562.8113368265994,
    "total_throughput": 1189.992487974563,
    "itl": 19.181450179244564,
    "ttft": 3921.033237479628,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 9256,
    "finished_requests": 9246,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1595049956813455. Arrivals time: 0.03610956110060215 Scheduler time: 0.7113755429163575 Scheduler overhead time: 0.15338391065597534 Adapter cache time: 0.029010199941694736 Engine time: 0.15118125081062317 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_16_slots_16_rate_0.4-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_16_slots_16_rate_0.4-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [5 5 6]
Adapter prompts. [270, 33, 33, 270, 4320, 33, 4320, 33, 270, 270, 33, 270, 4320, 4320, 4320, 4320]
Prompts retrieved: 27435 . Total input tokens: 6062288 . Total output tokens: 5520111
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.1623322409577668,
    "estimated_duration": 3599.20309235597,
    "input_throughput": 627.1810570495983,
    "output_throughput": 562.8112523858812,
    "total_throughput": 1189.9923094354795,
    "itl": 19.181497932260957,
    "ttft": 3920.9863608753944,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 9256,
    "finished_requests": 9246,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1624335409142077. Arrivals time: 0.036290577147156 Scheduler time: 0.7123452867381275 Scheduler overhead time: 0.15592794213443995 Adapter cache time: 0.029301894828677177 Engine time: 0.14965578401461244 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-32/adapters_16_slots_16_rate_0.4-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-32/adapters_16_slots_16_rate_0.4-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [5 5 6]
Adapter prompts. [270, 33, 33, 270, 4320, 33, 4320, 33, 270, 270, 33, 270, 4320, 4320, 4320, 4320]
Prompts retrieved: 27435 . Total input tokens: 6062288 . Total output tokens: 5520111
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.159040051046759,
    "estimated_duration": 3599.203063008984,
    "input_throughput": 627.181062163473,
    "output_throughput": 562.811256974901,
    "total_throughput": 1189.992319138374,
    "itl": 19.1814822251916,
    "ttft": 3921.0183719853508,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 9256,
    "finished_requests": 9246,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.159142378717661. Arrivals time: 0.03618552256375551 Scheduler time: 0.707143731880933 Scheduler overhead time: 0.15739139029756188 Adapter cache time: 0.029036987107247114 Engine time: 0.15054792864248157 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_16_slots_16_rate_0.4-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_16_slots_16_rate_0.4-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [5 5 6]
Adapter prompts. [270, 33, 33, 270, 4320, 33, 4320, 33, 270, 270, 33, 270, 4320, 4320, 4320, 4320]
Prompts retrieved: 27435 . Total input tokens: 6062288 . Total output tokens: 5520111
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 1.1465228600427508,
    "estimated_duration": 3599.2023901666057,
    "input_throughput": 627.1811794100048,
    "output_throughput": 562.8113621880076,
    "total_throughput": 1189.9925415980124,
    "itl": 19.18146690454318,
    "ttft": 3920.985846627097,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 9256,
    "finished_requests": 9246,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1466182530857623. Arrivals time: 0.03656022995710373 Scheduler time: 0.7000106200575829 Scheduler overhead time: 0.15321571240201592 Adapter cache time: 0.028798953164368868 Engine time: 0.14919089246541262 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-32/adapters_16_slots_16_rate_0.4-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-32/adapters_16_slots_16_rate_0.4-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [5 5 6]
Adapter prompts. [270, 33, 33, 270, 4320, 33, 4320, 33, 270, 270, 33, 270, 4320, 4320, 4320, 4320]
Prompts retrieved: 27435 . Total input tokens: 6062288 . Total output tokens: 5520111
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 1.1510817711241543,
    "estimated_duration": 3599.2042321896765,
    "input_throughput": 627.1808584273299,
    "output_throughput": 562.811074148917,
    "total_throughput": 1189.9919325762469,
    "itl": 19.181501399040034,
    "ttft": 3920.965071893831,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.0530347929522395,
    "arrivals": 9256,
    "finished_requests": 9246,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.151166819036007. Arrivals time: 0.036431397777050734 Scheduler time: 0.7025904846377671 Scheduler overhead time: 0.1532454201951623 Adapter cache time: 0.029242148622870445 Engine time: 0.1510168849490583 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_16_slots_16_rate_0.4-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_16_slots_16_rate_0.4-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [5 5 6]
Adapter prompts. [270, 33, 33, 270, 4320, 33, 4320, 33, 270, 270, 33, 270, 4320, 4320, 4320, 4320]
Prompts retrieved: 27435 . Total input tokens: 6062288 . Total output tokens: 5520111
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 1.1469288528896868,
    "estimated_duration": 3599.2023329170124,
    "input_throughput": 627.1811893860673,
    "output_throughput": 562.8113711401916,
    "total_throughput": 1189.9925605262588,
    "itl": 19.18146733345365,
    "ttft": 3920.962954966043,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 9256,
    "finished_requests": 9246,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1470533818937838. Arrivals time: 0.03568939305841923 Scheduler time: 0.7013539397157729 Scheduler overhead time: 0.15431199269369245 Adapter cache time: 0.028998191934078932 Engine time: 0.14823125768452883 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-32/adapters_16_slots_16_rate_0.4-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-32/adapters_16_slots_16_rate_0.4-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [5 5 6]
Adapter prompts. [270, 33, 33, 270, 4320, 33, 4320, 33, 270, 270, 33, 270, 4320, 4320, 4320, 4320]
Prompts retrieved: 27435 . Total input tokens: 6062288 . Total output tokens: 5520111
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.147050668951124,
    "estimated_duration": 3599.211786130142,
    "input_throughput": 627.1795421149961,
    "output_throughput": 562.8098929343622,
    "total_throughput": 1189.9894350493585,
    "itl": 19.181537289612383,
    "ttft": 3921.0358816367147,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072868,
    "arrivals": 9256,
    "finished_requests": 9246,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1471380372531712. Arrivals time: 0.036453391425311565 Scheduler time: 0.7012769267894328 Scheduler overhead time: 0.15312341321259737 Adapter cache time: 0.02909880131483078 Engine time: 0.1487663146108389 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_16_slots_16_rate_0.4-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_16_slots_16_rate_0.4-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [5 5 6]
Adapter prompts. [135, 66, 66, 135, 4320, 66, 4320, 66, 135, 135, 66, 135, 4320, 4320, 4320, 4320]
Prompts retrieved: 26925 . Total input tokens: 5942303 . Total output tokens: 5419449
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 1.1525637917220592,
    "estimated_duration": 3599.920823640733,
    "input_throughput": 621.3831107923396,
    "output_throughput": 557.6444867389515,
    "total_throughput": 1179.0275975312911,
    "itl": 19.144758915798523,
    "ttft": 4779.790440010058,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 9098,
    "finished_requests": 9086,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1526499199680984. Arrivals time: 0.036085743457078934 Scheduler time: 0.7022373452782631 Scheduler overhead time: 0.15443200757727027 Adapter cache time: 0.02926222374662757 Engine time: 0.15134238172322512 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_16_slots_16_rate_0.4-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_16_slots_16_rate_0.4-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [5 5 6]
Adapter prompts. [135, 66, 66, 135, 4320, 66, 4320, 66, 135, 135, 66, 135, 4320, 4320, 4320, 4320]
Prompts retrieved: 26925 . Total input tokens: 5942303 . Total output tokens: 5419449
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.1423059990629554,
    "estimated_duration": 3599.9297085515886,
    "input_throughput": 621.3815771697432,
    "output_throughput": 557.6431104283135,
    "total_throughput": 1179.0246875980567,
    "itl": 19.144819022621764,
    "ttft": 4779.790031576802,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 9098,
    "finished_requests": 9086,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1424014372751117. Arrivals time: 0.035201388876885176 Scheduler time: 0.6957188784144819 Scheduler overhead time: 0.15282476134598255 Adapter cache time: 0.029216510243713856 Engine time: 0.1509963939897716 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-32/adapters_16_slots_16_rate_0.4-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-32/adapters_16_slots_16_rate_0.4-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [5 5 6]
Adapter prompts. [135, 66, 66, 135, 4320, 66, 4320, 66, 135, 135, 66, 135, 4320, 4320, 4320, 4320]
Prompts retrieved: 26925 . Total input tokens: 5942303 . Total output tokens: 5419449
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.1465604230761528,
    "estimated_duration": 3599.928568960769,
    "input_throughput": 621.3817738738519,
    "output_throughput": 557.6432869554187,
    "total_throughput": 1179.0250608292706,
    "itl": 19.144816642339663,
    "ttft": 4779.731115649371,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 9098,
    "finished_requests": 9086,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.146657882258296. Arrivals time: 0.0347010069526732 Scheduler time: 0.6991913039237261 Scheduler overhead time: 0.15394327137619257 Adapter cache time: 0.029014356434345245 Engine time: 0.15126776369288564 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_16_slots_16_rate_0.4-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_16_slots_16_rate_0.4-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [5 5 6]
Adapter prompts. [135, 66, 66, 135, 4320, 66, 4320, 66, 135, 135, 66, 135, 4320, 4320, 4320, 4320]
Prompts retrieved: 26925 . Total input tokens: 5942303 . Total output tokens: 5419449
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 1.1376373320817947,
    "estimated_duration": 3599.922132697052,
    "input_throughput": 621.3828848359278,
    "output_throughput": 557.6442839601101,
    "total_throughput": 1179.027168796038,
    "itl": 19.14477491143552,
    "ttft": 4779.757023641021,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 9098,
    "finished_requests": 9086,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1377389156259596. Arrivals time: 0.0353243718855083 Scheduler time: 0.6929095657542348 Scheduler overhead time: 0.15242274990305305 Adapter cache time: 0.028941715136170387 Engine time: 0.1496357093565166 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-32/adapters_16_slots_16_rate_0.4-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-32/adapters_16_slots_16_rate_0.4-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [5 5 6]
Adapter prompts. [135, 66, 66, 135, 4320, 66, 4320, 66, 135, 135, 66, 135, 4320, 4320, 4320, 4320]
Prompts retrieved: 26925 . Total input tokens: 5942303 . Total output tokens: 5419449
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 1.1458265627734363,
    "estimated_duration": 3599.931102340769,
    "input_throughput": 621.3813365887725,
    "output_throughput": 557.6428945250332,
    "total_throughput": 1179.0242311138056,
    "itl": 19.144699293208724,
    "ttft": 4779.77534725338,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05303479295223951,
    "arrivals": 9098,
    "finished_requests": 9086,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1459141769446433. Arrivals time: 0.03498288197442889 Scheduler time: 0.697403356898576 Scheduler overhead time: 0.15443322202190757 Adapter cache time: 0.02919287607073784 Engine time: 0.15069866459816694 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_16_slots_16_rate_0.4-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_16_slots_16_rate_0.4-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [5 5 6]
Adapter prompts. [135, 66, 66, 135, 4320, 66, 4320, 66, 135, 135, 66, 135, 4320, 4320, 4320, 4320]
Prompts retrieved: 26925 . Total input tokens: 5942303 . Total output tokens: 5419449
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 1.140998219139874,
    "estimated_duration": 3599.9200162209386,
    "input_throughput": 621.3832501612759,
    "output_throughput": 557.6446118120627,
    "total_throughput": 1179.0278619733388,
    "itl": 19.144720888702153,
    "ttft": 4779.769721158787,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 9098,
    "finished_requests": 9086,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1410858039744198. Arrivals time: 0.03583455923944712 Scheduler time: 0.6945040472783148 Scheduler overhead time: 0.152446870226413 Adapter cache time: 0.028876070864498615 Engine time: 0.1506414576433599 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-32/adapters_16_slots_16_rate_0.4-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-32/adapters_16_slots_16_rate_0.4-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [5 5 6]
Adapter prompts. [135, 66, 66, 135, 4320, 66, 4320, 66, 135, 135, 66, 135, 4320, 4320, 4320, 4320]
Prompts retrieved: 26925 . Total input tokens: 5942303 . Total output tokens: 5419449
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.1423622551374137,
    "estimated_duration": 3599.9311041927813,
    "input_throughput": 621.381336269098,
    "output_throughput": 557.6428942381496,
    "total_throughput": 1179.0242305072475,
    "itl": 19.14469592789131,
    "ttft": 4779.769497084791,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072867,
    "arrivals": 9098,
    "finished_requests": 9086,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1424579722806811. Arrivals time: 0.0352252209559083 Scheduler time: 0.6951218824833632 Scheduler overhead time: 0.15311078215017915 Adapter cache time: 0.029165467247366905 Engine time: 0.15107944328337908 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_16_slots_16_rate_0.4-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_16_slots_16_rate_0.4-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [5 5 6]
Adapter prompts. [135, 33, 33, 135, 4320, 33, 4320, 33, 135, 135, 33, 135, 4320, 4320, 4320, 4320]
Prompts retrieved: 26760 . Total input tokens: 5908771 . Total output tokens: 5387771
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 1.140873315744102,
    "estimated_duration": 3599.8268891795833,
    "input_throughput": 612.658904968243,
    "output_throughput": 538.5475634473727,
    "total_throughput": 1151.2064684156157,
    "itl": 18.927006575428177,
    "ttft": 6013.447073416899,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 9027,
    "finished_requests": 9012,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1411458868533373. Arrivals time: 0.03605782566592097 Scheduler time: 0.687646902166307 Scheduler overhead time: 0.15358387399464846 Adapter cache time: 0.028917177114635706 Engine time: 0.15593927819281816 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_16_slots_16_rate_0.4-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_16_slots_16_rate_0.4-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [5 5 6]
Adapter prompts. [135, 33, 33, 135, 4320, 33, 4320, 33, 135, 135, 33, 135, 4320, 4320, 4320, 4320]
Prompts retrieved: 26760 . Total input tokens: 5908771 . Total output tokens: 5387771
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.1266989959403872,
    "estimated_duration": 3599.8272672790604,
    "input_throughput": 612.658840619041,
    "output_throughput": 538.5475068822831,
    "total_throughput": 1151.2063475013242,
    "itl": 18.92696924278781,
    "ttft": 6013.3613595781735,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 9027,
    "finished_requests": 9012,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1267944467253983. Arrivals time: 0.035312327556312084 Scheduler time: 0.6795355663634837 Scheduler overhead time: 0.15341663779690862 Adapter cache time: 0.028922951314598322 Engine time: 0.1508212899789214 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-32/adapters_16_slots_16_rate_0.4-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-32/adapters_16_slots_16_rate_0.4-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [5 5 6]
Adapter prompts. [135, 33, 33, 135, 4320, 33, 4320, 33, 135, 135, 33, 135, 4320, 4320, 4320, 4320]
Prompts retrieved: 26760 . Total input tokens: 5908771 . Total output tokens: 5387771
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.1420216620899737,
    "estimated_duration": 3599.8269983639007,
    "input_throughput": 612.6588863860321,
    "output_throughput": 538.5475471129911,
    "total_throughput": 1151.2064334990232,
    "itl": 18.926984177052514,
    "ttft": 6013.334724631832,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.0524060240201652,
    "arrivals": 9027,
    "finished_requests": 9012,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1421186910010874. Arrivals time: 0.03562680259346962 Scheduler time: 0.6843023053370416 Scheduler overhead time: 0.16152658220380545 Adapter cache time: 0.029197706375271082 Engine time: 0.15092115150764585 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_16_slots_16_rate_0.4-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_16_slots_16_rate_0.4-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [5 5 6]
Adapter prompts. [135, 33, 33, 135, 4320, 33, 4320, 33, 135, 135, 33, 135, 4320, 4320, 4320, 4320]
Prompts retrieved: 26760 . Total input tokens: 5908771 . Total output tokens: 5387771
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 1.1246066968888044,
    "estimated_duration": 3599.8269067867354,
    "input_throughput": 612.6589019716604,
    "output_throughput": 538.547560813277,
    "total_throughput": 1151.2064627849372,
    "itl": 18.926984062751803,
    "ttft": 6013.3881704938385,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 9027,
    "finished_requests": 9012,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1246971059590578. Arrivals time: 0.03547381004318595 Scheduler time: 0.6786959348246455 Scheduler overhead time: 0.15261626103892922 Adapter cache time: 0.028722759801894426 Engine time: 0.15047221165150404 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-32/adapters_16_slots_16_rate_0.4-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-32/adapters_16_slots_16_rate_0.4-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [5 5 6]
Adapter prompts. [135, 33, 33, 135, 4320, 33, 4320, 33, 135, 135, 33, 135, 4320, 4320, 4320, 4320]
Prompts retrieved: 26760 . Total input tokens: 5908771 . Total output tokens: 5387771
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 1.1280906610190868,
    "estimated_duration": 3599.8272630472757,
    "input_throughput": 612.6588413392535,
    "output_throughput": 538.5475075153737,
    "total_throughput": 1151.2063488546273,
    "itl": 18.926935750598936,
    "ttft": 6013.349872036633,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05303479295223951,
    "arrivals": 9027,
    "finished_requests": 9012,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.128179954830557. Arrivals time: 0.035255496855825186 Scheduler time: 0.6822970327921212 Scheduler overhead time: 0.15358701115474105 Adapter cache time: 0.028739669360220432 Engine time: 0.14946783054620028 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_16_slots_16_rate_0.4-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_16_slots_16_rate_0.4-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [5 5 6]
Adapter prompts. [135, 33, 33, 135, 4320, 33, 4320, 33, 135, 135, 33, 135, 4320, 4320, 4320, 4320]
Prompts retrieved: 26760 . Total input tokens: 5908771 . Total output tokens: 5387771
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 1.1387562658637762,
    "estimated_duration": 3599.826341791516,
    "input_throughput": 612.6589981288963,
    "output_throughput": 538.547645338687,
    "total_throughput": 1151.2066434675833,
    "itl": 18.92706057595261,
    "ttft": 6013.466385710455,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 9027,
    "finished_requests": 9012,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1388425347395241. Arrivals time: 0.035390148870646954 Scheduler time: 0.6903464053757489 Scheduler overhead time: 0.15403687115758657 Adapter cache time: 0.028836972080171108 Engine time: 0.1514837690629065 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-32/adapters_16_slots_16_rate_0.4-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-32/adapters_16_slots_16_rate_0.4-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [5 5 6]
Adapter prompts. [135, 33, 33, 135, 4320, 33, 4320, 33, 135, 135, 33, 135, 4320, 4320, 4320, 4320]
Prompts retrieved: 26760 . Total input tokens: 5908771 . Total output tokens: 5387771
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.1453677960671484,
    "estimated_duration": 3599.8354191942835,
    "input_throughput": 612.6574532381339,
    "output_throughput": 538.5462873283011,
    "total_throughput": 1151.203740566435,
    "itl": 18.92704215350443,
    "ttft": 6013.407097435548,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072868,
    "arrivals": 9027,
    "finished_requests": 9012,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.145464964210987. Arrivals time: 0.03512498643249273 Scheduler time: 0.6885640360414982 Scheduler overhead time: 0.1617974890395999 Adapter cache time: 0.029154655057936907 Engine time: 0.15141661604866385 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_16_slots_16_rate_0.4-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_16_slots_16_rate_0.4-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [5 5 6]
Adapter prompts. [66, 33, 33, 66, 4320, 33, 4320, 33, 66, 66, 33, 66, 4320, 4320, 4320, 4320]
Prompts retrieved: 26415 . Total input tokens: 5826447 . Total output tokens: 5318979
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 1.1292410609312356,
    "estimated_duration": 3599.887507447586,
    "input_throughput": 607.6945447528965,
    "output_throughput": 545.6551061487856,
    "total_throughput": 1153.3496509016823,
    "itl": 19.059963539780515,
    "ttft": 7294.21163467559,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 8922,
    "finished_requests": 8904,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1293376330286264. Arrivals time: 0.035010472405701876 Scheduler time: 0.682845285627991 Scheduler overhead time: 0.1538667087443173 Adapter cache time: 0.028394139371812344 Engine time: 0.15020726015791297 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_16_slots_16_rate_0.4-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_16_slots_16_rate_0.4-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [5 5 6]
Adapter prompts. [66, 33, 33, 66, 4320, 33, 4320, 33, 66, 66, 33, 66, 4320, 4320, 4320, 4320]
Prompts retrieved: 26415 . Total input tokens: 5826447 . Total output tokens: 5318979
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.1410339600406587,
    "estimated_duration": 3599.887732698583,
    "input_throughput": 607.6945067284323,
    "output_throughput": 545.6550720062329,
    "total_throughput": 1153.3495787346653,
    "itl": 19.059944489683314,
    "ttft": 7294.255353050318,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 8922,
    "finished_requests": 8904,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1412952891550958. Arrivals time: 0.03486702498048544 Scheduler time: 0.6878410805948079 Scheduler overhead time: 0.15927666891366243 Adapter cache time: 0.02848391141742468 Engine time: 0.1510320589877665 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-32/adapters_16_slots_16_rate_0.4-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-32/adapters_16_slots_16_rate_0.4-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [5 5 6]
Adapter prompts. [66, 33, 33, 66, 4320, 33, 4320, 33, 66, 66, 33, 66, 4320, 4320, 4320, 4320]
Prompts retrieved: 26415 . Total input tokens: 5826447 . Total output tokens: 5318979
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.1309253051877022,
    "estimated_duration": 3599.887626139424,
    "input_throughput": 607.6945247166093,
    "output_throughput": 545.6550881579998,
    "total_throughput": 1153.349612874609,
    "itl": 19.059939940540414,
    "ttft": 7294.268510128022,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 8922,
    "finished_requests": 8904,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1310119801200926. Arrivals time: 0.03536353958770633 Scheduler time: 0.6860663560219109 Scheduler overhead time: 0.1522761294618249 Adapter cache time: 0.0282074143178761 Engine time: 0.1502695376984775 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_16_slots_16_rate_0.4-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_16_slots_16_rate_0.4-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [5 5 6]
Adapter prompts. [66, 33, 33, 66, 4320, 33, 4320, 33, 66, 66, 33, 66, 4320, 4320, 4320, 4320]
Prompts retrieved: 26415 . Total input tokens: 5826447 . Total output tokens: 5318979
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 1.1369488127529621,
    "estimated_duration": 3599.887575482022,
    "input_throughput": 607.6945332680501,
    "output_throughput": 545.6550958364255,
    "total_throughput": 1153.3496291044755,
    "itl": 19.059967157724895,
    "ttft": 7294.204569523497,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 8922,
    "finished_requests": 8904,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1370292739011347. Arrivals time: 0.034629933536052704 Scheduler time: 0.689409620128572 Scheduler overhead time: 0.15407168865203857 Adapter cache time: 0.028364504221826792 Engine time: 0.15178094478324056 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-32/adapters_16_slots_16_rate_0.4-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-32/adapters_16_slots_16_rate_0.4-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [5 5 6]
Adapter prompts. [66, 33, 33, 66, 4320, 33, 4320, 33, 66, 66, 33, 66, 4320, 4320, 4320, 4320]
Prompts retrieved: 26415 . Total input tokens: 5826447 . Total output tokens: 5318979
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 1.131981659680605,
    "estimated_duration": 3599.8877095966754,
    "input_throughput": 607.6945106282491,
    "output_throughput": 545.655075507918,
    "total_throughput": 1153.349586136167,
    "itl": 19.059941777474368,
    "ttft": 7294.275275289739,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05303479295223951,
    "arrivals": 8922,
    "finished_requests": 8904,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1320811999030411. Arrivals time: 0.03545863088220358 Scheduler time: 0.6837893812917173 Scheduler overhead time: 0.15380411129444838 Adapter cache time: 0.02851622737944126 Engine time: 0.1511687422171235 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_16_slots_16_rate_0.4-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_16_slots_16_rate_0.4-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [5 5 6]
Adapter prompts. [66, 33, 33, 66, 4320, 33, 4320, 33, 66, 66, 33, 66, 4320, 4320, 4320, 4320]
Prompts retrieved: 26415 . Total input tokens: 5826447 . Total output tokens: 5318979
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 1.141332836356014,
    "estimated_duration": 3599.8865896460156,
    "input_throughput": 607.6946996863905,
    "output_throughput": 545.6552452651441,
    "total_throughput": 1153.3499449515346,
    "itl": 19.05991960836266,
    "ttft": 7294.250778085334,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 8922,
    "finished_requests": 8904,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1414226181805134. Arrivals time: 0.03488184232264757 Scheduler time: 0.6938662868924439 Scheduler overhead time: 0.15475370362401009 Adapter cache time: 0.02816321048885584 Engine time: 0.15064944000914693 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-32/adapters_16_slots_16_rate_0.4-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-32/adapters_16_slots_16_rate_0.4-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [5 5 6]
Adapter prompts. [66, 33, 33, 66, 4320, 33, 4320, 33, 66, 66, 33, 66, 4320, 4320, 4320, 4320]
Prompts retrieved: 26415 . Total input tokens: 5826447 . Total output tokens: 5318979
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.1319558210670948,
    "estimated_duration": 3599.887612644457,
    "input_throughput": 607.6945269946852,
    "output_throughput": 545.6550902035074,
    "total_throughput": 1153.3496171981926,
    "itl": 19.059932414546832,
    "ttft": 7294.267116553282,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072868,
    "arrivals": 8922,
    "finished_requests": 8904,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1320852199569345. Arrivals time: 0.03502284595742822 Scheduler time: 0.6834616120904684 Scheduler overhead time: 0.15383214317262173 Adapter cache time: 0.028323929756879807 Engine time: 0.15102075086906552 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_16_slots_16_rate_0.1-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_16_slots_16_rate_0.1-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [5 5 6]
Adapter prompts. [540, 270, 270, 540, 1080, 270, 1080, 270, 540, 540, 270, 540, 1080, 1080, 1080, 1080]
Prompts retrieved: 10530 . Total input tokens: 2295280 . Total output tokens: 2167065
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 0.7729156310670078,
    "estimated_duration": 3599.4432247312116,
    "input_throughput": 226.21832021278925,
    "output_throughput": 208.0093929126804,
    "total_throughput": 434.2277131254697,
    "itl": 18.230940027027078,
    "ttft": 7459.0534057532595,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 3392,
    "finished_requests": 3385,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7729823389090598. Arrivals time: 0.022432068828493357 Scheduler time: 0.34182098461315036 Scheduler overhead time: 0.14993992820382118 Adapter cache time: 0.03021038556471467 Engine time: 0.15089425817131996 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_16_slots_16_rate_0.1-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_16_slots_16_rate_0.1-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [5 5 6]
Adapter prompts. [540, 270, 270, 540, 1080, 270, 1080, 270, 540, 540, 270, 540, 1080, 1080, 1080, 1080]
Prompts retrieved: 10530 . Total input tokens: 2295280 . Total output tokens: 2167065
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 0.77571892272681,
    "estimated_duration": 3599.4432247312116,
    "input_throughput": 226.21832021278925,
    "output_throughput": 208.0093929126804,
    "total_throughput": 434.2277131254697,
    "itl": 18.231505533674007,
    "ttft": 7459.042675578625,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 3392,
    "finished_requests": 3385,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7758040870539844. Arrivals time: 0.022752410266548395 Scheduler time: 0.34521487914025784 Scheduler overhead time: 0.14994771173223853 Adapter cache time: 0.03017526865005493 Engine time: 0.15026836935430765 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-32/adapters_16_slots_16_rate_0.1-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-32/adapters_16_slots_16_rate_0.1-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [5 5 6]
Adapter prompts. [540, 270, 270, 540, 1080, 270, 1080, 270, 540, 540, 270, 540, 1080, 1080, 1080, 1080]
Prompts retrieved: 10530 . Total input tokens: 2295280 . Total output tokens: 2167065
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 0.7748375008814037,
    "estimated_duration": 3599.4432247312116,
    "input_throughput": 226.21832021278925,
    "output_throughput": 208.0093929126804,
    "total_throughput": 434.2277131254697,
    "itl": 18.231503679864655,
    "ttft": 7459.045264329189,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 3392,
    "finished_requests": 3385,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7749159117229283. Arrivals time: 0.02254533814266324 Scheduler time: 0.34226073417812586 Scheduler overhead time: 0.15039387345314026 Adapter cache time: 0.030402344651520252 Engine time: 0.15157468197867274 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_16_slots_16_rate_0.1-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_16_slots_16_rate_0.1-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [5 5 6]
Adapter prompts. [540, 270, 270, 540, 1080, 270, 1080, 270, 540, 540, 270, 540, 1080, 1080, 1080, 1080]
Prompts retrieved: 10530 . Total input tokens: 2295280 . Total output tokens: 2167065
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 0.7738616103306413,
    "estimated_duration": 3599.4432247312116,
    "input_throughput": 226.21832021278925,
    "output_throughput": 208.0093929126804,
    "total_throughput": 434.2277131254697,
    "itl": 18.23090279620243,
    "ttft": 7459.046267573224,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 3392,
    "finished_requests": 3385,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7739319861866534. Arrivals time: 0.023098435252904892 Scheduler time: 0.3403255990706384 Scheduler overhead time: 0.15020353300496936 Adapter cache time: 0.030582746490836143 Engine time: 0.15210873261094093 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-32/adapters_16_slots_16_rate_0.1-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-32/adapters_16_slots_16_rate_0.1-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [5 5 6]
Adapter prompts. [540, 270, 270, 540, 1080, 270, 1080, 270, 540, 540, 270, 540, 1080, 1080, 1080, 1080]
Prompts retrieved: 10530 . Total input tokens: 2295280 . Total output tokens: 2167065
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 0.7730931569822133,
    "estimated_duration": 3599.4432247312116,
    "input_throughput": 226.21832021278925,
    "output_throughput": 208.0093929126804,
    "total_throughput": 434.2277131254697,
    "itl": 18.231525179135247,
    "ttft": 7459.035484293178,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.0530347929522395,
    "arrivals": 3392,
    "finished_requests": 3385,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7731904028914869. Arrivals time: 0.022702008485794067 Scheduler time: 0.34139310102909803 Scheduler overhead time: 0.1499463771469891 Adapter cache time: 0.03047035075724125 Engine time: 0.15050784312188625 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_16_slots_16_rate_0.1-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_16_slots_16_rate_0.1-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [5 5 6]
Adapter prompts. [540, 270, 270, 540, 1080, 270, 1080, 270, 540, 540, 270, 540, 1080, 1080, 1080, 1080]
Prompts retrieved: 10530 . Total input tokens: 2295280 . Total output tokens: 2167065
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 0.7731891903094947,
    "estimated_duration": 3599.4432247312116,
    "input_throughput": 226.21832021278925,
    "output_throughput": 208.0093929126804,
    "total_throughput": 434.2277131254697,
    "itl": 18.230936366540394,
    "ttft": 7459.0175999826715,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 3392,
    "finished_requests": 3385,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7733043739572167. Arrivals time: 0.02301887609064579 Scheduler time: 0.3418308990076184 Scheduler overhead time: 0.15035645011812449 Adapter cache time: 0.030108895152807236 Engine time: 0.15066020004451275 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-32/adapters_16_slots_16_rate_0.1-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-32/adapters_16_slots_16_rate_0.1-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [5 5 6]
Adapter prompts. [540, 270, 270, 540, 1080, 270, 1080, 270, 540, 540, 270, 540, 1080, 1080, 1080, 1080]
Prompts retrieved: 10530 . Total input tokens: 2295280 . Total output tokens: 2167065
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 0.7811929183080792,
    "estimated_duration": 3599.4432247312116,
    "input_throughput": 226.21832021278925,
    "output_throughput": 208.0093929126804,
    "total_throughput": 434.2277131254697,
    "itl": 18.231686639568316,
    "ttft": 7459.038404507293,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072868,
    "arrivals": 3392,
    "finished_requests": 3385,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7812560480087996. Arrivals time: 0.02258620783686638 Scheduler time: 0.34672462148591876 Scheduler overhead time: 0.15297029539942741 Adapter cache time: 0.030241120140999556 Engine time: 0.15084927761927247 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_16_slots_16_rate_0.1-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_16_slots_16_rate_0.1-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [5 5 6]
Adapter prompts. [540, 135, 135, 540, 1080, 135, 1080, 135, 540, 540, 135, 540, 1080, 1080, 1080, 1080]
Prompts retrieved: 9855 . Total input tokens: 2153620 . Total output tokens: 2028641
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 0.7574024680070579,
    "estimated_duration": 3599.5134108334305,
    "input_throughput": 214.3861994450311,
    "output_throughput": 196.62074264535946,
    "total_throughput": 411.00694209039057,
    "itl": 18.21859127419722,
    "ttft": 6773.5512182776965,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 3203,
    "finished_requests": 3197,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7574741211719811. Arrivals time: 0.022331683430820704 Scheduler time: 0.32808449771255255 Scheduler overhead time: 0.149864437058568 Adapter cache time: 0.02928818017244339 Engine time: 0.15016273828223348 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_16_slots_16_rate_0.1-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_16_slots_16_rate_0.1-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [5 5 6]
Adapter prompts. [540, 135, 135, 540, 1080, 135, 1080, 135, 540, 540, 135, 540, 1080, 1080, 1080, 1080]
Prompts retrieved: 9855 . Total input tokens: 2153620 . Total output tokens: 2028641
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 0.7595297922380269,
    "estimated_duration": 3599.5134108334305,
    "input_throughput": 214.3861994450311,
    "output_throughput": 196.62074264535946,
    "total_throughput": 411.00694209039057,
    "itl": 18.218605947332556,
    "ttft": 6773.531658046812,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 3203,
    "finished_requests": 3197,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7596037052571774. Arrivals time: 0.0221440140157938 Scheduler time: 0.32786455238237977 Scheduler overhead time: 0.15173888858407736 Adapter cache time: 0.029525413643568754 Engine time: 0.15055168373510242 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-32/adapters_16_slots_16_rate_0.1-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-32/adapters_16_slots_16_rate_0.1-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [5 5 6]
Adapter prompts. [540, 135, 135, 540, 1080, 135, 1080, 135, 540, 540, 135, 540, 1080, 1080, 1080, 1080]
Prompts retrieved: 9855 . Total input tokens: 2153620 . Total output tokens: 2028641
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 0.7595781181007624,
    "estimated_duration": 3599.5134108334305,
    "input_throughput": 214.3861994450311,
    "output_throughput": 196.62074264535946,
    "total_throughput": 411.00694209039057,
    "itl": 18.218605817932655,
    "ttft": 6773.531624958001,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 3203,
    "finished_requests": 3197,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7597542861476541. Arrivals time: 0.022095346357673407 Scheduler time: 0.33122198516502976 Scheduler overhead time: 0.149769255425781 Adapter cache time: 0.029414834454655647 Engine time: 0.14992135390639305 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_16_slots_16_rate_0.1-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_16_slots_16_rate_0.1-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [5 5 6]
Adapter prompts. [540, 135, 135, 540, 1080, 135, 1080, 135, 540, 540, 135, 540, 1080, 1080, 1080, 1080]
Prompts retrieved: 9855 . Total input tokens: 2153620 . Total output tokens: 2028641
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 0.7597858137451112,
    "estimated_duration": 3599.5134108334305,
    "input_throughput": 214.3861994450311,
    "output_throughput": 196.62074264535946,
    "total_throughput": 411.00694209039057,
    "itl": 18.218595846787437,
    "ttft": 6773.533898074428,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 3203,
    "finished_requests": 3197,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7598623679950833. Arrivals time: 0.02210136316716671 Scheduler time: 0.3290180452167988 Scheduler overhead time: 0.14902018290013075 Adapter cache time: 0.029443534091114998 Engine time: 0.1524953180924058 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-32/adapters_16_slots_16_rate_0.1-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-32/adapters_16_slots_16_rate_0.1-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [5 5 6]
Adapter prompts. [540, 135, 135, 540, 1080, 135, 1080, 135, 540, 540, 135, 540, 1080, 1080, 1080, 1080]
Prompts retrieved: 9855 . Total input tokens: 2153620 . Total output tokens: 2028641
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 0.7646466875448823,
    "estimated_duration": 3599.5134108334305,
    "input_throughput": 214.3861994450311,
    "output_throughput": 196.62074264535946,
    "total_throughput": 411.00694209039057,
    "itl": 18.218608630120947,
    "ttft": 6773.536571875607,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05303479295223951,
    "arrivals": 3203,
    "finished_requests": 3197,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7647115159779787. Arrivals time: 0.02235986804589629 Scheduler time: 0.33510759798809886 Scheduler overhead time: 0.14891870552673936 Adapter cache time: 0.02941562095656991 Engine time: 0.15113734547048807 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_16_slots_16_rate_0.1-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_16_slots_16_rate_0.1-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [5 5 6]
Adapter prompts. [540, 135, 135, 540, 1080, 135, 1080, 135, 540, 540, 135, 540, 1080, 1080, 1080, 1080]
Prompts retrieved: 9855 . Total input tokens: 2153620 . Total output tokens: 2028641
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 0.7607477167621255,
    "estimated_duration": 3599.5134108334305,
    "input_throughput": 214.3861994450311,
    "output_throughput": 196.62074264535946,
    "total_throughput": 411.00694209039057,
    "itl": 18.218587096479457,
    "ttft": 6773.548767993587,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 3203,
    "finished_requests": 3197,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7608329299837351. Arrivals time: 0.022628161124885082 Scheduler time: 0.3327364083379507 Scheduler overhead time: 0.14858545968309045 Adapter cache time: 0.029328077100217342 Engine time: 0.15096223074942827 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-32/adapters_16_slots_16_rate_0.1-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-32/adapters_16_slots_16_rate_0.1-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [5 5 6]
Adapter prompts. [540, 135, 135, 540, 1080, 135, 1080, 135, 540, 540, 135, 540, 1080, 1080, 1080, 1080]
Prompts retrieved: 9855 . Total input tokens: 2153620 . Total output tokens: 2028641
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 0.760628046002239,
    "estimated_duration": 3599.5134108334305,
    "input_throughput": 214.3861994450311,
    "output_throughput": 196.62074264535946,
    "total_throughput": 411.00694209039057,
    "itl": 18.21861163552251,
    "ttft": 6773.543364071999,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072867,
    "arrivals": 3203,
    "finished_requests": 3197,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7606916362419724. Arrivals time: 0.02166189206764102 Scheduler time: 0.32871192786842585 Scheduler overhead time: 0.15027033630758524 Adapter cache time: 0.02939416142180562 Engine time: 0.15292748669162393 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_16_slots_16_rate_0.1-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_16_slots_16_rate_0.1-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [5 5 6]
Adapter prompts. [540, 66, 66, 540, 1080, 66, 1080, 66, 540, 540, 66, 540, 1080, 1080, 1080, 1080]
Prompts retrieved: 9510 . Total input tokens: 2073261 . Total output tokens: 1956093
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 0.7628101240843534,
    "estimated_duration": 3596.417840839194,
    "input_throughput": 206.44125150562476,
    "output_throughput": 191.68406745505965,
    "total_throughput": 398.1253189606844,
    "itl": 18.093724763040534,
    "ttft": 8192.847065463016,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 3087,
    "finished_requests": 3080,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.76287503214553. Arrivals time: 0.022252460941672325 Scheduler time: 0.32365810172632337 Scheduler overhead time: 0.15866171102970839 Adapter cache time: 0.02942358748987317 Engine time: 0.15093830227851868 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_16_slots_16_rate_0.1-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_16_slots_16_rate_0.1-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [5 5 6]
Adapter prompts. [540, 66, 66, 540, 1080, 66, 1080, 66, 540, 540, 66, 540, 1080, 1080, 1080, 1080]
Prompts retrieved: 9510 . Total input tokens: 2073261 . Total output tokens: 1956093
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 0.7511977409012616,
    "estimated_duration": 3596.417840839194,
    "input_throughput": 206.44125150562476,
    "output_throughput": 191.68406745505965,
    "total_throughput": 398.1253189606844,
    "itl": 18.093742061358032,
    "ttft": 8192.86377967619,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 3087,
    "finished_requests": 3080,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7512842081487179. Arrivals time: 0.021783821284770966 Scheduler time: 0.32771276216953993 Scheduler overhead time: 0.14722856739535928 Adapter cache time: 0.028907594736665487 Engine time: 0.14811366656795144 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-32/adapters_16_slots_16_rate_0.1-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-32/adapters_16_slots_16_rate_0.1-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [5 5 6]
Adapter prompts. [540, 66, 66, 540, 1080, 66, 1080, 66, 540, 540, 66, 540, 1080, 1080, 1080, 1080]
Prompts retrieved: 9510 . Total input tokens: 2073261 . Total output tokens: 1956093
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 0.7467961432412267,
    "estimated_duration": 3596.417840839194,
    "input_throughput": 206.44125150562476,
    "output_throughput": 191.68406745505965,
    "total_throughput": 398.1253189606844,
    "itl": 18.09374259320905,
    "ttft": 8192.864331920026,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 3087,
    "finished_requests": 3080,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7469017351977527. Arrivals time: 0.021912051364779472 Scheduler time: 0.32250693952664733 Scheduler overhead time: 0.1478729285299778 Adapter cache time: 0.02849990501999855 Engine time: 0.14949815720319748 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_16_slots_16_rate_0.1-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_16_slots_16_rate_0.1-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [5 5 6]
Adapter prompts. [540, 66, 66, 540, 1080, 66, 1080, 66, 540, 540, 66, 540, 1080, 1080, 1080, 1080]
Prompts retrieved: 9510 . Total input tokens: 2073261 . Total output tokens: 1956093
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 0.7524834387004375,
    "estimated_duration": 3596.417840839194,
    "input_throughput": 206.44125150562476,
    "output_throughput": 191.68406745505965,
    "total_throughput": 398.1253189606844,
    "itl": 18.09373376407295,
    "ttft": 8192.845449590428,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 3087,
    "finished_requests": 3080,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7525404090993106. Arrivals time: 0.02182039897888899 Scheduler time: 0.32494987780228257 Scheduler overhead time: 0.14883458334952593 Adapter cache time: 0.02920139580965042 Engine time: 0.15061599854379892 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-32/adapters_16_slots_16_rate_0.1-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-32/adapters_16_slots_16_rate_0.1-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [5 5 6]
Adapter prompts. [540, 66, 66, 540, 1080, 66, 1080, 66, 540, 540, 66, 540, 1080, 1080, 1080, 1080]
Prompts retrieved: 9510 . Total input tokens: 2073261 . Total output tokens: 1956093
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 0.7462568362243474,
    "estimated_duration": 3596.417840839194,
    "input_throughput": 206.44125150562476,
    "output_throughput": 191.68406745505965,
    "total_throughput": 398.1253189606844,
    "itl": 18.093743906130772,
    "ttft": 8192.861041879214,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.0530347929522395,
    "arrivals": 3087,
    "finished_requests": 3080,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7463249093852937. Arrivals time: 0.02165578119456768 Scheduler time: 0.32282892521470785 Scheduler overhead time: 0.14766947459429502 Adapter cache time: 0.028754308354109526 Engine time: 0.14921658718958497 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_16_slots_16_rate_0.1-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_16_slots_16_rate_0.1-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [5 5 6]
Adapter prompts. [540, 66, 66, 540, 1080, 66, 1080, 66, 540, 540, 66, 540, 1080, 1080, 1080, 1080]
Prompts retrieved: 9510 . Total input tokens: 2073261 . Total output tokens: 1956093
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 0.7489162292331457,
    "estimated_duration": 3596.417840839194,
    "input_throughput": 206.44125150562476,
    "output_throughput": 191.68406745505965,
    "total_throughput": 398.1253189606844,
    "itl": 18.09371955261333,
    "ttft": 8192.848011554559,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 3087,
    "finished_requests": 3080,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7490367628633976. Arrivals time: 0.021716922521591187 Scheduler time: 0.32331686234101653 Scheduler overhead time: 0.14951867749914527 Adapter cache time: 0.028844799380749464 Engine time: 0.14888800913468003 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-32/adapters_16_slots_16_rate_0.1-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-32/adapters_16_slots_16_rate_0.1-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [5 5 6]
Adapter prompts. [540, 66, 66, 540, 1080, 66, 1080, 66, 540, 540, 66, 540, 1080, 1080, 1080, 1080]
Prompts retrieved: 9510 . Total input tokens: 2073261 . Total output tokens: 1956093
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 0.7592609510757029,
    "estimated_duration": 3596.417840839194,
    "input_throughput": 206.44125150562476,
    "output_throughput": 191.68406745505965,
    "total_throughput": 398.1253189606844,
    "itl": 18.093743023797067,
    "ttft": 8192.863851981132,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072867,
    "arrivals": 3087,
    "finished_requests": 3080,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.759325954131782. Arrivals time: 0.022185312118381262 Scheduler time: 0.32662183744832873 Scheduler overhead time: 0.1539002638310194 Adapter cache time: 0.029035022482275963 Engine time: 0.15023176139220595 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_16_slots_16_rate_0.1-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_16_slots_16_rate_0.1-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [5 5 6]
Adapter prompts. [540, 33, 33, 540, 1080, 33, 1080, 33, 540, 540, 33, 540, 1080, 1080, 1080, 1080]
Prompts retrieved: 9345 . Total input tokens: 2036620 . Total output tokens: 1922467
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 0.7566258092410862,
    "estimated_duration": 3599.7097503250625,
    "input_throughput": 203.12804384686035,
    "output_throughput": 189.1160808002716,
    "total_throughput": 392.2441246471319,
    "itl": 18.153268007929082,
    "ttft": 3603.451996488205,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 3022,
    "finished_requests": 3019,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7566895638592541. Arrivals time: 0.021783458068966866 Scheduler time: 0.323379744309932 Scheduler overhead time: 0.15415320126339793 Adapter cache time: 0.028910929337143898 Engine time: 0.15097297495231032 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_16_slots_16_rate_0.1-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_16_slots_16_rate_0.1-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [5 5 6]
Adapter prompts. [540, 33, 33, 540, 1080, 33, 1080, 33, 540, 540, 33, 540, 1080, 1080, 1080, 1080]
Prompts retrieved: 9345 . Total input tokens: 2036620 . Total output tokens: 1922467
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 0.7476424598135054,
    "estimated_duration": 3599.7097503250625,
    "input_throughput": 203.12804384686035,
    "output_throughput": 189.1160808002716,
    "total_throughput": 392.2441246471319,
    "itl": 18.15328077236306,
    "ttft": 3603.4489425041033,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 3022,
    "finished_requests": 3019,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7477316567674279. Arrivals time: 0.02171193901449442 Scheduler time: 0.32023509545251727 Scheduler overhead time: 0.14781089685857296 Adapter cache time: 0.028616145253181458 Engine time: 0.1521125379949808 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-32/adapters_16_slots_16_rate_0.1-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-32/adapters_16_slots_16_rate_0.1-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [5 5 6]
Adapter prompts. [540, 33, 33, 540, 1080, 33, 1080, 33, 540, 540, 33, 540, 1080, 1080, 1080, 1080]
Prompts retrieved: 9345 . Total input tokens: 2036620 . Total output tokens: 1922467
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 0.7589952782727778,
    "estimated_duration": 3599.7097503250625,
    "input_throughput": 203.12804384686035,
    "output_throughput": 189.1160808002716,
    "total_throughput": 392.2441246471319,
    "itl": 18.15328062238236,
    "ttft": 3603.4489062012913,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 3022,
    "finished_requests": 3019,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7591454540379345. Arrivals time: 0.023353952448815107 Scheduler time: 0.32806812692433596 Scheduler overhead time: 0.15071535715833306 Adapter cache time: 0.028867441229522228 Engine time: 0.15036495635285974 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_16_slots_16_rate_0.1-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_16_slots_16_rate_0.1-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [5 5 6]
Adapter prompts. [540, 33, 33, 540, 1080, 33, 1080, 33, 540, 540, 33, 540, 1080, 1080, 1080, 1080]
Prompts retrieved: 9345 . Total input tokens: 2036620 . Total output tokens: 1922467
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 0.7825444466434419,
    "estimated_duration": 3599.7097503250625,
    "input_throughput": 203.12804384686035,
    "output_throughput": 189.1160808002716,
    "total_throughput": 392.2441246471319,
    "itl": 18.153271669133293,
    "ttft": 3603.455253535117,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 3022,
    "finished_requests": 3019,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.782636109739542. Arrivals time: 0.02307848632335663 Scheduler time: 0.34084447426721454 Scheduler overhead time: 0.1613479219377041 Adapter cache time: 0.028740327805280685 Engine time: 0.15017749555408955 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-32/adapters_16_slots_16_rate_0.1-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-32/adapters_16_slots_16_rate_0.1-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [5 5 6]
Adapter prompts. [540, 33, 33, 540, 1080, 33, 1080, 33, 540, 540, 33, 540, 1080, 1080, 1080, 1080]
Prompts retrieved: 9345 . Total input tokens: 2036620 . Total output tokens: 1922467
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 0.7596318540163338,
    "estimated_duration": 3599.7097503250625,
    "input_throughput": 203.12804384686035,
    "output_throughput": 189.1160808002716,
    "total_throughput": 392.2441246471319,
    "itl": 18.153280582163465,
    "ttft": 3603.450109189045,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05303479295223951,
    "arrivals": 3022,
    "finished_requests": 3019,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7597395316697657. Arrivals time: 0.02205826062709093 Scheduler time: 0.32588182715699077 Scheduler overhead time: 0.14888265868648887 Adapter cache time: 0.02853778889402747 Engine time: 0.15659717377275229 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_16_slots_16_rate_0.1-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_16_slots_16_rate_0.1-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [5 5 6]
Adapter prompts. [540, 33, 33, 540, 1080, 33, 1080, 33, 540, 540, 33, 540, 1080, 1080, 1080, 1080]
Prompts retrieved: 9345 . Total input tokens: 2036620 . Total output tokens: 1922467
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 0.7551515060476959,
    "estimated_duration": 3599.7097503250625,
    "input_throughput": 203.12804384686035,
    "output_throughput": 189.1160808002716,
    "total_throughput": 392.2441246471319,
    "itl": 18.153266121218472,
    "ttft": 3603.4447243505506,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 3022,
    "finished_requests": 3019,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7552172467112541. Arrivals time: 0.021969508845359087 Scheduler time: 0.32751648128032684 Scheduler overhead time: 0.14951648330315948 Adapter cache time: 0.028871996328234673 Engine time: 0.14963872078806162 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-32/adapters_16_slots_16_rate_0.1-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-32/adapters_16_slots_16_rate_0.1-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [5 5 6]
Adapter prompts. [540, 33, 33, 540, 1080, 33, 1080, 33, 540, 540, 33, 540, 1080, 1080, 1080, 1080]
Prompts retrieved: 9345 . Total input tokens: 2036620 . Total output tokens: 1922467
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 0.7530683702789247,
    "estimated_duration": 3599.7097503250625,
    "input_throughput": 203.12804384686035,
    "output_throughput": 189.1160808002716,
    "total_throughput": 392.2441246471319,
    "itl": 18.15328252318561,
    "ttft": 3603.457974002292,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072868,
    "arrivals": 3022,
    "finished_requests": 3019,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7531533660367131. Arrivals time: 0.021728085353970528 Scheduler time: 0.3224141667596996 Scheduler overhead time: 0.14932309510186315 Adapter cache time: 0.028684301767498255 Engine time: 0.1541768736205995 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_16_slots_16_rate_0.1-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_16_slots_16_rate_0.1-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [5 5 6]
Adapter prompts. [270, 135, 135, 270, 1080, 135, 1080, 135, 270, 270, 135, 270, 1080, 1080, 1080, 1080]
Prompts retrieved: 8505 . Total input tokens: 1856242 . Total output tokens: 1759055
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 0.7376572052016854,
    "estimated_duration": 3597.794139962386,
    "input_throughput": 177.40231240875633,
    "output_throughput": 169.66979661776367,
    "total_throughput": 347.07210902652,
    "itl": 18.0924367358203,
    "ttft": 9212.94000354204,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 2744,
    "finished_requests": 2737,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7377607664093375. Arrivals time: 0.021582340821623802 Scheduler time: 0.3102508704178035 Scheduler overhead time: 0.14832476852461696 Adapter cache time: 0.028870562557131052 Engine time: 0.15189166460186243 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_16_slots_16_rate_0.1-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_16_slots_16_rate_0.1-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [5 5 6]
Adapter prompts. [270, 135, 135, 270, 1080, 135, 1080, 135, 270, 270, 135, 270, 1080, 1080, 1080, 1080]
Prompts retrieved: 8505 . Total input tokens: 1856242 . Total output tokens: 1759055
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 0.7261025290936232,
    "estimated_duration": 3597.794139962386,
    "input_throughput": 177.40231240875633,
    "output_throughput": 169.66979661776367,
    "total_throughput": 347.07210902652,
    "itl": 18.092440671918414,
    "ttft": 9212.901098493447,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 2744,
    "finished_requests": 2737,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7261681533418596. Arrivals time: 0.020999267231673002 Scheduler time: 0.30180440004915 Scheduler overhead time: 0.14807484531775117 Adapter cache time: 0.02824192401021719 Engine time: 0.1500133997760713 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-32/adapters_16_slots_16_rate_0.1-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-32/adapters_16_slots_16_rate_0.1-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [5 5 6]
Adapter prompts. [270, 135, 135, 270, 1080, 135, 1080, 135, 270, 270, 135, 270, 1080, 1080, 1080, 1080]
Prompts retrieved: 8505 . Total input tokens: 1856242 . Total output tokens: 1759055
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 0.7238652338273823,
    "estimated_duration": 3597.794139962386,
    "input_throughput": 177.40231240875633,
    "output_throughput": 169.66979661776367,
    "total_throughput": 347.07210902652,
    "itl": 18.09244123441277,
    "ttft": 9212.899795132054,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 2744,
    "finished_requests": 2737,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7239394630305469. Arrivals time: 0.020864580292254686 Scheduler time: 0.3000219687819481 Scheduler overhead time: 0.14824164379388094 Adapter cache time: 0.02815527142956853 Engine time: 0.14992843894287944 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_16_slots_16_rate_0.1-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_16_slots_16_rate_0.1-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [5 5 6]
Adapter prompts. [270, 135, 135, 270, 1080, 135, 1080, 135, 270, 270, 135, 270, 1080, 1080, 1080, 1080]
Prompts retrieved: 8505 . Total input tokens: 1856242 . Total output tokens: 1759055
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 0.722867663949728,
    "estimated_duration": 3597.794139962386,
    "input_throughput": 177.40231240875633,
    "output_throughput": 169.66979661776367,
    "total_throughput": 347.07210902652,
    "itl": 18.09243193765866,
    "ttft": 9212.922027165843,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 2744,
    "finished_requests": 2737,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7229983420111239. Arrivals time: 0.02076868014410138 Scheduler time: 0.300353966653347 Scheduler overhead time: 0.14784451061859727 Adapter cache time: 0.02813614532351494 Engine time: 0.1489479262381792 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-32/adapters_16_slots_16_rate_0.1-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-32/adapters_16_slots_16_rate_0.1-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [5 5 6]
Adapter prompts. [270, 135, 135, 270, 1080, 135, 1080, 135, 270, 270, 135, 270, 1080, 1080, 1080, 1080]
Prompts retrieved: 8505 . Total input tokens: 1856242 . Total output tokens: 1759055
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 0.7277595694176853,
    "estimated_duration": 3597.794139962386,
    "input_throughput": 177.40231240875633,
    "output_throughput": 169.66979661776367,
    "total_throughput": 347.07210902652,
    "itl": 18.09244837364127,
    "ttft": 9212.888219961795,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.0530347929522395,
    "arrivals": 2744,
    "finished_requests": 2737,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7278300463221967. Arrivals time: 0.0213600005954504 Scheduler time: 0.30284743197262287 Scheduler overhead time: 0.148877858184278 Adapter cache time: 0.028406723402440548 Engine time: 0.149833295494318 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_16_slots_16_rate_0.1-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_16_slots_16_rate_0.1-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [5 5 6]
Adapter prompts. [270, 135, 135, 270, 1080, 135, 1080, 135, 270, 270, 135, 270, 1080, 1080, 1080, 1080]
Prompts retrieved: 8505 . Total input tokens: 1856242 . Total output tokens: 1759055
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 0.7265879157930613,
    "estimated_duration": 3597.794139962386,
    "input_throughput": 177.40231240875633,
    "output_throughput": 169.66979661776367,
    "total_throughput": 347.07210902652,
    "itl": 18.092431341561888,
    "ttft": 9212.938233435647,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 2744,
    "finished_requests": 2737,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7266498017124832. Arrivals time: 0.02071100613102317 Scheduler time: 0.30191576946526766 Scheduler overhead time: 0.14833810972049832 Adapter cache time: 0.028116766829043627 Engine time: 0.15064708050340414 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-32/adapters_16_slots_16_rate_0.1-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-32/adapters_16_slots_16_rate_0.1-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [5 5 6]
Adapter prompts. [270, 135, 135, 270, 1080, 135, 1080, 135, 270, 270, 135, 270, 1080, 1080, 1080, 1080]
Prompts retrieved: 8505 . Total input tokens: 1856242 . Total output tokens: 1759055
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 0.7216491880826652,
    "estimated_duration": 3597.794139962386,
    "input_throughput": 177.40231240875633,
    "output_throughput": 169.66979661776367,
    "total_throughput": 347.07210902652,
    "itl": 18.09245024282226,
    "ttft": 9212.903022612309,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072867,
    "arrivals": 2744,
    "finished_requests": 2737,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7217410770244896. Arrivals time: 0.021129228174686432 Scheduler time: 0.2997656539082527 Scheduler overhead time: 0.14810063457116485 Adapter cache time: 0.027958962135016918 Engine time: 0.147629554849118 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_16_slots_16_rate_0.1-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_16_slots_16_rate_0.1-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [5 5 6]
Adapter prompts. [270, 66, 66, 270, 1080, 66, 1080, 66, 270, 270, 66, 270, 1080, 1080, 1080, 1080]
Prompts retrieved: 8160 . Total input tokens: 1782495 . Total output tokens: 1691602
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 0.7129218927584589,
    "estimated_duration": 3599.1890048211885,
    "input_throughput": 176.47169936038276,
    "output_throughput": 159.64040766693373,
    "total_throughput": 336.1121070273165,
    "itl": 17.99281531916634,
    "ttft": 9596.347912590863,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 2634,
    "finished_requests": 2627,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7129908218048513. Arrivals time: 0.021107072941958904 Scheduler time: 0.2910610572434962 Scheduler overhead time: 0.14690298400819302 Adapter cache time: 0.027874070685356855 Engine time: 0.15013661654666066 
