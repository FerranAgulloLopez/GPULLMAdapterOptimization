INFO 06-01 00:47:28 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:47:29 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-32/adapters_384_slots_160_rate_0.4-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-32/adapters_384_slots_160_rate_0.4-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 270, 135, 4320, 4320, 135, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 135, 4320, 135, 4320, 270, 270, 270, 135, 135, 270, 135, 4320, 135, 4320, 270, 4320, 270, 135, 270, 4320, 270, 4320, 135, 4320, 4320, 4320, 4320, 135, 270, 270, 270, 4320, 270, 135, 270, 135, 4320, 270, 4320, 4320, 270, 4320, 4320, 135, 135, 4320, 270, 270, 135, 135, 135, 270, 135, 270, 135, 4320, 135, 270, 4320, 135, 4320, 270, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 4320, 4320, 270, 135, 135, 4320, 270, 270, 135, 135, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 135, 270, 270, 270, 270, 135, 135, 4320, 135, 4320, 135, 135, 135, 270, 270, 4320, 135, 135, 4320, 135, 4320, 270, 135, 4320, 270, 270, 135, 4320, 4320, 4320, 135, 270, 4320, 135, 4320, 270, 270, 4320, 4320, 135, 270, 4320, 135, 270, 270, 135, 270, 135, 270, 4320, 4320, 270, 135, 4320, 135, 4320, 270, 270, 270, 270, 270, 135, 135, 4320, 135, 4320, 135, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 135, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 135, 135, 135, 135, 135, 270, 135, 135, 270, 4320, 4320, 135, 135, 4320, 135, 135, 135, 270, 135, 270, 4320, 4320, 270, 270, 135, 4320, 270, 4320, 135, 270, 270, 135, 135, 270, 135, 4320, 4320, 135, 4320, 4320, 135, 270, 4320, 135, 135, 270, 270, 135, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 4320, 270, 270, 270, 4320, 135, 270, 270, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 270, 135, 4320, 4320, 4320, 270, 135, 4320, 4320, 270, 270, 4320, 4320, 135, 4320, 4320, 270, 135, 4320, 270, 270, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 270, 4320, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 4320, 135, 135, 135, 270, 135, 270, 270, 135, 4320, 270, 4320, 135, 4320, 135, 270, 270, 270, 270, 135, 270, 4320, 4320, 135, 4320, 4320, 135, 4320, 270, 4320, 270, 270, 270, 135, 270, 135, 135, 4320, 135, 270, 135, 135, 270, 4320, 270, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 604800 . Total input tokens: 134855028 . Total output tokens: 120795858
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.572093679104,
    "estimated_duration": 3600.0402352761225,
    "input_throughput": 3609.242994753198,
    "output_throughput": 3181.598885413982,
    "total_throughput": 6790.84188016718,
    "itl": 158.45286981541594,
    "ttft": 2066029.2075650077,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3777,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.662133919782141,
    "arrivals": 200966,
    "finished_requests": 52197,
    "scheduler_time": 97.80069477930873
}
#Debug simulation 
Total elapsed time: 4.572165296878666. Arrivals time: 0.4116262011229992 Scheduler time: 3.983678298536688 Scheduler overhead time: 0.03542115120217204 Adapter cache time: 0.0891664563678205 Engine time: 0.035795402713119984 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_384_slots_160_rate_0.4-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_384_slots_160_rate_0.4-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 270, 66, 4320, 4320, 66, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 66, 4320, 66, 4320, 270, 270, 270, 66, 66, 270, 66, 4320, 66, 4320, 270, 4320, 270, 66, 270, 4320, 270, 4320, 66, 4320, 4320, 4320, 4320, 66, 270, 270, 270, 4320, 270, 66, 270, 66, 4320, 270, 4320, 4320, 270, 4320, 4320, 66, 66, 4320, 270, 270, 66, 66, 66, 270, 66, 270, 66, 4320, 66, 270, 4320, 66, 4320, 270, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 4320, 4320, 270, 66, 66, 4320, 270, 270, 66, 66, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 66, 270, 270, 270, 270, 66, 66, 4320, 66, 4320, 66, 66, 66, 270, 270, 4320, 66, 66, 4320, 66, 4320, 270, 66, 4320, 270, 270, 66, 4320, 4320, 4320, 66, 270, 4320, 66, 4320, 270, 270, 4320, 4320, 66, 270, 4320, 66, 270, 270, 66, 270, 66, 270, 4320, 4320, 270, 66, 4320, 66, 4320, 270, 270, 270, 270, 270, 66, 66, 4320, 66, 4320, 66, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 66, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 66, 66, 66, 66, 66, 270, 66, 66, 270, 4320, 4320, 66, 66, 4320, 66, 66, 66, 270, 66, 270, 4320, 4320, 270, 270, 66, 4320, 270, 4320, 66, 270, 270, 66, 66, 270, 66, 4320, 4320, 66, 4320, 4320, 66, 270, 4320, 66, 66, 270, 270, 66, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 4320, 270, 270, 270, 4320, 66, 270, 270, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 270, 66, 4320, 4320, 4320, 270, 66, 4320, 4320, 270, 270, 4320, 4320, 66, 4320, 4320, 270, 66, 4320, 270, 270, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 270, 4320, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 4320, 66, 66, 66, 270, 66, 270, 270, 66, 4320, 270, 4320, 66, 4320, 66, 270, 270, 270, 270, 66, 270, 4320, 4320, 66, 4320, 4320, 66, 4320, 270, 4320, 270, 270, 270, 66, 270, 66, 66, 4320, 66, 270, 66, 66, 270, 4320, 270, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 595968 . Total input tokens: 132907362 . Total output tokens: 119020776
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 5.898423638194799,
    "estimated_duration": 3600.1683472779614,
    "input_throughput": 4078.483721768675,
    "output_throughput": 3600.2713622545116,
    "total_throughput": 7678.755084023187,
    "itl": 237.60236663540337,
    "ttft": 1947019.7828627336,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1396,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.272440890530237,
    "arrivals": 198105,
    "finished_requests": 59401,
    "scheduler_time": 86.6867413838965
}
#Debug simulation 
Total elapsed time: 5.898611007258296. Arrivals time: 0.21151512768119574 Scheduler time: 5.589474817272276 Scheduler overhead time: 0.025996907614171505 Adapter cache time: 0.034277747850865126 Engine time: 0.025707995984703302 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_384_slots_160_rate_0.4-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_384_slots_160_rate_0.4-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 270, 66, 4320, 4320, 66, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 66, 4320, 66, 4320, 270, 270, 270, 66, 66, 270, 66, 4320, 66, 4320, 270, 4320, 270, 66, 270, 4320, 270, 4320, 66, 4320, 4320, 4320, 4320, 66, 270, 270, 270, 4320, 270, 66, 270, 66, 4320, 270, 4320, 4320, 270, 4320, 4320, 66, 66, 4320, 270, 270, 66, 66, 66, 270, 66, 270, 66, 4320, 66, 270, 4320, 66, 4320, 270, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 4320, 4320, 270, 66, 66, 4320, 270, 270, 66, 66, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 66, 270, 270, 270, 270, 66, 66, 4320, 66, 4320, 66, 66, 66, 270, 270, 4320, 66, 66, 4320, 66, 4320, 270, 66, 4320, 270, 270, 66, 4320, 4320, 4320, 66, 270, 4320, 66, 4320, 270, 270, 4320, 4320, 66, 270, 4320, 66, 270, 270, 66, 270, 66, 270, 4320, 4320, 270, 66, 4320, 66, 4320, 270, 270, 270, 270, 270, 66, 66, 4320, 66, 4320, 66, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 66, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 66, 66, 66, 66, 66, 270, 66, 66, 270, 4320, 4320, 66, 66, 4320, 66, 66, 66, 270, 66, 270, 4320, 4320, 270, 270, 66, 4320, 270, 4320, 66, 270, 270, 66, 66, 270, 66, 4320, 4320, 66, 4320, 4320, 66, 270, 4320, 66, 66, 270, 270, 66, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 4320, 270, 270, 270, 4320, 66, 270, 270, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 270, 66, 4320, 4320, 4320, 270, 66, 4320, 4320, 270, 270, 4320, 4320, 66, 4320, 4320, 270, 66, 4320, 270, 270, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 270, 4320, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 4320, 66, 66, 66, 270, 66, 270, 270, 66, 4320, 270, 4320, 66, 4320, 66, 270, 270, 270, 270, 66, 270, 4320, 4320, 66, 4320, 4320, 66, 4320, 270, 4320, 270, 270, 270, 66, 270, 66, 66, 4320, 66, 270, 66, 66, 270, 4320, 270, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 595968 . Total input tokens: 132907362 . Total output tokens: 119020776
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 5.953908991068602,
    "estimated_duration": 3600.001576774252,
    "input_throughput": 4078.542102516619,
    "output_throughput": 3600.7592562265327,
    "total_throughput": 7679.3013587431515,
    "itl": 237.63123186951145,
    "ttft": 1947147.6640563016,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1411,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.601814779485528,
    "arrivals": 198105,
    "finished_requests": 59404,
    "scheduler_time": 86.67555331801799
}
#Debug simulation 
Total elapsed time: 5.954004272352904. Arrivals time: 0.21335020288825035 Scheduler time: 5.643992844037712 Scheduler overhead time: 0.025719687342643738 Adapter cache time: 0.03363936161622405 Engine time: 0.025750153232365847 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-32/adapters_384_slots_160_rate_0.4-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-32/adapters_384_slots_160_rate_0.4-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 270, 66, 4320, 4320, 66, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 66, 4320, 66, 4320, 270, 270, 270, 66, 66, 270, 66, 4320, 66, 4320, 270, 4320, 270, 66, 270, 4320, 270, 4320, 66, 4320, 4320, 4320, 4320, 66, 270, 270, 270, 4320, 270, 66, 270, 66, 4320, 270, 4320, 4320, 270, 4320, 4320, 66, 66, 4320, 270, 270, 66, 66, 66, 270, 66, 270, 66, 4320, 66, 270, 4320, 66, 4320, 270, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 4320, 4320, 270, 66, 66, 4320, 270, 270, 66, 66, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 66, 270, 270, 270, 270, 66, 66, 4320, 66, 4320, 66, 66, 66, 270, 270, 4320, 66, 66, 4320, 66, 4320, 270, 66, 4320, 270, 270, 66, 4320, 4320, 4320, 66, 270, 4320, 66, 4320, 270, 270, 4320, 4320, 66, 270, 4320, 66, 270, 270, 66, 270, 66, 270, 4320, 4320, 270, 66, 4320, 66, 4320, 270, 270, 270, 270, 270, 66, 66, 4320, 66, 4320, 66, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 66, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 66, 66, 66, 66, 66, 270, 66, 66, 270, 4320, 4320, 66, 66, 4320, 66, 66, 66, 270, 66, 270, 4320, 4320, 270, 270, 66, 4320, 270, 4320, 66, 270, 270, 66, 66, 270, 66, 4320, 4320, 66, 4320, 4320, 66, 270, 4320, 66, 66, 270, 270, 66, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 4320, 270, 270, 270, 4320, 66, 270, 270, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 270, 66, 4320, 4320, 4320, 270, 66, 4320, 4320, 270, 270, 4320, 4320, 66, 4320, 4320, 270, 66, 4320, 270, 270, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 270, 4320, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 4320, 66, 66, 66, 270, 66, 270, 270, 66, 4320, 270, 4320, 66, 4320, 66, 270, 270, 270, 270, 66, 270, 4320, 4320, 66, 4320, 4320, 66, 4320, 270, 4320, 270, 270, 270, 66, 270, 66, 66, 4320, 66, 270, 66, 66, 270, 4320, 270, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 595968 . Total input tokens: 132907362 . Total output tokens: 119020776
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.185332372318953,
    "estimated_duration": 3600.040138679508,
    "input_throughput": 3609.6516981520426,
    "output_throughput": 3190.648869879886,
    "total_throughput": 6800.300568031928,
    "itl": 158.7851224772484,
    "ttft": 2056639.7100150671,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3653,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.953673646002285,
    "arrivals": 198105,
    "finished_requests": 52475,
    "scheduler_time": 97.74303003652646
}
#Debug simulation 
Total elapsed time: 4.18549055699259. Arrivals time: 0.18860494252294302 Scheduler time: 3.8228547484613955 Scheduler overhead time: 0.03524202946573496 Adapter cache time: 0.08678045123815536 Engine time: 0.035705562215298414 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_384_slots_160_rate_0.4-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_384_slots_160_rate_0.4-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 270, 66, 4320, 4320, 66, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 66, 4320, 66, 4320, 270, 270, 270, 66, 66, 270, 66, 4320, 66, 4320, 270, 4320, 270, 66, 270, 4320, 270, 4320, 66, 4320, 4320, 4320, 4320, 66, 270, 270, 270, 4320, 270, 66, 270, 66, 4320, 270, 4320, 4320, 270, 4320, 4320, 66, 66, 4320, 270, 270, 66, 66, 66, 270, 66, 270, 66, 4320, 66, 270, 4320, 66, 4320, 270, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 4320, 4320, 270, 66, 66, 4320, 270, 270, 66, 66, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 66, 270, 270, 270, 270, 66, 66, 4320, 66, 4320, 66, 66, 66, 270, 270, 4320, 66, 66, 4320, 66, 4320, 270, 66, 4320, 270, 270, 66, 4320, 4320, 4320, 66, 270, 4320, 66, 4320, 270, 270, 4320, 4320, 66, 270, 4320, 66, 270, 270, 66, 270, 66, 270, 4320, 4320, 270, 66, 4320, 66, 4320, 270, 270, 270, 270, 270, 66, 66, 4320, 66, 4320, 66, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 66, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 66, 66, 66, 66, 66, 270, 66, 66, 270, 4320, 4320, 66, 66, 4320, 66, 66, 66, 270, 66, 270, 4320, 4320, 270, 270, 66, 4320, 270, 4320, 66, 270, 270, 66, 66, 270, 66, 4320, 4320, 66, 4320, 4320, 66, 270, 4320, 66, 66, 270, 270, 66, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 4320, 270, 270, 270, 4320, 66, 270, 270, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 270, 66, 4320, 4320, 4320, 270, 66, 4320, 4320, 270, 270, 4320, 4320, 66, 4320, 4320, 270, 66, 4320, 270, 270, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 270, 4320, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 4320, 66, 66, 66, 270, 66, 270, 270, 66, 4320, 270, 4320, 66, 4320, 66, 270, 270, 270, 270, 66, 270, 4320, 4320, 66, 4320, 4320, 66, 4320, 270, 4320, 270, 270, 270, 66, 270, 66, 66, 4320, 66, 270, 66, 66, 270, 4320, 270, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 595968 . Total input tokens: 132907362 . Total output tokens: 119020776
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 5.941257196944207,
    "estimated_duration": 3600.1073519249258,
    "input_throughput": 4078.4394921305075,
    "output_throughput": 3600.3079166707835,
    "total_throughput": 7678.7474088012905,
    "itl": 237.6085057519033,
    "ttft": 1947023.91739352,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1395,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.35539665000506,
    "arrivals": 198105,
    "finished_requests": 59399,
    "scheduler_time": 86.68343099988627
}
#Debug simulation 
Total elapsed time: 5.941386049147695. Arrivals time: 0.217633418738842 Scheduler time: 5.6267740349285305 Scheduler overhead time: 0.025808095932006836 Adapter cache time: 0.03382448246702552 Engine time: 0.025712367612868547 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-32/adapters_384_slots_160_rate_0.4-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-32/adapters_384_slots_160_rate_0.4-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 270, 66, 4320, 4320, 66, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 66, 4320, 66, 4320, 270, 270, 270, 66, 66, 270, 66, 4320, 66, 4320, 270, 4320, 270, 66, 270, 4320, 270, 4320, 66, 4320, 4320, 4320, 4320, 66, 270, 270, 270, 4320, 270, 66, 270, 66, 4320, 270, 4320, 4320, 270, 4320, 4320, 66, 66, 4320, 270, 270, 66, 66, 66, 270, 66, 270, 66, 4320, 66, 270, 4320, 66, 4320, 270, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 4320, 4320, 270, 66, 66, 4320, 270, 270, 66, 66, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 66, 270, 270, 270, 270, 66, 66, 4320, 66, 4320, 66, 66, 66, 270, 270, 4320, 66, 66, 4320, 66, 4320, 270, 66, 4320, 270, 270, 66, 4320, 4320, 4320, 66, 270, 4320, 66, 4320, 270, 270, 4320, 4320, 66, 270, 4320, 66, 270, 270, 66, 270, 66, 270, 4320, 4320, 270, 66, 4320, 66, 4320, 270, 270, 270, 270, 270, 66, 66, 4320, 66, 4320, 66, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 66, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 66, 66, 66, 66, 66, 270, 66, 66, 270, 4320, 4320, 66, 66, 4320, 66, 66, 66, 270, 66, 270, 4320, 4320, 270, 270, 66, 4320, 270, 4320, 66, 270, 270, 66, 66, 270, 66, 4320, 4320, 66, 4320, 4320, 66, 270, 4320, 66, 66, 270, 270, 66, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 4320, 270, 270, 270, 4320, 66, 270, 270, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 270, 66, 4320, 4320, 4320, 270, 66, 4320, 4320, 270, 270, 4320, 4320, 66, 4320, 4320, 270, 66, 4320, 270, 270, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 270, 4320, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 4320, 66, 66, 66, 270, 66, 270, 270, 66, 4320, 270, 4320, 66, 4320, 66, 270, 270, 270, 270, 66, 270, 4320, 4320, 66, 4320, 4320, 66, 4320, 270, 4320, 270, 270, 270, 66, 270, 66, 66, 4320, 66, 270, 66, 66, 270, 4320, 270, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 595968 . Total input tokens: 132907362 . Total output tokens: 119020776
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 4.1721978248097,
    "estimated_duration": 3600.017946542651,
    "input_throughput": 3609.6800607563428,
    "output_throughput": 3190.3310401633103,
    "total_throughput": 6800.0111009196535,
    "itl": 158.78536985110617,
    "ttft": 2056484.498656224,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3645,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.083665405008198,
    "arrivals": 198105,
    "finished_requests": 52474,
    "scheduler_time": 97.74291871661606
}
#Debug simulation 
Total elapsed time: 4.172335215844214. Arrivals time: 0.18615176947787404 Scheduler time: 3.8132087234407663 Scheduler overhead time: 0.03512398758903146 Adapter cache time: 0.0862113987095654 Engine time: 0.0353599158115685 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_384_slots_160_rate_0.4-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_384_slots_160_rate_0.4-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 270, 66, 4320, 4320, 66, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 66, 4320, 66, 4320, 270, 270, 270, 66, 66, 270, 66, 4320, 66, 4320, 270, 4320, 270, 66, 270, 4320, 270, 4320, 66, 4320, 4320, 4320, 4320, 66, 270, 270, 270, 4320, 270, 66, 270, 66, 4320, 270, 4320, 4320, 270, 4320, 4320, 66, 66, 4320, 270, 270, 66, 66, 66, 270, 66, 270, 66, 4320, 66, 270, 4320, 66, 4320, 270, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 4320, 4320, 270, 66, 66, 4320, 270, 270, 66, 66, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 66, 270, 270, 270, 270, 66, 66, 4320, 66, 4320, 66, 66, 66, 270, 270, 4320, 66, 66, 4320, 66, 4320, 270, 66, 4320, 270, 270, 66, 4320, 4320, 4320, 66, 270, 4320, 66, 4320, 270, 270, 4320, 4320, 66, 270, 4320, 66, 270, 270, 66, 270, 66, 270, 4320, 4320, 270, 66, 4320, 66, 4320, 270, 270, 270, 270, 270, 66, 66, 4320, 66, 4320, 66, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 66, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 66, 66, 66, 66, 66, 270, 66, 66, 270, 4320, 4320, 66, 66, 4320, 66, 66, 66, 270, 66, 270, 4320, 4320, 270, 270, 66, 4320, 270, 4320, 66, 270, 270, 66, 66, 270, 66, 4320, 4320, 66, 4320, 4320, 66, 270, 4320, 66, 66, 270, 270, 66, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 4320, 270, 270, 270, 4320, 66, 270, 270, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 270, 66, 4320, 4320, 4320, 270, 66, 4320, 4320, 270, 270, 4320, 4320, 66, 4320, 4320, 270, 66, 4320, 270, 270, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 270, 4320, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 4320, 66, 66, 66, 270, 66, 270, 270, 66, 4320, 270, 4320, 66, 4320, 66, 270, 270, 270, 270, 66, 270, 4320, 4320, 66, 4320, 4320, 66, 4320, 270, 4320, 270, 270, 270, 66, 270, 66, 66, 4320, 66, 270, 66, 66, 270, 4320, 270, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 595968 . Total input tokens: 132907362 . Total output tokens: 119020776
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 5.921964489854872,
    "estimated_duration": 3600.0684220137387,
    "input_throughput": 4078.5124833230093,
    "output_throughput": 3600.2599063797843,
    "total_throughput": 7678.772389702794,
    "itl": 237.59716121323117,
    "ttft": 1946994.804451884,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1396,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.174110211683326,
    "arrivals": 198105,
    "finished_requests": 59400,
    "scheduler_time": 86.68630462826671
}
#Debug simulation 
Total elapsed time: 5.922060867771506. Arrivals time: 0.22399942530319095 Scheduler time: 5.601254040841013 Scheduler overhead time: 0.025710480753332376 Adapter cache time: 0.033503169659525156 Engine time: 0.02599950786679983 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-32/adapters_384_slots_160_rate_0.4-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-32/adapters_384_slots_160_rate_0.4-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 270, 66, 4320, 4320, 66, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 66, 4320, 66, 4320, 270, 270, 270, 66, 66, 270, 66, 4320, 66, 4320, 270, 4320, 270, 66, 270, 4320, 270, 4320, 66, 4320, 4320, 4320, 4320, 66, 270, 270, 270, 4320, 270, 66, 270, 66, 4320, 270, 4320, 4320, 270, 4320, 4320, 66, 66, 4320, 270, 270, 66, 66, 66, 270, 66, 270, 66, 4320, 66, 270, 4320, 66, 4320, 270, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 4320, 4320, 270, 66, 66, 4320, 270, 270, 66, 66, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 66, 270, 270, 270, 270, 66, 66, 4320, 66, 4320, 66, 66, 66, 270, 270, 4320, 66, 66, 4320, 66, 4320, 270, 66, 4320, 270, 270, 66, 4320, 4320, 4320, 66, 270, 4320, 66, 4320, 270, 270, 4320, 4320, 66, 270, 4320, 66, 270, 270, 66, 270, 66, 270, 4320, 4320, 270, 66, 4320, 66, 4320, 270, 270, 270, 270, 270, 66, 66, 4320, 66, 4320, 66, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 66, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 66, 66, 66, 66, 66, 270, 66, 66, 270, 4320, 4320, 66, 66, 4320, 66, 66, 66, 270, 66, 270, 4320, 4320, 270, 270, 66, 4320, 270, 4320, 66, 270, 270, 66, 66, 270, 66, 4320, 4320, 66, 4320, 4320, 66, 270, 4320, 66, 66, 270, 270, 66, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 4320, 270, 270, 270, 4320, 66, 270, 270, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 270, 66, 4320, 4320, 4320, 270, 66, 4320, 4320, 270, 270, 4320, 4320, 66, 4320, 4320, 270, 66, 4320, 270, 270, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 270, 4320, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 4320, 66, 66, 66, 270, 66, 270, 270, 66, 4320, 270, 4320, 66, 4320, 66, 270, 270, 270, 270, 66, 270, 4320, 4320, 66, 4320, 4320, 66, 4320, 270, 4320, 270, 270, 270, 66, 270, 66, 66, 4320, 66, 270, 66, 66, 270, 4320, 270, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 595968 . Total input tokens: 132907362 . Total output tokens: 119020776
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.185090098064393,
    "estimated_duration": 3600.0692966021193,
    "input_throughput": 3609.3966336326635,
    "output_throughput": 3189.971373839704,
    "total_throughput": 6799.368007472368,
    "itl": 158.78518990333097,
    "ttft": 2056610.6519885147,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3649,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.253580454624442,
    "arrivals": 198105,
    "finished_requests": 52471,
    "scheduler_time": 97.73904681506004
}
#Debug simulation 
Total elapsed time: 4.185232313815504. Arrivals time: 0.19009745633229613 Scheduler time: 3.8208983782678843 Scheduler overhead time: 0.035382846370339394 Adapter cache time: 0.08690741891041398 Engine time: 0.03561369143426418 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_384_slots_160_rate_0.4-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_384_slots_160_rate_0.4-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 270, 33, 4320, 4320, 33, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 33, 4320, 33, 4320, 270, 270, 270, 33, 33, 270, 33, 4320, 33, 4320, 270, 4320, 270, 33, 270, 4320, 270, 4320, 33, 4320, 4320, 4320, 4320, 33, 270, 270, 270, 4320, 270, 33, 270, 33, 4320, 270, 4320, 4320, 270, 4320, 4320, 33, 33, 4320, 270, 270, 33, 33, 33, 270, 33, 270, 33, 4320, 33, 270, 4320, 33, 4320, 270, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 4320, 4320, 270, 33, 33, 4320, 270, 270, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 33, 270, 270, 270, 270, 33, 33, 4320, 33, 4320, 33, 33, 33, 270, 270, 4320, 33, 33, 4320, 33, 4320, 270, 33, 4320, 270, 270, 33, 4320, 4320, 4320, 33, 270, 4320, 33, 4320, 270, 270, 4320, 4320, 33, 270, 4320, 33, 270, 270, 33, 270, 33, 270, 4320, 4320, 270, 33, 4320, 33, 4320, 270, 270, 270, 270, 270, 33, 33, 4320, 33, 4320, 33, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 33, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 33, 33, 33, 33, 33, 270, 33, 33, 270, 4320, 4320, 33, 33, 4320, 33, 33, 33, 270, 33, 270, 4320, 4320, 270, 270, 33, 4320, 270, 4320, 33, 270, 270, 33, 33, 270, 33, 4320, 4320, 33, 4320, 4320, 33, 270, 4320, 33, 33, 270, 270, 33, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 4320, 270, 270, 270, 4320, 33, 270, 270, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 270, 33, 4320, 4320, 4320, 270, 33, 4320, 4320, 270, 270, 4320, 4320, 33, 4320, 4320, 270, 33, 4320, 270, 270, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 270, 4320, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 4320, 33, 33, 33, 270, 33, 270, 270, 33, 4320, 270, 4320, 33, 4320, 33, 270, 270, 270, 270, 33, 270, 4320, 4320, 33, 4320, 4320, 33, 4320, 270, 4320, 270, 270, 270, 33, 270, 33, 33, 4320, 33, 270, 33, 33, 270, 4320, 270, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 591744 . Total input tokens: 131952871 . Total output tokens: 118169411
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 5.368896247819066,
    "estimated_duration": 3600.1049078635897,
    "input_throughput": 4108.281113612596,
    "output_throughput": 3596.8435174530327,
    "total_throughput": 7705.124631065629,
    "itl": 236.88167879754212,
    "ttft": 1940257.8185054811,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1419,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.3428321086406925,
    "arrivals": 196756,
    "finished_requests": 59775,
    "scheduler_time": 86.68288947250187
}
#Debug simulation 
Total elapsed time: 5.36902519967407. Arrivals time: 0.2108612759038806 Scheduler time: 5.060244217980653 Scheduler overhead time: 0.0257811164483428 Adapter cache time: 0.03478089580312371 Engine time: 0.025716734118759632 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_384_slots_160_rate_0.4-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_384_slots_160_rate_0.4-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 270, 33, 4320, 4320, 33, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 33, 4320, 33, 4320, 270, 270, 270, 33, 33, 270, 33, 4320, 33, 4320, 270, 4320, 270, 33, 270, 4320, 270, 4320, 33, 4320, 4320, 4320, 4320, 33, 270, 270, 270, 4320, 270, 33, 270, 33, 4320, 270, 4320, 4320, 270, 4320, 4320, 33, 33, 4320, 270, 270, 33, 33, 33, 270, 33, 270, 33, 4320, 33, 270, 4320, 33, 4320, 270, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 4320, 4320, 270, 33, 33, 4320, 270, 270, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 33, 270, 270, 270, 270, 33, 33, 4320, 33, 4320, 33, 33, 33, 270, 270, 4320, 33, 33, 4320, 33, 4320, 270, 33, 4320, 270, 270, 33, 4320, 4320, 4320, 33, 270, 4320, 33, 4320, 270, 270, 4320, 4320, 33, 270, 4320, 33, 270, 270, 33, 270, 33, 270, 4320, 4320, 270, 33, 4320, 33, 4320, 270, 270, 270, 270, 270, 33, 33, 4320, 33, 4320, 33, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 33, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 33, 33, 33, 33, 33, 270, 33, 33, 270, 4320, 4320, 33, 33, 4320, 33, 33, 33, 270, 33, 270, 4320, 4320, 270, 270, 33, 4320, 270, 4320, 33, 270, 270, 33, 33, 270, 33, 4320, 4320, 33, 4320, 4320, 33, 270, 4320, 33, 33, 270, 270, 33, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 4320, 270, 270, 270, 4320, 33, 270, 270, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 270, 33, 4320, 4320, 4320, 270, 33, 4320, 4320, 270, 270, 4320, 4320, 33, 4320, 4320, 270, 33, 4320, 270, 270, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 270, 4320, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 4320, 33, 33, 33, 270, 33, 270, 270, 33, 4320, 270, 4320, 33, 4320, 33, 270, 270, 270, 270, 33, 270, 4320, 4320, 33, 4320, 4320, 33, 4320, 270, 4320, 270, 270, 270, 33, 270, 33, 33, 4320, 33, 270, 33, 33, 270, 4320, 270, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 591744 . Total input tokens: 131952871 . Total output tokens: 118169411
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 5.383773880079389,
    "estimated_duration": 3600.0869167615483,
    "input_throughput": 4108.360531835361,
    "output_throughput": 3596.4303916436734,
    "total_throughput": 7704.790923479035,
    "itl": 236.8922663364966,
    "ttft": 1940451.516439905,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1418,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.6239709175051615,
    "arrivals": 196756,
    "finished_requests": 59773,
    "scheduler_time": 86.67666232909936
}
#Debug simulation 
Total elapsed time: 5.3839132292196155. Arrivals time: 0.22094956040382385 Scheduler time: 5.065570359583944 Scheduler overhead time: 0.02559731062501669 Adapter cache time: 0.03423639899119735 Engine time: 0.025840019807219505 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-32/adapters_384_slots_160_rate_0.4-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-32/adapters_384_slots_160_rate_0.4-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 270, 33, 4320, 4320, 33, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 33, 4320, 33, 4320, 270, 270, 270, 33, 33, 270, 33, 4320, 33, 4320, 270, 4320, 270, 33, 270, 4320, 270, 4320, 33, 4320, 4320, 4320, 4320, 33, 270, 270, 270, 4320, 270, 33, 270, 33, 4320, 270, 4320, 4320, 270, 4320, 4320, 33, 33, 4320, 270, 270, 33, 33, 33, 270, 33, 270, 33, 4320, 33, 270, 4320, 33, 4320, 270, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 4320, 4320, 270, 33, 33, 4320, 270, 270, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 33, 270, 270, 270, 270, 33, 33, 4320, 33, 4320, 33, 33, 33, 270, 270, 4320, 33, 33, 4320, 33, 4320, 270, 33, 4320, 270, 270, 33, 4320, 4320, 4320, 33, 270, 4320, 33, 4320, 270, 270, 4320, 4320, 33, 270, 4320, 33, 270, 270, 33, 270, 33, 270, 4320, 4320, 270, 33, 4320, 33, 4320, 270, 270, 270, 270, 270, 33, 33, 4320, 33, 4320, 33, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 33, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 33, 33, 33, 33, 33, 270, 33, 33, 270, 4320, 4320, 33, 33, 4320, 33, 33, 33, 270, 33, 270, 4320, 4320, 270, 270, 33, 4320, 270, 4320, 33, 270, 270, 33, 33, 270, 33, 4320, 4320, 33, 4320, 4320, 33, 270, 4320, 33, 33, 270, 270, 33, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 4320, 270, 270, 270, 4320, 33, 270, 270, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 270, 33, 4320, 4320, 4320, 270, 33, 4320, 4320, 270, 270, 4320, 4320, 33, 4320, 4320, 270, 33, 4320, 270, 270, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 270, 4320, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 4320, 33, 33, 33, 270, 33, 270, 270, 33, 4320, 270, 4320, 33, 4320, 33, 270, 270, 270, 270, 33, 270, 4320, 4320, 33, 4320, 4320, 33, 4320, 270, 4320, 270, 270, 270, 33, 270, 33, 33, 4320, 33, 270, 33, 33, 270, 4320, 270, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 591744 . Total input tokens: 131952871 . Total output tokens: 118169411
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.1583336079493165,
    "estimated_duration": 3600.159986266865,
    "input_throughput": 3650.5641555191132,
    "output_throughput": 3209.702636571508,
    "total_throughput": 6860.2667920906215,
    "itl": 158.58595669750602,
    "ttft": 2042150.1776857018,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3361,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.991108940857849,
    "arrivals": 196756,
    "finished_requests": 53099,
    "scheduler_time": 98.03359856152488
}
#Debug simulation 
Total elapsed time: 4.1584273050539196. Arrivals time: 0.18846371164545417 Scheduler time: 3.796706209424883 Scheduler overhead time: 0.03519113780930638 Adapter cache time: 0.0859204106964171 Engine time: 0.03565722843632102 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_384_slots_160_rate_0.4-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_384_slots_160_rate_0.4-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 270, 33, 4320, 4320, 33, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 33, 4320, 33, 4320, 270, 270, 270, 33, 33, 270, 33, 4320, 33, 4320, 270, 4320, 270, 33, 270, 4320, 270, 4320, 33, 4320, 4320, 4320, 4320, 33, 270, 270, 270, 4320, 270, 33, 270, 33, 4320, 270, 4320, 4320, 270, 4320, 4320, 33, 33, 4320, 270, 270, 33, 33, 33, 270, 33, 270, 33, 4320, 33, 270, 4320, 33, 4320, 270, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 4320, 4320, 270, 33, 33, 4320, 270, 270, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 33, 270, 270, 270, 270, 33, 33, 4320, 33, 4320, 33, 33, 33, 270, 270, 4320, 33, 33, 4320, 33, 4320, 270, 33, 4320, 270, 270, 33, 4320, 4320, 4320, 33, 270, 4320, 33, 4320, 270, 270, 4320, 4320, 33, 270, 4320, 33, 270, 270, 33, 270, 33, 270, 4320, 4320, 270, 33, 4320, 33, 4320, 270, 270, 270, 270, 270, 33, 33, 4320, 33, 4320, 33, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 33, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 33, 33, 33, 33, 33, 270, 33, 33, 270, 4320, 4320, 33, 33, 4320, 33, 33, 33, 270, 33, 270, 4320, 4320, 270, 270, 33, 4320, 270, 4320, 33, 270, 270, 33, 33, 270, 33, 4320, 4320, 33, 4320, 4320, 33, 270, 4320, 33, 33, 270, 270, 33, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 4320, 270, 270, 270, 4320, 33, 270, 270, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 270, 33, 4320, 4320, 4320, 270, 33, 4320, 4320, 270, 270, 4320, 4320, 33, 4320, 4320, 270, 33, 4320, 270, 270, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 270, 4320, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 4320, 33, 33, 33, 270, 33, 270, 270, 33, 4320, 270, 4320, 33, 4320, 33, 270, 270, 270, 270, 33, 270, 4320, 4320, 33, 4320, 4320, 33, 4320, 270, 4320, 270, 270, 270, 33, 270, 33, 33, 4320, 33, 270, 33, 33, 270, 4320, 270, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 591744 . Total input tokens: 131952871 . Total output tokens: 118169411
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 5.405805273912847,
    "estimated_duration": 3600.1392270292226,
    "input_throughput": 4108.325836110766,
    "output_throughput": 3596.952557494768,
    "total_throughput": 7705.278393605535,
    "itl": 236.89757684843997,
    "ttft": 1940262.6674682205,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1421,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.442535649996641,
    "arrivals": 196756,
    "finished_requests": 59767,
    "scheduler_time": 86.6807080054563
}
#Debug simulation 
Total elapsed time: 5.40595271717757. Arrivals time: 0.2201894144527614 Scheduler time: 5.086812454741448 Scheduler overhead time: 0.025843308307230473 Adapter cache time: 0.03537699347361922 Engine time: 0.026027329731732607 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-32/adapters_384_slots_160_rate_0.4-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-32/adapters_384_slots_160_rate_0.4-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 270, 33, 4320, 4320, 33, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 33, 4320, 33, 4320, 270, 270, 270, 33, 33, 270, 33, 4320, 33, 4320, 270, 4320, 270, 33, 270, 4320, 270, 4320, 33, 4320, 4320, 4320, 4320, 33, 270, 270, 270, 4320, 270, 33, 270, 33, 4320, 270, 4320, 4320, 270, 4320, 4320, 33, 33, 4320, 270, 270, 33, 33, 33, 270, 33, 270, 33, 4320, 33, 270, 4320, 33, 4320, 270, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 4320, 4320, 270, 33, 33, 4320, 270, 270, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 33, 270, 270, 270, 270, 33, 33, 4320, 33, 4320, 33, 33, 33, 270, 270, 4320, 33, 33, 4320, 33, 4320, 270, 33, 4320, 270, 270, 33, 4320, 4320, 4320, 33, 270, 4320, 33, 4320, 270, 270, 4320, 4320, 33, 270, 4320, 33, 270, 270, 33, 270, 33, 270, 4320, 4320, 270, 33, 4320, 33, 4320, 270, 270, 270, 270, 270, 33, 33, 4320, 33, 4320, 33, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 33, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 33, 33, 33, 33, 33, 270, 33, 33, 270, 4320, 4320, 33, 33, 4320, 33, 33, 33, 270, 33, 270, 4320, 4320, 270, 270, 33, 4320, 270, 4320, 33, 270, 270, 33, 33, 270, 33, 4320, 4320, 33, 4320, 4320, 33, 270, 4320, 33, 33, 270, 270, 33, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 4320, 270, 270, 270, 4320, 33, 270, 270, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 270, 33, 4320, 4320, 4320, 270, 33, 4320, 4320, 270, 270, 4320, 4320, 33, 4320, 4320, 270, 33, 4320, 270, 270, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 270, 4320, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 4320, 33, 33, 33, 270, 33, 270, 270, 33, 4320, 270, 4320, 33, 4320, 33, 270, 270, 270, 270, 33, 270, 4320, 4320, 33, 4320, 4320, 33, 4320, 270, 4320, 270, 270, 270, 33, 270, 33, 33, 4320, 33, 270, 33, 33, 270, 4320, 270, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 591744 . Total input tokens: 131952871 . Total output tokens: 118169411
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 4.126917962916195,
    "estimated_duration": 3600.1101585169804,
    "input_throughput": 3650.5652386519914,
    "output_throughput": 3209.746505301415,
    "total_throughput": 6860.311743953406,
    "itl": 158.59245378093584,
    "ttft": 2042112.6088824773,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3367,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.143252110424768,
    "arrivals": 196756,
    "finished_requests": 53098,
    "scheduler_time": 98.03032636857213
}
#Debug simulation 
Total elapsed time: 4.127012963872403. Arrivals time: 0.19103235378861427 Scheduler time: 3.7635457077994943 Scheduler overhead time: 0.03527379734441638 Adapter cache time: 0.08531895885244012 Engine time: 0.035608531441539526 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_384_slots_160_rate_0.4-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_384_slots_160_rate_0.4-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 270, 33, 4320, 4320, 33, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 33, 4320, 33, 4320, 270, 270, 270, 33, 33, 270, 33, 4320, 33, 4320, 270, 4320, 270, 33, 270, 4320, 270, 4320, 33, 4320, 4320, 4320, 4320, 33, 270, 270, 270, 4320, 270, 33, 270, 33, 4320, 270, 4320, 4320, 270, 4320, 4320, 33, 33, 4320, 270, 270, 33, 33, 33, 270, 33, 270, 33, 4320, 33, 270, 4320, 33, 4320, 270, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 4320, 4320, 270, 33, 33, 4320, 270, 270, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 33, 270, 270, 270, 270, 33, 33, 4320, 33, 4320, 33, 33, 33, 270, 270, 4320, 33, 33, 4320, 33, 4320, 270, 33, 4320, 270, 270, 33, 4320, 4320, 4320, 33, 270, 4320, 33, 4320, 270, 270, 4320, 4320, 33, 270, 4320, 33, 270, 270, 33, 270, 33, 270, 4320, 4320, 270, 33, 4320, 33, 4320, 270, 270, 270, 270, 270, 33, 33, 4320, 33, 4320, 33, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 33, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 33, 33, 33, 33, 33, 270, 33, 33, 270, 4320, 4320, 33, 33, 4320, 33, 33, 33, 270, 33, 270, 4320, 4320, 270, 270, 33, 4320, 270, 4320, 33, 270, 270, 33, 33, 270, 33, 4320, 4320, 33, 4320, 4320, 33, 270, 4320, 33, 33, 270, 270, 33, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 4320, 270, 270, 270, 4320, 33, 270, 270, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 270, 33, 4320, 4320, 4320, 270, 33, 4320, 4320, 270, 270, 4320, 4320, 33, 4320, 4320, 270, 33, 4320, 270, 270, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 270, 4320, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 4320, 33, 33, 33, 270, 33, 270, 270, 33, 4320, 270, 4320, 33, 4320, 33, 270, 270, 270, 270, 33, 270, 4320, 4320, 33, 4320, 4320, 33, 4320, 270, 4320, 270, 270, 270, 33, 270, 33, 33, 4320, 33, 270, 33, 33, 270, 4320, 270, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 591744 . Total input tokens: 131952871 . Total output tokens: 118169411
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 5.374814851209521,
    "estimated_duration": 3600.023859888258,
    "input_throughput": 4108.676102068699,
    "output_throughput": 3597.4789345985027,
    "total_throughput": 7706.155036667202,
    "itl": 236.8885757954661,
    "ttft": 1940251.0677885218,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1421,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.2488614690558775,
    "arrivals": 196756,
    "finished_requests": 59778,
    "scheduler_time": 86.6819424823919
}
#Debug simulation 
Total elapsed time: 5.374967533163726. Arrivals time: 0.22599170776084065 Scheduler time: 5.050226389430463 Scheduler overhead time: 0.02577862609177828 Adapter cache time: 0.035291999112814665 Engine time: 0.025972103234380484 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-32/adapters_384_slots_160_rate_0.4-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-32/adapters_384_slots_160_rate_0.4-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 270, 33, 4320, 4320, 33, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 33, 4320, 33, 4320, 270, 270, 270, 33, 33, 270, 33, 4320, 33, 4320, 270, 4320, 270, 33, 270, 4320, 270, 4320, 33, 4320, 4320, 4320, 4320, 33, 270, 270, 270, 4320, 270, 33, 270, 33, 4320, 270, 4320, 4320, 270, 4320, 4320, 33, 33, 4320, 270, 270, 33, 33, 33, 270, 33, 270, 33, 4320, 33, 270, 4320, 33, 4320, 270, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 4320, 4320, 270, 33, 33, 4320, 270, 270, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 33, 270, 270, 270, 270, 33, 33, 4320, 33, 4320, 33, 33, 33, 270, 270, 4320, 33, 33, 4320, 33, 4320, 270, 33, 4320, 270, 270, 33, 4320, 4320, 4320, 33, 270, 4320, 33, 4320, 270, 270, 4320, 4320, 33, 270, 4320, 33, 270, 270, 33, 270, 33, 270, 4320, 4320, 270, 33, 4320, 33, 4320, 270, 270, 270, 270, 270, 33, 33, 4320, 33, 4320, 33, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 33, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 33, 33, 33, 33, 33, 270, 33, 33, 270, 4320, 4320, 33, 33, 4320, 33, 33, 33, 270, 33, 270, 4320, 4320, 270, 270, 33, 4320, 270, 4320, 33, 270, 270, 33, 33, 270, 33, 4320, 4320, 33, 4320, 4320, 33, 270, 4320, 33, 33, 270, 270, 33, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 4320, 270, 270, 270, 4320, 33, 270, 270, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 270, 33, 4320, 4320, 4320, 270, 33, 4320, 4320, 270, 270, 4320, 4320, 33, 4320, 4320, 270, 33, 4320, 270, 270, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 270, 4320, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 4320, 33, 33, 33, 270, 33, 270, 270, 33, 4320, 270, 4320, 33, 4320, 33, 270, 270, 270, 270, 33, 270, 4320, 4320, 33, 4320, 4320, 33, 4320, 270, 4320, 270, 270, 270, 33, 270, 33, 33, 4320, 33, 270, 33, 33, 270, 4320, 270, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 591744 . Total input tokens: 131952871 . Total output tokens: 118169411
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.3956676460802555,
    "estimated_duration": 3600.0555831924094,
    "input_throughput": 3650.488915047846,
    "output_throughput": 3209.356003818814,
    "total_throughput": 6859.84491886666,
    "itl": 158.6041008994256,
    "ttft": 2042305.0370215457,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3361,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.272871737963793,
    "arrivals": 196756,
    "finished_requests": 53092,
    "scheduler_time": 98.02229329562438
}
#Debug simulation 
Total elapsed time: 4.3957409569993615. Arrivals time: 0.42539362190291286 Scheduler time: 3.79620668431744 Scheduler overhead time: 0.03526233462616801 Adapter cache time: 0.08658494520932436 Engine time: 0.03597909398376942 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_384_slots_160_rate_0.4-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_384_slots_160_rate_0.4-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 135, 66, 4320, 4320, 66, 135, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 66, 4320, 66, 4320, 135, 135, 135, 66, 66, 135, 66, 4320, 66, 4320, 135, 4320, 135, 66, 135, 4320, 135, 4320, 66, 4320, 4320, 4320, 4320, 66, 135, 135, 135, 4320, 135, 66, 135, 66, 4320, 135, 4320, 4320, 135, 4320, 4320, 66, 66, 4320, 135, 135, 66, 66, 66, 135, 66, 135, 66, 4320, 66, 135, 4320, 66, 4320, 135, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 4320, 4320, 135, 66, 66, 4320, 135, 135, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 135, 4320, 4320, 66, 135, 135, 135, 135, 66, 66, 4320, 66, 4320, 66, 66, 66, 135, 135, 4320, 66, 66, 4320, 66, 4320, 135, 66, 4320, 135, 135, 66, 4320, 4320, 4320, 66, 135, 4320, 66, 4320, 135, 135, 4320, 4320, 66, 135, 4320, 66, 135, 135, 66, 135, 66, 135, 4320, 4320, 135, 66, 4320, 66, 4320, 135, 135, 135, 135, 135, 66, 66, 4320, 66, 4320, 66, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 66, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 66, 66, 66, 66, 66, 135, 66, 66, 135, 4320, 4320, 66, 66, 4320, 66, 66, 66, 135, 66, 135, 4320, 4320, 135, 135, 66, 4320, 135, 4320, 66, 135, 135, 66, 66, 135, 66, 4320, 4320, 66, 4320, 4320, 66, 135, 4320, 66, 66, 135, 135, 66, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 4320, 135, 135, 135, 4320, 66, 135, 135, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 135, 66, 4320, 4320, 4320, 135, 66, 4320, 4320, 135, 135, 4320, 4320, 66, 4320, 4320, 135, 66, 4320, 135, 135, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 135, 4320, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 4320, 66, 66, 66, 135, 66, 135, 135, 66, 4320, 135, 4320, 66, 4320, 66, 135, 135, 135, 135, 66, 135, 4320, 4320, 66, 4320, 4320, 66, 4320, 135, 4320, 135, 135, 135, 66, 135, 66, 66, 4320, 66, 135, 66, 66, 135, 4320, 135, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 578688 . Total input tokens: 129047464 . Total output tokens: 115563730
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.816831339150667,
    "estimated_duration": 3600.238005036111,
    "input_throughput": 4080.3838466931165,
    "output_throughput": 3600.112543078939,
    "total_throughput": 7680.496389772055,
    "itl": 237.87741905401685,
    "ttft": 1935216.3104226321,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1809,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.536422328774508,
    "arrivals": 192504,
    "finished_requests": 59404,
    "scheduler_time": 86.43678385372128
}
#Debug simulation 
Total elapsed time: 4.817008982878178. Arrivals time: 0.21454234328120947 Scheduler time: 4.497880968730897 Scheduler overhead time: 0.025215829722583294 Adapter cache time: 0.04231633385643363 Engine time: 0.02542789001017809 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_384_slots_160_rate_0.4-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_384_slots_160_rate_0.4-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 135, 66, 4320, 4320, 66, 135, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 66, 4320, 66, 4320, 135, 135, 135, 66, 66, 135, 66, 4320, 66, 4320, 135, 4320, 135, 66, 135, 4320, 135, 4320, 66, 4320, 4320, 4320, 4320, 66, 135, 135, 135, 4320, 135, 66, 135, 66, 4320, 135, 4320, 4320, 135, 4320, 4320, 66, 66, 4320, 135, 135, 66, 66, 66, 135, 66, 135, 66, 4320, 66, 135, 4320, 66, 4320, 135, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 4320, 4320, 135, 66, 66, 4320, 135, 135, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 135, 4320, 4320, 66, 135, 135, 135, 135, 66, 66, 4320, 66, 4320, 66, 66, 66, 135, 135, 4320, 66, 66, 4320, 66, 4320, 135, 66, 4320, 135, 135, 66, 4320, 4320, 4320, 66, 135, 4320, 66, 4320, 135, 135, 4320, 4320, 66, 135, 4320, 66, 135, 135, 66, 135, 66, 135, 4320, 4320, 135, 66, 4320, 66, 4320, 135, 135, 135, 135, 135, 66, 66, 4320, 66, 4320, 66, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 66, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 66, 66, 66, 66, 66, 135, 66, 66, 135, 4320, 4320, 66, 66, 4320, 66, 66, 66, 135, 66, 135, 4320, 4320, 135, 135, 66, 4320, 135, 4320, 66, 135, 135, 66, 66, 135, 66, 4320, 4320, 66, 4320, 4320, 66, 135, 4320, 66, 66, 135, 135, 66, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 4320, 135, 135, 135, 4320, 66, 135, 135, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 135, 66, 4320, 4320, 4320, 135, 66, 4320, 4320, 135, 135, 4320, 4320, 66, 4320, 4320, 135, 66, 4320, 135, 135, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 135, 4320, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 4320, 66, 66, 66, 135, 66, 135, 135, 66, 4320, 135, 4320, 66, 4320, 66, 135, 135, 135, 135, 66, 135, 4320, 4320, 66, 4320, 4320, 66, 4320, 135, 4320, 135, 135, 135, 66, 135, 66, 66, 4320, 66, 135, 66, 66, 135, 4320, 135, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 578688 . Total input tokens: 129047464 . Total output tokens: 115563730
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.831610973924398,
    "estimated_duration": 3600.005056794915,
    "input_throughput": 4080.309268531344,
    "output_throughput": 3600.126609693907,
    "total_throughput": 7680.435878225251,
    "itl": 237.89730826285953,
    "ttft": 1935280.1343043763,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1810,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.899036653353667,
    "arrivals": 192504,
    "finished_requests": 59400,
    "scheduler_time": 86.42303971987792
}
#Debug simulation 
Total elapsed time: 4.831706201191992. Arrivals time: 0.212627736851573 Scheduler time: 4.515336634591222 Scheduler overhead time: 0.025261784438043833 Adapter cache time: 0.04139409959316254 Engine time: 0.025558761321008205 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-32/adapters_384_slots_160_rate_0.4-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-32/adapters_384_slots_160_rate_0.4-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 135, 66, 4320, 4320, 66, 135, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 66, 4320, 66, 4320, 135, 135, 135, 66, 66, 135, 66, 4320, 66, 4320, 135, 4320, 135, 66, 135, 4320, 135, 4320, 66, 4320, 4320, 4320, 4320, 66, 135, 135, 135, 4320, 135, 66, 135, 66, 4320, 135, 4320, 4320, 135, 4320, 4320, 66, 66, 4320, 135, 135, 66, 66, 66, 135, 66, 135, 66, 4320, 66, 135, 4320, 66, 4320, 135, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 4320, 4320, 135, 66, 66, 4320, 135, 135, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 135, 4320, 4320, 66, 135, 135, 135, 135, 66, 66, 4320, 66, 4320, 66, 66, 66, 135, 135, 4320, 66, 66, 4320, 66, 4320, 135, 66, 4320, 135, 135, 66, 4320, 4320, 4320, 66, 135, 4320, 66, 4320, 135, 135, 4320, 4320, 66, 135, 4320, 66, 135, 135, 66, 135, 66, 135, 4320, 4320, 135, 66, 4320, 66, 4320, 135, 135, 135, 135, 135, 66, 66, 4320, 66, 4320, 66, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 66, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 66, 66, 66, 66, 66, 135, 66, 66, 135, 4320, 4320, 66, 66, 4320, 66, 66, 66, 135, 66, 135, 4320, 4320, 135, 135, 66, 4320, 135, 4320, 66, 135, 135, 66, 66, 135, 66, 4320, 4320, 66, 4320, 4320, 66, 135, 4320, 66, 66, 135, 135, 66, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 4320, 135, 135, 135, 4320, 66, 135, 135, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 135, 66, 4320, 4320, 4320, 135, 66, 4320, 4320, 135, 135, 4320, 4320, 66, 4320, 4320, 135, 66, 4320, 135, 135, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 135, 4320, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 4320, 66, 66, 66, 135, 66, 135, 135, 66, 4320, 135, 4320, 66, 4320, 66, 135, 135, 135, 135, 66, 135, 4320, 4320, 66, 4320, 4320, 66, 4320, 135, 4320, 135, 135, 135, 66, 135, 66, 66, 4320, 66, 135, 66, 66, 135, 4320, 135, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 578688 . Total input tokens: 129047464 . Total output tokens: 115563730
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.225167620927095,
    "estimated_duration": 3600.043532573448,
    "input_throughput": 3738.988953385768,
    "output_throughput": 3310.42080246202,
    "total_throughput": 7049.409755847789,
    "itl": 152.69246817442234,
    "ttft": 2017310.3485510873,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2425,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.920129199512262,
    "arrivals": 192504,
    "finished_requests": 54459,
    "scheduler_time": 101.21074948182623
}
#Debug simulation 
Total elapsed time: 4.22531198291108. Arrivals time: 0.19569916324689984 Scheduler time: 3.864696306642145 Scheduler overhead time: 0.03600139170885086 Adapter cache time: 0.07560551399365067 Engine time: 0.036613601725548506 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_384_slots_160_rate_0.4-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_384_slots_160_rate_0.4-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 135, 66, 4320, 4320, 66, 135, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 66, 4320, 66, 4320, 135, 135, 135, 66, 66, 135, 66, 4320, 66, 4320, 135, 4320, 135, 66, 135, 4320, 135, 4320, 66, 4320, 4320, 4320, 4320, 66, 135, 135, 135, 4320, 135, 66, 135, 66, 4320, 135, 4320, 4320, 135, 4320, 4320, 66, 66, 4320, 135, 135, 66, 66, 66, 135, 66, 135, 66, 4320, 66, 135, 4320, 66, 4320, 135, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 4320, 4320, 135, 66, 66, 4320, 135, 135, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 135, 4320, 4320, 66, 135, 135, 135, 135, 66, 66, 4320, 66, 4320, 66, 66, 66, 135, 135, 4320, 66, 66, 4320, 66, 4320, 135, 66, 4320, 135, 135, 66, 4320, 4320, 4320, 66, 135, 4320, 66, 4320, 135, 135, 4320, 4320, 66, 135, 4320, 66, 135, 135, 66, 135, 66, 135, 4320, 4320, 135, 66, 4320, 66, 4320, 135, 135, 135, 135, 135, 66, 66, 4320, 66, 4320, 66, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 66, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 66, 66, 66, 66, 66, 135, 66, 66, 135, 4320, 4320, 66, 66, 4320, 66, 66, 66, 135, 66, 135, 4320, 4320, 135, 135, 66, 4320, 135, 4320, 66, 135, 135, 66, 66, 135, 66, 4320, 4320, 66, 4320, 4320, 66, 135, 4320, 66, 66, 135, 135, 66, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 4320, 135, 135, 135, 4320, 66, 135, 135, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 135, 66, 4320, 4320, 4320, 135, 66, 4320, 4320, 135, 135, 4320, 4320, 66, 4320, 4320, 135, 66, 4320, 135, 135, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 135, 4320, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 4320, 66, 66, 66, 135, 66, 135, 135, 66, 4320, 135, 4320, 66, 4320, 66, 135, 135, 135, 135, 66, 135, 4320, 4320, 66, 4320, 4320, 66, 4320, 135, 4320, 135, 135, 135, 66, 135, 66, 66, 4320, 66, 135, 66, 66, 135, 4320, 135, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 578688 . Total input tokens: 129047464 . Total output tokens: 115563730
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.814262634143233,
    "estimated_duration": 3600.156746163653,
    "input_throughput": 4080.3273400952753,
    "output_throughput": 3600.1646355569046,
    "total_throughput": 7680.4919756521795,
    "itl": 237.88409166882664,
    "ttft": 1935234.2353131806,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1809,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.648437840083926,
    "arrivals": 192504,
    "finished_requests": 59403,
    "scheduler_time": 86.43228524186347
}
#Debug simulation 
Total elapsed time: 4.814370709005743. Arrivals time: 0.21315459068864584 Scheduler time: 4.4971290631219745 Scheduler overhead time: 0.025457674637436867 Adapter cache time: 0.04147731373086572 Engine time: 0.025602783542126417 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-32/adapters_384_slots_160_rate_0.4-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-32/adapters_384_slots_160_rate_0.4-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 135, 66, 4320, 4320, 66, 135, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 66, 4320, 66, 4320, 135, 135, 135, 66, 66, 135, 66, 4320, 66, 4320, 135, 4320, 135, 66, 135, 4320, 135, 4320, 66, 4320, 4320, 4320, 4320, 66, 135, 135, 135, 4320, 135, 66, 135, 66, 4320, 135, 4320, 4320, 135, 4320, 4320, 66, 66, 4320, 135, 135, 66, 66, 66, 135, 66, 135, 66, 4320, 66, 135, 4320, 66, 4320, 135, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 4320, 4320, 135, 66, 66, 4320, 135, 135, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 135, 4320, 4320, 66, 135, 135, 135, 135, 66, 66, 4320, 66, 4320, 66, 66, 66, 135, 135, 4320, 66, 66, 4320, 66, 4320, 135, 66, 4320, 135, 135, 66, 4320, 4320, 4320, 66, 135, 4320, 66, 4320, 135, 135, 4320, 4320, 66, 135, 4320, 66, 135, 135, 66, 135, 66, 135, 4320, 4320, 135, 66, 4320, 66, 4320, 135, 135, 135, 135, 135, 66, 66, 4320, 66, 4320, 66, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 66, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 66, 66, 66, 66, 66, 135, 66, 66, 135, 4320, 4320, 66, 66, 4320, 66, 66, 66, 135, 66, 135, 4320, 4320, 135, 135, 66, 4320, 135, 4320, 66, 135, 135, 66, 66, 135, 66, 4320, 4320, 66, 4320, 4320, 66, 135, 4320, 66, 66, 135, 135, 66, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 4320, 135, 135, 135, 4320, 66, 135, 135, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 135, 66, 4320, 4320, 4320, 135, 66, 4320, 4320, 135, 135, 4320, 4320, 66, 4320, 4320, 135, 66, 4320, 135, 135, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 135, 4320, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 4320, 66, 66, 66, 135, 66, 135, 135, 66, 4320, 135, 4320, 66, 4320, 66, 135, 135, 135, 135, 66, 135, 4320, 4320, 66, 4320, 4320, 66, 4320, 135, 4320, 135, 135, 135, 66, 135, 66, 66, 4320, 66, 135, 66, 66, 135, 4320, 135, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 578688 . Total input tokens: 129047464 . Total output tokens: 115563730
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 4.223582576960325,
    "estimated_duration": 3600.091571065514,
    "input_throughput": 3740.3740249903085,
    "output_throughput": 3311.4132695440417,
    "total_throughput": 7051.787294534351,
    "itl": 152.95910484189164,
    "ttft": 2016851.0347444764,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2432,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.042254066485723,
    "arrivals": 192504,
    "finished_requests": 54481,
    "scheduler_time": 101.13567185178434
}
#Debug simulation 
Total elapsed time: 4.223720767069608. Arrivals time: 0.20675358269363642 Scheduler time: 3.8521155091002584 Scheduler overhead time: 0.03591229300945997 Adapter cache time: 0.07533103227615356 Engine time: 0.03683833125978708 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_384_slots_160_rate_0.4-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_384_slots_160_rate_0.4-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 135, 66, 4320, 4320, 66, 135, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 66, 4320, 66, 4320, 135, 135, 135, 66, 66, 135, 66, 4320, 66, 4320, 135, 4320, 135, 66, 135, 4320, 135, 4320, 66, 4320, 4320, 4320, 4320, 66, 135, 135, 135, 4320, 135, 66, 135, 66, 4320, 135, 4320, 4320, 135, 4320, 4320, 66, 66, 4320, 135, 135, 66, 66, 66, 135, 66, 135, 66, 4320, 66, 135, 4320, 66, 4320, 135, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 4320, 4320, 135, 66, 66, 4320, 135, 135, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 135, 4320, 4320, 66, 135, 135, 135, 135, 66, 66, 4320, 66, 4320, 66, 66, 66, 135, 135, 4320, 66, 66, 4320, 66, 4320, 135, 66, 4320, 135, 135, 66, 4320, 4320, 4320, 66, 135, 4320, 66, 4320, 135, 135, 4320, 4320, 66, 135, 4320, 66, 135, 135, 66, 135, 66, 135, 4320, 4320, 135, 66, 4320, 66, 4320, 135, 135, 135, 135, 135, 66, 66, 4320, 66, 4320, 66, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 66, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 66, 66, 66, 66, 66, 135, 66, 66, 135, 4320, 4320, 66, 66, 4320, 66, 66, 66, 135, 66, 135, 4320, 4320, 135, 135, 66, 4320, 135, 4320, 66, 135, 135, 66, 66, 135, 66, 4320, 4320, 66, 4320, 4320, 66, 135, 4320, 66, 66, 135, 135, 66, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 4320, 135, 135, 135, 4320, 66, 135, 135, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 135, 66, 4320, 4320, 4320, 135, 66, 4320, 4320, 135, 135, 4320, 4320, 66, 4320, 4320, 135, 66, 4320, 135, 135, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 135, 4320, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 4320, 66, 66, 66, 135, 66, 135, 135, 66, 4320, 135, 4320, 66, 4320, 66, 135, 135, 135, 135, 66, 135, 4320, 4320, 66, 4320, 4320, 66, 4320, 135, 4320, 135, 135, 135, 66, 135, 66, 66, 4320, 66, 135, 66, 66, 135, 4320, 135, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 578688 . Total input tokens: 129047464 . Total output tokens: 115563730
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.839251404162496,
    "estimated_duration": 3600.0472679388417,
    "input_throughput": 4080.600032902002,
    "output_throughput": 3600.3032836346047,
    "total_throughput": 7680.903316536607,
    "itl": 237.8671168104848,
    "ttft": 1935152.8589565628,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1810,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.411991033772782,
    "arrivals": 192504,
    "finished_requests": 59404,
    "scheduler_time": 86.43477556520745
}
#Debug simulation 
Total elapsed time: 4.839345206972212. Arrivals time: 0.2142503964714706 Scheduler time: 4.52128081349656 Scheduler overhead time: 0.025305410381406546 Adapter cache time: 0.04147509578615427 Engine time: 0.02549695735797286 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-32/adapters_384_slots_160_rate_0.4-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-32/adapters_384_slots_160_rate_0.4-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 135, 66, 4320, 4320, 66, 135, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 66, 4320, 66, 4320, 135, 135, 135, 66, 66, 135, 66, 4320, 66, 4320, 135, 4320, 135, 66, 135, 4320, 135, 4320, 66, 4320, 4320, 4320, 4320, 66, 135, 135, 135, 4320, 135, 66, 135, 66, 4320, 135, 4320, 4320, 135, 4320, 4320, 66, 66, 4320, 135, 135, 66, 66, 66, 135, 66, 135, 66, 4320, 66, 135, 4320, 66, 4320, 135, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 4320, 4320, 135, 66, 66, 4320, 135, 135, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 135, 4320, 4320, 66, 135, 135, 135, 135, 66, 66, 4320, 66, 4320, 66, 66, 66, 135, 135, 4320, 66, 66, 4320, 66, 4320, 135, 66, 4320, 135, 135, 66, 4320, 4320, 4320, 66, 135, 4320, 66, 4320, 135, 135, 4320, 4320, 66, 135, 4320, 66, 135, 135, 66, 135, 66, 135, 4320, 4320, 135, 66, 4320, 66, 4320, 135, 135, 135, 135, 135, 66, 66, 4320, 66, 4320, 66, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 66, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 66, 66, 66, 66, 66, 135, 66, 66, 135, 4320, 4320, 66, 66, 4320, 66, 66, 66, 135, 66, 135, 4320, 4320, 135, 135, 66, 4320, 135, 4320, 66, 135, 135, 66, 66, 135, 66, 4320, 4320, 66, 4320, 4320, 66, 135, 4320, 66, 66, 135, 135, 66, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 4320, 135, 135, 135, 4320, 66, 135, 135, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 135, 66, 4320, 4320, 4320, 135, 66, 4320, 4320, 135, 135, 4320, 4320, 66, 4320, 4320, 135, 66, 4320, 135, 135, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 135, 4320, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 4320, 66, 66, 66, 135, 66, 135, 135, 66, 4320, 135, 4320, 66, 4320, 66, 135, 135, 135, 135, 66, 135, 4320, 4320, 66, 4320, 4320, 66, 4320, 135, 4320, 135, 135, 135, 66, 135, 66, 66, 4320, 66, 135, 66, 66, 135, 4320, 135, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 578688 . Total input tokens: 129047464 . Total output tokens: 115563730
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.236779281869531,
    "estimated_duration": 3600.0277661640157,
    "input_throughput": 3740.8944804750804,
    "output_throughput": 3311.9536221534763,
    "total_throughput": 7052.848102628557,
    "itl": 153.11077871828135,
    "ttft": 2016632.2843755877,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2428,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.130002813040864,
    "arrivals": 192504,
    "finished_requests": 54490,
    "scheduler_time": 101.0900358688766
}
#Debug simulation 
Total elapsed time: 4.236915110144764. Arrivals time: 0.19417600985616446 Scheduler time: 3.879504053387791 Scheduler overhead time: 0.035731224343180656 Adapter cache time: 0.07412162143737078 Engine time: 0.036593067925423384 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_384_slots_160_rate_0.4-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_384_slots_160_rate_0.4-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 135, 33, 4320, 4320, 33, 135, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 33, 4320, 33, 4320, 135, 135, 135, 33, 33, 135, 33, 4320, 33, 4320, 135, 4320, 135, 33, 135, 4320, 135, 4320, 33, 4320, 4320, 4320, 4320, 33, 135, 135, 135, 4320, 135, 33, 135, 33, 4320, 135, 4320, 4320, 135, 4320, 4320, 33, 33, 4320, 135, 135, 33, 33, 33, 135, 33, 135, 33, 4320, 33, 135, 4320, 33, 4320, 135, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 4320, 4320, 135, 33, 33, 4320, 135, 135, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 135, 4320, 4320, 33, 135, 135, 135, 135, 33, 33, 4320, 33, 4320, 33, 33, 33, 135, 135, 4320, 33, 33, 4320, 33, 4320, 135, 33, 4320, 135, 135, 33, 4320, 4320, 4320, 33, 135, 4320, 33, 4320, 135, 135, 4320, 4320, 33, 135, 4320, 33, 135, 135, 33, 135, 33, 135, 4320, 4320, 135, 33, 4320, 33, 4320, 135, 135, 135, 135, 135, 33, 33, 4320, 33, 4320, 33, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 33, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 33, 33, 33, 33, 33, 135, 33, 33, 135, 4320, 4320, 33, 33, 4320, 33, 33, 33, 135, 33, 135, 4320, 4320, 135, 135, 33, 4320, 135, 4320, 33, 135, 135, 33, 33, 135, 33, 4320, 4320, 33, 4320, 4320, 33, 135, 4320, 33, 33, 135, 135, 33, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 4320, 135, 135, 135, 4320, 33, 135, 135, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 135, 33, 4320, 4320, 4320, 135, 33, 4320, 4320, 135, 135, 4320, 4320, 33, 4320, 4320, 135, 33, 4320, 135, 135, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 135, 4320, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 4320, 33, 33, 33, 135, 33, 135, 135, 33, 4320, 135, 4320, 33, 4320, 33, 135, 135, 135, 135, 33, 135, 4320, 4320, 33, 4320, 4320, 33, 4320, 135, 4320, 135, 135, 135, 33, 135, 33, 33, 4320, 33, 135, 33, 33, 135, 4320, 135, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 574464 . Total input tokens: 128075419 . Total output tokens: 114736704
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.517734519671649,
    "estimated_duration": 3600.209695596667,
    "input_throughput": 4080.353713275967,
    "output_throughput": 3605.691084015761,
    "total_throughput": 7686.044797291728,
    "itl": 237.3450095155313,
    "ttft": 1933385.2341724415,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1891,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.787382323777003,
    "arrivals": 191087,
    "finished_requests": 59485,
    "scheduler_time": 86.47266726760573
}
#Debug simulation 
Total elapsed time: 4.517832196783274. Arrivals time: 0.20621959399431944 Scheduler time: 4.206912321969867 Scheduler overhead time: 0.0250613484531641 Adapter cache time: 0.042683267034590244 Engine time: 0.025500250980257988 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_384_slots_160_rate_0.4-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_384_slots_160_rate_0.4-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 135, 33, 4320, 4320, 33, 135, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 33, 4320, 33, 4320, 135, 135, 135, 33, 33, 135, 33, 4320, 33, 4320, 135, 4320, 135, 33, 135, 4320, 135, 4320, 33, 4320, 4320, 4320, 4320, 33, 135, 135, 135, 4320, 135, 33, 135, 33, 4320, 135, 4320, 4320, 135, 4320, 4320, 33, 33, 4320, 135, 135, 33, 33, 33, 135, 33, 135, 33, 4320, 33, 135, 4320, 33, 4320, 135, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 4320, 4320, 135, 33, 33, 4320, 135, 135, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 135, 4320, 4320, 33, 135, 135, 135, 135, 33, 33, 4320, 33, 4320, 33, 33, 33, 135, 135, 4320, 33, 33, 4320, 33, 4320, 135, 33, 4320, 135, 135, 33, 4320, 4320, 4320, 33, 135, 4320, 33, 4320, 135, 135, 4320, 4320, 33, 135, 4320, 33, 135, 135, 33, 135, 33, 135, 4320, 4320, 135, 33, 4320, 33, 4320, 135, 135, 135, 135, 135, 33, 33, 4320, 33, 4320, 33, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 33, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 33, 33, 33, 33, 33, 135, 33, 33, 135, 4320, 4320, 33, 33, 4320, 33, 33, 33, 135, 33, 135, 4320, 4320, 135, 135, 33, 4320, 135, 4320, 33, 135, 135, 33, 33, 135, 33, 4320, 4320, 33, 4320, 4320, 33, 135, 4320, 33, 33, 135, 135, 33, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 4320, 135, 135, 135, 4320, 33, 135, 135, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 135, 33, 4320, 4320, 4320, 135, 33, 4320, 4320, 135, 135, 4320, 4320, 33, 4320, 4320, 135, 33, 4320, 135, 135, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 135, 4320, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 4320, 33, 33, 33, 135, 33, 135, 135, 33, 4320, 135, 4320, 33, 4320, 33, 135, 135, 135, 135, 33, 135, 4320, 4320, 33, 4320, 4320, 33, 4320, 135, 4320, 135, 135, 135, 33, 135, 33, 33, 4320, 33, 135, 33, 33, 135, 4320, 135, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 574464 . Total input tokens: 128075419 . Total output tokens: 114736704
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.547630594111979,
    "estimated_duration": 3600.1600835112577,
    "input_throughput": 4079.2080516810934,
    "output_throughput": 3604.6380435792144,
    "total_throughput": 7683.846095260307,
    "itl": 237.378426729421,
    "ttft": 1933508.98405502,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1890,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.150089941180584,
    "arrivals": 191087,
    "finished_requests": 59470,
    "scheduler_time": 86.46019130665387
}
#Debug simulation 
Total elapsed time: 4.547768207266927. Arrivals time: 0.21563403867185116 Scheduler time: 4.227016162592918 Scheduler overhead time: 0.025035444647073746 Adapter cache time: 0.04324265755712986 Engine time: 0.02541434159502387 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-32/adapters_384_slots_160_rate_0.4-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-32/adapters_384_slots_160_rate_0.4-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 135, 33, 4320, 4320, 33, 135, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 33, 4320, 33, 4320, 135, 135, 135, 33, 33, 135, 33, 4320, 33, 4320, 135, 4320, 135, 33, 135, 4320, 135, 4320, 33, 4320, 4320, 4320, 4320, 33, 135, 135, 135, 4320, 135, 33, 135, 33, 4320, 135, 4320, 4320, 135, 4320, 4320, 33, 33, 4320, 135, 135, 33, 33, 33, 135, 33, 135, 33, 4320, 33, 135, 4320, 33, 4320, 135, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 4320, 4320, 135, 33, 33, 4320, 135, 135, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 135, 4320, 4320, 33, 135, 135, 135, 135, 33, 33, 4320, 33, 4320, 33, 33, 33, 135, 135, 4320, 33, 33, 4320, 33, 4320, 135, 33, 4320, 135, 135, 33, 4320, 4320, 4320, 33, 135, 4320, 33, 4320, 135, 135, 4320, 4320, 33, 135, 4320, 33, 135, 135, 33, 135, 33, 135, 4320, 4320, 135, 33, 4320, 33, 4320, 135, 135, 135, 135, 135, 33, 33, 4320, 33, 4320, 33, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 33, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 33, 33, 33, 33, 33, 135, 33, 33, 135, 4320, 4320, 33, 33, 4320, 33, 33, 33, 135, 33, 135, 4320, 4320, 135, 135, 33, 4320, 135, 4320, 33, 135, 135, 33, 33, 135, 33, 4320, 4320, 33, 4320, 4320, 33, 135, 4320, 33, 33, 135, 135, 33, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 4320, 135, 135, 135, 4320, 33, 135, 135, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 135, 33, 4320, 4320, 4320, 135, 33, 4320, 4320, 135, 135, 4320, 4320, 33, 4320, 4320, 135, 33, 4320, 135, 135, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 135, 4320, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 4320, 33, 33, 33, 135, 33, 135, 135, 33, 4320, 135, 4320, 33, 4320, 33, 135, 135, 135, 135, 33, 135, 4320, 4320, 33, 4320, 4320, 33, 4320, 135, 4320, 135, 135, 135, 33, 135, 33, 33, 4320, 33, 135, 33, 33, 135, 4320, 135, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 574464 . Total input tokens: 128075419 . Total output tokens: 114736704
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.465363598894328,
    "estimated_duration": 3600.0407681060256,
    "input_throughput": 3767.0937285342966,
    "output_throughput": 3350.8476089692786,
    "total_throughput": 7117.941337503575,
    "itl": 150.85664441045478,
    "ttft": 2006103.706512241,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1948,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.356067292969625,
    "arrivals": 191087,
    "finished_requests": 54993,
    "scheduler_time": 102.26428935664576
}
#Debug simulation 
Total elapsed time: 4.46542747085914. Arrivals time: 0.4274582280777395 Scheduler time: 3.8807343039661646 Scheduler overhead time: 0.03607709053903818 Adapter cache time: 0.06725305551663041 Engine time: 0.03706793114542961 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_384_slots_160_rate_0.4-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_384_slots_160_rate_0.4-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 135, 33, 4320, 4320, 33, 135, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 33, 4320, 33, 4320, 135, 135, 135, 33, 33, 135, 33, 4320, 33, 4320, 135, 4320, 135, 33, 135, 4320, 135, 4320, 33, 4320, 4320, 4320, 4320, 33, 135, 135, 135, 4320, 135, 33, 135, 33, 4320, 135, 4320, 4320, 135, 4320, 4320, 33, 33, 4320, 135, 135, 33, 33, 33, 135, 33, 135, 33, 4320, 33, 135, 4320, 33, 4320, 135, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 4320, 4320, 135, 33, 33, 4320, 135, 135, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 135, 4320, 4320, 33, 135, 135, 135, 135, 33, 33, 4320, 33, 4320, 33, 33, 33, 135, 135, 4320, 33, 33, 4320, 33, 4320, 135, 33, 4320, 135, 135, 33, 4320, 4320, 4320, 33, 135, 4320, 33, 4320, 135, 135, 4320, 4320, 33, 135, 4320, 33, 135, 135, 33, 135, 33, 135, 4320, 4320, 135, 33, 4320, 33, 4320, 135, 135, 135, 135, 135, 33, 33, 4320, 33, 4320, 33, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 33, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 33, 33, 33, 33, 33, 135, 33, 33, 135, 4320, 4320, 33, 33, 4320, 33, 33, 33, 135, 33, 135, 4320, 4320, 135, 135, 33, 4320, 135, 4320, 33, 135, 135, 33, 33, 135, 33, 4320, 4320, 33, 4320, 4320, 33, 135, 4320, 33, 33, 135, 135, 33, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 4320, 135, 135, 135, 4320, 33, 135, 135, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 135, 33, 4320, 4320, 4320, 135, 33, 4320, 4320, 135, 135, 4320, 4320, 33, 4320, 4320, 135, 33, 4320, 135, 135, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 135, 4320, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 4320, 33, 33, 33, 135, 33, 135, 135, 33, 4320, 135, 4320, 33, 4320, 33, 135, 135, 135, 135, 33, 135, 4320, 4320, 33, 4320, 4320, 33, 4320, 135, 4320, 135, 135, 135, 33, 135, 33, 33, 4320, 33, 135, 33, 33, 135, 4320, 135, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 574464 . Total input tokens: 128075419 . Total output tokens: 114736704
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.548908732831478,
    "estimated_duration": 3600.147199070497,
    "input_throughput": 4079.78346101853,
    "output_throughput": 3605.4747992946786,
    "total_throughput": 7685.258260313209,
    "itl": 237.35521056277685,
    "ttft": 1933415.8556856455,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1891,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.897707917450289,
    "arrivals": 191087,
    "finished_requests": 59480,
    "scheduler_time": 86.46851188076448
}
#Debug simulation 
Total elapsed time: 4.54904658626765. Arrivals time: 0.22338144853711128 Scheduler time: 4.219546821434051 Scheduler overhead time: 0.02509751869365573 Adapter cache time: 0.04382605757564306 Engine time: 0.02565711783245206 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-32/adapters_384_slots_160_rate_0.4-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-32/adapters_384_slots_160_rate_0.4-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 135, 33, 4320, 4320, 33, 135, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 33, 4320, 33, 4320, 135, 135, 135, 33, 33, 135, 33, 4320, 33, 4320, 135, 4320, 135, 33, 135, 4320, 135, 4320, 33, 4320, 4320, 4320, 4320, 33, 135, 135, 135, 4320, 135, 33, 135, 33, 4320, 135, 4320, 4320, 135, 4320, 4320, 33, 33, 4320, 135, 135, 33, 33, 33, 135, 33, 135, 33, 4320, 33, 135, 4320, 33, 4320, 135, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 4320, 4320, 135, 33, 33, 4320, 135, 135, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 135, 4320, 4320, 33, 135, 135, 135, 135, 33, 33, 4320, 33, 4320, 33, 33, 33, 135, 135, 4320, 33, 33, 4320, 33, 4320, 135, 33, 4320, 135, 135, 33, 4320, 4320, 4320, 33, 135, 4320, 33, 4320, 135, 135, 4320, 4320, 33, 135, 4320, 33, 135, 135, 33, 135, 33, 135, 4320, 4320, 135, 33, 4320, 33, 4320, 135, 135, 135, 135, 135, 33, 33, 4320, 33, 4320, 33, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 33, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 33, 33, 33, 33, 33, 135, 33, 33, 135, 4320, 4320, 33, 33, 4320, 33, 33, 33, 135, 33, 135, 4320, 4320, 135, 135, 33, 4320, 135, 4320, 33, 135, 135, 33, 33, 135, 33, 4320, 4320, 33, 4320, 4320, 33, 135, 4320, 33, 33, 135, 135, 33, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 4320, 135, 135, 135, 4320, 33, 135, 135, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 135, 33, 4320, 4320, 4320, 135, 33, 4320, 4320, 135, 135, 4320, 4320, 33, 4320, 4320, 135, 33, 4320, 135, 135, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 135, 4320, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 4320, 33, 33, 33, 135, 33, 135, 135, 33, 4320, 135, 4320, 33, 4320, 33, 135, 135, 135, 135, 33, 135, 4320, 4320, 33, 4320, 4320, 33, 4320, 135, 4320, 135, 135, 135, 33, 135, 33, 33, 4320, 33, 135, 33, 33, 135, 4320, 135, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 574464 . Total input tokens: 128075419 . Total output tokens: 114736704
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 4.459190994035453,
    "estimated_duration": 3600.071943871721,
    "input_throughput": 3768.4969110393477,
    "output_throughput": 3352.1996749379455,
    "total_throughput": 7120.696585977293,
    "itl": 151.0292980624071,
    "ttft": 2005631.2592211326,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1957,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.468525672666604,
    "arrivals": 191087,
    "finished_requests": 55015,
    "scheduler_time": 102.22201425836634
}
#Debug simulation 
Total elapsed time: 4.459256937261671. Arrivals time: 0.4273135019466281 Scheduler time: 3.8739127423614264 Scheduler overhead time: 0.036043557804077864 Adapter cache time: 0.06817155703902245 Engine time: 0.03709149919450283 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_384_slots_160_rate_0.4-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_384_slots_160_rate_0.4-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 135, 33, 4320, 4320, 33, 135, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 33, 4320, 33, 4320, 135, 135, 135, 33, 33, 135, 33, 4320, 33, 4320, 135, 4320, 135, 33, 135, 4320, 135, 4320, 33, 4320, 4320, 4320, 4320, 33, 135, 135, 135, 4320, 135, 33, 135, 33, 4320, 135, 4320, 4320, 135, 4320, 4320, 33, 33, 4320, 135, 135, 33, 33, 33, 135, 33, 135, 33, 4320, 33, 135, 4320, 33, 4320, 135, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 4320, 4320, 135, 33, 33, 4320, 135, 135, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 135, 4320, 4320, 33, 135, 135, 135, 135, 33, 33, 4320, 33, 4320, 33, 33, 33, 135, 135, 4320, 33, 33, 4320, 33, 4320, 135, 33, 4320, 135, 135, 33, 4320, 4320, 4320, 33, 135, 4320, 33, 4320, 135, 135, 4320, 4320, 33, 135, 4320, 33, 135, 135, 33, 135, 33, 135, 4320, 4320, 135, 33, 4320, 33, 4320, 135, 135, 135, 135, 135, 33, 33, 4320, 33, 4320, 33, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 33, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 33, 33, 33, 33, 33, 135, 33, 33, 135, 4320, 4320, 33, 33, 4320, 33, 33, 33, 135, 33, 135, 4320, 4320, 135, 135, 33, 4320, 135, 4320, 33, 135, 135, 33, 33, 135, 33, 4320, 4320, 33, 4320, 4320, 33, 135, 4320, 33, 33, 135, 135, 33, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 4320, 135, 135, 135, 4320, 33, 135, 135, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 135, 33, 4320, 4320, 4320, 135, 33, 4320, 4320, 135, 135, 4320, 4320, 33, 4320, 4320, 135, 33, 4320, 135, 135, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 135, 4320, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 4320, 33, 33, 33, 135, 33, 135, 135, 33, 4320, 135, 4320, 33, 4320, 33, 135, 135, 135, 135, 33, 135, 4320, 4320, 33, 4320, 4320, 33, 4320, 135, 4320, 135, 135, 135, 33, 135, 33, 33, 4320, 33, 135, 33, 33, 135, 4320, 135, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 574464 . Total input tokens: 128075419 . Total output tokens: 114736704
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.550951041746885,
    "estimated_duration": 3600.026778170474,
    "input_throughput": 4080.214927585861,
    "output_throughput": 3605.737623595342,
    "total_throughput": 7685.9525511812035,
    "itl": 237.3394658885732,
    "ttft": 1933332.0657991872,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1892,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.657175157954752,
    "arrivals": 191087,
    "finished_requests": 59482,
    "scheduler_time": 86.47061191936677
}
#Debug simulation 
Total elapsed time: 4.551110696978867. Arrivals time: 0.23150758165866137 Scheduler time: 4.213450771290809 Scheduler overhead time: 0.025131612084805965 Adapter cache time: 0.0439875521697104 Engine time: 0.025478191673755646 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-32/adapters_384_slots_160_rate_0.4-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-32/adapters_384_slots_160_rate_0.4-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 135, 33, 4320, 4320, 33, 135, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 33, 4320, 33, 4320, 135, 135, 135, 33, 33, 135, 33, 4320, 33, 4320, 135, 4320, 135, 33, 135, 4320, 135, 4320, 33, 4320, 4320, 4320, 4320, 33, 135, 135, 135, 4320, 135, 33, 135, 33, 4320, 135, 4320, 4320, 135, 4320, 4320, 33, 33, 4320, 135, 135, 33, 33, 33, 135, 33, 135, 33, 4320, 33, 135, 4320, 33, 4320, 135, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 4320, 4320, 135, 33, 33, 4320, 135, 135, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 135, 4320, 4320, 33, 135, 135, 135, 135, 33, 33, 4320, 33, 4320, 33, 33, 33, 135, 135, 4320, 33, 33, 4320, 33, 4320, 135, 33, 4320, 135, 135, 33, 4320, 4320, 4320, 33, 135, 4320, 33, 4320, 135, 135, 4320, 4320, 33, 135, 4320, 33, 135, 135, 33, 135, 33, 135, 4320, 4320, 135, 33, 4320, 33, 4320, 135, 135, 135, 135, 135, 33, 33, 4320, 33, 4320, 33, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 33, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 33, 33, 33, 33, 33, 135, 33, 33, 135, 4320, 4320, 33, 33, 4320, 33, 33, 33, 135, 33, 135, 4320, 4320, 135, 135, 33, 4320, 135, 4320, 33, 135, 135, 33, 33, 135, 33, 4320, 4320, 33, 4320, 4320, 33, 135, 4320, 33, 33, 135, 135, 33, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 4320, 135, 135, 135, 4320, 33, 135, 135, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 135, 33, 4320, 4320, 4320, 135, 33, 4320, 4320, 135, 135, 4320, 4320, 33, 4320, 4320, 135, 33, 4320, 135, 135, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 135, 4320, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 4320, 33, 33, 33, 135, 33, 135, 135, 33, 4320, 135, 4320, 33, 4320, 33, 135, 135, 135, 135, 33, 135, 4320, 4320, 33, 4320, 4320, 33, 4320, 135, 4320, 135, 135, 135, 33, 135, 33, 33, 4320, 33, 135, 33, 33, 135, 4320, 135, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 574464 . Total input tokens: 128075419 . Total output tokens: 114736704
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.468761241063476,
    "estimated_duration": 3600.0984609989314,
    "input_throughput": 3767.407793684792,
    "output_throughput": 3351.2036214288364,
    "total_throughput": 7118.611415113629,
    "itl": 150.84401989418203,
    "ttft": 2006066.5052463843,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1955,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.539016978703247,
    "arrivals": 191087,
    "finished_requests": 54999,
    "scheduler_time": 102.27920109272841
}
#Debug simulation 
Total elapsed time: 4.4688676609657705. Arrivals time: 0.41545850364491343 Scheduler time: 3.895629026927054 Scheduler overhead time: 0.0361854899674654 Adapter cache time: 0.06771939294412732 Engine time: 0.036994106601923704 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_384_slots_160_rate_0.4-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_384_slots_160_rate_0.4-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 66, 33, 4320, 4320, 33, 66, 4320, 4320, 4320, 4320, 66, 66, 66, 66, 4320, 4320, 66, 66, 33, 4320, 33, 4320, 66, 66, 66, 33, 33, 66, 33, 4320, 33, 4320, 66, 4320, 66, 33, 66, 4320, 66, 4320, 33, 4320, 4320, 4320, 4320, 33, 66, 66, 66, 4320, 66, 33, 66, 33, 4320, 66, 4320, 4320, 66, 4320, 4320, 33, 33, 4320, 66, 66, 33, 33, 33, 66, 33, 66, 33, 4320, 33, 66, 4320, 33, 4320, 66, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 4320, 4320, 66, 33, 33, 4320, 66, 66, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 66, 4320, 4320, 33, 66, 66, 66, 66, 33, 33, 4320, 33, 4320, 33, 33, 33, 66, 66, 4320, 33, 33, 4320, 33, 4320, 66, 33, 4320, 66, 66, 33, 4320, 4320, 4320, 33, 66, 4320, 33, 4320, 66, 66, 4320, 4320, 33, 66, 4320, 33, 66, 66, 33, 66, 33, 66, 4320, 4320, 66, 33, 4320, 33, 4320, 66, 66, 66, 66, 66, 33, 33, 4320, 33, 4320, 33, 66, 4320, 66, 4320, 66, 4320, 66, 4320, 33, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 33, 33, 33, 33, 33, 66, 33, 33, 66, 4320, 4320, 33, 33, 4320, 33, 33, 33, 66, 33, 66, 4320, 4320, 66, 66, 33, 4320, 66, 4320, 33, 66, 66, 33, 33, 66, 33, 4320, 4320, 33, 4320, 4320, 33, 66, 4320, 33, 33, 66, 66, 33, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 4320, 66, 66, 66, 4320, 33, 66, 66, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 66, 33, 4320, 4320, 4320, 66, 33, 4320, 4320, 66, 66, 4320, 4320, 33, 4320, 4320, 66, 33, 4320, 66, 66, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 66, 4320, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 4320, 33, 33, 33, 66, 33, 66, 66, 33, 4320, 66, 4320, 33, 4320, 33, 66, 66, 66, 66, 33, 66, 4320, 4320, 33, 4320, 4320, 33, 4320, 66, 4320, 66, 66, 66, 33, 66, 33, 33, 4320, 33, 66, 33, 33, 66, 4320, 66, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 565632 . Total input tokens: 126102881 . Total output tokens: 112978603
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.577545312233269,
    "estimated_duration": 3600.098293531465,
    "input_throughput": 4242.09223049274,
    "output_throughput": 3751.0603597306954,
    "total_throughput": 7993.152590223435,
    "itl": 228.4803704171212,
    "ttft": 1887087.5744854289,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1373,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.202049672419781,
    "arrivals": 188115,
    "finished_requests": 61847,
    "scheduler_time": 89.82659162010516
}
#Debug simulation 
Total elapsed time: 4.577689158264548. Arrivals time: 0.21190224308520555 Scheduler time: 4.2675735065713525 Scheduler overhead time: 0.025337948463857174 Adapter cache time: 0.03502260521054268 Engine time: 0.0260635856539011 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_384_slots_160_rate_0.4-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_384_slots_160_rate_0.4-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 66, 33, 4320, 4320, 33, 66, 4320, 4320, 4320, 4320, 66, 66, 66, 66, 4320, 4320, 66, 66, 33, 4320, 33, 4320, 66, 66, 66, 33, 33, 66, 33, 4320, 33, 4320, 66, 4320, 66, 33, 66, 4320, 66, 4320, 33, 4320, 4320, 4320, 4320, 33, 66, 66, 66, 4320, 66, 33, 66, 33, 4320, 66, 4320, 4320, 66, 4320, 4320, 33, 33, 4320, 66, 66, 33, 33, 33, 66, 33, 66, 33, 4320, 33, 66, 4320, 33, 4320, 66, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 4320, 4320, 66, 33, 33, 4320, 66, 66, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 66, 4320, 4320, 33, 66, 66, 66, 66, 33, 33, 4320, 33, 4320, 33, 33, 33, 66, 66, 4320, 33, 33, 4320, 33, 4320, 66, 33, 4320, 66, 66, 33, 4320, 4320, 4320, 33, 66, 4320, 33, 4320, 66, 66, 4320, 4320, 33, 66, 4320, 33, 66, 66, 33, 66, 33, 66, 4320, 4320, 66, 33, 4320, 33, 4320, 66, 66, 66, 66, 66, 33, 33, 4320, 33, 4320, 33, 66, 4320, 66, 4320, 66, 4320, 66, 4320, 33, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 33, 33, 33, 33, 33, 66, 33, 33, 66, 4320, 4320, 33, 33, 4320, 33, 33, 33, 66, 33, 66, 4320, 4320, 66, 66, 33, 4320, 66, 4320, 33, 66, 66, 33, 33, 66, 33, 4320, 4320, 33, 4320, 4320, 33, 66, 4320, 33, 33, 66, 66, 33, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 4320, 66, 66, 66, 4320, 33, 66, 66, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 66, 33, 4320, 4320, 4320, 66, 33, 4320, 4320, 66, 66, 4320, 4320, 33, 4320, 4320, 66, 33, 4320, 66, 66, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 66, 4320, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 4320, 33, 33, 33, 66, 33, 66, 66, 33, 4320, 66, 4320, 33, 4320, 33, 66, 66, 66, 66, 33, 66, 4320, 4320, 33, 4320, 4320, 33, 4320, 66, 4320, 66, 66, 66, 33, 66, 33, 33, 4320, 33, 66, 33, 33, 66, 4320, 66, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 565632 . Total input tokens: 126102881 . Total output tokens: 112978603
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.554176672361791,
    "estimated_duration": 3600.08999866481,
    "input_throughput": 4241.593128411604,
    "output_throughput": 3750.5329047350688,
    "total_throughput": 7992.126033146673,
    "itl": 228.49772375524444,
    "ttft": 1887193.461688964,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1373,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.477160794681361,
    "arrivals": 188115,
    "finished_requests": 61840,
    "scheduler_time": 89.82061618509894
}
#Debug simulation 
Total elapsed time: 4.554268078412861. Arrivals time: 0.2101446851156652 Scheduler time: 4.246675557456911 Scheduler overhead time: 0.02541430853307247 Adapter cache time: 0.03414551122114062 Engine time: 0.026181552559137344 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-32/adapters_384_slots_160_rate_0.4-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-32/adapters_384_slots_160_rate_0.4-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 66, 33, 4320, 4320, 33, 66, 4320, 4320, 4320, 4320, 66, 66, 66, 66, 4320, 4320, 66, 66, 33, 4320, 33, 4320, 66, 66, 66, 33, 33, 66, 33, 4320, 33, 4320, 66, 4320, 66, 33, 66, 4320, 66, 4320, 33, 4320, 4320, 4320, 4320, 33, 66, 66, 66, 4320, 66, 33, 66, 33, 4320, 66, 4320, 4320, 66, 4320, 4320, 33, 33, 4320, 66, 66, 33, 33, 33, 66, 33, 66, 33, 4320, 33, 66, 4320, 33, 4320, 66, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 4320, 4320, 66, 33, 33, 4320, 66, 66, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 66, 4320, 4320, 33, 66, 66, 66, 66, 33, 33, 4320, 33, 4320, 33, 33, 33, 66, 66, 4320, 33, 33, 4320, 33, 4320, 66, 33, 4320, 66, 66, 33, 4320, 4320, 4320, 33, 66, 4320, 33, 4320, 66, 66, 4320, 4320, 33, 66, 4320, 33, 66, 66, 33, 66, 33, 66, 4320, 4320, 66, 33, 4320, 33, 4320, 66, 66, 66, 66, 66, 33, 33, 4320, 33, 4320, 33, 66, 4320, 66, 4320, 66, 4320, 66, 4320, 33, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 33, 33, 33, 33, 33, 66, 33, 33, 66, 4320, 4320, 33, 33, 4320, 33, 33, 33, 66, 33, 66, 4320, 4320, 66, 66, 33, 4320, 66, 4320, 33, 66, 66, 33, 33, 66, 33, 4320, 4320, 33, 4320, 4320, 33, 66, 4320, 33, 33, 66, 66, 33, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 4320, 66, 66, 66, 4320, 33, 66, 66, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 66, 33, 4320, 4320, 4320, 66, 33, 4320, 4320, 66, 66, 4320, 4320, 33, 4320, 4320, 66, 33, 4320, 66, 66, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 66, 4320, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 4320, 33, 33, 33, 66, 33, 66, 66, 33, 4320, 66, 4320, 33, 4320, 33, 66, 66, 66, 66, 33, 66, 4320, 4320, 33, 4320, 4320, 33, 4320, 66, 4320, 66, 66, 66, 33, 66, 33, 33, 4320, 33, 66, 33, 33, 66, 4320, 66, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 565632 . Total input tokens: 126102881 . Total output tokens: 112978603
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.383959012106061,
    "estimated_duration": 3600.133446970092,
    "input_throughput": 3897.4905254717814,
    "output_throughput": 3457.356007310082,
    "total_throughput": 7354.846532781864,
    "itl": 146.66555737098423,
    "ttft": 1967017.4151741485,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1266,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.135033767968353,
    "arrivals": 188115,
    "finished_requests": 56780,
    "scheduler_time": 105.23020966063216
}
#Debug simulation 
Total elapsed time: 4.3840689598582685. Arrivals time: 0.201953268609941 Scheduler time: 4.037005431950092 Scheduler overhead time: 0.03695451840758324 Adapter cache time: 0.05267066042870283 Engine time: 0.03817236144095659 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_384_slots_160_rate_0.4-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_384_slots_160_rate_0.4-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 66, 33, 4320, 4320, 33, 66, 4320, 4320, 4320, 4320, 66, 66, 66, 66, 4320, 4320, 66, 66, 33, 4320, 33, 4320, 66, 66, 66, 33, 33, 66, 33, 4320, 33, 4320, 66, 4320, 66, 33, 66, 4320, 66, 4320, 33, 4320, 4320, 4320, 4320, 33, 66, 66, 66, 4320, 66, 33, 66, 33, 4320, 66, 4320, 4320, 66, 4320, 4320, 33, 33, 4320, 66, 66, 33, 33, 33, 66, 33, 66, 33, 4320, 33, 66, 4320, 33, 4320, 66, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 4320, 4320, 66, 33, 33, 4320, 66, 66, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 66, 4320, 4320, 33, 66, 66, 66, 66, 33, 33, 4320, 33, 4320, 33, 33, 33, 66, 66, 4320, 33, 33, 4320, 33, 4320, 66, 33, 4320, 66, 66, 33, 4320, 4320, 4320, 33, 66, 4320, 33, 4320, 66, 66, 4320, 4320, 33, 66, 4320, 33, 66, 66, 33, 66, 33, 66, 4320, 4320, 66, 33, 4320, 33, 4320, 66, 66, 66, 66, 66, 33, 33, 4320, 33, 4320, 33, 66, 4320, 66, 4320, 66, 4320, 66, 4320, 33, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 33, 33, 33, 33, 33, 66, 33, 33, 66, 4320, 4320, 33, 33, 4320, 33, 33, 33, 66, 33, 66, 4320, 4320, 66, 66, 33, 4320, 66, 4320, 33, 66, 66, 33, 33, 66, 33, 4320, 4320, 33, 4320, 4320, 33, 66, 4320, 33, 33, 66, 66, 33, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 4320, 66, 66, 66, 4320, 33, 66, 66, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 66, 33, 4320, 4320, 4320, 66, 33, 4320, 4320, 66, 66, 4320, 4320, 33, 4320, 4320, 66, 33, 4320, 66, 66, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 66, 4320, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 4320, 33, 33, 33, 66, 33, 66, 66, 33, 4320, 66, 4320, 33, 4320, 33, 66, 66, 66, 66, 33, 66, 4320, 4320, 33, 4320, 4320, 33, 4320, 66, 4320, 66, 66, 66, 33, 66, 33, 33, 4320, 33, 66, 33, 33, 66, 4320, 66, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 565632 . Total input tokens: 126102881 . Total output tokens: 112978603
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.582305538933724,
    "estimated_duration": 3600.0111458915635,
    "input_throughput": 4242.1190882779565,
    "output_throughput": 3751.0383864813593,
    "total_throughput": 7993.157474759316,
    "itl": 228.48730321207051,
    "ttft": 1887088.3810786302,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1373,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.281443637148408,
    "arrivals": 188115,
    "finished_requests": 61845,
    "scheduler_time": 89.8222144977115
}
#Debug simulation 
Total elapsed time: 4.582401630003005. Arrivals time: 0.21439800644293427 Scheduler time: 4.270596224348992 Scheduler overhead time: 0.025318255182355642 Adapter cache time: 0.03415294084697962 Engine time: 0.026211006566882133 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-32/adapters_384_slots_160_rate_0.4-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-32/adapters_384_slots_160_rate_0.4-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 66, 33, 4320, 4320, 33, 66, 4320, 4320, 4320, 4320, 66, 66, 66, 66, 4320, 4320, 66, 66, 33, 4320, 33, 4320, 66, 66, 66, 33, 33, 66, 33, 4320, 33, 4320, 66, 4320, 66, 33, 66, 4320, 66, 4320, 33, 4320, 4320, 4320, 4320, 33, 66, 66, 66, 4320, 66, 33, 66, 33, 4320, 66, 4320, 4320, 66, 4320, 4320, 33, 33, 4320, 66, 66, 33, 33, 33, 66, 33, 66, 33, 4320, 33, 66, 4320, 33, 4320, 66, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 4320, 4320, 66, 33, 33, 4320, 66, 66, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 66, 4320, 4320, 33, 66, 66, 66, 66, 33, 33, 4320, 33, 4320, 33, 33, 33, 66, 66, 4320, 33, 33, 4320, 33, 4320, 66, 33, 4320, 66, 66, 33, 4320, 4320, 4320, 33, 66, 4320, 33, 4320, 66, 66, 4320, 4320, 33, 66, 4320, 33, 66, 66, 33, 66, 33, 66, 4320, 4320, 66, 33, 4320, 33, 4320, 66, 66, 66, 66, 66, 33, 33, 4320, 33, 4320, 33, 66, 4320, 66, 4320, 66, 4320, 66, 4320, 33, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 33, 33, 33, 33, 33, 66, 33, 33, 66, 4320, 4320, 33, 33, 4320, 33, 33, 33, 66, 33, 66, 4320, 4320, 66, 66, 33, 4320, 66, 4320, 33, 66, 66, 33, 33, 66, 33, 4320, 4320, 33, 4320, 4320, 33, 66, 4320, 33, 33, 66, 66, 33, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 4320, 66, 66, 66, 4320, 33, 66, 66, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 66, 33, 4320, 4320, 4320, 66, 33, 4320, 4320, 66, 66, 4320, 4320, 33, 4320, 4320, 66, 33, 4320, 66, 66, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 66, 4320, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 4320, 33, 33, 33, 66, 33, 66, 66, 33, 4320, 66, 4320, 33, 4320, 33, 66, 66, 66, 66, 33, 66, 4320, 4320, 33, 4320, 4320, 33, 4320, 66, 4320, 66, 66, 66, 33, 66, 33, 33, 4320, 33, 66, 33, 33, 66, 4320, 66, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 565632 . Total input tokens: 126102881 . Total output tokens: 112978603
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 4.368923689704388,
    "estimated_duration": 3600.0701947756233,
    "input_throughput": 3899.1117507570902,
    "output_throughput": 3458.640894855118,
    "total_throughput": 7357.752645612208,
    "itl": 146.8247982761739,
    "ttft": 1966583.8822846743,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1265,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.187070407569407,
    "arrivals": 188115,
    "finished_requests": 56801,
    "scheduler_time": 105.19772191390484
}
#Debug simulation 
Total elapsed time: 4.369020381942391. Arrivals time: 0.19766874378547072 Scheduler time: 4.023875953629613 Scheduler overhead time: 0.037285528145730495 Adapter cache time: 0.05436023976653814 Engine time: 0.038505648728460073 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_384_slots_160_rate_0.4-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_384_slots_160_rate_0.4-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 66, 33, 4320, 4320, 33, 66, 4320, 4320, 4320, 4320, 66, 66, 66, 66, 4320, 4320, 66, 66, 33, 4320, 33, 4320, 66, 66, 66, 33, 33, 66, 33, 4320, 33, 4320, 66, 4320, 66, 33, 66, 4320, 66, 4320, 33, 4320, 4320, 4320, 4320, 33, 66, 66, 66, 4320, 66, 33, 66, 33, 4320, 66, 4320, 4320, 66, 4320, 4320, 33, 33, 4320, 66, 66, 33, 33, 33, 66, 33, 66, 33, 4320, 33, 66, 4320, 33, 4320, 66, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 4320, 4320, 66, 33, 33, 4320, 66, 66, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 66, 4320, 4320, 33, 66, 66, 66, 66, 33, 33, 4320, 33, 4320, 33, 33, 33, 66, 66, 4320, 33, 33, 4320, 33, 4320, 66, 33, 4320, 66, 66, 33, 4320, 4320, 4320, 33, 66, 4320, 33, 4320, 66, 66, 4320, 4320, 33, 66, 4320, 33, 66, 66, 33, 66, 33, 66, 4320, 4320, 66, 33, 4320, 33, 4320, 66, 66, 66, 66, 66, 33, 33, 4320, 33, 4320, 33, 66, 4320, 66, 4320, 66, 4320, 66, 4320, 33, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 33, 33, 33, 33, 33, 66, 33, 33, 66, 4320, 4320, 33, 33, 4320, 33, 33, 33, 66, 33, 66, 4320, 4320, 66, 66, 33, 4320, 66, 4320, 33, 66, 66, 33, 33, 66, 33, 4320, 4320, 33, 4320, 4320, 33, 66, 4320, 33, 33, 66, 66, 33, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 4320, 66, 66, 66, 4320, 33, 66, 66, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 66, 33, 4320, 4320, 4320, 66, 33, 4320, 4320, 66, 66, 4320, 4320, 33, 4320, 4320, 66, 33, 4320, 66, 66, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 66, 4320, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 4320, 33, 33, 33, 66, 33, 66, 66, 33, 4320, 66, 4320, 33, 4320, 33, 66, 66, 66, 66, 33, 66, 4320, 4320, 33, 4320, 4320, 33, 4320, 66, 4320, 66, 66, 66, 33, 66, 33, 33, 4320, 33, 66, 33, 33, 66, 4320, 66, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 565632 . Total input tokens: 126102881 . Total output tokens: 112978603
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.586889065802097,
    "estimated_duration": 3600.149761038926,
    "input_throughput": 4242.657115350722,
    "output_throughput": 3751.37588612497,
    "total_throughput": 7994.033001475692,
    "itl": 228.47294912806953,
    "ttft": 1887014.6729442151,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1373,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.105339054900578,
    "arrivals": 188115,
    "finished_requests": 61852,
    "scheduler_time": 89.83144847725133
}
#Debug simulation 
Total elapsed time: 4.586988032795489. Arrivals time: 0.22208349592983723 Scheduler time: 4.26677636988461 Scheduler overhead time: 0.025318088475614786 Adapter cache time: 0.03517469484359026 Engine time: 0.02596678165718913 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-32/adapters_384_slots_160_rate_0.4-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-32/adapters_384_slots_160_rate_0.4-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 66, 33, 4320, 4320, 33, 66, 4320, 4320, 4320, 4320, 66, 66, 66, 66, 4320, 4320, 66, 66, 33, 4320, 33, 4320, 66, 66, 66, 33, 33, 66, 33, 4320, 33, 4320, 66, 4320, 66, 33, 66, 4320, 66, 4320, 33, 4320, 4320, 4320, 4320, 33, 66, 66, 66, 4320, 66, 33, 66, 33, 4320, 66, 4320, 4320, 66, 4320, 4320, 33, 33, 4320, 66, 66, 33, 33, 33, 66, 33, 66, 33, 4320, 33, 66, 4320, 33, 4320, 66, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 4320, 4320, 66, 33, 33, 4320, 66, 66, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 66, 4320, 4320, 33, 66, 66, 66, 66, 33, 33, 4320, 33, 4320, 33, 33, 33, 66, 66, 4320, 33, 33, 4320, 33, 4320, 66, 33, 4320, 66, 66, 33, 4320, 4320, 4320, 33, 66, 4320, 33, 4320, 66, 66, 4320, 4320, 33, 66, 4320, 33, 66, 66, 33, 66, 33, 66, 4320, 4320, 66, 33, 4320, 33, 4320, 66, 66, 66, 66, 66, 33, 33, 4320, 33, 4320, 33, 66, 4320, 66, 4320, 66, 4320, 66, 4320, 33, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 33, 33, 33, 33, 33, 66, 33, 33, 66, 4320, 4320, 33, 33, 4320, 33, 33, 33, 66, 33, 66, 4320, 4320, 66, 66, 33, 4320, 66, 4320, 33, 66, 66, 33, 33, 66, 33, 4320, 4320, 33, 4320, 4320, 33, 66, 4320, 33, 33, 66, 66, 33, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 4320, 66, 66, 66, 4320, 33, 66, 66, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 66, 33, 4320, 4320, 4320, 66, 33, 4320, 4320, 66, 66, 4320, 4320, 33, 4320, 4320, 66, 33, 4320, 66, 66, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 66, 4320, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 4320, 33, 33, 33, 66, 33, 66, 66, 33, 4320, 66, 4320, 33, 4320, 33, 66, 66, 66, 66, 33, 66, 4320, 4320, 33, 4320, 4320, 33, 4320, 66, 4320, 66, 66, 66, 33, 66, 33, 33, 4320, 33, 66, 33, 33, 66, 4320, 66, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 565632 . Total input tokens: 126102881 . Total output tokens: 112978603
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.338570038788021,
    "estimated_duration": 3600.0441353400893,
    "input_throughput": 3900.253294720668,
    "output_throughput": 3459.4159215282757,
    "total_throughput": 7359.6692162489435,
    "itl": 146.94758510725092,
    "ttft": 1966295.6201202369,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1267,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.243670453541021,
    "arrivals": 188115,
    "finished_requests": 56811,
    "scheduler_time": 105.15961700021118
}
#Debug simulation 
Total elapsed time: 4.33866022201255. Arrivals time: 0.19529306096956134 Scheduler time: 3.99794586468488 Scheduler overhead time: 0.036929149646312 Adapter cache time: 0.05304303765296936 Engine time: 0.038197072222828865 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_384_slots_160_rate_0.1-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_384_slots_160_rate_0.1-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 1080, 540, 270, 1080, 1080, 270, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 270, 1080, 270, 1080, 540, 540, 540, 270, 270, 540, 270, 1080, 270, 1080, 540, 1080, 540, 270, 540, 1080, 540, 1080, 270, 1080, 1080, 1080, 1080, 270, 540, 540, 540, 1080, 540, 270, 540, 270, 1080, 540, 1080, 1080, 540, 1080, 1080, 270, 270, 1080, 540, 540, 270, 270, 270, 540, 270, 540, 270, 1080, 270, 540, 1080, 270, 1080, 540, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 1080, 1080, 540, 270, 270, 1080, 540, 540, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 270, 540, 540, 540, 540, 270, 270, 1080, 270, 1080, 270, 270, 270, 540, 540, 1080, 270, 270, 1080, 270, 1080, 540, 270, 1080, 540, 540, 270, 1080, 1080, 1080, 270, 540, 1080, 270, 1080, 540, 540, 1080, 1080, 270, 540, 1080, 270, 540, 540, 270, 540, 270, 540, 1080, 1080, 540, 270, 1080, 270, 1080, 540, 540, 540, 540, 540, 270, 270, 1080, 270, 1080, 270, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 270, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 270, 270, 270, 270, 270, 540, 270, 270, 540, 1080, 1080, 270, 270, 1080, 270, 270, 270, 540, 270, 540, 1080, 1080, 540, 540, 270, 1080, 540, 1080, 270, 540, 540, 270, 270, 540, 270, 1080, 1080, 270, 1080, 1080, 270, 540, 1080, 270, 270, 540, 540, 270, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 1080, 540, 540, 540, 1080, 270, 540, 540, 1080, 1080, 270, 1080, 1080, 270, 1080, 270, 270, 540, 270, 1080, 1080, 1080, 540, 270, 1080, 1080, 540, 540, 1080, 1080, 270, 1080, 1080, 540, 270, 1080, 540, 540, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 1080, 270, 540, 1080, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 1080, 270, 270, 270, 540, 270, 540, 540, 270, 1080, 540, 1080, 270, 1080, 270, 540, 540, 540, 540, 270, 540, 1080, 1080, 270, 1080, 1080, 270, 1080, 540, 1080, 540, 540, 540, 270, 540, 270, 270, 1080, 270, 540, 270, 270, 540, 1080, 540, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 1080, 270, 270, 270]
Prompts retrieved: 241920 . Total input tokens: 53925975 . Total output tokens: 48373036
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 14.85468706395477,
    "estimated_duration": 3600.1242145658002,
    "input_throughput": 4074.644963818064,
    "output_throughput": 3575.3460805386167,
    "total_throughput": 7649.9910443566805,
    "itl": 229.00595441666437,
    "ttft": 1302214.9606054132,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1680,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.141619409807169,
    "arrivals": 80883,
    "finished_requests": 59038,
    "scheduler_time": 66.66097107630578
}
#Debug simulation 
Total elapsed time: 14.854808962903917. Arrivals time: 0.22603647923097014 Scheduler time: 14.508684025611728 Scheduler overhead time: 0.03129601385444403 Adapter cache time: 0.043995967134833336 Engine time: 0.031659846659749746 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_384_slots_160_rate_0.1-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_384_slots_160_rate_0.1-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 1080, 540, 270, 1080, 1080, 270, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 270, 1080, 270, 1080, 540, 540, 540, 270, 270, 540, 270, 1080, 270, 1080, 540, 1080, 540, 270, 540, 1080, 540, 1080, 270, 1080, 1080, 1080, 1080, 270, 540, 540, 540, 1080, 540, 270, 540, 270, 1080, 540, 1080, 1080, 540, 1080, 1080, 270, 270, 1080, 540, 540, 270, 270, 270, 540, 270, 540, 270, 1080, 270, 540, 1080, 270, 1080, 540, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 1080, 1080, 540, 270, 270, 1080, 540, 540, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 270, 540, 540, 540, 540, 270, 270, 1080, 270, 1080, 270, 270, 270, 540, 540, 1080, 270, 270, 1080, 270, 1080, 540, 270, 1080, 540, 540, 270, 1080, 1080, 1080, 270, 540, 1080, 270, 1080, 540, 540, 1080, 1080, 270, 540, 1080, 270, 540, 540, 270, 540, 270, 540, 1080, 1080, 540, 270, 1080, 270, 1080, 540, 540, 540, 540, 540, 270, 270, 1080, 270, 1080, 270, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 270, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 270, 270, 270, 270, 270, 540, 270, 270, 540, 1080, 1080, 270, 270, 1080, 270, 270, 270, 540, 270, 540, 1080, 1080, 540, 540, 270, 1080, 540, 1080, 270, 540, 540, 270, 270, 540, 270, 1080, 1080, 270, 1080, 1080, 270, 540, 1080, 270, 270, 540, 540, 270, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 1080, 540, 540, 540, 1080, 270, 540, 540, 1080, 1080, 270, 1080, 1080, 270, 1080, 270, 270, 540, 270, 1080, 1080, 1080, 540, 270, 1080, 1080, 540, 540, 1080, 1080, 270, 1080, 1080, 540, 270, 1080, 540, 540, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 1080, 270, 540, 1080, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 1080, 270, 270, 270, 540, 270, 540, 540, 270, 1080, 540, 1080, 270, 1080, 270, 540, 540, 540, 540, 270, 540, 1080, 1080, 270, 1080, 1080, 270, 1080, 540, 1080, 540, 540, 540, 270, 540, 270, 270, 1080, 270, 540, 270, 270, 540, 1080, 540, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 1080, 270, 270, 270]
Prompts retrieved: 241920 . Total input tokens: 53925975 . Total output tokens: 48373036
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 14.870460961014032,
    "estimated_duration": 3600.0766345361553,
    "input_throughput": 4078.3651267722885,
    "output_throughput": 3574.661404855924,
    "total_throughput": 7653.026531628212,
    "itl": 228.83488321255177,
    "ttft": 1304006.2265770927,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1662,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.4225957982776425,
    "arrivals": 80883,
    "finished_requests": 59067,
    "scheduler_time": 66.68214487349817
}
#Debug simulation 
Total elapsed time: 14.870576352346689. Arrivals time: 0.22528137639164925 Scheduler time: 14.526994608342648 Scheduler overhead time: 0.030818834900856018 Adapter cache time: 0.04361399030312896 Engine time: 0.030911121983081102 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-32/adapters_384_slots_160_rate_0.1-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-32/adapters_384_slots_160_rate_0.1-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 1080, 540, 270, 1080, 1080, 270, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 270, 1080, 270, 1080, 540, 540, 540, 270, 270, 540, 270, 1080, 270, 1080, 540, 1080, 540, 270, 540, 1080, 540, 1080, 270, 1080, 1080, 1080, 1080, 270, 540, 540, 540, 1080, 540, 270, 540, 270, 1080, 540, 1080, 1080, 540, 1080, 1080, 270, 270, 1080, 540, 540, 270, 270, 270, 540, 270, 540, 270, 1080, 270, 540, 1080, 270, 1080, 540, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 1080, 1080, 540, 270, 270, 1080, 540, 540, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 270, 540, 540, 540, 540, 270, 270, 1080, 270, 1080, 270, 270, 270, 540, 540, 1080, 270, 270, 1080, 270, 1080, 540, 270, 1080, 540, 540, 270, 1080, 1080, 1080, 270, 540, 1080, 270, 1080, 540, 540, 1080, 1080, 270, 540, 1080, 270, 540, 540, 270, 540, 270, 540, 1080, 1080, 540, 270, 1080, 270, 1080, 540, 540, 540, 540, 540, 270, 270, 1080, 270, 1080, 270, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 270, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 270, 270, 270, 270, 270, 540, 270, 270, 540, 1080, 1080, 270, 270, 1080, 270, 270, 270, 540, 270, 540, 1080, 1080, 540, 540, 270, 1080, 540, 1080, 270, 540, 540, 270, 270, 540, 270, 1080, 1080, 270, 1080, 1080, 270, 540, 1080, 270, 270, 540, 540, 270, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 1080, 540, 540, 540, 1080, 270, 540, 540, 1080, 1080, 270, 1080, 1080, 270, 1080, 270, 270, 540, 270, 1080, 1080, 1080, 540, 270, 1080, 1080, 540, 540, 1080, 1080, 270, 1080, 1080, 540, 270, 1080, 540, 540, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 1080, 270, 540, 1080, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 1080, 270, 270, 270, 540, 270, 540, 540, 270, 1080, 540, 1080, 270, 1080, 270, 540, 540, 540, 540, 270, 540, 1080, 1080, 270, 1080, 1080, 270, 1080, 540, 1080, 540, 540, 540, 270, 540, 270, 270, 1080, 270, 540, 270, 270, 540, 1080, 540, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 1080, 270, 270, 270]
Prompts retrieved: 241920 . Total input tokens: 53925975 . Total output tokens: 48373036
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 6.311902184039354,
    "estimated_duration": 3600.0487202694853,
    "input_throughput": 3621.858761684748,
    "output_throughput": 3193.3781715985865,
    "total_throughput": 6815.236933283334,
    "itl": 157.0147360282056,
    "ttft": 1598407.1909079165,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4203,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.735865458565662,
    "arrivals": 80883,
    "finished_requests": 52570,
    "scheduler_time": 75.44242121501992
}
#Debug simulation 
Total elapsed time: 6.311995467171073. Arrivals time: 0.19663638714700937 Scheduler time: 5.919657193589956 Scheduler overhead time: 0.037075100466609 Adapter cache time: 0.10501900780946016 Engine time: 0.03679455351084471 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_384_slots_160_rate_0.1-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_384_slots_160_rate_0.1-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 1080, 540, 270, 1080, 1080, 270, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 270, 1080, 270, 1080, 540, 540, 540, 270, 270, 540, 270, 1080, 270, 1080, 540, 1080, 540, 270, 540, 1080, 540, 1080, 270, 1080, 1080, 1080, 1080, 270, 540, 540, 540, 1080, 540, 270, 540, 270, 1080, 540, 1080, 1080, 540, 1080, 1080, 270, 270, 1080, 540, 540, 270, 270, 270, 540, 270, 540, 270, 1080, 270, 540, 1080, 270, 1080, 540, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 1080, 1080, 540, 270, 270, 1080, 540, 540, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 270, 540, 540, 540, 540, 270, 270, 1080, 270, 1080, 270, 270, 270, 540, 540, 1080, 270, 270, 1080, 270, 1080, 540, 270, 1080, 540, 540, 270, 1080, 1080, 1080, 270, 540, 1080, 270, 1080, 540, 540, 1080, 1080, 270, 540, 1080, 270, 540, 540, 270, 540, 270, 540, 1080, 1080, 540, 270, 1080, 270, 1080, 540, 540, 540, 540, 540, 270, 270, 1080, 270, 1080, 270, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 270, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 270, 270, 270, 270, 270, 540, 270, 270, 540, 1080, 1080, 270, 270, 1080, 270, 270, 270, 540, 270, 540, 1080, 1080, 540, 540, 270, 1080, 540, 1080, 270, 540, 540, 270, 270, 540, 270, 1080, 1080, 270, 1080, 1080, 270, 540, 1080, 270, 270, 540, 540, 270, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 1080, 540, 540, 540, 1080, 270, 540, 540, 1080, 1080, 270, 1080, 1080, 270, 1080, 270, 270, 540, 270, 1080, 1080, 1080, 540, 270, 1080, 1080, 540, 540, 1080, 1080, 270, 1080, 1080, 540, 270, 1080, 540, 540, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 1080, 270, 540, 1080, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 1080, 270, 270, 270, 540, 270, 540, 540, 270, 1080, 540, 1080, 270, 1080, 270, 540, 540, 540, 540, 270, 540, 1080, 1080, 270, 1080, 1080, 270, 1080, 540, 1080, 540, 540, 540, 270, 540, 270, 270, 1080, 270, 540, 270, 270, 540, 1080, 540, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 1080, 270, 270, 270]
Prompts retrieved: 241920 . Total input tokens: 53925975 . Total output tokens: 48373036
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 14.755870230030268,
    "estimated_duration": 3600.0981343981143,
    "input_throughput": 4076.0669437843885,
    "output_throughput": 3574.1314596556736,
    "total_throughput": 7650.198403440062,
    "itl": 228.8682304550529,
    "ttft": 1303273.7163930084,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1663,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.206170162570071,
    "arrivals": 80883,
    "finished_requests": 59046,
    "scheduler_time": 66.6740043698701
}
#Debug simulation 
Total elapsed time: 14.755975264124572. Arrivals time: 0.22251362819224596 Scheduler time: 14.413838356733322 Scheduler overhead time: 0.03129049250856042 Adapter cache time: 0.04345533065497875 Engine time: 0.03170665865764022 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-32/adapters_384_slots_160_rate_0.1-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-32/adapters_384_slots_160_rate_0.1-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 1080, 540, 270, 1080, 1080, 270, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 270, 1080, 270, 1080, 540, 540, 540, 270, 270, 540, 270, 1080, 270, 1080, 540, 1080, 540, 270, 540, 1080, 540, 1080, 270, 1080, 1080, 1080, 1080, 270, 540, 540, 540, 1080, 540, 270, 540, 270, 1080, 540, 1080, 1080, 540, 1080, 1080, 270, 270, 1080, 540, 540, 270, 270, 270, 540, 270, 540, 270, 1080, 270, 540, 1080, 270, 1080, 540, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 1080, 1080, 540, 270, 270, 1080, 540, 540, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 270, 540, 540, 540, 540, 270, 270, 1080, 270, 1080, 270, 270, 270, 540, 540, 1080, 270, 270, 1080, 270, 1080, 540, 270, 1080, 540, 540, 270, 1080, 1080, 1080, 270, 540, 1080, 270, 1080, 540, 540, 1080, 1080, 270, 540, 1080, 270, 540, 540, 270, 540, 270, 540, 1080, 1080, 540, 270, 1080, 270, 1080, 540, 540, 540, 540, 540, 270, 270, 1080, 270, 1080, 270, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 270, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 270, 270, 270, 270, 270, 540, 270, 270, 540, 1080, 1080, 270, 270, 1080, 270, 270, 270, 540, 270, 540, 1080, 1080, 540, 540, 270, 1080, 540, 1080, 270, 540, 540, 270, 270, 540, 270, 1080, 1080, 270, 1080, 1080, 270, 540, 1080, 270, 270, 540, 540, 270, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 1080, 540, 540, 540, 1080, 270, 540, 540, 1080, 1080, 270, 1080, 1080, 270, 1080, 270, 270, 540, 270, 1080, 1080, 1080, 540, 270, 1080, 1080, 540, 540, 1080, 1080, 270, 1080, 1080, 540, 270, 1080, 540, 540, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 1080, 270, 540, 1080, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 1080, 270, 270, 270, 540, 270, 540, 540, 270, 1080, 540, 1080, 270, 1080, 270, 540, 540, 540, 540, 270, 540, 1080, 1080, 270, 1080, 1080, 270, 1080, 540, 1080, 540, 540, 540, 270, 540, 270, 270, 1080, 270, 540, 270, 270, 540, 1080, 540, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 1080, 270, 270, 270]
Prompts retrieved: 241920 . Total input tokens: 53925975 . Total output tokens: 48373036
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 6.367788289673626,
    "estimated_duration": 3600.141891289988,
    "input_throughput": 3621.5380931356176,
    "output_throughput": 3192.1789048936976,
    "total_throughput": 6813.716998029316,
    "itl": 156.91617921611729,
    "ttft": 1597948.3017726494,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4122,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.640387951432697,
    "arrivals": 80883,
    "finished_requests": 52536,
    "scheduler_time": 75.46211908418897
}
#Debug simulation 
Total elapsed time: 6.367900423705578. Arrivals time: 0.19984667701646686 Scheduler time: 5.975032525137067 Scheduler overhead time: 0.037423291243612766 Adapter cache time: 0.10132033564150333 Engine time: 0.037311066407710314 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_384_slots_160_rate_0.1-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_384_slots_160_rate_0.1-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 1080, 540, 270, 1080, 1080, 270, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 270, 1080, 270, 1080, 540, 540, 540, 270, 270, 540, 270, 1080, 270, 1080, 540, 1080, 540, 270, 540, 1080, 540, 1080, 270, 1080, 1080, 1080, 1080, 270, 540, 540, 540, 1080, 540, 270, 540, 270, 1080, 540, 1080, 1080, 540, 1080, 1080, 270, 270, 1080, 540, 540, 270, 270, 270, 540, 270, 540, 270, 1080, 270, 540, 1080, 270, 1080, 540, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 1080, 1080, 540, 270, 270, 1080, 540, 540, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 270, 540, 540, 540, 540, 270, 270, 1080, 270, 1080, 270, 270, 270, 540, 540, 1080, 270, 270, 1080, 270, 1080, 540, 270, 1080, 540, 540, 270, 1080, 1080, 1080, 270, 540, 1080, 270, 1080, 540, 540, 1080, 1080, 270, 540, 1080, 270, 540, 540, 270, 540, 270, 540, 1080, 1080, 540, 270, 1080, 270, 1080, 540, 540, 540, 540, 540, 270, 270, 1080, 270, 1080, 270, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 270, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 270, 270, 270, 270, 270, 540, 270, 270, 540, 1080, 1080, 270, 270, 1080, 270, 270, 270, 540, 270, 540, 1080, 1080, 540, 540, 270, 1080, 540, 1080, 270, 540, 540, 270, 270, 540, 270, 1080, 1080, 270, 1080, 1080, 270, 540, 1080, 270, 270, 540, 540, 270, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 1080, 540, 540, 540, 1080, 270, 540, 540, 1080, 1080, 270, 1080, 1080, 270, 1080, 270, 270, 540, 270, 1080, 1080, 1080, 540, 270, 1080, 1080, 540, 540, 1080, 1080, 270, 1080, 1080, 540, 270, 1080, 540, 540, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 1080, 270, 540, 1080, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 1080, 270, 270, 270, 540, 270, 540, 540, 270, 1080, 540, 1080, 270, 1080, 270, 540, 540, 540, 540, 270, 540, 1080, 1080, 270, 1080, 1080, 270, 1080, 540, 1080, 540, 540, 540, 270, 540, 270, 270, 1080, 270, 540, 270, 270, 540, 1080, 540, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 1080, 270, 270, 270]
Prompts retrieved: 241920 . Total input tokens: 53925975 . Total output tokens: 48373036
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 14.733595842961222,
    "estimated_duration": 3600.2647021262546,
    "input_throughput": 4071.4767420692715,
    "output_throughput": 3573.9213820586397,
    "total_throughput": 7645.398124127911,
    "itl": 228.9717767927171,
    "ttft": 1303836.7528798375,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1797,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.3731203799390554,
    "arrivals": 80883,
    "finished_requests": 59035,
    "scheduler_time": 66.65865770444239
}
#Debug simulation 
Total elapsed time: 14.733714031986892. Arrivals time: 0.22389666130766273 Scheduler time: 14.387873618863523 Scheduler overhead time: 0.030879516154527664 Adapter cache time: 0.046555406879633665 Engine time: 0.03133626189082861 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-32/adapters_384_slots_160_rate_0.1-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-32/adapters_384_slots_160_rate_0.1-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 1080, 540, 270, 1080, 1080, 270, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 270, 1080, 270, 1080, 540, 540, 540, 270, 270, 540, 270, 1080, 270, 1080, 540, 1080, 540, 270, 540, 1080, 540, 1080, 270, 1080, 1080, 1080, 1080, 270, 540, 540, 540, 1080, 540, 270, 540, 270, 1080, 540, 1080, 1080, 540, 1080, 1080, 270, 270, 1080, 540, 540, 270, 270, 270, 540, 270, 540, 270, 1080, 270, 540, 1080, 270, 1080, 540, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 1080, 1080, 540, 270, 270, 1080, 540, 540, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 270, 540, 540, 540, 540, 270, 270, 1080, 270, 1080, 270, 270, 270, 540, 540, 1080, 270, 270, 1080, 270, 1080, 540, 270, 1080, 540, 540, 270, 1080, 1080, 1080, 270, 540, 1080, 270, 1080, 540, 540, 1080, 1080, 270, 540, 1080, 270, 540, 540, 270, 540, 270, 540, 1080, 1080, 540, 270, 1080, 270, 1080, 540, 540, 540, 540, 540, 270, 270, 1080, 270, 1080, 270, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 270, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 270, 270, 270, 270, 270, 540, 270, 270, 540, 1080, 1080, 270, 270, 1080, 270, 270, 270, 540, 270, 540, 1080, 1080, 540, 540, 270, 1080, 540, 1080, 270, 540, 540, 270, 270, 540, 270, 1080, 1080, 270, 1080, 1080, 270, 540, 1080, 270, 270, 540, 540, 270, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 1080, 540, 540, 540, 1080, 270, 540, 540, 1080, 1080, 270, 1080, 1080, 270, 1080, 270, 270, 540, 270, 1080, 1080, 1080, 540, 270, 1080, 1080, 540, 540, 1080, 1080, 270, 1080, 1080, 540, 270, 1080, 540, 540, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 1080, 270, 540, 1080, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 1080, 270, 270, 270, 540, 270, 540, 540, 270, 1080, 540, 1080, 270, 1080, 270, 540, 540, 540, 540, 270, 540, 1080, 1080, 270, 1080, 1080, 270, 1080, 540, 1080, 540, 540, 540, 270, 540, 270, 270, 1080, 270, 540, 270, 270, 540, 1080, 540, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 1080, 270, 270, 270]
Prompts retrieved: 241920 . Total input tokens: 53925975 . Total output tokens: 48373036
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 6.2953071552328765,
    "estimated_duration": 3600.0270627425443,
    "input_throughput": 3622.0233272542237,
    "output_throughput": 3192.4657230894595,
    "total_throughput": 6814.489050343683,
    "itl": 157.01059289774636,
    "ttft": 1597934.8584949516,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4246,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.227981642856243,
    "arrivals": 80883,
    "finished_requests": 52539,
    "scheduler_time": 75.4568742171326
}
#Debug simulation 
Total elapsed time: 6.295399351976812. Arrivals time: 0.19759570248425007 Scheduler time: 5.903299750760198 Scheduler overhead time: 0.03720297012478113 Adapter cache time: 0.10322286002337933 Engine time: 0.03714099107310176 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_384_slots_160_rate_0.1-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_384_slots_160_rate_0.1-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 1080, 540, 135, 1080, 1080, 135, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 135, 1080, 135, 1080, 540, 540, 540, 135, 135, 540, 135, 1080, 135, 1080, 540, 1080, 540, 135, 540, 1080, 540, 1080, 135, 1080, 1080, 1080, 1080, 135, 540, 540, 540, 1080, 540, 135, 540, 135, 1080, 540, 1080, 1080, 540, 1080, 1080, 135, 135, 1080, 540, 540, 135, 135, 135, 540, 135, 540, 135, 1080, 135, 540, 1080, 135, 1080, 540, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 1080, 1080, 540, 135, 135, 1080, 540, 540, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 135, 540, 540, 540, 540, 135, 135, 1080, 135, 1080, 135, 135, 135, 540, 540, 1080, 135, 135, 1080, 135, 1080, 540, 135, 1080, 540, 540, 135, 1080, 1080, 1080, 135, 540, 1080, 135, 1080, 540, 540, 1080, 1080, 135, 540, 1080, 135, 540, 540, 135, 540, 135, 540, 1080, 1080, 540, 135, 1080, 135, 1080, 540, 540, 540, 540, 540, 135, 135, 1080, 135, 1080, 135, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 135, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 135, 135, 135, 135, 135, 540, 135, 135, 540, 1080, 1080, 135, 135, 1080, 135, 135, 135, 540, 135, 540, 1080, 1080, 540, 540, 135, 1080, 540, 1080, 135, 540, 540, 135, 135, 540, 135, 1080, 1080, 135, 1080, 1080, 135, 540, 1080, 135, 135, 540, 540, 135, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 1080, 540, 540, 540, 1080, 135, 540, 540, 1080, 1080, 135, 1080, 1080, 135, 1080, 135, 135, 540, 135, 1080, 1080, 1080, 540, 135, 1080, 1080, 540, 540, 1080, 1080, 135, 1080, 1080, 540, 135, 1080, 540, 540, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 1080, 135, 540, 1080, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 1080, 135, 135, 135, 540, 135, 540, 540, 135, 1080, 540, 1080, 135, 1080, 135, 540, 540, 540, 540, 135, 540, 1080, 1080, 135, 1080, 1080, 135, 1080, 540, 1080, 540, 540, 540, 135, 540, 135, 135, 1080, 135, 540, 135, 135, 540, 1080, 540, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 224640 . Total input tokens: 50059495 . Total output tokens: 44930825
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 13.754805551841855,
    "estimated_duration": 3600.218701083316,
    "input_throughput": 4092.0239083161937,
    "output_throughput": 3561.236709353811,
    "total_throughput": 7653.260617670005,
    "itl": 225.30867280156863,
    "ttft": 1060381.2349264675,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1910,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.845531590911727,
    "arrivals": 75147,
    "finished_requests": 58906,
    "scheduler_time": 62.1922513174892
}
#Debug simulation 
Total elapsed time: 13.754929433111101. Arrivals time: 0.21066108951345086 Scheduler time: 13.418647846672684 Scheduler overhead time: 0.030781926587224007 Adapter cache time: 0.050045916344970465 Engine time: 0.03166878875344992 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_384_slots_160_rate_0.1-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_384_slots_160_rate_0.1-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 1080, 540, 135, 1080, 1080, 135, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 135, 1080, 135, 1080, 540, 540, 540, 135, 135, 540, 135, 1080, 135, 1080, 540, 1080, 540, 135, 540, 1080, 540, 1080, 135, 1080, 1080, 1080, 1080, 135, 540, 540, 540, 1080, 540, 135, 540, 135, 1080, 540, 1080, 1080, 540, 1080, 1080, 135, 135, 1080, 540, 540, 135, 135, 135, 540, 135, 540, 135, 1080, 135, 540, 1080, 135, 1080, 540, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 1080, 1080, 540, 135, 135, 1080, 540, 540, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 135, 540, 540, 540, 540, 135, 135, 1080, 135, 1080, 135, 135, 135, 540, 540, 1080, 135, 135, 1080, 135, 1080, 540, 135, 1080, 540, 540, 135, 1080, 1080, 1080, 135, 540, 1080, 135, 1080, 540, 540, 1080, 1080, 135, 540, 1080, 135, 540, 540, 135, 540, 135, 540, 1080, 1080, 540, 135, 1080, 135, 1080, 540, 540, 540, 540, 540, 135, 135, 1080, 135, 1080, 135, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 135, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 135, 135, 135, 135, 135, 540, 135, 135, 540, 1080, 1080, 135, 135, 1080, 135, 135, 135, 540, 135, 540, 1080, 1080, 540, 540, 135, 1080, 540, 1080, 135, 540, 540, 135, 135, 540, 135, 1080, 1080, 135, 1080, 1080, 135, 540, 1080, 135, 135, 540, 540, 135, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 1080, 540, 540, 540, 1080, 135, 540, 540, 1080, 1080, 135, 1080, 1080, 135, 1080, 135, 135, 540, 135, 1080, 1080, 1080, 540, 135, 1080, 1080, 540, 540, 1080, 1080, 135, 1080, 1080, 540, 135, 1080, 540, 540, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 1080, 135, 540, 1080, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 1080, 135, 135, 135, 540, 135, 540, 540, 135, 1080, 540, 1080, 135, 1080, 135, 540, 540, 540, 540, 135, 540, 1080, 1080, 135, 1080, 1080, 135, 1080, 540, 1080, 540, 540, 540, 135, 540, 135, 135, 1080, 135, 540, 135, 135, 540, 1080, 540, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 224640 . Total input tokens: 50059495 . Total output tokens: 44930825
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 13.499140186235309,
    "estimated_duration": 3600.256751549917,
    "input_throughput": 4091.457642196929,
    "output_throughput": 3560.4791226296716,
    "total_throughput": 7651.936764826601,
    "itl": 225.1395104691151,
    "ttft": 1065868.9420226002,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1933,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.306446585515309,
    "arrivals": 75147,
    "finished_requests": 58925,
    "scheduler_time": 62.1866459443566
}
#Debug simulation 
Total elapsed time: 13.499234681017697. Arrivals time: 0.2178866295143962 Scheduler time: 13.155038362368941 Scheduler overhead time: 0.03087399061769247 Adapter cache time: 0.05064101051539183 Engine time: 0.03143338207155466 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-32/adapters_384_slots_160_rate_0.1-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-32/adapters_384_slots_160_rate_0.1-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 1080, 540, 135, 1080, 1080, 135, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 135, 1080, 135, 1080, 540, 540, 540, 135, 135, 540, 135, 1080, 135, 1080, 540, 1080, 540, 135, 540, 1080, 540, 1080, 135, 1080, 1080, 1080, 1080, 135, 540, 540, 540, 1080, 540, 135, 540, 135, 1080, 540, 1080, 1080, 540, 1080, 1080, 135, 135, 1080, 540, 540, 135, 135, 135, 540, 135, 540, 135, 1080, 135, 540, 1080, 135, 1080, 540, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 1080, 1080, 540, 135, 135, 1080, 540, 540, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 135, 540, 540, 540, 540, 135, 135, 1080, 135, 1080, 135, 135, 135, 540, 540, 1080, 135, 135, 1080, 135, 1080, 540, 135, 1080, 540, 540, 135, 1080, 1080, 1080, 135, 540, 1080, 135, 1080, 540, 540, 1080, 1080, 135, 540, 1080, 135, 540, 540, 135, 540, 135, 540, 1080, 1080, 540, 135, 1080, 135, 1080, 540, 540, 540, 540, 540, 135, 135, 1080, 135, 1080, 135, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 135, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 135, 135, 135, 135, 135, 540, 135, 135, 540, 1080, 1080, 135, 135, 1080, 135, 135, 135, 540, 135, 540, 1080, 1080, 540, 540, 135, 1080, 540, 1080, 135, 540, 540, 135, 135, 540, 135, 1080, 1080, 135, 1080, 1080, 135, 540, 1080, 135, 135, 540, 540, 135, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 1080, 540, 540, 540, 1080, 135, 540, 540, 1080, 1080, 135, 1080, 1080, 135, 1080, 135, 135, 540, 135, 1080, 1080, 1080, 540, 135, 1080, 1080, 540, 540, 1080, 1080, 135, 1080, 1080, 540, 135, 1080, 540, 540, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 1080, 135, 540, 1080, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 1080, 135, 135, 135, 540, 135, 540, 540, 135, 1080, 540, 1080, 135, 1080, 135, 540, 540, 540, 540, 135, 540, 1080, 1080, 135, 1080, 1080, 135, 1080, 540, 1080, 540, 540, 540, 135, 540, 135, 135, 1080, 135, 540, 135, 135, 540, 1080, 540, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 224640 . Total input tokens: 50059495 . Total output tokens: 44930825
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 6.104420802090317,
    "estimated_duration": 3600.032546417939,
    "input_throughput": 3644.5645506885908,
    "output_throughput": 3192.3761387755467,
    "total_throughput": 6836.940689464138,
    "itl": 155.95115674114984,
    "ttft": 1441957.7049339628,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3874,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.659004318545659,
    "arrivals": 75147,
    "finished_requests": 52492,
    "scheduler_time": 68.84870118824199
}
#Debug simulation 
Total elapsed time: 6.104532934259623. Arrivals time: 0.18966523930430412 Scheduler time: 5.725572579074651 Scheduler overhead time: 0.0373114594258368 Adapter cache time: 0.09769715461879969 Engine time: 0.037210636772215366 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_384_slots_160_rate_0.1-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_384_slots_160_rate_0.1-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 1080, 540, 135, 1080, 1080, 135, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 135, 1080, 135, 1080, 540, 540, 540, 135, 135, 540, 135, 1080, 135, 1080, 540, 1080, 540, 135, 540, 1080, 540, 1080, 135, 1080, 1080, 1080, 1080, 135, 540, 540, 540, 1080, 540, 135, 540, 135, 1080, 540, 1080, 1080, 540, 1080, 1080, 135, 135, 1080, 540, 540, 135, 135, 135, 540, 135, 540, 135, 1080, 135, 540, 1080, 135, 1080, 540, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 1080, 1080, 540, 135, 135, 1080, 540, 540, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 135, 540, 540, 540, 540, 135, 135, 1080, 135, 1080, 135, 135, 135, 540, 540, 1080, 135, 135, 1080, 135, 1080, 540, 135, 1080, 540, 540, 135, 1080, 1080, 1080, 135, 540, 1080, 135, 1080, 540, 540, 1080, 1080, 135, 540, 1080, 135, 540, 540, 135, 540, 135, 540, 1080, 1080, 540, 135, 1080, 135, 1080, 540, 540, 540, 540, 540, 135, 135, 1080, 135, 1080, 135, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 135, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 135, 135, 135, 135, 135, 540, 135, 135, 540, 1080, 1080, 135, 135, 1080, 135, 135, 135, 540, 135, 540, 1080, 1080, 540, 540, 135, 1080, 540, 1080, 135, 540, 540, 135, 135, 540, 135, 1080, 1080, 135, 1080, 1080, 135, 540, 1080, 135, 135, 540, 540, 135, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 1080, 540, 540, 540, 1080, 135, 540, 540, 1080, 1080, 135, 1080, 1080, 135, 1080, 135, 135, 540, 135, 1080, 1080, 1080, 540, 135, 1080, 1080, 540, 540, 1080, 1080, 135, 1080, 1080, 540, 135, 1080, 540, 540, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 1080, 135, 540, 1080, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 1080, 135, 135, 135, 540, 135, 540, 540, 135, 1080, 540, 1080, 135, 1080, 135, 540, 540, 540, 540, 135, 540, 1080, 1080, 135, 1080, 1080, 135, 1080, 540, 1080, 540, 540, 540, 135, 540, 135, 135, 1080, 135, 540, 135, 135, 540, 1080, 540, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 224640 . Total input tokens: 50059495 . Total output tokens: 44930825
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 12.941246575210243,
    "estimated_duration": 3600.172072971052,
    "input_throughput": 4086.3316257712363,
    "output_throughput": 3560.186496703337,
    "total_throughput": 7646.518122474573,
    "itl": 225.49522233989487,
    "ttft": 1063035.1603243684,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1988,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.215118682391286,
    "arrivals": 75147,
    "finished_requests": 58910,
    "scheduler_time": 62.159801037511016
}
#Debug simulation 
Total elapsed time: 12.941396608948708. Arrivals time: 0.2063423409126699 Scheduler time: 12.610128860920668 Scheduler overhead time: 0.030290787108242512 Adapter cache time: 0.0508856987580657 Engine time: 0.03066492872312665 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-32/adapters_384_slots_160_rate_0.1-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-32/adapters_384_slots_160_rate_0.1-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 1080, 540, 135, 1080, 1080, 135, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 135, 1080, 135, 1080, 540, 540, 540, 135, 135, 540, 135, 1080, 135, 1080, 540, 1080, 540, 135, 540, 1080, 540, 1080, 135, 1080, 1080, 1080, 1080, 135, 540, 540, 540, 1080, 540, 135, 540, 135, 1080, 540, 1080, 1080, 540, 1080, 1080, 135, 135, 1080, 540, 540, 135, 135, 135, 540, 135, 540, 135, 1080, 135, 540, 1080, 135, 1080, 540, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 1080, 1080, 540, 135, 135, 1080, 540, 540, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 135, 540, 540, 540, 540, 135, 135, 1080, 135, 1080, 135, 135, 135, 540, 540, 1080, 135, 135, 1080, 135, 1080, 540, 135, 1080, 540, 540, 135, 1080, 1080, 1080, 135, 540, 1080, 135, 1080, 540, 540, 1080, 1080, 135, 540, 1080, 135, 540, 540, 135, 540, 135, 540, 1080, 1080, 540, 135, 1080, 135, 1080, 540, 540, 540, 540, 540, 135, 135, 1080, 135, 1080, 135, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 135, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 135, 135, 135, 135, 135, 540, 135, 135, 540, 1080, 1080, 135, 135, 1080, 135, 135, 135, 540, 135, 540, 1080, 1080, 540, 540, 135, 1080, 540, 1080, 135, 540, 540, 135, 135, 540, 135, 1080, 1080, 135, 1080, 1080, 135, 540, 1080, 135, 135, 540, 540, 135, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 1080, 540, 540, 540, 1080, 135, 540, 540, 1080, 1080, 135, 1080, 1080, 135, 1080, 135, 135, 540, 135, 1080, 1080, 1080, 540, 135, 1080, 1080, 540, 540, 1080, 1080, 135, 1080, 1080, 540, 135, 1080, 540, 540, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 1080, 135, 540, 1080, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 1080, 135, 135, 135, 540, 135, 540, 540, 135, 1080, 540, 1080, 135, 1080, 135, 540, 540, 540, 540, 135, 540, 1080, 1080, 135, 1080, 1080, 135, 1080, 540, 1080, 540, 540, 540, 135, 540, 135, 135, 1080, 135, 540, 135, 135, 540, 1080, 540, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 224640 . Total input tokens: 50059495 . Total output tokens: 44930825
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 6.101756291929632,
    "estimated_duration": 3600.10456077678,
    "input_throughput": 3645.5202282147698,
    "output_throughput": 3194.198058936047,
    "total_throughput": 6839.718287150817,
    "itl": 156.1367528077474,
    "ttft": 1441660.326188998,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3892,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.876816003265883,
    "arrivals": 75147,
    "finished_requests": 52486,
    "scheduler_time": 68.80942516840575
}
#Debug simulation 
Total elapsed time: 6.10185202723369. Arrivals time: 0.18702358193695545 Scheduler time: 5.725834654644132 Scheduler overhead time: 0.03726130770519376 Adapter cache time: 0.0974309891462326 Engine time: 0.03727196902036667 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_384_slots_160_rate_0.1-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_384_slots_160_rate_0.1-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 1080, 540, 135, 1080, 1080, 135, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 135, 1080, 135, 1080, 540, 540, 540, 135, 135, 540, 135, 1080, 135, 1080, 540, 1080, 540, 135, 540, 1080, 540, 1080, 135, 1080, 1080, 1080, 1080, 135, 540, 540, 540, 1080, 540, 135, 540, 135, 1080, 540, 1080, 1080, 540, 1080, 1080, 135, 135, 1080, 540, 540, 135, 135, 135, 540, 135, 540, 135, 1080, 135, 540, 1080, 135, 1080, 540, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 1080, 1080, 540, 135, 135, 1080, 540, 540, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 135, 540, 540, 540, 540, 135, 135, 1080, 135, 1080, 135, 135, 135, 540, 540, 1080, 135, 135, 1080, 135, 1080, 540, 135, 1080, 540, 540, 135, 1080, 1080, 1080, 135, 540, 1080, 135, 1080, 540, 540, 1080, 1080, 135, 540, 1080, 135, 540, 540, 135, 540, 135, 540, 1080, 1080, 540, 135, 1080, 135, 1080, 540, 540, 540, 540, 540, 135, 135, 1080, 135, 1080, 135, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 135, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 135, 135, 135, 135, 135, 540, 135, 135, 540, 1080, 1080, 135, 135, 1080, 135, 135, 135, 540, 135, 540, 1080, 1080, 540, 540, 135, 1080, 540, 1080, 135, 540, 540, 135, 135, 540, 135, 1080, 1080, 135, 1080, 1080, 135, 540, 1080, 135, 135, 540, 540, 135, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 1080, 540, 540, 540, 1080, 135, 540, 540, 1080, 1080, 135, 1080, 1080, 135, 1080, 135, 135, 540, 135, 1080, 1080, 1080, 540, 135, 1080, 1080, 540, 540, 1080, 1080, 135, 1080, 1080, 540, 135, 1080, 540, 540, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 1080, 135, 540, 1080, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 1080, 135, 135, 135, 540, 135, 540, 540, 135, 1080, 540, 1080, 135, 1080, 135, 540, 540, 540, 540, 135, 540, 1080, 1080, 135, 1080, 1080, 135, 1080, 540, 1080, 540, 540, 540, 135, 540, 135, 135, 1080, 135, 540, 135, 135, 540, 1080, 540, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 224640 . Total input tokens: 50059495 . Total output tokens: 44930825
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 12.79280361533165,
    "estimated_duration": 3600.188207202858,
    "input_throughput": 4089.340932383773,
    "output_throughput": 3563.6228612525674,
    "total_throughput": 7652.963793636341,
    "itl": 225.35263013244418,
    "ttft": 1061516.502346839,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1979,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.917309533611232,
    "arrivals": 75147,
    "finished_requests": 58911,
    "scheduler_time": 62.178198707154095
}
#Debug simulation 
Total elapsed time: 12.792919110041112. Arrivals time: 0.20865267235785723 Scheduler time: 12.458787426352501 Scheduler overhead time: 0.03024923987686634 Adapter cache time: 0.051495264284312725 Engine time: 0.030634861439466476 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-32/adapters_384_slots_160_rate_0.1-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-32/adapters_384_slots_160_rate_0.1-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 1080, 540, 135, 1080, 1080, 135, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 135, 1080, 135, 1080, 540, 540, 540, 135, 135, 540, 135, 1080, 135, 1080, 540, 1080, 540, 135, 540, 1080, 540, 1080, 135, 1080, 1080, 1080, 1080, 135, 540, 540, 540, 1080, 540, 135, 540, 135, 1080, 540, 1080, 1080, 540, 1080, 1080, 135, 135, 1080, 540, 540, 135, 135, 135, 540, 135, 540, 135, 1080, 135, 540, 1080, 135, 1080, 540, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 1080, 1080, 540, 135, 135, 1080, 540, 540, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 135, 540, 540, 540, 540, 135, 135, 1080, 135, 1080, 135, 135, 135, 540, 540, 1080, 135, 135, 1080, 135, 1080, 540, 135, 1080, 540, 540, 135, 1080, 1080, 1080, 135, 540, 1080, 135, 1080, 540, 540, 1080, 1080, 135, 540, 1080, 135, 540, 540, 135, 540, 135, 540, 1080, 1080, 540, 135, 1080, 135, 1080, 540, 540, 540, 540, 540, 135, 135, 1080, 135, 1080, 135, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 135, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 135, 135, 135, 135, 135, 540, 135, 135, 540, 1080, 1080, 135, 135, 1080, 135, 135, 135, 540, 135, 540, 1080, 1080, 540, 540, 135, 1080, 540, 1080, 135, 540, 540, 135, 135, 540, 135, 1080, 1080, 135, 1080, 1080, 135, 540, 1080, 135, 135, 540, 540, 135, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 1080, 540, 540, 540, 1080, 135, 540, 540, 1080, 1080, 135, 1080, 1080, 135, 1080, 135, 135, 540, 135, 1080, 1080, 1080, 540, 135, 1080, 1080, 540, 540, 1080, 1080, 135, 1080, 1080, 540, 135, 1080, 540, 540, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 1080, 135, 540, 1080, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 1080, 135, 135, 135, 540, 135, 540, 540, 135, 1080, 540, 1080, 135, 1080, 135, 540, 540, 540, 540, 135, 540, 1080, 1080, 135, 1080, 1080, 135, 1080, 540, 1080, 540, 540, 540, 135, 540, 135, 135, 1080, 135, 540, 135, 135, 540, 1080, 540, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 224640 . Total input tokens: 50059495 . Total output tokens: 44930825
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 6.091888029593974,
    "estimated_duration": 3600.002692207661,
    "input_throughput": 3644.7642187605134,
    "output_throughput": 3191.8776130007327,
    "total_throughput": 6836.641831761246,
    "itl": 156.20694936086798,
    "ttft": 1442061.7417067937,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3982,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.342078438772889,
    "arrivals": 75147,
    "finished_requests": 52479,
    "scheduler_time": 68.80487032840838
}
#Debug simulation 
Total elapsed time: 6.09197845403105. Arrivals time: 0.1897168760187924 Scheduler time: 5.71217164862901 Scheduler overhead time: 0.03740192810073495 Adapter cache time: 0.09815648570656776 Engine time: 0.037503259256482124 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_384_slots_160_rate_0.1-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_384_slots_160_rate_0.1-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 540, 66, 1080, 1080, 66, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 66, 1080, 66, 1080, 540, 540, 540, 66, 66, 540, 66, 1080, 66, 1080, 540, 1080, 540, 66, 540, 1080, 540, 1080, 66, 1080, 1080, 1080, 1080, 66, 540, 540, 540, 1080, 540, 66, 540, 66, 1080, 540, 1080, 1080, 540, 1080, 1080, 66, 66, 1080, 540, 540, 66, 66, 66, 540, 66, 540, 66, 1080, 66, 540, 1080, 66, 1080, 540, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 1080, 1080, 540, 66, 66, 1080, 540, 540, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 66, 540, 540, 540, 540, 66, 66, 1080, 66, 1080, 66, 66, 66, 540, 540, 1080, 66, 66, 1080, 66, 1080, 540, 66, 1080, 540, 540, 66, 1080, 1080, 1080, 66, 540, 1080, 66, 1080, 540, 540, 1080, 1080, 66, 540, 1080, 66, 540, 540, 66, 540, 66, 540, 1080, 1080, 540, 66, 1080, 66, 1080, 540, 540, 540, 540, 540, 66, 66, 1080, 66, 1080, 66, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 66, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 66, 66, 66, 66, 66, 540, 66, 66, 540, 1080, 1080, 66, 66, 1080, 66, 66, 66, 540, 66, 540, 1080, 1080, 540, 540, 66, 1080, 540, 1080, 66, 540, 540, 66, 66, 540, 66, 1080, 1080, 66, 1080, 1080, 66, 540, 1080, 66, 66, 540, 540, 66, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 1080, 540, 540, 540, 1080, 66, 540, 540, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 540, 66, 1080, 1080, 1080, 540, 66, 1080, 1080, 540, 540, 1080, 1080, 66, 1080, 1080, 540, 66, 1080, 540, 540, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 540, 1080, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 1080, 66, 66, 66, 540, 66, 540, 540, 66, 1080, 540, 1080, 66, 1080, 66, 540, 540, 540, 540, 66, 540, 1080, 1080, 66, 1080, 1080, 66, 1080, 540, 1080, 540, 540, 540, 66, 540, 66, 66, 1080, 66, 540, 66, 66, 540, 1080, 540, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 215808 . Total input tokens: 48083984 . Total output tokens: 43180710
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 14.244218275882304,
    "estimated_duration": 3600.1125855829014,
    "input_throughput": 4053.6673931926803,
    "output_throughput": 3583.150996904553,
    "total_throughput": 7636.818390097233,
    "itl": 227.03092188388635,
    "ttft": 893787.6481177779,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1693,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.181405750478296,
    "arrivals": 72240,
    "finished_requests": 59089,
    "scheduler_time": 59.5792733829737
}
#Debug simulation 
Total elapsed time: 14.244328959845006. Arrivals time: 0.19831253634765744 Scheduler time: 13.926697100978345 Scheduler overhead time: 0.030749693512916565 Adapter cache time: 0.04480485478416085 Engine time: 0.03060619765892625 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_384_slots_160_rate_0.1-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_384_slots_160_rate_0.1-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 540, 66, 1080, 1080, 66, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 66, 1080, 66, 1080, 540, 540, 540, 66, 66, 540, 66, 1080, 66, 1080, 540, 1080, 540, 66, 540, 1080, 540, 1080, 66, 1080, 1080, 1080, 1080, 66, 540, 540, 540, 1080, 540, 66, 540, 66, 1080, 540, 1080, 1080, 540, 1080, 1080, 66, 66, 1080, 540, 540, 66, 66, 66, 540, 66, 540, 66, 1080, 66, 540, 1080, 66, 1080, 540, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 1080, 1080, 540, 66, 66, 1080, 540, 540, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 66, 540, 540, 540, 540, 66, 66, 1080, 66, 1080, 66, 66, 66, 540, 540, 1080, 66, 66, 1080, 66, 1080, 540, 66, 1080, 540, 540, 66, 1080, 1080, 1080, 66, 540, 1080, 66, 1080, 540, 540, 1080, 1080, 66, 540, 1080, 66, 540, 540, 66, 540, 66, 540, 1080, 1080, 540, 66, 1080, 66, 1080, 540, 540, 540, 540, 540, 66, 66, 1080, 66, 1080, 66, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 66, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 66, 66, 66, 66, 66, 540, 66, 66, 540, 1080, 1080, 66, 66, 1080, 66, 66, 66, 540, 66, 540, 1080, 1080, 540, 540, 66, 1080, 540, 1080, 66, 540, 540, 66, 66, 540, 66, 1080, 1080, 66, 1080, 1080, 66, 540, 1080, 66, 66, 540, 540, 66, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 1080, 540, 540, 540, 1080, 66, 540, 540, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 540, 66, 1080, 1080, 1080, 540, 66, 1080, 1080, 540, 540, 1080, 1080, 66, 1080, 1080, 540, 66, 1080, 540, 540, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 540, 1080, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 1080, 66, 66, 66, 540, 66, 540, 540, 66, 1080, 540, 1080, 66, 1080, 66, 540, 540, 540, 540, 66, 540, 1080, 1080, 66, 1080, 1080, 66, 1080, 540, 1080, 540, 540, 540, 66, 540, 66, 66, 1080, 66, 540, 66, 66, 540, 1080, 540, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 215808 . Total input tokens: 48083984 . Total output tokens: 43180710
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 13.56374274706468,
    "estimated_duration": 3600.193966678128,
    "input_throughput": 4065.634833976881,
    "output_throughput": 3590.449047923663,
    "total_throughput": 7656.083881900544,
    "itl": 226.8885378340977,
    "ttft": 884415.0325516167,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1774,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.788943270826554,
    "arrivals": 72240,
    "finished_requests": 59233,
    "scheduler_time": 59.59172927351516
}
#Debug simulation 
Total elapsed time: 13.563846082892269. Arrivals time: 0.2018496855162084 Scheduler time: 13.240632484667003 Scheduler overhead time: 0.030740502756088972 Adapter cache time: 0.046787573490291834 Engine time: 0.03088115295395255 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-32/adapters_384_slots_160_rate_0.1-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-32/adapters_384_slots_160_rate_0.1-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 540, 66, 1080, 1080, 66, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 66, 1080, 66, 1080, 540, 540, 540, 66, 66, 540, 66, 1080, 66, 1080, 540, 1080, 540, 66, 540, 1080, 540, 1080, 66, 1080, 1080, 1080, 1080, 66, 540, 540, 540, 1080, 540, 66, 540, 66, 1080, 540, 1080, 1080, 540, 1080, 1080, 66, 66, 1080, 540, 540, 66, 66, 66, 540, 66, 540, 66, 1080, 66, 540, 1080, 66, 1080, 540, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 1080, 1080, 540, 66, 66, 1080, 540, 540, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 66, 540, 540, 540, 540, 66, 66, 1080, 66, 1080, 66, 66, 66, 540, 540, 1080, 66, 66, 1080, 66, 1080, 540, 66, 1080, 540, 540, 66, 1080, 1080, 1080, 66, 540, 1080, 66, 1080, 540, 540, 1080, 1080, 66, 540, 1080, 66, 540, 540, 66, 540, 66, 540, 1080, 1080, 540, 66, 1080, 66, 1080, 540, 540, 540, 540, 540, 66, 66, 1080, 66, 1080, 66, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 66, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 66, 66, 66, 66, 66, 540, 66, 66, 540, 1080, 1080, 66, 66, 1080, 66, 66, 66, 540, 66, 540, 1080, 1080, 540, 540, 66, 1080, 540, 1080, 66, 540, 540, 66, 66, 540, 66, 1080, 1080, 66, 1080, 1080, 66, 540, 1080, 66, 66, 540, 540, 66, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 1080, 540, 540, 540, 1080, 66, 540, 540, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 540, 66, 1080, 1080, 1080, 540, 66, 1080, 1080, 540, 540, 1080, 1080, 66, 1080, 1080, 540, 66, 1080, 540, 540, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 540, 1080, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 1080, 66, 66, 66, 540, 66, 540, 540, 66, 1080, 540, 1080, 66, 1080, 66, 540, 540, 540, 540, 66, 540, 1080, 1080, 66, 1080, 1080, 66, 1080, 540, 1080, 540, 540, 540, 66, 540, 66, 66, 1080, 66, 540, 66, 66, 540, 1080, 540, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 215808 . Total input tokens: 48083984 . Total output tokens: 43180710
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 5.77669426612556,
    "estimated_duration": 3600.127129412205,
    "input_throughput": 3618.17472877041,
    "output_throughput": 3207.4558994491194,
    "total_throughput": 6825.63062821953,
    "itl": 157.08658431242867,
    "ttft": 1296272.1690979577,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3712,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.132566763087352,
    "arrivals": 72240,
    "finished_requests": 52734,
    "scheduler_time": 64.68305279670624
}
#Debug simulation 
Total elapsed time: 5.776786628179252. Arrivals time: 0.17821550322696567 Scheduler time: 5.413801685906947 Scheduler overhead time: 0.03707143943756819 Adapter cache time: 0.09349310304969549 Engine time: 0.037271576933562756 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_384_slots_160_rate_0.1-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_384_slots_160_rate_0.1-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 540, 66, 1080, 1080, 66, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 66, 1080, 66, 1080, 540, 540, 540, 66, 66, 540, 66, 1080, 66, 1080, 540, 1080, 540, 66, 540, 1080, 540, 1080, 66, 1080, 1080, 1080, 1080, 66, 540, 540, 540, 1080, 540, 66, 540, 66, 1080, 540, 1080, 1080, 540, 1080, 1080, 66, 66, 1080, 540, 540, 66, 66, 66, 540, 66, 540, 66, 1080, 66, 540, 1080, 66, 1080, 540, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 1080, 1080, 540, 66, 66, 1080, 540, 540, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 66, 540, 540, 540, 540, 66, 66, 1080, 66, 1080, 66, 66, 66, 540, 540, 1080, 66, 66, 1080, 66, 1080, 540, 66, 1080, 540, 540, 66, 1080, 1080, 1080, 66, 540, 1080, 66, 1080, 540, 540, 1080, 1080, 66, 540, 1080, 66, 540, 540, 66, 540, 66, 540, 1080, 1080, 540, 66, 1080, 66, 1080, 540, 540, 540, 540, 540, 66, 66, 1080, 66, 1080, 66, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 66, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 66, 66, 66, 66, 66, 540, 66, 66, 540, 1080, 1080, 66, 66, 1080, 66, 66, 66, 540, 66, 540, 1080, 1080, 540, 540, 66, 1080, 540, 1080, 66, 540, 540, 66, 66, 540, 66, 1080, 1080, 66, 1080, 1080, 66, 540, 1080, 66, 66, 540, 540, 66, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 1080, 540, 540, 540, 1080, 66, 540, 540, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 540, 66, 1080, 1080, 1080, 540, 66, 1080, 1080, 540, 540, 1080, 1080, 66, 1080, 1080, 540, 66, 1080, 540, 540, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 540, 1080, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 1080, 66, 66, 66, 540, 66, 540, 540, 66, 1080, 540, 1080, 66, 1080, 66, 540, 540, 540, 540, 66, 540, 1080, 1080, 66, 1080, 1080, 66, 1080, 540, 1080, 540, 540, 540, 66, 540, 66, 66, 1080, 66, 540, 66, 66, 540, 1080, 540, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 215808 . Total input tokens: 48083984 . Total output tokens: 43180710
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 14.251035747118294,
    "estimated_duration": 3600.090284590428,
    "input_throughput": 4052.165319976039,
    "output_throughput": 3582.9706980438923,
    "total_throughput": 7635.136018019931,
    "itl": 226.83381344748176,
    "ttft": 894582.0356036552,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1666,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.205334025812212,
    "arrivals": 72240,
    "finished_requests": 59079,
    "scheduler_time": 59.58852247863485
}
#Debug simulation 
Total elapsed time: 14.251134375110269. Arrivals time: 0.21000281954184175 Scheduler time: 13.921899246051908 Scheduler overhead time: 0.030779163353145123 Adapter cache time: 0.044240543618798256 Engine time: 0.03119181515648961 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-32/adapters_384_slots_160_rate_0.1-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-32/adapters_384_slots_160_rate_0.1-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 540, 66, 1080, 1080, 66, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 66, 1080, 66, 1080, 540, 540, 540, 66, 66, 540, 66, 1080, 66, 1080, 540, 1080, 540, 66, 540, 1080, 540, 1080, 66, 1080, 1080, 1080, 1080, 66, 540, 540, 540, 1080, 540, 66, 540, 66, 1080, 540, 1080, 1080, 540, 1080, 1080, 66, 66, 1080, 540, 540, 66, 66, 66, 540, 66, 540, 66, 1080, 66, 540, 1080, 66, 1080, 540, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 1080, 1080, 540, 66, 66, 1080, 540, 540, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 66, 540, 540, 540, 540, 66, 66, 1080, 66, 1080, 66, 66, 66, 540, 540, 1080, 66, 66, 1080, 66, 1080, 540, 66, 1080, 540, 540, 66, 1080, 1080, 1080, 66, 540, 1080, 66, 1080, 540, 540, 1080, 1080, 66, 540, 1080, 66, 540, 540, 66, 540, 66, 540, 1080, 1080, 540, 66, 1080, 66, 1080, 540, 540, 540, 540, 540, 66, 66, 1080, 66, 1080, 66, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 66, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 66, 66, 66, 66, 66, 540, 66, 66, 540, 1080, 1080, 66, 66, 1080, 66, 66, 66, 540, 66, 540, 1080, 1080, 540, 540, 66, 1080, 540, 1080, 66, 540, 540, 66, 66, 540, 66, 1080, 1080, 66, 1080, 1080, 66, 540, 1080, 66, 66, 540, 540, 66, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 1080, 540, 540, 540, 1080, 66, 540, 540, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 540, 66, 1080, 1080, 1080, 540, 66, 1080, 1080, 540, 540, 1080, 1080, 66, 1080, 1080, 540, 66, 1080, 540, 540, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 540, 1080, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 1080, 66, 66, 66, 540, 66, 540, 540, 66, 1080, 540, 1080, 66, 1080, 66, 540, 540, 540, 540, 66, 540, 1080, 1080, 66, 1080, 1080, 66, 1080, 540, 1080, 540, 540, 540, 66, 540, 66, 66, 1080, 66, 540, 66, 66, 540, 1080, 540, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 215808 . Total input tokens: 48083984 . Total output tokens: 43180710
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 5.806913722772151,
    "estimated_duration": 3599.998868769259,
    "input_throughput": 3618.385859230366,
    "output_throughput": 3205.079896023585,
    "total_throughput": 6823.465755253951,
    "itl": 157.11559437476504,
    "ttft": 1296904.7653348055,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3691,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.212709584570657,
    "arrivals": 72240,
    "finished_requests": 52717,
    "scheduler_time": 64.67558071450594
}
#Debug simulation 
Total elapsed time: 5.807006378658116. Arrivals time: 0.18665823340415955 Scheduler time: 5.437144402880222 Scheduler overhead time: 0.03723567724227905 Adapter cache time: 0.09213668713346124 Engine time: 0.03695715265348554 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_384_slots_160_rate_0.1-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_384_slots_160_rate_0.1-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 540, 66, 1080, 1080, 66, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 66, 1080, 66, 1080, 540, 540, 540, 66, 66, 540, 66, 1080, 66, 1080, 540, 1080, 540, 66, 540, 1080, 540, 1080, 66, 1080, 1080, 1080, 1080, 66, 540, 540, 540, 1080, 540, 66, 540, 66, 1080, 540, 1080, 1080, 540, 1080, 1080, 66, 66, 1080, 540, 540, 66, 66, 66, 540, 66, 540, 66, 1080, 66, 540, 1080, 66, 1080, 540, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 1080, 1080, 540, 66, 66, 1080, 540, 540, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 66, 540, 540, 540, 540, 66, 66, 1080, 66, 1080, 66, 66, 66, 540, 540, 1080, 66, 66, 1080, 66, 1080, 540, 66, 1080, 540, 540, 66, 1080, 1080, 1080, 66, 540, 1080, 66, 1080, 540, 540, 1080, 1080, 66, 540, 1080, 66, 540, 540, 66, 540, 66, 540, 1080, 1080, 540, 66, 1080, 66, 1080, 540, 540, 540, 540, 540, 66, 66, 1080, 66, 1080, 66, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 66, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 66, 66, 66, 66, 66, 540, 66, 66, 540, 1080, 1080, 66, 66, 1080, 66, 66, 66, 540, 66, 540, 1080, 1080, 540, 540, 66, 1080, 540, 1080, 66, 540, 540, 66, 66, 540, 66, 1080, 1080, 66, 1080, 1080, 66, 540, 1080, 66, 66, 540, 540, 66, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 1080, 540, 540, 540, 1080, 66, 540, 540, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 540, 66, 1080, 1080, 1080, 540, 66, 1080, 1080, 540, 540, 1080, 1080, 66, 1080, 1080, 540, 66, 1080, 540, 540, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 540, 1080, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 1080, 66, 66, 66, 540, 66, 540, 540, 66, 1080, 540, 1080, 66, 1080, 66, 540, 540, 540, 540, 66, 540, 1080, 1080, 66, 1080, 1080, 66, 1080, 540, 1080, 540, 540, 540, 66, 540, 66, 66, 1080, 66, 540, 66, 66, 540, 1080, 540, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 215808 . Total input tokens: 48083984 . Total output tokens: 43180710
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 13.124311123043299,
    "estimated_duration": 3600.0394410984827,
    "input_throughput": 4047.6809319493714,
    "output_throughput": 3580.488550444018,
    "total_throughput": 7628.169482393389,
    "itl": 227.16793502564215,
    "ttft": 895086.557424768,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1778,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.316309424335916,
    "arrivals": 72240,
    "finished_requests": 59030,
    "scheduler_time": 59.53180991510849
}
#Debug simulation 
Total elapsed time: 13.124435858335346. Arrivals time: 0.19438424380496144 Scheduler time: 12.809434582479298 Scheduler overhead time: 0.030280407518148422 Adapter cache time: 0.046454157680273056 Engine time: 0.030582884326577187 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-32/adapters_384_slots_160_rate_0.1-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-32/adapters_384_slots_160_rate_0.1-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 540, 66, 1080, 1080, 66, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 66, 1080, 66, 1080, 540, 540, 540, 66, 66, 540, 66, 1080, 66, 1080, 540, 1080, 540, 66, 540, 1080, 540, 1080, 66, 1080, 1080, 1080, 1080, 66, 540, 540, 540, 1080, 540, 66, 540, 66, 1080, 540, 1080, 1080, 540, 1080, 1080, 66, 66, 1080, 540, 540, 66, 66, 66, 540, 66, 540, 66, 1080, 66, 540, 1080, 66, 1080, 540, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 1080, 1080, 540, 66, 66, 1080, 540, 540, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 66, 540, 540, 540, 540, 66, 66, 1080, 66, 1080, 66, 66, 66, 540, 540, 1080, 66, 66, 1080, 66, 1080, 540, 66, 1080, 540, 540, 66, 1080, 1080, 1080, 66, 540, 1080, 66, 1080, 540, 540, 1080, 1080, 66, 540, 1080, 66, 540, 540, 66, 540, 66, 540, 1080, 1080, 540, 66, 1080, 66, 1080, 540, 540, 540, 540, 540, 66, 66, 1080, 66, 1080, 66, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 66, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 66, 66, 66, 66, 66, 540, 66, 66, 540, 1080, 1080, 66, 66, 1080, 66, 66, 66, 540, 66, 540, 1080, 1080, 540, 540, 66, 1080, 540, 1080, 66, 540, 540, 66, 66, 540, 66, 1080, 1080, 66, 1080, 1080, 66, 540, 1080, 66, 66, 540, 540, 66, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 1080, 540, 540, 540, 1080, 66, 540, 540, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 540, 66, 1080, 1080, 1080, 540, 66, 1080, 1080, 540, 540, 1080, 1080, 66, 1080, 1080, 540, 66, 1080, 540, 540, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 540, 1080, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 1080, 66, 66, 66, 540, 66, 540, 540, 66, 1080, 540, 1080, 66, 1080, 66, 540, 540, 540, 540, 66, 540, 1080, 1080, 66, 1080, 1080, 66, 1080, 540, 1080, 540, 540, 540, 66, 540, 66, 66, 1080, 66, 540, 66, 66, 540, 1080, 540, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 215808 . Total input tokens: 48083984 . Total output tokens: 43180710
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 5.746265875641257,
    "estimated_duration": 3600.1552109085956,
    "input_throughput": 3619.9014310582943,
    "output_throughput": 3208.390006353329,
    "total_throughput": 6828.2914374116235,
    "itl": 157.25848760689803,
    "ttft": 1294396.686406021,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3725,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.476553864068503,
    "arrivals": 72240,
    "finished_requests": 52762,
    "scheduler_time": 64.64342000044545
}
#Debug simulation 
Total elapsed time: 5.746359258890152. Arrivals time: 0.18101608147844672 Scheduler time: 5.3806757759302855 Scheduler overhead time: 0.03701549023389816 Adapter cache time: 0.09385439474135637 Engine time: 0.03690767474472523 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_384_slots_160_rate_0.1-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_384_slots_160_rate_0.1-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 540, 33, 1080, 1080, 33, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 33, 1080, 33, 1080, 540, 540, 540, 33, 33, 540, 33, 1080, 33, 1080, 540, 1080, 540, 33, 540, 1080, 540, 1080, 33, 1080, 1080, 1080, 1080, 33, 540, 540, 540, 1080, 540, 33, 540, 33, 1080, 540, 1080, 1080, 540, 1080, 1080, 33, 33, 1080, 540, 540, 33, 33, 33, 540, 33, 540, 33, 1080, 33, 540, 1080, 33, 1080, 540, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 1080, 1080, 540, 33, 33, 1080, 540, 540, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 33, 540, 540, 540, 540, 33, 33, 1080, 33, 1080, 33, 33, 33, 540, 540, 1080, 33, 33, 1080, 33, 1080, 540, 33, 1080, 540, 540, 33, 1080, 1080, 1080, 33, 540, 1080, 33, 1080, 540, 540, 1080, 1080, 33, 540, 1080, 33, 540, 540, 33, 540, 33, 540, 1080, 1080, 540, 33, 1080, 33, 1080, 540, 540, 540, 540, 540, 33, 33, 1080, 33, 1080, 33, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 33, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 33, 33, 33, 33, 33, 540, 33, 33, 540, 1080, 1080, 33, 33, 1080, 33, 33, 33, 540, 33, 540, 1080, 1080, 540, 540, 33, 1080, 540, 1080, 33, 540, 540, 33, 33, 540, 33, 1080, 1080, 33, 1080, 1080, 33, 540, 1080, 33, 33, 540, 540, 33, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 1080, 540, 540, 540, 1080, 33, 540, 540, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 540, 33, 1080, 1080, 1080, 540, 33, 1080, 1080, 540, 540, 1080, 1080, 33, 1080, 1080, 540, 33, 1080, 540, 540, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 540, 1080, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 1080, 33, 33, 33, 540, 33, 540, 540, 33, 1080, 540, 1080, 33, 1080, 33, 540, 540, 540, 540, 33, 540, 1080, 1080, 33, 1080, 1080, 33, 1080, 540, 1080, 540, 540, 540, 33, 540, 33, 33, 1080, 33, 540, 33, 33, 540, 1080, 540, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 211584 . Total input tokens: 47166834 . Total output tokens: 42349164
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 11.381185020320117,
    "estimated_duration": 3600.019961705935,
    "input_throughput": 4048.87532709482,
    "output_throughput": 3579.6115402352975,
    "total_throughput": 7628.486867330118,
    "itl": 227.82019275183558,
    "ttft": 835228.1014448511,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1852,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.668023301763621,
    "arrivals": 70816,
    "finished_requests": 58840,
    "scheduler_time": 58.69487893100063
}
#Debug simulation 
Total elapsed time: 11.381306745111942. Arrivals time: 0.19115220149978995 Scheduler time: 11.073275871574879 Scheduler overhead time: 0.028937979135662317 Adapter cache time: 0.045604787301272154 Engine time: 0.029765422455966473 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_384_slots_160_rate_0.1-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_384_slots_160_rate_0.1-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 540, 33, 1080, 1080, 33, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 33, 1080, 33, 1080, 540, 540, 540, 33, 33, 540, 33, 1080, 33, 1080, 540, 1080, 540, 33, 540, 1080, 540, 1080, 33, 1080, 1080, 1080, 1080, 33, 540, 540, 540, 1080, 540, 33, 540, 33, 1080, 540, 1080, 1080, 540, 1080, 1080, 33, 33, 1080, 540, 540, 33, 33, 33, 540, 33, 540, 33, 1080, 33, 540, 1080, 33, 1080, 540, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 1080, 1080, 540, 33, 33, 1080, 540, 540, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 33, 540, 540, 540, 540, 33, 33, 1080, 33, 1080, 33, 33, 33, 540, 540, 1080, 33, 33, 1080, 33, 1080, 540, 33, 1080, 540, 540, 33, 1080, 1080, 1080, 33, 540, 1080, 33, 1080, 540, 540, 1080, 1080, 33, 540, 1080, 33, 540, 540, 33, 540, 33, 540, 1080, 1080, 540, 33, 1080, 33, 1080, 540, 540, 540, 540, 540, 33, 33, 1080, 33, 1080, 33, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 33, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 33, 33, 33, 33, 33, 540, 33, 33, 540, 1080, 1080, 33, 33, 1080, 33, 33, 33, 540, 33, 540, 1080, 1080, 540, 540, 33, 1080, 540, 1080, 33, 540, 540, 33, 33, 540, 33, 1080, 1080, 33, 1080, 1080, 33, 540, 1080, 33, 33, 540, 540, 33, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 1080, 540, 540, 540, 1080, 33, 540, 540, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 540, 33, 1080, 1080, 1080, 540, 33, 1080, 1080, 540, 540, 1080, 1080, 33, 1080, 1080, 540, 33, 1080, 540, 540, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 540, 1080, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 1080, 33, 33, 33, 540, 33, 540, 540, 33, 1080, 540, 1080, 33, 1080, 33, 540, 540, 540, 540, 33, 540, 1080, 1080, 33, 1080, 1080, 33, 1080, 540, 1080, 540, 540, 540, 33, 540, 33, 33, 1080, 33, 540, 33, 33, 540, 1080, 540, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 211584 . Total input tokens: 47166834 . Total output tokens: 42349164
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 12.571395949926227,
    "estimated_duration": 3600.154301829622,
    "input_throughput": 4043.786954520643,
    "output_throughput": 3577.838592488635,
    "total_throughput": 7621.625547009278,
    "itl": 228.1948313387567,
    "ttft": 833763.7803617156,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1634,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.3335626508806655,
    "arrivals": 70816,
    "finished_requests": 58773,
    "scheduler_time": 58.64731008355447
}
#Debug simulation 
Total elapsed time: 12.571526709012687. Arrivals time: 0.19125719228759408 Scheduler time: 12.264892423059791 Scheduler overhead time: 0.03002267051488161 Adapter cache time: 0.04237830778583884 Engine time: 0.030220163520425558 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-32/adapters_384_slots_160_rate_0.1-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-32/adapters_384_slots_160_rate_0.1-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 540, 33, 1080, 1080, 33, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 33, 1080, 33, 1080, 540, 540, 540, 33, 33, 540, 33, 1080, 33, 1080, 540, 1080, 540, 33, 540, 1080, 540, 1080, 33, 1080, 1080, 1080, 1080, 33, 540, 540, 540, 1080, 540, 33, 540, 33, 1080, 540, 1080, 1080, 540, 1080, 1080, 33, 33, 1080, 540, 540, 33, 33, 33, 540, 33, 540, 33, 1080, 33, 540, 1080, 33, 1080, 540, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 1080, 1080, 540, 33, 33, 1080, 540, 540, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 33, 540, 540, 540, 540, 33, 33, 1080, 33, 1080, 33, 33, 33, 540, 540, 1080, 33, 33, 1080, 33, 1080, 540, 33, 1080, 540, 540, 33, 1080, 1080, 1080, 33, 540, 1080, 33, 1080, 540, 540, 1080, 1080, 33, 540, 1080, 33, 540, 540, 33, 540, 33, 540, 1080, 1080, 540, 33, 1080, 33, 1080, 540, 540, 540, 540, 540, 33, 33, 1080, 33, 1080, 33, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 33, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 33, 33, 33, 33, 33, 540, 33, 33, 540, 1080, 1080, 33, 33, 1080, 33, 33, 33, 540, 33, 540, 1080, 1080, 540, 540, 33, 1080, 540, 1080, 33, 540, 540, 33, 33, 540, 33, 1080, 1080, 33, 1080, 1080, 33, 540, 1080, 33, 33, 540, 540, 33, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 1080, 540, 540, 540, 1080, 33, 540, 540, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 540, 33, 1080, 1080, 1080, 540, 33, 1080, 1080, 540, 540, 1080, 1080, 33, 1080, 1080, 540, 33, 1080, 540, 540, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 540, 1080, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 1080, 33, 33, 33, 540, 33, 540, 540, 33, 1080, 540, 1080, 33, 1080, 33, 540, 540, 540, 540, 33, 540, 1080, 1080, 33, 1080, 1080, 33, 1080, 540, 1080, 540, 540, 540, 33, 540, 33, 33, 1080, 33, 540, 33, 33, 540, 1080, 540, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 211584 . Total input tokens: 47166834 . Total output tokens: 42349164
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 5.598466142080724,
    "estimated_duration": 3600.08054947304,
    "input_throughput": 3607.9348285418887,
    "output_throughput": 3203.161663059994,
    "total_throughput": 6811.096491601883,
    "itl": 156.36964271323194,
    "ttft": 1252306.1692430384,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3376,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.035749981104775,
    "arrivals": 70816,
    "finished_requests": 52483,
    "scheduler_time": 63.585777726075584
}
#Debug simulation 
Total elapsed time: 5.5985591458156705. Arrivals time: 0.17793273506686091 Scheduler time: 5.243170163128525 Scheduler overhead time: 0.0372470673173666 Adapter cache time: 0.08580306591466069 Engine time: 0.037351399660110474 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_384_slots_160_rate_0.1-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_384_slots_160_rate_0.1-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 540, 33, 1080, 1080, 33, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 33, 1080, 33, 1080, 540, 540, 540, 33, 33, 540, 33, 1080, 33, 1080, 540, 1080, 540, 33, 540, 1080, 540, 1080, 33, 1080, 1080, 1080, 1080, 33, 540, 540, 540, 1080, 540, 33, 540, 33, 1080, 540, 1080, 1080, 540, 1080, 1080, 33, 33, 1080, 540, 540, 33, 33, 33, 540, 33, 540, 33, 1080, 33, 540, 1080, 33, 1080, 540, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 1080, 1080, 540, 33, 33, 1080, 540, 540, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 33, 540, 540, 540, 540, 33, 33, 1080, 33, 1080, 33, 33, 33, 540, 540, 1080, 33, 33, 1080, 33, 1080, 540, 33, 1080, 540, 540, 33, 1080, 1080, 1080, 33, 540, 1080, 33, 1080, 540, 540, 1080, 1080, 33, 540, 1080, 33, 540, 540, 33, 540, 33, 540, 1080, 1080, 540, 33, 1080, 33, 1080, 540, 540, 540, 540, 540, 33, 33, 1080, 33, 1080, 33, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 33, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 33, 33, 33, 33, 33, 540, 33, 33, 540, 1080, 1080, 33, 33, 1080, 33, 33, 33, 540, 33, 540, 1080, 1080, 540, 540, 33, 1080, 540, 1080, 33, 540, 540, 33, 33, 540, 33, 1080, 1080, 33, 1080, 1080, 33, 540, 1080, 33, 33, 540, 540, 33, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 1080, 540, 540, 540, 1080, 33, 540, 540, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 540, 33, 1080, 1080, 1080, 540, 33, 1080, 1080, 540, 540, 1080, 1080, 33, 1080, 1080, 540, 33, 1080, 540, 540, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 540, 1080, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 1080, 33, 33, 33, 540, 33, 540, 540, 33, 1080, 540, 1080, 33, 1080, 33, 540, 540, 540, 540, 33, 540, 1080, 1080, 33, 1080, 1080, 33, 1080, 540, 1080, 540, 540, 540, 33, 540, 33, 33, 1080, 33, 540, 33, 33, 540, 1080, 540, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 211584 . Total input tokens: 47166834 . Total output tokens: 42349164
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 11.401922875083983,
    "estimated_duration": 3600.0310543679534,
    "input_throughput": 4048.8628514231164,
    "output_throughput": 3579.600510491284,
    "total_throughput": 7628.4633619144,
    "itl": 227.82710273966416,
    "ttft": 835219.5545839218,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1853,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.792666507931268,
    "arrivals": 70816,
    "finished_requests": 58840,
    "scheduler_time": 58.69450513092872
}
#Debug simulation 
Total elapsed time: 11.402032257057726. Arrivals time: 0.1914778877981007 Scheduler time: 11.09291632194072 Scheduler overhead time: 0.029564185068011284 Adapter cache time: 0.04558469774201512 Engine time: 0.029761887155473232 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-32/adapters_384_slots_160_rate_0.1-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-32/adapters_384_slots_160_rate_0.1-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 540, 33, 1080, 1080, 33, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 33, 1080, 33, 1080, 540, 540, 540, 33, 33, 540, 33, 1080, 33, 1080, 540, 1080, 540, 33, 540, 1080, 540, 1080, 33, 1080, 1080, 1080, 1080, 33, 540, 540, 540, 1080, 540, 33, 540, 33, 1080, 540, 1080, 1080, 540, 1080, 1080, 33, 33, 1080, 540, 540, 33, 33, 33, 540, 33, 540, 33, 1080, 33, 540, 1080, 33, 1080, 540, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 1080, 1080, 540, 33, 33, 1080, 540, 540, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 33, 540, 540, 540, 540, 33, 33, 1080, 33, 1080, 33, 33, 33, 540, 540, 1080, 33, 33, 1080, 33, 1080, 540, 33, 1080, 540, 540, 33, 1080, 1080, 1080, 33, 540, 1080, 33, 1080, 540, 540, 1080, 1080, 33, 540, 1080, 33, 540, 540, 33, 540, 33, 540, 1080, 1080, 540, 33, 1080, 33, 1080, 540, 540, 540, 540, 540, 33, 33, 1080, 33, 1080, 33, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 33, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 33, 33, 33, 33, 33, 540, 33, 33, 540, 1080, 1080, 33, 33, 1080, 33, 33, 33, 540, 33, 540, 1080, 1080, 540, 540, 33, 1080, 540, 1080, 33, 540, 540, 33, 33, 540, 33, 1080, 1080, 33, 1080, 1080, 33, 540, 1080, 33, 33, 540, 540, 33, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 1080, 540, 540, 540, 1080, 33, 540, 540, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 540, 33, 1080, 1080, 1080, 540, 33, 1080, 1080, 540, 540, 1080, 1080, 33, 1080, 1080, 540, 33, 1080, 540, 540, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 540, 1080, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 1080, 33, 33, 33, 540, 33, 540, 540, 33, 1080, 540, 1080, 33, 1080, 33, 540, 540, 540, 540, 33, 540, 1080, 1080, 33, 1080, 1080, 33, 1080, 540, 1080, 540, 540, 540, 33, 540, 33, 33, 1080, 33, 540, 33, 33, 540, 1080, 540, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 211584 . Total input tokens: 47166834 . Total output tokens: 42349164
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 5.521343287080526,
    "estimated_duration": 3600.13033619479,
    "input_throughput": 3609.7034791622796,
    "output_throughput": 3205.770881117219,
    "total_throughput": 6815.474360279498,
    "itl": 156.72226391690307,
    "ttft": 1249724.5039056777,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3393,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.231449297498292,
    "arrivals": 70816,
    "finished_requests": 52521,
    "scheduler_time": 63.53408820146957
}
#Debug simulation 
Total elapsed time: 5.5214354558847845. Arrivals time: 0.17233967734500766 Scheduler time: 5.172258296515793 Scheduler overhead time: 0.03704078169539571 Adapter cache time: 0.08591847773641348 Engine time: 0.03698190441355109 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_384_slots_160_rate_0.1-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_384_slots_160_rate_0.1-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 540, 33, 1080, 1080, 33, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 33, 1080, 33, 1080, 540, 540, 540, 33, 33, 540, 33, 1080, 33, 1080, 540, 1080, 540, 33, 540, 1080, 540, 1080, 33, 1080, 1080, 1080, 1080, 33, 540, 540, 540, 1080, 540, 33, 540, 33, 1080, 540, 1080, 1080, 540, 1080, 1080, 33, 33, 1080, 540, 540, 33, 33, 33, 540, 33, 540, 33, 1080, 33, 540, 1080, 33, 1080, 540, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 1080, 1080, 540, 33, 33, 1080, 540, 540, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 33, 540, 540, 540, 540, 33, 33, 1080, 33, 1080, 33, 33, 33, 540, 540, 1080, 33, 33, 1080, 33, 1080, 540, 33, 1080, 540, 540, 33, 1080, 1080, 1080, 33, 540, 1080, 33, 1080, 540, 540, 1080, 1080, 33, 540, 1080, 33, 540, 540, 33, 540, 33, 540, 1080, 1080, 540, 33, 1080, 33, 1080, 540, 540, 540, 540, 540, 33, 33, 1080, 33, 1080, 33, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 33, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 33, 33, 33, 33, 33, 540, 33, 33, 540, 1080, 1080, 33, 33, 1080, 33, 33, 33, 540, 33, 540, 1080, 1080, 540, 540, 33, 1080, 540, 1080, 33, 540, 540, 33, 33, 540, 33, 1080, 1080, 33, 1080, 1080, 33, 540, 1080, 33, 33, 540, 540, 33, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 1080, 540, 540, 540, 1080, 33, 540, 540, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 540, 33, 1080, 1080, 1080, 540, 33, 1080, 1080, 540, 540, 1080, 1080, 33, 1080, 1080, 540, 33, 1080, 540, 540, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 540, 1080, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 1080, 33, 33, 33, 540, 33, 540, 540, 33, 1080, 540, 1080, 33, 1080, 33, 540, 540, 540, 540, 33, 540, 1080, 1080, 33, 1080, 1080, 33, 1080, 540, 1080, 540, 540, 540, 33, 540, 33, 33, 1080, 33, 540, 33, 33, 540, 1080, 540, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 211584 . Total input tokens: 47166834 . Total output tokens: 42349164
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 11.406333357095718,
    "estimated_duration": 3600.1712437258943,
    "input_throughput": 4048.847683399199,
    "output_throughput": 3579.8933238135905,
    "total_throughput": 7628.74100721279,
    "itl": 227.81167235183398,
    "ttft": 835129.7873043789,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1852,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.537573146158669,
    "arrivals": 70816,
    "finished_requests": 58845,
    "scheduler_time": 58.69812210279267
}
#Debug simulation 
Total elapsed time: 11.40644010109827. Arrivals time: 0.18894038256257772 Scheduler time: 11.100484933238477 Scheduler overhead time: 0.029258095659315586 Adapter cache time: 0.04553182190284133 Engine time: 0.029502817429602146 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-32/adapters_384_slots_160_rate_0.1-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-32/adapters_384_slots_160_rate_0.1-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 540, 33, 1080, 1080, 33, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 33, 1080, 33, 1080, 540, 540, 540, 33, 33, 540, 33, 1080, 33, 1080, 540, 1080, 540, 33, 540, 1080, 540, 1080, 33, 1080, 1080, 1080, 1080, 33, 540, 540, 540, 1080, 540, 33, 540, 33, 1080, 540, 1080, 1080, 540, 1080, 1080, 33, 33, 1080, 540, 540, 33, 33, 33, 540, 33, 540, 33, 1080, 33, 540, 1080, 33, 1080, 540, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 1080, 1080, 540, 33, 33, 1080, 540, 540, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 33, 540, 540, 540, 540, 33, 33, 1080, 33, 1080, 33, 33, 33, 540, 540, 1080, 33, 33, 1080, 33, 1080, 540, 33, 1080, 540, 540, 33, 1080, 1080, 1080, 33, 540, 1080, 33, 1080, 540, 540, 1080, 1080, 33, 540, 1080, 33, 540, 540, 33, 540, 33, 540, 1080, 1080, 540, 33, 1080, 33, 1080, 540, 540, 540, 540, 540, 33, 33, 1080, 33, 1080, 33, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 33, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 33, 33, 33, 33, 33, 540, 33, 33, 540, 1080, 1080, 33, 33, 1080, 33, 33, 33, 540, 33, 540, 1080, 1080, 540, 540, 33, 1080, 540, 1080, 33, 540, 540, 33, 33, 540, 33, 1080, 1080, 33, 1080, 1080, 33, 540, 1080, 33, 33, 540, 540, 33, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 1080, 540, 540, 540, 1080, 33, 540, 540, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 540, 33, 1080, 1080, 1080, 540, 33, 1080, 1080, 540, 540, 1080, 1080, 33, 1080, 1080, 540, 33, 1080, 540, 540, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 540, 1080, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 1080, 33, 33, 33, 540, 33, 540, 540, 33, 1080, 540, 1080, 33, 1080, 33, 540, 540, 540, 540, 33, 540, 1080, 1080, 33, 1080, 1080, 33, 1080, 540, 1080, 540, 540, 540, 33, 540, 33, 33, 1080, 33, 540, 33, 33, 540, 1080, 540, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 211584 . Total input tokens: 47166834 . Total output tokens: 42349164
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 5.566333042923361,
    "estimated_duration": 3600.011702598117,
    "input_throughput": 3610.521318755559,
    "output_throughput": 3206.4170768304316,
    "total_throughput": 6816.938395585991,
    "itl": 156.72604444715174,
    "ttft": 1249185.8896531225,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3361,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.268241725153564,
    "arrivals": 70816,
    "finished_requests": 52544,
    "scheduler_time": 63.54253050799442
}
#Debug simulation 
Total elapsed time: 5.566461763810366. Arrivals time: 0.17407908756285906 Scheduler time: 5.214834203477949 Scheduler overhead time: 0.03709303727373481 Adapter cache time: 0.08622618764638901 Engine time: 0.03720560157671571 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_384_slots_160_rate_0.1-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_384_slots_160_rate_0.1-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 1080, 270, 135, 1080, 1080, 135, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 135, 1080, 135, 1080, 270, 270, 270, 135, 135, 270, 135, 1080, 135, 1080, 270, 1080, 270, 135, 270, 1080, 270, 1080, 135, 1080, 1080, 1080, 1080, 135, 270, 270, 270, 1080, 270, 135, 270, 135, 1080, 270, 1080, 1080, 270, 1080, 1080, 135, 135, 1080, 270, 270, 135, 135, 135, 270, 135, 270, 135, 1080, 135, 270, 1080, 135, 1080, 270, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 1080, 1080, 270, 135, 135, 1080, 270, 270, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 135, 270, 270, 270, 270, 135, 135, 1080, 135, 1080, 135, 135, 135, 270, 270, 1080, 135, 135, 1080, 135, 1080, 270, 135, 1080, 270, 270, 135, 1080, 1080, 1080, 135, 270, 1080, 135, 1080, 270, 270, 1080, 1080, 135, 270, 1080, 135, 270, 270, 135, 270, 135, 270, 1080, 1080, 270, 135, 1080, 135, 1080, 270, 270, 270, 270, 270, 135, 135, 1080, 135, 1080, 135, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 135, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 135, 135, 135, 135, 135, 270, 135, 135, 270, 1080, 1080, 135, 135, 1080, 135, 135, 135, 270, 135, 270, 1080, 1080, 270, 270, 135, 1080, 270, 1080, 135, 270, 270, 135, 135, 270, 135, 1080, 1080, 135, 1080, 1080, 135, 270, 1080, 135, 135, 270, 270, 135, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 1080, 270, 270, 270, 1080, 135, 270, 270, 1080, 1080, 135, 1080, 1080, 135, 1080, 135, 135, 270, 135, 1080, 1080, 1080, 270, 135, 1080, 1080, 270, 270, 1080, 1080, 135, 1080, 1080, 270, 135, 1080, 270, 270, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 1080, 135, 270, 1080, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 1080, 135, 135, 135, 270, 135, 270, 270, 135, 1080, 270, 1080, 135, 1080, 135, 270, 270, 270, 270, 135, 270, 1080, 1080, 135, 1080, 1080, 135, 1080, 270, 1080, 270, 270, 270, 135, 270, 135, 135, 1080, 135, 270, 135, 135, 270, 1080, 270, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 190080 . Total input tokens: 42435601 . Total output tokens: 38009403
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 10.432810188736767,
    "estimated_duration": 3600.2119425990645,
    "input_throughput": 4044.586327739322,
    "output_throughput": 3539.399402914283,
    "total_throughput": 7583.985730653605,
    "itl": 219.8785955599562,
    "ttft": 418450.9985534134,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2039,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.240334509879066,
    "arrivals": 63706,
    "finished_requests": 58405,
    "scheduler_time": 53.16871728721301
}
#Debug simulation 
Total elapsed time: 10.432905515655875. Arrivals time: 0.16423912346363068 Scheduler time: 10.14638349879533 Scheduler overhead time: 0.02977312868461013 Adapter cache time: 0.05021578958258033 Engine time: 0.029370172414928675 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_384_slots_160_rate_0.1-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_384_slots_160_rate_0.1-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 1080, 270, 135, 1080, 1080, 135, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 135, 1080, 135, 1080, 270, 270, 270, 135, 135, 270, 135, 1080, 135, 1080, 270, 1080, 270, 135, 270, 1080, 270, 1080, 135, 1080, 1080, 1080, 1080, 135, 270, 270, 270, 1080, 270, 135, 270, 135, 1080, 270, 1080, 1080, 270, 1080, 1080, 135, 135, 1080, 270, 270, 135, 135, 135, 270, 135, 270, 135, 1080, 135, 270, 1080, 135, 1080, 270, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 1080, 1080, 270, 135, 135, 1080, 270, 270, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 135, 270, 270, 270, 270, 135, 135, 1080, 135, 1080, 135, 135, 135, 270, 270, 1080, 135, 135, 1080, 135, 1080, 270, 135, 1080, 270, 270, 135, 1080, 1080, 1080, 135, 270, 1080, 135, 1080, 270, 270, 1080, 1080, 135, 270, 1080, 135, 270, 270, 135, 270, 135, 270, 1080, 1080, 270, 135, 1080, 135, 1080, 270, 270, 270, 270, 270, 135, 135, 1080, 135, 1080, 135, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 135, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 135, 135, 135, 135, 135, 270, 135, 135, 270, 1080, 1080, 135, 135, 1080, 135, 135, 135, 270, 135, 270, 1080, 1080, 270, 270, 135, 1080, 270, 1080, 135, 270, 270, 135, 135, 270, 135, 1080, 1080, 135, 1080, 1080, 135, 270, 1080, 135, 135, 270, 270, 135, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 1080, 270, 270, 270, 1080, 135, 270, 270, 1080, 1080, 135, 1080, 1080, 135, 1080, 135, 135, 270, 135, 1080, 1080, 1080, 270, 135, 1080, 1080, 270, 270, 1080, 1080, 135, 1080, 1080, 270, 135, 1080, 270, 270, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 1080, 135, 270, 1080, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 1080, 135, 135, 135, 270, 135, 270, 270, 135, 1080, 270, 1080, 135, 1080, 135, 270, 270, 270, 270, 135, 270, 1080, 1080, 135, 1080, 1080, 135, 1080, 270, 1080, 270, 270, 270, 135, 270, 135, 135, 1080, 135, 270, 135, 135, 270, 1080, 270, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 190080 . Total input tokens: 42435601 . Total output tokens: 38009403
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 11.369982047006488,
    "estimated_duration": 3600.0598230528585,
    "input_throughput": 4054.040965248068,
    "output_throughput": 3542.775016773029,
    "total_throughput": 7596.815982021098,
    "itl": 220.50489880072044,
    "ttft": 409793.2165668479,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1765,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.754269507122073,
    "arrivals": 63706,
    "finished_requests": 58515,
    "scheduler_time": 53.19598173284954
}
#Debug simulation 
Total elapsed time: 11.370098079089075. Arrivals time: 0.1704616378992796 Scheduler time: 11.081233761273324 Scheduler overhead time: 0.03001382714137435 Adapter cache time: 0.04558375338092446 Engine time: 0.029550158884376287 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-32/adapters_384_slots_160_rate_0.1-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-32/adapters_384_slots_160_rate_0.1-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 1080, 270, 135, 1080, 1080, 135, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 135, 1080, 135, 1080, 270, 270, 270, 135, 135, 270, 135, 1080, 135, 1080, 270, 1080, 270, 135, 270, 1080, 270, 1080, 135, 1080, 1080, 1080, 1080, 135, 270, 270, 270, 1080, 270, 135, 270, 135, 1080, 270, 1080, 1080, 270, 1080, 1080, 135, 135, 1080, 270, 270, 135, 135, 135, 270, 135, 270, 135, 1080, 135, 270, 1080, 135, 1080, 270, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 1080, 1080, 270, 135, 135, 1080, 270, 270, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 135, 270, 270, 270, 270, 135, 135, 1080, 135, 1080, 135, 135, 135, 270, 270, 1080, 135, 135, 1080, 135, 1080, 270, 135, 1080, 270, 270, 135, 1080, 1080, 1080, 135, 270, 1080, 135, 1080, 270, 270, 1080, 1080, 135, 270, 1080, 135, 270, 270, 135, 270, 135, 270, 1080, 1080, 270, 135, 1080, 135, 1080, 270, 270, 270, 270, 270, 135, 135, 1080, 135, 1080, 135, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 135, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 135, 135, 135, 135, 135, 270, 135, 135, 270, 1080, 1080, 135, 135, 1080, 135, 135, 135, 270, 135, 270, 1080, 1080, 270, 270, 135, 1080, 270, 1080, 135, 270, 270, 135, 135, 270, 135, 1080, 1080, 135, 1080, 1080, 135, 270, 1080, 135, 135, 270, 270, 135, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 1080, 270, 270, 270, 1080, 135, 270, 270, 1080, 1080, 135, 1080, 1080, 135, 1080, 135, 135, 270, 135, 1080, 1080, 1080, 270, 135, 1080, 1080, 270, 270, 1080, 1080, 135, 1080, 1080, 270, 135, 1080, 270, 270, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 1080, 135, 270, 1080, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 1080, 135, 135, 135, 270, 135, 270, 270, 135, 1080, 270, 1080, 135, 1080, 135, 270, 270, 270, 270, 135, 270, 1080, 1080, 135, 1080, 1080, 135, 1080, 270, 1080, 270, 270, 270, 135, 270, 135, 135, 1080, 135, 270, 135, 135, 270, 1080, 270, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 190080 . Total input tokens: 42435601 . Total output tokens: 38009403
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 5.988661323674023,
    "estimated_duration": 3600.044760507457,
    "input_throughput": 3656.334816832824,
    "output_throughput": 3205.7326416056085,
    "total_throughput": 6862.067458438432,
    "itl": 155.6189869934369,
    "ttft": 853457.9922777055,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3881,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.682669682948926,
    "arrivals": 63706,
    "finished_requests": 52732,
    "scheduler_time": 55.131249343414844
}
#Debug simulation 
Total elapsed time: 5.988783185835928. Arrivals time: 0.1622647731564939 Scheduler time: 5.639724247623235 Scheduler overhead time: 0.03774837078526616 Adapter cache time: 0.09383631823584437 Engine time: 0.03815122228115797 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_384_slots_160_rate_0.1-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_384_slots_160_rate_0.1-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 1080, 270, 135, 1080, 1080, 135, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 135, 1080, 135, 1080, 270, 270, 270, 135, 135, 270, 135, 1080, 135, 1080, 270, 1080, 270, 135, 270, 1080, 270, 1080, 135, 1080, 1080, 1080, 1080, 135, 270, 270, 270, 1080, 270, 135, 270, 135, 1080, 270, 1080, 1080, 270, 1080, 1080, 135, 135, 1080, 270, 270, 135, 135, 135, 270, 135, 270, 135, 1080, 135, 270, 1080, 135, 1080, 270, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 1080, 1080, 270, 135, 135, 1080, 270, 270, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 135, 270, 270, 270, 270, 135, 135, 1080, 135, 1080, 135, 135, 135, 270, 270, 1080, 135, 135, 1080, 135, 1080, 270, 135, 1080, 270, 270, 135, 1080, 1080, 1080, 135, 270, 1080, 135, 1080, 270, 270, 1080, 1080, 135, 270, 1080, 135, 270, 270, 135, 270, 135, 270, 1080, 1080, 270, 135, 1080, 135, 1080, 270, 270, 270, 270, 270, 135, 135, 1080, 135, 1080, 135, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 135, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 135, 135, 135, 135, 135, 270, 135, 135, 270, 1080, 1080, 135, 135, 1080, 135, 135, 135, 270, 135, 270, 1080, 1080, 270, 270, 135, 1080, 270, 1080, 135, 270, 270, 135, 135, 270, 135, 1080, 1080, 135, 1080, 1080, 135, 270, 1080, 135, 135, 270, 270, 135, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 1080, 270, 270, 270, 1080, 135, 270, 270, 1080, 1080, 135, 1080, 1080, 135, 1080, 135, 135, 270, 135, 1080, 1080, 1080, 270, 135, 1080, 1080, 270, 270, 1080, 1080, 135, 1080, 1080, 270, 135, 1080, 270, 270, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 1080, 135, 270, 1080, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 1080, 135, 135, 135, 270, 135, 270, 270, 135, 1080, 270, 1080, 135, 1080, 135, 270, 270, 270, 270, 135, 270, 1080, 1080, 135, 1080, 1080, 135, 1080, 270, 1080, 270, 270, 270, 135, 270, 135, 135, 1080, 135, 270, 135, 135, 270, 1080, 270, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 190080 . Total input tokens: 42435601 . Total output tokens: 38009403
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 10.715658336877823,
    "estimated_duration": 3600.0493320679357,
    "input_throughput": 4051.537813683703,
    "output_throughput": 3539.0331700486745,
    "total_throughput": 7590.5709837323775,
    "itl": 219.84293624903597,
    "ttft": 413910.83349506895,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2004,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.258056343288435,
    "arrivals": 63706,
    "finished_requests": 58479,
    "scheduler_time": 53.162673029537416
}
#Debug simulation 
Total elapsed time: 10.715751634910703. Arrivals time: 0.16784873232245445 Scheduler time: 10.424670410808176 Scheduler overhead time: 0.02959352545440197 Adapter cache time: 0.05076520098373294 Engine time: 0.029868584591895342 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-32/adapters_384_slots_160_rate_0.1-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-32/adapters_384_slots_160_rate_0.1-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 1080, 270, 135, 1080, 1080, 135, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 135, 1080, 135, 1080, 270, 270, 270, 135, 135, 270, 135, 1080, 135, 1080, 270, 1080, 270, 135, 270, 1080, 270, 1080, 135, 1080, 1080, 1080, 1080, 135, 270, 270, 270, 1080, 270, 135, 270, 135, 1080, 270, 1080, 1080, 270, 1080, 1080, 135, 135, 1080, 270, 270, 135, 135, 135, 270, 135, 270, 135, 1080, 135, 270, 1080, 135, 1080, 270, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 1080, 1080, 270, 135, 135, 1080, 270, 270, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 135, 270, 270, 270, 270, 135, 135, 1080, 135, 1080, 135, 135, 135, 270, 270, 1080, 135, 135, 1080, 135, 1080, 270, 135, 1080, 270, 270, 135, 1080, 1080, 1080, 135, 270, 1080, 135, 1080, 270, 270, 1080, 1080, 135, 270, 1080, 135, 270, 270, 135, 270, 135, 270, 1080, 1080, 270, 135, 1080, 135, 1080, 270, 270, 270, 270, 270, 135, 135, 1080, 135, 1080, 135, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 135, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 135, 135, 135, 135, 135, 270, 135, 135, 270, 1080, 1080, 135, 135, 1080, 135, 135, 135, 270, 135, 270, 1080, 1080, 270, 270, 135, 1080, 270, 1080, 135, 270, 270, 135, 135, 270, 135, 1080, 1080, 135, 1080, 1080, 135, 270, 1080, 135, 135, 270, 270, 135, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 1080, 270, 270, 270, 1080, 135, 270, 270, 1080, 1080, 135, 1080, 1080, 135, 1080, 135, 135, 270, 135, 1080, 1080, 1080, 270, 135, 1080, 1080, 270, 270, 1080, 1080, 135, 1080, 1080, 270, 135, 1080, 270, 270, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 1080, 135, 270, 1080, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 1080, 135, 135, 135, 270, 135, 270, 270, 135, 1080, 270, 1080, 135, 1080, 135, 270, 270, 270, 270, 135, 270, 1080, 1080, 135, 1080, 1080, 135, 1080, 270, 1080, 270, 270, 270, 135, 270, 135, 135, 1080, 135, 270, 135, 135, 270, 1080, 270, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 190080 . Total input tokens: 42435601 . Total output tokens: 38009403
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 5.977534122765064,
    "estimated_duration": 3600.0178561136013,
    "input_throughput": 3656.231864974574,
    "output_throughput": 3205.419101020109,
    "total_throughput": 6861.650965994683,
    "itl": 155.65850663801,
    "ttft": 852639.2185470281,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3828,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.67203912589617,
    "arrivals": 63706,
    "finished_requests": 52750,
    "scheduler_time": 55.126645006324495
}
#Debug simulation 
Total elapsed time: 5.977643821854144. Arrivals time: 0.16139625804498792 Scheduler time: 5.630997091066092 Scheduler overhead time: 0.037396694999188185 Adapter cache time: 0.09314811648800969 Engine time: 0.03762049414217472 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_384_slots_160_rate_0.1-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_384_slots_160_rate_0.1-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 1080, 270, 135, 1080, 1080, 135, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 135, 1080, 135, 1080, 270, 270, 270, 135, 135, 270, 135, 1080, 135, 1080, 270, 1080, 270, 135, 270, 1080, 270, 1080, 135, 1080, 1080, 1080, 1080, 135, 270, 270, 270, 1080, 270, 135, 270, 135, 1080, 270, 1080, 1080, 270, 1080, 1080, 135, 135, 1080, 270, 270, 135, 135, 135, 270, 135, 270, 135, 1080, 135, 270, 1080, 135, 1080, 270, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 1080, 1080, 270, 135, 135, 1080, 270, 270, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 135, 270, 270, 270, 270, 135, 135, 1080, 135, 1080, 135, 135, 135, 270, 270, 1080, 135, 135, 1080, 135, 1080, 270, 135, 1080, 270, 270, 135, 1080, 1080, 1080, 135, 270, 1080, 135, 1080, 270, 270, 1080, 1080, 135, 270, 1080, 135, 270, 270, 135, 270, 135, 270, 1080, 1080, 270, 135, 1080, 135, 1080, 270, 270, 270, 270, 270, 135, 135, 1080, 135, 1080, 135, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 135, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 135, 135, 135, 135, 135, 270, 135, 135, 270, 1080, 1080, 135, 135, 1080, 135, 135, 135, 270, 135, 270, 1080, 1080, 270, 270, 135, 1080, 270, 1080, 135, 270, 270, 135, 135, 270, 135, 1080, 1080, 135, 1080, 1080, 135, 270, 1080, 135, 135, 270, 270, 135, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 1080, 270, 270, 270, 1080, 135, 270, 270, 1080, 1080, 135, 1080, 1080, 135, 1080, 135, 135, 270, 135, 1080, 1080, 1080, 270, 135, 1080, 1080, 270, 270, 1080, 1080, 135, 1080, 1080, 270, 135, 1080, 270, 270, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 1080, 135, 270, 1080, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 1080, 135, 135, 135, 270, 135, 270, 270, 135, 1080, 270, 1080, 135, 1080, 135, 270, 270, 270, 270, 135, 270, 1080, 1080, 135, 1080, 1080, 135, 1080, 270, 1080, 270, 270, 270, 135, 270, 135, 135, 1080, 135, 270, 135, 135, 270, 1080, 270, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 190080 . Total input tokens: 42435601 . Total output tokens: 38009403
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 10.94273520866409,
    "estimated_duration": 3600.260127127467,
    "input_throughput": 4052.962142944451,
    "output_throughput": 3542.1504418279196,
    "total_throughput": 7595.112584772371,
    "itl": 220.19683446631967,
    "ttft": 416042.33530398936,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2050,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.129603104549279,
    "arrivals": 63706,
    "finished_requests": 58488,
    "scheduler_time": 53.16902685443789
}
#Debug simulation 
Total elapsed time: 10.94285310106352. Arrivals time: 0.16881816647946835 Scheduler time: 10.649506234563887 Scheduler overhead time: 0.029697798192501068 Adapter cache time: 0.05093824164941907 Engine time: 0.030691805761307478 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-32/adapters_384_slots_160_rate_0.1-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-32/adapters_384_slots_160_rate_0.1-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 1080, 270, 135, 1080, 1080, 135, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 135, 1080, 135, 1080, 270, 270, 270, 135, 135, 270, 135, 1080, 135, 1080, 270, 1080, 270, 135, 270, 1080, 270, 1080, 135, 1080, 1080, 1080, 1080, 135, 270, 270, 270, 1080, 270, 135, 270, 135, 1080, 270, 1080, 1080, 270, 1080, 1080, 135, 135, 1080, 270, 270, 135, 135, 135, 270, 135, 270, 135, 1080, 135, 270, 1080, 135, 1080, 270, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 1080, 1080, 270, 135, 135, 1080, 270, 270, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 135, 270, 270, 270, 270, 135, 135, 1080, 135, 1080, 135, 135, 135, 270, 270, 1080, 135, 135, 1080, 135, 1080, 270, 135, 1080, 270, 270, 135, 1080, 1080, 1080, 135, 270, 1080, 135, 1080, 270, 270, 1080, 1080, 135, 270, 1080, 135, 270, 270, 135, 270, 135, 270, 1080, 1080, 270, 135, 1080, 135, 1080, 270, 270, 270, 270, 270, 135, 135, 1080, 135, 1080, 135, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 135, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 135, 135, 135, 135, 135, 270, 135, 135, 270, 1080, 1080, 135, 135, 1080, 135, 135, 135, 270, 135, 270, 1080, 1080, 270, 270, 135, 1080, 270, 1080, 135, 270, 270, 135, 135, 270, 135, 1080, 1080, 135, 1080, 1080, 135, 270, 1080, 135, 135, 270, 270, 135, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 1080, 270, 270, 270, 1080, 135, 270, 270, 1080, 1080, 135, 1080, 1080, 135, 1080, 135, 135, 270, 135, 1080, 1080, 1080, 270, 135, 1080, 1080, 270, 270, 1080, 1080, 135, 1080, 1080, 270, 135, 1080, 270, 270, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 1080, 135, 270, 1080, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 1080, 135, 135, 135, 270, 135, 270, 270, 135, 1080, 270, 1080, 135, 1080, 135, 270, 270, 270, 270, 135, 270, 1080, 1080, 135, 1080, 1080, 135, 1080, 270, 1080, 270, 270, 270, 135, 270, 135, 135, 1080, 135, 270, 135, 135, 270, 1080, 270, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 190080 . Total input tokens: 42435601 . Total output tokens: 38009403
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 5.958595906384289,
    "estimated_duration": 3600.0973315972115,
    "input_throughput": 3655.99504337862,
    "output_throughput": 3205.2419524114785,
    "total_throughput": 6861.236995790098,
    "itl": 155.64425699922344,
    "ttft": 853392.3984454615,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3934,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.18256249688481,
    "arrivals": 63706,
    "finished_requests": 52735,
    "scheduler_time": 55.12347898653534
}
#Debug simulation 
Total elapsed time: 5.958688926417381. Arrivals time: 0.1603154856711626 Scheduler time: 5.610623583663255 Scheduler overhead time: 0.037768364418298006 Adapter cache time: 0.09542216779664159 Engine time: 0.03749903989955783 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_384_slots_160_rate_0.1-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_384_slots_160_rate_0.1-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 270, 66, 1080, 1080, 66, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 66, 1080, 66, 1080, 270, 270, 270, 66, 66, 270, 66, 1080, 66, 1080, 270, 1080, 270, 66, 270, 1080, 270, 1080, 66, 1080, 1080, 1080, 1080, 66, 270, 270, 270, 1080, 270, 66, 270, 66, 1080, 270, 1080, 1080, 270, 1080, 1080, 66, 66, 1080, 270, 270, 66, 66, 66, 270, 66, 270, 66, 1080, 66, 270, 1080, 66, 1080, 270, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 1080, 1080, 270, 66, 66, 1080, 270, 270, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 66, 270, 270, 270, 270, 66, 66, 1080, 66, 1080, 66, 66, 66, 270, 270, 1080, 66, 66, 1080, 66, 1080, 270, 66, 1080, 270, 270, 66, 1080, 1080, 1080, 66, 270, 1080, 66, 1080, 270, 270, 1080, 1080, 66, 270, 1080, 66, 270, 270, 66, 270, 66, 270, 1080, 1080, 270, 66, 1080, 66, 1080, 270, 270, 270, 270, 270, 66, 66, 1080, 66, 1080, 66, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 66, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 66, 66, 66, 66, 66, 270, 66, 66, 270, 1080, 1080, 66, 66, 1080, 66, 66, 66, 270, 66, 270, 1080, 1080, 270, 270, 66, 1080, 270, 1080, 66, 270, 270, 66, 66, 270, 66, 1080, 1080, 66, 1080, 1080, 66, 270, 1080, 66, 66, 270, 270, 66, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 1080, 270, 270, 270, 1080, 66, 270, 270, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 270, 66, 1080, 1080, 1080, 270, 66, 1080, 1080, 270, 270, 1080, 1080, 66, 1080, 1080, 270, 66, 1080, 270, 270, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 270, 1080, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 1080, 66, 66, 66, 270, 66, 270, 270, 66, 1080, 270, 1080, 66, 1080, 66, 270, 270, 270, 270, 66, 270, 1080, 1080, 66, 1080, 1080, 66, 1080, 270, 1080, 270, 270, 270, 66, 270, 66, 66, 1080, 66, 270, 66, 66, 270, 1080, 270, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 181248 . Total input tokens: 40496111 . Total output tokens: 36247495
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 10.405892196111381,
    "estimated_duration": 3600.0430609936293,
    "input_throughput": 3980.53960944701,
    "output_throughput": 3504.5803025805326,
    "total_throughput": 7485.119912027542,
    "itl": 211.67513013063615,
    "ttft": 259891.22263707724,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1862,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.69862817920295,
    "arrivals": 60894,
    "finished_requests": 57763,
    "scheduler_time": 51.089104002159345
}
#Debug simulation 
Total elapsed time: 10.40599914919585. Arrivals time: 0.1614543334580958 Scheduler time: 10.123368015512824 Scheduler overhead time: 0.030193950980901718 Adapter cache time: 0.04673838382586837 Engine time: 0.0307565457187593 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_384_slots_160_rate_0.1-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_384_slots_160_rate_0.1-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 270, 66, 1080, 1080, 66, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 66, 1080, 66, 1080, 270, 270, 270, 66, 66, 270, 66, 1080, 66, 1080, 270, 1080, 270, 66, 270, 1080, 270, 1080, 66, 1080, 1080, 1080, 1080, 66, 270, 270, 270, 1080, 270, 66, 270, 66, 1080, 270, 1080, 1080, 270, 1080, 1080, 66, 66, 1080, 270, 270, 66, 66, 66, 270, 66, 270, 66, 1080, 66, 270, 1080, 66, 1080, 270, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 1080, 1080, 270, 66, 66, 1080, 270, 270, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 66, 270, 270, 270, 270, 66, 66, 1080, 66, 1080, 66, 66, 66, 270, 270, 1080, 66, 66, 1080, 66, 1080, 270, 66, 1080, 270, 270, 66, 1080, 1080, 1080, 66, 270, 1080, 66, 1080, 270, 270, 1080, 1080, 66, 270, 1080, 66, 270, 270, 66, 270, 66, 270, 1080, 1080, 270, 66, 1080, 66, 1080, 270, 270, 270, 270, 270, 66, 66, 1080, 66, 1080, 66, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 66, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 66, 66, 66, 66, 66, 270, 66, 66, 270, 1080, 1080, 66, 66, 1080, 66, 66, 66, 270, 66, 270, 1080, 1080, 270, 270, 66, 1080, 270, 1080, 66, 270, 270, 66, 66, 270, 66, 1080, 1080, 66, 1080, 1080, 66, 270, 1080, 66, 66, 270, 270, 66, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 1080, 270, 270, 270, 1080, 66, 270, 270, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 270, 66, 1080, 1080, 1080, 270, 66, 1080, 1080, 270, 270, 1080, 1080, 66, 1080, 1080, 270, 66, 1080, 270, 270, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 270, 1080, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 1080, 66, 66, 66, 270, 66, 270, 270, 66, 1080, 270, 1080, 66, 1080, 66, 270, 270, 270, 270, 66, 270, 1080, 1080, 66, 1080, 1080, 66, 1080, 270, 1080, 270, 270, 270, 66, 270, 66, 66, 1080, 66, 270, 66, 66, 270, 1080, 270, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 181248 . Total input tokens: 40496111 . Total output tokens: 36247495
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 10.513581675942987,
    "estimated_duration": 3600.0553164658245,
    "input_throughput": 3983.4810133079623,
    "output_throughput": 3505.9600174118095,
    "total_throughput": 7489.441030719772,
    "itl": 212.0017880466164,
    "ttft": 255181.017107729,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1817,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.924461553920828,
    "arrivals": 60894,
    "finished_requests": 57836,
    "scheduler_time": 51.10215075028168
}
#Debug simulation 
Total elapsed time: 10.513699879869819. Arrivals time: 0.15695266192778945 Scheduler time: 10.237189471255988 Scheduler overhead time: 0.03013923577964306 Adapter cache time: 0.04555779788643122 Engine time: 0.030410486739128828 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_384_slots_160_rate_0.1-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_384_slots_160_rate_0.1-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 270, 66, 1080, 1080, 66, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 66, 1080, 66, 1080, 270, 270, 270, 66, 66, 270, 66, 1080, 66, 1080, 270, 1080, 270, 66, 270, 1080, 270, 1080, 66, 1080, 1080, 1080, 1080, 66, 270, 270, 270, 1080, 270, 66, 270, 66, 1080, 270, 1080, 1080, 270, 1080, 1080, 66, 66, 1080, 270, 270, 66, 66, 66, 270, 66, 270, 66, 1080, 66, 270, 1080, 66, 1080, 270, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 1080, 1080, 270, 66, 66, 1080, 270, 270, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 66, 270, 270, 270, 270, 66, 66, 1080, 66, 1080, 66, 66, 66, 270, 270, 1080, 66, 66, 1080, 66, 1080, 270, 66, 1080, 270, 270, 66, 1080, 1080, 1080, 66, 270, 1080, 66, 1080, 270, 270, 1080, 1080, 66, 270, 1080, 66, 270, 270, 66, 270, 66, 270, 1080, 1080, 270, 66, 1080, 66, 1080, 270, 270, 270, 270, 270, 66, 66, 1080, 66, 1080, 66, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 66, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 66, 66, 66, 66, 66, 270, 66, 66, 270, 1080, 1080, 66, 66, 1080, 66, 66, 66, 270, 66, 270, 1080, 1080, 270, 270, 66, 1080, 270, 1080, 66, 270, 270, 66, 66, 270, 66, 1080, 1080, 66, 1080, 1080, 66, 270, 1080, 66, 66, 270, 270, 66, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 1080, 270, 270, 270, 1080, 66, 270, 270, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 270, 66, 1080, 1080, 1080, 270, 66, 1080, 1080, 270, 270, 1080, 1080, 66, 1080, 1080, 270, 66, 1080, 270, 270, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 270, 1080, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 1080, 66, 66, 66, 270, 66, 270, 270, 66, 1080, 270, 1080, 66, 1080, 66, 270, 270, 270, 270, 66, 270, 1080, 1080, 66, 1080, 1080, 66, 1080, 270, 1080, 270, 270, 270, 66, 270, 66, 66, 1080, 66, 270, 66, 66, 270, 1080, 270, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 181248 . Total input tokens: 40496111 . Total output tokens: 36247495
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 5.566132929176092,
    "estimated_duration": 3600.0851985847603,
    "input_throughput": 3625.09420752886,
    "output_throughput": 3206.166344212491,
    "total_throughput": 6831.26055174135,
    "itl": 155.43950846361616,
    "ttft": 675360.1112070424,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3822,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.487251438628062,
    "arrivals": 60894,
    "finished_requests": 52643,
    "scheduler_time": 51.92774927120003
}
#Debug simulation 
Total elapsed time: 5.566228561103344. Arrivals time: 0.15414613718166947 Scheduler time: 5.225518841296434 Scheduler overhead time: 0.0375677440315485 Adapter cache time: 0.09450939763337374 Engine time: 0.03739621350541711 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_384_slots_160_rate_0.1-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_384_slots_160_rate_0.1-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 270, 66, 1080, 1080, 66, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 66, 1080, 66, 1080, 270, 270, 270, 66, 66, 270, 66, 1080, 66, 1080, 270, 1080, 270, 66, 270, 1080, 270, 1080, 66, 1080, 1080, 1080, 1080, 66, 270, 270, 270, 1080, 270, 66, 270, 66, 1080, 270, 1080, 1080, 270, 1080, 1080, 66, 66, 1080, 270, 270, 66, 66, 66, 270, 66, 270, 66, 1080, 66, 270, 1080, 66, 1080, 270, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 1080, 1080, 270, 66, 66, 1080, 270, 270, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 66, 270, 270, 270, 270, 66, 66, 1080, 66, 1080, 66, 66, 66, 270, 270, 1080, 66, 66, 1080, 66, 1080, 270, 66, 1080, 270, 270, 66, 1080, 1080, 1080, 66, 270, 1080, 66, 1080, 270, 270, 1080, 1080, 66, 270, 1080, 66, 270, 270, 66, 270, 66, 270, 1080, 1080, 270, 66, 1080, 66, 1080, 270, 270, 270, 270, 270, 66, 66, 1080, 66, 1080, 66, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 66, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 66, 66, 66, 66, 66, 270, 66, 66, 270, 1080, 1080, 66, 66, 1080, 66, 66, 66, 270, 66, 270, 1080, 1080, 270, 270, 66, 1080, 270, 1080, 66, 270, 270, 66, 66, 270, 66, 1080, 1080, 66, 1080, 1080, 66, 270, 1080, 66, 66, 270, 270, 66, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 1080, 270, 270, 270, 1080, 66, 270, 270, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 270, 66, 1080, 1080, 1080, 270, 66, 1080, 1080, 270, 270, 1080, 1080, 66, 1080, 1080, 270, 66, 1080, 270, 270, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 270, 1080, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 1080, 66, 66, 66, 270, 66, 270, 270, 66, 1080, 270, 1080, 66, 1080, 66, 270, 270, 270, 270, 66, 270, 1080, 1080, 66, 1080, 1080, 66, 1080, 270, 1080, 270, 270, 270, 66, 270, 66, 66, 1080, 66, 270, 66, 66, 270, 1080, 270, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 181248 . Total input tokens: 40496111 . Total output tokens: 36247495
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 10.446716527920216,
    "estimated_duration": 3600.121858577077,
    "input_throughput": 3983.299889095401,
    "output_throughput": 3505.6541127716923,
    "total_throughput": 7488.954001867093,
    "itl": 211.7149753702153,
    "ttft": 257680.23961709146,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1828,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.710151939508351,
    "arrivals": 60894,
    "finished_requests": 57805,
    "scheduler_time": 51.09055751299869
}
#Debug simulation 
Total elapsed time: 10.446826963685453. Arrivals time: 0.16440189303830266 Scheduler time: 10.160729761235416 Scheduler overhead time: 0.03056166460737586 Adapter cache time: 0.04722619382664561 Engine time: 0.03039986500516534 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_384_slots_160_rate_0.1-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_384_slots_160_rate_0.1-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 270, 66, 1080, 1080, 66, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 66, 1080, 66, 1080, 270, 270, 270, 66, 66, 270, 66, 1080, 66, 1080, 270, 1080, 270, 66, 270, 1080, 270, 1080, 66, 1080, 1080, 1080, 1080, 66, 270, 270, 270, 1080, 270, 66, 270, 66, 1080, 270, 1080, 1080, 270, 1080, 1080, 66, 66, 1080, 270, 270, 66, 66, 66, 270, 66, 270, 66, 1080, 66, 270, 1080, 66, 1080, 270, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 1080, 1080, 270, 66, 66, 1080, 270, 270, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 66, 270, 270, 270, 270, 66, 66, 1080, 66, 1080, 66, 66, 66, 270, 270, 1080, 66, 66, 1080, 66, 1080, 270, 66, 1080, 270, 270, 66, 1080, 1080, 1080, 66, 270, 1080, 66, 1080, 270, 270, 1080, 1080, 66, 270, 1080, 66, 270, 270, 66, 270, 66, 270, 1080, 1080, 270, 66, 1080, 66, 1080, 270, 270, 270, 270, 270, 66, 66, 1080, 66, 1080, 66, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 66, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 66, 66, 66, 66, 66, 270, 66, 66, 270, 1080, 1080, 66, 66, 1080, 66, 66, 66, 270, 66, 270, 1080, 1080, 270, 270, 66, 1080, 270, 1080, 66, 270, 270, 66, 66, 270, 66, 1080, 1080, 66, 1080, 1080, 66, 270, 1080, 66, 66, 270, 270, 66, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 1080, 270, 270, 270, 1080, 66, 270, 270, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 270, 66, 1080, 1080, 1080, 270, 66, 1080, 1080, 270, 270, 1080, 1080, 66, 1080, 1080, 270, 66, 1080, 270, 270, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 270, 1080, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 1080, 66, 66, 66, 270, 66, 270, 270, 66, 1080, 270, 1080, 66, 1080, 66, 270, 270, 270, 270, 66, 270, 1080, 1080, 66, 1080, 1080, 66, 1080, 270, 1080, 270, 270, 270, 66, 270, 66, 66, 1080, 66, 270, 66, 66, 270, 1080, 270, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 181248 . Total input tokens: 40496111 . Total output tokens: 36247495
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 5.5354714542627335,
    "estimated_duration": 3600.0320533859804,
    "input_throughput": 3625.929104637464,
    "output_throughput": 3206.4403396472694,
    "total_throughput": 6832.369444284734,
    "itl": 155.40853818515583,
    "ttft": 675079.4205757288,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3778,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.50027995148594,
    "arrivals": 60894,
    "finished_requests": 52644,
    "scheduler_time": 51.925254275063764
}
#Debug simulation 
Total elapsed time: 5.535592040978372. Arrivals time: 0.15221861330792308 Scheduler time: 5.197925866115838 Scheduler overhead time: 0.037603314500302076 Adapter cache time: 0.09273439506068826 Engine time: 0.037971257232129574 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_384_slots_160_rate_0.1-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_384_slots_160_rate_0.1-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 270, 66, 1080, 1080, 66, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 66, 1080, 66, 1080, 270, 270, 270, 66, 66, 270, 66, 1080, 66, 1080, 270, 1080, 270, 66, 270, 1080, 270, 1080, 66, 1080, 1080, 1080, 1080, 66, 270, 270, 270, 1080, 270, 66, 270, 66, 1080, 270, 1080, 1080, 270, 1080, 1080, 66, 66, 1080, 270, 270, 66, 66, 66, 270, 66, 270, 66, 1080, 66, 270, 1080, 66, 1080, 270, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 1080, 1080, 270, 66, 66, 1080, 270, 270, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 66, 270, 270, 270, 270, 66, 66, 1080, 66, 1080, 66, 66, 66, 270, 270, 1080, 66, 66, 1080, 66, 1080, 270, 66, 1080, 270, 270, 66, 1080, 1080, 1080, 66, 270, 1080, 66, 1080, 270, 270, 1080, 1080, 66, 270, 1080, 66, 270, 270, 66, 270, 66, 270, 1080, 1080, 270, 66, 1080, 66, 1080, 270, 270, 270, 270, 270, 66, 66, 1080, 66, 1080, 66, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 66, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 66, 66, 66, 66, 66, 270, 66, 66, 270, 1080, 1080, 66, 66, 1080, 66, 66, 66, 270, 66, 270, 1080, 1080, 270, 270, 66, 1080, 270, 1080, 66, 270, 270, 66, 66, 270, 66, 1080, 1080, 66, 1080, 1080, 66, 270, 1080, 66, 66, 270, 270, 66, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 1080, 270, 270, 270, 1080, 66, 270, 270, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 270, 66, 1080, 1080, 1080, 270, 66, 1080, 1080, 270, 270, 1080, 1080, 66, 1080, 1080, 270, 66, 1080, 270, 270, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 270, 1080, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 1080, 66, 66, 66, 270, 66, 270, 270, 66, 1080, 270, 1080, 66, 1080, 66, 270, 270, 270, 270, 66, 270, 1080, 1080, 66, 1080, 1080, 66, 1080, 270, 1080, 270, 270, 270, 66, 270, 66, 66, 1080, 66, 270, 66, 66, 270, 1080, 270, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 181248 . Total input tokens: 40496111 . Total output tokens: 36247495
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 10.348718448076397,
    "estimated_duration": 3600.0837894229285,
    "input_throughput": 3982.6311937862597,
    "output_throughput": 3507.1797598421713,
    "total_throughput": 7489.810953628431,
    "itl": 211.74960664517457,
    "ttft": 257197.62343417198,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1850,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.531593045568865,
    "arrivals": 60894,
    "finished_requests": 57833,
    "scheduler_time": 51.0949304595168
}
#Debug simulation 
Total elapsed time: 10.34881215216592. Arrivals time: 0.16867042938247323 Scheduler time: 10.058878098614514 Scheduler overhead time: 0.030245324596762657 Adapter cache time: 0.04707638779655099 Engine time: 0.03051378857344389 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_384_slots_160_rate_0.1-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_384_slots_160_rate_0.1-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 270, 66, 1080, 1080, 66, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 66, 1080, 66, 1080, 270, 270, 270, 66, 66, 270, 66, 1080, 66, 1080, 270, 1080, 270, 66, 270, 1080, 270, 1080, 66, 1080, 1080, 1080, 1080, 66, 270, 270, 270, 1080, 270, 66, 270, 66, 1080, 270, 1080, 1080, 270, 1080, 1080, 66, 66, 1080, 270, 270, 66, 66, 66, 270, 66, 270, 66, 1080, 66, 270, 1080, 66, 1080, 270, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 1080, 1080, 270, 66, 66, 1080, 270, 270, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 66, 270, 270, 270, 270, 66, 66, 1080, 66, 1080, 66, 66, 66, 270, 270, 1080, 66, 66, 1080, 66, 1080, 270, 66, 1080, 270, 270, 66, 1080, 1080, 1080, 66, 270, 1080, 66, 1080, 270, 270, 1080, 1080, 66, 270, 1080, 66, 270, 270, 66, 270, 66, 270, 1080, 1080, 270, 66, 1080, 66, 1080, 270, 270, 270, 270, 270, 66, 66, 1080, 66, 1080, 66, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 66, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 66, 66, 66, 66, 66, 270, 66, 66, 270, 1080, 1080, 66, 66, 1080, 66, 66, 66, 270, 66, 270, 1080, 1080, 270, 270, 66, 1080, 270, 1080, 66, 270, 270, 66, 66, 270, 66, 1080, 1080, 66, 1080, 1080, 66, 270, 1080, 66, 66, 270, 270, 66, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 1080, 270, 270, 270, 1080, 66, 270, 270, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 270, 66, 1080, 1080, 1080, 270, 66, 1080, 1080, 270, 270, 1080, 1080, 66, 1080, 1080, 270, 66, 1080, 270, 270, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 270, 1080, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 1080, 66, 66, 66, 270, 66, 270, 270, 66, 1080, 270, 1080, 66, 1080, 66, 270, 270, 270, 270, 66, 270, 1080, 1080, 66, 1080, 1080, 66, 1080, 270, 1080, 270, 270, 270, 66, 270, 66, 66, 1080, 66, 270, 66, 66, 270, 1080, 270, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 181248 . Total input tokens: 40496111 . Total output tokens: 36247495
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 5.572404381819069,
    "estimated_duration": 3600.004344493233,
    "input_throughput": 3625.694513387423,
    "output_throughput": 3206.2127973972774,
    "total_throughput": 6831.9073107847,
    "itl": 155.42672528180003,
    "ttft": 675701.4807205662,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3801,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.733789368308274,
    "arrivals": 60894,
    "finished_requests": 52635,
    "scheduler_time": 51.92584803662385
}
#Debug simulation 
Total elapsed time: 5.572514875791967. Arrivals time: 0.15625085169449449 Scheduler time: 5.231387993786484 Scheduler overhead time: 0.03748533595353365 Adapter cache time: 0.09273612825199962 Engine time: 0.03754423186182976 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_384_slots_160_rate_0.1-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_384_slots_160_rate_0.1-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 270, 33, 1080, 1080, 33, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 33, 1080, 33, 1080, 270, 270, 270, 33, 33, 270, 33, 1080, 33, 1080, 270, 1080, 270, 33, 270, 1080, 270, 1080, 33, 1080, 1080, 1080, 1080, 33, 270, 270, 270, 1080, 270, 33, 270, 33, 1080, 270, 1080, 1080, 270, 1080, 1080, 33, 33, 1080, 270, 270, 33, 33, 33, 270, 33, 270, 33, 1080, 33, 270, 1080, 33, 1080, 270, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 1080, 1080, 270, 33, 33, 1080, 270, 270, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 33, 270, 270, 270, 270, 33, 33, 1080, 33, 1080, 33, 33, 33, 270, 270, 1080, 33, 33, 1080, 33, 1080, 270, 33, 1080, 270, 270, 33, 1080, 1080, 1080, 33, 270, 1080, 33, 1080, 270, 270, 1080, 1080, 33, 270, 1080, 33, 270, 270, 33, 270, 33, 270, 1080, 1080, 270, 33, 1080, 33, 1080, 270, 270, 270, 270, 270, 33, 33, 1080, 33, 1080, 33, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 33, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 33, 33, 33, 33, 33, 270, 33, 33, 270, 1080, 1080, 33, 33, 1080, 33, 33, 33, 270, 33, 270, 1080, 1080, 270, 270, 33, 1080, 270, 1080, 33, 270, 270, 33, 33, 270, 33, 1080, 1080, 33, 1080, 1080, 33, 270, 1080, 33, 33, 270, 270, 33, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 1080, 270, 270, 270, 1080, 33, 270, 270, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 270, 33, 1080, 1080, 1080, 270, 33, 1080, 1080, 270, 270, 1080, 1080, 33, 1080, 1080, 270, 33, 1080, 270, 270, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 270, 1080, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 1080, 33, 33, 33, 270, 33, 270, 270, 33, 1080, 270, 1080, 33, 1080, 33, 270, 270, 270, 270, 33, 270, 1080, 1080, 33, 1080, 1080, 33, 1080, 270, 1080, 270, 270, 270, 33, 270, 33, 33, 1080, 33, 270, 33, 33, 270, 1080, 270, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 177024 . Total input tokens: 39529967 . Total output tokens: 35428185
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 8.765739309135824,
    "estimated_duration": 3600.033198964657,
    "input_throughput": 3964.106221049353,
    "output_throughput": 3484.1331473296614,
    "total_throughput": 7448.239368379014,
    "itl": 203.50989715026503,
    "ttft": 185216.61877416482,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1881,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.756777446337674,
    "arrivals": 59412,
    "finished_requests": 57197,
    "scheduler_time": 49.78911929464015
}
#Debug simulation 
Total elapsed time: 8.765853343065828. Arrivals time: 0.15765382582321763 Scheduler time: 8.486448402516544 Scheduler overhead time: 0.030591748654842377 Adapter cache time: 0.046834667678922415 Engine time: 0.030557902064174414 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_384_slots_160_rate_0.1-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_384_slots_160_rate_0.1-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 270, 33, 1080, 1080, 33, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 33, 1080, 33, 1080, 270, 270, 270, 33, 33, 270, 33, 1080, 33, 1080, 270, 1080, 270, 33, 270, 1080, 270, 1080, 33, 1080, 1080, 1080, 1080, 33, 270, 270, 270, 1080, 270, 33, 270, 33, 1080, 270, 1080, 1080, 270, 1080, 1080, 33, 33, 1080, 270, 270, 33, 33, 33, 270, 33, 270, 33, 1080, 33, 270, 1080, 33, 1080, 270, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 1080, 1080, 270, 33, 33, 1080, 270, 270, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 33, 270, 270, 270, 270, 33, 33, 1080, 33, 1080, 33, 33, 33, 270, 270, 1080, 33, 33, 1080, 33, 1080, 270, 33, 1080, 270, 270, 33, 1080, 1080, 1080, 33, 270, 1080, 33, 1080, 270, 270, 1080, 1080, 33, 270, 1080, 33, 270, 270, 33, 270, 33, 270, 1080, 1080, 270, 33, 1080, 33, 1080, 270, 270, 270, 270, 270, 33, 33, 1080, 33, 1080, 33, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 33, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 33, 33, 33, 33, 33, 270, 33, 33, 270, 1080, 1080, 33, 33, 1080, 33, 33, 33, 270, 33, 270, 1080, 1080, 270, 270, 33, 1080, 270, 1080, 33, 270, 270, 33, 33, 270, 33, 1080, 1080, 33, 1080, 1080, 33, 270, 1080, 33, 33, 270, 270, 33, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 1080, 270, 270, 270, 1080, 33, 270, 270, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 270, 33, 1080, 1080, 1080, 270, 33, 1080, 1080, 270, 270, 1080, 1080, 33, 1080, 1080, 270, 33, 1080, 270, 270, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 270, 1080, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 1080, 33, 33, 33, 270, 33, 270, 270, 33, 1080, 270, 1080, 33, 1080, 33, 270, 270, 270, 270, 33, 270, 1080, 1080, 33, 1080, 1080, 33, 1080, 270, 1080, 270, 270, 270, 33, 270, 33, 33, 1080, 33, 270, 33, 33, 270, 1080, 270, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 177024 . Total input tokens: 39529967 . Total output tokens: 35428185
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 8.79026829218492,
    "estimated_duration": 3600.162429111304,
    "input_throughput": 3961.797913523817,
    "output_throughput": 3481.5837470683427,
    "total_throughput": 7443.381660592159,
    "itl": 203.28695323571307,
    "ttft": 186839.36146003124,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1882,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.126986729458256,
    "arrivals": 59412,
    "finished_requests": 57189,
    "scheduler_time": 49.78909971800714
}
#Debug simulation 
Total elapsed time: 8.790363564155996. Arrivals time: 0.15876043448224664 Scheduler time: 8.508579371962696 Scheduler overhead time: 0.031015576794743538 Adapter cache time: 0.04758411692455411 Engine time: 0.030578918289393187 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_384_slots_160_rate_0.1-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_384_slots_160_rate_0.1-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 270, 33, 1080, 1080, 33, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 33, 1080, 33, 1080, 270, 270, 270, 33, 33, 270, 33, 1080, 33, 1080, 270, 1080, 270, 33, 270, 1080, 270, 1080, 33, 1080, 1080, 1080, 1080, 33, 270, 270, 270, 1080, 270, 33, 270, 33, 1080, 270, 1080, 1080, 270, 1080, 1080, 33, 33, 1080, 270, 270, 33, 33, 33, 270, 33, 270, 33, 1080, 33, 270, 1080, 33, 1080, 270, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 1080, 1080, 270, 33, 33, 1080, 270, 270, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 33, 270, 270, 270, 270, 33, 33, 1080, 33, 1080, 33, 33, 33, 270, 270, 1080, 33, 33, 1080, 33, 1080, 270, 33, 1080, 270, 270, 33, 1080, 1080, 1080, 33, 270, 1080, 33, 1080, 270, 270, 1080, 1080, 33, 270, 1080, 33, 270, 270, 33, 270, 33, 270, 1080, 1080, 270, 33, 1080, 33, 1080, 270, 270, 270, 270, 270, 33, 33, 1080, 33, 1080, 33, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 33, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 33, 33, 33, 33, 33, 270, 33, 33, 270, 1080, 1080, 33, 33, 1080, 33, 33, 33, 270, 33, 270, 1080, 1080, 270, 270, 33, 1080, 270, 1080, 33, 270, 270, 33, 33, 270, 33, 1080, 1080, 33, 1080, 1080, 33, 270, 1080, 33, 33, 270, 270, 33, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 1080, 270, 270, 270, 1080, 33, 270, 270, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 270, 33, 1080, 1080, 1080, 270, 33, 1080, 1080, 270, 270, 1080, 1080, 33, 1080, 1080, 270, 33, 1080, 270, 270, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 270, 1080, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 1080, 33, 33, 33, 270, 33, 270, 270, 33, 1080, 270, 1080, 33, 1080, 33, 270, 270, 270, 270, 33, 270, 1080, 1080, 33, 1080, 1080, 33, 1080, 270, 1080, 270, 270, 270, 33, 270, 33, 33, 1080, 33, 270, 33, 33, 270, 1080, 270, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 177024 . Total input tokens: 39529967 . Total output tokens: 35428185
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 5.206884356215596,
    "estimated_duration": 3600.137947573096,
    "input_throughput": 3636.202887399,
    "output_throughput": 3206.913226139812,
    "total_throughput": 6843.116113538812,
    "itl": 154.85977564152728,
    "ttft": 577665.0057562633,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3615,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.798224725387284,
    "arrivals": 59412,
    "finished_requests": 52527,
    "scheduler_time": 50.298968109779466
}
#Debug simulation 
Total elapsed time: 5.206978089176118. Arrivals time: 0.15645396569743752 Scheduler time: 4.86807664623484 Scheduler overhead time: 0.03737226594239473 Adapter cache time: 0.09058256726711988 Engine time: 0.03748433757573366 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_384_slots_160_rate_0.1-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_384_slots_160_rate_0.1-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 270, 33, 1080, 1080, 33, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 33, 1080, 33, 1080, 270, 270, 270, 33, 33, 270, 33, 1080, 33, 1080, 270, 1080, 270, 33, 270, 1080, 270, 1080, 33, 1080, 1080, 1080, 1080, 33, 270, 270, 270, 1080, 270, 33, 270, 33, 1080, 270, 1080, 1080, 270, 1080, 1080, 33, 33, 1080, 270, 270, 33, 33, 33, 270, 33, 270, 33, 1080, 33, 270, 1080, 33, 1080, 270, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 1080, 1080, 270, 33, 33, 1080, 270, 270, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 33, 270, 270, 270, 270, 33, 33, 1080, 33, 1080, 33, 33, 33, 270, 270, 1080, 33, 33, 1080, 33, 1080, 270, 33, 1080, 270, 270, 33, 1080, 1080, 1080, 33, 270, 1080, 33, 1080, 270, 270, 1080, 1080, 33, 270, 1080, 33, 270, 270, 33, 270, 33, 270, 1080, 1080, 270, 33, 1080, 33, 1080, 270, 270, 270, 270, 270, 33, 33, 1080, 33, 1080, 33, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 33, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 33, 33, 33, 33, 33, 270, 33, 33, 270, 1080, 1080, 33, 33, 1080, 33, 33, 33, 270, 33, 270, 1080, 1080, 270, 270, 33, 1080, 270, 1080, 33, 270, 270, 33, 33, 270, 33, 1080, 1080, 33, 1080, 1080, 33, 270, 1080, 33, 33, 270, 270, 33, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 1080, 270, 270, 270, 1080, 33, 270, 270, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 270, 33, 1080, 1080, 1080, 270, 33, 1080, 1080, 270, 270, 1080, 1080, 33, 1080, 1080, 270, 33, 1080, 270, 270, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 270, 1080, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 1080, 33, 33, 33, 270, 33, 270, 270, 33, 1080, 270, 1080, 33, 1080, 33, 270, 270, 270, 270, 33, 270, 1080, 1080, 33, 1080, 1080, 33, 1080, 270, 1080, 270, 270, 270, 33, 270, 33, 33, 1080, 33, 270, 33, 33, 270, 1080, 270, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 177024 . Total input tokens: 39529967 . Total output tokens: 35428185
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 8.787594921886921,
    "estimated_duration": 3600.2119870662113,
    "input_throughput": 3964.9717992390747,
    "output_throughput": 3482.615480711528,
    "total_throughput": 7447.587279950603,
    "itl": 203.5137059527755,
    "ttft": 185369.70460670005,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1891,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.896482131494973,
    "arrivals": 59412,
    "finished_requests": 57215,
    "scheduler_time": 49.808278601823844
}
#Debug simulation 
Total elapsed time: 8.787718367762864. Arrivals time: 0.1574413040652871 Scheduler time: 8.507420231588185 Scheduler overhead time: 0.03071928396821022 Adapter cache time: 0.047482694033533335 Engine time: 0.030783346854150295 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_384_slots_160_rate_0.1-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_384_slots_160_rate_0.1-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 270, 33, 1080, 1080, 33, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 33, 1080, 33, 1080, 270, 270, 270, 33, 33, 270, 33, 1080, 33, 1080, 270, 1080, 270, 33, 270, 1080, 270, 1080, 33, 1080, 1080, 1080, 1080, 33, 270, 270, 270, 1080, 270, 33, 270, 33, 1080, 270, 1080, 1080, 270, 1080, 1080, 33, 33, 1080, 270, 270, 33, 33, 33, 270, 33, 270, 33, 1080, 33, 270, 1080, 33, 1080, 270, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 1080, 1080, 270, 33, 33, 1080, 270, 270, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 33, 270, 270, 270, 270, 33, 33, 1080, 33, 1080, 33, 33, 33, 270, 270, 1080, 33, 33, 1080, 33, 1080, 270, 33, 1080, 270, 270, 33, 1080, 1080, 1080, 33, 270, 1080, 33, 1080, 270, 270, 1080, 1080, 33, 270, 1080, 33, 270, 270, 33, 270, 33, 270, 1080, 1080, 270, 33, 1080, 33, 1080, 270, 270, 270, 270, 270, 33, 33, 1080, 33, 1080, 33, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 33, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 33, 33, 33, 33, 33, 270, 33, 33, 270, 1080, 1080, 33, 33, 1080, 33, 33, 33, 270, 33, 270, 1080, 1080, 270, 270, 33, 1080, 270, 1080, 33, 270, 270, 33, 33, 270, 33, 1080, 1080, 33, 1080, 1080, 33, 270, 1080, 33, 33, 270, 270, 33, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 1080, 270, 270, 270, 1080, 33, 270, 270, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 270, 33, 1080, 1080, 1080, 270, 33, 1080, 1080, 270, 270, 1080, 1080, 33, 1080, 1080, 270, 33, 1080, 270, 270, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 270, 1080, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 1080, 33, 33, 33, 270, 33, 270, 270, 33, 1080, 270, 1080, 33, 1080, 33, 270, 270, 270, 270, 33, 270, 1080, 1080, 33, 1080, 1080, 33, 1080, 270, 1080, 270, 270, 270, 33, 270, 33, 33, 1080, 33, 270, 33, 33, 270, 1080, 270, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 177024 . Total input tokens: 39529967 . Total output tokens: 35428185
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 5.2260326710529625,
    "estimated_duration": 3600.1122295701057,
    "input_throughput": 3637.336606465646,
    "output_throughput": 3207.936659624379,
    "total_throughput": 6845.273266090026,
    "itl": 155.0712242085679,
    "ttft": 575757.5545093137,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3575,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.815893510840112,
    "arrivals": 59412,
    "finished_requests": 52546,
    "scheduler_time": 50.28541016895767
}
#Debug simulation 
Total elapsed time: 5.226133259944618. Arrivals time: 0.1529635190963745 Scheduler time: 4.891682150773704 Scheduler overhead time: 0.037374213337898254 Adapter cache time: 0.0896522169932723 Engine time: 0.03743438422679901 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_384_slots_160_rate_0.1-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_384_slots_160_rate_0.1-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 270, 33, 1080, 1080, 33, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 33, 1080, 33, 1080, 270, 270, 270, 33, 33, 270, 33, 1080, 33, 1080, 270, 1080, 270, 33, 270, 1080, 270, 1080, 33, 1080, 1080, 1080, 1080, 33, 270, 270, 270, 1080, 270, 33, 270, 33, 1080, 270, 1080, 1080, 270, 1080, 1080, 33, 33, 1080, 270, 270, 33, 33, 33, 270, 33, 270, 33, 1080, 33, 270, 1080, 33, 1080, 270, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 1080, 1080, 270, 33, 33, 1080, 270, 270, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 33, 270, 270, 270, 270, 33, 33, 1080, 33, 1080, 33, 33, 33, 270, 270, 1080, 33, 33, 1080, 33, 1080, 270, 33, 1080, 270, 270, 33, 1080, 1080, 1080, 33, 270, 1080, 33, 1080, 270, 270, 1080, 1080, 33, 270, 1080, 33, 270, 270, 33, 270, 33, 270, 1080, 1080, 270, 33, 1080, 33, 1080, 270, 270, 270, 270, 270, 33, 33, 1080, 33, 1080, 33, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 33, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 33, 33, 33, 33, 33, 270, 33, 33, 270, 1080, 1080, 33, 33, 1080, 33, 33, 33, 270, 33, 270, 1080, 1080, 270, 270, 33, 1080, 270, 1080, 33, 270, 270, 33, 33, 270, 33, 1080, 1080, 33, 1080, 1080, 33, 270, 1080, 33, 33, 270, 270, 33, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 1080, 270, 270, 270, 1080, 33, 270, 270, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 270, 33, 1080, 1080, 1080, 270, 33, 1080, 1080, 270, 270, 1080, 1080, 33, 1080, 1080, 270, 33, 1080, 270, 270, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 270, 1080, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 1080, 33, 33, 33, 270, 33, 270, 270, 33, 1080, 270, 1080, 33, 1080, 33, 270, 270, 270, 270, 33, 270, 1080, 1080, 33, 1080, 1080, 33, 1080, 270, 1080, 270, 270, 270, 33, 270, 33, 33, 1080, 33, 270, 33, 33, 270, 1080, 270, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 177024 . Total input tokens: 39529967 . Total output tokens: 35428185
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 8.685979976784438,
    "estimated_duration": 3600.040366296126,
    "input_throughput": 3962.993619062785,
    "output_throughput": 3483.355108293385,
    "total_throughput": 7446.3487273561705,
    "itl": 203.5958163367737,
    "ttft": 184594.2106359609,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1901,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.684085610608871,
    "arrivals": 59412,
    "finished_requests": 57212,
    "scheduler_time": 49.787257666700356
}
#Debug simulation 
Total elapsed time: 8.6860803947784. Arrivals time: 0.15858400706201792 Scheduler time: 8.40506754629314 Scheduler overhead time: 0.030727257952094078 Adapter cache time: 0.04754883423447609 Engine time: 0.03046010062098503 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_384_slots_160_rate_0.1-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_384_slots_160_rate_0.1-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 270, 33, 1080, 1080, 33, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 33, 1080, 33, 1080, 270, 270, 270, 33, 33, 270, 33, 1080, 33, 1080, 270, 1080, 270, 33, 270, 1080, 270, 1080, 33, 1080, 1080, 1080, 1080, 33, 270, 270, 270, 1080, 270, 33, 270, 33, 1080, 270, 1080, 1080, 270, 1080, 1080, 33, 33, 1080, 270, 270, 33, 33, 33, 270, 33, 270, 33, 1080, 33, 270, 1080, 33, 1080, 270, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 1080, 1080, 270, 33, 33, 1080, 270, 270, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 33, 270, 270, 270, 270, 33, 33, 1080, 33, 1080, 33, 33, 33, 270, 270, 1080, 33, 33, 1080, 33, 1080, 270, 33, 1080, 270, 270, 33, 1080, 1080, 1080, 33, 270, 1080, 33, 1080, 270, 270, 1080, 1080, 33, 270, 1080, 33, 270, 270, 33, 270, 33, 270, 1080, 1080, 270, 33, 1080, 33, 1080, 270, 270, 270, 270, 270, 33, 33, 1080, 33, 1080, 33, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 33, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 33, 33, 33, 33, 33, 270, 33, 33, 270, 1080, 1080, 33, 33, 1080, 33, 33, 33, 270, 33, 270, 1080, 1080, 270, 270, 33, 1080, 270, 1080, 33, 270, 270, 33, 33, 270, 33, 1080, 1080, 33, 1080, 1080, 33, 270, 1080, 33, 33, 270, 270, 33, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 1080, 270, 270, 270, 1080, 33, 270, 270, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 270, 33, 1080, 1080, 1080, 270, 33, 1080, 1080, 270, 270, 1080, 1080, 33, 1080, 1080, 270, 33, 1080, 270, 270, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 270, 1080, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 1080, 33, 33, 33, 270, 33, 270, 270, 33, 1080, 270, 1080, 33, 1080, 33, 270, 270, 270, 270, 33, 270, 1080, 1080, 33, 1080, 1080, 33, 1080, 270, 1080, 270, 270, 270, 33, 270, 33, 33, 1080, 33, 270, 33, 33, 270, 1080, 270, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 177024 . Total input tokens: 39529967 . Total output tokens: 35428185
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 5.2065065880306065,
    "estimated_duration": 3600.147586441836,
    "input_throughput": 3636.5492485099585,
    "output_throughput": 3206.803810898856,
    "total_throughput": 6843.353059408814,
    "itl": 154.8494065765649,
    "ttft": 577910.3133307828,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3603,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.054314423612507,
    "arrivals": 59412,
    "finished_requests": 52524,
    "scheduler_time": 50.29995675862643
}
#Debug simulation 
Total elapsed time: 5.206622990779579. Arrivals time: 0.1511924983933568 Scheduler time: 4.873679216019809 Scheduler overhead time: 0.03776256646960974 Adapter cache time: 0.08947589248418808 Engine time: 0.037385191302746534 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_384_slots_160_rate_0.1-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_384_slots_160_rate_0.1-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 135, 66, 1080, 1080, 66, 135, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 66, 1080, 66, 1080, 135, 135, 135, 66, 66, 135, 66, 1080, 66, 1080, 135, 1080, 135, 66, 135, 1080, 135, 1080, 66, 1080, 1080, 1080, 1080, 66, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 135, 1080, 1080, 135, 1080, 1080, 66, 66, 1080, 135, 135, 66, 66, 66, 135, 66, 135, 66, 1080, 66, 135, 1080, 66, 1080, 135, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 1080, 1080, 135, 66, 66, 1080, 135, 135, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 135, 1080, 1080, 66, 135, 135, 135, 135, 66, 66, 1080, 66, 1080, 66, 66, 66, 135, 135, 1080, 66, 66, 1080, 66, 1080, 135, 66, 1080, 135, 135, 66, 1080, 1080, 1080, 66, 135, 1080, 66, 1080, 135, 135, 1080, 1080, 66, 135, 1080, 66, 135, 135, 66, 135, 66, 135, 1080, 1080, 135, 66, 1080, 66, 1080, 135, 135, 135, 135, 135, 66, 66, 1080, 66, 1080, 66, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 66, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 66, 66, 66, 66, 66, 135, 66, 66, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66, 135, 1080, 1080, 135, 135, 66, 1080, 135, 1080, 66, 135, 135, 66, 66, 135, 66, 1080, 1080, 66, 1080, 1080, 66, 135, 1080, 66, 66, 135, 135, 66, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 1080, 135, 135, 135, 1080, 66, 135, 135, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 135, 66, 1080, 1080, 1080, 135, 66, 1080, 1080, 135, 135, 1080, 1080, 66, 1080, 1080, 135, 66, 1080, 135, 135, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 135, 1080, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 1080, 66, 66, 66, 135, 66, 135, 135, 66, 1080, 135, 1080, 66, 1080, 66, 135, 135, 135, 135, 66, 135, 1080, 1080, 66, 1080, 1080, 66, 1080, 135, 1080, 135, 135, 135, 66, 135, 66, 66, 1080, 66, 135, 66, 66, 135, 1080, 135, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 163968 . Total input tokens: 36634820 . Total output tokens: 32787314
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 6.538610976189375,
    "estimated_duration": 3600.082393226352,
    "input_throughput": 3746.340368591672,
    "output_throughput": 3287.0036592120796,
    "total_throughput": 7033.3440278037515,
    "itl": 165.5762764953099,
    "ttft": 96425.18911995426,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3235,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.900677851622214,
    "arrivals": 55057,
    "finished_requests": 53986,
    "scheduler_time": 45.315561552210994
}
#Debug simulation 
Total elapsed time: 6.5387047324329615. Arrivals time: 0.13786132168024778 Scheduler time: 6.241632354911417 Scheduler overhead time: 0.03525593224912882 Adapter cache time: 0.0727944360114634 Engine time: 0.03514105919748545 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_384_slots_160_rate_0.1-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_384_slots_160_rate_0.1-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 135, 66, 1080, 1080, 66, 135, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 66, 1080, 66, 1080, 135, 135, 135, 66, 66, 135, 66, 1080, 66, 1080, 135, 1080, 135, 66, 135, 1080, 135, 1080, 66, 1080, 1080, 1080, 1080, 66, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 135, 1080, 1080, 135, 1080, 1080, 66, 66, 1080, 135, 135, 66, 66, 66, 135, 66, 135, 66, 1080, 66, 135, 1080, 66, 1080, 135, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 1080, 1080, 135, 66, 66, 1080, 135, 135, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 135, 1080, 1080, 66, 135, 135, 135, 135, 66, 66, 1080, 66, 1080, 66, 66, 66, 135, 135, 1080, 66, 66, 1080, 66, 1080, 135, 66, 1080, 135, 135, 66, 1080, 1080, 1080, 66, 135, 1080, 66, 1080, 135, 135, 1080, 1080, 66, 135, 1080, 66, 135, 135, 66, 135, 66, 135, 1080, 1080, 135, 66, 1080, 66, 1080, 135, 135, 135, 135, 135, 66, 66, 1080, 66, 1080, 66, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 66, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 66, 66, 66, 66, 66, 135, 66, 66, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66, 135, 1080, 1080, 135, 135, 66, 1080, 135, 1080, 66, 135, 135, 66, 66, 135, 66, 1080, 1080, 66, 1080, 1080, 66, 135, 1080, 66, 66, 135, 135, 66, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 1080, 135, 135, 135, 1080, 66, 135, 135, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 135, 66, 1080, 1080, 1080, 135, 66, 1080, 1080, 135, 135, 1080, 1080, 66, 1080, 1080, 135, 66, 1080, 135, 135, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 135, 1080, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 1080, 66, 66, 66, 135, 66, 135, 135, 66, 1080, 135, 1080, 66, 1080, 66, 135, 135, 135, 135, 66, 135, 1080, 1080, 66, 1080, 1080, 66, 1080, 135, 1080, 135, 135, 135, 66, 135, 66, 66, 1080, 66, 135, 66, 66, 135, 1080, 135, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 163968 . Total input tokens: 36634820 . Total output tokens: 32787314
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 6.504161110147834,
    "estimated_duration": 3600.1377793616152,
    "input_throughput": 3747.6757354526744,
    "output_throughput": 3287.6513970803603,
    "total_throughput": 7035.327132533035,
    "itl": 165.95433019055366,
    "ttft": 93759.88557261771,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3324,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.847234573147887,
    "arrivals": 55057,
    "finished_requests": 54007,
    "scheduler_time": 45.304674548201355
}
#Debug simulation 
Total elapsed time: 6.504253038205206. Arrivals time: 0.1421973118558526 Scheduler time: 6.199812204577029 Scheduler overhead time: 0.03541582077741623 Adapter cache time: 0.07529294677078724 Engine time: 0.035552526358515024 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_384_slots_160_rate_0.1-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_384_slots_160_rate_0.1-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 135, 66, 1080, 1080, 66, 135, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 66, 1080, 66, 1080, 135, 135, 135, 66, 66, 135, 66, 1080, 66, 1080, 135, 1080, 135, 66, 135, 1080, 135, 1080, 66, 1080, 1080, 1080, 1080, 66, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 135, 1080, 1080, 135, 1080, 1080, 66, 66, 1080, 135, 135, 66, 66, 66, 135, 66, 135, 66, 1080, 66, 135, 1080, 66, 1080, 135, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 1080, 1080, 135, 66, 66, 1080, 135, 135, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 135, 1080, 1080, 66, 135, 135, 135, 135, 66, 66, 1080, 66, 1080, 66, 66, 66, 135, 135, 1080, 66, 66, 1080, 66, 1080, 135, 66, 1080, 135, 135, 66, 1080, 1080, 1080, 66, 135, 1080, 66, 1080, 135, 135, 1080, 1080, 66, 135, 1080, 66, 135, 135, 66, 135, 66, 135, 1080, 1080, 135, 66, 1080, 66, 1080, 135, 135, 135, 135, 135, 66, 66, 1080, 66, 1080, 66, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 66, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 66, 66, 66, 66, 66, 135, 66, 66, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66, 135, 1080, 1080, 135, 135, 66, 1080, 135, 1080, 66, 135, 135, 66, 66, 135, 66, 1080, 1080, 66, 1080, 1080, 66, 135, 1080, 66, 66, 135, 135, 66, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 1080, 135, 135, 135, 1080, 66, 135, 135, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 135, 66, 1080, 1080, 1080, 135, 66, 1080, 1080, 135, 135, 1080, 1080, 66, 1080, 1080, 135, 66, 1080, 135, 135, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 135, 1080, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 1080, 66, 66, 66, 135, 66, 135, 135, 66, 1080, 135, 1080, 66, 1080, 66, 135, 135, 135, 135, 66, 135, 1080, 1080, 66, 1080, 1080, 66, 1080, 135, 1080, 135, 135, 135, 66, 135, 66, 66, 1080, 66, 135, 66, 66, 135, 1080, 135, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 163968 . Total input tokens: 36634820 . Total output tokens: 32787314
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 5.193927612155676,
    "estimated_duration": 3600.148842549349,
    "input_throughput": 3645.720933778334,
    "output_throughput": 3204.9141590017025,
    "total_throughput": 6850.635092780037,
    "itl": 153.77859374452646,
    "ttft": 232269.9037615446,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3999,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.068447459171542,
    "arrivals": 55057,
    "finished_requests": 52521,
    "scheduler_time": 45.460547715428206
}
#Debug simulation 
Total elapsed time: 5.194035603199154. Arrivals time: 0.14158369647338986 Scheduler time: 4.8654394331388175 Scheduler overhead time: 0.03770871972665191 Adapter cache time: 0.09421639330685139 Engine time: 0.037760671228170395 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_384_slots_160_rate_0.1-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_384_slots_160_rate_0.1-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 135, 66, 1080, 1080, 66, 135, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 66, 1080, 66, 1080, 135, 135, 135, 66, 66, 135, 66, 1080, 66, 1080, 135, 1080, 135, 66, 135, 1080, 135, 1080, 66, 1080, 1080, 1080, 1080, 66, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 135, 1080, 1080, 135, 1080, 1080, 66, 66, 1080, 135, 135, 66, 66, 66, 135, 66, 135, 66, 1080, 66, 135, 1080, 66, 1080, 135, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 1080, 1080, 135, 66, 66, 1080, 135, 135, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 135, 1080, 1080, 66, 135, 135, 135, 135, 66, 66, 1080, 66, 1080, 66, 66, 66, 135, 135, 1080, 66, 66, 1080, 66, 1080, 135, 66, 1080, 135, 135, 66, 1080, 1080, 1080, 66, 135, 1080, 66, 1080, 135, 135, 1080, 1080, 66, 135, 1080, 66, 135, 135, 66, 135, 66, 135, 1080, 1080, 135, 66, 1080, 66, 1080, 135, 135, 135, 135, 135, 66, 66, 1080, 66, 1080, 66, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 66, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 66, 66, 66, 66, 66, 135, 66, 66, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66, 135, 1080, 1080, 135, 135, 66, 1080, 135, 1080, 66, 135, 135, 66, 66, 135, 66, 1080, 1080, 66, 1080, 1080, 66, 135, 1080, 66, 66, 135, 135, 66, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 1080, 135, 135, 135, 1080, 66, 135, 135, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 135, 66, 1080, 1080, 1080, 135, 66, 1080, 1080, 135, 135, 1080, 1080, 66, 1080, 1080, 135, 66, 1080, 135, 135, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 135, 1080, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 1080, 66, 66, 66, 135, 66, 135, 135, 66, 1080, 135, 1080, 66, 1080, 66, 135, 135, 135, 135, 66, 135, 1080, 1080, 66, 1080, 1080, 66, 1080, 135, 1080, 135, 135, 135, 66, 135, 66, 66, 1080, 66, 135, 66, 66, 135, 1080, 135, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 163968 . Total input tokens: 36634820 . Total output tokens: 32787314
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 6.465616349130869,
    "estimated_duration": 3600.135826473528,
    "input_throughput": 3748.18386039003,
    "output_throughput": 3288.567590405899,
    "total_throughput": 7036.751450795929,
    "itl": 165.97026113616892,
    "ttft": 93296.90406940048,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3312,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.35168423636373,
    "arrivals": 55057,
    "finished_requests": 54014,
    "scheduler_time": 45.311917005151045
}
#Debug simulation 
Total elapsed time: 6.465716284234077. Arrivals time: 0.1397567642852664 Scheduler time: 6.164150974247605 Scheduler overhead time: 0.03527084272354841 Adapter cache time: 0.07551990728825331 Engine time: 0.03502242546528578 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_384_slots_160_rate_0.1-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_384_slots_160_rate_0.1-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 135, 66, 1080, 1080, 66, 135, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 66, 1080, 66, 1080, 135, 135, 135, 66, 66, 135, 66, 1080, 66, 1080, 135, 1080, 135, 66, 135, 1080, 135, 1080, 66, 1080, 1080, 1080, 1080, 66, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 135, 1080, 1080, 135, 1080, 1080, 66, 66, 1080, 135, 135, 66, 66, 66, 135, 66, 135, 66, 1080, 66, 135, 1080, 66, 1080, 135, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 1080, 1080, 135, 66, 66, 1080, 135, 135, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 135, 1080, 1080, 66, 135, 135, 135, 135, 66, 66, 1080, 66, 1080, 66, 66, 66, 135, 135, 1080, 66, 66, 1080, 66, 1080, 135, 66, 1080, 135, 135, 66, 1080, 1080, 1080, 66, 135, 1080, 66, 1080, 135, 135, 1080, 1080, 66, 135, 1080, 66, 135, 135, 66, 135, 66, 135, 1080, 1080, 135, 66, 1080, 66, 1080, 135, 135, 135, 135, 135, 66, 66, 1080, 66, 1080, 66, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 66, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 66, 66, 66, 66, 66, 135, 66, 66, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66, 135, 1080, 1080, 135, 135, 66, 1080, 135, 1080, 66, 135, 135, 66, 66, 135, 66, 1080, 1080, 66, 1080, 1080, 66, 135, 1080, 66, 66, 135, 135, 66, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 1080, 135, 135, 135, 1080, 66, 135, 135, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 135, 66, 1080, 1080, 1080, 135, 66, 1080, 1080, 135, 135, 1080, 1080, 66, 1080, 1080, 135, 66, 1080, 135, 135, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 135, 1080, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 1080, 66, 66, 66, 135, 66, 135, 135, 66, 1080, 135, 1080, 66, 1080, 66, 135, 135, 135, 135, 66, 135, 1080, 1080, 66, 1080, 1080, 66, 1080, 135, 1080, 135, 135, 135, 66, 135, 66, 66, 1080, 66, 135, 66, 66, 135, 1080, 135, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 163968 . Total input tokens: 36634820 . Total output tokens: 32787314
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 5.105421683285385,
    "estimated_duration": 3600.1749624600834,
    "input_throughput": 3644.7895274049442,
    "output_throughput": 3204.9675697193097,
    "total_throughput": 6849.757097124254,
    "itl": 153.78281150612173,
    "ttft": 232536.71428567346,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4002,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.25016364892855,
    "arrivals": 55057,
    "finished_requests": 52518,
    "scheduler_time": 45.46120341916506
}
#Debug simulation 
Total elapsed time: 5.105519661214203. Arrivals time: 0.13483325904235244 Scheduler time: 4.783308509737253 Scheduler overhead time: 0.03763273498043418 Adapter cache time: 0.09470918914303184 Engine time: 0.03777302196249366 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_384_slots_160_rate_0.1-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_384_slots_160_rate_0.1-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 135, 66, 1080, 1080, 66, 135, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 66, 1080, 66, 1080, 135, 135, 135, 66, 66, 135, 66, 1080, 66, 1080, 135, 1080, 135, 66, 135, 1080, 135, 1080, 66, 1080, 1080, 1080, 1080, 66, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 135, 1080, 1080, 135, 1080, 1080, 66, 66, 1080, 135, 135, 66, 66, 66, 135, 66, 135, 66, 1080, 66, 135, 1080, 66, 1080, 135, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 1080, 1080, 135, 66, 66, 1080, 135, 135, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 135, 1080, 1080, 66, 135, 135, 135, 135, 66, 66, 1080, 66, 1080, 66, 66, 66, 135, 135, 1080, 66, 66, 1080, 66, 1080, 135, 66, 1080, 135, 135, 66, 1080, 1080, 1080, 66, 135, 1080, 66, 1080, 135, 135, 1080, 1080, 66, 135, 1080, 66, 135, 135, 66, 135, 66, 135, 1080, 1080, 135, 66, 1080, 66, 1080, 135, 135, 135, 135, 135, 66, 66, 1080, 66, 1080, 66, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 66, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 66, 66, 66, 66, 66, 135, 66, 66, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66, 135, 1080, 1080, 135, 135, 66, 1080, 135, 1080, 66, 135, 135, 66, 66, 135, 66, 1080, 1080, 66, 1080, 1080, 66, 135, 1080, 66, 66, 135, 135, 66, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 1080, 135, 135, 135, 1080, 66, 135, 135, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 135, 66, 1080, 1080, 1080, 135, 66, 1080, 1080, 135, 135, 1080, 1080, 66, 1080, 1080, 135, 66, 1080, 135, 135, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 135, 1080, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 1080, 66, 66, 66, 135, 66, 135, 135, 66, 1080, 135, 1080, 66, 1080, 66, 135, 135, 135, 135, 66, 135, 1080, 1080, 66, 1080, 1080, 66, 1080, 135, 1080, 135, 135, 135, 66, 135, 66, 66, 1080, 66, 135, 66, 66, 135, 1080, 135, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 163968 . Total input tokens: 36634820 . Total output tokens: 32787314
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 6.606384346727282,
    "estimated_duration": 3600.111310296035,
    "input_throughput": 3746.7369304453077,
    "output_throughput": 3286.460050877453,
    "total_throughput": 7033.196981322761,
    "itl": 165.56071945071236,
    "ttft": 96282.91377425072,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3242,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.693743056073048,
    "arrivals": 55057,
    "finished_requests": 53989,
    "scheduler_time": 45.318738069217915
}
#Debug simulation 
Total elapsed time: 6.606476116925478. Arrivals time: 0.13709761295467615 Scheduler time: 6.308702642098069 Scheduler overhead time: 0.0356670836918056 Adapter cache time: 0.07377209514379501 Engine time: 0.03523683222010732 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_384_slots_160_rate_0.1-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_384_slots_160_rate_0.1-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 135, 66, 1080, 1080, 66, 135, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 66, 1080, 66, 1080, 135, 135, 135, 66, 66, 135, 66, 1080, 66, 1080, 135, 1080, 135, 66, 135, 1080, 135, 1080, 66, 1080, 1080, 1080, 1080, 66, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 135, 1080, 1080, 135, 1080, 1080, 66, 66, 1080, 135, 135, 66, 66, 66, 135, 66, 135, 66, 1080, 66, 135, 1080, 66, 1080, 135, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 1080, 1080, 135, 66, 66, 1080, 135, 135, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 135, 1080, 1080, 66, 135, 135, 135, 135, 66, 66, 1080, 66, 1080, 66, 66, 66, 135, 135, 1080, 66, 66, 1080, 66, 1080, 135, 66, 1080, 135, 135, 66, 1080, 1080, 1080, 66, 135, 1080, 66, 1080, 135, 135, 1080, 1080, 66, 135, 1080, 66, 135, 135, 66, 135, 66, 135, 1080, 1080, 135, 66, 1080, 66, 1080, 135, 135, 135, 135, 135, 66, 66, 1080, 66, 1080, 66, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 66, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 66, 66, 66, 66, 66, 135, 66, 66, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66, 135, 1080, 1080, 135, 135, 66, 1080, 135, 1080, 66, 135, 135, 66, 66, 135, 66, 1080, 1080, 66, 1080, 1080, 66, 135, 1080, 66, 66, 135, 135, 66, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 1080, 135, 135, 135, 1080, 66, 135, 135, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 135, 66, 1080, 1080, 1080, 135, 66, 1080, 1080, 135, 135, 1080, 1080, 66, 1080, 1080, 135, 66, 1080, 135, 135, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 135, 1080, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 1080, 66, 66, 66, 135, 66, 135, 135, 66, 1080, 135, 1080, 66, 1080, 66, 135, 135, 135, 135, 66, 135, 1080, 1080, 66, 1080, 1080, 66, 1080, 135, 1080, 135, 135, 135, 66, 135, 66, 66, 1080, 66, 135, 66, 66, 135, 1080, 135, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 163968 . Total input tokens: 36634820 . Total output tokens: 32787314
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 5.120193010661751,
    "estimated_duration": 3600.078556204343,
    "input_throughput": 3645.027961232956,
    "output_throughput": 3204.37202130464,
    "total_throughput": 6849.399982537596,
    "itl": 153.78522141703021,
    "ttft": 232469.1805831658,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3993,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.382502165324116,
    "arrivals": 55057,
    "finished_requests": 52518,
    "scheduler_time": 45.462214635778984
}
#Debug simulation 
Total elapsed time: 5.120303996838629. Arrivals time: 0.13362885499373078 Scheduler time: 4.799729239195585 Scheduler overhead time: 0.037356921937316656 Adapter cache time: 0.09507052414119244 Engine time: 0.03737260214984417 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_384_slots_160_rate_0.1-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_384_slots_160_rate_0.1-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 135, 33, 1080, 1080, 33, 135, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 33, 1080, 33, 1080, 135, 135, 135, 33, 33, 135, 33, 1080, 33, 1080, 135, 1080, 135, 33, 135, 1080, 135, 1080, 33, 1080, 1080, 1080, 1080, 33, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 135, 1080, 1080, 135, 1080, 1080, 33, 33, 1080, 135, 135, 33, 33, 33, 135, 33, 135, 33, 1080, 33, 135, 1080, 33, 1080, 135, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 1080, 1080, 135, 33, 33, 1080, 135, 135, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 135, 1080, 1080, 33, 135, 135, 135, 135, 33, 33, 1080, 33, 1080, 33, 33, 33, 135, 135, 1080, 33, 33, 1080, 33, 1080, 135, 33, 1080, 135, 135, 33, 1080, 1080, 1080, 33, 135, 1080, 33, 1080, 135, 135, 1080, 1080, 33, 135, 1080, 33, 135, 135, 33, 135, 33, 135, 1080, 1080, 135, 33, 1080, 33, 1080, 135, 135, 135, 135, 135, 33, 33, 1080, 33, 1080, 33, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 33, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 33, 33, 33, 33, 33, 135, 33, 33, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33, 135, 1080, 1080, 135, 135, 33, 1080, 135, 1080, 33, 135, 135, 33, 33, 135, 33, 1080, 1080, 33, 1080, 1080, 33, 135, 1080, 33, 33, 135, 135, 33, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 1080, 135, 135, 135, 1080, 33, 135, 135, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 135, 33, 1080, 1080, 1080, 135, 33, 1080, 1080, 135, 135, 1080, 1080, 33, 1080, 1080, 135, 33, 1080, 135, 135, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 135, 1080, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 1080, 33, 33, 33, 135, 33, 135, 135, 33, 1080, 135, 1080, 33, 1080, 33, 135, 135, 135, 135, 33, 135, 1080, 1080, 33, 1080, 1080, 33, 1080, 135, 1080, 135, 135, 135, 33, 135, 33, 33, 1080, 33, 135, 33, 33, 135, 1080, 135, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 159744 . Total input tokens: 35685722 . Total output tokens: 31942819
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 5.193760888185352,
    "estimated_duration": 3600.0951051613024,
    "input_throughput": 3665.556218523493,
    "output_throughput": 3193.971454674891,
    "total_throughput": 6859.527673198384,
    "itl": 152.33720624143393,
    "ttft": 68079.66995979304,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3934,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.039958784630663,
    "arrivals": 53529,
    "finished_requests": 52686,
    "scheduler_time": 43.06997511047194
}
#Debug simulation 
Total elapsed time: 5.193851409014314. Arrivals time: 0.12911357078701258 Scheduler time: 4.8831096342764795 Scheduler overhead time: 0.037947146221995354 Adapter cache time: 0.08930334821343422 Engine time: 0.037266156636178493 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_384_slots_160_rate_0.1-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_384_slots_160_rate_0.1-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 135, 33, 1080, 1080, 33, 135, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 33, 1080, 33, 1080, 135, 135, 135, 33, 33, 135, 33, 1080, 33, 1080, 135, 1080, 135, 33, 135, 1080, 135, 1080, 33, 1080, 1080, 1080, 1080, 33, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 135, 1080, 1080, 135, 1080, 1080, 33, 33, 1080, 135, 135, 33, 33, 33, 135, 33, 135, 33, 1080, 33, 135, 1080, 33, 1080, 135, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 1080, 1080, 135, 33, 33, 1080, 135, 135, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 135, 1080, 1080, 33, 135, 135, 135, 135, 33, 33, 1080, 33, 1080, 33, 33, 33, 135, 135, 1080, 33, 33, 1080, 33, 1080, 135, 33, 1080, 135, 135, 33, 1080, 1080, 1080, 33, 135, 1080, 33, 1080, 135, 135, 1080, 1080, 33, 135, 1080, 33, 135, 135, 33, 135, 33, 135, 1080, 1080, 135, 33, 1080, 33, 1080, 135, 135, 135, 135, 135, 33, 33, 1080, 33, 1080, 33, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 33, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 33, 33, 33, 33, 33, 135, 33, 33, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33, 135, 1080, 1080, 135, 135, 33, 1080, 135, 1080, 33, 135, 135, 33, 33, 135, 33, 1080, 1080, 33, 1080, 1080, 33, 135, 1080, 33, 33, 135, 135, 33, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 1080, 135, 135, 135, 1080, 33, 135, 135, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 135, 33, 1080, 1080, 1080, 135, 33, 1080, 1080, 135, 135, 1080, 1080, 33, 1080, 1080, 135, 33, 1080, 135, 135, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 135, 1080, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 1080, 33, 33, 33, 135, 33, 135, 135, 33, 1080, 135, 1080, 33, 1080, 33, 135, 135, 135, 135, 33, 135, 1080, 1080, 33, 1080, 1080, 33, 1080, 135, 1080, 135, 135, 135, 33, 135, 33, 33, 1080, 33, 135, 33, 33, 135, 1080, 135, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 159744 . Total input tokens: 35685722 . Total output tokens: 31942819
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 5.173687629867345,
    "estimated_duration": 3600.0220113790137,
    "input_throughput": 3665.485088227348,
    "output_throughput": 3193.8304720519372,
    "total_throughput": 6859.315560279286,
    "itl": 152.4451686860206,
    "ttft": 68178.61127583425,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3929,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.816792961711123,
    "arrivals": 53529,
    "finished_requests": 52682,
    "scheduler_time": 43.07232588551957
}
#Debug simulation 
Total elapsed time: 5.173777393065393. Arrivals time: 0.12749607907608151 Scheduler time: 4.865902446210384 Scheduler overhead time: 0.03774643363431096 Adapter cache time: 0.08824593666940928 Engine time: 0.03737857611849904 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_384_slots_160_rate_0.1-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_384_slots_160_rate_0.1-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 135, 33, 1080, 1080, 33, 135, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 33, 1080, 33, 1080, 135, 135, 135, 33, 33, 135, 33, 1080, 33, 1080, 135, 1080, 135, 33, 135, 1080, 135, 1080, 33, 1080, 1080, 1080, 1080, 33, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 135, 1080, 1080, 135, 1080, 1080, 33, 33, 1080, 135, 135, 33, 33, 33, 135, 33, 135, 33, 1080, 33, 135, 1080, 33, 1080, 135, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 1080, 1080, 135, 33, 33, 1080, 135, 135, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 135, 1080, 1080, 33, 135, 135, 135, 135, 33, 33, 1080, 33, 1080, 33, 33, 33, 135, 135, 1080, 33, 33, 1080, 33, 1080, 135, 33, 1080, 135, 135, 33, 1080, 1080, 1080, 33, 135, 1080, 33, 1080, 135, 135, 1080, 1080, 33, 135, 1080, 33, 135, 135, 33, 135, 33, 135, 1080, 1080, 135, 33, 1080, 33, 1080, 135, 135, 135, 135, 135, 33, 33, 1080, 33, 1080, 33, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 33, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 33, 33, 33, 33, 33, 135, 33, 33, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33, 135, 1080, 1080, 135, 135, 33, 1080, 135, 1080, 33, 135, 135, 33, 33, 135, 33, 1080, 1080, 33, 1080, 1080, 33, 135, 1080, 33, 33, 135, 135, 33, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 1080, 135, 135, 135, 1080, 33, 135, 135, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 135, 33, 1080, 1080, 1080, 135, 33, 1080, 1080, 135, 135, 1080, 1080, 33, 1080, 1080, 135, 33, 1080, 135, 135, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 135, 1080, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 1080, 33, 33, 33, 135, 33, 135, 135, 33, 1080, 135, 1080, 33, 1080, 33, 135, 135, 135, 135, 33, 135, 1080, 1080, 33, 1080, 1080, 33, 1080, 135, 1080, 135, 135, 135, 33, 135, 33, 33, 1080, 33, 135, 33, 33, 135, 1080, 135, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 159744 . Total input tokens: 35685722 . Total output tokens: 31942819
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.8261644607409835,
    "estimated_duration": 3600.1265367475576,
    "input_throughput": 3652.096076566862,
    "output_throughput": 3184.210300106968,
    "total_throughput": 6836.3063766738305,
    "itl": 151.06489851175857,
    "ttft": 85880.44042521463,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4069,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.29430918337682,
    "arrivals": 53529,
    "finished_requests": 52481,
    "scheduler_time": 43.045671534569536
}
#Debug simulation 
Total elapsed time: 4.826254009734839. Arrivals time: 0.13091262755915523 Scheduler time: 4.507438587490469 Scheduler overhead time: 0.037754368502646685 Adapter cache time: 0.09556677378714085 Engine time: 0.037230927031487226 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_384_slots_160_rate_0.1-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_384_slots_160_rate_0.1-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 135, 33, 1080, 1080, 33, 135, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 33, 1080, 33, 1080, 135, 135, 135, 33, 33, 135, 33, 1080, 33, 1080, 135, 1080, 135, 33, 135, 1080, 135, 1080, 33, 1080, 1080, 1080, 1080, 33, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 135, 1080, 1080, 135, 1080, 1080, 33, 33, 1080, 135, 135, 33, 33, 33, 135, 33, 135, 33, 1080, 33, 135, 1080, 33, 1080, 135, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 1080, 1080, 135, 33, 33, 1080, 135, 135, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 135, 1080, 1080, 33, 135, 135, 135, 135, 33, 33, 1080, 33, 1080, 33, 33, 33, 135, 135, 1080, 33, 33, 1080, 33, 1080, 135, 33, 1080, 135, 135, 33, 1080, 1080, 1080, 33, 135, 1080, 33, 1080, 135, 135, 1080, 1080, 33, 135, 1080, 33, 135, 135, 33, 135, 33, 135, 1080, 1080, 135, 33, 1080, 33, 1080, 135, 135, 135, 135, 135, 33, 33, 1080, 33, 1080, 33, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 33, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 33, 33, 33, 33, 33, 135, 33, 33, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33, 135, 1080, 1080, 135, 135, 33, 1080, 135, 1080, 33, 135, 135, 33, 33, 135, 33, 1080, 1080, 33, 1080, 1080, 33, 135, 1080, 33, 33, 135, 135, 33, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 1080, 135, 135, 135, 1080, 33, 135, 135, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 135, 33, 1080, 1080, 1080, 135, 33, 1080, 1080, 135, 135, 1080, 1080, 33, 1080, 1080, 135, 33, 1080, 135, 135, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 135, 1080, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 1080, 33, 33, 33, 135, 33, 135, 135, 33, 1080, 135, 1080, 33, 1080, 33, 135, 135, 135, 135, 33, 135, 1080, 1080, 33, 1080, 1080, 33, 1080, 135, 1080, 135, 135, 135, 33, 135, 33, 33, 1080, 33, 135, 33, 33, 135, 1080, 135, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 159744 . Total input tokens: 35685722 . Total output tokens: 31942819
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 5.094284160062671,
    "estimated_duration": 3600.101054638669,
    "input_throughput": 3665.248224906944,
    "output_throughput": 3193.5611877300294,
    "total_throughput": 6858.809412636973,
    "itl": 152.37392382669847,
    "ttft": 68414.11099073167,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3933,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.300030820829038,
    "arrivals": 53529,
    "finished_requests": 52681,
    "scheduler_time": 43.07084369686434
}
#Debug simulation 
Total elapsed time: 5.0943710980936885. Arrivals time: 0.12581996200606227 Scheduler time: 4.790437498595566 Scheduler overhead time: 0.03752847667783499 Adapter cache time: 0.0872489707544446 Engine time: 0.03654806036502123 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_384_slots_160_rate_0.1-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_384_slots_160_rate_0.1-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 135, 33, 1080, 1080, 33, 135, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 33, 1080, 33, 1080, 135, 135, 135, 33, 33, 135, 33, 1080, 33, 1080, 135, 1080, 135, 33, 135, 1080, 135, 1080, 33, 1080, 1080, 1080, 1080, 33, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 135, 1080, 1080, 135, 1080, 1080, 33, 33, 1080, 135, 135, 33, 33, 33, 135, 33, 135, 33, 1080, 33, 135, 1080, 33, 1080, 135, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 1080, 1080, 135, 33, 33, 1080, 135, 135, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 135, 1080, 1080, 33, 135, 135, 135, 135, 33, 33, 1080, 33, 1080, 33, 33, 33, 135, 135, 1080, 33, 33, 1080, 33, 1080, 135, 33, 1080, 135, 135, 33, 1080, 1080, 1080, 33, 135, 1080, 33, 1080, 135, 135, 1080, 1080, 33, 135, 1080, 33, 135, 135, 33, 135, 33, 135, 1080, 1080, 135, 33, 1080, 33, 1080, 135, 135, 135, 135, 135, 33, 33, 1080, 33, 1080, 33, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 33, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 33, 33, 33, 33, 33, 135, 33, 33, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33, 135, 1080, 1080, 135, 135, 33, 1080, 135, 1080, 33, 135, 135, 33, 33, 135, 33, 1080, 1080, 33, 1080, 1080, 33, 135, 1080, 33, 33, 135, 135, 33, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 1080, 135, 135, 135, 1080, 33, 135, 135, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 135, 33, 1080, 1080, 1080, 135, 33, 1080, 1080, 135, 135, 1080, 1080, 33, 1080, 1080, 135, 33, 1080, 135, 135, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 135, 1080, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 1080, 33, 33, 33, 135, 33, 135, 135, 33, 1080, 135, 1080, 33, 1080, 33, 135, 135, 135, 135, 33, 135, 1080, 1080, 33, 1080, 1080, 33, 1080, 135, 1080, 135, 135, 135, 33, 135, 33, 33, 1080, 33, 135, 33, 33, 135, 1080, 135, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 159744 . Total input tokens: 35685722 . Total output tokens: 31942819
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 4.73307785205543,
    "estimated_duration": 3600.1616783405775,
    "input_throughput": 3652.0754273625666,
    "output_throughput": 3184.2072729589036,
    "total_throughput": 6836.282700321471,
    "itl": 151.1135268001451,
    "ttft": 85351.46184686222,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4059,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.429560334942305,
    "arrivals": 53529,
    "finished_requests": 52488,
    "scheduler_time": 43.048430103708114
}
#Debug simulation 
Total elapsed time: 4.7331655491143465. Arrivals time: 0.12629323173314333 Scheduler time: 4.419254585634917 Scheduler overhead time: 0.03781216265633702 Adapter cache time: 0.0950049008242786 Engine time: 0.0375360487960279 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_384_slots_160_rate_0.1-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_384_slots_160_rate_0.1-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 135, 33, 1080, 1080, 33, 135, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 33, 1080, 33, 1080, 135, 135, 135, 33, 33, 135, 33, 1080, 33, 1080, 135, 1080, 135, 33, 135, 1080, 135, 1080, 33, 1080, 1080, 1080, 1080, 33, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 135, 1080, 1080, 135, 1080, 1080, 33, 33, 1080, 135, 135, 33, 33, 33, 135, 33, 135, 33, 1080, 33, 135, 1080, 33, 1080, 135, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 1080, 1080, 135, 33, 33, 1080, 135, 135, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 135, 1080, 1080, 33, 135, 135, 135, 135, 33, 33, 1080, 33, 1080, 33, 33, 33, 135, 135, 1080, 33, 33, 1080, 33, 1080, 135, 33, 1080, 135, 135, 33, 1080, 1080, 1080, 33, 135, 1080, 33, 1080, 135, 135, 1080, 1080, 33, 135, 1080, 33, 135, 135, 33, 135, 33, 135, 1080, 1080, 135, 33, 1080, 33, 1080, 135, 135, 135, 135, 135, 33, 33, 1080, 33, 1080, 33, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 33, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 33, 33, 33, 33, 33, 135, 33, 33, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33, 135, 1080, 1080, 135, 135, 33, 1080, 135, 1080, 33, 135, 135, 33, 33, 135, 33, 1080, 1080, 33, 1080, 1080, 33, 135, 1080, 33, 33, 135, 135, 33, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 1080, 135, 135, 135, 1080, 33, 135, 135, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 135, 33, 1080, 1080, 1080, 135, 33, 1080, 1080, 135, 135, 1080, 1080, 33, 1080, 1080, 135, 33, 1080, 135, 135, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 135, 1080, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 1080, 33, 33, 33, 135, 33, 135, 135, 33, 1080, 135, 1080, 33, 1080, 33, 135, 135, 135, 135, 33, 135, 1080, 1080, 33, 1080, 1080, 33, 1080, 135, 1080, 135, 135, 135, 33, 135, 33, 33, 1080, 33, 135, 33, 33, 135, 1080, 135, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 159744 . Total input tokens: 35685722 . Total output tokens: 31942819
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 5.150512641761452,
    "estimated_duration": 3600.1719342151373,
    "input_throughput": 3665.818811199961,
    "output_throughput": 3193.860518360699,
    "total_throughput": 6859.67932956066,
    "itl": 152.29626079480337,
    "ttft": 68021.84582864692,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3942,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.786778262505118,
    "arrivals": 53529,
    "finished_requests": 52686,
    "scheduler_time": 43.06800634790222
}
#Debug simulation 
Total elapsed time: 5.150606079958379. Arrivals time: 0.12450247351080179 Scheduler time: 4.846779517829418 Scheduler overhead time: 0.03757723234593868 Adapter cache time: 0.08775837672874331 Engine time: 0.03698684135451913 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_384_slots_160_rate_0.1-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_384_slots_160_rate_0.1-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 135, 33, 1080, 1080, 33, 135, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 33, 1080, 33, 1080, 135, 135, 135, 33, 33, 135, 33, 1080, 33, 1080, 135, 1080, 135, 33, 135, 1080, 135, 1080, 33, 1080, 1080, 1080, 1080, 33, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 135, 1080, 1080, 135, 1080, 1080, 33, 33, 1080, 135, 135, 33, 33, 33, 135, 33, 135, 33, 1080, 33, 135, 1080, 33, 1080, 135, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 1080, 1080, 135, 33, 33, 1080, 135, 135, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 135, 1080, 1080, 33, 135, 135, 135, 135, 33, 33, 1080, 33, 1080, 33, 33, 33, 135, 135, 1080, 33, 33, 1080, 33, 1080, 135, 33, 1080, 135, 135, 33, 1080, 1080, 1080, 33, 135, 1080, 33, 1080, 135, 135, 1080, 1080, 33, 135, 1080, 33, 135, 135, 33, 135, 33, 135, 1080, 1080, 135, 33, 1080, 33, 1080, 135, 135, 135, 135, 135, 33, 33, 1080, 33, 1080, 33, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 33, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 33, 33, 33, 33, 33, 135, 33, 33, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33, 135, 1080, 1080, 135, 135, 33, 1080, 135, 1080, 33, 135, 135, 33, 33, 135, 33, 1080, 1080, 33, 1080, 1080, 33, 135, 1080, 33, 33, 135, 135, 33, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 1080, 135, 135, 135, 1080, 33, 135, 135, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 135, 33, 1080, 1080, 1080, 135, 33, 1080, 1080, 135, 135, 1080, 1080, 33, 1080, 1080, 135, 33, 1080, 135, 135, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 135, 1080, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 1080, 33, 33, 33, 135, 33, 135, 135, 33, 1080, 135, 1080, 33, 1080, 33, 135, 135, 135, 135, 33, 135, 1080, 1080, 33, 1080, 1080, 33, 1080, 135, 1080, 135, 135, 135, 33, 135, 33, 33, 1080, 33, 135, 33, 33, 135, 1080, 135, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 159744 . Total input tokens: 35685722 . Total output tokens: 31942819
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.679164084140211,
    "estimated_duration": 3600.0735624688305,
    "input_throughput": 3652.361478686824,
    "output_throughput": 3184.180212178442,
    "total_throughput": 6836.541690865266,
    "itl": 151.13215966122635,
    "ttft": 85540.3912259234,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4064,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.618964059948027,
    "arrivals": 53529,
    "finished_requests": 52485,
    "scheduler_time": 43.048787721829996
}
#Debug simulation 
Total elapsed time: 4.679256736300886. Arrivals time: 0.1217184355482459 Scheduler time: 4.372514494694769 Scheduler overhead time: 0.037317227106541395 Adapter cache time: 0.09362485446035862 Engine time: 0.03710481524467468 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_384_slots_160_rate_0.1-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_384_slots_160_rate_0.1-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 66, 33, 1080, 1080, 33, 66, 1080, 1080, 1080, 1080, 66, 66, 66, 66, 1080, 1080, 66, 66, 33, 1080, 33, 1080, 66, 66, 66, 33, 33, 66, 33, 1080, 33, 1080, 66, 1080, 66, 33, 66, 1080, 66, 1080, 33, 1080, 1080, 1080, 1080, 33, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 66, 1080, 1080, 66, 1080, 1080, 33, 33, 1080, 66, 66, 33, 33, 33, 66, 33, 66, 33, 1080, 33, 66, 1080, 33, 1080, 66, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 1080, 1080, 66, 33, 33, 1080, 66, 66, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 66, 1080, 1080, 33, 66, 66, 66, 66, 33, 33, 1080, 33, 1080, 33, 33, 33, 66, 66, 1080, 33, 33, 1080, 33, 1080, 66, 33, 1080, 66, 66, 33, 1080, 1080, 1080, 33, 66, 1080, 33, 1080, 66, 66, 1080, 1080, 33, 66, 1080, 33, 66, 66, 33, 66, 33, 66, 1080, 1080, 66, 33, 1080, 33, 1080, 66, 66, 66, 66, 66, 33, 33, 1080, 33, 1080, 33, 66, 1080, 66, 1080, 66, 1080, 66, 1080, 33, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 33, 33, 33, 33, 33, 66, 33, 33, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33, 66, 1080, 1080, 66, 66, 33, 1080, 66, 1080, 33, 66, 66, 33, 33, 66, 33, 1080, 1080, 33, 1080, 1080, 33, 66, 1080, 33, 33, 66, 66, 33, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 1080, 66, 66, 66, 1080, 33, 66, 66, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 66, 33, 1080, 1080, 1080, 66, 33, 1080, 1080, 66, 66, 1080, 1080, 33, 1080, 1080, 66, 33, 1080, 66, 66, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 66, 1080, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 1080, 33, 33, 33, 66, 33, 66, 66, 33, 1080, 66, 1080, 33, 1080, 33, 66, 66, 66, 66, 33, 66, 1080, 1080, 33, 1080, 1080, 33, 1080, 66, 1080, 66, 66, 66, 33, 66, 33, 33, 1080, 33, 66, 33, 33, 66, 1080, 66, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 150912 . Total input tokens: 33712521 . Total output tokens: 30175123
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.86800488922745,
    "estimated_duration": 3600.1146399413756,
    "input_throughput": 3470.533371738256,
    "output_throughput": 3061.4283438983693,
    "total_throughput": 6531.961715636626,
    "itl": 133.97527846369536,
    "ttft": 36352.0486427152,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4964,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.192261160880594,
    "arrivals": 50610,
    "finished_requests": 50111,
    "scheduler_time": 40.06156726881081
}
#Debug simulation 
Total elapsed time: 3.8680967590771616. Arrivals time: 0.11452059401199222 Scheduler time: 3.5456840372644365 Scheduler overhead time: 0.040214432403445244 Adapter cache time: 0.10980579955503345 Engine time: 0.03950193105265498 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_384_slots_160_rate_0.1-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_384_slots_160_rate_0.1-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 66, 33, 1080, 1080, 33, 66, 1080, 1080, 1080, 1080, 66, 66, 66, 66, 1080, 1080, 66, 66, 33, 1080, 33, 1080, 66, 66, 66, 33, 33, 66, 33, 1080, 33, 1080, 66, 1080, 66, 33, 66, 1080, 66, 1080, 33, 1080, 1080, 1080, 1080, 33, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 66, 1080, 1080, 66, 1080, 1080, 33, 33, 1080, 66, 66, 33, 33, 33, 66, 33, 66, 33, 1080, 33, 66, 1080, 33, 1080, 66, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 1080, 1080, 66, 33, 33, 1080, 66, 66, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 66, 1080, 1080, 33, 66, 66, 66, 66, 33, 33, 1080, 33, 1080, 33, 33, 33, 66, 66, 1080, 33, 33, 1080, 33, 1080, 66, 33, 1080, 66, 66, 33, 1080, 1080, 1080, 33, 66, 1080, 33, 1080, 66, 66, 1080, 1080, 33, 66, 1080, 33, 66, 66, 33, 66, 33, 66, 1080, 1080, 66, 33, 1080, 33, 1080, 66, 66, 66, 66, 66, 33, 33, 1080, 33, 1080, 33, 66, 1080, 66, 1080, 66, 1080, 66, 1080, 33, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 33, 33, 33, 33, 33, 66, 33, 33, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33, 66, 1080, 1080, 66, 66, 33, 1080, 66, 1080, 33, 66, 66, 33, 33, 66, 33, 1080, 1080, 33, 1080, 1080, 33, 66, 1080, 33, 33, 66, 66, 33, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 1080, 66, 66, 66, 1080, 33, 66, 66, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 66, 33, 1080, 1080, 1080, 66, 33, 1080, 1080, 66, 66, 1080, 1080, 33, 1080, 1080, 66, 33, 1080, 66, 66, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 66, 1080, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 1080, 33, 33, 33, 66, 33, 66, 66, 33, 1080, 66, 1080, 33, 1080, 33, 66, 66, 66, 66, 33, 66, 1080, 1080, 33, 1080, 1080, 33, 1080, 66, 1080, 66, 66, 66, 33, 66, 33, 33, 1080, 33, 66, 33, 33, 66, 1080, 66, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 150912 . Total input tokens: 33712521 . Total output tokens: 30175123
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.9422544999979436,
    "estimated_duration": 3600.015689489034,
    "input_throughput": 3470.4218196819215,
    "output_throughput": 3061.2777694766683,
    "total_throughput": 6531.69958915859,
    "itl": 134.127710899052,
    "ttft": 36500.845770468826,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4965,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.189878311859083,
    "arrivals": 50610,
    "finished_requests": 50107,
    "scheduler_time": 40.06630769352875
}
#Debug simulation 
Total elapsed time: 3.9423322500661016. Arrivals time: 0.11413367511704564 Scheduler time: 3.617270697839558 Scheduler overhead time: 0.04035323532298207 Adapter cache time: 0.11161784967407584 Engine time: 0.040394172072410583 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_384_slots_160_rate_0.1-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_384_slots_160_rate_0.1-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 66, 33, 1080, 1080, 33, 66, 1080, 1080, 1080, 1080, 66, 66, 66, 66, 1080, 1080, 66, 66, 33, 1080, 33, 1080, 66, 66, 66, 33, 33, 66, 33, 1080, 33, 1080, 66, 1080, 66, 33, 66, 1080, 66, 1080, 33, 1080, 1080, 1080, 1080, 33, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 66, 1080, 1080, 66, 1080, 1080, 33, 33, 1080, 66, 66, 33, 33, 33, 66, 33, 66, 33, 1080, 33, 66, 1080, 33, 1080, 66, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 1080, 1080, 66, 33, 33, 1080, 66, 66, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 66, 1080, 1080, 33, 66, 66, 66, 66, 33, 33, 1080, 33, 1080, 33, 33, 33, 66, 66, 1080, 33, 33, 1080, 33, 1080, 66, 33, 1080, 66, 66, 33, 1080, 1080, 1080, 33, 66, 1080, 33, 1080, 66, 66, 1080, 1080, 33, 66, 1080, 33, 66, 66, 33, 66, 33, 66, 1080, 1080, 66, 33, 1080, 33, 1080, 66, 66, 66, 66, 66, 33, 33, 1080, 33, 1080, 33, 66, 1080, 66, 1080, 66, 1080, 66, 1080, 33, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 33, 33, 33, 33, 33, 66, 33, 33, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33, 66, 1080, 1080, 66, 66, 33, 1080, 66, 1080, 33, 66, 66, 33, 33, 66, 33, 1080, 1080, 33, 1080, 1080, 33, 66, 1080, 33, 33, 66, 66, 33, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 1080, 66, 66, 66, 1080, 33, 66, 66, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 66, 33, 1080, 1080, 1080, 66, 33, 1080, 1080, 66, 66, 1080, 1080, 33, 1080, 1080, 66, 33, 1080, 66, 66, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 66, 1080, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 1080, 33, 33, 33, 66, 33, 66, 66, 33, 1080, 66, 1080, 33, 1080, 33, 66, 66, 66, 66, 33, 66, 1080, 1080, 33, 1080, 1080, 33, 1080, 66, 1080, 66, 66, 66, 33, 66, 33, 33, 1080, 33, 66, 33, 33, 66, 1080, 66, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 150912 . Total input tokens: 33712521 . Total output tokens: 30175123
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.925222699996084,
    "estimated_duration": 3600.1371664915114,
    "input_throughput": 3470.4644357137327,
    "output_throughput": 3061.2741932664876,
    "total_throughput": 6531.738628980221,
    "itl": 134.12442051113496,
    "ttft": 36442.79448644897,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4964,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.217909069786305,
    "arrivals": 50610,
    "finished_requests": 50110,
    "scheduler_time": 40.06910728664728
}
#Debug simulation 
Total elapsed time: 3.9253047457896173. Arrivals time: 0.11379952915012836 Scheduler time: 3.601742918137461 Scheduler overhead time: 0.040218889247626066 Adapter cache time: 0.11087878001853824 Engine time: 0.040276250801980495 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_384_slots_160_rate_0.1-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_384_slots_160_rate_0.1-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 66, 33, 1080, 1080, 33, 66, 1080, 1080, 1080, 1080, 66, 66, 66, 66, 1080, 1080, 66, 66, 33, 1080, 33, 1080, 66, 66, 66, 33, 33, 66, 33, 1080, 33, 1080, 66, 1080, 66, 33, 66, 1080, 66, 1080, 33, 1080, 1080, 1080, 1080, 33, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 66, 1080, 1080, 66, 1080, 1080, 33, 33, 1080, 66, 66, 33, 33, 33, 66, 33, 66, 33, 1080, 33, 66, 1080, 33, 1080, 66, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 1080, 1080, 66, 33, 33, 1080, 66, 66, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 66, 1080, 1080, 33, 66, 66, 66, 66, 33, 33, 1080, 33, 1080, 33, 33, 33, 66, 66, 1080, 33, 33, 1080, 33, 1080, 66, 33, 1080, 66, 66, 33, 1080, 1080, 1080, 33, 66, 1080, 33, 1080, 66, 66, 1080, 1080, 33, 66, 1080, 33, 66, 66, 33, 66, 33, 66, 1080, 1080, 66, 33, 1080, 33, 1080, 66, 66, 66, 66, 66, 33, 33, 1080, 33, 1080, 33, 66, 1080, 66, 1080, 66, 1080, 66, 1080, 33, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 33, 33, 33, 33, 33, 66, 33, 33, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33, 66, 1080, 1080, 66, 66, 33, 1080, 66, 1080, 33, 66, 66, 33, 33, 66, 33, 1080, 1080, 33, 1080, 1080, 33, 66, 1080, 33, 33, 66, 66, 33, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 1080, 66, 66, 66, 1080, 33, 66, 66, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 66, 33, 1080, 1080, 1080, 66, 33, 1080, 1080, 66, 66, 1080, 1080, 33, 1080, 1080, 66, 33, 1080, 66, 66, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 66, 1080, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 1080, 33, 33, 33, 66, 33, 66, 66, 33, 1080, 66, 1080, 33, 1080, 33, 66, 66, 66, 66, 33, 66, 1080, 1080, 33, 1080, 1080, 33, 1080, 66, 1080, 66, 66, 66, 33, 66, 33, 33, 1080, 33, 66, 33, 33, 66, 1080, 66, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 150912 . Total input tokens: 33712521 . Total output tokens: 30175123
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 3.9267228110693395,
    "estimated_duration": 3600.0098020047685,
    "input_throughput": 3470.427495236984,
    "output_throughput": 3061.2827759143424,
    "total_throughput": 6531.710271151326,
    "itl": 134.0274664957983,
    "ttft": 36499.16616470451,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4963,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.522382390714668,
    "arrivals": 50610,
    "finished_requests": 50107,
    "scheduler_time": 40.06232999432288
}
#Debug simulation 
Total elapsed time: 3.926813692320138. Arrivals time: 0.11424227245151997 Scheduler time: 3.6026036855764687 Scheduler overhead time: 0.04034442035481334 Adapter cache time: 0.11110033467411995 Engine time: 0.040056068915873766 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_384_slots_160_rate_0.1-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_384_slots_160_rate_0.1-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 66, 33, 1080, 1080, 33, 66, 1080, 1080, 1080, 1080, 66, 66, 66, 66, 1080, 1080, 66, 66, 33, 1080, 33, 1080, 66, 66, 66, 33, 33, 66, 33, 1080, 33, 1080, 66, 1080, 66, 33, 66, 1080, 66, 1080, 33, 1080, 1080, 1080, 1080, 33, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 66, 1080, 1080, 66, 1080, 1080, 33, 33, 1080, 66, 66, 33, 33, 33, 66, 33, 66, 33, 1080, 33, 66, 1080, 33, 1080, 66, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 1080, 1080, 66, 33, 33, 1080, 66, 66, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 66, 1080, 1080, 33, 66, 66, 66, 66, 33, 33, 1080, 33, 1080, 33, 33, 33, 66, 66, 1080, 33, 33, 1080, 33, 1080, 66, 33, 1080, 66, 66, 33, 1080, 1080, 1080, 33, 66, 1080, 33, 1080, 66, 66, 1080, 1080, 33, 66, 1080, 33, 66, 66, 33, 66, 33, 66, 1080, 1080, 66, 33, 1080, 33, 1080, 66, 66, 66, 66, 66, 33, 33, 1080, 33, 1080, 33, 66, 1080, 66, 1080, 66, 1080, 66, 1080, 33, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 33, 33, 33, 33, 33, 66, 33, 33, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33, 66, 1080, 1080, 66, 66, 33, 1080, 66, 1080, 33, 66, 66, 33, 33, 66, 33, 1080, 1080, 33, 1080, 1080, 33, 66, 1080, 33, 33, 66, 66, 33, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 1080, 66, 66, 66, 1080, 33, 66, 66, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 66, 33, 1080, 1080, 1080, 66, 33, 1080, 1080, 66, 66, 1080, 1080, 33, 1080, 1080, 66, 33, 1080, 66, 66, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 66, 1080, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 1080, 33, 33, 33, 66, 33, 66, 66, 33, 1080, 66, 1080, 33, 1080, 33, 66, 66, 66, 66, 33, 66, 1080, 1080, 33, 1080, 1080, 33, 1080, 66, 1080, 66, 66, 66, 33, 66, 33, 33, 1080, 33, 66, 33, 33, 66, 1080, 66, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 150912 . Total input tokens: 33712521 . Total output tokens: 30175123
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 3.95447011385113,
    "estimated_duration": 3600.027578132102,
    "input_throughput": 3470.4103590457416,
    "output_throughput": 3061.267659987798,
    "total_throughput": 6531.678019033539,
    "itl": 134.13704745996068,
    "ttft": 36513.24070367144,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4967,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.432149764167736,
    "arrivals": 50610,
    "finished_requests": 50107,
    "scheduler_time": 40.06780337879341
}
#Debug simulation 
Total elapsed time: 3.9545585988089442. Arrivals time: 0.11559103848412633 Scheduler time: 3.6257111951708794 Scheduler overhead time: 0.04094334086403251 Adapter cache time: 0.11303300363942981 Engine time: 0.04073079256340861 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_384_slots_160_rate_0.1-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_384_slots_160_rate_0.1-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 66, 33, 1080, 1080, 33, 66, 1080, 1080, 1080, 1080, 66, 66, 66, 66, 1080, 1080, 66, 66, 33, 1080, 33, 1080, 66, 66, 66, 33, 33, 66, 33, 1080, 33, 1080, 66, 1080, 66, 33, 66, 1080, 66, 1080, 33, 1080, 1080, 1080, 1080, 33, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 66, 1080, 1080, 66, 1080, 1080, 33, 33, 1080, 66, 66, 33, 33, 33, 66, 33, 66, 33, 1080, 33, 66, 1080, 33, 1080, 66, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 1080, 1080, 66, 33, 33, 1080, 66, 66, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 66, 1080, 1080, 33, 66, 66, 66, 66, 33, 33, 1080, 33, 1080, 33, 33, 33, 66, 66, 1080, 33, 33, 1080, 33, 1080, 66, 33, 1080, 66, 66, 33, 1080, 1080, 1080, 33, 66, 1080, 33, 1080, 66, 66, 1080, 1080, 33, 66, 1080, 33, 66, 66, 33, 66, 33, 66, 1080, 1080, 66, 33, 1080, 33, 1080, 66, 66, 66, 66, 66, 33, 33, 1080, 33, 1080, 33, 66, 1080, 66, 1080, 66, 1080, 66, 1080, 33, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 33, 33, 33, 33, 33, 66, 33, 33, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33, 66, 1080, 1080, 66, 66, 33, 1080, 66, 1080, 33, 66, 66, 33, 33, 66, 33, 1080, 1080, 33, 1080, 1080, 33, 66, 1080, 33, 33, 66, 66, 33, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 1080, 66, 66, 66, 1080, 33, 66, 66, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 66, 33, 1080, 1080, 1080, 66, 33, 1080, 1080, 66, 66, 1080, 1080, 33, 1080, 1080, 66, 33, 1080, 66, 66, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 66, 1080, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 1080, 33, 33, 33, 66, 33, 66, 66, 33, 1080, 66, 1080, 33, 1080, 33, 66, 66, 66, 66, 33, 66, 1080, 1080, 33, 1080, 1080, 33, 1080, 66, 1080, 66, 66, 66, 33, 66, 33, 33, 1080, 33, 66, 33, 33, 66, 1080, 66, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 150912 . Total input tokens: 33712521 . Total output tokens: 30175123
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.9656913513317704,
    "estimated_duration": 3600.0335443317813,
    "input_throughput": 3470.47377368786,
    "output_throughput": 3061.487862343167,
    "total_throughput": 6531.961636031027,
    "itl": 133.90398410864836,
    "ttft": 36341.48026005017,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4971,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.863540015960261,
    "arrivals": 50610,
    "finished_requests": 50109,
    "scheduler_time": 40.05778131451638
}
#Debug simulation 
Total elapsed time: 3.9657791503705084. Arrivals time: 0.11636663833633065 Scheduler time: 3.6381777389906347 Scheduler overhead time: 0.0409455974586308 Adapter cache time: 0.11125732585787773 Engine time: 0.04046519938856363 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_384_slots_160_rate_0.1-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_384_slots_160_rate_0.1-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 66, 33, 1080, 1080, 33, 66, 1080, 1080, 1080, 1080, 66, 66, 66, 66, 1080, 1080, 66, 66, 33, 1080, 33, 1080, 66, 66, 66, 33, 33, 66, 33, 1080, 33, 1080, 66, 1080, 66, 33, 66, 1080, 66, 1080, 33, 1080, 1080, 1080, 1080, 33, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 66, 1080, 1080, 66, 1080, 1080, 33, 33, 1080, 66, 66, 33, 33, 33, 66, 33, 66, 33, 1080, 33, 66, 1080, 33, 1080, 66, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 1080, 1080, 66, 33, 33, 1080, 66, 66, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 66, 1080, 1080, 33, 66, 66, 66, 66, 33, 33, 1080, 33, 1080, 33, 33, 33, 66, 66, 1080, 33, 33, 1080, 33, 1080, 66, 33, 1080, 66, 66, 33, 1080, 1080, 1080, 33, 66, 1080, 33, 1080, 66, 66, 1080, 1080, 33, 66, 1080, 33, 66, 66, 33, 66, 33, 66, 1080, 1080, 66, 33, 1080, 33, 1080, 66, 66, 66, 66, 66, 33, 33, 1080, 33, 1080, 33, 66, 1080, 66, 1080, 66, 1080, 66, 1080, 33, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 33, 33, 33, 33, 33, 66, 33, 33, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33, 66, 1080, 1080, 66, 66, 33, 1080, 66, 1080, 33, 66, 66, 33, 33, 66, 33, 1080, 1080, 33, 1080, 1080, 33, 66, 1080, 33, 33, 66, 66, 33, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 1080, 66, 66, 66, 1080, 33, 66, 66, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 66, 33, 1080, 1080, 1080, 66, 33, 1080, 1080, 66, 66, 1080, 1080, 33, 1080, 1080, 66, 33, 1080, 66, 66, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 66, 1080, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 1080, 33, 33, 33, 66, 33, 66, 66, 33, 1080, 66, 1080, 33, 1080, 33, 66, 66, 66, 66, 33, 66, 1080, 1080, 33, 1080, 1080, 33, 1080, 66, 1080, 66, 66, 66, 33, 66, 33, 33, 1080, 33, 66, 33, 33, 66, 1080, 66, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 150912 . Total input tokens: 33712521 . Total output tokens: 30175123
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.957483380101621,
    "estimated_duration": 3600.0783363985024,
    "input_throughput": 3470.383372962539,
    "output_throughput": 3061.3147743405266,
    "total_throughput": 6531.6981473030655,
    "itl": 134.16900938561665,
    "ttft": 36583.818229920056,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4968,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.645327860115763,
    "arrivals": 50610,
    "finished_requests": 50108,
    "scheduler_time": 40.06969445433514
}
#Debug simulation 
Total elapsed time: 3.957570150960237. Arrivals time: 0.11716014891862869 Scheduler time: 3.62980167940259 Scheduler overhead time: 0.04062177427113056 Adapter cache time: 0.11129373125731945 Engine time: 0.04022359102964401 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_384_slots_160_rate_0.05-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_384_slots_160_rate_0.05-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 540, 270, 135, 540, 540, 135, 270, 540, 540, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 135, 540, 135, 540, 270, 270, 270, 135, 135, 270, 135, 540, 135, 540, 270, 540, 270, 135, 270, 540, 270, 540, 135, 540, 540, 540, 540, 135, 270, 270, 270, 540, 270, 135, 270, 135, 540, 270, 540, 540, 270, 540, 540, 135, 135, 540, 270, 270, 135, 135, 135, 270, 135, 270, 135, 540, 135, 270, 540, 135, 540, 270, 135, 540, 540, 540, 540, 270, 135, 270, 540, 540, 270, 135, 135, 540, 270, 270, 135, 135, 540, 270, 540, 270, 540, 540, 270, 540, 540, 135, 270, 270, 270, 270, 135, 135, 540, 135, 540, 135, 135, 135, 270, 270, 540, 135, 135, 540, 135, 540, 270, 135, 540, 270, 270, 135, 540, 540, 540, 135, 270, 540, 135, 540, 270, 270, 540, 540, 135, 270, 540, 135, 270, 270, 135, 270, 135, 270, 540, 540, 270, 135, 540, 135, 540, 270, 270, 270, 270, 270, 135, 135, 540, 135, 540, 135, 270, 540, 270, 540, 270, 540, 270, 540, 135, 270, 270, 270, 270, 270, 270, 270, 270, 540, 135, 135, 135, 135, 135, 270, 135, 135, 270, 540, 540, 135, 135, 540, 135, 135, 135, 270, 135, 270, 540, 540, 270, 270, 135, 540, 270, 540, 135, 270, 270, 135, 135, 270, 135, 540, 540, 135, 540, 540, 135, 270, 540, 135, 135, 270, 270, 135, 135, 540, 540, 540, 540, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 540, 270, 270, 270, 540, 135, 270, 270, 540, 540, 135, 540, 540, 135, 540, 135, 135, 270, 135, 540, 540, 540, 270, 135, 540, 540, 270, 270, 540, 540, 135, 540, 540, 270, 135, 540, 270, 270, 540, 540, 540, 135, 540, 135, 540, 540, 135, 135, 540, 135, 270, 540, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 540, 135, 135, 135, 270, 135, 270, 270, 135, 540, 270, 540, 135, 540, 135, 270, 270, 270, 270, 135, 270, 540, 540, 135, 540, 540, 135, 540, 270, 540, 270, 270, 270, 135, 270, 135, 135, 540, 135, 270, 135, 135, 270, 540, 270, 540, 135, 540, 540, 270, 540, 270, 135, 540, 135, 540, 540, 135, 135, 135]
Prompts retrieved: 120960 . Total input tokens: 27012138 . Total output tokens: 24203683
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.7811492877081037,
    "estimated_duration": 3600.0044080131797,
    "input_throughput": 2788.029363980505,
    "output_throughput": 2428.1161935643936,
    "total_throughput": 5216.145557544899,
    "itl": 95.0321332413207,
    "ttft": 37758.71556293346,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 14388,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 44.0342976596978,
    "arrivals": 40507,
    "finished_requests": 40150,
    "scheduler_time": 29.01559949330497
}
#Debug simulation 
Total elapsed time: 3.7812343728728592. Arrivals time: 0.09929110994562507 Scheduler time: 3.2981360629200935 Scheduler overhead time: 0.05149638745933771 Adapter cache time: 0.25979403126984835 Engine time: 0.04898342862725258 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_384_slots_160_rate_0.05-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_384_slots_160_rate_0.05-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 540, 270, 135, 540, 540, 135, 270, 540, 540, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 135, 540, 135, 540, 270, 270, 270, 135, 135, 270, 135, 540, 135, 540, 270, 540, 270, 135, 270, 540, 270, 540, 135, 540, 540, 540, 540, 135, 270, 270, 270, 540, 270, 135, 270, 135, 540, 270, 540, 540, 270, 540, 540, 135, 135, 540, 270, 270, 135, 135, 135, 270, 135, 270, 135, 540, 135, 270, 540, 135, 540, 270, 135, 540, 540, 540, 540, 270, 135, 270, 540, 540, 270, 135, 135, 540, 270, 270, 135, 135, 540, 270, 540, 270, 540, 540, 270, 540, 540, 135, 270, 270, 270, 270, 135, 135, 540, 135, 540, 135, 135, 135, 270, 270, 540, 135, 135, 540, 135, 540, 270, 135, 540, 270, 270, 135, 540, 540, 540, 135, 270, 540, 135, 540, 270, 270, 540, 540, 135, 270, 540, 135, 270, 270, 135, 270, 135, 270, 540, 540, 270, 135, 540, 135, 540, 270, 270, 270, 270, 270, 135, 135, 540, 135, 540, 135, 270, 540, 270, 540, 270, 540, 270, 540, 135, 270, 270, 270, 270, 270, 270, 270, 270, 540, 135, 135, 135, 135, 135, 270, 135, 135, 270, 540, 540, 135, 135, 540, 135, 135, 135, 270, 135, 270, 540, 540, 270, 270, 135, 540, 270, 540, 135, 270, 270, 135, 135, 270, 135, 540, 540, 135, 540, 540, 135, 270, 540, 135, 135, 270, 270, 135, 135, 540, 540, 540, 540, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 540, 270, 270, 270, 540, 135, 270, 270, 540, 540, 135, 540, 540, 135, 540, 135, 135, 270, 135, 540, 540, 540, 270, 135, 540, 540, 270, 270, 540, 540, 135, 540, 540, 270, 135, 540, 270, 270, 540, 540, 540, 135, 540, 135, 540, 540, 135, 135, 540, 135, 270, 540, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 540, 135, 135, 135, 270, 135, 270, 270, 135, 540, 270, 540, 135, 540, 135, 270, 270, 270, 270, 135, 270, 540, 540, 135, 540, 540, 135, 540, 270, 540, 270, 270, 270, 135, 270, 135, 135, 540, 135, 270, 135, 135, 270, 540, 270, 540, 135, 540, 540, 270, 540, 270, 135, 540, 135, 540, 540, 135, 135, 135]
Prompts retrieved: 120960 . Total input tokens: 27012138 . Total output tokens: 24203683
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.8618291686289012,
    "estimated_duration": 3600.0099106638463,
    "input_throughput": 2788.0251024501154,
    "output_throughput": 2428.1124821648355,
    "total_throughput": 5216.13758461495,
    "itl": 95.18946370829188,
    "ttft": 37792.980117591076,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 14349,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 46.83328426367974,
    "arrivals": 40507,
    "finished_requests": 40150,
    "scheduler_time": 29.02770989690974
}
#Debug simulation 
Total elapsed time: 3.8619133038446307. Arrivals time: 0.10052589187398553 Scheduler time: 3.3733856920152903 Scheduler overhead time: 0.05179943051189184 Adapter cache time: 0.2616743501275778 Engine time: 0.05070216627791524 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_384_slots_160_rate_0.05-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_384_slots_160_rate_0.05-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 540, 270, 135, 540, 540, 135, 270, 540, 540, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 135, 540, 135, 540, 270, 270, 270, 135, 135, 270, 135, 540, 135, 540, 270, 540, 270, 135, 270, 540, 270, 540, 135, 540, 540, 540, 540, 135, 270, 270, 270, 540, 270, 135, 270, 135, 540, 270, 540, 540, 270, 540, 540, 135, 135, 540, 270, 270, 135, 135, 135, 270, 135, 270, 135, 540, 135, 270, 540, 135, 540, 270, 135, 540, 540, 540, 540, 270, 135, 270, 540, 540, 270, 135, 135, 540, 270, 270, 135, 135, 540, 270, 540, 270, 540, 540, 270, 540, 540, 135, 270, 270, 270, 270, 135, 135, 540, 135, 540, 135, 135, 135, 270, 270, 540, 135, 135, 540, 135, 540, 270, 135, 540, 270, 270, 135, 540, 540, 540, 135, 270, 540, 135, 540, 270, 270, 540, 540, 135, 270, 540, 135, 270, 270, 135, 270, 135, 270, 540, 540, 270, 135, 540, 135, 540, 270, 270, 270, 270, 270, 135, 135, 540, 135, 540, 135, 270, 540, 270, 540, 270, 540, 270, 540, 135, 270, 270, 270, 270, 270, 270, 270, 270, 540, 135, 135, 135, 135, 135, 270, 135, 135, 270, 540, 540, 135, 135, 540, 135, 135, 135, 270, 135, 270, 540, 540, 270, 270, 135, 540, 270, 540, 135, 270, 270, 135, 135, 270, 135, 540, 540, 135, 540, 540, 135, 270, 540, 135, 135, 270, 270, 135, 135, 540, 540, 540, 540, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 540, 270, 270, 270, 540, 135, 270, 270, 540, 540, 135, 540, 540, 135, 540, 135, 135, 270, 135, 540, 540, 540, 270, 135, 540, 540, 270, 270, 540, 540, 135, 540, 540, 270, 135, 540, 270, 270, 540, 540, 540, 135, 540, 135, 540, 540, 135, 135, 540, 135, 270, 540, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 540, 135, 135, 135, 270, 135, 270, 270, 135, 540, 270, 540, 135, 540, 135, 270, 270, 270, 270, 135, 270, 540, 540, 135, 540, 540, 135, 540, 270, 540, 270, 270, 270, 135, 270, 135, 135, 540, 135, 270, 135, 135, 270, 540, 270, 540, 135, 540, 540, 270, 540, 270, 135, 540, 135, 540, 540, 135, 135, 135]
Prompts retrieved: 120960 . Total input tokens: 27012138 . Total output tokens: 24203683
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.832526451908052,
    "estimated_duration": 3600.0295654300803,
    "input_throughput": 2788.009880913556,
    "output_throughput": 2428.0992256116992,
    "total_throughput": 5216.109106525256,
    "itl": 95.1943368514477,
    "ttft": 37786.96734338256,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 14353,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 46.92794693377842,
    "arrivals": 40507,
    "finished_requests": 40150,
    "scheduler_time": 29.028084244808607
}
#Debug simulation 
Total elapsed time: 3.832610433921218. Arrivals time: 0.1014297385700047 Scheduler time: 3.3451253371313214 Scheduler overhead time: 0.05189548805356026 Adapter cache time: 0.26091597508639097 Engine time: 0.049378089141100645 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_384_slots_160_rate_0.05-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_384_slots_160_rate_0.05-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 540, 270, 135, 540, 540, 135, 270, 540, 540, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 135, 540, 135, 540, 270, 270, 270, 135, 135, 270, 135, 540, 135, 540, 270, 540, 270, 135, 270, 540, 270, 540, 135, 540, 540, 540, 540, 135, 270, 270, 270, 540, 270, 135, 270, 135, 540, 270, 540, 540, 270, 540, 540, 135, 135, 540, 270, 270, 135, 135, 135, 270, 135, 270, 135, 540, 135, 270, 540, 135, 540, 270, 135, 540, 540, 540, 540, 270, 135, 270, 540, 540, 270, 135, 135, 540, 270, 270, 135, 135, 540, 270, 540, 270, 540, 540, 270, 540, 540, 135, 270, 270, 270, 270, 135, 135, 540, 135, 540, 135, 135, 135, 270, 270, 540, 135, 135, 540, 135, 540, 270, 135, 540, 270, 270, 135, 540, 540, 540, 135, 270, 540, 135, 540, 270, 270, 540, 540, 135, 270, 540, 135, 270, 270, 135, 270, 135, 270, 540, 540, 270, 135, 540, 135, 540, 270, 270, 270, 270, 270, 135, 135, 540, 135, 540, 135, 270, 540, 270, 540, 270, 540, 270, 540, 135, 270, 270, 270, 270, 270, 270, 270, 270, 540, 135, 135, 135, 135, 135, 270, 135, 135, 270, 540, 540, 135, 135, 540, 135, 135, 135, 270, 135, 270, 540, 540, 270, 270, 135, 540, 270, 540, 135, 270, 270, 135, 135, 270, 135, 540, 540, 135, 540, 540, 135, 270, 540, 135, 135, 270, 270, 135, 135, 540, 540, 540, 540, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 540, 270, 270, 270, 540, 135, 270, 270, 540, 540, 135, 540, 540, 135, 540, 135, 135, 270, 135, 540, 540, 540, 270, 135, 540, 540, 270, 270, 540, 540, 135, 540, 540, 270, 135, 540, 270, 270, 540, 540, 540, 135, 540, 135, 540, 540, 135, 135, 540, 135, 270, 540, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 540, 135, 135, 135, 270, 135, 270, 270, 135, 540, 270, 540, 135, 540, 135, 270, 270, 270, 270, 135, 270, 540, 540, 135, 540, 540, 135, 540, 270, 540, 270, 270, 270, 135, 270, 135, 135, 540, 135, 270, 135, 135, 270, 540, 270, 540, 135, 540, 540, 270, 540, 270, 135, 540, 135, 540, 540, 135, 135, 135]
Prompts retrieved: 120960 . Total input tokens: 27012138 . Total output tokens: 24203683
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 3.8192999698221684,
    "estimated_duration": 3600.073401236591,
    "input_throughput": 2788.0109323749816,
    "output_throughput": 2428.1346588648416,
    "total_throughput": 5216.145591239823,
    "itl": 95.08508024828748,
    "ttft": 37695.29987920774,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 14367,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 44.938514095345965,
    "arrivals": 40507,
    "finished_requests": 40151,
    "scheduler_time": 29.020623480295086
}
#Debug simulation 
Total elapsed time: 3.8193822386674583. Arrivals time: 0.09957984881475568 Scheduler time: 3.3351162201724946 Scheduler overhead time: 0.05113624269142747 Adapter cache time: 0.26068255212157965 Engine time: 0.04924221709370613 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_384_slots_160_rate_0.05-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_384_slots_160_rate_0.05-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 540, 270, 135, 540, 540, 135, 270, 540, 540, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 135, 540, 135, 540, 270, 270, 270, 135, 135, 270, 135, 540, 135, 540, 270, 540, 270, 135, 270, 540, 270, 540, 135, 540, 540, 540, 540, 135, 270, 270, 270, 540, 270, 135, 270, 135, 540, 270, 540, 540, 270, 540, 540, 135, 135, 540, 270, 270, 135, 135, 135, 270, 135, 270, 135, 540, 135, 270, 540, 135, 540, 270, 135, 540, 540, 540, 540, 270, 135, 270, 540, 540, 270, 135, 135, 540, 270, 270, 135, 135, 540, 270, 540, 270, 540, 540, 270, 540, 540, 135, 270, 270, 270, 270, 135, 135, 540, 135, 540, 135, 135, 135, 270, 270, 540, 135, 135, 540, 135, 540, 270, 135, 540, 270, 270, 135, 540, 540, 540, 135, 270, 540, 135, 540, 270, 270, 540, 540, 135, 270, 540, 135, 270, 270, 135, 270, 135, 270, 540, 540, 270, 135, 540, 135, 540, 270, 270, 270, 270, 270, 135, 135, 540, 135, 540, 135, 270, 540, 270, 540, 270, 540, 270, 540, 135, 270, 270, 270, 270, 270, 270, 270, 270, 540, 135, 135, 135, 135, 135, 270, 135, 135, 270, 540, 540, 135, 135, 540, 135, 135, 135, 270, 135, 270, 540, 540, 270, 270, 135, 540, 270, 540, 135, 270, 270, 135, 135, 270, 135, 540, 540, 135, 540, 540, 135, 270, 540, 135, 135, 270, 270, 135, 135, 540, 540, 540, 540, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 540, 270, 270, 270, 540, 135, 270, 270, 540, 540, 135, 540, 540, 135, 540, 135, 135, 270, 135, 540, 540, 540, 270, 135, 540, 540, 270, 270, 540, 540, 135, 540, 540, 270, 135, 540, 270, 270, 540, 540, 540, 135, 540, 135, 540, 540, 135, 135, 540, 135, 270, 540, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 540, 135, 135, 135, 270, 135, 270, 270, 135, 540, 270, 540, 135, 540, 135, 270, 270, 270, 270, 135, 270, 540, 540, 135, 540, 540, 135, 540, 270, 540, 270, 270, 270, 135, 270, 135, 135, 540, 135, 270, 135, 135, 270, 540, 270, 540, 135, 540, 540, 270, 540, 270, 135, 540, 135, 540, 540, 135, 135, 135]
Prompts retrieved: 120960 . Total input tokens: 27012138 . Total output tokens: 24203683
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 3.830209954176098,
    "estimated_duration": 3599.9965916233514,
    "input_throughput": 2788.03541740967,
    "output_throughput": 2428.121465542362,
    "total_throughput": 5216.156882952032,
    "itl": 95.22824025458708,
    "ttft": 37808.103110179254,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 14346,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 47.504590131850854,
    "arrivals": 40507,
    "finished_requests": 40150,
    "scheduler_time": 29.030897233752135
}
#Debug simulation 
Total elapsed time: 3.8302936861291528. Arrivals time: 0.09990220284089446 Scheduler time: 3.3450997974723577 Scheduler overhead time: 0.051529266871511936 Adapter cache time: 0.2601192509755492 Engine time: 0.049912082962691784 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_384_slots_160_rate_0.05-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_384_slots_160_rate_0.05-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 540, 270, 135, 540, 540, 135, 270, 540, 540, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 135, 540, 135, 540, 270, 270, 270, 135, 135, 270, 135, 540, 135, 540, 270, 540, 270, 135, 270, 540, 270, 540, 135, 540, 540, 540, 540, 135, 270, 270, 270, 540, 270, 135, 270, 135, 540, 270, 540, 540, 270, 540, 540, 135, 135, 540, 270, 270, 135, 135, 135, 270, 135, 270, 135, 540, 135, 270, 540, 135, 540, 270, 135, 540, 540, 540, 540, 270, 135, 270, 540, 540, 270, 135, 135, 540, 270, 270, 135, 135, 540, 270, 540, 270, 540, 540, 270, 540, 540, 135, 270, 270, 270, 270, 135, 135, 540, 135, 540, 135, 135, 135, 270, 270, 540, 135, 135, 540, 135, 540, 270, 135, 540, 270, 270, 135, 540, 540, 540, 135, 270, 540, 135, 540, 270, 270, 540, 540, 135, 270, 540, 135, 270, 270, 135, 270, 135, 270, 540, 540, 270, 135, 540, 135, 540, 270, 270, 270, 270, 270, 135, 135, 540, 135, 540, 135, 270, 540, 270, 540, 270, 540, 270, 540, 135, 270, 270, 270, 270, 270, 270, 270, 270, 540, 135, 135, 135, 135, 135, 270, 135, 135, 270, 540, 540, 135, 135, 540, 135, 135, 135, 270, 135, 270, 540, 540, 270, 270, 135, 540, 270, 540, 135, 270, 270, 135, 135, 270, 135, 540, 540, 135, 540, 540, 135, 270, 540, 135, 135, 270, 270, 135, 135, 540, 540, 540, 540, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 540, 270, 270, 270, 540, 135, 270, 270, 540, 540, 135, 540, 540, 135, 540, 135, 135, 270, 135, 540, 540, 540, 270, 135, 540, 540, 270, 270, 540, 540, 135, 540, 540, 270, 135, 540, 270, 270, 540, 540, 540, 135, 540, 135, 540, 540, 135, 135, 540, 135, 270, 540, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 540, 135, 135, 135, 270, 135, 270, 270, 135, 540, 270, 540, 135, 540, 135, 270, 270, 270, 270, 135, 270, 540, 540, 135, 540, 540, 135, 540, 270, 540, 270, 270, 270, 135, 270, 135, 135, 540, 135, 270, 135, 135, 270, 540, 270, 540, 135, 540, 540, 270, 540, 270, 135, 540, 135, 540, 540, 135, 135, 135]
Prompts retrieved: 120960 . Total input tokens: 27012138 . Total output tokens: 24203683
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.827576099894941,
    "estimated_duration": 3600.054931058418,
    "input_throughput": 2788.1710674478377,
    "output_throughput": 2428.1973934853136,
    "total_throughput": 5216.368460933151,
    "itl": 94.98684705794453,
    "ttft": 37591.872992619305,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 14539,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 43.47234123758906,
    "arrivals": 40507,
    "finished_requests": 40150,
    "scheduler_time": 29.00673602397588
}
#Debug simulation 
Total elapsed time: 3.8276566099375486. Arrivals time: 0.09946873923763633 Scheduler time: 3.339367968495935 Scheduler overhead time: 0.05160593148320913 Adapter cache time: 0.26360441371798515 Engine time: 0.04984891973435879 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_384_slots_160_rate_0.05-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_384_slots_160_rate_0.05-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 540, 270, 135, 540, 540, 135, 270, 540, 540, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 135, 540, 135, 540, 270, 270, 270, 135, 135, 270, 135, 540, 135, 540, 270, 540, 270, 135, 270, 540, 270, 540, 135, 540, 540, 540, 540, 135, 270, 270, 270, 540, 270, 135, 270, 135, 540, 270, 540, 540, 270, 540, 540, 135, 135, 540, 270, 270, 135, 135, 135, 270, 135, 270, 135, 540, 135, 270, 540, 135, 540, 270, 135, 540, 540, 540, 540, 270, 135, 270, 540, 540, 270, 135, 135, 540, 270, 270, 135, 135, 540, 270, 540, 270, 540, 540, 270, 540, 540, 135, 270, 270, 270, 270, 135, 135, 540, 135, 540, 135, 135, 135, 270, 270, 540, 135, 135, 540, 135, 540, 270, 135, 540, 270, 270, 135, 540, 540, 540, 135, 270, 540, 135, 540, 270, 270, 540, 540, 135, 270, 540, 135, 270, 270, 135, 270, 135, 270, 540, 540, 270, 135, 540, 135, 540, 270, 270, 270, 270, 270, 135, 135, 540, 135, 540, 135, 270, 540, 270, 540, 270, 540, 270, 540, 135, 270, 270, 270, 270, 270, 270, 270, 270, 540, 135, 135, 135, 135, 135, 270, 135, 135, 270, 540, 540, 135, 135, 540, 135, 135, 135, 270, 135, 270, 540, 540, 270, 270, 135, 540, 270, 540, 135, 270, 270, 135, 135, 270, 135, 540, 540, 135, 540, 540, 135, 270, 540, 135, 135, 270, 270, 135, 135, 540, 540, 540, 540, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 540, 270, 270, 270, 540, 135, 270, 270, 540, 540, 135, 540, 540, 135, 540, 135, 135, 270, 135, 540, 540, 540, 270, 135, 540, 540, 270, 270, 540, 540, 135, 540, 540, 270, 135, 540, 270, 270, 540, 540, 540, 135, 540, 135, 540, 540, 135, 135, 540, 135, 270, 540, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 540, 135, 135, 135, 270, 135, 270, 270, 135, 540, 270, 540, 135, 540, 135, 270, 270, 270, 270, 135, 270, 540, 540, 135, 540, 540, 135, 540, 270, 540, 270, 270, 270, 135, 270, 135, 135, 540, 135, 270, 135, 135, 270, 540, 270, 540, 135, 540, 540, 270, 540, 270, 135, 540, 135, 540, 540, 135, 135, 135]
Prompts retrieved: 120960 . Total input tokens: 27012138 . Total output tokens: 24203683
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.8227718672715127,
    "estimated_duration": 3599.998333888055,
    "input_throughput": 2788.034068104684,
    "output_throughput": 2428.1202904222832,
    "total_throughput": 5216.154358526967,
    "itl": 95.26303825195895,
    "ttft": 37822.21009343551,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 14331,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 48.063332923912746,
    "arrivals": 40507,
    "finished_requests": 40150,
    "scheduler_time": 29.03356056043662
}
#Debug simulation 
Total elapsed time: 3.8228587810881436. Arrivals time: 0.10007455106824636 Scheduler time: 3.33858990855515 Scheduler overhead time: 0.05175322201102972 Adapter cache time: 0.2594750295393169 Engine time: 0.049194111954420805 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_384_slots_160_rate_0.05-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_384_slots_160_rate_0.05-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 540, 270, 66, 540, 540, 66, 270, 540, 540, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 66, 540, 66, 540, 270, 270, 270, 66, 66, 270, 66, 540, 66, 540, 270, 540, 270, 66, 270, 540, 270, 540, 66, 540, 540, 540, 540, 66, 270, 270, 270, 540, 270, 66, 270, 66, 540, 270, 540, 540, 270, 540, 540, 66, 66, 540, 270, 270, 66, 66, 66, 270, 66, 270, 66, 540, 66, 270, 540, 66, 540, 270, 66, 540, 540, 540, 540, 270, 66, 270, 540, 540, 270, 66, 66, 540, 270, 270, 66, 66, 540, 270, 540, 270, 540, 540, 270, 540, 540, 66, 270, 270, 270, 270, 66, 66, 540, 66, 540, 66, 66, 66, 270, 270, 540, 66, 66, 540, 66, 540, 270, 66, 540, 270, 270, 66, 540, 540, 540, 66, 270, 540, 66, 540, 270, 270, 540, 540, 66, 270, 540, 66, 270, 270, 66, 270, 66, 270, 540, 540, 270, 66, 540, 66, 540, 270, 270, 270, 270, 270, 66, 66, 540, 66, 540, 66, 270, 540, 270, 540, 270, 540, 270, 540, 66, 270, 270, 270, 270, 270, 270, 270, 270, 540, 66, 66, 66, 66, 66, 270, 66, 66, 270, 540, 540, 66, 66, 540, 66, 66, 66, 270, 66, 270, 540, 540, 270, 270, 66, 540, 270, 540, 66, 270, 270, 66, 66, 270, 66, 540, 540, 66, 540, 540, 66, 270, 540, 66, 66, 270, 270, 66, 66, 540, 540, 540, 540, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 540, 270, 270, 270, 540, 66, 270, 270, 540, 540, 66, 540, 540, 66, 540, 66, 66, 270, 66, 540, 540, 540, 270, 66, 540, 540, 270, 270, 540, 540, 66, 540, 540, 270, 66, 540, 270, 270, 540, 540, 540, 66, 540, 66, 540, 540, 66, 66, 540, 66, 270, 540, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 540, 66, 66, 66, 270, 66, 270, 270, 66, 540, 270, 540, 66, 540, 66, 270, 270, 270, 270, 66, 270, 540, 540, 66, 540, 540, 66, 540, 270, 540, 270, 270, 270, 66, 270, 66, 66, 540, 66, 270, 66, 66, 270, 540, 270, 540, 66, 540, 540, 270, 540, 270, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 112128 . Total input tokens: 25003147 . Total output tokens: 22451802
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.219761381391436,
    "estimated_duration": 3600.046503457301,
    "input_throughput": 2571.687057683534,
    "output_throughput": 2311.1168125216645,
    "total_throughput": 4882.803870205198,
    "itl": 82.66688830686122,
    "ttft": 28714.66640367336,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 15831,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 48.45058147418907,
    "arrivals": 37708,
    "finished_requests": 37411,
    "scheduler_time": 25.92345725772178
}
#Debug simulation 
Total elapsed time: 3.219845816027373. Arrivals time: 0.09536611288785934 Scheduler time: 2.6999684502370656 Scheduler overhead time: 0.053964522667229176 Adapter cache time: 0.29351669317111373 Engine time: 0.05190593143925071 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_384_slots_160_rate_0.05-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_384_slots_160_rate_0.05-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 540, 270, 66, 540, 540, 66, 270, 540, 540, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 66, 540, 66, 540, 270, 270, 270, 66, 66, 270, 66, 540, 66, 540, 270, 540, 270, 66, 270, 540, 270, 540, 66, 540, 540, 540, 540, 66, 270, 270, 270, 540, 270, 66, 270, 66, 540, 270, 540, 540, 270, 540, 540, 66, 66, 540, 270, 270, 66, 66, 66, 270, 66, 270, 66, 540, 66, 270, 540, 66, 540, 270, 66, 540, 540, 540, 540, 270, 66, 270, 540, 540, 270, 66, 66, 540, 270, 270, 66, 66, 540, 270, 540, 270, 540, 540, 270, 540, 540, 66, 270, 270, 270, 270, 66, 66, 540, 66, 540, 66, 66, 66, 270, 270, 540, 66, 66, 540, 66, 540, 270, 66, 540, 270, 270, 66, 540, 540, 540, 66, 270, 540, 66, 540, 270, 270, 540, 540, 66, 270, 540, 66, 270, 270, 66, 270, 66, 270, 540, 540, 270, 66, 540, 66, 540, 270, 270, 270, 270, 270, 66, 66, 540, 66, 540, 66, 270, 540, 270, 540, 270, 540, 270, 540, 66, 270, 270, 270, 270, 270, 270, 270, 270, 540, 66, 66, 66, 66, 66, 270, 66, 66, 270, 540, 540, 66, 66, 540, 66, 66, 66, 270, 66, 270, 540, 540, 270, 270, 66, 540, 270, 540, 66, 270, 270, 66, 66, 270, 66, 540, 540, 66, 540, 540, 66, 270, 540, 66, 66, 270, 270, 66, 66, 540, 540, 540, 540, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 540, 270, 270, 270, 540, 66, 270, 270, 540, 540, 66, 540, 540, 66, 540, 66, 66, 270, 66, 540, 540, 540, 270, 66, 540, 540, 270, 270, 540, 540, 66, 540, 540, 270, 66, 540, 270, 270, 540, 540, 540, 66, 540, 66, 540, 540, 66, 66, 540, 66, 270, 540, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 540, 66, 66, 66, 270, 66, 270, 270, 66, 540, 270, 540, 66, 540, 66, 270, 270, 270, 270, 66, 270, 540, 540, 66, 540, 540, 66, 540, 270, 540, 270, 270, 270, 66, 270, 66, 66, 540, 66, 270, 66, 66, 270, 540, 270, 540, 66, 540, 540, 270, 540, 270, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 112128 . Total input tokens: 25003147 . Total output tokens: 22451802
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.2015832089819014,
    "estimated_duration": 3600.0708640978573,
    "input_throughput": 2571.6696558194035,
    "output_throughput": 2311.1011738611824,
    "total_throughput": 4882.770829680586,
    "itl": 83.06443245853484,
    "ttft": 28832.369759263413,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 15792,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 51.56959720785745,
    "arrivals": 37708,
    "finished_requests": 37411,
    "scheduler_time": 25.96480332393121
}
#Debug simulation 
Total elapsed time: 3.2016646270640194. Arrivals time: 0.09465343272313476 Scheduler time: 2.683558375108987 Scheduler overhead time: 0.052756999153643847 Adapter cache time: 0.2946731806732714 Engine time: 0.05119864083826542 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_384_slots_160_rate_0.05-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_384_slots_160_rate_0.05-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 540, 270, 66, 540, 540, 66, 270, 540, 540, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 66, 540, 66, 540, 270, 270, 270, 66, 66, 270, 66, 540, 66, 540, 270, 540, 270, 66, 270, 540, 270, 540, 66, 540, 540, 540, 540, 66, 270, 270, 270, 540, 270, 66, 270, 66, 540, 270, 540, 540, 270, 540, 540, 66, 66, 540, 270, 270, 66, 66, 66, 270, 66, 270, 66, 540, 66, 270, 540, 66, 540, 270, 66, 540, 540, 540, 540, 270, 66, 270, 540, 540, 270, 66, 66, 540, 270, 270, 66, 66, 540, 270, 540, 270, 540, 540, 270, 540, 540, 66, 270, 270, 270, 270, 66, 66, 540, 66, 540, 66, 66, 66, 270, 270, 540, 66, 66, 540, 66, 540, 270, 66, 540, 270, 270, 66, 540, 540, 540, 66, 270, 540, 66, 540, 270, 270, 540, 540, 66, 270, 540, 66, 270, 270, 66, 270, 66, 270, 540, 540, 270, 66, 540, 66, 540, 270, 270, 270, 270, 270, 66, 66, 540, 66, 540, 66, 270, 540, 270, 540, 270, 540, 270, 540, 66, 270, 270, 270, 270, 270, 270, 270, 270, 540, 66, 66, 66, 66, 66, 270, 66, 66, 270, 540, 540, 66, 66, 540, 66, 66, 66, 270, 66, 270, 540, 540, 270, 270, 66, 540, 270, 540, 66, 270, 270, 66, 66, 270, 66, 540, 540, 66, 540, 540, 66, 270, 540, 66, 66, 270, 270, 66, 66, 540, 540, 540, 540, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 540, 270, 270, 270, 540, 66, 270, 270, 540, 540, 66, 540, 540, 66, 540, 66, 66, 270, 66, 540, 540, 540, 270, 66, 540, 540, 270, 270, 540, 540, 66, 540, 540, 270, 66, 540, 270, 270, 540, 540, 540, 66, 540, 66, 540, 540, 66, 66, 540, 66, 270, 540, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 540, 66, 66, 66, 270, 66, 270, 270, 66, 540, 270, 540, 66, 540, 66, 270, 270, 270, 270, 66, 270, 540, 540, 66, 540, 540, 66, 540, 270, 540, 270, 270, 270, 66, 270, 66, 66, 540, 66, 270, 66, 66, 270, 540, 270, 540, 66, 540, 540, 270, 540, 270, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 112128 . Total input tokens: 25003147 . Total output tokens: 22451802
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.1769643570296466,
    "estimated_duration": 3600.0938448061925,
    "input_throughput": 2571.653239916696,
    "output_throughput": 2311.0864212618617,
    "total_throughput": 4882.739661178558,
    "itl": 83.0749649667319,
    "ttft": 28833.52286679444,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 15793,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 51.656967252896536,
    "arrivals": 37708,
    "finished_requests": 37411,
    "scheduler_time": 25.96584513317682
}
#Debug simulation 
Total elapsed time: 3.1770460926927626. Arrivals time: 0.0969808422960341 Scheduler time: 2.660570771433413 Scheduler overhead time: 0.05288743320852518 Adapter cache time: 0.2910265903919935 Engine time: 0.05081988126039505 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_384_slots_160_rate_0.05-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_384_slots_160_rate_0.05-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 540, 270, 66, 540, 540, 66, 270, 540, 540, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 66, 540, 66, 540, 270, 270, 270, 66, 66, 270, 66, 540, 66, 540, 270, 540, 270, 66, 270, 540, 270, 540, 66, 540, 540, 540, 540, 66, 270, 270, 270, 540, 270, 66, 270, 66, 540, 270, 540, 540, 270, 540, 540, 66, 66, 540, 270, 270, 66, 66, 66, 270, 66, 270, 66, 540, 66, 270, 540, 66, 540, 270, 66, 540, 540, 540, 540, 270, 66, 270, 540, 540, 270, 66, 66, 540, 270, 270, 66, 66, 540, 270, 540, 270, 540, 540, 270, 540, 540, 66, 270, 270, 270, 270, 66, 66, 540, 66, 540, 66, 66, 66, 270, 270, 540, 66, 66, 540, 66, 540, 270, 66, 540, 270, 270, 66, 540, 540, 540, 66, 270, 540, 66, 540, 270, 270, 540, 540, 66, 270, 540, 66, 270, 270, 66, 270, 66, 270, 540, 540, 270, 66, 540, 66, 540, 270, 270, 270, 270, 270, 66, 66, 540, 66, 540, 66, 270, 540, 270, 540, 270, 540, 270, 540, 66, 270, 270, 270, 270, 270, 270, 270, 270, 540, 66, 66, 66, 66, 66, 270, 66, 66, 270, 540, 540, 66, 66, 540, 66, 66, 66, 270, 66, 270, 540, 540, 270, 270, 66, 540, 270, 540, 66, 270, 270, 66, 66, 270, 66, 540, 540, 66, 540, 540, 66, 270, 540, 66, 66, 270, 270, 66, 66, 540, 540, 540, 540, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 540, 270, 270, 270, 540, 66, 270, 270, 540, 540, 66, 540, 540, 66, 540, 66, 66, 270, 66, 540, 540, 540, 270, 66, 540, 540, 270, 270, 540, 540, 66, 540, 540, 270, 66, 540, 270, 270, 540, 540, 540, 66, 540, 66, 540, 540, 66, 66, 540, 66, 270, 540, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 540, 66, 66, 66, 270, 66, 270, 270, 66, 540, 270, 540, 66, 540, 66, 270, 270, 270, 270, 66, 270, 540, 540, 66, 540, 540, 66, 540, 270, 540, 270, 270, 270, 66, 270, 66, 66, 540, 66, 270, 66, 66, 270, 540, 270, 540, 66, 540, 540, 270, 540, 270, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 112128 . Total input tokens: 25003147 . Total output tokens: 22451802
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 3.2144212522543967,
    "estimated_duration": 3600.040886236315,
    "input_throughput": 2571.6910703419912,
    "output_throughput": 2311.120418606781,
    "total_throughput": 4882.811488948772,
    "itl": 82.80508004984986,
    "ttft": 28723.030403243723,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 15814,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 49.538058544791134,
    "arrivals": 37708,
    "finished_requests": 37411,
    "scheduler_time": 25.93764577668288
}
#Debug simulation 
Total elapsed time: 3.2145209023728967. Arrivals time: 0.09417948266491294 Scheduler time: 2.6961275739595294 Scheduler overhead time: 0.05299323331564665 Adapter cache time: 0.2947352947667241 Engine time: 0.05151068326085806 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_384_slots_160_rate_0.05-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_384_slots_160_rate_0.05-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 540, 270, 66, 540, 540, 66, 270, 540, 540, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 66, 540, 66, 540, 270, 270, 270, 66, 66, 270, 66, 540, 66, 540, 270, 540, 270, 66, 270, 540, 270, 540, 66, 540, 540, 540, 540, 66, 270, 270, 270, 540, 270, 66, 270, 66, 540, 270, 540, 540, 270, 540, 540, 66, 66, 540, 270, 270, 66, 66, 66, 270, 66, 270, 66, 540, 66, 270, 540, 66, 540, 270, 66, 540, 540, 540, 540, 270, 66, 270, 540, 540, 270, 66, 66, 540, 270, 270, 66, 66, 540, 270, 540, 270, 540, 540, 270, 540, 540, 66, 270, 270, 270, 270, 66, 66, 540, 66, 540, 66, 66, 66, 270, 270, 540, 66, 66, 540, 66, 540, 270, 66, 540, 270, 270, 66, 540, 540, 540, 66, 270, 540, 66, 540, 270, 270, 540, 540, 66, 270, 540, 66, 270, 270, 66, 270, 66, 270, 540, 540, 270, 66, 540, 66, 540, 270, 270, 270, 270, 270, 66, 66, 540, 66, 540, 66, 270, 540, 270, 540, 270, 540, 270, 540, 66, 270, 270, 270, 270, 270, 270, 270, 270, 540, 66, 66, 66, 66, 66, 270, 66, 66, 270, 540, 540, 66, 66, 540, 66, 66, 66, 270, 66, 270, 540, 540, 270, 270, 66, 540, 270, 540, 66, 270, 270, 66, 66, 270, 66, 540, 540, 66, 540, 540, 66, 270, 540, 66, 66, 270, 270, 66, 66, 540, 540, 540, 540, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 540, 270, 270, 270, 540, 66, 270, 270, 540, 540, 66, 540, 540, 66, 540, 66, 66, 270, 66, 540, 540, 540, 270, 66, 540, 540, 270, 270, 540, 540, 66, 540, 540, 270, 66, 540, 270, 270, 540, 540, 540, 66, 540, 66, 540, 540, 66, 66, 540, 66, 270, 540, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 540, 66, 66, 66, 270, 66, 270, 270, 66, 540, 270, 540, 66, 540, 66, 270, 270, 270, 270, 66, 270, 540, 540, 66, 540, 540, 66, 540, 270, 540, 270, 270, 270, 66, 270, 66, 66, 540, 66, 270, 66, 66, 270, 540, 270, 540, 66, 540, 540, 270, 540, 270, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 112128 . Total input tokens: 25003147 . Total output tokens: 22451802
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 3.2386606889776886,
    "estimated_duration": 3600.056917230491,
    "input_throughput": 2571.672952082733,
    "output_throughput": 2310.980684827695,
    "total_throughput": 4882.653636910428,
    "itl": 83.14964662117757,
    "ttft": 28933.805018693532,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 15777,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 52.2541767000111,
    "arrivals": 37708,
    "finished_requests": 37409,
    "scheduler_time": 25.97360076833078
}
#Debug simulation 
Total elapsed time: 3.238742466084659. Arrivals time: 0.09454654389992356 Scheduler time: 2.7193172345869243 Scheduler overhead time: 0.053148761857301 Adapter cache time: 0.29504784289747477 Engine time: 0.051745498552918434 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_384_slots_160_rate_0.05-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_384_slots_160_rate_0.05-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 540, 270, 66, 540, 540, 66, 270, 540, 540, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 66, 540, 66, 540, 270, 270, 270, 66, 66, 270, 66, 540, 66, 540, 270, 540, 270, 66, 270, 540, 270, 540, 66, 540, 540, 540, 540, 66, 270, 270, 270, 540, 270, 66, 270, 66, 540, 270, 540, 540, 270, 540, 540, 66, 66, 540, 270, 270, 66, 66, 66, 270, 66, 270, 66, 540, 66, 270, 540, 66, 540, 270, 66, 540, 540, 540, 540, 270, 66, 270, 540, 540, 270, 66, 66, 540, 270, 270, 66, 66, 540, 270, 540, 270, 540, 540, 270, 540, 540, 66, 270, 270, 270, 270, 66, 66, 540, 66, 540, 66, 66, 66, 270, 270, 540, 66, 66, 540, 66, 540, 270, 66, 540, 270, 270, 66, 540, 540, 540, 66, 270, 540, 66, 540, 270, 270, 540, 540, 66, 270, 540, 66, 270, 270, 66, 270, 66, 270, 540, 540, 270, 66, 540, 66, 540, 270, 270, 270, 270, 270, 66, 66, 540, 66, 540, 66, 270, 540, 270, 540, 270, 540, 270, 540, 66, 270, 270, 270, 270, 270, 270, 270, 270, 540, 66, 66, 66, 66, 66, 270, 66, 66, 270, 540, 540, 66, 66, 540, 66, 66, 66, 270, 66, 270, 540, 540, 270, 270, 66, 540, 270, 540, 66, 270, 270, 66, 66, 270, 66, 540, 540, 66, 540, 540, 66, 270, 540, 66, 66, 270, 270, 66, 66, 540, 540, 540, 540, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 540, 270, 270, 270, 540, 66, 270, 270, 540, 540, 66, 540, 540, 66, 540, 66, 66, 270, 66, 540, 540, 540, 270, 66, 540, 540, 270, 270, 540, 540, 66, 540, 540, 270, 66, 540, 270, 270, 540, 540, 540, 66, 540, 66, 540, 540, 66, 66, 540, 66, 270, 540, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 540, 66, 66, 66, 270, 66, 270, 270, 66, 540, 270, 540, 66, 540, 66, 270, 270, 270, 270, 66, 270, 540, 540, 66, 540, 540, 66, 540, 270, 540, 270, 270, 270, 66, 270, 66, 66, 540, 66, 270, 66, 66, 270, 540, 270, 540, 66, 540, 540, 270, 540, 270, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 112128 . Total input tokens: 25003147 . Total output tokens: 22451802
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.2564631598070264,
    "estimated_duration": 3600.0260555850577,
    "input_throughput": 2571.7016646690367,
    "output_throughput": 2311.129939488134,
    "total_throughput": 4882.831604157171,
    "itl": 82.5301953522355,
    "ttft": 28706.846801981847,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 15837,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 47.35342652037541,
    "arrivals": 37708,
    "finished_requests": 37411,
    "scheduler_time": 25.909436819765798
}
#Debug simulation 
Total elapsed time: 3.2565617277286947. Arrivals time: 0.09437261754646897 Scheduler time: 2.732437188271433 Scheduler overhead time: 0.053543440997600555 Adapter cache time: 0.29886428266763687 Engine time: 0.05218893103301525 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_384_slots_160_rate_0.05-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_384_slots_160_rate_0.05-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 540, 270, 66, 540, 540, 66, 270, 540, 540, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 66, 540, 66, 540, 270, 270, 270, 66, 66, 270, 66, 540, 66, 540, 270, 540, 270, 66, 270, 540, 270, 540, 66, 540, 540, 540, 540, 66, 270, 270, 270, 540, 270, 66, 270, 66, 540, 270, 540, 540, 270, 540, 540, 66, 66, 540, 270, 270, 66, 66, 66, 270, 66, 270, 66, 540, 66, 270, 540, 66, 540, 270, 66, 540, 540, 540, 540, 270, 66, 270, 540, 540, 270, 66, 66, 540, 270, 270, 66, 66, 540, 270, 540, 270, 540, 540, 270, 540, 540, 66, 270, 270, 270, 270, 66, 66, 540, 66, 540, 66, 66, 66, 270, 270, 540, 66, 66, 540, 66, 540, 270, 66, 540, 270, 270, 66, 540, 540, 540, 66, 270, 540, 66, 540, 270, 270, 540, 540, 66, 270, 540, 66, 270, 270, 66, 270, 66, 270, 540, 540, 270, 66, 540, 66, 540, 270, 270, 270, 270, 270, 66, 66, 540, 66, 540, 66, 270, 540, 270, 540, 270, 540, 270, 540, 66, 270, 270, 270, 270, 270, 270, 270, 270, 540, 66, 66, 66, 66, 66, 270, 66, 66, 270, 540, 540, 66, 66, 540, 66, 66, 66, 270, 66, 270, 540, 540, 270, 270, 66, 540, 270, 540, 66, 270, 270, 66, 66, 270, 66, 540, 540, 66, 540, 540, 66, 270, 540, 66, 66, 270, 270, 66, 66, 540, 540, 540, 540, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 540, 270, 270, 270, 540, 66, 270, 270, 540, 540, 66, 540, 540, 66, 540, 66, 66, 270, 66, 540, 540, 540, 270, 66, 540, 540, 270, 270, 540, 540, 66, 540, 540, 270, 66, 540, 270, 270, 540, 540, 540, 66, 540, 66, 540, 540, 66, 66, 540, 66, 270, 540, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 540, 66, 66, 66, 270, 66, 270, 270, 66, 540, 270, 540, 66, 540, 66, 270, 270, 270, 270, 66, 270, 540, 540, 66, 540, 540, 66, 540, 270, 540, 270, 270, 270, 66, 270, 66, 66, 540, 66, 270, 66, 66, 270, 540, 270, 540, 66, 540, 540, 270, 540, 270, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 112128 . Total input tokens: 25003147 . Total output tokens: 22451802
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.2215896830894053,
    "estimated_duration": 3600.0363051959944,
    "input_throughput": 2571.556010876393,
    "output_throughput": 2310.992805264795,
    "total_throughput": 4882.548816141189,
    "itl": 83.23452720931192,
    "ttft": 29128.87904240286,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 15771,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 52.92520639192566,
    "arrivals": 37708,
    "finished_requests": 37407,
    "scheduler_time": 25.981862406467688
}
#Debug simulation 
Total elapsed time: 3.221666721161455. Arrivals time: 0.09196005808189511 Scheduler time: 2.706852705683559 Scheduler overhead time: 0.052257862873375416 Adapter cache time: 0.29462441289797425 Engine time: 0.051076865289360285 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_384_slots_160_rate_0.05-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_384_slots_160_rate_0.05-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 540, 270, 33, 540, 540, 33, 270, 540, 540, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 33, 540, 33, 540, 270, 270, 270, 33, 33, 270, 33, 540, 33, 540, 270, 540, 270, 33, 270, 540, 270, 540, 33, 540, 540, 540, 540, 33, 270, 270, 270, 540, 270, 33, 270, 33, 540, 270, 540, 540, 270, 540, 540, 33, 33, 540, 270, 270, 33, 33, 33, 270, 33, 270, 33, 540, 33, 270, 540, 33, 540, 270, 33, 540, 540, 540, 540, 270, 33, 270, 540, 540, 270, 33, 33, 540, 270, 270, 33, 33, 540, 270, 540, 270, 540, 540, 270, 540, 540, 33, 270, 270, 270, 270, 33, 33, 540, 33, 540, 33, 33, 33, 270, 270, 540, 33, 33, 540, 33, 540, 270, 33, 540, 270, 270, 33, 540, 540, 540, 33, 270, 540, 33, 540, 270, 270, 540, 540, 33, 270, 540, 33, 270, 270, 33, 270, 33, 270, 540, 540, 270, 33, 540, 33, 540, 270, 270, 270, 270, 270, 33, 33, 540, 33, 540, 33, 270, 540, 270, 540, 270, 540, 270, 540, 33, 270, 270, 270, 270, 270, 270, 270, 270, 540, 33, 33, 33, 33, 33, 270, 33, 33, 270, 540, 540, 33, 33, 540, 33, 33, 33, 270, 33, 270, 540, 540, 270, 270, 33, 540, 270, 540, 33, 270, 270, 33, 33, 270, 33, 540, 540, 33, 540, 540, 33, 270, 540, 33, 33, 270, 270, 33, 33, 540, 540, 540, 540, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 540, 270, 270, 270, 540, 33, 270, 270, 540, 540, 33, 540, 540, 33, 540, 33, 33, 270, 33, 540, 540, 540, 270, 33, 540, 540, 270, 270, 540, 540, 33, 540, 540, 270, 33, 540, 270, 270, 540, 540, 540, 33, 540, 33, 540, 540, 33, 33, 540, 33, 270, 540, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 540, 33, 33, 33, 270, 33, 270, 270, 33, 540, 270, 540, 33, 540, 33, 270, 270, 270, 270, 33, 270, 540, 540, 33, 540, 540, 33, 540, 270, 540, 270, 270, 270, 33, 270, 33, 33, 540, 33, 270, 33, 33, 270, 540, 270, 540, 33, 540, 540, 270, 540, 270, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 107904 . Total input tokens: 24035451 . Total output tokens: 21614343
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.0906799831427634,
    "estimated_duration": 3600.014948578521,
    "input_throughput": 2479.951646735578,
    "output_throughput": 2184.496206913034,
    "total_throughput": 4664.447853648612,
    "itl": 58.837702454028125,
    "ttft": 9056.634268261065,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 14200,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 43.45892596383892,
    "arrivals": 36171,
    "finished_requests": 36078,
    "scheduler_time": 20.615368091043457
}
#Debug simulation 
Total elapsed time: 3.0907606803812087. Arrivals time: 0.09288058057427406 Scheduler time: 2.519967110361904 Scheduler overhead time: 0.06777304131537676 Adapter cache time: 0.3117254008539021 Engine time: 0.0662154951132834 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_384_slots_160_rate_0.05-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_384_slots_160_rate_0.05-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 540, 270, 33, 540, 540, 33, 270, 540, 540, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 33, 540, 33, 540, 270, 270, 270, 33, 33, 270, 33, 540, 33, 540, 270, 540, 270, 33, 270, 540, 270, 540, 33, 540, 540, 540, 540, 33, 270, 270, 270, 540, 270, 33, 270, 33, 540, 270, 540, 540, 270, 540, 540, 33, 33, 540, 270, 270, 33, 33, 33, 270, 33, 270, 33, 540, 33, 270, 540, 33, 540, 270, 33, 540, 540, 540, 540, 270, 33, 270, 540, 540, 270, 33, 33, 540, 270, 270, 33, 33, 540, 270, 540, 270, 540, 540, 270, 540, 540, 33, 270, 270, 270, 270, 33, 33, 540, 33, 540, 33, 33, 33, 270, 270, 540, 33, 33, 540, 33, 540, 270, 33, 540, 270, 270, 33, 540, 540, 540, 33, 270, 540, 33, 540, 270, 270, 540, 540, 33, 270, 540, 33, 270, 270, 33, 270, 33, 270, 540, 540, 270, 33, 540, 33, 540, 270, 270, 270, 270, 270, 33, 33, 540, 33, 540, 33, 270, 540, 270, 540, 270, 540, 270, 540, 33, 270, 270, 270, 270, 270, 270, 270, 270, 540, 33, 33, 33, 33, 33, 270, 33, 33, 270, 540, 540, 33, 33, 540, 33, 33, 33, 270, 33, 270, 540, 540, 270, 270, 33, 540, 270, 540, 33, 270, 270, 33, 33, 270, 33, 540, 540, 33, 540, 540, 33, 270, 540, 33, 33, 270, 270, 33, 33, 540, 540, 540, 540, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 540, 270, 270, 270, 540, 33, 270, 270, 540, 540, 33, 540, 540, 33, 540, 33, 33, 270, 33, 540, 540, 540, 270, 33, 540, 540, 270, 270, 540, 540, 33, 540, 540, 270, 33, 540, 270, 270, 540, 540, 540, 33, 540, 33, 540, 540, 33, 33, 540, 33, 270, 540, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 540, 33, 33, 33, 270, 33, 270, 270, 33, 540, 270, 540, 33, 540, 33, 270, 270, 270, 270, 33, 270, 540, 540, 33, 540, 540, 33, 540, 270, 540, 270, 270, 270, 33, 270, 33, 33, 540, 33, 270, 33, 33, 270, 540, 270, 540, 33, 540, 540, 270, 540, 270, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 107904 . Total input tokens: 24035451 . Total output tokens: 21614343
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.112301322631538,
    "estimated_duration": 3600.046649040351,
    "input_throughput": 2479.9298093484044,
    "output_throughput": 2184.4769711793406,
    "total_throughput": 4664.406780527745,
    "itl": 59.05208603134929,
    "ttft": 9354.925064206585,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 14185,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 46.327389393214645,
    "arrivals": 36171,
    "finished_requests": 36078,
    "scheduler_time": 20.654999199504037
}
#Debug simulation 
Total elapsed time: 3.112377902958542. Arrivals time: 0.09340878715738654 Scheduler time: 2.5425547817721963 Scheduler overhead time: 0.06770887458696961 Adapter cache time: 0.3094085231423378 Engine time: 0.0671645519323647 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-32/adapters_384_slots_160_rate_0.05-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-32/adapters_384_slots_160_rate_0.05-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 540, 270, 33, 540, 540, 33, 270, 540, 540, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 33, 540, 33, 540, 270, 270, 270, 33, 33, 270, 33, 540, 33, 540, 270, 540, 270, 33, 270, 540, 270, 540, 33, 540, 540, 540, 540, 33, 270, 270, 270, 540, 270, 33, 270, 33, 540, 270, 540, 540, 270, 540, 540, 33, 33, 540, 270, 270, 33, 33, 33, 270, 33, 270, 33, 540, 33, 270, 540, 33, 540, 270, 33, 540, 540, 540, 540, 270, 33, 270, 540, 540, 270, 33, 33, 540, 270, 270, 33, 33, 540, 270, 540, 270, 540, 540, 270, 540, 540, 33, 270, 270, 270, 270, 33, 33, 540, 33, 540, 33, 33, 33, 270, 270, 540, 33, 33, 540, 33, 540, 270, 33, 540, 270, 270, 33, 540, 540, 540, 33, 270, 540, 33, 540, 270, 270, 540, 540, 33, 270, 540, 33, 270, 270, 33, 270, 33, 270, 540, 540, 270, 33, 540, 33, 540, 270, 270, 270, 270, 270, 33, 33, 540, 33, 540, 33, 270, 540, 270, 540, 270, 540, 270, 540, 33, 270, 270, 270, 270, 270, 270, 270, 270, 540, 33, 33, 33, 33, 33, 270, 33, 33, 270, 540, 540, 33, 33, 540, 33, 33, 33, 270, 33, 270, 540, 540, 270, 270, 33, 540, 270, 540, 33, 270, 270, 33, 33, 270, 33, 540, 540, 33, 540, 540, 33, 270, 540, 33, 33, 270, 270, 33, 33, 540, 540, 540, 540, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 540, 270, 270, 270, 540, 33, 270, 270, 540, 540, 33, 540, 540, 33, 540, 33, 33, 270, 33, 540, 540, 540, 270, 33, 540, 540, 270, 270, 540, 540, 33, 540, 540, 270, 33, 540, 270, 270, 540, 540, 540, 33, 540, 33, 540, 540, 33, 33, 540, 33, 270, 540, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 540, 33, 33, 33, 270, 33, 270, 270, 33, 540, 270, 540, 33, 540, 33, 270, 270, 270, 270, 33, 270, 540, 540, 33, 540, 540, 33, 540, 270, 540, 270, 270, 270, 33, 270, 33, 33, 540, 33, 270, 33, 33, 270, 540, 270, 540, 33, 540, 540, 270, 540, 270, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 107904 . Total input tokens: 24035451 . Total output tokens: 21614343
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.0924190590158105,
    "estimated_duration": 3600.0421550423994,
    "input_throughput": 2479.9329050897886,
    "output_throughput": 2184.479698101585,
    "total_throughput": 4664.412603191374,
    "itl": 59.05482903445212,
    "ttft": 9156.611607298348,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 14186,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 46.40551489126877,
    "arrivals": 36171,
    "finished_requests": 36078,
    "scheduler_time": 20.65591736129013
}
#Debug simulation 
Total elapsed time: 3.092500881291926. Arrivals time: 0.09297360992059112 Scheduler time: 2.5218672431074083 Scheduler overhead time: 0.0674726814031601 Adapter cache time: 0.3121619331650436 Engine time: 0.0659296871162951 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_384_slots_160_rate_0.05-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_384_slots_160_rate_0.05-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 540, 270, 33, 540, 540, 33, 270, 540, 540, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 33, 540, 33, 540, 270, 270, 270, 33, 33, 270, 33, 540, 33, 540, 270, 540, 270, 33, 270, 540, 270, 540, 33, 540, 540, 540, 540, 33, 270, 270, 270, 540, 270, 33, 270, 33, 540, 270, 540, 540, 270, 540, 540, 33, 33, 540, 270, 270, 33, 33, 33, 270, 33, 270, 33, 540, 33, 270, 540, 33, 540, 270, 33, 540, 540, 540, 540, 270, 33, 270, 540, 540, 270, 33, 33, 540, 270, 270, 33, 33, 540, 270, 540, 270, 540, 540, 270, 540, 540, 33, 270, 270, 270, 270, 33, 33, 540, 33, 540, 33, 33, 33, 270, 270, 540, 33, 33, 540, 33, 540, 270, 33, 540, 270, 270, 33, 540, 540, 540, 33, 270, 540, 33, 540, 270, 270, 540, 540, 33, 270, 540, 33, 270, 270, 33, 270, 33, 270, 540, 540, 270, 33, 540, 33, 540, 270, 270, 270, 270, 270, 33, 33, 540, 33, 540, 33, 270, 540, 270, 540, 270, 540, 270, 540, 33, 270, 270, 270, 270, 270, 270, 270, 270, 540, 33, 33, 33, 33, 33, 270, 33, 33, 270, 540, 540, 33, 33, 540, 33, 33, 33, 270, 33, 270, 540, 540, 270, 270, 33, 540, 270, 540, 33, 270, 270, 33, 33, 270, 33, 540, 540, 33, 540, 540, 33, 270, 540, 33, 33, 270, 270, 33, 33, 540, 540, 540, 540, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 540, 270, 270, 270, 540, 33, 270, 270, 540, 540, 33, 540, 540, 33, 540, 33, 33, 270, 33, 540, 540, 540, 270, 33, 540, 540, 270, 270, 540, 540, 33, 540, 540, 270, 33, 540, 270, 270, 540, 540, 540, 33, 540, 33, 540, 540, 33, 33, 540, 33, 270, 540, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 540, 33, 33, 33, 270, 33, 270, 270, 33, 540, 270, 540, 33, 540, 33, 270, 270, 270, 270, 33, 270, 540, 540, 33, 540, 540, 33, 540, 270, 540, 270, 270, 270, 33, 270, 33, 33, 540, 33, 270, 33, 33, 270, 540, 270, 540, 33, 540, 540, 270, 540, 270, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 107904 . Total input tokens: 24035451 . Total output tokens: 21614343
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 3.0662057818844914,
    "estimated_duration": 3600.0482853395556,
    "input_throughput": 2479.9286821670853,
    "output_throughput": 2184.475978287677,
    "total_throughput": 4664.404660454763,
    "itl": 58.91269977558653,
    "ttft": 9354.824718187177,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 14198,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 44.473237936714256,
    "arrivals": 36171,
    "finished_requests": 36078,
    "scheduler_time": 20.629559429662372
}
#Debug simulation 
Total elapsed time: 3.0662893378175795. Arrivals time: 0.09414201928302646 Scheduler time: 2.4970204876735806 Scheduler overhead time: 0.06762526603415608 Adapter cache time: 0.30906743463128805 Engine time: 0.066152005456388 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-32/adapters_384_slots_160_rate_0.05-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-32/adapters_384_slots_160_rate_0.05-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 540, 270, 33, 540, 540, 33, 270, 540, 540, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 33, 540, 33, 540, 270, 270, 270, 33, 33, 270, 33, 540, 33, 540, 270, 540, 270, 33, 270, 540, 270, 540, 33, 540, 540, 540, 540, 33, 270, 270, 270, 540, 270, 33, 270, 33, 540, 270, 540, 540, 270, 540, 540, 33, 33, 540, 270, 270, 33, 33, 33, 270, 33, 270, 33, 540, 33, 270, 540, 33, 540, 270, 33, 540, 540, 540, 540, 270, 33, 270, 540, 540, 270, 33, 33, 540, 270, 270, 33, 33, 540, 270, 540, 270, 540, 540, 270, 540, 540, 33, 270, 270, 270, 270, 33, 33, 540, 33, 540, 33, 33, 33, 270, 270, 540, 33, 33, 540, 33, 540, 270, 33, 540, 270, 270, 33, 540, 540, 540, 33, 270, 540, 33, 540, 270, 270, 540, 540, 33, 270, 540, 33, 270, 270, 33, 270, 33, 270, 540, 540, 270, 33, 540, 33, 540, 270, 270, 270, 270, 270, 33, 33, 540, 33, 540, 33, 270, 540, 270, 540, 270, 540, 270, 540, 33, 270, 270, 270, 270, 270, 270, 270, 270, 540, 33, 33, 33, 33, 33, 270, 33, 33, 270, 540, 540, 33, 33, 540, 33, 33, 33, 270, 33, 270, 540, 540, 270, 270, 33, 540, 270, 540, 33, 270, 270, 33, 33, 270, 33, 540, 540, 33, 540, 540, 33, 270, 540, 33, 33, 270, 270, 33, 33, 540, 540, 540, 540, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 540, 270, 270, 270, 540, 33, 270, 270, 540, 540, 33, 540, 540, 33, 540, 33, 33, 270, 33, 540, 540, 540, 270, 33, 540, 540, 270, 270, 540, 540, 33, 540, 540, 270, 33, 540, 270, 270, 540, 540, 540, 33, 540, 33, 540, 540, 33, 33, 540, 33, 270, 540, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 540, 33, 33, 33, 270, 33, 270, 270, 33, 540, 270, 540, 33, 540, 33, 270, 270, 270, 270, 33, 270, 540, 540, 33, 540, 540, 33, 540, 270, 540, 270, 270, 270, 33, 270, 33, 33, 540, 33, 270, 33, 33, 270, 540, 270, 540, 33, 540, 540, 270, 540, 270, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 107904 . Total input tokens: 24035451 . Total output tokens: 21614343
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 3.1164282020181417,
    "estimated_duration": 3600.0405629732204,
    "input_throughput": 2479.934001806527,
    "output_throughput": 2184.4806641581445,
    "total_throughput": 4664.414665964671,
    "itl": 59.09966797837854,
    "ttft": 9156.516486004119,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 14191,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 47.00591629194634,
    "arrivals": 36171,
    "finished_requests": 36078,
    "scheduler_time": 20.663968970103582
}
#Debug simulation 
Total elapsed time: 3.1165052708238363. Arrivals time: 0.09372919937595725 Scheduler time: 2.546188878826797 Scheduler overhead time: 0.06745113944634795 Adapter cache time: 0.31054095458239317 Engine time: 0.06640032585710287 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_384_slots_160_rate_0.05-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_384_slots_160_rate_0.05-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 540, 270, 33, 540, 540, 33, 270, 540, 540, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 33, 540, 33, 540, 270, 270, 270, 33, 33, 270, 33, 540, 33, 540, 270, 540, 270, 33, 270, 540, 270, 540, 33, 540, 540, 540, 540, 33, 270, 270, 270, 540, 270, 33, 270, 33, 540, 270, 540, 540, 270, 540, 540, 33, 33, 540, 270, 270, 33, 33, 33, 270, 33, 270, 33, 540, 33, 270, 540, 33, 540, 270, 33, 540, 540, 540, 540, 270, 33, 270, 540, 540, 270, 33, 33, 540, 270, 270, 33, 33, 540, 270, 540, 270, 540, 540, 270, 540, 540, 33, 270, 270, 270, 270, 33, 33, 540, 33, 540, 33, 33, 33, 270, 270, 540, 33, 33, 540, 33, 540, 270, 33, 540, 270, 270, 33, 540, 540, 540, 33, 270, 540, 33, 540, 270, 270, 540, 540, 33, 270, 540, 33, 270, 270, 33, 270, 33, 270, 540, 540, 270, 33, 540, 33, 540, 270, 270, 270, 270, 270, 33, 33, 540, 33, 540, 33, 270, 540, 270, 540, 270, 540, 270, 540, 33, 270, 270, 270, 270, 270, 270, 270, 270, 540, 33, 33, 33, 33, 33, 270, 33, 33, 270, 540, 540, 33, 33, 540, 33, 33, 33, 270, 33, 270, 540, 540, 270, 270, 33, 540, 270, 540, 33, 270, 270, 33, 33, 270, 33, 540, 540, 33, 540, 540, 33, 270, 540, 33, 33, 270, 270, 33, 33, 540, 540, 540, 540, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 540, 270, 270, 270, 540, 33, 270, 270, 540, 540, 33, 540, 540, 33, 540, 33, 33, 270, 33, 540, 540, 540, 270, 33, 540, 540, 270, 270, 540, 540, 33, 540, 540, 270, 33, 540, 270, 270, 540, 540, 540, 33, 540, 33, 540, 540, 33, 33, 540, 33, 270, 540, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 540, 33, 33, 33, 270, 33, 270, 270, 33, 540, 270, 540, 33, 540, 33, 270, 270, 270, 270, 33, 270, 540, 540, 33, 540, 540, 33, 540, 270, 540, 270, 270, 270, 33, 270, 33, 33, 540, 33, 270, 33, 33, 270, 540, 270, 540, 33, 540, 540, 270, 540, 270, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 107904 . Total input tokens: 24035451 . Total output tokens: 21614343
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.0820142361335456,
    "estimated_duration": 3600.041070184461,
    "input_throughput": 2479.9336524076234,
    "output_throughput": 2184.480356385781,
    "total_throughput": 4664.414008793405,
    "itl": 58.76356580968963,
    "ttft": 9155.939605881684,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 14197,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 42.449744036731644,
    "arrivals": 36171,
    "finished_requests": 36078,
    "scheduler_time": 20.60187254928324
}
#Debug simulation 
Total elapsed time: 3.0820970349013805. Arrivals time: 0.09290937893092632 Scheduler time: 2.504133894108236 Scheduler overhead time: 0.07206497760489583 Adapter cache time: 0.31267440784722567 Engine time: 0.06733521446585655 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-32/adapters_384_slots_160_rate_0.05-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-32/adapters_384_slots_160_rate_0.05-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 540, 270, 33, 540, 540, 33, 270, 540, 540, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 33, 540, 33, 540, 270, 270, 270, 33, 33, 270, 33, 540, 33, 540, 270, 540, 270, 33, 270, 540, 270, 540, 33, 540, 540, 540, 540, 33, 270, 270, 270, 540, 270, 33, 270, 33, 540, 270, 540, 540, 270, 540, 540, 33, 33, 540, 270, 270, 33, 33, 33, 270, 33, 270, 33, 540, 33, 270, 540, 33, 540, 270, 33, 540, 540, 540, 540, 270, 33, 270, 540, 540, 270, 33, 33, 540, 270, 270, 33, 33, 540, 270, 540, 270, 540, 540, 270, 540, 540, 33, 270, 270, 270, 270, 33, 33, 540, 33, 540, 33, 33, 33, 270, 270, 540, 33, 33, 540, 33, 540, 270, 33, 540, 270, 270, 33, 540, 540, 540, 33, 270, 540, 33, 540, 270, 270, 540, 540, 33, 270, 540, 33, 270, 270, 33, 270, 33, 270, 540, 540, 270, 33, 540, 33, 540, 270, 270, 270, 270, 270, 33, 33, 540, 33, 540, 33, 270, 540, 270, 540, 270, 540, 270, 540, 33, 270, 270, 270, 270, 270, 270, 270, 270, 540, 33, 33, 33, 33, 33, 270, 33, 33, 270, 540, 540, 33, 33, 540, 33, 33, 33, 270, 33, 270, 540, 540, 270, 270, 33, 540, 270, 540, 33, 270, 270, 33, 33, 270, 33, 540, 540, 33, 540, 540, 33, 270, 540, 33, 33, 270, 270, 33, 33, 540, 540, 540, 540, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 540, 270, 270, 270, 540, 33, 270, 270, 540, 540, 33, 540, 540, 33, 540, 33, 33, 270, 33, 540, 540, 540, 270, 33, 540, 540, 270, 270, 540, 540, 33, 540, 540, 270, 33, 540, 270, 270, 540, 540, 540, 33, 540, 33, 540, 540, 33, 33, 540, 33, 270, 540, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 540, 33, 33, 33, 270, 33, 270, 270, 33, 540, 270, 540, 33, 540, 33, 270, 270, 270, 270, 33, 270, 540, 540, 33, 540, 540, 33, 540, 270, 540, 270, 270, 270, 33, 270, 33, 33, 540, 33, 270, 33, 33, 270, 540, 270, 540, 33, 540, 540, 270, 540, 270, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 107904 . Total input tokens: 24035451 . Total output tokens: 21614343
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.1044106581248343,
    "estimated_duration": 3600.017829302545,
    "input_throughput": 2479.949662285326,
    "output_throughput": 2184.4944588853846,
    "total_throughput": 4664.444121170711,
    "itl": 59.142786142135364,
    "ttft": 9057.452702142116,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 14181,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 47.59430406201735,
    "arrivals": 36171,
    "finished_requests": 36078,
    "scheduler_time": 20.67206423781957
}
#Debug simulation 
Total elapsed time: 3.1044901702553034. Arrivals time: 0.09343548398464918 Scheduler time: 2.5342931197956204 Scheduler overhead time: 0.06759827444329858 Adapter cache time: 0.31048391992226243 Engine time: 0.06661752890795469 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_384_slots_160_rate_0.05-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_384_slots_160_rate_0.05-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 540, 135, 66, 540, 540, 66, 135, 540, 540, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 66, 540, 66, 540, 135, 135, 135, 66, 66, 135, 66, 540, 66, 540, 135, 540, 135, 66, 135, 540, 135, 540, 66, 540, 540, 540, 540, 66, 135, 135, 135, 540, 135, 66, 135, 66, 540, 135, 540, 540, 135, 540, 540, 66, 66, 540, 135, 135, 66, 66, 66, 135, 66, 135, 66, 540, 66, 135, 540, 66, 540, 135, 66, 540, 540, 540, 540, 135, 66, 135, 540, 540, 135, 66, 66, 540, 135, 135, 66, 66, 540, 135, 540, 135, 540, 540, 135, 540, 540, 66, 135, 135, 135, 135, 66, 66, 540, 66, 540, 66, 66, 66, 135, 135, 540, 66, 66, 540, 66, 540, 135, 66, 540, 135, 135, 66, 540, 540, 540, 66, 135, 540, 66, 540, 135, 135, 540, 540, 66, 135, 540, 66, 135, 135, 66, 135, 66, 135, 540, 540, 135, 66, 540, 66, 540, 135, 135, 135, 135, 135, 66, 66, 540, 66, 540, 66, 135, 540, 135, 540, 135, 540, 135, 540, 66, 135, 135, 135, 135, 135, 135, 135, 135, 540, 66, 66, 66, 66, 66, 135, 66, 66, 135, 540, 540, 66, 66, 540, 66, 66, 66, 135, 66, 135, 540, 540, 135, 135, 66, 540, 135, 540, 66, 135, 135, 66, 66, 135, 66, 540, 540, 66, 540, 540, 66, 135, 540, 66, 66, 135, 135, 66, 66, 540, 540, 540, 540, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 540, 135, 135, 135, 540, 66, 135, 135, 540, 540, 66, 540, 540, 66, 540, 66, 66, 135, 66, 540, 540, 540, 135, 66, 540, 540, 135, 135, 540, 540, 66, 540, 540, 135, 66, 540, 135, 135, 540, 540, 540, 66, 540, 66, 540, 540, 66, 66, 540, 66, 135, 540, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 540, 66, 66, 66, 135, 66, 135, 135, 66, 540, 135, 540, 66, 540, 66, 135, 135, 135, 135, 66, 135, 540, 540, 66, 540, 540, 66, 540, 135, 540, 135, 135, 135, 66, 135, 66, 66, 540, 66, 135, 66, 66, 135, 540, 135, 540, 66, 540, 540, 135, 540, 135, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 94848 . Total input tokens: 21112697 . Total output tokens: 18991968
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 2.8095702747814357,
    "estimated_duration": 3599.748021955947,
    "input_throughput": 2206.008573812665,
    "output_throughput": 1937.341713215433,
    "total_throughput": 4143.350287028098,
    "itl": 42.54048165612123,
    "ttft": 8557.954676355292,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11674,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 35.72813392267125,
    "arrivals": 31815,
    "finished_requests": 31740,
    "scheduler_time": 12.861420585122135
}
#Debug simulation 
Total elapsed time: 2.8096461165696383. Arrivals time: 0.0835480303503573 Scheduler time: 2.2275044745765626 Scheduler overhead time: 0.08457264304161072 Adapter cache time: 0.29145799158141017 Engine time: 0.08187384624034166 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_384_slots_160_rate_0.05-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_384_slots_160_rate_0.05-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 540, 135, 66, 540, 540, 66, 135, 540, 540, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 66, 540, 66, 540, 135, 135, 135, 66, 66, 135, 66, 540, 66, 540, 135, 540, 135, 66, 135, 540, 135, 540, 66, 540, 540, 540, 540, 66, 135, 135, 135, 540, 135, 66, 135, 66, 540, 135, 540, 540, 135, 540, 540, 66, 66, 540, 135, 135, 66, 66, 66, 135, 66, 135, 66, 540, 66, 135, 540, 66, 540, 135, 66, 540, 540, 540, 540, 135, 66, 135, 540, 540, 135, 66, 66, 540, 135, 135, 66, 66, 540, 135, 540, 135, 540, 540, 135, 540, 540, 66, 135, 135, 135, 135, 66, 66, 540, 66, 540, 66, 66, 66, 135, 135, 540, 66, 66, 540, 66, 540, 135, 66, 540, 135, 135, 66, 540, 540, 540, 66, 135, 540, 66, 540, 135, 135, 540, 540, 66, 135, 540, 66, 135, 135, 66, 135, 66, 135, 540, 540, 135, 66, 540, 66, 540, 135, 135, 135, 135, 135, 66, 66, 540, 66, 540, 66, 135, 540, 135, 540, 135, 540, 135, 540, 66, 135, 135, 135, 135, 135, 135, 135, 135, 540, 66, 66, 66, 66, 66, 135, 66, 66, 135, 540, 540, 66, 66, 540, 66, 66, 66, 135, 66, 135, 540, 540, 135, 135, 66, 540, 135, 540, 66, 135, 135, 66, 66, 135, 66, 540, 540, 66, 540, 540, 66, 135, 540, 66, 66, 135, 135, 66, 66, 540, 540, 540, 540, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 540, 135, 135, 135, 540, 66, 135, 135, 540, 540, 66, 540, 540, 66, 540, 66, 66, 135, 66, 540, 540, 540, 135, 66, 540, 540, 135, 135, 540, 540, 66, 540, 540, 135, 66, 540, 135, 135, 540, 540, 540, 66, 540, 66, 540, 540, 66, 66, 540, 66, 135, 540, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 540, 66, 66, 66, 135, 66, 135, 135, 66, 540, 135, 540, 66, 540, 66, 135, 135, 135, 135, 66, 135, 540, 540, 66, 540, 540, 66, 540, 135, 540, 135, 135, 135, 66, 135, 66, 66, 540, 66, 135, 66, 66, 135, 540, 135, 540, 66, 540, 540, 135, 540, 135, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 94848 . Total input tokens: 21112697 . Total output tokens: 18991968
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 2.8111631092615426,
    "estimated_duration": 3599.7761159032943,
    "input_throughput": 2205.991357328438,
    "output_throughput": 1937.3265935040029,
    "total_throughput": 4143.317950832441,
    "itl": 42.248201569629494,
    "ttft": 8557.606831368237,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11682,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 38.1556275841335,
    "arrivals": 31815,
    "finished_requests": 31740,
    "scheduler_time": 12.753717514576932
}
#Debug simulation 
Total elapsed time: 2.8112631691619754. Arrivals time: 0.08477486856281757 Scheduler time: 2.2218640940263867 Scheduler overhead time: 0.08604534529149532 Adapter cache time: 0.2926605688408017 Engine time: 0.08492232766002417 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-32/adapters_384_slots_160_rate_0.05-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-32/adapters_384_slots_160_rate_0.05-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 540, 135, 66, 540, 540, 66, 135, 540, 540, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 66, 540, 66, 540, 135, 135, 135, 66, 66, 135, 66, 540, 66, 540, 135, 540, 135, 66, 135, 540, 135, 540, 66, 540, 540, 540, 540, 66, 135, 135, 135, 540, 135, 66, 135, 66, 540, 135, 540, 540, 135, 540, 540, 66, 66, 540, 135, 135, 66, 66, 66, 135, 66, 135, 66, 540, 66, 135, 540, 66, 540, 135, 66, 540, 540, 540, 540, 135, 66, 135, 540, 540, 135, 66, 66, 540, 135, 135, 66, 66, 540, 135, 540, 135, 540, 540, 135, 540, 540, 66, 135, 135, 135, 135, 66, 66, 540, 66, 540, 66, 66, 66, 135, 135, 540, 66, 66, 540, 66, 540, 135, 66, 540, 135, 135, 66, 540, 540, 540, 66, 135, 540, 66, 540, 135, 135, 540, 540, 66, 135, 540, 66, 135, 135, 66, 135, 66, 135, 540, 540, 135, 66, 540, 66, 540, 135, 135, 135, 135, 135, 66, 66, 540, 66, 540, 66, 135, 540, 135, 540, 135, 540, 135, 540, 66, 135, 135, 135, 135, 135, 135, 135, 135, 540, 66, 66, 66, 66, 66, 135, 66, 66, 135, 540, 540, 66, 66, 540, 66, 66, 66, 135, 66, 135, 540, 540, 135, 135, 66, 540, 135, 540, 66, 135, 135, 66, 66, 135, 66, 540, 540, 66, 540, 540, 66, 135, 540, 66, 66, 135, 135, 66, 66, 540, 540, 540, 540, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 540, 135, 135, 135, 540, 66, 135, 135, 540, 540, 66, 540, 540, 66, 540, 66, 66, 135, 66, 540, 540, 540, 135, 66, 540, 540, 135, 135, 540, 540, 66, 540, 540, 135, 66, 540, 135, 135, 540, 540, 540, 66, 540, 66, 540, 540, 66, 66, 540, 66, 135, 540, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 540, 66, 66, 66, 135, 66, 135, 135, 66, 540, 135, 540, 66, 540, 66, 135, 135, 135, 135, 66, 135, 540, 540, 66, 540, 540, 66, 540, 135, 540, 135, 135, 135, 66, 135, 66, 66, 540, 66, 135, 66, 66, 135, 540, 135, 540, 66, 540, 540, 135, 540, 135, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 94848 . Total input tokens: 21112697 . Total output tokens: 18991968
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 2.7744797756895423,
    "estimated_duration": 3599.754982214288,
    "input_throughput": 2206.0043084141444,
    "output_throughput": 1937.337967294145,
    "total_throughput": 4143.342275708289,
    "itl": 42.24994026954706,
    "ttft": 8557.47514496287,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11685,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 38.22709845968101,
    "arrivals": 31815,
    "finished_requests": 31740,
    "scheduler_time": 12.754538370004596
}
#Debug simulation 
Total elapsed time: 2.774561129976064. Arrivals time: 0.08408665098249912 Scheduler time: 2.190129220020026 Scheduler overhead time: 0.08557162946090102 Adapter cache time: 0.28951487923040986 Engine time: 0.08438260434195399 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_384_slots_160_rate_0.05-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_384_slots_160_rate_0.05-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 540, 135, 66, 540, 540, 66, 135, 540, 540, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 66, 540, 66, 540, 135, 135, 135, 66, 66, 135, 66, 540, 66, 540, 135, 540, 135, 66, 135, 540, 135, 540, 66, 540, 540, 540, 540, 66, 135, 135, 135, 540, 135, 66, 135, 66, 540, 135, 540, 540, 135, 540, 540, 66, 66, 540, 135, 135, 66, 66, 66, 135, 66, 135, 66, 540, 66, 135, 540, 66, 540, 135, 66, 540, 540, 540, 540, 135, 66, 135, 540, 540, 135, 66, 66, 540, 135, 135, 66, 66, 540, 135, 540, 135, 540, 540, 135, 540, 540, 66, 135, 135, 135, 135, 66, 66, 540, 66, 540, 66, 66, 66, 135, 135, 540, 66, 66, 540, 66, 540, 135, 66, 540, 135, 135, 66, 540, 540, 540, 66, 135, 540, 66, 540, 135, 135, 540, 540, 66, 135, 540, 66, 135, 135, 66, 135, 66, 135, 540, 540, 135, 66, 540, 66, 540, 135, 135, 135, 135, 135, 66, 66, 540, 66, 540, 66, 135, 540, 135, 540, 135, 540, 135, 540, 66, 135, 135, 135, 135, 135, 135, 135, 135, 540, 66, 66, 66, 66, 66, 135, 66, 66, 135, 540, 540, 66, 66, 540, 66, 66, 66, 135, 66, 135, 540, 540, 135, 135, 66, 540, 135, 540, 66, 135, 135, 66, 66, 135, 66, 540, 540, 66, 540, 540, 66, 135, 540, 66, 66, 135, 135, 66, 66, 540, 540, 540, 540, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 540, 135, 135, 135, 540, 66, 135, 135, 540, 540, 66, 540, 540, 66, 540, 66, 66, 135, 66, 540, 540, 540, 135, 66, 540, 540, 135, 135, 540, 540, 66, 540, 540, 135, 66, 540, 135, 135, 540, 540, 540, 66, 540, 66, 540, 540, 66, 66, 540, 66, 135, 540, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 540, 66, 66, 66, 135, 66, 135, 135, 66, 540, 135, 540, 66, 540, 66, 135, 135, 135, 135, 66, 135, 540, 540, 66, 540, 540, 66, 540, 135, 540, 135, 135, 135, 66, 135, 66, 66, 540, 66, 135, 66, 66, 135, 540, 135, 540, 66, 540, 540, 135, 540, 135, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 94848 . Total input tokens: 21112697 . Total output tokens: 18991968
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 2.856782021932304,
    "estimated_duration": 3599.75655132802,
    "input_throughput": 2206.0033468292136,
    "output_throughput": 1937.337122819369,
    "total_throughput": 4143.340469648582,
    "itl": 42.19856085194542,
    "ttft": 8557.430086144848,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11682,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 36.60133099278614,
    "arrivals": 31815,
    "finished_requests": 31740,
    "scheduler_time": 12.735350635125045
}
#Debug simulation 
Total elapsed time: 2.85685859574005. Arrivals time: 0.08550182171165943 Scheduler time: 2.263748036697507 Scheduler overhead time: 0.08635433809831738 Adapter cache time: 0.2945456625893712 Engine time: 0.08540007844567299 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-32/adapters_384_slots_160_rate_0.05-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-32/adapters_384_slots_160_rate_0.05-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 540, 135, 66, 540, 540, 66, 135, 540, 540, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 66, 540, 66, 540, 135, 135, 135, 66, 66, 135, 66, 540, 66, 540, 135, 540, 135, 66, 135, 540, 135, 540, 66, 540, 540, 540, 540, 66, 135, 135, 135, 540, 135, 66, 135, 66, 540, 135, 540, 540, 135, 540, 540, 66, 66, 540, 135, 135, 66, 66, 66, 135, 66, 135, 66, 540, 66, 135, 540, 66, 540, 135, 66, 540, 540, 540, 540, 135, 66, 135, 540, 540, 135, 66, 66, 540, 135, 135, 66, 66, 540, 135, 540, 135, 540, 540, 135, 540, 540, 66, 135, 135, 135, 135, 66, 66, 540, 66, 540, 66, 66, 66, 135, 135, 540, 66, 66, 540, 66, 540, 135, 66, 540, 135, 135, 66, 540, 540, 540, 66, 135, 540, 66, 540, 135, 135, 540, 540, 66, 135, 540, 66, 135, 135, 66, 135, 66, 135, 540, 540, 135, 66, 540, 66, 540, 135, 135, 135, 135, 135, 66, 66, 540, 66, 540, 66, 135, 540, 135, 540, 135, 540, 135, 540, 66, 135, 135, 135, 135, 135, 135, 135, 135, 540, 66, 66, 66, 66, 66, 135, 66, 66, 135, 540, 540, 66, 66, 540, 66, 66, 66, 135, 66, 135, 540, 540, 135, 135, 66, 540, 135, 540, 66, 135, 135, 66, 66, 135, 66, 540, 540, 66, 540, 540, 66, 135, 540, 66, 66, 135, 135, 66, 66, 540, 540, 540, 540, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 540, 135, 135, 135, 540, 66, 135, 135, 540, 540, 66, 540, 540, 66, 540, 66, 66, 135, 66, 540, 540, 540, 135, 66, 540, 540, 135, 135, 540, 540, 66, 540, 540, 135, 66, 540, 135, 135, 540, 540, 540, 66, 540, 66, 540, 540, 66, 66, 540, 66, 135, 540, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 540, 66, 66, 66, 135, 66, 135, 135, 66, 540, 135, 540, 66, 540, 66, 135, 135, 135, 135, 66, 135, 540, 540, 66, 540, 540, 66, 540, 135, 540, 135, 135, 135, 66, 135, 66, 66, 540, 66, 135, 66, 66, 135, 540, 135, 540, 66, 540, 540, 135, 540, 135, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 94848 . Total input tokens: 21112697 . Total output tokens: 18991968
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 2.7702090521343052,
    "estimated_duration": 3599.7444681492343,
    "input_throughput": 2206.010751669495,
    "output_throughput": 1937.3436258339661,
    "total_throughput": 4143.354377503461,
    "itl": 42.26664879143535,
    "ttft": 8557.629279057097,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11687,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 38.71327915223535,
    "arrivals": 31815,
    "finished_requests": 31740,
    "scheduler_time": 12.760284582635203
}
#Debug simulation 
Total elapsed time: 2.770294122863561. Arrivals time: 0.08422036562114954 Scheduler time: 2.185941099654883 Scheduler overhead time: 0.08542733965441585 Adapter cache time: 0.2903263494372368 Engine time: 0.08356634993106127 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_384_slots_160_rate_0.05-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_384_slots_160_rate_0.05-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 540, 135, 66, 540, 540, 66, 135, 540, 540, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 66, 540, 66, 540, 135, 135, 135, 66, 66, 135, 66, 540, 66, 540, 135, 540, 135, 66, 135, 540, 135, 540, 66, 540, 540, 540, 540, 66, 135, 135, 135, 540, 135, 66, 135, 66, 540, 135, 540, 540, 135, 540, 540, 66, 66, 540, 135, 135, 66, 66, 66, 135, 66, 135, 66, 540, 66, 135, 540, 66, 540, 135, 66, 540, 540, 540, 540, 135, 66, 135, 540, 540, 135, 66, 66, 540, 135, 135, 66, 66, 540, 135, 540, 135, 540, 540, 135, 540, 540, 66, 135, 135, 135, 135, 66, 66, 540, 66, 540, 66, 66, 66, 135, 135, 540, 66, 66, 540, 66, 540, 135, 66, 540, 135, 135, 66, 540, 540, 540, 66, 135, 540, 66, 540, 135, 135, 540, 540, 66, 135, 540, 66, 135, 135, 66, 135, 66, 135, 540, 540, 135, 66, 540, 66, 540, 135, 135, 135, 135, 135, 66, 66, 540, 66, 540, 66, 135, 540, 135, 540, 135, 540, 135, 540, 66, 135, 135, 135, 135, 135, 135, 135, 135, 540, 66, 66, 66, 66, 66, 135, 66, 66, 135, 540, 540, 66, 66, 540, 66, 66, 66, 135, 66, 135, 540, 540, 135, 135, 66, 540, 135, 540, 66, 135, 135, 66, 66, 135, 66, 540, 540, 66, 540, 540, 66, 135, 540, 66, 66, 135, 135, 66, 66, 540, 540, 540, 540, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 540, 135, 135, 135, 540, 66, 135, 135, 540, 540, 66, 540, 540, 66, 540, 66, 66, 135, 66, 540, 540, 540, 135, 66, 540, 540, 135, 135, 540, 540, 66, 540, 540, 135, 66, 540, 135, 135, 540, 540, 540, 66, 540, 66, 540, 540, 66, 66, 540, 66, 135, 540, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 540, 66, 66, 66, 135, 66, 135, 135, 66, 540, 135, 540, 66, 540, 66, 135, 135, 135, 135, 66, 135, 540, 540, 66, 540, 540, 66, 540, 135, 540, 135, 135, 135, 66, 135, 66, 66, 540, 66, 135, 66, 66, 135, 540, 135, 540, 66, 540, 540, 135, 540, 135, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 94848 . Total input tokens: 21112697 . Total output tokens: 18991968
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 2.8225631047971547,
    "estimated_duration": 3599.7760595480586,
    "input_throughput": 2205.991391863687,
    "output_throughput": 1937.3266238332499,
    "total_throughput": 4143.3180156969365,
    "itl": 42.513472777387804,
    "ttft": 8557.662119801209,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11673,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 34.9028570923921,
    "arrivals": 31815,
    "finished_requests": 31740,
    "scheduler_time": 12.85207499382283
}
#Debug simulation 
Total elapsed time: 2.822650056798011. Arrivals time: 0.08444565301761031 Scheduler time: 2.2338474388234317 Scheduler overhead time: 0.08563382597640157 Adapter cache time: 0.2933116410858929 Engine time: 0.0845381049439311 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-32/adapters_384_slots_160_rate_0.05-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-32/adapters_384_slots_160_rate_0.05-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 540, 135, 66, 540, 540, 66, 135, 540, 540, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 66, 540, 66, 540, 135, 135, 135, 66, 66, 135, 66, 540, 66, 540, 135, 540, 135, 66, 135, 540, 135, 540, 66, 540, 540, 540, 540, 66, 135, 135, 135, 540, 135, 66, 135, 66, 540, 135, 540, 540, 135, 540, 540, 66, 66, 540, 135, 135, 66, 66, 66, 135, 66, 135, 66, 540, 66, 135, 540, 66, 540, 135, 66, 540, 540, 540, 540, 135, 66, 135, 540, 540, 135, 66, 66, 540, 135, 135, 66, 66, 540, 135, 540, 135, 540, 540, 135, 540, 540, 66, 135, 135, 135, 135, 66, 66, 540, 66, 540, 66, 66, 66, 135, 135, 540, 66, 66, 540, 66, 540, 135, 66, 540, 135, 135, 66, 540, 540, 540, 66, 135, 540, 66, 540, 135, 135, 540, 540, 66, 135, 540, 66, 135, 135, 66, 135, 66, 135, 540, 540, 135, 66, 540, 66, 540, 135, 135, 135, 135, 135, 66, 66, 540, 66, 540, 66, 135, 540, 135, 540, 135, 540, 135, 540, 66, 135, 135, 135, 135, 135, 135, 135, 135, 540, 66, 66, 66, 66, 66, 135, 66, 66, 135, 540, 540, 66, 66, 540, 66, 66, 66, 135, 66, 135, 540, 540, 135, 135, 66, 540, 135, 540, 66, 135, 135, 66, 66, 135, 66, 540, 540, 66, 540, 540, 66, 135, 540, 66, 66, 135, 135, 66, 66, 540, 540, 540, 540, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 540, 135, 135, 135, 540, 66, 135, 135, 540, 540, 66, 540, 540, 66, 540, 66, 66, 135, 66, 540, 540, 540, 135, 66, 540, 540, 135, 135, 540, 540, 66, 540, 540, 135, 66, 540, 135, 135, 540, 540, 540, 66, 540, 66, 540, 540, 66, 66, 540, 66, 135, 540, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 540, 66, 66, 66, 135, 66, 135, 135, 66, 540, 135, 540, 66, 540, 66, 135, 135, 135, 135, 66, 135, 540, 540, 66, 540, 540, 66, 540, 135, 540, 135, 135, 135, 66, 135, 66, 66, 540, 66, 135, 66, 66, 135, 540, 135, 540, 66, 540, 540, 135, 540, 135, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 94848 . Total input tokens: 21112697 . Total output tokens: 18991968
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 2.8234848836436868,
    "estimated_duration": 3599.777903409104,
    "input_throughput": 2205.9902619213117,
    "output_throughput": 1937.3256315050592,
    "total_throughput": 4143.315893426371,
    "itl": 42.283404777094454,
    "ttft": 8557.577394007723,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11684,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 39.217258345930844,
    "arrivals": 31815,
    "finished_requests": 31740,
    "scheduler_time": 12.766425518481812
}
#Debug simulation 
Total elapsed time: 2.8235611519776285. Arrivals time: 0.08474917896091938 Scheduler time: 2.2344226334244013 Scheduler overhead time: 0.08595813065767288 Adapter cache time: 0.2927474109455943 Engine time: 0.08450498338788748 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_384_slots_160_rate_0.05-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_384_slots_160_rate_0.05-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 540, 135, 33, 540, 540, 33, 135, 540, 540, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 33, 540, 33, 540, 135, 135, 135, 33, 33, 135, 33, 540, 33, 540, 135, 540, 135, 33, 135, 540, 135, 540, 33, 540, 540, 540, 540, 33, 135, 135, 135, 540, 135, 33, 135, 33, 540, 135, 540, 540, 135, 540, 540, 33, 33, 540, 135, 135, 33, 33, 33, 135, 33, 135, 33, 540, 33, 135, 540, 33, 540, 135, 33, 540, 540, 540, 540, 135, 33, 135, 540, 540, 135, 33, 33, 540, 135, 135, 33, 33, 540, 135, 540, 135, 540, 540, 135, 540, 540, 33, 135, 135, 135, 135, 33, 33, 540, 33, 540, 33, 33, 33, 135, 135, 540, 33, 33, 540, 33, 540, 135, 33, 540, 135, 135, 33, 540, 540, 540, 33, 135, 540, 33, 540, 135, 135, 540, 540, 33, 135, 540, 33, 135, 135, 33, 135, 33, 135, 540, 540, 135, 33, 540, 33, 540, 135, 135, 135, 135, 135, 33, 33, 540, 33, 540, 33, 135, 540, 135, 540, 135, 540, 135, 540, 33, 135, 135, 135, 135, 135, 135, 135, 135, 540, 33, 33, 33, 33, 33, 135, 33, 33, 135, 540, 540, 33, 33, 540, 33, 33, 33, 135, 33, 135, 540, 540, 135, 135, 33, 540, 135, 540, 33, 135, 135, 33, 33, 135, 33, 540, 540, 33, 540, 540, 33, 135, 540, 33, 33, 135, 135, 33, 33, 540, 540, 540, 540, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 540, 135, 135, 135, 540, 33, 135, 135, 540, 540, 33, 540, 540, 33, 540, 33, 33, 135, 33, 540, 540, 540, 135, 33, 540, 540, 135, 135, 540, 540, 33, 540, 540, 135, 33, 540, 135, 135, 540, 540, 540, 33, 540, 33, 540, 540, 33, 33, 540, 33, 135, 540, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 540, 33, 33, 33, 135, 33, 135, 135, 33, 540, 135, 540, 33, 540, 33, 135, 135, 135, 135, 33, 135, 540, 540, 33, 540, 540, 33, 540, 135, 540, 135, 135, 135, 33, 135, 33, 33, 540, 33, 135, 33, 33, 135, 540, 135, 540, 33, 540, 540, 135, 540, 135, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 90624 . Total input tokens: 20179995 . Total output tokens: 18105372
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 2.648657181765884,
    "estimated_duration": 3599.941003743118,
    "input_throughput": 2099.196345757461,
    "output_throughput": 1836.7659339763536,
    "total_throughput": 3935.9622797338147,
    "itl": 37.91191823726385,
    "ttft": 5266.713459327075,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9582,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.325593562366176,
    "arrivals": 30443,
    "finished_requests": 30399,
    "scheduler_time": 9.531980713316724
}
#Debug simulation 
Total elapsed time: 2.6487344237975776. Arrivals time: 0.08124377205967903 Scheduler time: 2.065869639161974 Scheduler overhead time: 0.09326322190463543 Adapter cache time: 0.2728816894814372 Engine time: 0.09096207655966282 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_384_slots_160_rate_0.05-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_384_slots_160_rate_0.05-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 540, 135, 33, 540, 540, 33, 135, 540, 540, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 33, 540, 33, 540, 135, 135, 135, 33, 33, 135, 33, 540, 33, 540, 135, 540, 135, 33, 135, 540, 135, 540, 33, 540, 540, 540, 540, 33, 135, 135, 135, 540, 135, 33, 135, 33, 540, 135, 540, 540, 135, 540, 540, 33, 33, 540, 135, 135, 33, 33, 33, 135, 33, 135, 33, 540, 33, 135, 540, 33, 540, 135, 33, 540, 540, 540, 540, 135, 33, 135, 540, 540, 135, 33, 33, 540, 135, 135, 33, 33, 540, 135, 540, 135, 540, 540, 135, 540, 540, 33, 135, 135, 135, 135, 33, 33, 540, 33, 540, 33, 33, 33, 135, 135, 540, 33, 33, 540, 33, 540, 135, 33, 540, 135, 135, 33, 540, 540, 540, 33, 135, 540, 33, 540, 135, 135, 540, 540, 33, 135, 540, 33, 135, 135, 33, 135, 33, 135, 540, 540, 135, 33, 540, 33, 540, 135, 135, 135, 135, 135, 33, 33, 540, 33, 540, 33, 135, 540, 135, 540, 135, 540, 135, 540, 33, 135, 135, 135, 135, 135, 135, 135, 135, 540, 33, 33, 33, 33, 33, 135, 33, 33, 135, 540, 540, 33, 33, 540, 33, 33, 33, 135, 33, 135, 540, 540, 135, 135, 33, 540, 135, 540, 33, 135, 135, 33, 33, 135, 33, 540, 540, 33, 540, 540, 33, 135, 540, 33, 33, 135, 135, 33, 33, 540, 540, 540, 540, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 540, 135, 135, 135, 540, 33, 135, 135, 540, 540, 33, 540, 540, 33, 540, 33, 33, 135, 33, 540, 540, 540, 135, 33, 540, 540, 135, 135, 540, 540, 33, 540, 540, 135, 33, 540, 135, 135, 540, 540, 540, 33, 540, 33, 540, 540, 33, 33, 540, 33, 135, 540, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 540, 33, 33, 33, 135, 33, 135, 135, 33, 540, 135, 540, 33, 540, 33, 135, 135, 135, 135, 33, 135, 540, 540, 33, 540, 540, 33, 540, 135, 540, 135, 135, 135, 33, 135, 33, 33, 540, 33, 135, 33, 33, 135, 540, 135, 540, 33, 540, 540, 135, 540, 135, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 90624 . Total input tokens: 20179995 . Total output tokens: 18105372
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 2.665813966654241,
    "estimated_duration": 3599.9463274331015,
    "input_throughput": 2099.193241413801,
    "output_throughput": 1836.7632177213,
    "total_throughput": 3935.956459135101,
    "itl": 37.96413961084925,
    "ttft": 5266.901895815045,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9581,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 31.301498468723334,
    "arrivals": 30443,
    "finished_requests": 30399,
    "scheduler_time": 9.554274860772006
}
#Debug simulation 
Total elapsed time: 2.665943185798824. Arrivals time: 0.08169703790917993 Scheduler time: 2.0830135229043663 Scheduler overhead time: 0.09285064693540335 Adapter cache time: 0.2744143456220627 Engine time: 0.08940948219969869 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-32/adapters_384_slots_160_rate_0.05-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-32/adapters_384_slots_160_rate_0.05-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 540, 135, 33, 540, 540, 33, 135, 540, 540, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 33, 540, 33, 540, 135, 135, 135, 33, 33, 135, 33, 540, 33, 540, 135, 540, 135, 33, 135, 540, 135, 540, 33, 540, 540, 540, 540, 33, 135, 135, 135, 540, 135, 33, 135, 33, 540, 135, 540, 540, 135, 540, 540, 33, 33, 540, 135, 135, 33, 33, 33, 135, 33, 135, 33, 540, 33, 135, 540, 33, 540, 135, 33, 540, 540, 540, 540, 135, 33, 135, 540, 540, 135, 33, 33, 540, 135, 135, 33, 33, 540, 135, 540, 135, 540, 540, 135, 540, 540, 33, 135, 135, 135, 135, 33, 33, 540, 33, 540, 33, 33, 33, 135, 135, 540, 33, 33, 540, 33, 540, 135, 33, 540, 135, 135, 33, 540, 540, 540, 33, 135, 540, 33, 540, 135, 135, 540, 540, 33, 135, 540, 33, 135, 135, 33, 135, 33, 135, 540, 540, 135, 33, 540, 33, 540, 135, 135, 135, 135, 135, 33, 33, 540, 33, 540, 33, 135, 540, 135, 540, 135, 540, 135, 540, 33, 135, 135, 135, 135, 135, 135, 135, 135, 540, 33, 33, 33, 33, 33, 135, 33, 33, 135, 540, 540, 33, 33, 540, 33, 33, 33, 135, 33, 135, 540, 540, 135, 135, 33, 540, 135, 540, 33, 135, 135, 33, 33, 135, 33, 540, 540, 33, 540, 540, 33, 135, 540, 33, 33, 135, 135, 33, 33, 540, 540, 540, 540, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 540, 135, 135, 135, 540, 33, 135, 135, 540, 540, 33, 540, 540, 33, 540, 33, 33, 135, 33, 540, 540, 540, 135, 33, 540, 540, 135, 135, 540, 540, 33, 540, 540, 135, 33, 540, 135, 135, 540, 540, 540, 33, 540, 33, 540, 540, 33, 33, 540, 33, 135, 540, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 540, 33, 33, 33, 135, 33, 135, 135, 33, 540, 135, 540, 33, 540, 33, 135, 135, 135, 135, 33, 135, 540, 540, 33, 540, 540, 33, 540, 135, 540, 135, 135, 135, 33, 135, 33, 33, 540, 33, 135, 33, 33, 135, 540, 135, 540, 33, 540, 540, 135, 540, 135, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 90624 . Total input tokens: 20179995 . Total output tokens: 18105372
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 2.676794411148876,
    "estimated_duration": 3599.9603872736243,
    "input_throughput": 2099.1850429007545,
    "output_throughput": 1836.7560441429432,
    "total_throughput": 3935.9410870436977,
    "itl": 37.96494046700161,
    "ttft": 5266.92318689891,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9582,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 31.353757333384486,
    "arrivals": 30443,
    "finished_requests": 30399,
    "scheduler_time": 9.554696354794341
}
#Debug simulation 
Total elapsed time: 2.676876293029636. Arrivals time: 0.0821203850209713 Scheduler time: 2.0925525878556073 Scheduler overhead time: 0.0928797866217792 Adapter cache time: 0.27447665575891733 Engine time: 0.09041275922209024 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-16/adapters_384_slots_160_rate_0.05-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-16/adapters_384_slots_160_rate_0.05-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 540, 135, 33, 540, 540, 33, 135, 540, 540, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 33, 540, 33, 540, 135, 135, 135, 33, 33, 135, 33, 540, 33, 540, 135, 540, 135, 33, 135, 540, 135, 540, 33, 540, 540, 540, 540, 33, 135, 135, 135, 540, 135, 33, 135, 33, 540, 135, 540, 540, 135, 540, 540, 33, 33, 540, 135, 135, 33, 33, 33, 135, 33, 135, 33, 540, 33, 135, 540, 33, 540, 135, 33, 540, 540, 540, 540, 135, 33, 135, 540, 540, 135, 33, 33, 540, 135, 135, 33, 33, 540, 135, 540, 135, 540, 540, 135, 540, 540, 33, 135, 135, 135, 135, 33, 33, 540, 33, 540, 33, 33, 33, 135, 135, 540, 33, 33, 540, 33, 540, 135, 33, 540, 135, 135, 33, 540, 540, 540, 33, 135, 540, 33, 540, 135, 135, 540, 540, 33, 135, 540, 33, 135, 135, 33, 135, 33, 135, 540, 540, 135, 33, 540, 33, 540, 135, 135, 135, 135, 135, 33, 33, 540, 33, 540, 33, 135, 540, 135, 540, 135, 540, 135, 540, 33, 135, 135, 135, 135, 135, 135, 135, 135, 540, 33, 33, 33, 33, 33, 135, 33, 33, 135, 540, 540, 33, 33, 540, 33, 33, 33, 135, 33, 135, 540, 540, 135, 135, 33, 540, 135, 540, 33, 135, 135, 33, 33, 135, 33, 540, 540, 33, 540, 540, 33, 135, 540, 33, 33, 135, 135, 33, 33, 540, 540, 540, 540, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 540, 135, 135, 135, 540, 33, 135, 135, 540, 540, 33, 540, 540, 33, 540, 33, 33, 135, 33, 540, 540, 540, 135, 33, 540, 540, 135, 135, 540, 540, 33, 540, 540, 135, 33, 540, 135, 135, 540, 540, 540, 33, 540, 33, 540, 540, 33, 33, 540, 33, 135, 540, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 540, 33, 33, 33, 135, 33, 135, 135, 33, 540, 135, 540, 33, 540, 33, 135, 135, 135, 135, 33, 135, 540, 540, 33, 540, 540, 33, 540, 135, 540, 135, 135, 135, 33, 135, 33, 33, 540, 33, 135, 33, 33, 135, 540, 135, 540, 33, 540, 540, 135, 540, 135, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 90624 . Total input tokens: 20179995 . Total output tokens: 18105372
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 2.672015124000609,
    "estimated_duration": 3599.949888816801,
    "input_throughput": 2099.1911647091733,
    "output_throughput": 1836.761400635289,
    "total_throughput": 3935.9525653444625,
    "itl": 37.930637053430026,
    "ttft": 5266.753731571169,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9580,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 30.016336309163634,
    "arrivals": 30443,
    "finished_requests": 30399,
    "scheduler_time": 9.53978001082099
}
#Debug simulation 
Total elapsed time: 2.672091618180275. Arrivals time: 0.08252680581063032 Scheduler time: 2.0836853235960007 Scheduler overhead time: 0.0929730636999011 Adapter cache time: 0.2757996874861419 Engine time: 0.09269499313086271 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-32/adapters_384_slots_160_rate_0.05-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-32/adapters_384_slots_160_rate_0.05-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 540, 135, 33, 540, 540, 33, 135, 540, 540, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 33, 540, 33, 540, 135, 135, 135, 33, 33, 135, 33, 540, 33, 540, 135, 540, 135, 33, 135, 540, 135, 540, 33, 540, 540, 540, 540, 33, 135, 135, 135, 540, 135, 33, 135, 33, 540, 135, 540, 540, 135, 540, 540, 33, 33, 540, 135, 135, 33, 33, 33, 135, 33, 135, 33, 540, 33, 135, 540, 33, 540, 135, 33, 540, 540, 540, 540, 135, 33, 135, 540, 540, 135, 33, 33, 540, 135, 135, 33, 33, 540, 135, 540, 135, 540, 540, 135, 540, 540, 33, 135, 135, 135, 135, 33, 33, 540, 33, 540, 33, 33, 33, 135, 135, 540, 33, 33, 540, 33, 540, 135, 33, 540, 135, 135, 33, 540, 540, 540, 33, 135, 540, 33, 540, 135, 135, 540, 540, 33, 135, 540, 33, 135, 135, 33, 135, 33, 135, 540, 540, 135, 33, 540, 33, 540, 135, 135, 135, 135, 135, 33, 33, 540, 33, 540, 33, 135, 540, 135, 540, 135, 540, 135, 540, 33, 135, 135, 135, 135, 135, 135, 135, 135, 540, 33, 33, 33, 33, 33, 135, 33, 33, 135, 540, 540, 33, 33, 540, 33, 33, 33, 135, 33, 135, 540, 540, 135, 135, 33, 540, 135, 540, 33, 135, 135, 33, 33, 135, 33, 540, 540, 33, 540, 540, 33, 135, 540, 33, 33, 135, 135, 33, 33, 540, 540, 540, 540, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 540, 135, 135, 135, 540, 33, 135, 135, 540, 540, 33, 540, 540, 33, 540, 33, 33, 135, 33, 540, 540, 540, 135, 33, 540, 540, 135, 135, 540, 540, 33, 540, 540, 135, 33, 540, 135, 135, 540, 540, 540, 33, 540, 33, 540, 540, 33, 33, 540, 33, 135, 540, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 540, 33, 33, 33, 135, 33, 135, 135, 33, 540, 135, 540, 33, 540, 33, 135, 135, 135, 135, 33, 135, 540, 540, 33, 540, 540, 33, 540, 135, 540, 135, 135, 135, 33, 135, 33, 33, 540, 33, 135, 33, 33, 135, 540, 135, 540, 33, 540, 540, 135, 540, 135, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 90624 . Total input tokens: 20179995 . Total output tokens: 18105372
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 2.7034821598790586,
    "estimated_duration": 3599.948562213042,
    "input_throughput": 2099.1919382743627,
    "output_throughput": 1836.7620774934542,
    "total_throughput": 3935.9540157678166,
    "itl": 37.97603018020815,
    "ttft": 5266.98123762507,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9586,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 31.760884038041773,
    "arrivals": 30443,
    "finished_requests": 30399,
    "scheduler_time": 9.559282782107834
}
#Debug simulation 
Total elapsed time: 2.703584859147668. Arrivals time: 0.08751785475760698 Scheduler time: 2.1130536030977964 Scheduler overhead time: 0.09225224191322923 Adapter cache time: 0.274665963370353 Engine time: 0.09166514500975609 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-16/adapters_384_slots_160_rate_0.05-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-16/adapters_384_slots_160_rate_0.05-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 540, 135, 33, 540, 540, 33, 135, 540, 540, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 33, 540, 33, 540, 135, 135, 135, 33, 33, 135, 33, 540, 33, 540, 135, 540, 135, 33, 135, 540, 135, 540, 33, 540, 540, 540, 540, 33, 135, 135, 135, 540, 135, 33, 135, 33, 540, 135, 540, 540, 135, 540, 540, 33, 33, 540, 135, 135, 33, 33, 33, 135, 33, 135, 33, 540, 33, 135, 540, 33, 540, 135, 33, 540, 540, 540, 540, 135, 33, 135, 540, 540, 135, 33, 33, 540, 135, 135, 33, 33, 540, 135, 540, 135, 540, 540, 135, 540, 540, 33, 135, 135, 135, 135, 33, 33, 540, 33, 540, 33, 33, 33, 135, 135, 540, 33, 33, 540, 33, 540, 135, 33, 540, 135, 135, 33, 540, 540, 540, 33, 135, 540, 33, 540, 135, 135, 540, 540, 33, 135, 540, 33, 135, 135, 33, 135, 33, 135, 540, 540, 135, 33, 540, 33, 540, 135, 135, 135, 135, 135, 33, 33, 540, 33, 540, 33, 135, 540, 135, 540, 135, 540, 135, 540, 33, 135, 135, 135, 135, 135, 135, 135, 135, 540, 33, 33, 33, 33, 33, 135, 33, 33, 135, 540, 540, 33, 33, 540, 33, 33, 33, 135, 33, 135, 540, 540, 135, 135, 33, 540, 135, 540, 33, 135, 135, 33, 33, 135, 33, 540, 540, 33, 540, 540, 33, 135, 540, 33, 33, 135, 135, 33, 33, 540, 540, 540, 540, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 540, 135, 135, 135, 540, 33, 135, 135, 540, 540, 33, 540, 540, 33, 540, 33, 33, 135, 33, 540, 540, 540, 135, 33, 540, 540, 135, 135, 540, 540, 33, 540, 540, 135, 33, 540, 135, 135, 540, 540, 540, 33, 540, 33, 540, 540, 33, 33, 540, 33, 135, 540, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 540, 33, 33, 33, 135, 33, 135, 135, 33, 540, 135, 540, 33, 540, 33, 135, 135, 135, 135, 33, 135, 540, 540, 33, 540, 540, 33, 540, 135, 540, 135, 135, 135, 33, 135, 33, 33, 540, 33, 135, 33, 33, 135, 540, 135, 540, 33, 540, 540, 135, 540, 135, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 90624 . Total input tokens: 20179995 . Total output tokens: 18105372
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 2.6572845592163503,
    "estimated_duration": 3599.959614437245,
    "input_throughput": 2099.185493552079,
    "output_throughput": 1836.7564384562254,
    "total_throughput": 3935.9419320083043,
    "itl": 37.89568479649585,
    "ttft": 5266.6228510764995,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9588,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.66860222751969,
    "arrivals": 30443,
    "finished_requests": 30399,
    "scheduler_time": 9.52470652235454
}
#Debug simulation 
Total elapsed time: 2.657355986069888. Arrivals time: 0.08050655946135521 Scheduler time: 2.077625196427107 Scheduler overhead time: 0.09320355672389269 Adapter cache time: 0.27220168290659785 Engine time: 0.08935364382341504 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-32/adapters_384_slots_160_rate_0.05-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-32/adapters_384_slots_160_rate_0.05-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 540, 135, 33, 540, 540, 33, 135, 540, 540, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 33, 540, 33, 540, 135, 135, 135, 33, 33, 135, 33, 540, 33, 540, 135, 540, 135, 33, 135, 540, 135, 540, 33, 540, 540, 540, 540, 33, 135, 135, 135, 540, 135, 33, 135, 33, 540, 135, 540, 540, 135, 540, 540, 33, 33, 540, 135, 135, 33, 33, 33, 135, 33, 135, 33, 540, 33, 135, 540, 33, 540, 135, 33, 540, 540, 540, 540, 135, 33, 135, 540, 540, 135, 33, 33, 540, 135, 135, 33, 33, 540, 135, 540, 135, 540, 540, 135, 540, 540, 33, 135, 135, 135, 135, 33, 33, 540, 33, 540, 33, 33, 33, 135, 135, 540, 33, 33, 540, 33, 540, 135, 33, 540, 135, 135, 33, 540, 540, 540, 33, 135, 540, 33, 540, 135, 135, 540, 540, 33, 135, 540, 33, 135, 135, 33, 135, 33, 135, 540, 540, 135, 33, 540, 33, 540, 135, 135, 135, 135, 135, 33, 33, 540, 33, 540, 33, 135, 540, 135, 540, 135, 540, 135, 540, 33, 135, 135, 135, 135, 135, 135, 135, 135, 540, 33, 33, 33, 33, 33, 135, 33, 33, 135, 540, 540, 33, 33, 540, 33, 33, 33, 135, 33, 135, 540, 540, 135, 135, 33, 540, 135, 540, 33, 135, 135, 33, 33, 135, 33, 540, 540, 33, 540, 540, 33, 135, 540, 33, 33, 135, 135, 33, 33, 540, 540, 540, 540, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 540, 135, 135, 135, 540, 33, 135, 135, 540, 540, 33, 540, 540, 33, 540, 33, 33, 135, 33, 540, 540, 540, 135, 33, 540, 540, 135, 135, 540, 540, 33, 540, 540, 135, 33, 540, 135, 135, 540, 540, 540, 33, 540, 33, 540, 540, 33, 33, 540, 33, 135, 540, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 540, 33, 33, 33, 135, 33, 135, 135, 33, 540, 135, 540, 33, 540, 33, 135, 135, 135, 135, 33, 135, 540, 540, 33, 540, 540, 33, 540, 135, 540, 135, 135, 135, 33, 135, 33, 33, 540, 33, 135, 33, 33, 135, 540, 135, 540, 33, 540, 540, 135, 540, 135, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 90624 . Total input tokens: 20179995 . Total output tokens: 18105372
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 2.6474811951629817,
    "estimated_duration": 3599.9439335904394,
    "input_throughput": 2099.1946373073006,
    "output_throughput": 1836.764439107586,
    "total_throughput": 3935.9590764148866,
    "itl": 37.98699069295605,
    "ttft": 5267.043777551355,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9583,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 32.17277144621793,
    "arrivals": 30443,
    "finished_requests": 30399,
    "scheduler_time": 9.564133684072633
}
#Debug simulation 
Total elapsed time: 2.6475584260188043. Arrivals time: 0.08073527738451958 Scheduler time: 2.0673656314611435 Scheduler overhead time: 0.09280999610200524 Adapter cache time: 0.2729595033451915 Engine time: 0.08949467213824391 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-8/adapters_384_slots_160_rate_0.05-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-8/adapters_384_slots_160_rate_0.05-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 540, 66, 33, 540, 540, 33, 66, 540, 540, 540, 540, 66, 66, 66, 66, 540, 540, 66, 66, 33, 540, 33, 540, 66, 66, 66, 33, 33, 66, 33, 540, 33, 540, 66, 540, 66, 33, 66, 540, 66, 540, 33, 540, 540, 540, 540, 33, 66, 66, 66, 540, 66, 33, 66, 33, 540, 66, 540, 540, 66, 540, 540, 33, 33, 540, 66, 66, 33, 33, 33, 66, 33, 66, 33, 540, 33, 66, 540, 33, 540, 66, 33, 540, 540, 540, 540, 66, 33, 66, 540, 540, 66, 33, 33, 540, 66, 66, 33, 33, 540, 66, 540, 66, 540, 540, 66, 540, 540, 33, 66, 66, 66, 66, 33, 33, 540, 33, 540, 33, 33, 33, 66, 66, 540, 33, 33, 540, 33, 540, 66, 33, 540, 66, 66, 33, 540, 540, 540, 33, 66, 540, 33, 540, 66, 66, 540, 540, 33, 66, 540, 33, 66, 66, 33, 66, 33, 66, 540, 540, 66, 33, 540, 33, 540, 66, 66, 66, 66, 66, 33, 33, 540, 33, 540, 33, 66, 540, 66, 540, 66, 540, 66, 540, 33, 66, 66, 66, 66, 66, 66, 66, 66, 540, 33, 33, 33, 33, 33, 66, 33, 33, 66, 540, 540, 33, 33, 540, 33, 33, 33, 66, 33, 66, 540, 540, 66, 66, 33, 540, 66, 540, 33, 66, 66, 33, 33, 66, 33, 540, 540, 33, 540, 540, 33, 66, 540, 33, 33, 66, 66, 33, 33, 540, 540, 540, 540, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 540, 66, 66, 66, 540, 33, 66, 66, 540, 540, 33, 540, 540, 33, 540, 33, 33, 66, 33, 540, 540, 540, 66, 33, 540, 540, 66, 66, 540, 540, 33, 540, 540, 66, 33, 540, 66, 66, 540, 540, 540, 33, 540, 33, 540, 540, 33, 33, 540, 33, 66, 540, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 540, 33, 33, 33, 66, 33, 66, 66, 33, 540, 66, 540, 33, 540, 33, 66, 66, 66, 66, 33, 66, 540, 540, 33, 540, 540, 33, 540, 66, 540, 66, 66, 66, 33, 66, 33, 33, 540, 33, 66, 33, 33, 66, 540, 66, 540, 33, 540, 540, 66, 540, 66, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 81792 . Total input tokens: 18226101 . Total output tokens: 16350805
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 2.4818047783337533,
    "estimated_duration": 3600.0198515378506,
    "input_throughput": 1870.4221859008833,
    "output_throughput": 1691.3645621701041,
    "total_throughput": 3561.7867480709874,
    "itl": 33.474459824352,
    "ttft": 4897.382443984942,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6147,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.81281816195375,
    "arrivals": 27512,
    "finished_requests": 27475,
    "scheduler_time": 5.356000680136608
}
#Debug simulation 
Total elapsed time: 2.4818823630921543. Arrivals time: 0.07568349875509739 Scheduler time: 1.9135050210170448 Scheduler overhead time: 0.10227827681228518 Adapter cache time: 0.2413389626890421 Engine time: 0.10051918169483542 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-16/adapters_384_slots_160_rate_0.05-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-16/adapters_384_slots_160_rate_0.05-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 540, 66, 33, 540, 540, 33, 66, 540, 540, 540, 540, 66, 66, 66, 66, 540, 540, 66, 66, 33, 540, 33, 540, 66, 66, 66, 33, 33, 66, 33, 540, 33, 540, 66, 540, 66, 33, 66, 540, 66, 540, 33, 540, 540, 540, 540, 33, 66, 66, 66, 540, 66, 33, 66, 33, 540, 66, 540, 540, 66, 540, 540, 33, 33, 540, 66, 66, 33, 33, 33, 66, 33, 66, 33, 540, 33, 66, 540, 33, 540, 66, 33, 540, 540, 540, 540, 66, 33, 66, 540, 540, 66, 33, 33, 540, 66, 66, 33, 33, 540, 66, 540, 66, 540, 540, 66, 540, 540, 33, 66, 66, 66, 66, 33, 33, 540, 33, 540, 33, 33, 33, 66, 66, 540, 33, 33, 540, 33, 540, 66, 33, 540, 66, 66, 33, 540, 540, 540, 33, 66, 540, 33, 540, 66, 66, 540, 540, 33, 66, 540, 33, 66, 66, 33, 66, 33, 66, 540, 540, 66, 33, 540, 33, 540, 66, 66, 66, 66, 66, 33, 33, 540, 33, 540, 33, 66, 540, 66, 540, 66, 540, 66, 540, 33, 66, 66, 66, 66, 66, 66, 66, 66, 540, 33, 33, 33, 33, 33, 66, 33, 33, 66, 540, 540, 33, 33, 540, 33, 33, 33, 66, 33, 66, 540, 540, 66, 66, 33, 540, 66, 540, 33, 66, 66, 33, 33, 66, 33, 540, 540, 33, 540, 540, 33, 66, 540, 33, 33, 66, 66, 33, 33, 540, 540, 540, 540, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 540, 66, 66, 66, 540, 33, 66, 66, 540, 540, 33, 540, 540, 33, 540, 33, 33, 66, 33, 540, 540, 540, 66, 33, 540, 540, 66, 66, 540, 540, 33, 540, 540, 66, 33, 540, 66, 66, 540, 540, 540, 33, 540, 33, 540, 540, 33, 33, 540, 33, 66, 540, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 540, 33, 33, 33, 66, 33, 66, 66, 33, 540, 66, 540, 33, 540, 33, 66, 66, 66, 66, 33, 66, 540, 540, 33, 540, 540, 33, 540, 66, 540, 66, 66, 66, 33, 66, 33, 33, 540, 33, 66, 33, 33, 66, 540, 66, 540, 33, 540, 540, 66, 540, 66, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 81792 . Total input tokens: 18226101 . Total output tokens: 16350805
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 2.4964154330082238,
    "estimated_duration": 3600.0182115953944,
    "input_throughput": 1870.4230379478936,
    "output_throughput": 1691.3653326496938,
    "total_throughput": 3561.7883705975873,
    "itl": 33.49888328066225,
    "ttft": 4897.535934964148,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6144,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.071442727227303,
    "arrivals": 27512,
    "finished_requests": 27475,
    "scheduler_time": 5.367724076690157
}
#Debug simulation 
Total elapsed time: 2.496494262944907. Arrivals time: 0.07511841366067529 Scheduler time: 1.9329418991692364 Scheduler overhead time: 0.10149848973378539 Adapter cache time: 0.2405625176616013 Engine time: 0.0978563386015594 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-32/adapters_384_slots_160_rate_0.05-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-32/adapters_384_slots_160_rate_0.05-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 540, 66, 33, 540, 540, 33, 66, 540, 540, 540, 540, 66, 66, 66, 66, 540, 540, 66, 66, 33, 540, 33, 540, 66, 66, 66, 33, 33, 66, 33, 540, 33, 540, 66, 540, 66, 33, 66, 540, 66, 540, 33, 540, 540, 540, 540, 33, 66, 66, 66, 540, 66, 33, 66, 33, 540, 66, 540, 540, 66, 540, 540, 33, 33, 540, 66, 66, 33, 33, 33, 66, 33, 66, 33, 540, 33, 66, 540, 33, 540, 66, 33, 540, 540, 540, 540, 66, 33, 66, 540, 540, 66, 33, 33, 540, 66, 66, 33, 33, 540, 66, 540, 66, 540, 540, 66, 540, 540, 33, 66, 66, 66, 66, 33, 33, 540, 33, 540, 33, 33, 33, 66, 66, 540, 33, 33, 540, 33, 540, 66, 33, 540, 66, 66, 33, 540, 540, 540, 33, 66, 540, 33, 540, 66, 66, 540, 540, 33, 66, 540, 33, 66, 66, 33, 66, 33, 66, 540, 540, 66, 33, 540, 33, 540, 66, 66, 66, 66, 66, 33, 33, 540, 33, 540, 33, 66, 540, 66, 540, 66, 540, 66, 540, 33, 66, 66, 66, 66, 66, 66, 66, 66, 540, 33, 33, 33, 33, 33, 66, 33, 33, 66, 540, 540, 33, 33, 540, 33, 33, 33, 66, 33, 66, 540, 540, 66, 66, 33, 540, 66, 540, 33, 66, 66, 33, 33, 66, 33, 540, 540, 33, 540, 540, 33, 66, 540, 33, 33, 66, 66, 33, 33, 540, 540, 540, 540, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 540, 66, 66, 66, 540, 33, 66, 66, 540, 540, 33, 540, 540, 33, 540, 33, 33, 66, 33, 540, 540, 540, 66, 33, 540, 540, 66, 66, 540, 540, 33, 540, 540, 66, 33, 540, 66, 66, 540, 540, 540, 33, 540, 33, 540, 540, 33, 33, 540, 33, 66, 540, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 540, 33, 33, 33, 66, 33, 66, 66, 33, 540, 66, 540, 33, 540, 33, 66, 66, 66, 66, 33, 66, 540, 540, 33, 540, 540, 33, 540, 66, 540, 66, 66, 66, 33, 66, 33, 33, 540, 33, 66, 33, 33, 66, 540, 66, 540, 33, 540, 540, 66, 540, 66, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 81792 . Total input tokens: 18226101 . Total output tokens: 16350805
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 2.4976433399133384,
    "estimated_duration": 3600.016153899872,
    "input_throughput": 1870.4241070434048,
    "output_throughput": 1691.366299399487,
    "total_throughput": 3561.7904064428917,
    "itl": 33.499386394701446,
    "ttft": 4897.491218983889,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6145,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.10638464542039,
    "arrivals": 27512,
    "finished_requests": 27475,
    "scheduler_time": 5.368380294700853
}
#Debug simulation 
Total elapsed time: 2.4977225670590997. Arrivals time: 0.07580534787848592 Scheduler time: 1.9304635412991047 Scheduler overhead time: 0.10183794610202312 Adapter cache time: 0.24077557865530252 Engine time: 0.10019500739872456 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-16/adapters_384_slots_160_rate_0.05-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-16/adapters_384_slots_160_rate_0.05-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 540, 66, 33, 540, 540, 33, 66, 540, 540, 540, 540, 66, 66, 66, 66, 540, 540, 66, 66, 33, 540, 33, 540, 66, 66, 66, 33, 33, 66, 33, 540, 33, 540, 66, 540, 66, 33, 66, 540, 66, 540, 33, 540, 540, 540, 540, 33, 66, 66, 66, 540, 66, 33, 66, 33, 540, 66, 540, 540, 66, 540, 540, 33, 33, 540, 66, 66, 33, 33, 33, 66, 33, 66, 33, 540, 33, 66, 540, 33, 540, 66, 33, 540, 540, 540, 540, 66, 33, 66, 540, 540, 66, 33, 33, 540, 66, 66, 33, 33, 540, 66, 540, 66, 540, 540, 66, 540, 540, 33, 66, 66, 66, 66, 33, 33, 540, 33, 540, 33, 33, 33, 66, 66, 540, 33, 33, 540, 33, 540, 66, 33, 540, 66, 66, 33, 540, 540, 540, 33, 66, 540, 33, 540, 66, 66, 540, 540, 33, 66, 540, 33, 66, 66, 33, 66, 33, 66, 540, 540, 66, 33, 540, 33, 540, 66, 66, 66, 66, 66, 33, 33, 540, 33, 540, 33, 66, 540, 66, 540, 66, 540, 66, 540, 33, 66, 66, 66, 66, 66, 66, 66, 66, 540, 33, 33, 33, 33, 33, 66, 33, 33, 66, 540, 540, 33, 33, 540, 33, 33, 33, 66, 33, 66, 540, 540, 66, 66, 33, 540, 66, 540, 33, 66, 66, 33, 33, 66, 33, 540, 540, 33, 540, 540, 33, 66, 540, 33, 33, 66, 66, 33, 33, 540, 540, 540, 540, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 540, 66, 66, 66, 540, 33, 66, 66, 540, 540, 33, 540, 540, 33, 540, 33, 33, 66, 33, 540, 540, 540, 66, 33, 540, 540, 66, 66, 540, 540, 33, 540, 540, 66, 33, 540, 66, 66, 540, 540, 540, 33, 540, 33, 540, 540, 33, 33, 540, 33, 66, 540, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 540, 33, 33, 33, 66, 33, 66, 66, 33, 540, 66, 540, 33, 540, 33, 66, 66, 66, 66, 33, 66, 540, 540, 33, 540, 540, 33, 540, 66, 540, 66, 66, 66, 33, 66, 33, 33, 540, 33, 66, 33, 33, 66, 540, 66, 540, 33, 540, 540, 66, 540, 66, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 81792 . Total input tokens: 18226101 . Total output tokens: 16350805
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 2.4846035302616656,
    "estimated_duration": 3599.995024438232,
    "input_throughput": 1870.4350851292497,
    "output_throughput": 1691.3762265408022,
    "total_throughput": 3561.811311670052,
    "itl": 33.482197721318066,
    "ttft": 4897.507933675297,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6146,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.238576639059772,
    "arrivals": 27512,
    "finished_requests": 27475,
    "scheduler_time": 5.359949747258863
}
#Debug simulation 
Total elapsed time: 2.484680902212858. Arrivals time: 0.07531254179775715 Scheduler time: 1.9202990331687033 Scheduler overhead time: 0.10199136519804597 Adapter cache time: 0.23917947569862008 Engine time: 0.09939060872420669 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-32/adapters_384_slots_160_rate_0.05-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-32/adapters_384_slots_160_rate_0.05-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 540, 66, 33, 540, 540, 33, 66, 540, 540, 540, 540, 66, 66, 66, 66, 540, 540, 66, 66, 33, 540, 33, 540, 66, 66, 66, 33, 33, 66, 33, 540, 33, 540, 66, 540, 66, 33, 66, 540, 66, 540, 33, 540, 540, 540, 540, 33, 66, 66, 66, 540, 66, 33, 66, 33, 540, 66, 540, 540, 66, 540, 540, 33, 33, 540, 66, 66, 33, 33, 33, 66, 33, 66, 33, 540, 33, 66, 540, 33, 540, 66, 33, 540, 540, 540, 540, 66, 33, 66, 540, 540, 66, 33, 33, 540, 66, 66, 33, 33, 540, 66, 540, 66, 540, 540, 66, 540, 540, 33, 66, 66, 66, 66, 33, 33, 540, 33, 540, 33, 33, 33, 66, 66, 540, 33, 33, 540, 33, 540, 66, 33, 540, 66, 66, 33, 540, 540, 540, 33, 66, 540, 33, 540, 66, 66, 540, 540, 33, 66, 540, 33, 66, 66, 33, 66, 33, 66, 540, 540, 66, 33, 540, 33, 540, 66, 66, 66, 66, 66, 33, 33, 540, 33, 540, 33, 66, 540, 66, 540, 66, 540, 66, 540, 33, 66, 66, 66, 66, 66, 66, 66, 66, 540, 33, 33, 33, 33, 33, 66, 33, 33, 66, 540, 540, 33, 33, 540, 33, 33, 33, 66, 33, 66, 540, 540, 66, 66, 33, 540, 66, 540, 33, 66, 66, 33, 33, 66, 33, 540, 540, 33, 540, 540, 33, 66, 540, 33, 33, 66, 66, 33, 33, 540, 540, 540, 540, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 540, 66, 66, 66, 540, 33, 66, 66, 540, 540, 33, 540, 540, 33, 540, 33, 33, 66, 33, 540, 540, 540, 66, 33, 540, 540, 66, 66, 540, 540, 33, 540, 540, 66, 33, 540, 66, 66, 540, 540, 540, 33, 540, 33, 540, 540, 33, 33, 540, 33, 66, 540, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 540, 33, 33, 33, 66, 33, 66, 66, 33, 540, 66, 540, 33, 540, 33, 66, 66, 66, 66, 33, 66, 540, 540, 33, 540, 540, 33, 540, 66, 540, 66, 66, 66, 33, 66, 33, 33, 540, 33, 66, 33, 33, 66, 540, 66, 540, 33, 540, 540, 66, 540, 66, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 81792 . Total input tokens: 18226101 . Total output tokens: 16350805
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 2.510254526976496,
    "estimated_duration": 3600.0194015240054,
    "input_throughput": 1870.42241970959,
    "output_throughput": 1691.3647735960399,
    "total_throughput": 3561.78719330563,
    "itl": 33.50480841105292,
    "ttft": 4897.686398796627,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6144,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.361427910159232,
    "arrivals": 27512,
    "finished_requests": 27475,
    "scheduler_time": 5.370821232165742
}
#Debug simulation 
Total elapsed time: 2.510329911019653. Arrivals time: 0.07603602390736341 Scheduler time: 1.938878498505801 Scheduler overhead time: 0.10193491633981466 Adapter cache time: 0.2430736138485372 Engine time: 0.10129690915346146 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-16/adapters_384_slots_160_rate_0.05-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-16/adapters_384_slots_160_rate_0.05-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 540, 66, 33, 540, 540, 33, 66, 540, 540, 540, 540, 66, 66, 66, 66, 540, 540, 66, 66, 33, 540, 33, 540, 66, 66, 66, 33, 33, 66, 33, 540, 33, 540, 66, 540, 66, 33, 66, 540, 66, 540, 33, 540, 540, 540, 540, 33, 66, 66, 66, 540, 66, 33, 66, 33, 540, 66, 540, 540, 66, 540, 540, 33, 33, 540, 66, 66, 33, 33, 33, 66, 33, 66, 33, 540, 33, 66, 540, 33, 540, 66, 33, 540, 540, 540, 540, 66, 33, 66, 540, 540, 66, 33, 33, 540, 66, 66, 33, 33, 540, 66, 540, 66, 540, 540, 66, 540, 540, 33, 66, 66, 66, 66, 33, 33, 540, 33, 540, 33, 33, 33, 66, 66, 540, 33, 33, 540, 33, 540, 66, 33, 540, 66, 66, 33, 540, 540, 540, 33, 66, 540, 33, 540, 66, 66, 540, 540, 33, 66, 540, 33, 66, 66, 33, 66, 33, 66, 540, 540, 66, 33, 540, 33, 540, 66, 66, 66, 66, 66, 33, 33, 540, 33, 540, 33, 66, 540, 66, 540, 66, 540, 66, 540, 33, 66, 66, 66, 66, 66, 66, 66, 66, 540, 33, 33, 33, 33, 33, 66, 33, 33, 66, 540, 540, 33, 33, 540, 33, 33, 33, 66, 33, 66, 540, 540, 66, 66, 33, 540, 66, 540, 33, 66, 66, 33, 33, 66, 33, 540, 540, 33, 540, 540, 33, 66, 540, 33, 33, 66, 66, 33, 33, 540, 540, 540, 540, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 540, 66, 66, 66, 540, 33, 66, 66, 540, 540, 33, 540, 540, 33, 540, 33, 33, 66, 33, 540, 540, 540, 66, 33, 540, 540, 66, 66, 540, 540, 33, 540, 540, 66, 33, 540, 66, 66, 540, 540, 540, 33, 540, 33, 540, 540, 33, 33, 540, 33, 66, 540, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 540, 33, 33, 33, 66, 33, 66, 66, 33, 540, 66, 540, 33, 540, 33, 66, 66, 66, 66, 33, 66, 540, 540, 33, 540, 540, 33, 540, 66, 540, 66, 66, 66, 33, 66, 33, 33, 540, 33, 66, 33, 33, 66, 540, 66, 540, 33, 540, 540, 66, 540, 66, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 81792 . Total input tokens: 18226101 . Total output tokens: 16350805
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 2.4897214891389012,
    "estimated_duration": 3600.016997707516,
    "input_throughput": 1870.4236686348747,
    "output_throughput": 1691.3659029602998,
    "total_throughput": 3561.7895715951745,
    "itl": 33.466081921711464,
    "ttft": 4897.362370589471,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6147,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.379839162764725,
    "arrivals": 27512,
    "finished_requests": 27475,
    "scheduler_time": 5.351980849807516
}
#Debug simulation 
Total elapsed time: 2.4898294447921216. Arrivals time: 0.07616178132593632 Scheduler time: 1.922571187838912 Scheduler overhead time: 0.10211597895249724 Adapter cache time: 0.24000400584191084 Engine time: 0.10016200924292207 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-32/adapters_384_slots_160_rate_0.05-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-32/adapters_384_slots_160_rate_0.05-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 540, 66, 33, 540, 540, 33, 66, 540, 540, 540, 540, 66, 66, 66, 66, 540, 540, 66, 66, 33, 540, 33, 540, 66, 66, 66, 33, 33, 66, 33, 540, 33, 540, 66, 540, 66, 33, 66, 540, 66, 540, 33, 540, 540, 540, 540, 33, 66, 66, 66, 540, 66, 33, 66, 33, 540, 66, 540, 540, 66, 540, 540, 33, 33, 540, 66, 66, 33, 33, 33, 66, 33, 66, 33, 540, 33, 66, 540, 33, 540, 66, 33, 540, 540, 540, 540, 66, 33, 66, 540, 540, 66, 33, 33, 540, 66, 66, 33, 33, 540, 66, 540, 66, 540, 540, 66, 540, 540, 33, 66, 66, 66, 66, 33, 33, 540, 33, 540, 33, 33, 33, 66, 66, 540, 33, 33, 540, 33, 540, 66, 33, 540, 66, 66, 33, 540, 540, 540, 33, 66, 540, 33, 540, 66, 66, 540, 540, 33, 66, 540, 33, 66, 66, 33, 66, 33, 66, 540, 540, 66, 33, 540, 33, 540, 66, 66, 66, 66, 66, 33, 33, 540, 33, 540, 33, 66, 540, 66, 540, 66, 540, 66, 540, 33, 66, 66, 66, 66, 66, 66, 66, 66, 540, 33, 33, 33, 33, 33, 66, 33, 33, 66, 540, 540, 33, 33, 540, 33, 33, 33, 66, 33, 66, 540, 540, 66, 66, 33, 540, 66, 540, 33, 66, 66, 33, 33, 66, 33, 540, 540, 33, 540, 540, 33, 66, 540, 33, 33, 66, 66, 33, 33, 540, 540, 540, 540, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 540, 66, 66, 66, 540, 33, 66, 66, 540, 540, 33, 540, 540, 33, 540, 33, 33, 66, 33, 540, 540, 540, 66, 33, 540, 540, 66, 66, 540, 540, 33, 540, 540, 66, 33, 540, 66, 66, 540, 540, 540, 33, 540, 33, 540, 540, 33, 33, 540, 33, 66, 540, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 540, 33, 33, 33, 66, 33, 66, 66, 33, 540, 66, 540, 33, 540, 33, 66, 66, 66, 66, 33, 66, 540, 540, 33, 540, 540, 33, 540, 66, 540, 66, 66, 66, 33, 66, 33, 33, 540, 33, 66, 33, 33, 66, 540, 66, 540, 33, 540, 540, 66, 540, 66, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 81792 . Total input tokens: 18226101 . Total output tokens: 16350805
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 2.51228067278862,
    "estimated_duration": 3600.006957061281,
    "input_throughput": 1870.4288853643397,
    "output_throughput": 1691.3706202863739,
    "total_throughput": 3561.7995056507134,
    "itl": 33.50884091160062,
    "ttft": 4897.540988077522,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6142,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.619841099156357,
    "arrivals": 27512,
    "finished_requests": 27475,
    "scheduler_time": 5.373403362546105
}
#Debug simulation 
Total elapsed time: 2.512357017956674. Arrivals time: 0.07570996042340994 Scheduler time: 1.943845215253532 Scheduler overhead time: 0.1015533423051238 Adapter cache time: 0.24138468876481056 Engine time: 0.10091663524508476 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-8/adapters_384_slots_160_rate_0.025-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-8/adapters_384_slots_160_rate_0.025-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 270, 135, 66, 270, 270, 66, 135, 270, 270, 270, 270, 135, 135, 135, 135, 270, 270, 135, 135, 66, 270, 66, 270, 135, 135, 135, 66, 66, 135, 66, 270, 66, 270, 135, 270, 135, 66, 135, 270, 135, 270, 66, 270, 270, 270, 270, 66, 135, 135, 135, 270, 135, 66, 135, 66, 270, 135, 270, 270, 135, 270, 270, 66, 66, 270, 135, 135, 66, 66, 66, 135, 66, 135, 66, 270, 66, 135, 270, 66, 270, 135, 66, 270, 270, 270, 270, 135, 66, 135, 270, 270, 135, 66, 66, 270, 135, 135, 66, 66, 270, 135, 270, 135, 270, 270, 135, 270, 270, 66, 135, 135, 135, 135, 66, 66, 270, 66, 270, 66, 66, 66, 135, 135, 270, 66, 66, 270, 66, 270, 135, 66, 270, 135, 135, 66, 270, 270, 270, 66, 135, 270, 66, 270, 135, 135, 270, 270, 66, 135, 270, 66, 135, 135, 66, 135, 66, 135, 270, 270, 135, 66, 270, 66, 270, 135, 135, 135, 135, 135, 66, 66, 270, 66, 270, 66, 135, 270, 135, 270, 135, 270, 135, 270, 66, 135, 135, 135, 135, 135, 135, 135, 135, 270, 66, 66, 66, 66, 66, 135, 66, 66, 135, 270, 270, 66, 66, 270, 66, 66, 66, 135, 66, 135, 270, 270, 135, 135, 66, 270, 135, 270, 66, 135, 135, 66, 66, 135, 66, 270, 270, 66, 270, 270, 66, 135, 270, 66, 66, 135, 135, 66, 66, 270, 270, 270, 270, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 270, 135, 135, 135, 270, 66, 135, 135, 270, 270, 66, 270, 270, 66, 270, 66, 66, 135, 66, 270, 270, 270, 135, 66, 270, 270, 135, 135, 270, 270, 66, 270, 270, 135, 66, 270, 135, 135, 270, 270, 270, 66, 270, 66, 270, 270, 66, 66, 270, 66, 135, 270, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 270, 66, 66, 66, 135, 66, 135, 135, 66, 270, 135, 270, 66, 270, 66, 135, 135, 135, 135, 66, 135, 270, 270, 66, 270, 270, 66, 270, 135, 270, 135, 135, 135, 66, 135, 66, 66, 270, 66, 135, 66, 66, 135, 270, 135, 270, 66, 270, 270, 135, 270, 135, 66, 270, 66, 270, 270, 66, 66, 66]
Prompts retrieved: 60288 . Total input tokens: 13366582 . Total output tokens: 12077996
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 1.9735843520611525,
    "estimated_duration": 3599.929245829512,
    "input_throughput": 1401.6072693221363,
    "output_throughput": 1224.9293524611776,
    "total_throughput": 2626.536621783314,
    "itl": 26.947358915565722,
    "ttft": 7503.293886874825,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9841,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 30.118259888045017,
    "arrivals": 20275,
    "finished_requests": 20233,
    "scheduler_time": 0.1053758329003137
}
#Debug simulation 
Total elapsed time: 1.9736686237156391. Arrivals time: 0.059720158111304045 Scheduler time: 1.4065410709008574 Scheduler overhead time: 0.11833574157208204 Adapter cache time: 0.21741226967424154 Engine time: 0.1141444006934762 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-16/adapters_384_slots_160_rate_0.025-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-16/adapters_384_slots_160_rate_0.025-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 270, 135, 66, 270, 270, 66, 135, 270, 270, 270, 270, 135, 135, 135, 135, 270, 270, 135, 135, 66, 270, 66, 270, 135, 135, 135, 66, 66, 135, 66, 270, 66, 270, 135, 270, 135, 66, 135, 270, 135, 270, 66, 270, 270, 270, 270, 66, 135, 135, 135, 270, 135, 66, 135, 66, 270, 135, 270, 270, 135, 270, 270, 66, 66, 270, 135, 135, 66, 66, 66, 135, 66, 135, 66, 270, 66, 135, 270, 66, 270, 135, 66, 270, 270, 270, 270, 135, 66, 135, 270, 270, 135, 66, 66, 270, 135, 135, 66, 66, 270, 135, 270, 135, 270, 270, 135, 270, 270, 66, 135, 135, 135, 135, 66, 66, 270, 66, 270, 66, 66, 66, 135, 135, 270, 66, 66, 270, 66, 270, 135, 66, 270, 135, 135, 66, 270, 270, 270, 66, 135, 270, 66, 270, 135, 135, 270, 270, 66, 135, 270, 66, 135, 135, 66, 135, 66, 135, 270, 270, 135, 66, 270, 66, 270, 135, 135, 135, 135, 135, 66, 66, 270, 66, 270, 66, 135, 270, 135, 270, 135, 270, 135, 270, 66, 135, 135, 135, 135, 135, 135, 135, 135, 270, 66, 66, 66, 66, 66, 135, 66, 66, 135, 270, 270, 66, 66, 270, 66, 66, 66, 135, 66, 135, 270, 270, 135, 135, 66, 270, 135, 270, 66, 135, 135, 66, 66, 135, 66, 270, 270, 66, 270, 270, 66, 135, 270, 66, 66, 135, 135, 66, 66, 270, 270, 270, 270, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 270, 135, 135, 135, 270, 66, 135, 135, 270, 270, 66, 270, 270, 66, 270, 66, 66, 135, 66, 270, 270, 270, 135, 66, 270, 270, 135, 135, 270, 270, 66, 270, 270, 135, 66, 270, 135, 135, 270, 270, 270, 66, 270, 66, 270, 270, 66, 66, 270, 66, 135, 270, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 270, 66, 66, 66, 135, 66, 135, 135, 66, 270, 135, 270, 66, 270, 66, 135, 135, 135, 135, 66, 135, 270, 270, 66, 270, 270, 66, 270, 135, 270, 135, 135, 135, 66, 135, 66, 66, 270, 66, 135, 66, 66, 135, 270, 135, 270, 66, 270, 270, 135, 270, 135, 66, 270, 66, 270, 270, 66, 66, 66]
Prompts retrieved: 60288 . Total input tokens: 13366582 . Total output tokens: 12077996
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 1.988085919059813,
    "estimated_duration": 3599.936858276746,
    "input_throughput": 1401.6043054753245,
    "output_throughput": 1224.9267622185073,
    "total_throughput": 2626.5310676938316,
    "itl": 26.97141673250299,
    "ttft": 7503.485886806231,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9841,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 32.112007766191404,
    "arrivals": 20275,
    "finished_requests": 20233,
    "scheduler_time": 0.1068167022850436
}
#Debug simulation 
Total elapsed time: 1.988160707987845. Arrivals time: 0.06099581252783537 Scheduler time: 1.4192862515337765 Scheduler overhead time: 0.11819216841831803 Adapter cache time: 0.2172090238891542 Engine time: 0.11486145434901118 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-32/adapters_384_slots_160_rate_0.025-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-32/adapters_384_slots_160_rate_0.025-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 270, 135, 66, 270, 270, 66, 135, 270, 270, 270, 270, 135, 135, 135, 135, 270, 270, 135, 135, 66, 270, 66, 270, 135, 135, 135, 66, 66, 135, 66, 270, 66, 270, 135, 270, 135, 66, 135, 270, 135, 270, 66, 270, 270, 270, 270, 66, 135, 135, 135, 270, 135, 66, 135, 66, 270, 135, 270, 270, 135, 270, 270, 66, 66, 270, 135, 135, 66, 66, 66, 135, 66, 135, 66, 270, 66, 135, 270, 66, 270, 135, 66, 270, 270, 270, 270, 135, 66, 135, 270, 270, 135, 66, 66, 270, 135, 135, 66, 66, 270, 135, 270, 135, 270, 270, 135, 270, 270, 66, 135, 135, 135, 135, 66, 66, 270, 66, 270, 66, 66, 66, 135, 135, 270, 66, 66, 270, 66, 270, 135, 66, 270, 135, 135, 66, 270, 270, 270, 66, 135, 270, 66, 270, 135, 135, 270, 270, 66, 135, 270, 66, 135, 135, 66, 135, 66, 135, 270, 270, 135, 66, 270, 66, 270, 135, 135, 135, 135, 135, 66, 66, 270, 66, 270, 66, 135, 270, 135, 270, 135, 270, 135, 270, 66, 135, 135, 135, 135, 135, 135, 135, 135, 270, 66, 66, 66, 66, 66, 135, 66, 66, 135, 270, 270, 66, 66, 270, 66, 66, 66, 135, 66, 135, 270, 270, 135, 135, 66, 270, 135, 270, 66, 135, 135, 66, 66, 135, 66, 270, 270, 66, 270, 270, 66, 135, 270, 66, 66, 135, 135, 66, 66, 270, 270, 270, 270, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 270, 135, 135, 135, 270, 66, 135, 135, 270, 270, 66, 270, 270, 66, 270, 66, 66, 135, 66, 270, 270, 270, 135, 66, 270, 270, 135, 135, 270, 270, 66, 270, 270, 135, 66, 270, 135, 135, 270, 270, 270, 66, 270, 66, 270, 270, 66, 66, 270, 66, 135, 270, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 270, 66, 66, 66, 135, 66, 135, 135, 66, 270, 135, 270, 66, 270, 66, 135, 135, 135, 135, 66, 135, 270, 270, 66, 270, 270, 66, 270, 135, 270, 135, 135, 135, 66, 135, 66, 66, 270, 66, 135, 66, 66, 135, 270, 135, 270, 66, 270, 270, 135, 270, 135, 66, 270, 66, 270, 270, 66, 66, 66]
Prompts retrieved: 60288 . Total input tokens: 13366582 . Total output tokens: 12077996
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 1.9869979261420667,
    "estimated_duration": 3599.953148738704,
    "input_throughput": 1401.597962953443,
    "output_throughput": 1224.9212191955855,
    "total_throughput": 2626.5191821490284,
    "itl": 26.97241725561654,
    "ttft": 7503.518607312523,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9843,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 32.1754327999631,
    "arrivals": 20275,
    "finished_requests": 20233,
    "scheduler_time": 0.10669452405779735
}
#Debug simulation 
Total elapsed time: 1.9870846862904727. Arrivals time: 0.06000956008210778 Scheduler time: 1.4182462473399937 Scheduler overhead time: 0.11741321533918381 Adapter cache time: 0.21816784981638193 Engine time: 0.11561747035011649 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-16/adapters_384_slots_160_rate_0.025-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-16/adapters_384_slots_160_rate_0.025-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 270, 135, 66, 270, 270, 66, 135, 270, 270, 270, 270, 135, 135, 135, 135, 270, 270, 135, 135, 66, 270, 66, 270, 135, 135, 135, 66, 66, 135, 66, 270, 66, 270, 135, 270, 135, 66, 135, 270, 135, 270, 66, 270, 270, 270, 270, 66, 135, 135, 135, 270, 135, 66, 135, 66, 270, 135, 270, 270, 135, 270, 270, 66, 66, 270, 135, 135, 66, 66, 66, 135, 66, 135, 66, 270, 66, 135, 270, 66, 270, 135, 66, 270, 270, 270, 270, 135, 66, 135, 270, 270, 135, 66, 66, 270, 135, 135, 66, 66, 270, 135, 270, 135, 270, 270, 135, 270, 270, 66, 135, 135, 135, 135, 66, 66, 270, 66, 270, 66, 66, 66, 135, 135, 270, 66, 66, 270, 66, 270, 135, 66, 270, 135, 135, 66, 270, 270, 270, 66, 135, 270, 66, 270, 135, 135, 270, 270, 66, 135, 270, 66, 135, 135, 66, 135, 66, 135, 270, 270, 135, 66, 270, 66, 270, 135, 135, 135, 135, 135, 66, 66, 270, 66, 270, 66, 135, 270, 135, 270, 135, 270, 135, 270, 66, 135, 135, 135, 135, 135, 135, 135, 135, 270, 66, 66, 66, 66, 66, 135, 66, 66, 135, 270, 270, 66, 66, 270, 66, 66, 66, 135, 66, 135, 270, 270, 135, 135, 66, 270, 135, 270, 66, 135, 135, 66, 66, 135, 66, 270, 270, 66, 270, 270, 66, 135, 270, 66, 66, 135, 135, 66, 66, 270, 270, 270, 270, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 270, 135, 135, 135, 270, 66, 135, 135, 270, 270, 66, 270, 270, 66, 270, 66, 66, 135, 66, 270, 270, 270, 135, 66, 270, 270, 135, 135, 270, 270, 66, 270, 270, 135, 66, 270, 135, 135, 270, 270, 270, 66, 270, 66, 270, 270, 66, 66, 270, 66, 135, 270, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 270, 66, 66, 66, 135, 66, 135, 135, 66, 270, 135, 270, 66, 270, 66, 135, 135, 135, 135, 66, 135, 270, 270, 66, 270, 270, 66, 270, 135, 270, 135, 135, 135, 66, 135, 66, 66, 270, 66, 135, 66, 66, 135, 270, 135, 270, 66, 270, 270, 135, 270, 135, 66, 270, 66, 270, 270, 66, 66, 66]
Prompts retrieved: 60288 . Total input tokens: 13366582 . Total output tokens: 12077996
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 1.9968934278003871,
    "estimated_duration": 3599.9302892864557,
    "input_throughput": 1401.6068630595923,
    "output_throughput": 1224.9289974095695,
    "total_throughput": 2626.535860469162,
    "itl": 26.956223145600873,
    "ttft": 7503.278181033265,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9840,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 30.774545405871265,
    "arrivals": 20275,
    "finished_requests": 20233,
    "scheduler_time": 0.10592500955392888
}
#Debug simulation 
Total elapsed time: 1.9969684458337724. Arrivals time: 0.06045061768963933 Scheduler time: 1.4242157568223774 Scheduler overhead time: 0.1184833119623363 Adapter cache time: 0.2190324137918651 Engine time: 0.11702125100418925 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-32/adapters_384_slots_160_rate_0.025-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-32/adapters_384_slots_160_rate_0.025-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 270, 135, 66, 270, 270, 66, 135, 270, 270, 270, 270, 135, 135, 135, 135, 270, 270, 135, 135, 66, 270, 66, 270, 135, 135, 135, 66, 66, 135, 66, 270, 66, 270, 135, 270, 135, 66, 135, 270, 135, 270, 66, 270, 270, 270, 270, 66, 135, 135, 135, 270, 135, 66, 135, 66, 270, 135, 270, 270, 135, 270, 270, 66, 66, 270, 135, 135, 66, 66, 66, 135, 66, 135, 66, 270, 66, 135, 270, 66, 270, 135, 66, 270, 270, 270, 270, 135, 66, 135, 270, 270, 135, 66, 66, 270, 135, 135, 66, 66, 270, 135, 270, 135, 270, 270, 135, 270, 270, 66, 135, 135, 135, 135, 66, 66, 270, 66, 270, 66, 66, 66, 135, 135, 270, 66, 66, 270, 66, 270, 135, 66, 270, 135, 135, 66, 270, 270, 270, 66, 135, 270, 66, 270, 135, 135, 270, 270, 66, 135, 270, 66, 135, 135, 66, 135, 66, 135, 270, 270, 135, 66, 270, 66, 270, 135, 135, 135, 135, 135, 66, 66, 270, 66, 270, 66, 135, 270, 135, 270, 135, 270, 135, 270, 66, 135, 135, 135, 135, 135, 135, 135, 135, 270, 66, 66, 66, 66, 66, 135, 66, 66, 135, 270, 270, 66, 66, 270, 66, 66, 66, 135, 66, 135, 270, 270, 135, 135, 66, 270, 135, 270, 66, 135, 135, 66, 66, 135, 66, 270, 270, 66, 270, 270, 66, 135, 270, 66, 66, 135, 135, 66, 66, 270, 270, 270, 270, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 270, 135, 135, 135, 270, 66, 135, 135, 270, 270, 66, 270, 270, 66, 270, 66, 66, 135, 66, 270, 270, 270, 135, 66, 270, 270, 135, 135, 270, 270, 66, 270, 270, 135, 66, 270, 135, 135, 270, 270, 270, 66, 270, 66, 270, 270, 66, 66, 270, 66, 135, 270, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 270, 66, 66, 66, 135, 66, 135, 135, 66, 270, 135, 270, 66, 270, 66, 135, 135, 135, 135, 66, 135, 270, 270, 66, 270, 270, 66, 270, 135, 270, 135, 135, 135, 66, 135, 66, 66, 270, 66, 135, 66, 66, 135, 270, 135, 270, 66, 270, 270, 135, 270, 135, 66, 270, 66, 270, 270, 66, 66, 66]
Prompts retrieved: 60288 . Total input tokens: 13366582 . Total output tokens: 12077996
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 1.9751213761046529,
    "estimated_duration": 3599.9343370507117,
    "input_throughput": 1401.60528709358,
    "output_throughput": 1224.9276201000557,
    "total_throughput": 2626.5329071936358,
    "itl": 26.977832017913265,
    "ttft": 7503.526401586656,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9839,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 32.57304458843513,
    "arrivals": 20275,
    "finished_requests": 20233,
    "scheduler_time": 0.10696352472654945
}
#Debug simulation 
Total elapsed time: 1.9752218420617282. Arrivals time: 0.060255417600274086 Scheduler time: 1.4045138559304178 Scheduler overhead time: 0.11842215294018388 Adapter cache time: 0.21807326702401042 Engine time: 0.11619743471965194 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-16/adapters_384_slots_160_rate_0.025-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-16/adapters_384_slots_160_rate_0.025-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 270, 135, 66, 270, 270, 66, 135, 270, 270, 270, 270, 135, 135, 135, 135, 270, 270, 135, 135, 66, 270, 66, 270, 135, 135, 135, 66, 66, 135, 66, 270, 66, 270, 135, 270, 135, 66, 135, 270, 135, 270, 66, 270, 270, 270, 270, 66, 135, 135, 135, 270, 135, 66, 135, 66, 270, 135, 270, 270, 135, 270, 270, 66, 66, 270, 135, 135, 66, 66, 66, 135, 66, 135, 66, 270, 66, 135, 270, 66, 270, 135, 66, 270, 270, 270, 270, 135, 66, 135, 270, 270, 135, 66, 66, 270, 135, 135, 66, 66, 270, 135, 270, 135, 270, 270, 135, 270, 270, 66, 135, 135, 135, 135, 66, 66, 270, 66, 270, 66, 66, 66, 135, 135, 270, 66, 66, 270, 66, 270, 135, 66, 270, 135, 135, 66, 270, 270, 270, 66, 135, 270, 66, 270, 135, 135, 270, 270, 66, 135, 270, 66, 135, 135, 66, 135, 66, 135, 270, 270, 135, 66, 270, 66, 270, 135, 135, 135, 135, 135, 66, 66, 270, 66, 270, 66, 135, 270, 135, 270, 135, 270, 135, 270, 66, 135, 135, 135, 135, 135, 135, 135, 135, 270, 66, 66, 66, 66, 66, 135, 66, 66, 135, 270, 270, 66, 66, 270, 66, 66, 66, 135, 66, 135, 270, 270, 135, 135, 66, 270, 135, 270, 66, 135, 135, 66, 66, 135, 66, 270, 270, 66, 270, 270, 66, 135, 270, 66, 66, 135, 135, 66, 66, 270, 270, 270, 270, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 270, 135, 135, 135, 270, 66, 135, 135, 270, 270, 66, 270, 270, 66, 270, 66, 66, 135, 66, 270, 270, 270, 135, 66, 270, 270, 135, 135, 270, 270, 66, 270, 270, 135, 66, 270, 135, 135, 270, 270, 270, 66, 270, 66, 270, 270, 66, 66, 270, 66, 135, 270, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 270, 66, 66, 66, 135, 66, 135, 135, 66, 270, 135, 270, 66, 270, 66, 135, 135, 135, 135, 66, 135, 270, 270, 66, 270, 270, 66, 270, 135, 270, 135, 135, 135, 66, 135, 66, 66, 270, 66, 135, 66, 66, 135, 270, 135, 270, 66, 270, 270, 135, 270, 135, 66, 270, 66, 270, 270, 66, 66, 66]
Prompts retrieved: 60288 . Total input tokens: 13366582 . Total output tokens: 12077996
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 1.9741349471732974,
    "estimated_duration": 3599.942565993126,
    "input_throughput": 1401.6020832288007,
    "output_throughput": 1224.9248200945938,
    "total_throughput": 2626.5269033233944,
    "itl": 26.93840655202649,
    "ttft": 7503.33571215178,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9838,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.416114801244984,
    "arrivals": 20275,
    "finished_requests": 20233,
    "scheduler_time": 0.10497681463224032
}
#Debug simulation 
Total elapsed time: 1.974226191174239. Arrivals time: 0.05996535951271653 Scheduler time: 1.4064963907003403 Scheduler overhead time: 0.11810169275850058 Adapter cache time: 0.2181642595678568 Engine time: 0.11406423291191459 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-32/adapters_384_slots_160_rate_0.025-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-32/adapters_384_slots_160_rate_0.025-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 270, 135, 66, 270, 270, 66, 135, 270, 270, 270, 270, 135, 135, 135, 135, 270, 270, 135, 135, 66, 270, 66, 270, 135, 135, 135, 66, 66, 135, 66, 270, 66, 270, 135, 270, 135, 66, 135, 270, 135, 270, 66, 270, 270, 270, 270, 66, 135, 135, 135, 270, 135, 66, 135, 66, 270, 135, 270, 270, 135, 270, 270, 66, 66, 270, 135, 135, 66, 66, 66, 135, 66, 135, 66, 270, 66, 135, 270, 66, 270, 135, 66, 270, 270, 270, 270, 135, 66, 135, 270, 270, 135, 66, 66, 270, 135, 135, 66, 66, 270, 135, 270, 135, 270, 270, 135, 270, 270, 66, 135, 135, 135, 135, 66, 66, 270, 66, 270, 66, 66, 66, 135, 135, 270, 66, 66, 270, 66, 270, 135, 66, 270, 135, 135, 66, 270, 270, 270, 66, 135, 270, 66, 270, 135, 135, 270, 270, 66, 135, 270, 66, 135, 135, 66, 135, 66, 135, 270, 270, 135, 66, 270, 66, 270, 135, 135, 135, 135, 135, 66, 66, 270, 66, 270, 66, 135, 270, 135, 270, 135, 270, 135, 270, 66, 135, 135, 135, 135, 135, 135, 135, 135, 270, 66, 66, 66, 66, 66, 135, 66, 66, 135, 270, 270, 66, 66, 270, 66, 66, 66, 135, 66, 135, 270, 270, 135, 135, 66, 270, 135, 270, 66, 135, 135, 66, 66, 135, 66, 270, 270, 66, 270, 270, 66, 135, 270, 66, 66, 135, 135, 66, 66, 270, 270, 270, 270, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 270, 135, 135, 135, 270, 66, 135, 135, 270, 270, 66, 270, 270, 66, 270, 66, 66, 135, 66, 270, 270, 270, 135, 66, 270, 270, 135, 135, 270, 270, 66, 270, 270, 135, 66, 270, 135, 135, 270, 270, 270, 66, 270, 66, 270, 270, 66, 66, 270, 66, 135, 270, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 270, 66, 66, 66, 135, 66, 135, 135, 66, 270, 135, 270, 66, 270, 66, 135, 135, 135, 135, 66, 135, 270, 270, 66, 270, 270, 66, 270, 135, 270, 135, 135, 135, 66, 135, 66, 66, 270, 66, 135, 66, 66, 135, 270, 135, 270, 66, 270, 270, 135, 270, 135, 66, 270, 66, 270, 270, 66, 66, 66]
Prompts retrieved: 60288 . Total input tokens: 13366582 . Total output tokens: 12077996
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 1.9904719381593168,
    "estimated_duration": 3599.9321625684324,
    "input_throughput": 1401.6061337111612,
    "output_throughput": 1224.9283599982768,
    "total_throughput": 2626.534493709438,
    "itl": 26.983359663415037,
    "ttft": 7503.411049223132,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9840,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 32.99153289153925,
    "arrivals": 20275,
    "finished_requests": 20233,
    "scheduler_time": 0.10730875113806579
}
#Debug simulation 
Total elapsed time: 1.9905585409142077. Arrivals time: 0.06244386686012149 Scheduler time: 1.4153804052621126 Scheduler overhead time: 0.11796194547787309 Adapter cache time: 0.2200610446743667 Engine time: 0.11732286401093006 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-8/adapters_384_slots_160_rate_0.025-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-8/adapters_384_slots_160_rate_0.025-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 270, 135, 33, 270, 270, 33, 135, 270, 270, 270, 270, 135, 135, 135, 135, 270, 270, 135, 135, 33, 270, 33, 270, 135, 135, 135, 33, 33, 135, 33, 270, 33, 270, 135, 270, 135, 33, 135, 270, 135, 270, 33, 270, 270, 270, 270, 33, 135, 135, 135, 270, 135, 33, 135, 33, 270, 135, 270, 270, 135, 270, 270, 33, 33, 270, 135, 135, 33, 33, 33, 135, 33, 135, 33, 270, 33, 135, 270, 33, 270, 135, 33, 270, 270, 270, 270, 135, 33, 135, 270, 270, 135, 33, 33, 270, 135, 135, 33, 33, 270, 135, 270, 135, 270, 270, 135, 270, 270, 33, 135, 135, 135, 135, 33, 33, 270, 33, 270, 33, 33, 33, 135, 135, 270, 33, 33, 270, 33, 270, 135, 33, 270, 135, 135, 33, 270, 270, 270, 33, 135, 270, 33, 270, 135, 135, 270, 270, 33, 135, 270, 33, 135, 135, 33, 135, 33, 135, 270, 270, 135, 33, 270, 33, 270, 135, 135, 135, 135, 135, 33, 33, 270, 33, 270, 33, 135, 270, 135, 270, 135, 270, 135, 270, 33, 135, 135, 135, 135, 135, 135, 135, 135, 270, 33, 33, 33, 33, 33, 135, 33, 33, 135, 270, 270, 33, 33, 270, 33, 33, 33, 135, 33, 135, 270, 270, 135, 135, 33, 270, 135, 270, 33, 135, 135, 33, 33, 135, 33, 270, 270, 33, 270, 270, 33, 135, 270, 33, 33, 135, 135, 33, 33, 270, 270, 270, 270, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 270, 135, 135, 135, 270, 33, 135, 135, 270, 270, 33, 270, 270, 33, 270, 33, 33, 135, 33, 270, 270, 270, 135, 33, 270, 270, 135, 135, 270, 270, 33, 270, 270, 135, 33, 270, 135, 135, 270, 270, 270, 33, 270, 33, 270, 270, 33, 33, 270, 33, 135, 270, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 270, 33, 33, 33, 135, 33, 135, 135, 33, 270, 135, 270, 33, 270, 33, 135, 135, 135, 135, 33, 135, 270, 270, 33, 270, 270, 33, 270, 135, 270, 135, 135, 135, 33, 135, 33, 33, 270, 33, 135, 33, 33, 135, 270, 135, 270, 33, 270, 270, 135, 270, 135, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 56064 . Total input tokens: 12441396 . Total output tokens: 11225519
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 1.9044461320154369,
    "estimated_duration": 3598.9711667929373,
    "input_throughput": 1267.8317742862098,
    "output_throughput": 1156.6569464099018,
    "total_throughput": 2424.4887206961116,
    "itl": 26.010402193459147,
    "ttft": 10329.774942106173,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8164,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.98582194146812,
    "arrivals": 18900,
    "finished_requests": 18846,
    "scheduler_time": 0.022359124751036536
}
#Debug simulation 
Total elapsed time: 1.904516365379095. Arrivals time: 0.0572804887779057 Scheduler time: 1.3450903412885964 Scheduler overhead time: 0.12105423584580421 Adapter cache time: 0.20135605335235596 Engine time: 0.12020570179447532 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-16/adapters_384_slots_160_rate_0.025-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-16/adapters_384_slots_160_rate_0.025-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 270, 135, 33, 270, 270, 33, 135, 270, 270, 270, 270, 135, 135, 135, 135, 270, 270, 135, 135, 33, 270, 33, 270, 135, 135, 135, 33, 33, 135, 33, 270, 33, 270, 135, 270, 135, 33, 135, 270, 135, 270, 33, 270, 270, 270, 270, 33, 135, 135, 135, 270, 135, 33, 135, 33, 270, 135, 270, 270, 135, 270, 270, 33, 33, 270, 135, 135, 33, 33, 33, 135, 33, 135, 33, 270, 33, 135, 270, 33, 270, 135, 33, 270, 270, 270, 270, 135, 33, 135, 270, 270, 135, 33, 33, 270, 135, 135, 33, 33, 270, 135, 270, 135, 270, 270, 135, 270, 270, 33, 135, 135, 135, 135, 33, 33, 270, 33, 270, 33, 33, 33, 135, 135, 270, 33, 33, 270, 33, 270, 135, 33, 270, 135, 135, 33, 270, 270, 270, 33, 135, 270, 33, 270, 135, 135, 270, 270, 33, 135, 270, 33, 135, 135, 33, 135, 33, 135, 270, 270, 135, 33, 270, 33, 270, 135, 135, 135, 135, 135, 33, 33, 270, 33, 270, 33, 135, 270, 135, 270, 135, 270, 135, 270, 33, 135, 135, 135, 135, 135, 135, 135, 135, 270, 33, 33, 33, 33, 33, 135, 33, 33, 135, 270, 270, 33, 33, 270, 33, 33, 33, 135, 33, 135, 270, 270, 135, 135, 33, 270, 135, 270, 33, 135, 135, 33, 33, 135, 33, 270, 270, 33, 270, 270, 33, 135, 270, 33, 33, 135, 135, 33, 33, 270, 270, 270, 270, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 270, 135, 135, 135, 270, 33, 135, 135, 270, 270, 33, 270, 270, 33, 270, 33, 33, 135, 33, 270, 270, 270, 135, 33, 270, 270, 135, 135, 270, 270, 33, 270, 270, 135, 33, 270, 135, 135, 270, 270, 270, 33, 270, 33, 270, 270, 33, 33, 270, 33, 135, 270, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 270, 33, 33, 33, 135, 33, 135, 135, 33, 270, 135, 270, 33, 270, 33, 135, 135, 135, 135, 33, 135, 270, 270, 33, 270, 270, 33, 270, 135, 270, 135, 135, 135, 33, 135, 33, 33, 270, 33, 135, 33, 33, 135, 270, 135, 270, 33, 270, 270, 135, 270, 135, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 56064 . Total input tokens: 12441396 . Total output tokens: 11225519
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 1.886916486080736,
    "estimated_duration": 3598.974502490715,
    "input_throughput": 1267.8305992004653,
    "output_throughput": 1156.655874366184,
    "total_throughput": 2424.4864735666492,
    "itl": 26.031432462838556,
    "ttft": 10329.916264722377,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8165,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.677787317351434,
    "arrivals": 18900,
    "finished_requests": 18846,
    "scheduler_time": 0.022652519390040073
}
#Debug simulation 
Total elapsed time: 1.8869874780066311. Arrivals time: 0.0566161572933197 Scheduler time: 1.3294205353595316 Scheduler overhead time: 0.12198713608086109 Adapter cache time: 0.20043421257287264 Engine time: 0.11951885418966413 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-32/adapters_384_slots_160_rate_0.025-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-32/adapters_384_slots_160_rate_0.025-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 270, 135, 33, 270, 270, 33, 135, 270, 270, 270, 270, 135, 135, 135, 135, 270, 270, 135, 135, 33, 270, 33, 270, 135, 135, 135, 33, 33, 135, 33, 270, 33, 270, 135, 270, 135, 33, 135, 270, 135, 270, 33, 270, 270, 270, 270, 33, 135, 135, 135, 270, 135, 33, 135, 33, 270, 135, 270, 270, 135, 270, 270, 33, 33, 270, 135, 135, 33, 33, 33, 135, 33, 135, 33, 270, 33, 135, 270, 33, 270, 135, 33, 270, 270, 270, 270, 135, 33, 135, 270, 270, 135, 33, 33, 270, 135, 135, 33, 33, 270, 135, 270, 135, 270, 270, 135, 270, 270, 33, 135, 135, 135, 135, 33, 33, 270, 33, 270, 33, 33, 33, 135, 135, 270, 33, 33, 270, 33, 270, 135, 33, 270, 135, 135, 33, 270, 270, 270, 33, 135, 270, 33, 270, 135, 135, 270, 270, 33, 135, 270, 33, 135, 135, 33, 135, 33, 135, 270, 270, 135, 33, 270, 33, 270, 135, 135, 135, 135, 135, 33, 33, 270, 33, 270, 33, 135, 270, 135, 270, 135, 270, 135, 270, 33, 135, 135, 135, 135, 135, 135, 135, 135, 270, 33, 33, 33, 33, 33, 135, 33, 33, 135, 270, 270, 33, 33, 270, 33, 33, 33, 135, 33, 135, 270, 270, 135, 135, 33, 270, 135, 270, 33, 135, 135, 33, 33, 135, 33, 270, 270, 33, 270, 270, 33, 135, 270, 33, 33, 135, 135, 33, 33, 270, 270, 270, 270, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 270, 135, 135, 135, 270, 33, 135, 135, 270, 270, 33, 270, 270, 33, 270, 33, 33, 135, 33, 270, 270, 270, 135, 33, 270, 270, 135, 135, 270, 270, 33, 270, 270, 135, 33, 270, 135, 135, 270, 270, 270, 33, 270, 33, 270, 270, 33, 33, 270, 33, 135, 270, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 270, 33, 33, 33, 135, 33, 135, 135, 33, 270, 135, 270, 33, 270, 33, 135, 135, 135, 135, 33, 135, 270, 270, 33, 270, 270, 33, 270, 135, 270, 135, 135, 135, 33, 135, 33, 33, 270, 33, 135, 33, 33, 135, 270, 135, 270, 33, 270, 270, 135, 270, 135, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 56064 . Total input tokens: 12441396 . Total output tokens: 11225519
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 1.888649060856551,
    "estimated_duration": 3598.9622654169334,
    "input_throughput": 1267.834910036601,
    "output_throughput": 1156.6598071896567,
    "total_throughput": 2424.4947172262578,
    "itl": 26.032913843555413,
    "ttft": 10329.878603834208,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8164,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.715976248551787,
    "arrivals": 18900,
    "finished_requests": 18846,
    "scheduler_time": 0.02268629558238036
}
#Debug simulation 
Total elapsed time: 1.888724714051932. Arrivals time: 0.05670464504510164 Scheduler time: 1.33289629034698 Scheduler overhead time: 0.12127519678324461 Adapter cache time: 0.20080897491425276 Engine time: 0.11786523880437016 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-16/adapters_384_slots_160_rate_0.025-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-16/adapters_384_slots_160_rate_0.025-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 270, 135, 33, 270, 270, 33, 135, 270, 270, 270, 270, 135, 135, 135, 135, 270, 270, 135, 135, 33, 270, 33, 270, 135, 135, 135, 33, 33, 135, 33, 270, 33, 270, 135, 270, 135, 33, 135, 270, 135, 270, 33, 270, 270, 270, 270, 33, 135, 135, 135, 270, 135, 33, 135, 33, 270, 135, 270, 270, 135, 270, 270, 33, 33, 270, 135, 135, 33, 33, 33, 135, 33, 135, 33, 270, 33, 135, 270, 33, 270, 135, 33, 270, 270, 270, 270, 135, 33, 135, 270, 270, 135, 33, 33, 270, 135, 135, 33, 33, 270, 135, 270, 135, 270, 270, 135, 270, 270, 33, 135, 135, 135, 135, 33, 33, 270, 33, 270, 33, 33, 33, 135, 135, 270, 33, 33, 270, 33, 270, 135, 33, 270, 135, 135, 33, 270, 270, 270, 33, 135, 270, 33, 270, 135, 135, 270, 270, 33, 135, 270, 33, 135, 135, 33, 135, 33, 135, 270, 270, 135, 33, 270, 33, 270, 135, 135, 135, 135, 135, 33, 33, 270, 33, 270, 33, 135, 270, 135, 270, 135, 270, 135, 270, 33, 135, 135, 135, 135, 135, 135, 135, 135, 270, 33, 33, 33, 33, 33, 135, 33, 33, 135, 270, 270, 33, 33, 270, 33, 33, 33, 135, 33, 135, 270, 270, 135, 135, 33, 270, 135, 270, 33, 135, 135, 33, 33, 135, 33, 270, 270, 33, 270, 270, 33, 135, 270, 33, 33, 135, 135, 33, 33, 270, 270, 270, 270, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 270, 135, 135, 135, 270, 33, 135, 135, 270, 270, 33, 270, 270, 33, 270, 33, 33, 135, 33, 270, 270, 270, 135, 33, 270, 270, 135, 135, 270, 270, 33, 270, 270, 135, 33, 270, 135, 135, 270, 270, 270, 33, 270, 33, 270, 270, 33, 33, 270, 33, 135, 270, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 270, 33, 33, 33, 135, 33, 135, 135, 33, 270, 135, 270, 33, 270, 33, 135, 135, 135, 135, 33, 135, 270, 270, 33, 270, 270, 33, 270, 135, 270, 135, 135, 135, 33, 135, 33, 33, 270, 33, 135, 33, 33, 135, 270, 135, 270, 33, 270, 270, 135, 270, 135, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 56064 . Total input tokens: 12441396 . Total output tokens: 11225519
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 1.896706904284656,
    "estimated_duration": 3598.9490226597177,
    "input_throughput": 1267.8395751846201,
    "output_throughput": 1156.664063255778,
    "total_throughput": 2424.503638440398,
    "itl": 26.0184636715947,
    "ttft": 10329.736601391063,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8164,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.577310241726646,
    "arrivals": 18900,
    "finished_requests": 18846,
    "scheduler_time": 0.022499984168475106
}
#Debug simulation 
Total elapsed time: 1.8967803809791803. Arrivals time: 0.056798400823026896 Scheduler time: 1.3406632794067264 Scheduler overhead time: 0.12121570343151689 Adapter cache time: 0.20054215658456087 Engine time: 0.11834857286885381 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-32/adapters_384_slots_160_rate_0.025-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-32/adapters_384_slots_160_rate_0.025-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 270, 135, 33, 270, 270, 33, 135, 270, 270, 270, 270, 135, 135, 135, 135, 270, 270, 135, 135, 33, 270, 33, 270, 135, 135, 135, 33, 33, 135, 33, 270, 33, 270, 135, 270, 135, 33, 135, 270, 135, 270, 33, 270, 270, 270, 270, 33, 135, 135, 135, 270, 135, 33, 135, 33, 270, 135, 270, 270, 135, 270, 270, 33, 33, 270, 135, 135, 33, 33, 33, 135, 33, 135, 33, 270, 33, 135, 270, 33, 270, 135, 33, 270, 270, 270, 270, 135, 33, 135, 270, 270, 135, 33, 33, 270, 135, 135, 33, 33, 270, 135, 270, 135, 270, 270, 135, 270, 270, 33, 135, 135, 135, 135, 33, 33, 270, 33, 270, 33, 33, 33, 135, 135, 270, 33, 33, 270, 33, 270, 135, 33, 270, 135, 135, 33, 270, 270, 270, 33, 135, 270, 33, 270, 135, 135, 270, 270, 33, 135, 270, 33, 135, 135, 33, 135, 33, 135, 270, 270, 135, 33, 270, 33, 270, 135, 135, 135, 135, 135, 33, 33, 270, 33, 270, 33, 135, 270, 135, 270, 135, 270, 135, 270, 33, 135, 135, 135, 135, 135, 135, 135, 135, 270, 33, 33, 33, 33, 33, 135, 33, 33, 135, 270, 270, 33, 33, 270, 33, 33, 33, 135, 33, 135, 270, 270, 135, 135, 33, 270, 135, 270, 33, 135, 135, 33, 33, 135, 33, 270, 270, 33, 270, 270, 33, 135, 270, 33, 33, 135, 135, 33, 33, 270, 270, 270, 270, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 270, 135, 135, 135, 270, 33, 135, 135, 270, 270, 33, 270, 270, 33, 270, 33, 33, 135, 33, 270, 270, 270, 135, 33, 270, 270, 135, 135, 270, 270, 33, 270, 270, 135, 33, 270, 135, 135, 270, 270, 270, 33, 270, 33, 270, 270, 33, 33, 270, 33, 135, 270, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 270, 33, 33, 33, 135, 33, 135, 135, 33, 270, 135, 270, 33, 270, 33, 135, 135, 135, 135, 33, 135, 270, 270, 33, 270, 270, 33, 270, 135, 270, 135, 135, 135, 33, 135, 33, 33, 270, 33, 135, 33, 33, 135, 270, 135, 270, 33, 270, 270, 135, 270, 135, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 56064 . Total input tokens: 12441396 . Total output tokens: 11225519
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 1.8955413550138474,
    "estimated_duration": 3598.9747286381157,
    "input_throughput": 1267.8305195342782,
    "output_throughput": 1156.6558016858405,
    "total_throughput": 2424.4863212201185,
    "itl": 26.034356702083812,
    "ttft": 10329.929137549147,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8163,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.05024439873098,
    "arrivals": 18900,
    "finished_requests": 18846,
    "scheduler_time": 0.022740546058934646
}
#Debug simulation 
Total elapsed time: 1.8956345058977604. Arrivals time: 0.05675104772672057 Scheduler time: 1.3402622155845165 Scheduler overhead time: 0.1209276202134788 Adapter cache time: 0.2007651817984879 Engine time: 0.11800414603203535 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-16/adapters_384_slots_160_rate_0.025-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-16/adapters_384_slots_160_rate_0.025-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 270, 135, 33, 270, 270, 33, 135, 270, 270, 270, 270, 135, 135, 135, 135, 270, 270, 135, 135, 33, 270, 33, 270, 135, 135, 135, 33, 33, 135, 33, 270, 33, 270, 135, 270, 135, 33, 135, 270, 135, 270, 33, 270, 270, 270, 270, 33, 135, 135, 135, 270, 135, 33, 135, 33, 270, 135, 270, 270, 135, 270, 270, 33, 33, 270, 135, 135, 33, 33, 33, 135, 33, 135, 33, 270, 33, 135, 270, 33, 270, 135, 33, 270, 270, 270, 270, 135, 33, 135, 270, 270, 135, 33, 33, 270, 135, 135, 33, 33, 270, 135, 270, 135, 270, 270, 135, 270, 270, 33, 135, 135, 135, 135, 33, 33, 270, 33, 270, 33, 33, 33, 135, 135, 270, 33, 33, 270, 33, 270, 135, 33, 270, 135, 135, 33, 270, 270, 270, 33, 135, 270, 33, 270, 135, 135, 270, 270, 33, 135, 270, 33, 135, 135, 33, 135, 33, 135, 270, 270, 135, 33, 270, 33, 270, 135, 135, 135, 135, 135, 33, 33, 270, 33, 270, 33, 135, 270, 135, 270, 135, 270, 135, 270, 33, 135, 135, 135, 135, 135, 135, 135, 135, 270, 33, 33, 33, 33, 33, 135, 33, 33, 135, 270, 270, 33, 33, 270, 33, 33, 33, 135, 33, 135, 270, 270, 135, 135, 33, 270, 135, 270, 33, 135, 135, 33, 33, 135, 33, 270, 270, 33, 270, 270, 33, 135, 270, 33, 33, 135, 135, 33, 33, 270, 270, 270, 270, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 270, 135, 135, 135, 270, 33, 135, 135, 270, 270, 33, 270, 270, 33, 270, 33, 33, 135, 33, 270, 270, 270, 135, 33, 270, 270, 135, 135, 270, 270, 33, 270, 270, 135, 33, 270, 135, 135, 270, 270, 270, 33, 270, 33, 270, 270, 33, 33, 270, 33, 135, 270, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 270, 33, 33, 33, 135, 33, 135, 135, 33, 270, 135, 270, 33, 270, 33, 135, 135, 135, 135, 33, 135, 270, 270, 33, 270, 270, 33, 270, 135, 270, 135, 135, 135, 33, 135, 33, 33, 270, 33, 135, 33, 33, 135, 270, 135, 270, 33, 270, 270, 135, 270, 135, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 56064 . Total input tokens: 12441396 . Total output tokens: 11225519
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 1.8754724669270217,
    "estimated_duration": 3598.970083900478,
    "input_throughput": 1267.8324336208007,
    "output_throughput": 1156.7478759056896,
    "total_throughput": 2424.5803095264905,
    "itl": 26.006905798057982,
    "ttft": 10139.108514422389,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8163,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.407780557285506,
    "arrivals": 18900,
    "finished_requests": 18847,
    "scheduler_time": 0.02233377167277225
}
#Debug simulation 
Total elapsed time: 1.8755408828146756. Arrivals time: 0.056341512594372034 Scheduler time: 1.3227674337103963 Scheduler overhead time: 0.12148793833330274 Adapter cache time: 0.19891784945502877 Engine time: 0.11680488660931587 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-32/adapters_384_slots_160_rate_0.025-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-32/adapters_384_slots_160_rate_0.025-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 270, 135, 33, 270, 270, 33, 135, 270, 270, 270, 270, 135, 135, 135, 135, 270, 270, 135, 135, 33, 270, 33, 270, 135, 135, 135, 33, 33, 135, 33, 270, 33, 270, 135, 270, 135, 33, 135, 270, 135, 270, 33, 270, 270, 270, 270, 33, 135, 135, 135, 270, 135, 33, 135, 33, 270, 135, 270, 270, 135, 270, 270, 33, 33, 270, 135, 135, 33, 33, 33, 135, 33, 135, 33, 270, 33, 135, 270, 33, 270, 135, 33, 270, 270, 270, 270, 135, 33, 135, 270, 270, 135, 33, 33, 270, 135, 135, 33, 33, 270, 135, 270, 135, 270, 270, 135, 270, 270, 33, 135, 135, 135, 135, 33, 33, 270, 33, 270, 33, 33, 33, 135, 135, 270, 33, 33, 270, 33, 270, 135, 33, 270, 135, 135, 33, 270, 270, 270, 33, 135, 270, 33, 270, 135, 135, 270, 270, 33, 135, 270, 33, 135, 135, 33, 135, 33, 135, 270, 270, 135, 33, 270, 33, 270, 135, 135, 135, 135, 135, 33, 33, 270, 33, 270, 33, 135, 270, 135, 270, 135, 270, 135, 270, 33, 135, 135, 135, 135, 135, 135, 135, 135, 270, 33, 33, 33, 33, 33, 135, 33, 33, 135, 270, 270, 33, 33, 270, 33, 33, 33, 135, 33, 135, 270, 270, 135, 135, 33, 270, 135, 270, 33, 135, 135, 33, 33, 135, 33, 270, 270, 33, 270, 270, 33, 135, 270, 33, 33, 135, 135, 33, 33, 270, 270, 270, 270, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 270, 135, 135, 135, 270, 33, 135, 135, 270, 270, 33, 270, 270, 33, 270, 33, 33, 135, 33, 270, 270, 270, 135, 33, 270, 270, 135, 135, 270, 270, 33, 270, 270, 135, 33, 270, 135, 135, 270, 270, 270, 33, 270, 33, 270, 270, 33, 33, 270, 33, 135, 270, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 270, 33, 33, 33, 135, 33, 135, 135, 33, 270, 135, 270, 33, 270, 33, 135, 135, 135, 135, 33, 135, 270, 270, 33, 270, 270, 33, 270, 135, 270, 135, 135, 135, 33, 135, 33, 33, 270, 33, 135, 33, 33, 135, 270, 135, 270, 33, 270, 270, 135, 270, 135, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 56064 . Total input tokens: 12441396 . Total output tokens: 11225519
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 1.891306122764945,
    "estimated_duration": 3598.9684093798455,
    "input_throughput": 1267.8327456578736,
    "output_throughput": 1156.6578326030115,
    "total_throughput": 2424.4905782608853,
    "itl": 26.03982664147311,
    "ttft": 10329.893936253431,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8165,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.415821497922387,
    "arrivals": 18900,
    "finished_requests": 18846,
    "scheduler_time": 0.02276089522114478
}
#Debug simulation 
Total elapsed time: 1.8913791826926172. Arrivals time: 0.056487949565052986 Scheduler time: 1.3359222235158086 Scheduler overhead time: 0.12102341093122959 Adapter cache time: 0.20011173328384757 Engine time: 0.11882852530106902 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-8/adapters_384_slots_160_rate_0.025-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-8/adapters_384_slots_160_rate_0.025-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 270, 66, 33, 270, 270, 33, 66, 270, 270, 270, 270, 66, 66, 66, 66, 270, 270, 66, 66, 33, 270, 33, 270, 66, 66, 66, 33, 33, 66, 33, 270, 33, 270, 66, 270, 66, 33, 66, 270, 66, 270, 33, 270, 270, 270, 270, 33, 66, 66, 66, 270, 66, 33, 66, 33, 270, 66, 270, 270, 66, 270, 270, 33, 33, 270, 66, 66, 33, 33, 33, 66, 33, 66, 33, 270, 33, 66, 270, 33, 270, 66, 33, 270, 270, 270, 270, 66, 33, 66, 270, 270, 66, 33, 33, 270, 66, 66, 33, 33, 270, 66, 270, 66, 270, 270, 66, 270, 270, 33, 66, 66, 66, 66, 33, 33, 270, 33, 270, 33, 33, 33, 66, 66, 270, 33, 33, 270, 33, 270, 66, 33, 270, 66, 66, 33, 270, 270, 270, 33, 66, 270, 33, 270, 66, 66, 270, 270, 33, 66, 270, 33, 66, 66, 33, 66, 33, 66, 270, 270, 66, 33, 270, 33, 270, 66, 66, 66, 66, 66, 33, 33, 270, 33, 270, 33, 66, 270, 66, 270, 66, 270, 66, 270, 33, 66, 66, 66, 66, 66, 66, 66, 66, 270, 33, 33, 33, 33, 33, 66, 33, 33, 66, 270, 270, 33, 33, 270, 33, 33, 33, 66, 33, 66, 270, 270, 66, 66, 33, 270, 66, 270, 33, 66, 66, 33, 33, 66, 33, 270, 270, 33, 270, 270, 33, 66, 270, 33, 33, 66, 66, 33, 33, 270, 270, 270, 270, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 270, 66, 66, 66, 270, 33, 66, 66, 270, 270, 33, 270, 270, 33, 270, 33, 33, 66, 33, 270, 270, 270, 66, 33, 270, 270, 66, 66, 270, 270, 33, 270, 270, 66, 33, 270, 66, 66, 270, 270, 270, 33, 270, 33, 270, 270, 33, 33, 270, 33, 66, 270, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 270, 33, 33, 33, 66, 33, 66, 66, 33, 270, 66, 270, 33, 270, 33, 66, 66, 66, 66, 33, 66, 270, 270, 33, 270, 270, 33, 270, 66, 270, 66, 66, 66, 33, 66, 33, 33, 270, 33, 66, 33, 33, 66, 270, 66, 270, 33, 270, 270, 66, 270, 66, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 47232 . Total input tokens: 10467415 . Total output tokens: 9475189
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 1.6995167951099575,
    "estimated_duration": 3599.9290197287687,
    "input_throughput": 1096.9377391495136,
    "output_throughput": 1001.5414138003335,
    "total_throughput": 2098.479152949847,
    "itl": 24.205525749355708,
    "ttft": 5629.5280987373735,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5832,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.84876452261462,
    "arrivals": 16104,
    "finished_requests": 16079,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6995844352059066. Arrivals time: 0.05023398483172059 Scheduler time: 1.1630056570284069 Scheduler overhead time: 0.12756837625056505 Adapter cache time: 0.1712934891693294 Engine time: 0.12519146176055074 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-16/adapters_384_slots_160_rate_0.025-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-16/adapters_384_slots_160_rate_0.025-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 270, 66, 33, 270, 270, 33, 66, 270, 270, 270, 270, 66, 66, 66, 66, 270, 270, 66, 66, 33, 270, 33, 270, 66, 66, 66, 33, 33, 66, 33, 270, 33, 270, 66, 270, 66, 33, 66, 270, 66, 270, 33, 270, 270, 270, 270, 33, 66, 66, 66, 270, 66, 33, 66, 33, 270, 66, 270, 270, 66, 270, 270, 33, 33, 270, 66, 66, 33, 33, 33, 66, 33, 66, 33, 270, 33, 66, 270, 33, 270, 66, 33, 270, 270, 270, 270, 66, 33, 66, 270, 270, 66, 33, 33, 270, 66, 66, 33, 33, 270, 66, 270, 66, 270, 270, 66, 270, 270, 33, 66, 66, 66, 66, 33, 33, 270, 33, 270, 33, 33, 33, 66, 66, 270, 33, 33, 270, 33, 270, 66, 33, 270, 66, 66, 33, 270, 270, 270, 33, 66, 270, 33, 270, 66, 66, 270, 270, 33, 66, 270, 33, 66, 66, 33, 66, 33, 66, 270, 270, 66, 33, 270, 33, 270, 66, 66, 66, 66, 66, 33, 33, 270, 33, 270, 33, 66, 270, 66, 270, 66, 270, 66, 270, 33, 66, 66, 66, 66, 66, 66, 66, 66, 270, 33, 33, 33, 33, 33, 66, 33, 33, 66, 270, 270, 33, 33, 270, 33, 33, 33, 66, 33, 66, 270, 270, 66, 66, 33, 270, 66, 270, 33, 66, 66, 33, 33, 66, 33, 270, 270, 33, 270, 270, 33, 66, 270, 33, 33, 66, 66, 33, 33, 270, 270, 270, 270, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 270, 66, 66, 66, 270, 33, 66, 66, 270, 270, 33, 270, 270, 33, 270, 33, 33, 66, 33, 270, 270, 270, 66, 33, 270, 270, 66, 66, 270, 270, 33, 270, 270, 66, 33, 270, 66, 66, 270, 270, 270, 33, 270, 33, 270, 270, 33, 33, 270, 33, 66, 270, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 270, 33, 33, 33, 66, 33, 66, 66, 33, 270, 66, 270, 33, 270, 33, 66, 66, 66, 66, 33, 66, 270, 270, 33, 270, 270, 33, 270, 66, 270, 66, 66, 66, 33, 66, 33, 33, 270, 33, 66, 33, 33, 66, 270, 66, 270, 33, 270, 270, 66, 270, 66, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 47232 . Total input tokens: 10467415 . Total output tokens: 9475189
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 1.7073490894399583,
    "estimated_duration": 3599.9483874246785,
    "input_throughput": 1096.9318376325257,
    "output_throughput": 1001.5360255148762,
    "total_throughput": 2098.4678631474017,
    "itl": 24.218673270648452,
    "ttft": 5629.516121215979,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5833,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.040205446539897,
    "arrivals": 16104,
    "finished_requests": 16079,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.7074409262277186. Arrivals time: 0.05113163962960243 Scheduler time: 1.167995112016797 Scheduler overhead time: 0.1267718323506415 Adapter cache time: 0.17114641051739454 Engine time: 0.12784990342333913 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-32/adapters_384_slots_160_rate_0.025-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-32/adapters_384_slots_160_rate_0.025-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 270, 66, 33, 270, 270, 33, 66, 270, 270, 270, 270, 66, 66, 66, 66, 270, 270, 66, 66, 33, 270, 33, 270, 66, 66, 66, 33, 33, 66, 33, 270, 33, 270, 66, 270, 66, 33, 66, 270, 66, 270, 33, 270, 270, 270, 270, 33, 66, 66, 66, 270, 66, 33, 66, 33, 270, 66, 270, 270, 66, 270, 270, 33, 33, 270, 66, 66, 33, 33, 33, 66, 33, 66, 33, 270, 33, 66, 270, 33, 270, 66, 33, 270, 270, 270, 270, 66, 33, 66, 270, 270, 66, 33, 33, 270, 66, 66, 33, 33, 270, 66, 270, 66, 270, 270, 66, 270, 270, 33, 66, 66, 66, 66, 33, 33, 270, 33, 270, 33, 33, 33, 66, 66, 270, 33, 33, 270, 33, 270, 66, 33, 270, 66, 66, 33, 270, 270, 270, 33, 66, 270, 33, 270, 66, 66, 270, 270, 33, 66, 270, 33, 66, 66, 33, 66, 33, 66, 270, 270, 66, 33, 270, 33, 270, 66, 66, 66, 66, 66, 33, 33, 270, 33, 270, 33, 66, 270, 66, 270, 66, 270, 66, 270, 33, 66, 66, 66, 66, 66, 66, 66, 66, 270, 33, 33, 33, 33, 33, 66, 33, 33, 66, 270, 270, 33, 33, 270, 33, 33, 33, 66, 33, 66, 270, 270, 66, 66, 33, 270, 66, 270, 33, 66, 66, 33, 33, 66, 33, 270, 270, 33, 270, 270, 33, 66, 270, 33, 33, 66, 66, 33, 33, 270, 270, 270, 270, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 270, 66, 66, 66, 270, 33, 66, 66, 270, 270, 33, 270, 270, 33, 270, 33, 33, 66, 33, 270, 270, 270, 66, 33, 270, 270, 66, 66, 270, 270, 33, 270, 270, 66, 33, 270, 66, 66, 270, 270, 270, 33, 270, 33, 270, 270, 33, 33, 270, 33, 66, 270, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 270, 33, 33, 33, 66, 33, 66, 66, 33, 270, 66, 270, 33, 270, 33, 66, 66, 66, 66, 33, 66, 270, 270, 33, 270, 270, 33, 270, 66, 270, 66, 66, 66, 33, 66, 33, 33, 270, 33, 66, 33, 33, 66, 270, 66, 270, 33, 270, 270, 66, 270, 66, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 47232 . Total input tokens: 10467415 . Total output tokens: 9475189
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 1.712081435136497,
    "estimated_duration": 3599.950820801477,
    "input_throughput": 1096.9310961644844,
    "output_throughput": 1001.5353485293703,
    "total_throughput": 2098.4664446938546,
    "itl": 24.21900139709565,
    "ttft": 5629.487690395541,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5834,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.076212904806326,
    "arrivals": 16104,
    "finished_requests": 16079,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.712167083285749. Arrivals time: 0.05196544295176864 Scheduler time: 1.1699207755737007 Scheduler overhead time: 0.12819305108860135 Adapter cache time: 0.17234205221757293 Engine time: 0.12717687571421266 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-16/adapters_384_slots_160_rate_0.025-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-16/adapters_384_slots_160_rate_0.025-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 270, 66, 33, 270, 270, 33, 66, 270, 270, 270, 270, 66, 66, 66, 66, 270, 270, 66, 66, 33, 270, 33, 270, 66, 66, 66, 33, 33, 66, 33, 270, 33, 270, 66, 270, 66, 33, 66, 270, 66, 270, 33, 270, 270, 270, 270, 33, 66, 66, 66, 270, 66, 33, 66, 33, 270, 66, 270, 270, 66, 270, 270, 33, 33, 270, 66, 66, 33, 33, 33, 66, 33, 66, 33, 270, 33, 66, 270, 33, 270, 66, 33, 270, 270, 270, 270, 66, 33, 66, 270, 270, 66, 33, 33, 270, 66, 66, 33, 33, 270, 66, 270, 66, 270, 270, 66, 270, 270, 33, 66, 66, 66, 66, 33, 33, 270, 33, 270, 33, 33, 33, 66, 66, 270, 33, 33, 270, 33, 270, 66, 33, 270, 66, 66, 33, 270, 270, 270, 33, 66, 270, 33, 270, 66, 66, 270, 270, 33, 66, 270, 33, 66, 66, 33, 66, 33, 66, 270, 270, 66, 33, 270, 33, 270, 66, 66, 66, 66, 66, 33, 33, 270, 33, 270, 33, 66, 270, 66, 270, 66, 270, 66, 270, 33, 66, 66, 66, 66, 66, 66, 66, 66, 270, 33, 33, 33, 33, 33, 66, 33, 33, 66, 270, 270, 33, 33, 270, 33, 33, 33, 66, 33, 66, 270, 270, 66, 66, 33, 270, 66, 270, 33, 66, 66, 33, 33, 66, 33, 270, 270, 33, 270, 270, 33, 66, 270, 33, 33, 66, 66, 33, 33, 270, 270, 270, 270, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 270, 66, 66, 66, 270, 33, 66, 66, 270, 270, 33, 270, 270, 33, 270, 33, 33, 66, 33, 270, 270, 270, 66, 33, 270, 270, 66, 66, 270, 270, 33, 270, 270, 66, 33, 270, 66, 66, 270, 270, 270, 33, 270, 33, 270, 270, 33, 33, 270, 33, 66, 270, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 270, 33, 33, 33, 66, 33, 66, 66, 33, 270, 66, 270, 33, 270, 33, 66, 66, 66, 66, 33, 66, 270, 270, 33, 270, 270, 33, 270, 66, 270, 66, 66, 66, 33, 66, 33, 33, 270, 33, 66, 33, 33, 66, 270, 66, 270, 33, 270, 270, 66, 270, 66, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 47232 . Total input tokens: 10467415 . Total output tokens: 9475189
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 1.730004210025072,
    "estimated_duration": 3599.9344389264033,
    "input_throughput": 1096.9360878632187,
    "output_throughput": 1001.5399061198598,
    "total_throughput": 2098.4759939830783,
    "itl": 24.2103327543602,
    "ttft": 5629.513902743699,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5830,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.24754947488728,
    "arrivals": 16104,
    "finished_requests": 16079,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.730080546811223. Arrivals time: 0.0515349879860878 Scheduler time: 1.1789145865477622 Scheduler overhead time: 0.13301189383491874 Adapter cache time: 0.17378754680976272 Engine time: 0.1294262376613915 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-32/adapters_384_slots_160_rate_0.025-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-32/adapters_384_slots_160_rate_0.025-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 270, 66, 33, 270, 270, 33, 66, 270, 270, 270, 270, 66, 66, 66, 66, 270, 270, 66, 66, 33, 270, 33, 270, 66, 66, 66, 33, 33, 66, 33, 270, 33, 270, 66, 270, 66, 33, 66, 270, 66, 270, 33, 270, 270, 270, 270, 33, 66, 66, 66, 270, 66, 33, 66, 33, 270, 66, 270, 270, 66, 270, 270, 33, 33, 270, 66, 66, 33, 33, 33, 66, 33, 66, 33, 270, 33, 66, 270, 33, 270, 66, 33, 270, 270, 270, 270, 66, 33, 66, 270, 270, 66, 33, 33, 270, 66, 66, 33, 33, 270, 66, 270, 66, 270, 270, 66, 270, 270, 33, 66, 66, 66, 66, 33, 33, 270, 33, 270, 33, 33, 33, 66, 66, 270, 33, 33, 270, 33, 270, 66, 33, 270, 66, 66, 33, 270, 270, 270, 33, 66, 270, 33, 270, 66, 66, 270, 270, 33, 66, 270, 33, 66, 66, 33, 66, 33, 66, 270, 270, 66, 33, 270, 33, 270, 66, 66, 66, 66, 66, 33, 33, 270, 33, 270, 33, 66, 270, 66, 270, 66, 270, 66, 270, 33, 66, 66, 66, 66, 66, 66, 66, 66, 270, 33, 33, 33, 33, 33, 66, 33, 33, 66, 270, 270, 33, 33, 270, 33, 33, 33, 66, 33, 66, 270, 270, 66, 66, 33, 270, 66, 270, 33, 66, 66, 33, 33, 66, 33, 270, 270, 33, 270, 270, 33, 66, 270, 33, 33, 66, 66, 33, 33, 270, 270, 270, 270, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 270, 66, 66, 66, 270, 33, 66, 66, 270, 270, 33, 270, 270, 33, 270, 33, 33, 66, 33, 270, 270, 270, 66, 33, 270, 270, 66, 66, 270, 270, 33, 270, 270, 66, 33, 270, 66, 66, 270, 270, 270, 33, 270, 33, 270, 270, 33, 33, 270, 33, 66, 270, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 270, 33, 33, 33, 66, 33, 66, 66, 33, 270, 66, 270, 33, 270, 33, 66, 66, 66, 66, 33, 66, 270, 270, 33, 270, 270, 33, 270, 66, 270, 66, 66, 66, 33, 66, 33, 33, 270, 33, 66, 33, 33, 66, 270, 66, 270, 33, 270, 270, 66, 270, 66, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 47232 . Total input tokens: 10467415 . Total output tokens: 9475189
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 1.7089908737689257,
    "estimated_duration": 3599.9462046691488,
    "input_throughput": 1096.9325027352518,
    "output_throughput": 1001.5366327762555,
    "total_throughput": 2098.4691355115074,
    "itl": 24.221667927409513,
    "ttft": 5629.705322001956,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5834,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.316945665868744,
    "arrivals": 16104,
    "finished_requests": 16079,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.709064960014075. Arrivals time: 0.050249356776475906 Scheduler time: 1.1714708828367293 Scheduler overhead time: 0.12748186336830258 Adapter cache time: 0.1719492068514228 Engine time: 0.12544850585982203 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-16/adapters_384_slots_160_rate_0.025-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-16/adapters_384_slots_160_rate_0.025-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 270, 66, 33, 270, 270, 33, 66, 270, 270, 270, 270, 66, 66, 66, 66, 270, 270, 66, 66, 33, 270, 33, 270, 66, 66, 66, 33, 33, 66, 33, 270, 33, 270, 66, 270, 66, 33, 66, 270, 66, 270, 33, 270, 270, 270, 270, 33, 66, 66, 66, 270, 66, 33, 66, 33, 270, 66, 270, 270, 66, 270, 270, 33, 33, 270, 66, 66, 33, 33, 33, 66, 33, 66, 33, 270, 33, 66, 270, 33, 270, 66, 33, 270, 270, 270, 270, 66, 33, 66, 270, 270, 66, 33, 33, 270, 66, 66, 33, 33, 270, 66, 270, 66, 270, 270, 66, 270, 270, 33, 66, 66, 66, 66, 33, 33, 270, 33, 270, 33, 33, 33, 66, 66, 270, 33, 33, 270, 33, 270, 66, 33, 270, 66, 66, 33, 270, 270, 270, 33, 66, 270, 33, 270, 66, 66, 270, 270, 33, 66, 270, 33, 66, 66, 33, 66, 33, 66, 270, 270, 66, 33, 270, 33, 270, 66, 66, 66, 66, 66, 33, 33, 270, 33, 270, 33, 66, 270, 66, 270, 66, 270, 66, 270, 33, 66, 66, 66, 66, 66, 66, 66, 66, 270, 33, 33, 33, 33, 33, 66, 33, 33, 66, 270, 270, 33, 33, 270, 33, 33, 33, 66, 33, 66, 270, 270, 66, 66, 33, 270, 66, 270, 33, 66, 66, 33, 33, 66, 33, 270, 270, 33, 270, 270, 33, 66, 270, 33, 33, 66, 66, 33, 33, 270, 270, 270, 270, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 270, 66, 66, 66, 270, 33, 66, 66, 270, 270, 33, 270, 270, 33, 270, 33, 33, 66, 33, 270, 270, 270, 66, 33, 270, 270, 66, 66, 270, 270, 33, 270, 270, 66, 33, 270, 66, 66, 270, 270, 270, 33, 270, 33, 270, 270, 33, 33, 270, 33, 66, 270, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 270, 33, 33, 33, 66, 33, 66, 66, 33, 270, 66, 270, 33, 270, 33, 66, 66, 66, 66, 33, 66, 270, 270, 33, 270, 270, 33, 270, 66, 270, 66, 66, 66, 33, 66, 33, 33, 270, 33, 66, 33, 33, 66, 270, 66, 270, 33, 270, 270, 66, 270, 66, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 47232 . Total input tokens: 10467415 . Total output tokens: 9475189
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 1.714667156804353,
    "estimated_duration": 3599.951636767908,
    "input_throughput": 1096.930847533658,
    "output_throughput": 1001.5351215209806,
    "total_throughput": 2098.4659690546387,
    "itl": 24.202500914356637,
    "ttft": 5629.406098303969,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5833,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.440963370165754,
    "arrivals": 16104,
    "finished_requests": 16079,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.714738525915891. Arrivals time: 0.05079667968675494 Scheduler time: 1.1761208628304303 Scheduler overhead time: 0.12813047505915165 Adapter cache time: 0.1712985527701676 Engine time: 0.1257345429621637 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-32/adapters_384_slots_160_rate_0.025-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-32/adapters_384_slots_160_rate_0.025-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 270, 66, 33, 270, 270, 33, 66, 270, 270, 270, 270, 66, 66, 66, 66, 270, 270, 66, 66, 33, 270, 33, 270, 66, 66, 66, 33, 33, 66, 33, 270, 33, 270, 66, 270, 66, 33, 66, 270, 66, 270, 33, 270, 270, 270, 270, 33, 66, 66, 66, 270, 66, 33, 66, 33, 270, 66, 270, 270, 66, 270, 270, 33, 33, 270, 66, 66, 33, 33, 33, 66, 33, 66, 33, 270, 33, 66, 270, 33, 270, 66, 33, 270, 270, 270, 270, 66, 33, 66, 270, 270, 66, 33, 33, 270, 66, 66, 33, 33, 270, 66, 270, 66, 270, 270, 66, 270, 270, 33, 66, 66, 66, 66, 33, 33, 270, 33, 270, 33, 33, 33, 66, 66, 270, 33, 33, 270, 33, 270, 66, 33, 270, 66, 66, 33, 270, 270, 270, 33, 66, 270, 33, 270, 66, 66, 270, 270, 33, 66, 270, 33, 66, 66, 33, 66, 33, 66, 270, 270, 66, 33, 270, 33, 270, 66, 66, 66, 66, 66, 33, 33, 270, 33, 270, 33, 66, 270, 66, 270, 66, 270, 66, 270, 33, 66, 66, 66, 66, 66, 66, 66, 66, 270, 33, 33, 33, 33, 33, 66, 33, 33, 66, 270, 270, 33, 33, 270, 33, 33, 33, 66, 33, 66, 270, 270, 66, 66, 33, 270, 66, 270, 33, 66, 66, 33, 33, 66, 33, 270, 270, 33, 270, 270, 33, 66, 270, 33, 33, 66, 66, 33, 33, 270, 270, 270, 270, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 270, 66, 66, 66, 270, 33, 66, 66, 270, 270, 33, 270, 270, 33, 270, 33, 33, 66, 33, 270, 270, 270, 66, 33, 270, 270, 66, 66, 270, 270, 33, 270, 270, 66, 33, 270, 66, 66, 270, 270, 270, 33, 270, 33, 270, 270, 33, 33, 270, 33, 66, 270, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 270, 33, 33, 33, 66, 33, 66, 66, 33, 270, 66, 270, 33, 270, 33, 66, 66, 66, 66, 33, 66, 270, 270, 33, 270, 270, 33, 270, 66, 270, 66, 66, 66, 33, 66, 33, 33, 270, 33, 66, 33, 33, 66, 270, 66, 270, 33, 270, 270, 66, 270, 66, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 47232 . Total input tokens: 10467415 . Total output tokens: 9475189
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 1.71058520488441,
    "estimated_duration": 3599.950079201775,
    "input_throughput": 1096.931322135333,
    "output_throughput": 1001.5355548484301,
    "total_throughput": 2098.466876983763,
    "itl": 24.223933999877143,
    "ttft": 5629.680766872053,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5836,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.575089017598344,
    "arrivals": 16104,
    "finished_requests": 16079,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.7106590536423028. Arrivals time: 0.05129427183419466 Scheduler time: 1.1671729497611523 Scheduler overhead time: 0.1283350712619722 Adapter cache time: 0.1716126943938434 Engine time: 0.129408476408571 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-8/adapters_384_slots_160_rate_0.0125-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-8/adapters_384_slots_160_rate_0.0125-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 135, 66, 33, 135, 135, 33, 66, 135, 135, 135, 135, 66, 66, 66, 66, 135, 135, 66, 66, 33, 135, 33, 135, 66, 66, 66, 33, 33, 66, 33, 135, 33, 135, 66, 135, 66, 33, 66, 135, 66, 135, 33, 135, 135, 135, 135, 33, 66, 66, 66, 135, 66, 33, 66, 33, 135, 66, 135, 135, 66, 135, 135, 33, 33, 135, 66, 66, 33, 33, 33, 66, 33, 66, 33, 135, 33, 66, 135, 33, 135, 66, 33, 135, 135, 135, 135, 66, 33, 66, 135, 135, 66, 33, 33, 135, 66, 66, 33, 33, 135, 66, 135, 66, 135, 135, 66, 135, 135, 33, 66, 66, 66, 66, 33, 33, 135, 33, 135, 33, 33, 33, 66, 66, 135, 33, 33, 135, 33, 135, 66, 33, 135, 66, 66, 33, 135, 135, 135, 33, 66, 135, 33, 135, 66, 66, 135, 135, 33, 66, 135, 33, 66, 66, 33, 66, 33, 66, 135, 135, 66, 33, 135, 33, 135, 66, 66, 66, 66, 66, 33, 33, 135, 33, 135, 33, 66, 135, 66, 135, 66, 135, 66, 135, 33, 66, 66, 66, 66, 66, 66, 66, 66, 135, 33, 33, 33, 33, 33, 66, 33, 33, 66, 135, 135, 33, 33, 135, 33, 33, 33, 66, 33, 66, 135, 135, 66, 66, 33, 135, 66, 135, 33, 66, 66, 33, 33, 66, 33, 135, 135, 33, 135, 135, 33, 66, 135, 33, 33, 66, 66, 33, 33, 135, 135, 135, 135, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 135, 66, 66, 66, 135, 33, 66, 66, 135, 135, 33, 135, 135, 33, 135, 33, 33, 66, 33, 135, 135, 135, 66, 33, 135, 135, 66, 66, 135, 135, 33, 135, 135, 66, 33, 135, 66, 66, 135, 135, 135, 33, 135, 33, 135, 135, 33, 33, 135, 33, 66, 135, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 135, 33, 33, 33, 66, 33, 66, 66, 33, 135, 66, 135, 33, 135, 33, 66, 66, 66, 66, 33, 66, 135, 135, 33, 135, 135, 33, 135, 66, 135, 66, 66, 66, 33, 66, 33, 33, 135, 33, 66, 33, 33, 66, 135, 66, 135, 33, 135, 135, 66, 135, 66, 33, 135, 33, 135, 135, 33, 33, 33]
Prompts retrieved: 29952 . Total input tokens: 6581748 . Total output tokens: 6022685
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 1.2776868753135204,
    "estimated_duration": 3599.910460901834,
    "input_throughput": 679.464677404014,
    "output_throughput": 621.0640581987984,
    "total_throughput": 1300.5287356028125,
    "itl": 20.931379581311983,
    "ttft": 5694.764100263141,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5052,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.461584082346608,
    "arrivals": 10179,
    "finished_requests": 10163,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2777608600445092. Arrivals time: 0.03791885916143656 Scheduler time: 0.7662540446035564 Scheduler overhead time: 0.14134437683969736 Adapter cache time: 0.12321272771805525 Engine time: 0.1392572857439518 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-16/adapters_384_slots_160_rate_0.0125-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-16/adapters_384_slots_160_rate_0.0125-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 135, 66, 33, 135, 135, 33, 66, 135, 135, 135, 135, 66, 66, 66, 66, 135, 135, 66, 66, 33, 135, 33, 135, 66, 66, 66, 33, 33, 66, 33, 135, 33, 135, 66, 135, 66, 33, 66, 135, 66, 135, 33, 135, 135, 135, 135, 33, 66, 66, 66, 135, 66, 33, 66, 33, 135, 66, 135, 135, 66, 135, 135, 33, 33, 135, 66, 66, 33, 33, 33, 66, 33, 66, 33, 135, 33, 66, 135, 33, 135, 66, 33, 135, 135, 135, 135, 66, 33, 66, 135, 135, 66, 33, 33, 135, 66, 66, 33, 33, 135, 66, 135, 66, 135, 135, 66, 135, 135, 33, 66, 66, 66, 66, 33, 33, 135, 33, 135, 33, 33, 33, 66, 66, 135, 33, 33, 135, 33, 135, 66, 33, 135, 66, 66, 33, 135, 135, 135, 33, 66, 135, 33, 135, 66, 66, 135, 135, 33, 66, 135, 33, 66, 66, 33, 66, 33, 66, 135, 135, 66, 33, 135, 33, 135, 66, 66, 66, 66, 66, 33, 33, 135, 33, 135, 33, 66, 135, 66, 135, 66, 135, 66, 135, 33, 66, 66, 66, 66, 66, 66, 66, 66, 135, 33, 33, 33, 33, 33, 66, 33, 33, 66, 135, 135, 33, 33, 135, 33, 33, 33, 66, 33, 66, 135, 135, 66, 66, 33, 135, 66, 135, 33, 66, 66, 33, 33, 66, 33, 135, 135, 33, 135, 135, 33, 66, 135, 33, 33, 66, 66, 33, 33, 135, 135, 135, 135, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 135, 66, 66, 66, 135, 33, 66, 66, 135, 135, 33, 135, 135, 33, 135, 33, 33, 66, 33, 135, 135, 135, 66, 33, 135, 135, 66, 66, 135, 135, 33, 135, 135, 66, 33, 135, 66, 66, 135, 135, 135, 33, 135, 33, 135, 135, 33, 33, 135, 33, 66, 135, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 135, 33, 33, 33, 66, 33, 66, 66, 33, 135, 66, 135, 33, 135, 33, 66, 66, 66, 66, 33, 66, 135, 135, 33, 135, 135, 33, 135, 66, 135, 66, 66, 66, 33, 66, 33, 33, 135, 33, 66, 33, 33, 66, 135, 66, 135, 33, 135, 135, 66, 135, 66, 33, 135, 33, 135, 135, 33, 33, 33]
Prompts retrieved: 29952 . Total input tokens: 6581748 . Total output tokens: 6022685
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 1.296504896134138,
    "estimated_duration": 3599.9088514048944,
    "input_throughput": 679.4649811884608,
    "output_throughput": 621.0643358726903,
    "total_throughput": 1300.529317061151,
    "itl": 20.94019337893976,
    "ttft": 5694.865002429671,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5051,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.48951655033834,
    "arrivals": 10179,
    "finished_requests": 10163,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2965940870344639. Arrivals time: 0.03807491576299071 Scheduler time: 0.7828344800509512 Scheduler overhead time: 0.14062709221616387 Adapter cache time: 0.12496391125023365 Engine time: 0.14032958960160613 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-32/adapters_384_slots_160_rate_0.0125-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-32/adapters_384_slots_160_rate_0.0125-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 135, 66, 33, 135, 135, 33, 66, 135, 135, 135, 135, 66, 66, 66, 66, 135, 135, 66, 66, 33, 135, 33, 135, 66, 66, 66, 33, 33, 66, 33, 135, 33, 135, 66, 135, 66, 33, 66, 135, 66, 135, 33, 135, 135, 135, 135, 33, 66, 66, 66, 135, 66, 33, 66, 33, 135, 66, 135, 135, 66, 135, 135, 33, 33, 135, 66, 66, 33, 33, 33, 66, 33, 66, 33, 135, 33, 66, 135, 33, 135, 66, 33, 135, 135, 135, 135, 66, 33, 66, 135, 135, 66, 33, 33, 135, 66, 66, 33, 33, 135, 66, 135, 66, 135, 135, 66, 135, 135, 33, 66, 66, 66, 66, 33, 33, 135, 33, 135, 33, 33, 33, 66, 66, 135, 33, 33, 135, 33, 135, 66, 33, 135, 66, 66, 33, 135, 135, 135, 33, 66, 135, 33, 135, 66, 66, 135, 135, 33, 66, 135, 33, 66, 66, 33, 66, 33, 66, 135, 135, 66, 33, 135, 33, 135, 66, 66, 66, 66, 66, 33, 33, 135, 33, 135, 33, 66, 135, 66, 135, 66, 135, 66, 135, 33, 66, 66, 66, 66, 66, 66, 66, 66, 135, 33, 33, 33, 33, 33, 66, 33, 33, 66, 135, 135, 33, 33, 135, 33, 33, 33, 66, 33, 66, 135, 135, 66, 66, 33, 135, 66, 135, 33, 66, 66, 33, 33, 66, 33, 135, 135, 33, 135, 135, 33, 66, 135, 33, 33, 66, 66, 33, 33, 135, 135, 135, 135, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 135, 66, 66, 66, 135, 33, 66, 66, 135, 135, 33, 135, 135, 33, 135, 33, 33, 66, 33, 135, 135, 135, 66, 33, 135, 135, 66, 66, 135, 135, 33, 135, 135, 66, 33, 135, 66, 66, 135, 135, 135, 33, 135, 33, 135, 135, 33, 33, 135, 33, 66, 135, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 135, 33, 33, 33, 66, 33, 66, 66, 33, 135, 66, 135, 33, 135, 33, 66, 66, 66, 66, 33, 66, 135, 135, 33, 135, 135, 33, 135, 66, 135, 66, 66, 66, 33, 66, 33, 33, 135, 33, 66, 33, 33, 66, 135, 66, 135, 33, 135, 135, 66, 135, 66, 33, 135, 33, 135, 135, 33, 33, 33]
Prompts retrieved: 29952 . Total input tokens: 6581748 . Total output tokens: 6022685
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 1.2830324838869274,
    "estimated_duration": 3599.897164965941,
    "input_throughput": 679.4671869531422,
    "output_throughput": 621.0663520498516,
    "total_throughput": 1300.5335390029938,
    "itl": 20.939715268588554,
    "ttft": 5694.9236464562055,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5051,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.51743170156942,
    "arrivals": 10179,
    "finished_requests": 10163,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.283105369657278. Arrivals time: 0.037424024660140276 Scheduler time: 0.7700871778652072 Scheduler overhead time: 0.14144837344065309 Adapter cache time: 0.12487943610176444 Engine time: 0.13953551556915045 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-16/adapters_384_slots_160_rate_0.0125-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-16/adapters_384_slots_160_rate_0.0125-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 135, 66, 33, 135, 135, 33, 66, 135, 135, 135, 135, 66, 66, 66, 66, 135, 135, 66, 66, 33, 135, 33, 135, 66, 66, 66, 33, 33, 66, 33, 135, 33, 135, 66, 135, 66, 33, 66, 135, 66, 135, 33, 135, 135, 135, 135, 33, 66, 66, 66, 135, 66, 33, 66, 33, 135, 66, 135, 135, 66, 135, 135, 33, 33, 135, 66, 66, 33, 33, 33, 66, 33, 66, 33, 135, 33, 66, 135, 33, 135, 66, 33, 135, 135, 135, 135, 66, 33, 66, 135, 135, 66, 33, 33, 135, 66, 66, 33, 33, 135, 66, 135, 66, 135, 135, 66, 135, 135, 33, 66, 66, 66, 66, 33, 33, 135, 33, 135, 33, 33, 33, 66, 66, 135, 33, 33, 135, 33, 135, 66, 33, 135, 66, 66, 33, 135, 135, 135, 33, 66, 135, 33, 135, 66, 66, 135, 135, 33, 66, 135, 33, 66, 66, 33, 66, 33, 66, 135, 135, 66, 33, 135, 33, 135, 66, 66, 66, 66, 66, 33, 33, 135, 33, 135, 33, 66, 135, 66, 135, 66, 135, 66, 135, 33, 66, 66, 66, 66, 66, 66, 66, 66, 135, 33, 33, 33, 33, 33, 66, 33, 33, 66, 135, 135, 33, 33, 135, 33, 33, 33, 66, 33, 66, 135, 135, 66, 66, 33, 135, 66, 135, 33, 66, 66, 33, 33, 66, 33, 135, 135, 33, 135, 135, 33, 66, 135, 33, 33, 66, 66, 33, 33, 135, 135, 135, 135, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 135, 66, 66, 66, 135, 33, 66, 66, 135, 135, 33, 135, 135, 33, 135, 33, 33, 66, 33, 135, 135, 135, 66, 33, 135, 135, 66, 66, 135, 135, 33, 135, 135, 66, 33, 135, 66, 66, 135, 135, 135, 33, 135, 33, 135, 135, 33, 33, 135, 33, 66, 135, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 135, 33, 33, 33, 66, 33, 66, 66, 33, 135, 66, 135, 33, 135, 33, 66, 66, 66, 66, 33, 66, 135, 135, 33, 135, 135, 33, 135, 66, 135, 66, 66, 66, 33, 66, 33, 33, 135, 33, 66, 33, 33, 66, 135, 66, 135, 33, 135, 135, 66, 135, 66, 33, 135, 33, 135, 135, 33, 33, 33]
Prompts retrieved: 29952 . Total input tokens: 6581748 . Total output tokens: 6022685
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 1.2879641000181437,
    "estimated_duration": 3599.9027621586633,
    "input_throughput": 679.4661305054977,
    "output_throughput": 621.0653864048619,
    "total_throughput": 1300.5315169103596,
    "itl": 20.93334414848657,
    "ttft": 5694.895889983442,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5052,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.809335228201467,
    "arrivals": 10179,
    "finished_requests": 10163,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2880591680295765. Arrivals time: 0.038208148907870054 Scheduler time: 0.7751196334138513 Scheduler overhead time: 0.14160421583801508 Adapter cache time: 0.12342263711616397 Engine time: 0.13945413986220956 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-32/adapters_384_slots_160_rate_0.0125-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-32/adapters_384_slots_160_rate_0.0125-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 135, 66, 33, 135, 135, 33, 66, 135, 135, 135, 135, 66, 66, 66, 66, 135, 135, 66, 66, 33, 135, 33, 135, 66, 66, 66, 33, 33, 66, 33, 135, 33, 135, 66, 135, 66, 33, 66, 135, 66, 135, 33, 135, 135, 135, 135, 33, 66, 66, 66, 135, 66, 33, 66, 33, 135, 66, 135, 135, 66, 135, 135, 33, 33, 135, 66, 66, 33, 33, 33, 66, 33, 66, 33, 135, 33, 66, 135, 33, 135, 66, 33, 135, 135, 135, 135, 66, 33, 66, 135, 135, 66, 33, 33, 135, 66, 66, 33, 33, 135, 66, 135, 66, 135, 135, 66, 135, 135, 33, 66, 66, 66, 66, 33, 33, 135, 33, 135, 33, 33, 33, 66, 66, 135, 33, 33, 135, 33, 135, 66, 33, 135, 66, 66, 33, 135, 135, 135, 33, 66, 135, 33, 135, 66, 66, 135, 135, 33, 66, 135, 33, 66, 66, 33, 66, 33, 66, 135, 135, 66, 33, 135, 33, 135, 66, 66, 66, 66, 66, 33, 33, 135, 33, 135, 33, 66, 135, 66, 135, 66, 135, 66, 135, 33, 66, 66, 66, 66, 66, 66, 66, 66, 135, 33, 33, 33, 33, 33, 66, 33, 33, 66, 135, 135, 33, 33, 135, 33, 33, 33, 66, 33, 66, 135, 135, 66, 66, 33, 135, 66, 135, 33, 66, 66, 33, 33, 66, 33, 135, 135, 33, 135, 135, 33, 66, 135, 33, 33, 66, 66, 33, 33, 135, 135, 135, 135, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 135, 66, 66, 66, 135, 33, 66, 66, 135, 135, 33, 135, 135, 33, 135, 33, 33, 66, 33, 135, 135, 135, 66, 33, 135, 135, 66, 66, 135, 135, 33, 135, 135, 66, 33, 135, 66, 66, 135, 135, 135, 33, 135, 33, 135, 135, 33, 33, 135, 33, 66, 135, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 135, 33, 33, 33, 66, 33, 66, 66, 33, 135, 66, 135, 33, 135, 33, 66, 66, 66, 66, 33, 66, 135, 135, 33, 135, 135, 33, 135, 66, 135, 66, 66, 66, 33, 66, 33, 33, 135, 33, 66, 33, 33, 66, 135, 66, 135, 33, 135, 135, 66, 135, 66, 33, 135, 33, 135, 135, 33, 33, 33]
Prompts retrieved: 29952 . Total input tokens: 6581748 . Total output tokens: 6022685
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 1.2745781308040023,
    "estimated_duration": 3599.899343899017,
    "input_throughput": 679.4667756878856,
    "output_throughput": 621.0659761332253,
    "total_throughput": 1300.5327518211109,
    "itl": 20.942436121163073,
    "ttft": 5695.11176245203,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5051,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.727817786241566,
    "arrivals": 10179,
    "finished_requests": 10163,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2746509788557887. Arrivals time: 0.03800668939948082 Scheduler time: 0.7629606896080077 Scheduler overhead time: 0.1401590802706778 Adapter cache time: 0.12290048971772194 Engine time: 0.14079338870942593 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-16/adapters_384_slots_160_rate_0.0125-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-16/adapters_384_slots_160_rate_0.0125-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 135, 66, 33, 135, 135, 33, 66, 135, 135, 135, 135, 66, 66, 66, 66, 135, 135, 66, 66, 33, 135, 33, 135, 66, 66, 66, 33, 33, 66, 33, 135, 33, 135, 66, 135, 66, 33, 66, 135, 66, 135, 33, 135, 135, 135, 135, 33, 66, 66, 66, 135, 66, 33, 66, 33, 135, 66, 135, 135, 66, 135, 135, 33, 33, 135, 66, 66, 33, 33, 33, 66, 33, 66, 33, 135, 33, 66, 135, 33, 135, 66, 33, 135, 135, 135, 135, 66, 33, 66, 135, 135, 66, 33, 33, 135, 66, 66, 33, 33, 135, 66, 135, 66, 135, 135, 66, 135, 135, 33, 66, 66, 66, 66, 33, 33, 135, 33, 135, 33, 33, 33, 66, 66, 135, 33, 33, 135, 33, 135, 66, 33, 135, 66, 66, 33, 135, 135, 135, 33, 66, 135, 33, 135, 66, 66, 135, 135, 33, 66, 135, 33, 66, 66, 33, 66, 33, 66, 135, 135, 66, 33, 135, 33, 135, 66, 66, 66, 66, 66, 33, 33, 135, 33, 135, 33, 66, 135, 66, 135, 66, 135, 66, 135, 33, 66, 66, 66, 66, 66, 66, 66, 66, 135, 33, 33, 33, 33, 33, 66, 33, 33, 66, 135, 135, 33, 33, 135, 33, 33, 33, 66, 33, 66, 135, 135, 66, 66, 33, 135, 66, 135, 33, 66, 66, 33, 33, 66, 33, 135, 135, 33, 135, 135, 33, 66, 135, 33, 33, 66, 66, 33, 33, 135, 135, 135, 135, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 135, 66, 66, 66, 135, 33, 66, 66, 135, 135, 33, 135, 135, 33, 135, 33, 33, 66, 33, 135, 135, 135, 66, 33, 135, 135, 66, 66, 135, 135, 33, 135, 135, 66, 33, 135, 66, 66, 135, 135, 135, 33, 135, 33, 135, 135, 33, 33, 135, 33, 66, 135, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 135, 33, 33, 33, 66, 33, 66, 66, 33, 135, 66, 135, 33, 135, 33, 66, 66, 66, 66, 33, 66, 135, 135, 33, 135, 135, 33, 135, 66, 135, 66, 66, 66, 33, 66, 33, 33, 135, 33, 66, 33, 33, 66, 135, 66, 135, 33, 135, 135, 66, 135, 66, 33, 135, 33, 135, 135, 33, 33, 33]
Prompts retrieved: 29952 . Total input tokens: 6581748 . Total output tokens: 6022685
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 1.2859790921211243,
    "estimated_duration": 3599.9131040281177,
    "input_throughput": 679.4641785278201,
    "output_throughput": 621.0636022014761,
    "total_throughput": 1300.5277807292962,
    "itl": 20.929255891547598,
    "ttft": 5694.855989896468,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5052,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.1057340898474,
    "arrivals": 10179,
    "finished_requests": 10163,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2860448551364243. Arrivals time: 0.038096911273896694 Scheduler time: 0.7743600346148014 Scheduler overhead time: 0.14039167808368802 Adapter cache time: 0.12417168822139502 Engine time: 0.13920016214251518 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-32/adapters_384_slots_160_rate_0.0125-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-32/adapters_384_slots_160_rate_0.0125-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 135, 66, 33, 135, 135, 33, 66, 135, 135, 135, 135, 66, 66, 66, 66, 135, 135, 66, 66, 33, 135, 33, 135, 66, 66, 66, 33, 33, 66, 33, 135, 33, 135, 66, 135, 66, 33, 66, 135, 66, 135, 33, 135, 135, 135, 135, 33, 66, 66, 66, 135, 66, 33, 66, 33, 135, 66, 135, 135, 66, 135, 135, 33, 33, 135, 66, 66, 33, 33, 33, 66, 33, 66, 33, 135, 33, 66, 135, 33, 135, 66, 33, 135, 135, 135, 135, 66, 33, 66, 135, 135, 66, 33, 33, 135, 66, 66, 33, 33, 135, 66, 135, 66, 135, 135, 66, 135, 135, 33, 66, 66, 66, 66, 33, 33, 135, 33, 135, 33, 33, 33, 66, 66, 135, 33, 33, 135, 33, 135, 66, 33, 135, 66, 66, 33, 135, 135, 135, 33, 66, 135, 33, 135, 66, 66, 135, 135, 33, 66, 135, 33, 66, 66, 33, 66, 33, 66, 135, 135, 66, 33, 135, 33, 135, 66, 66, 66, 66, 66, 33, 33, 135, 33, 135, 33, 66, 135, 66, 135, 66, 135, 66, 135, 33, 66, 66, 66, 66, 66, 66, 66, 66, 135, 33, 33, 33, 33, 33, 66, 33, 33, 66, 135, 135, 33, 33, 135, 33, 33, 33, 66, 33, 66, 135, 135, 66, 66, 33, 135, 66, 135, 33, 66, 66, 33, 33, 66, 33, 135, 135, 33, 135, 135, 33, 66, 135, 33, 33, 66, 66, 33, 33, 135, 135, 135, 135, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 135, 66, 66, 66, 135, 33, 66, 66, 135, 135, 33, 135, 135, 33, 135, 33, 33, 66, 33, 135, 135, 135, 66, 33, 135, 135, 66, 66, 135, 135, 33, 135, 135, 66, 33, 135, 66, 66, 135, 135, 135, 33, 135, 33, 135, 135, 33, 33, 135, 33, 66, 135, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 135, 33, 33, 33, 66, 33, 66, 66, 33, 135, 66, 135, 33, 135, 33, 66, 66, 66, 66, 33, 66, 135, 135, 33, 135, 135, 33, 135, 66, 135, 66, 66, 66, 33, 66, 33, 33, 135, 33, 66, 33, 33, 66, 135, 66, 135, 33, 135, 135, 66, 135, 66, 33, 135, 33, 135, 135, 33, 33, 33]
Prompts retrieved: 29952 . Total input tokens: 6581748 . Total output tokens: 6022685
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 1.2771265087649226,
    "estimated_duration": 3599.9111898638125,
    "input_throughput": 679.4645398161988,
    "output_throughput": 621.0639324367836,
    "total_throughput": 1300.5284722529823,
    "itl": 20.943310125273598,
    "ttft": 5694.91632322701,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5051,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.944240052661577,
    "arrivals": 10179,
    "finished_requests": 10163,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2772012068890035. Arrivals time: 0.03779002698138356 Scheduler time: 0.7654072484001517 Scheduler overhead time: 0.1415731026791036 Adapter cache time: 0.12350786151364446 Engine time: 0.13928472436964512 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-8/adapters_384_slots_192_rate_3.2-1.6-0.8_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-8/adapters_384_slots_192_rate_3.2-1.6-0.8_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [128 128 128]
Adapter prompts. [8640, 8640, 34560, 17280, 8640, 34560, 34560, 8640, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 8640, 34560, 17280, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 8640, 34560, 17280, 34560, 17280, 8640, 17280, 34560, 17280, 34560, 8640, 34560, 34560, 34560, 34560, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 17280, 8640, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 8640, 8640, 34560, 17280, 17280, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 8640, 34560, 17280, 17280, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 34560, 8640, 8640, 8640, 17280, 17280, 34560, 8640, 8640, 34560, 8640, 34560, 17280, 8640, 34560, 17280, 17280, 8640, 34560, 34560, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 17280, 34560, 34560, 8640, 17280, 34560, 8640, 17280, 17280, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 34560, 8640, 34560, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 34560, 8640, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 8640, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 8640, 34560, 8640, 8640, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 34560, 8640, 34560, 34560, 8640, 17280, 34560, 8640, 8640, 17280, 17280, 8640, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 34560, 17280, 17280, 17280, 34560, 8640, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 8640, 8640, 17280, 8640, 34560, 34560, 34560, 17280, 8640, 34560, 34560, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 17280, 8640, 34560, 17280, 17280, 34560, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 34560, 8640, 17280, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 8640, 8640, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 17280, 34560, 17280, 17280, 17280, 8640, 17280, 8640, 8640, 34560, 8640, 17280, 8640, 8640, 17280, 34560, 17280, 34560, 8640, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 8640]
Prompts retrieved: 7741440 . Total input tokens: 1724144384 . Total output tokens: 1548076799
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 9.343443030957133,
    "estimated_duration": 3600.2095958936766,
    "input_throughput": 3625.3861483195333,
    "output_throughput": 3222.3307257532815,
    "total_throughput": 6847.716874072815,
    "itl": 266.1053283507913,
    "ttft": 2331689.032850553,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1911,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.84859207865566,
    "arrivals": 2579962,
    "finished_requests": 53175,
    "scheduler_time": 74.03724037811857
}
#Debug simulation 
Total elapsed time: 9.343564115930349. Arrivals time: 0.7424480603076518 Scheduler time: 8.48808818962425 Scheduler overhead time: 0.024596034549176693 Adapter cache time: 0.05287223309278488 Engine time: 0.024960896465927362 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-16/adapters_384_slots_192_rate_3.2-1.6-0.8_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-16/adapters_384_slots_192_rate_3.2-1.6-0.8_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [128 128 128]
Adapter prompts. [8640, 8640, 34560, 17280, 8640, 34560, 34560, 8640, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 8640, 34560, 17280, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 8640, 34560, 17280, 34560, 17280, 8640, 17280, 34560, 17280, 34560, 8640, 34560, 34560, 34560, 34560, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 17280, 8640, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 8640, 8640, 34560, 17280, 17280, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 8640, 34560, 17280, 17280, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 34560, 8640, 8640, 8640, 17280, 17280, 34560, 8640, 8640, 34560, 8640, 34560, 17280, 8640, 34560, 17280, 17280, 8640, 34560, 34560, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 17280, 34560, 34560, 8640, 17280, 34560, 8640, 17280, 17280, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 34560, 8640, 34560, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 34560, 8640, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 8640, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 8640, 34560, 8640, 8640, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 34560, 8640, 34560, 34560, 8640, 17280, 34560, 8640, 8640, 17280, 17280, 8640, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 34560, 17280, 17280, 17280, 34560, 8640, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 8640, 8640, 17280, 8640, 34560, 34560, 34560, 17280, 8640, 34560, 34560, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 17280, 8640, 34560, 17280, 17280, 34560, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 34560, 8640, 17280, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 8640, 8640, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 17280, 34560, 17280, 17280, 17280, 8640, 17280, 8640, 8640, 34560, 8640, 17280, 8640, 8640, 17280, 34560, 17280, 34560, 8640, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 8640]
Prompts retrieved: 7741440 . Total input tokens: 1724144384 . Total output tokens: 1548076799
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 8.772230151109397,
    "estimated_duration": 3600.263727574061,
    "input_throughput": 3611.3982151971495,
    "output_throughput": 3206.1312374407303,
    "total_throughput": 6817.52945263788,
    "itl": 261.21313857224624,
    "ttft": 2334141.086849695,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1851,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.031026407768772,
    "arrivals": 2579962,
    "finished_requests": 52965,
    "scheduler_time": 74.32756431015308
}
#Debug simulation 
Total elapsed time: 8.772292690817267. Arrivals time: 0.2564941346645355 Scheduler time: 8.402428376954049 Scheduler overhead time: 0.024901755154132843 Adapter cache time: 0.052715870551764965 Engine time: 0.025087947491556406 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-32/adapters_384_slots_192_rate_3.2-1.6-0.8_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-32/adapters_384_slots_192_rate_3.2-1.6-0.8_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [128 128 128]
Adapter prompts. [8640, 8640, 34560, 17280, 8640, 34560, 34560, 8640, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 8640, 34560, 17280, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 8640, 34560, 17280, 34560, 17280, 8640, 17280, 34560, 17280, 34560, 8640, 34560, 34560, 34560, 34560, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 17280, 8640, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 8640, 8640, 34560, 17280, 17280, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 8640, 34560, 17280, 17280, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 34560, 8640, 8640, 8640, 17280, 17280, 34560, 8640, 8640, 34560, 8640, 34560, 17280, 8640, 34560, 17280, 17280, 8640, 34560, 34560, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 17280, 34560, 34560, 8640, 17280, 34560, 8640, 17280, 17280, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 34560, 8640, 34560, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 34560, 8640, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 8640, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 8640, 34560, 8640, 8640, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 34560, 8640, 34560, 34560, 8640, 17280, 34560, 8640, 8640, 17280, 17280, 8640, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 34560, 17280, 17280, 17280, 34560, 8640, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 8640, 8640, 17280, 8640, 34560, 34560, 34560, 17280, 8640, 34560, 34560, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 17280, 8640, 34560, 17280, 17280, 34560, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 34560, 8640, 17280, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 8640, 8640, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 17280, 34560, 17280, 17280, 17280, 8640, 17280, 8640, 8640, 34560, 8640, 17280, 8640, 8640, 17280, 34560, 17280, 34560, 8640, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 8640]
Prompts retrieved: 7741440 . Total input tokens: 1724144384 . Total output tokens: 1548076799
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.776977537199855,
    "estimated_duration": 3600.073460357928,
    "input_throughput": 2798.0459595950856,
    "output_throughput": 2489.7319731661405,
    "total_throughput": 5287.777932761226,
    "itl": 134.81270206879606,
    "ttft": 2460464.007400377,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9576,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 31.277826898714093,
    "arrivals": 2579962,
    "finished_requests": 41027,
    "scheduler_time": 88.91871170786806
}
#Debug simulation 
Total elapsed time: 3.7770563261583447. Arrivals time: 0.19639652408659458 Scheduler time: 3.2609688472002745 Scheduler overhead time: 0.03929717279970646 Adapter cache time: 0.22298643179237843 Engine time: 0.03911504987627268 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-16/adapters_384_slots_192_rate_3.2-1.6-0.8_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-16/adapters_384_slots_192_rate_3.2-1.6-0.8_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [128 128 128]
Adapter prompts. [8640, 8640, 34560, 17280, 8640, 34560, 34560, 8640, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 8640, 34560, 17280, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 8640, 34560, 17280, 34560, 17280, 8640, 17280, 34560, 17280, 34560, 8640, 34560, 34560, 34560, 34560, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 17280, 8640, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 8640, 8640, 34560, 17280, 17280, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 8640, 34560, 17280, 17280, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 34560, 8640, 8640, 8640, 17280, 17280, 34560, 8640, 8640, 34560, 8640, 34560, 17280, 8640, 34560, 17280, 17280, 8640, 34560, 34560, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 17280, 34560, 34560, 8640, 17280, 34560, 8640, 17280, 17280, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 34560, 8640, 34560, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 34560, 8640, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 8640, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 8640, 34560, 8640, 8640, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 34560, 8640, 34560, 34560, 8640, 17280, 34560, 8640, 8640, 17280, 17280, 8640, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 34560, 17280, 17280, 17280, 34560, 8640, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 8640, 8640, 17280, 8640, 34560, 34560, 34560, 17280, 8640, 34560, 34560, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 17280, 8640, 34560, 17280, 17280, 34560, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 34560, 8640, 17280, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 8640, 8640, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 17280, 34560, 17280, 17280, 17280, 8640, 17280, 8640, 8640, 34560, 8640, 17280, 8640, 8640, 17280, 34560, 17280, 34560, 8640, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 8640]
Prompts retrieved: 7741440 . Total input tokens: 1724144384 . Total output tokens: 1548076799
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 8.708404088858515,
    "estimated_duration": 3600.0157352951182,
    "input_throughput": 3611.6469915746457,
    "output_throughput": 3206.3520964176414,
    "total_throughput": 6817.999087992287,
    "itl": 261.1965607040558,
    "ttft": 2334055.8350567706,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1851,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.783417644793938,
    "arrivals": 2579962,
    "finished_requests": 52965,
    "scheduler_time": 74.32718079412165
}
#Debug simulation 
Total elapsed time: 8.708468736615032. Arrivals time: 0.25241703633219004 Scheduler time: 8.344639017712325 Scheduler overhead time: 0.024686009157449007 Adapter cache time: 0.05113893002271652 Engine time: 0.02491546794772148 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-32/adapters_384_slots_192_rate_3.2-1.6-0.8_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-32/adapters_384_slots_192_rate_3.2-1.6-0.8_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [128 128 128]
Adapter prompts. [8640, 8640, 34560, 17280, 8640, 34560, 34560, 8640, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 8640, 34560, 17280, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 8640, 34560, 17280, 34560, 17280, 8640, 17280, 34560, 17280, 34560, 8640, 34560, 34560, 34560, 34560, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 17280, 8640, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 8640, 8640, 34560, 17280, 17280, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 8640, 34560, 17280, 17280, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 34560, 8640, 8640, 8640, 17280, 17280, 34560, 8640, 8640, 34560, 8640, 34560, 17280, 8640, 34560, 17280, 17280, 8640, 34560, 34560, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 17280, 34560, 34560, 8640, 17280, 34560, 8640, 17280, 17280, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 34560, 8640, 34560, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 34560, 8640, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 8640, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 8640, 34560, 8640, 8640, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 34560, 8640, 34560, 34560, 8640, 17280, 34560, 8640, 8640, 17280, 17280, 8640, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 34560, 17280, 17280, 17280, 34560, 8640, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 8640, 8640, 17280, 8640, 34560, 34560, 34560, 17280, 8640, 34560, 34560, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 17280, 8640, 34560, 17280, 17280, 34560, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 34560, 8640, 17280, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 8640, 8640, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 17280, 34560, 17280, 17280, 17280, 8640, 17280, 8640, 8640, 34560, 8640, 17280, 8640, 8640, 17280, 34560, 17280, 34560, 8640, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 8640]
Prompts retrieved: 7741440 . Total input tokens: 1724144384 . Total output tokens: 1548076799
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 3.7735225441865623,
    "estimated_duration": 3600.021036004838,
    "input_throughput": 2797.755040669841,
    "output_throughput": 2489.4515644124576,
    "total_throughput": 5287.206605082299,
    "itl": 134.82728726679633,
    "ttft": 2460473.9213741813,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9575,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 31.67069631336195,
    "arrivals": 2579962,
    "finished_requests": 41021,
    "scheduler_time": 88.90775178658956
}
#Debug simulation 
Total elapsed time: 3.773611018899828. Arrivals time: 0.19560035271570086 Scheduler time: 3.25788350449875 Scheduler overhead time: 0.039399891160428524 Adapter cache time: 0.22343894885852933 Engine time: 0.03902536351233721 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-16/adapters_384_slots_192_rate_3.2-1.6-0.8_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-16/adapters_384_slots_192_rate_3.2-1.6-0.8_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [128 128 128]
Adapter prompts. [8640, 8640, 34560, 17280, 8640, 34560, 34560, 8640, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 8640, 34560, 17280, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 8640, 34560, 17280, 34560, 17280, 8640, 17280, 34560, 17280, 34560, 8640, 34560, 34560, 34560, 34560, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 17280, 8640, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 8640, 8640, 34560, 17280, 17280, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 8640, 34560, 17280, 17280, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 34560, 8640, 8640, 8640, 17280, 17280, 34560, 8640, 8640, 34560, 8640, 34560, 17280, 8640, 34560, 17280, 17280, 8640, 34560, 34560, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 17280, 34560, 34560, 8640, 17280, 34560, 8640, 17280, 17280, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 34560, 8640, 34560, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 34560, 8640, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 8640, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 8640, 34560, 8640, 8640, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 34560, 8640, 34560, 34560, 8640, 17280, 34560, 8640, 8640, 17280, 17280, 8640, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 34560, 17280, 17280, 17280, 34560, 8640, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 8640, 8640, 17280, 8640, 34560, 34560, 34560, 17280, 8640, 34560, 34560, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 17280, 8640, 34560, 17280, 17280, 34560, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 34560, 8640, 17280, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 8640, 8640, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 17280, 34560, 17280, 17280, 17280, 8640, 17280, 8640, 8640, 34560, 8640, 17280, 8640, 8640, 17280, 34560, 17280, 34560, 8640, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 8640]
Prompts retrieved: 7741440 . Total input tokens: 1724144384 . Total output tokens: 1548076799
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 8.778372957836837,
    "estimated_duration": 3600.106010120923,
    "input_throughput": 3615.4074250615786,
    "output_throughput": 3208.6902351000476,
    "total_throughput": 6824.097660161627,
    "itl": 261.48669820708466,
    "ttft": 2334111.6581863733,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1909,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.708006012968087,
    "arrivals": 2579962,
    "finished_requests": 52995,
    "scheduler_time": 74.3106564192538
}
#Debug simulation 
Total elapsed time: 8.778438130859286. Arrivals time: 0.25271793687716126 Scheduler time: 8.41547436779365 Scheduler overhead time: 0.024575570598244667 Adapter cache time: 0.050259902607649565 Engine time: 0.02479371940717101 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-32/adapters_384_slots_192_rate_3.2-1.6-0.8_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-32/adapters_384_slots_192_rate_3.2-1.6-0.8_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [128 128 128]
Adapter prompts. [8640, 8640, 34560, 17280, 8640, 34560, 34560, 8640, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 8640, 34560, 17280, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 8640, 34560, 17280, 34560, 17280, 8640, 17280, 34560, 17280, 34560, 8640, 34560, 34560, 34560, 34560, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 17280, 8640, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 8640, 8640, 34560, 17280, 17280, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 8640, 34560, 17280, 17280, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 34560, 8640, 8640, 8640, 17280, 17280, 34560, 8640, 8640, 34560, 8640, 34560, 17280, 8640, 34560, 17280, 17280, 8640, 34560, 34560, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 17280, 34560, 34560, 8640, 17280, 34560, 8640, 17280, 17280, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 34560, 8640, 34560, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 34560, 8640, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 8640, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 8640, 34560, 8640, 8640, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 34560, 8640, 34560, 34560, 8640, 17280, 34560, 8640, 8640, 17280, 17280, 8640, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 34560, 17280, 17280, 17280, 34560, 8640, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 8640, 8640, 17280, 8640, 34560, 34560, 34560, 17280, 8640, 34560, 34560, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 17280, 8640, 34560, 17280, 17280, 34560, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 34560, 8640, 17280, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 8640, 8640, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 17280, 34560, 17280, 17280, 17280, 8640, 17280, 8640, 8640, 34560, 8640, 17280, 8640, 8640, 17280, 34560, 17280, 34560, 8640, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 8640]
Prompts retrieved: 7741440 . Total input tokens: 1724144384 . Total output tokens: 1548076799
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.7880056900903583,
    "estimated_duration": 3600.119695067784,
    "input_throughput": 2797.2644947879685,
    "output_throughput": 2489.030020939702,
    "total_throughput": 5286.294515727671,
    "itl": 134.84219579353064,
    "ttft": 2460568.962029598,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9574,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 32.0666695588055,
    "arrivals": 2579962,
    "finished_requests": 41016,
    "scheduler_time": 88.90048104091477
}
#Debug simulation 
Total elapsed time: 3.788093749433756. Arrivals time: 0.1990749421529472 Scheduler time: 3.268065322190523 Scheduler overhead time: 0.03935594204813242 Adapter cache time: 0.2238203384913504 Engine time: 0.03940807329490781 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-8/adapters_384_slots_192_rate_3.2-1.6-0.4_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-8/adapters_384_slots_192_rate_3.2-1.6-0.4_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [128 128 128]
Adapter prompts. [4320, 4320, 34560, 17280, 4320, 34560, 34560, 4320, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 4320, 34560, 4320, 34560, 17280, 17280, 17280, 4320, 4320, 17280, 4320, 34560, 4320, 34560, 17280, 34560, 17280, 4320, 17280, 34560, 17280, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 17280, 17280, 17280, 34560, 17280, 4320, 17280, 4320, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 4320, 4320, 34560, 17280, 17280, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 4320, 34560, 34560, 34560, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 4320, 34560, 17280, 17280, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 17280, 17280, 34560, 4320, 4320, 34560, 4320, 34560, 17280, 4320, 34560, 17280, 17280, 4320, 34560, 34560, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 17280, 34560, 34560, 4320, 17280, 34560, 4320, 17280, 17280, 4320, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 34560, 4320, 34560, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 34560, 4320, 34560, 4320, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 4320, 34560, 4320, 4320, 4320, 17280, 4320, 17280, 34560, 34560, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 17280, 17280, 4320, 4320, 17280, 4320, 34560, 34560, 4320, 34560, 34560, 4320, 17280, 34560, 4320, 4320, 17280, 17280, 4320, 4320, 34560, 34560, 34560, 34560, 17280, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 34560, 17280, 17280, 17280, 34560, 4320, 17280, 17280, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 4320, 4320, 17280, 4320, 34560, 34560, 34560, 17280, 4320, 34560, 34560, 17280, 17280, 34560, 34560, 4320, 34560, 34560, 17280, 4320, 34560, 17280, 17280, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 34560, 4320, 17280, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 34560, 4320, 4320, 4320, 17280, 4320, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 17280, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 17280, 34560, 17280, 17280, 17280, 4320, 17280, 4320, 4320, 34560, 4320, 17280, 4320, 4320, 17280, 34560, 17280, 34560, 4320, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 7188480 . Total input tokens: 1601032366 . Total output tokens: 1437456396
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 8.494498189073056,
    "estimated_duration": 3600.089861731619,
    "input_throughput": 3646.4025910969403,
    "output_throughput": 3223.873693646491,
    "total_throughput": 6870.2762847434315,
    "itl": 265.6161816075179,
    "ttft": 2328945.5743594933,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1643,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.028381363281653,
    "arrivals": 2395765,
    "finished_requests": 53402,
    "scheduler_time": 74.06945299716233
}
#Debug simulation 
Total elapsed time: 8.494565313216299. Arrivals time: 0.2505336864851415 Scheduler time: 8.139909623656422 Scheduler overhead time: 0.0243932600133121 Adapter cache time: 0.044663128443062305 Engine time: 0.02463130373507738 
