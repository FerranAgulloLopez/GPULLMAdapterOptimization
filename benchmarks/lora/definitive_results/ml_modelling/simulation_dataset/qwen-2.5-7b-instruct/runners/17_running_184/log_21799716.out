INFO 06-01 00:46:59 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:46:59 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_16-16-32/adapters_64_slots_16_rate_0.4-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_16-16-32/adapters_64_slots_16_rate_0.4-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [21 21 22]
Adapter prompts. [270, 1080, 4320, 4320, 270, 4320, 270, 1080, 270, 4320, 1080, 4320, 270, 1080, 4320, 4320, 4320, 270, 4320, 1080, 1080, 270, 270, 270, 4320, 270, 270, 270, 4320, 1080, 270, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 270, 1080, 1080, 4320, 4320, 1080, 4320, 270, 4320, 1080, 1080, 1080, 4320, 1080, 270, 270, 1080, 1080, 270, 1080, 270, 270, 270, 4320, 1080]
Prompts retrieved: 123390 . Total input tokens: 27563012 . Total output tokens: 24672264
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 4.633533702697605,
    "estimated_duration": 3599.9748635213814,
    "input_throughput": 2845.5379241119967,
    "output_throughput": 2503.6780371248465,
    "total_throughput": 5349.215961236843,
    "itl": 27.104391173952603,
    "ttft": 45676.67750613035,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2153,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.225436942614361,
    "arrivals": 41341,
    "finished_requests": 41058,
    "scheduler_time": 17.07817411324987
}
#Debug simulation 
Total elapsed time: 4.6336456327699125. Arrivals time: 0.11189767206087708 Scheduler time: 4.163942153565586 Scheduler overhead time: 0.13477312307804823 Adapter cache time: 0.03164054453372955 Engine time: 0.1299897925928235 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-8/adapters_64_slots_16_rate_0.4-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-8/adapters_64_slots_16_rate_0.4-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [21 21 22]
Adapter prompts. [135, 1080, 4320, 4320, 135, 4320, 135, 1080, 135, 4320, 1080, 4320, 135, 1080, 4320, 4320, 4320, 135, 4320, 1080, 1080, 135, 135, 135, 4320, 135, 135, 135, 4320, 1080, 135, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 135, 1080, 1080, 4320, 4320, 1080, 4320, 135, 4320, 1080, 1080, 1080, 4320, 1080, 135, 135, 1080, 1080, 135, 1080, 135, 135, 135, 4320, 1080]
Prompts retrieved: 120555 . Total input tokens: 26904447 . Total output tokens: 24124616
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 4.359172388911247,
    "estimated_duration": 3600.0145454702233,
    "input_throughput": 2771.441857798606,
    "output_throughput": 2449.8101017666977,
    "total_throughput": 5221.251959565304,
    "itl": 26.756384716215607,
    "ttft": 38245.276586207474,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2182,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.677984257261465,
    "arrivals": 40385,
    "finished_requests": 40155,
    "scheduler_time": 15.296859727006643
}
#Debug simulation 
Total elapsed time: 4.359292879234999. Arrivals time: 0.10944598913192749 Scheduler time: 3.8967523057945073 Scheduler overhead time: 0.1314349086023867 Adapter cache time: 0.03189767291769385 Engine time: 0.12871933821588755 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-16/adapters_64_slots_16_rate_0.4-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-16/adapters_64_slots_16_rate_0.4-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [21 21 22]
Adapter prompts. [135, 1080, 4320, 4320, 135, 4320, 135, 1080, 135, 4320, 1080, 4320, 135, 1080, 4320, 4320, 4320, 135, 4320, 1080, 1080, 135, 135, 135, 4320, 135, 135, 135, 4320, 1080, 135, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 135, 1080, 1080, 4320, 4320, 1080, 4320, 135, 4320, 1080, 1080, 1080, 4320, 1080, 135, 135, 1080, 1080, 135, 1080, 135, 135, 135, 4320, 1080]
Prompts retrieved: 120555 . Total input tokens: 26904447 . Total output tokens: 24124616
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 4.392181653995067,
    "estimated_duration": 3600.0107325458407,
    "input_throughput": 2771.429515418245,
    "output_throughput": 2450.206028625411,
    "total_throughput": 5221.6355440436555,
    "itl": 26.77662302876706,
    "ttft": 38401.156645457035,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2138,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.9762016452334015,
    "arrivals": 40385,
    "finished_requests": 40158,
    "scheduler_time": 15.408863242582303
}
#Debug simulation 
Total elapsed time: 4.392281362786889. Arrivals time: 0.11062485491856933 Scheduler time: 3.929132394492626 Scheduler overhead time: 0.13148147240281105 Adapter cache time: 0.03169299615547061 Engine time: 0.1283419681712985 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-32/adapters_64_slots_16_rate_0.4-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-32/adapters_64_slots_16_rate_0.4-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [21 21 22]
Adapter prompts. [135, 1080, 4320, 4320, 135, 4320, 135, 1080, 135, 4320, 1080, 4320, 135, 1080, 4320, 4320, 4320, 135, 4320, 1080, 1080, 135, 135, 135, 4320, 135, 135, 135, 4320, 1080, 135, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 135, 1080, 1080, 4320, 4320, 1080, 4320, 135, 4320, 1080, 1080, 1080, 4320, 1080, 135, 135, 1080, 1080, 135, 1080, 135, 135, 135, 4320, 1080]
Prompts retrieved: 120555 . Total input tokens: 26904447 . Total output tokens: 24124616
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 4.380635101813823,
    "estimated_duration": 3600.0028338846446,
    "input_throughput": 2771.4328183553034,
    "output_throughput": 2449.711404944574,
    "total_throughput": 5221.144223299877,
    "itl": 26.77823488122495,
    "ttft": 39217.91628988326,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2133,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.972740631625019,
    "arrivals": 40385,
    "finished_requests": 40149,
    "scheduler_time": 15.416084204487913
}
#Debug simulation 
Total elapsed time: 4.380726495757699. Arrivals time: 0.10732574667781591 Scheduler time: 3.921383948531002 Scheduler overhead time: 0.1312157860957086 Adapter cache time: 0.03129405248910189 Engine time: 0.12828308250755072 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-16/adapters_64_slots_16_rate_0.4-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-16/adapters_64_slots_16_rate_0.4-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [21 21 22]
Adapter prompts. [135, 1080, 4320, 4320, 135, 4320, 135, 1080, 135, 4320, 1080, 4320, 135, 1080, 4320, 4320, 4320, 135, 4320, 1080, 1080, 135, 135, 135, 4320, 135, 135, 135, 4320, 1080, 135, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 135, 1080, 1080, 4320, 4320, 1080, 4320, 135, 4320, 1080, 1080, 1080, 4320, 1080, 135, 135, 1080, 1080, 135, 1080, 135, 135, 135, 4320, 1080]
Prompts retrieved: 120555 . Total input tokens: 26904447 . Total output tokens: 24124616
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 4.462282745167613,
    "estimated_duration": 3599.999864365695,
    "input_throughput": 2771.860937766509,
    "output_throughput": 2450.870925672826,
    "total_throughput": 5222.731863439335,
    "itl": 26.797955174547372,
    "ttft": 38814.200353466484,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2017,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.281400375021428,
    "arrivals": 40385,
    "finished_requests": 40164,
    "scheduler_time": 15.62803684929493
}
#Debug simulation 
Total elapsed time: 4.462379992939532. Arrivals time: 0.11321485275402665 Scheduler time: 3.997069325763732 Scheduler overhead time: 0.13154857931658626 Adapter cache time: 0.031287201680243015 Engine time: 0.1280370126478374 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-32/adapters_64_slots_16_rate_0.4-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-32/adapters_64_slots_16_rate_0.4-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [21 21 22]
Adapter prompts. [135, 1080, 4320, 4320, 135, 4320, 135, 1080, 135, 4320, 1080, 4320, 135, 1080, 4320, 4320, 4320, 135, 4320, 1080, 1080, 135, 135, 135, 4320, 135, 135, 135, 4320, 1080, 135, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 135, 1080, 1080, 4320, 4320, 1080, 4320, 135, 4320, 1080, 1080, 1080, 4320, 1080, 135, 135, 1080, 1080, 135, 1080, 135, 135, 135, 4320, 1080]
Prompts retrieved: 120555 . Total input tokens: 26904447 . Total output tokens: 24124616
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 4.519964636303484,
    "estimated_duration": 3600.015532033762,
    "input_throughput": 2771.423042823258,
    "output_throughput": 2449.7027642038775,
    "total_throughput": 5221.125807027136,
    "itl": 26.77900784513502,
    "ttft": 39218.02819720017,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2133,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.0684392630866215,
    "arrivals": 40385,
    "finished_requests": 40149,
    "scheduler_time": 15.41690866975039
}
#Debug simulation 
Total elapsed time: 4.52006442938. Arrivals time: 0.10757064493373036 Scheduler time: 4.059185210149735 Scheduler overhead time: 0.13174642389640212 Adapter cache time: 0.03204779280349612 Engine time: 0.12830722332000732 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-16/adapters_64_slots_16_rate_0.4-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-16/adapters_64_slots_16_rate_0.4-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [21 21 22]
Adapter prompts. [135, 1080, 4320, 4320, 135, 4320, 135, 1080, 135, 4320, 1080, 4320, 135, 1080, 4320, 4320, 4320, 135, 4320, 1080, 1080, 135, 135, 135, 4320, 135, 135, 135, 4320, 1080, 135, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 135, 1080, 1080, 4320, 4320, 1080, 4320, 135, 4320, 1080, 1080, 1080, 4320, 1080, 135, 135, 1080, 1080, 135, 1080, 135, 135, 135, 4320, 1080]
Prompts retrieved: 120555 . Total input tokens: 26904447 . Total output tokens: 24124616
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 4.333770096767694,
    "estimated_duration": 3600.015608879497,
    "input_throughput": 2771.792426507229,
    "output_throughput": 2450.076876957019,
    "total_throughput": 5221.869303464248,
    "itl": 26.739681337458027,
    "ttft": 38429.13215347865,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2183,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.527279793771254,
    "arrivals": 40385,
    "finished_requests": 40151,
    "scheduler_time": 15.262387593395733
}
#Debug simulation 
Total elapsed time: 4.33386556385085. Arrivals time: 0.10781502723693848 Scheduler time: 3.874823022633791 Scheduler overhead time: 0.13103548903018236 Adapter cache time: 0.03171486686915159 Engine time: 0.12751644616946578 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-32/adapters_64_slots_16_rate_0.4-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-32/adapters_64_slots_16_rate_0.4-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [21 21 22]
Adapter prompts. [135, 1080, 4320, 4320, 135, 4320, 135, 1080, 135, 4320, 1080, 4320, 135, 1080, 4320, 4320, 4320, 135, 4320, 1080, 1080, 135, 135, 135, 4320, 135, 135, 135, 4320, 1080, 135, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 135, 1080, 1080, 4320, 4320, 1080, 4320, 135, 4320, 1080, 1080, 1080, 4320, 1080, 135, 135, 1080, 1080, 135, 1080, 135, 135, 135, 4320, 1080]
Prompts retrieved: 120555 . Total input tokens: 26904447 . Total output tokens: 24124616
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 4.38553561642766,
    "estimated_duration": 3600.0153896053075,
    "input_throughput": 2772.0492609044395,
    "output_throughput": 2450.5939684239047,
    "total_throughput": 5222.643229328344,
    "itl": 26.775203453643766,
    "ttft": 37248.96964045709,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2144,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.1887852473554466,
    "arrivals": 40385,
    "finished_requests": 40170,
    "scheduler_time": 15.390677219383228
}
#Debug simulation 
Total elapsed time: 4.3856311440467834. Arrivals time: 0.11049153795465827 Scheduler time: 3.9236749820411205 Scheduler overhead time: 0.13089844631031156 Adapter cache time: 0.031611885875463486 Engine time: 0.1275420137681067 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-8/adapters_64_slots_16_rate_0.4-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-8/adapters_64_slots_16_rate_0.4-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 1080, 4320, 4320, 66, 4320, 66, 1080, 66, 4320, 1080, 4320, 66, 1080, 4320, 4320, 4320, 66, 4320, 1080, 1080, 66, 66, 66, 4320, 66, 66, 66, 4320, 1080, 66, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 66, 1080, 1080, 4320, 4320, 1080, 4320, 66, 4320, 1080, 1080, 1080, 4320, 1080, 66, 66, 1080, 1080, 66, 1080, 66, 66, 66, 4320, 1080]
Prompts retrieved: 119106 . Total input tokens: 26581357 . Total output tokens: 23854509
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 4.305704554077238,
    "estimated_duration": 3600.003709206715,
    "input_throughput": 2728.056633631671,
    "output_throughput": 2458.037467397478,
    "total_throughput": 5186.094101029149,
    "itl": 26.840891928910708,
    "ttft": 40971.075764788235,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2034,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.225032071159402,
    "arrivals": 39938,
    "finished_requests": 39668,
    "scheduler_time": 15.16011937020198
}
#Debug simulation 
Total elapsed time: 4.305800694040954. Arrivals time: 0.10668845102190971 Scheduler time: 3.8487036717124283 Scheduler overhead time: 0.13087838608771563 Adapter cache time: 0.03101090295240283 Engine time: 0.12755266577005386 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-16/adapters_64_slots_16_rate_0.4-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-16/adapters_64_slots_16_rate_0.4-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 1080, 4320, 4320, 66, 4320, 66, 1080, 66, 4320, 1080, 4320, 66, 1080, 4320, 4320, 4320, 66, 4320, 1080, 1080, 66, 66, 66, 4320, 66, 66, 66, 4320, 1080, 66, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 66, 1080, 1080, 4320, 4320, 1080, 4320, 66, 4320, 1080, 1080, 1080, 4320, 1080, 66, 66, 1080, 1080, 66, 1080, 66, 66, 66, 4320, 1080]
Prompts retrieved: 119106 . Total input tokens: 26581357 . Total output tokens: 23854509
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 4.315462848171592,
    "estimated_duration": 3600.010927221939,
    "input_throughput": 2726.84200088674,
    "output_throughput": 2458.2539272538206,
    "total_throughput": 5185.095928140561,
    "itl": 26.849108648655665,
    "ttft": 42898.60136232695,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2009,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.553302983212992,
    "arrivals": 39938,
    "finished_requests": 39648,
    "scheduler_time": 15.168309550491617
}
#Debug simulation 
Total elapsed time: 4.315630638971925. Arrivals time: 0.11402460327371955 Scheduler time: 3.851479911711067 Scheduler overhead time: 0.13041962124407291 Adapter cache time: 0.031063200440257788 Engine time: 0.1274525998160243 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-32/adapters_64_slots_16_rate_0.4-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-32/adapters_64_slots_16_rate_0.4-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 1080, 4320, 4320, 66, 4320, 66, 1080, 66, 4320, 1080, 4320, 66, 1080, 4320, 4320, 4320, 66, 4320, 1080, 1080, 66, 66, 66, 4320, 66, 66, 66, 4320, 1080, 66, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 66, 1080, 1080, 4320, 4320, 1080, 4320, 66, 4320, 1080, 1080, 1080, 4320, 1080, 66, 66, 1080, 1080, 66, 1080, 66, 66, 66, 4320, 1080]
Prompts retrieved: 119106 . Total input tokens: 26581357 . Total output tokens: 23854509
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 4.3352081356570125,
    "estimated_duration": 3600.004121921322,
    "input_throughput": 2725.6527125205466,
    "output_throughput": 2456.981353476714,
    "total_throughput": 5182.63406599726,
    "itl": 26.83035132517521,
    "ttft": 43223.96668432796,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2019,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.598125188313377,
    "arrivals": 39938,
    "finished_requests": 39644,
    "scheduler_time": 15.153065512007089
}
#Debug simulation 
Total elapsed time: 4.335300331003964. Arrivals time: 0.10731303133070469 Scheduler time: 3.8763037333264947 Scheduler overhead time: 0.13176822289824486 Adapter cache time: 0.031059153378009796 Engine time: 0.12762100528925657 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-16/adapters_64_slots_16_rate_0.4-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-16/adapters_64_slots_16_rate_0.4-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 1080, 4320, 4320, 66, 4320, 66, 1080, 66, 4320, 1080, 4320, 66, 1080, 4320, 4320, 4320, 66, 4320, 1080, 1080, 66, 66, 66, 4320, 66, 66, 66, 4320, 1080, 66, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 66, 1080, 1080, 4320, 4320, 1080, 4320, 66, 4320, 1080, 1080, 1080, 4320, 1080, 66, 66, 1080, 1080, 66, 1080, 66, 66, 66, 4320, 1080]
Prompts retrieved: 119106 . Total input tokens: 26581357 . Total output tokens: 23854509
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 4.297787714749575,
    "estimated_duration": 3600.0120998685775,
    "input_throughput": 2727.6299988987457,
    "output_throughput": 2457.615906436255,
    "total_throughput": 5185.245905335001,
    "itl": 26.824035222810206,
    "ttft": 41200.07474355807,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2007,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.248231109524889,
    "arrivals": 39938,
    "finished_requests": 39666,
    "scheduler_time": 15.165475372495028
}
#Debug simulation 
Total elapsed time: 4.2978809657506645. Arrivals time: 0.10747537855058908 Scheduler time: 3.839825770817697 Scheduler overhead time: 0.13039486669003963 Adapter cache time: 0.03123957384377718 Engine time: 0.12772432249039412 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-32/adapters_64_slots_16_rate_0.4-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-32/adapters_64_slots_16_rate_0.4-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 1080, 4320, 4320, 66, 4320, 66, 1080, 66, 4320, 1080, 4320, 66, 1080, 4320, 4320, 4320, 66, 4320, 1080, 1080, 66, 66, 66, 4320, 66, 66, 66, 4320, 1080, 66, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 66, 1080, 1080, 4320, 4320, 1080, 4320, 66, 4320, 1080, 1080, 1080, 4320, 1080, 66, 66, 1080, 1080, 66, 1080, 66, 66, 66, 4320, 1080]
Prompts retrieved: 119106 . Total input tokens: 26581357 . Total output tokens: 23854509
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 4.306737058330327,
    "estimated_duration": 3600.0002561523515,
    "input_throughput": 2727.6389725857953,
    "output_throughput": 2457.6239917982875,
    "total_throughput": 5185.262964384083,
    "itl": 26.82665023841839,
    "ttft": 41200.83536298937,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2007,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.65222000388415,
    "arrivals": 39938,
    "finished_requests": 39666,
    "scheduler_time": 15.168085893711465
}
#Debug simulation 
Total elapsed time: 4.306832507252693. Arrivals time: 0.11042769998311996 Scheduler time: 3.8465746426954865 Scheduler overhead time: 0.13058924861252308 Adapter cache time: 0.030793446116149426 Engine time: 0.12755299592390656 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-16/adapters_64_slots_16_rate_0.4-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-16/adapters_64_slots_16_rate_0.4-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 1080, 4320, 4320, 66, 4320, 66, 1080, 66, 4320, 1080, 4320, 66, 1080, 4320, 4320, 4320, 66, 4320, 1080, 1080, 66, 66, 66, 4320, 66, 66, 66, 4320, 1080, 66, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 66, 1080, 1080, 4320, 4320, 1080, 4320, 66, 4320, 1080, 1080, 1080, 4320, 1080, 66, 66, 1080, 1080, 66, 1080, 66, 66, 66, 4320, 1080]
Prompts retrieved: 119106 . Total input tokens: 26581357 . Total output tokens: 23854509
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 4.3143128589726985,
    "estimated_duration": 3600.027274545459,
    "input_throughput": 2727.6185015125516,
    "output_throughput": 2457.6055472016064,
    "total_throughput": 5185.224048714158,
    "itl": 26.820500244674992,
    "ttft": 41199.166367026606,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2007,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.00103094186849,
    "arrivals": 39938,
    "finished_requests": 39666,
    "scheduler_time": 15.163152288632398
}
#Debug simulation 
Total elapsed time: 4.31440388970077. Arrivals time: 0.10816089157015085 Scheduler time: 3.8558261273428798 Scheduler overhead time: 0.13083210866898298 Adapter cache time: 0.031044038012623787 Engine time: 0.1274378695525229 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-32/adapters_64_slots_16_rate_0.4-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-32/adapters_64_slots_16_rate_0.4-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 1080, 4320, 4320, 66, 4320, 66, 1080, 66, 4320, 1080, 4320, 66, 1080, 4320, 4320, 4320, 66, 4320, 1080, 1080, 66, 66, 66, 4320, 66, 66, 66, 4320, 1080, 66, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 66, 1080, 1080, 4320, 4320, 1080, 4320, 66, 4320, 1080, 1080, 1080, 4320, 1080, 66, 66, 1080, 1080, 66, 1080, 66, 66, 66, 4320, 1080]
Prompts retrieved: 119106 . Total input tokens: 26581357 . Total output tokens: 23854509
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 4.354600385762751,
    "estimated_duration": 3600.018565085919,
    "input_throughput": 2727.7853773416946,
    "output_throughput": 2458.4400996800896,
    "total_throughput": 5186.225477021784,
    "itl": 26.805412842232812,
    "ttft": 41347.68477475832,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1997,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.694161845929716,
    "arrivals": 39938,
    "finished_requests": 39667,
    "scheduler_time": 15.202214132842307
}
#Debug simulation 
Total elapsed time: 4.354722579009831. Arrivals time: 0.10760937910526991 Scheduler time: 3.895380209200084 Scheduler overhead time: 0.13124882336705923 Adapter cache time: 0.03128706989809871 Engine time: 0.1278453036211431 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-8/adapters_64_slots_16_rate_0.4-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-8/adapters_64_slots_16_rate_0.4-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 1080, 4320, 4320, 33, 4320, 33, 1080, 33, 4320, 1080, 4320, 33, 1080, 4320, 4320, 4320, 33, 4320, 1080, 1080, 33, 33, 33, 4320, 33, 33, 33, 4320, 1080, 33, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 33, 1080, 1080, 4320, 4320, 1080, 4320, 33, 4320, 1080, 1080, 1080, 4320, 1080, 33, 33, 1080, 1080, 33, 1080, 33, 33, 33, 4320, 1080]
Prompts retrieved: 118413 . Total input tokens: 26410766 . Total output tokens: 23719308
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 4.2056351522915065,
    "estimated_duration": 3599.7725535222808,
    "input_throughput": 2732.6934837521017,
    "output_throughput": 2406.2575818920795,
    "total_throughput": 5138.951065644181,
    "itl": 26.477435386199303,
    "ttft": 36845.318988812025,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1963,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.0077374413401685,
    "arrivals": 39719,
    "finished_requests": 39478,
    "scheduler_time": 13.833004299526431
}
#Debug simulation 
Total elapsed time: 4.205741923302412. Arrivals time: 0.10947722615674138 Scheduler time: 3.745089190546423 Scheduler overhead time: 0.12995659047737718 Adapter cache time: 0.03062198171392083 Engine time: 0.1289989808574319 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-16/adapters_64_slots_16_rate_0.4-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-16/adapters_64_slots_16_rate_0.4-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 1080, 4320, 4320, 33, 4320, 33, 1080, 33, 4320, 1080, 4320, 33, 1080, 4320, 4320, 4320, 33, 4320, 1080, 1080, 33, 33, 33, 4320, 33, 33, 33, 4320, 1080, 33, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 33, 1080, 1080, 4320, 4320, 1080, 4320, 33, 4320, 1080, 1080, 1080, 4320, 1080, 33, 33, 1080, 1080, 33, 1080, 33, 33, 33, 4320, 1080]
Prompts retrieved: 118413 . Total input tokens: 26410766 . Total output tokens: 23719308
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 4.166854029987007,
    "estimated_duration": 3599.7668693597407,
    "input_throughput": 2731.465774545796,
    "output_throughput": 2404.8729582145806,
    "total_throughput": 5136.338732760377,
    "itl": 26.53309642621673,
    "ttft": 37910.48481749084,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1982,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.457453598468348,
    "arrivals": 39719,
    "finished_requests": 39465,
    "scheduler_time": 13.792829924894837
}
#Debug simulation 
Total elapsed time: 4.166950400918722. Arrivals time: 0.10712094651535153 Scheduler time: 3.706706768833101 Scheduler overhead time: 0.13237981358543038 Adapter cache time: 0.03101566294208169 Engine time: 0.12804916454479098 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-32/adapters_64_slots_16_rate_0.4-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-32/adapters_64_slots_16_rate_0.4-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 1080, 4320, 4320, 33, 4320, 33, 1080, 33, 4320, 1080, 4320, 33, 1080, 4320, 4320, 4320, 33, 4320, 1080, 1080, 33, 33, 33, 4320, 33, 33, 33, 4320, 1080, 33, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 33, 1080, 1080, 4320, 4320, 1080, 4320, 33, 4320, 1080, 1080, 1080, 4320, 1080, 33, 33, 1080, 1080, 33, 1080, 33, 33, 33, 4320, 1080]
Prompts retrieved: 118413 . Total input tokens: 26410766 . Total output tokens: 23719308
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 4.215963376220316,
    "estimated_duration": 3599.7836482013627,
    "input_throughput": 2732.108360154942,
    "output_throughput": 2405.8559753520917,
    "total_throughput": 5137.964335507034,
    "itl": 26.490290707960753,
    "ttft": 37832.756380057246,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1945,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.348960221391118,
    "arrivals": 39719,
    "finished_requests": 39468,
    "scheduler_time": 13.848562492025627
}
#Debug simulation 
Total elapsed time: 4.21605987008661. Arrivals time: 0.10979559877887368 Scheduler time: 3.7528943181969225 Scheduler overhead time: 0.13066374091431499 Adapter cache time: 0.031049448065459728 Engine time: 0.13015663111582398 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-16/adapters_64_slots_16_rate_0.4-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-16/adapters_64_slots_16_rate_0.4-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 1080, 4320, 4320, 33, 4320, 33, 1080, 33, 4320, 1080, 4320, 33, 1080, 4320, 4320, 4320, 33, 4320, 1080, 1080, 33, 33, 33, 4320, 33, 33, 33, 4320, 1080, 33, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 33, 1080, 1080, 4320, 4320, 1080, 4320, 33, 4320, 1080, 1080, 1080, 4320, 1080, 33, 33, 1080, 1080, 33, 1080, 33, 33, 33, 4320, 1080]
Prompts retrieved: 118413 . Total input tokens: 26410766 . Total output tokens: 23719308
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 4.190969803836197,
    "estimated_duration": 3599.7897524634855,
    "input_throughput": 2731.9801089132516,
    "output_throughput": 2405.780502617797,
    "total_throughput": 5137.760611531049,
    "itl": 26.465420756530577,
    "ttft": 37702.18332138885,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1989,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.171120271065554,
    "arrivals": 39719,
    "finished_requests": 39467,
    "scheduler_time": 13.807267682899697
}
#Debug simulation 
Total elapsed time: 4.191088356077671. Arrivals time: 0.1071467436850071 Scheduler time: 3.729499312117696 Scheduler overhead time: 0.13150386698544025 Adapter cache time: 0.03101388830691576 Engine time: 0.12908108532428741 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-32/adapters_64_slots_16_rate_0.4-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-32/adapters_64_slots_16_rate_0.4-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 1080, 4320, 4320, 33, 4320, 33, 1080, 33, 4320, 1080, 4320, 33, 1080, 4320, 4320, 4320, 33, 4320, 1080, 1080, 33, 33, 33, 4320, 33, 33, 33, 4320, 1080, 33, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 33, 1080, 1080, 4320, 4320, 1080, 4320, 33, 4320, 1080, 1080, 1080, 4320, 1080, 33, 33, 1080, 1080, 33, 1080, 33, 33, 33, 4320, 1080]
Prompts retrieved: 118413 . Total input tokens: 26410766 . Total output tokens: 23719308
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 4.179654311854392,
    "estimated_duration": 3599.773108588538,
    "input_throughput": 2732.411655760353,
    "output_throughput": 2406.096922979714,
    "total_throughput": 5138.508578740067,
    "itl": 26.49336040556629,
    "ttft": 36996.46714193801,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1984,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.570741231161959,
    "arrivals": 39719,
    "finished_requests": 39475,
    "scheduler_time": 13.825522951905663
}
#Debug simulation 
Total elapsed time: 4.179747405927628. Arrivals time: 0.10746714193373919 Scheduler time: 3.721094476059079 Scheduler overhead time: 0.1301958910189569 Adapter cache time: 0.031079189851880074 Engine time: 0.1285174060612917 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-16/adapters_64_slots_16_rate_0.4-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-16/adapters_64_slots_16_rate_0.4-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 1080, 4320, 4320, 33, 4320, 33, 1080, 33, 4320, 1080, 4320, 33, 1080, 4320, 4320, 4320, 33, 4320, 1080, 1080, 33, 33, 33, 4320, 33, 33, 33, 4320, 1080, 33, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 33, 1080, 1080, 4320, 4320, 1080, 4320, 33, 4320, 1080, 1080, 1080, 4320, 1080, 33, 33, 1080, 1080, 33, 1080, 33, 33, 33, 4320, 1080]
Prompts retrieved: 118413 . Total input tokens: 26410766 . Total output tokens: 23719308
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 4.149021881166846,
    "estimated_duration": 3599.767688308336,
    "input_throughput": 2732.0738035241798,
    "output_throughput": 2405.2518800369803,
    "total_throughput": 5137.32568356116,
    "itl": 26.45806870952087,
    "ttft": 37473.63382903012,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1997,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.971130438919469,
    "arrivals": 39719,
    "finished_requests": 39469,
    "scheduler_time": 13.780778615267074
}
#Debug simulation 
Total elapsed time: 4.149115507025272. Arrivals time: 0.10892711114138365 Scheduler time: 3.6874562758021057 Scheduler overhead time: 0.13008454255759716 Adapter cache time: 0.031054151710122824 Engine time: 0.130261673592031 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-32/adapters_64_slots_16_rate_0.4-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-32/adapters_64_slots_16_rate_0.4-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 1080, 4320, 4320, 33, 4320, 33, 1080, 33, 4320, 1080, 4320, 33, 1080, 4320, 4320, 4320, 33, 4320, 1080, 1080, 33, 33, 33, 4320, 33, 33, 33, 4320, 1080, 33, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 33, 1080, 1080, 4320, 4320, 1080, 4320, 33, 4320, 1080, 1080, 1080, 4320, 1080, 33, 33, 1080, 1080, 33, 1080, 33, 33, 33, 4320, 1080]
Prompts retrieved: 118413 . Total input tokens: 26410766 . Total output tokens: 23719308
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 4.1781101119704545,
    "estimated_duration": 3599.782981269617,
    "input_throughput": 2732.2399853479783,
    "output_throughput": 2404.983868484925,
    "total_throughput": 5137.223853832904,
    "itl": 26.486840821459804,
    "ttft": 37991.45325754827,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1948,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.519564351886321,
    "arrivals": 39719,
    "finished_requests": 39466,
    "scheduler_time": 13.832650452612592
}
#Debug simulation 
Total elapsed time: 4.178201046772301. Arrivals time: 0.1083627543412149 Scheduler time: 3.7189649171195924 Scheduler overhead time: 0.13032830087468028 Adapter cache time: 0.030599527060985565 Engine time: 0.1286518843844533 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-8/adapters_64_slots_16_rate_0.4-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-8/adapters_64_slots_16_rate_0.4-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [21 21 22]
Adapter prompts. [270, 540, 4320, 4320, 270, 4320, 270, 540, 270, 4320, 540, 4320, 270, 540, 4320, 4320, 4320, 270, 4320, 540, 540, 270, 270, 270, 4320, 270, 270, 270, 4320, 540, 270, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 270, 540, 540, 4320, 4320, 540, 4320, 270, 4320, 540, 540, 540, 4320, 540, 270, 270, 540, 540, 270, 540, 270, 270, 270, 4320, 540]
Prompts retrieved: 112050 . Total input tokens: 24972799 . Total output tokens: 22423910
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 4.014618382323533,
    "estimated_duration": 3600.0236064759383,
    "input_throughput": 2576.5250492565056,
    "output_throughput": 2284.4955753083805,
    "total_throughput": 4861.020624564886,
    "itl": 26.138342193306457,
    "ttft": 39563.31440355628,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2486,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.6083725314170545,
    "arrivals": 37601,
    "finished_requests": 37353,
    "scheduler_time": 11.808419950523813
}
#Debug simulation 
Total elapsed time: 4.014766652137041. Arrivals time: 0.10507900780066848 Scheduler time: 3.5507502825930715 Scheduler overhead time: 0.13366698008030653 Adapter cache time: 0.03326864121481776 Engine time: 0.12947983341291547 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-16/adapters_64_slots_16_rate_0.4-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-16/adapters_64_slots_16_rate_0.4-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [21 21 22]
Adapter prompts. [270, 540, 4320, 4320, 270, 4320, 270, 540, 270, 4320, 540, 4320, 270, 540, 4320, 4320, 4320, 270, 4320, 540, 540, 270, 270, 270, 4320, 270, 270, 270, 4320, 540, 270, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 270, 540, 540, 4320, 4320, 540, 4320, 270, 4320, 540, 540, 540, 4320, 540, 270, 270, 540, 540, 270, 540, 270, 270, 270, 4320, 540]
Prompts retrieved: 112050 . Total input tokens: 24972799 . Total output tokens: 22423910
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 4.01120911212638,
    "estimated_duration": 3600.0108314982845,
    "input_throughput": 2576.503636834799,
    "output_throughput": 2284.4934043093363,
    "total_throughput": 4860.997041144135,
    "itl": 26.144252438156034,
    "ttft": 39658.18219671254,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2485,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.11589792717447,
    "arrivals": 37601,
    "finished_requests": 37352,
    "scheduler_time": 11.812555289785008
}
#Debug simulation 
Total elapsed time: 4.0112973428331316. Arrivals time: 0.10198113601654768 Scheduler time: 3.5515186870470643 Scheduler overhead time: 0.13194264192134142 Adapter cache time: 0.03381324838846922 Engine time: 0.12978197680786252 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-32/adapters_64_slots_16_rate_0.4-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-32/adapters_64_slots_16_rate_0.4-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [21 21 22]
Adapter prompts. [270, 540, 4320, 4320, 270, 4320, 270, 540, 270, 4320, 540, 4320, 270, 540, 4320, 4320, 4320, 270, 4320, 540, 540, 270, 270, 270, 4320, 270, 270, 270, 4320, 540, 270, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 270, 540, 540, 4320, 4320, 540, 4320, 270, 4320, 540, 540, 540, 4320, 540, 270, 270, 540, 540, 270, 540, 270, 270, 270, 4320, 540]
Prompts retrieved: 112050 . Total input tokens: 24972799 . Total output tokens: 22423910
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 4.011374942958355,
    "estimated_duration": 3600.0019663905205,
    "input_throughput": 2576.35637052146,
    "output_throughput": 2285.2304184290465,
    "total_throughput": 4861.586788950506,
    "itl": 26.14188043312207,
    "ttft": 39417.18995985453,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2482,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.118903335984756,
    "arrivals": 37601,
    "finished_requests": 37354,
    "scheduler_time": 11.818100168769318
}
#Debug simulation 
Total elapsed time: 4.011468417011201. Arrivals time: 0.10456158313900232 Scheduler time: 3.547983650583774 Scheduler overhead time: 0.1325990897603333 Adapter cache time: 0.03383896639570594 Engine time: 0.13016967568546534 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-16/adapters_64_slots_16_rate_0.4-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-16/adapters_64_slots_16_rate_0.4-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [21 21 22]
Adapter prompts. [270, 540, 4320, 4320, 270, 4320, 270, 540, 270, 4320, 540, 4320, 270, 540, 4320, 4320, 4320, 270, 4320, 540, 540, 270, 270, 270, 4320, 270, 270, 270, 4320, 540, 270, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 270, 540, 540, 4320, 4320, 540, 4320, 270, 4320, 540, 540, 540, 4320, 540, 270, 270, 540, 540, 270, 540, 270, 270, 270, 4320, 540]
Prompts retrieved: 112050 . Total input tokens: 24972799 . Total output tokens: 22423910
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 4.019311374053359,
    "estimated_duration": 3600.026289973218,
    "input_throughput": 2576.7564603171304,
    "output_throughput": 2285.114701221029,
    "total_throughput": 4861.87116153816,
    "itl": 26.160802261115382,
    "ttft": 38667.6823536507,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2457,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.682827521650764,
    "arrivals": 37601,
    "finished_requests": 37364,
    "scheduler_time": 11.859021168831546
}
#Debug simulation 
Total elapsed time: 4.019402815960348. Arrivals time: 0.10599721828475595 Scheduler time: 3.5553970029577613 Scheduler overhead time: 0.13284287694841623 Adapter cache time: 0.033293984830379486 Engine time: 0.12956741452217102 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-32/adapters_64_slots_16_rate_0.4-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-32/adapters_64_slots_16_rate_0.4-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [21 21 22]
Adapter prompts. [270, 540, 4320, 4320, 270, 4320, 270, 540, 270, 4320, 540, 4320, 270, 540, 4320, 4320, 4320, 270, 4320, 540, 540, 270, 270, 270, 4320, 270, 270, 270, 4320, 540, 270, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 270, 540, 540, 4320, 4320, 540, 4320, 270, 4320, 540, 540, 540, 4320, 540, 270, 270, 540, 540, 270, 540, 270, 270, 270, 4320, 540]
Prompts retrieved: 112050 . Total input tokens: 24972799 . Total output tokens: 22423910
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 4.006525916978717,
    "estimated_duration": 3600.0188756406483,
    "input_throughput": 2577.5648185590935,
    "output_throughput": 2285.308295372735,
    "total_throughput": 4862.873113931829,
    "itl": 26.14918185467412,
    "ttft": 38191.49186838126,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2493,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.263737006932285,
    "arrivals": 37601,
    "finished_requests": 37367,
    "scheduler_time": 11.808861732110685
}
#Debug simulation 
Total elapsed time: 4.00664217909798. Arrivals time: 0.10289288824424148 Scheduler time: 3.5456144800409675 Scheduler overhead time: 0.1324074170552194 Adapter cache time: 0.03364173090085387 Engine time: 0.12978495378047228 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-16/adapters_64_slots_16_rate_0.4-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-16/adapters_64_slots_16_rate_0.4-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [21 21 22]
Adapter prompts. [270, 540, 4320, 4320, 270, 4320, 270, 540, 270, 4320, 540, 4320, 270, 540, 4320, 4320, 4320, 270, 4320, 540, 540, 270, 270, 270, 4320, 270, 270, 270, 4320, 540, 270, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 270, 540, 540, 4320, 4320, 540, 4320, 270, 4320, 540, 540, 540, 4320, 540, 270, 270, 540, 540, 270, 540, 270, 270, 270, 4320, 540]
Prompts retrieved: 112050 . Total input tokens: 24972799 . Total output tokens: 22423910
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 3.9908351521007717,
    "estimated_duration": 3600.0012419162063,
    "input_throughput": 2576.751055525307,
    "output_throughput": 2284.7886562455387,
    "total_throughput": 4861.539711770845,
    "itl": 26.128112791083296,
    "ttft": 39058.40418799273,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2505,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.49007598872972,
    "arrivals": 37601,
    "finished_requests": 37356,
    "scheduler_time": 11.769860822107043
}
#Debug simulation 
Total elapsed time: 3.9909314969554543. Arrivals time: 0.10944940894842148 Scheduler time: 3.5242825052700937 Scheduler overhead time: 0.13174768025055528 Adapter cache time: 0.033263837452977896 Engine time: 0.13006616523489356 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-32/adapters_64_slots_16_rate_0.4-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-32/adapters_64_slots_16_rate_0.4-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [21 21 22]
Adapter prompts. [270, 540, 4320, 4320, 270, 4320, 270, 540, 270, 4320, 540, 4320, 270, 540, 4320, 4320, 4320, 270, 4320, 540, 540, 270, 270, 270, 4320, 270, 270, 270, 4320, 540, 270, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 270, 540, 540, 4320, 4320, 540, 4320, 270, 4320, 540, 540, 540, 4320, 540, 270, 270, 540, 540, 270, 540, 270, 270, 270, 4320, 540]
Prompts retrieved: 112050 . Total input tokens: 24972799 . Total output tokens: 22423910
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 4.034865078050643,
    "estimated_duration": 3600.0021781331357,
    "input_throughput": 2577.0406630173165,
    "output_throughput": 2285.7372281555567,
    "total_throughput": 4862.777891172874,
    "itl": 26.13925152271272,
    "ttft": 38463.6880471289,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2455,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.239957898817602,
    "arrivals": 37601,
    "finished_requests": 37365,
    "scheduler_time": 11.856803969405071
}
#Debug simulation 
Total elapsed time: 4.034963100217283. Arrivals time: 0.1032075067050755 Scheduler time: 3.573008188046515 Scheduler overhead time: 0.13270058203488588 Adapter cache time: 0.03304170863702893 Engine time: 0.13048173626884818 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-8/adapters_64_slots_16_rate_0.4-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-8/adapters_64_slots_16_rate_0.4-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [21 21 22]
Adapter prompts. [135, 540, 4320, 4320, 135, 4320, 135, 540, 135, 4320, 540, 4320, 135, 540, 4320, 4320, 4320, 135, 4320, 540, 540, 135, 135, 135, 4320, 135, 135, 135, 4320, 540, 135, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 135, 540, 540, 4320, 4320, 540, 4320, 135, 4320, 540, 540, 540, 4320, 540, 135, 135, 540, 540, 135, 540, 135, 135, 135, 4320, 540]
Prompts retrieved: 109215 . Total input tokens: 24374214 . Total output tokens: 21824796
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 3.8066852940246463,
    "estimated_duration": 3599.843026254327,
    "input_throughput": 2514.86521328122,
    "output_throughput": 2246.5285127765032,
    "total_throughput": 4761.393726057723,
    "itl": 25.896061708764783,
    "ttft": 32588.00724835576,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2434,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.449227168732546,
    "arrivals": 36626,
    "finished_requests": 36424,
    "scheduler_time": 10.394237582181894
}
#Debug simulation 
Total elapsed time: 3.806787619832903. Arrivals time: 0.10121724242344499 Scheduler time: 3.345993227791041 Scheduler overhead time: 0.13362262351438403 Adapter cache time: 0.03340343339368701 Engine time: 0.1301538050174713 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-16/adapters_64_slots_16_rate_0.4-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-16/adapters_64_slots_16_rate_0.4-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [21 21 22]
Adapter prompts. [135, 540, 4320, 4320, 135, 4320, 135, 540, 135, 4320, 540, 4320, 135, 540, 4320, 4320, 4320, 135, 4320, 540, 540, 135, 135, 135, 4320, 135, 135, 135, 4320, 540, 135, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 135, 540, 540, 4320, 4320, 540, 4320, 135, 4320, 540, 540, 540, 4320, 540, 135, 135, 540, 540, 135, 540, 135, 135, 135, 4320, 540]
Prompts retrieved: 109215 . Total input tokens: 24374214 . Total output tokens: 21824796
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.783092000056058,
    "estimated_duration": 3599.8410341975755,
    "input_throughput": 2514.177685631454,
    "output_throughput": 2244.99413258159,
    "total_throughput": 4759.171818213044,
    "itl": 25.885390776881355,
    "ttft": 34108.871426086036,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2459,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.01609247231122,
    "arrivals": 36626,
    "finished_requests": 36408,
    "scheduler_time": 10.356907681011503
}
#Debug simulation 
Total elapsed time: 3.783188881818205. Arrivals time: 0.10284757195040584 Scheduler time: 3.32270642882213 Scheduler overhead time: 0.13292384380474687 Adapter cache time: 0.033067526295781136 Engine time: 0.12906849151477218 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-32/adapters_64_slots_16_rate_0.4-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-32/adapters_64_slots_16_rate_0.4-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [21 21 22]
Adapter prompts. [135, 540, 4320, 4320, 135, 4320, 135, 540, 135, 4320, 540, 4320, 135, 540, 4320, 4320, 4320, 135, 4320, 540, 540, 135, 135, 135, 4320, 135, 135, 135, 4320, 540, 135, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 135, 540, 540, 4320, 4320, 540, 4320, 135, 4320, 540, 540, 540, 4320, 540, 135, 135, 540, 540, 135, 540, 135, 135, 135, 4320, 540]
Prompts retrieved: 109215 . Total input tokens: 24374214 . Total output tokens: 21824796
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.7868400430306792,
    "estimated_duration": 3599.837673922415,
    "input_throughput": 2514.7145010392223,
    "output_throughput": 2246.031274846383,
    "total_throughput": 4760.745775885605,
    "itl": 25.90123040278743,
    "ttft": 33179.013164396216,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2452,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.009386405814402,
    "arrivals": 36626,
    "finished_requests": 36418,
    "scheduler_time": 10.383275556082413
}
#Debug simulation 
Total elapsed time: 3.7869314551353455. Arrivals time: 0.09953809855505824 Scheduler time: 3.3293303679674864 Scheduler overhead time: 0.13195314211770892 Adapter cache time: 0.033641955349594355 Engine time: 0.1300564082339406 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-16/adapters_64_slots_16_rate_0.4-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-16/adapters_64_slots_16_rate_0.4-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [21 21 22]
Adapter prompts. [135, 540, 4320, 4320, 135, 4320, 135, 540, 135, 4320, 540, 4320, 135, 540, 4320, 4320, 4320, 135, 4320, 540, 540, 135, 135, 135, 4320, 135, 135, 135, 4320, 540, 135, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 135, 540, 540, 4320, 4320, 540, 4320, 135, 4320, 540, 540, 540, 4320, 540, 135, 135, 540, 540, 135, 540, 135, 135, 135, 4320, 540]
Prompts retrieved: 109215 . Total input tokens: 24374214 . Total output tokens: 21824796
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 3.777890756726265,
    "estimated_duration": 3599.8388630171808,
    "input_throughput": 2514.7136703815277,
    "output_throughput": 2246.030532939833,
    "total_throughput": 4760.74420332136,
    "itl": 25.90422442893144,
    "ttft": 33165.44128625549,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2468,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.689976569832952,
    "arrivals": 36626,
    "finished_requests": 36418,
    "scheduler_time": 10.38206907640555
}
#Debug simulation 
Total elapsed time: 3.7780330097302794. Arrivals time: 0.10004240414127707 Scheduler time: 3.3201683326624334 Scheduler overhead time: 0.1327263256534934 Adapter cache time: 0.03341751731932163 Engine time: 0.1290631964802742 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-32/adapters_64_slots_16_rate_0.4-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-32/adapters_64_slots_16_rate_0.4-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [21 21 22]
Adapter prompts. [135, 540, 4320, 4320, 135, 4320, 135, 540, 135, 4320, 540, 4320, 135, 540, 4320, 4320, 4320, 135, 4320, 540, 540, 135, 135, 135, 4320, 135, 135, 135, 4320, 540, 135, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 135, 540, 540, 4320, 4320, 540, 4320, 135, 4320, 540, 540, 540, 4320, 540, 135, 135, 540, 540, 135, 540, 135, 135, 135, 4320, 540]
Prompts retrieved: 109215 . Total input tokens: 24374214 . Total output tokens: 21824796
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 3.7895124228671193,
    "estimated_duration": 3599.835750131948,
    "input_throughput": 2514.715844929366,
    "output_throughput": 2246.0324751493567,
    "total_throughput": 4760.748320078723,
    "itl": 25.90062060103095,
    "ttft": 33213.664959136615,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2435,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.063182601667735,
    "arrivals": 36626,
    "finished_requests": 36418,
    "scheduler_time": 10.404787439998165
}
#Debug simulation 
Total elapsed time: 3.789616391994059. Arrivals time: 0.10396588500589132 Scheduler time: 3.3285990548320115 Scheduler overhead time: 0.1322406609542668 Adapter cache time: 0.03327279118821025 Engine time: 0.12928041396662593 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-16/adapters_64_slots_16_rate_0.4-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-16/adapters_64_slots_16_rate_0.4-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [21 21 22]
Adapter prompts. [135, 540, 4320, 4320, 135, 4320, 135, 540, 135, 4320, 540, 4320, 135, 540, 4320, 4320, 4320, 135, 4320, 540, 540, 135, 135, 135, 4320, 135, 135, 135, 4320, 540, 135, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 135, 540, 540, 4320, 4320, 540, 4320, 135, 4320, 540, 540, 540, 4320, 540, 135, 135, 540, 540, 135, 540, 135, 135, 135, 4320, 540]
Prompts retrieved: 109215 . Total input tokens: 24374214 . Total output tokens: 21824796
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 3.801172793842852,
    "estimated_duration": 3599.8435105643734,
    "input_throughput": 2514.7104237819394,
    "output_throughput": 2246.0276332213125,
    "total_throughput": 4760.738057003252,
    "itl": 25.905926405570547,
    "ttft": 33203.031708328745,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2451,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.328613272805009,
    "arrivals": 36626,
    "finished_requests": 36418,
    "scheduler_time": 10.398752030886667
}
#Debug simulation 
Total elapsed time: 3.8012679889798164. Arrivals time: 0.10082178702577949 Scheduler time: 3.33724568458274 Scheduler overhead time: 0.13633411657065153 Adapter cache time: 0.033639620523899794 Engine time: 0.130128619261086 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-32/adapters_64_slots_16_rate_0.4-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-32/adapters_64_slots_16_rate_0.4-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [21 21 22]
Adapter prompts. [135, 540, 4320, 4320, 135, 4320, 135, 540, 135, 4320, 540, 4320, 135, 540, 4320, 4320, 4320, 135, 4320, 540, 540, 135, 135, 135, 4320, 135, 135, 135, 4320, 540, 135, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 135, 540, 540, 4320, 4320, 540, 4320, 135, 4320, 540, 540, 540, 4320, 540, 135, 135, 540, 540, 135, 540, 135, 135, 135, 4320, 540]
Prompts retrieved: 109215 . Total input tokens: 24374214 . Total output tokens: 21824796
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.7974818209186196,
    "estimated_duration": 3599.8467968072787,
    "input_throughput": 2514.708128142776,
    "output_throughput": 2246.025582858397,
    "total_throughput": 4760.733711001172,
    "itl": 25.90530646884025,
    "ttft": 33198.92063680959,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2448,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.19874421179259,
    "arrivals": 36626,
    "finished_requests": 36418,
    "scheduler_time": 10.393172648210248
}
#Debug simulation 
Total elapsed time: 3.7975786137394607. Arrivals time: 0.10181201854720712 Scheduler time: 3.3374464227817953 Scheduler overhead time: 0.1324588772840798 Adapter cache time: 0.03334516193717718 Engine time: 0.13015243643894792 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-8/adapters_64_slots_16_rate_0.4-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-8/adapters_64_slots_16_rate_0.4-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 540, 4320, 4320, 66, 4320, 66, 540, 66, 4320, 540, 4320, 66, 540, 4320, 4320, 4320, 66, 4320, 540, 540, 66, 66, 66, 4320, 66, 66, 66, 4320, 540, 66, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 66, 540, 540, 4320, 4320, 540, 4320, 66, 4320, 540, 540, 540, 4320, 540, 66, 66, 540, 540, 66, 540, 66, 66, 66, 4320, 540]
Prompts retrieved: 107766 . Total input tokens: 24055828 . Total output tokens: 21538374
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 3.607965003233403,
    "estimated_duration": 3599.9065031771997,
    "input_throughput": 2470.5883311553916,
    "output_throughput": 2182.9555831698167,
    "total_throughput": 4653.543914325209,
    "itl": 25.66156995324882,
    "ttft": 28075.363622932793,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2478,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.583888629465592,
    "arrivals": 36150,
    "finished_requests": 35975,
    "scheduler_time": 8.881701379559956
}
#Debug simulation 
Total elapsed time: 3.608055824879557. Arrivals time: 0.09925129171460867 Scheduler time: 3.1473268903791904 Scheduler overhead time: 0.13357562385499477 Adapter cache time: 0.033888289239257574 Engine time: 0.13099094666540623 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-16/adapters_64_slots_16_rate_0.4-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-16/adapters_64_slots_16_rate_0.4-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 540, 4320, 4320, 66, 4320, 66, 540, 66, 4320, 540, 4320, 66, 540, 4320, 4320, 4320, 66, 4320, 540, 540, 66, 66, 66, 4320, 66, 66, 66, 4320, 540, 66, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 66, 540, 540, 4320, 4320, 540, 4320, 66, 4320, 540, 540, 540, 4320, 540, 66, 66, 540, 540, 66, 540, 66, 66, 66, 4320, 540]
Prompts retrieved: 107766 . Total input tokens: 24055828 . Total output tokens: 21538374
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.6181303788907826,
    "estimated_duration": 3599.923192534903,
    "input_throughput": 2471.1643899646197,
    "output_throughput": 2184.0463197392983,
    "total_throughput": 4655.210709703918,
    "itl": 25.656399665596012,
    "ttft": 26990.714689835797,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2497,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.13992926647854,
    "arrivals": 36150,
    "finished_requests": 35986,
    "scheduler_time": 8.87715746758911
}
#Debug simulation 
Total elapsed time: 3.6182240890339017. Arrivals time: 0.0994465104304254 Scheduler time: 3.159029704052955 Scheduler overhead time: 0.13333686022087932 Adapter cache time: 0.033379029016941786 Engine time: 0.13032544683665037 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-32/adapters_64_slots_16_rate_0.4-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-32/adapters_64_slots_16_rate_0.4-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 540, 4320, 4320, 66, 4320, 66, 540, 66, 4320, 540, 4320, 66, 540, 4320, 4320, 4320, 66, 4320, 540, 540, 66, 66, 66, 4320, 66, 66, 66, 4320, 540, 66, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 66, 540, 540, 4320, 4320, 540, 4320, 66, 4320, 540, 540, 540, 4320, 540, 66, 66, 540, 540, 66, 540, 66, 66, 66, 4320, 540]
Prompts retrieved: 107766 . Total input tokens: 24055828 . Total output tokens: 21538374
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.613791699986905,
    "estimated_duration": 3599.9229639555124,
    "input_throughput": 2470.5770343006457,
    "output_throughput": 2182.9456015262426,
    "total_throughput": 4653.522635826888,
    "itl": 25.654299043360005,
    "ttft": 28070.83243300128,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2497,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.157136673834106,
    "arrivals": 36150,
    "finished_requests": 35975,
    "scheduler_time": 8.86581062364317
}
#Debug simulation 
Total elapsed time: 3.6138885961845517. Arrivals time: 0.10178302275016904 Scheduler time: 3.1504692025482655 Scheduler overhead time: 0.133690123911947 Adapter cache time: 0.03339570900425315 Engine time: 0.1316085341386497 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-16/adapters_64_slots_16_rate_0.4-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-16/adapters_64_slots_16_rate_0.4-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 540, 4320, 4320, 66, 4320, 66, 540, 66, 4320, 540, 4320, 66, 540, 4320, 4320, 4320, 66, 4320, 540, 540, 66, 66, 66, 4320, 66, 66, 66, 4320, 540, 66, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 66, 540, 540, 4320, 4320, 540, 4320, 66, 4320, 540, 540, 540, 4320, 540, 66, 66, 540, 540, 66, 540, 66, 66, 66, 4320, 540]
Prompts retrieved: 107766 . Total input tokens: 24055828 . Total output tokens: 21538374
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 3.606180477887392,
    "estimated_duration": 3599.926808223497,
    "input_throughput": 2470.5743960358413,
    "output_throughput": 2182.9432704155465,
    "total_throughput": 4653.517666451387,
    "itl": 25.663497155594996,
    "ttft": 28077.30037952141,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2480,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.709921955952607,
    "arrivals": 36150,
    "finished_requests": 35975,
    "scheduler_time": 8.879274438376175
}
#Debug simulation 
Total elapsed time: 3.606268819887191. Arrivals time: 0.0984584717079997 Scheduler time: 3.1477851807139814 Scheduler overhead time: 0.1334784496575594 Adapter cache time: 0.03366166865453124 Engine time: 0.13012910122051835 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-32/adapters_64_slots_16_rate_0.4-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-32/adapters_64_slots_16_rate_0.4-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 540, 4320, 4320, 66, 4320, 66, 540, 66, 4320, 540, 4320, 66, 540, 4320, 4320, 4320, 66, 4320, 540, 540, 66, 66, 66, 4320, 66, 66, 66, 4320, 540, 66, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 66, 540, 540, 4320, 4320, 540, 4320, 66, 4320, 540, 540, 540, 4320, 540, 66, 66, 540, 540, 66, 540, 66, 66, 66, 4320, 540]
Prompts retrieved: 107766 . Total input tokens: 24055828 . Total output tokens: 21538374
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 3.606049188878387,
    "estimated_duration": 3599.919158546637,
    "input_throughput": 2470.8335404928976,
    "output_throughput": 2183.628202132629,
    "total_throughput": 4654.461742625527,
    "itl": 25.66441465469494,
    "ttft": 27235.104643093444,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2490,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.247524281516426,
    "arrivals": 36150,
    "finished_requests": 35983,
    "scheduler_time": 8.864383947340553
}
#Debug simulation 
Total elapsed time: 3.6061670389026403. Arrivals time: 0.09929661871865392 Scheduler time: 3.143782730679959 Scheduler overhead time: 0.13454849971458316 Adapter cache time: 0.03350923443213105 Engine time: 0.13213670160621405 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-16/adapters_64_slots_16_rate_0.4-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-16/adapters_64_slots_16_rate_0.4-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 540, 4320, 4320, 66, 4320, 66, 540, 66, 4320, 540, 4320, 66, 540, 4320, 4320, 4320, 66, 4320, 540, 540, 66, 66, 66, 4320, 66, 66, 66, 4320, 540, 66, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 66, 540, 540, 4320, 4320, 540, 4320, 66, 4320, 540, 540, 540, 4320, 540, 66, 66, 540, 540, 66, 540, 66, 66, 66, 4320, 540]
Prompts retrieved: 107766 . Total input tokens: 24055828 . Total output tokens: 21538374
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 3.592049388680607,
    "estimated_duration": 3599.928126563927,
    "input_throughput": 2471.089612694808,
    "output_throughput": 2183.8327665457614,
    "total_throughput": 4654.922379240569,
    "itl": 25.67567496578602,
    "ttft": 26951.488654717392,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2496,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.463165536075602,
    "arrivals": 36150,
    "finished_requests": 35986,
    "scheduler_time": 8.898590796794265
}
#Debug simulation 
Total elapsed time: 3.592145132832229. Arrivals time: 0.10066119814291596 Scheduler time: 3.130989325698465 Scheduler overhead time: 0.13365589920431376 Adapter cache time: 0.03362323762848973 Engine time: 0.13067243993282318 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-32/adapters_64_slots_16_rate_0.4-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-32/adapters_64_slots_16_rate_0.4-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 540, 4320, 4320, 66, 4320, 66, 540, 66, 4320, 540, 4320, 66, 540, 4320, 4320, 4320, 66, 4320, 540, 540, 66, 66, 66, 4320, 66, 66, 66, 4320, 540, 66, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 66, 540, 540, 4320, 4320, 540, 4320, 66, 4320, 540, 540, 540, 4320, 540, 66, 66, 540, 540, 66, 540, 66, 66, 66, 4320, 540]
Prompts retrieved: 107766 . Total input tokens: 24055828 . Total output tokens: 21538374
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.621603967156261,
    "estimated_duration": 3599.906234713621,
    "input_throughput": 2470.842410901738,
    "output_throughput": 2183.6360414607707,
    "total_throughput": 4654.4784523625085,
    "itl": 25.667103143399235,
    "ttft": 27234.714979530458,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2491,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.342116556875036,
    "arrivals": 36150,
    "finished_requests": 35983,
    "scheduler_time": 8.869067712052086
}
#Debug simulation 
Total elapsed time: 3.6216944972984493. Arrivals time: 0.09883284894749522 Scheduler time: 3.16123123280704 Scheduler overhead time: 0.1334185218438506 Adapter cache time: 0.033746379893273115 Engine time: 0.1315993661992252 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-8/adapters_64_slots_16_rate_0.4-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-8/adapters_64_slots_16_rate_0.4-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 540, 4320, 4320, 33, 4320, 33, 540, 33, 4320, 540, 4320, 33, 540, 4320, 4320, 4320, 33, 4320, 540, 540, 33, 33, 33, 4320, 33, 33, 33, 4320, 540, 33, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 33, 540, 540, 4320, 4320, 540, 4320, 33, 4320, 540, 540, 540, 4320, 540, 33, 33, 540, 540, 33, 540, 33, 33, 33, 4320, 540]
Prompts retrieved: 107073 . Total input tokens: 23891210 . Total output tokens: 21397833
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 3.596085235942155,
    "estimated_duration": 3599.927747366841,
    "input_throughput": 2469.087332794804,
    "output_throughput": 2170.163833347596,
    "total_throughput": 4639.2511661424005,
    "itl": 25.551325305183187,
    "ttft": 27294.81217798478,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2290,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.008516933606214,
    "arrivals": 35929,
    "finished_requests": 35759,
    "scheduler_time": 8.519760687420685
}
#Debug simulation 
Total elapsed time: 3.5961791831068695. Arrivals time: 0.10135226231068373 Scheduler time: 3.1343761142343283 Scheduler overhead time: 0.13351058773696423 Adapter cache time: 0.03267841134220362 Engine time: 0.1314791077747941 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-16/adapters_64_slots_16_rate_0.4-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-16/adapters_64_slots_16_rate_0.4-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 540, 4320, 4320, 33, 4320, 33, 540, 33, 4320, 540, 4320, 33, 540, 4320, 4320, 4320, 33, 4320, 540, 540, 33, 33, 33, 4320, 33, 33, 33, 4320, 540, 33, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 33, 540, 540, 4320, 4320, 540, 4320, 33, 4320, 540, 540, 540, 4320, 540, 33, 33, 540, 540, 33, 540, 33, 33, 33, 4320, 540]
Prompts retrieved: 107073 . Total input tokens: 23891210 . Total output tokens: 21397833
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.5598552958108485,
    "estimated_duration": 3599.935894138652,
    "input_throughput": 2468.3433986887985,
    "output_throughput": 2167.748601497579,
    "total_throughput": 4636.092000186378,
    "itl": 25.544851622764646,
    "ttft": 28627.371262954635,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2279,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.4255832184685175,
    "arrivals": 35929,
    "finished_requests": 35747,
    "scheduler_time": 8.557937861545014
}
#Debug simulation 
Total elapsed time: 3.559951600152999. Arrivals time: 0.0976848634891212 Scheduler time: 3.1023712949827313 Scheduler overhead time: 0.13317793607711792 Adapter cache time: 0.03264177264645696 Engine time: 0.1313121784478426 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-32/adapters_64_slots_16_rate_0.4-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-32/adapters_64_slots_16_rate_0.4-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 540, 4320, 4320, 33, 4320, 33, 540, 33, 4320, 540, 4320, 33, 540, 4320, 4320, 4320, 33, 4320, 540, 540, 33, 33, 33, 4320, 33, 33, 33, 4320, 540, 33, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 33, 540, 540, 4320, 4320, 540, 4320, 33, 4320, 540, 540, 540, 4320, 540, 33, 33, 540, 540, 33, 540, 33, 33, 33, 4320, 540]
Prompts retrieved: 107073 . Total input tokens: 23891210 . Total output tokens: 21397833
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.556748246308416,
    "estimated_duration": 3599.9238221623405,
    "input_throughput": 2469.2339169167963,
    "output_throughput": 2169.5522977229807,
    "total_throughput": 4638.7862146397765,
    "itl": 25.57275784650188,
    "ttft": 27599.557034878104,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2284,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.458954529855351,
    "arrivals": 35929,
    "finished_requests": 35757,
    "scheduler_time": 8.55687363357635
}
#Debug simulation 
Total elapsed time: 3.5569506851024926. Arrivals time: 0.09726684726774693 Scheduler time: 3.0992796034552157 Scheduler overhead time: 0.13385016890242696 Adapter cache time: 0.032729022204875946 Engine time: 0.13066082587465644 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-16/adapters_64_slots_16_rate_0.4-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-16/adapters_64_slots_16_rate_0.4-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 540, 4320, 4320, 33, 4320, 33, 540, 33, 4320, 540, 4320, 33, 540, 4320, 4320, 4320, 33, 4320, 540, 540, 33, 33, 33, 4320, 33, 33, 33, 4320, 540, 33, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 33, 540, 540, 4320, 4320, 540, 4320, 33, 4320, 540, 540, 540, 4320, 540, 33, 33, 540, 540, 33, 540, 33, 33, 33, 4320, 540]
Prompts retrieved: 107073 . Total input tokens: 23891210 . Total output tokens: 21397833
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 3.5879968954250216,
    "estimated_duration": 3599.9201985431173,
    "input_throughput": 2469.0925103276395,
    "output_throughput": 2170.1683840552023,
    "total_throughput": 4639.260894382842,
    "itl": 25.568482346246114,
    "ttft": 27373.979734507895,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2285,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.102346429340297,
    "arrivals": 35929,
    "finished_requests": 35759,
    "scheduler_time": 8.549704677690354
}
#Debug simulation 
Total elapsed time: 3.588091076351702. Arrivals time: 0.1003038533963263 Scheduler time: 3.1260627605952322 Scheduler overhead time: 0.13385314168408513 Adapter cache time: 0.03300953656435013 Engine time: 0.1315637044608593 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-32/adapters_64_slots_16_rate_0.4-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-32/adapters_64_slots_16_rate_0.4-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 540, 4320, 4320, 33, 4320, 33, 540, 33, 4320, 540, 4320, 33, 540, 4320, 4320, 4320, 33, 4320, 540, 540, 33, 33, 33, 4320, 33, 33, 33, 4320, 540, 33, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 33, 540, 540, 4320, 4320, 540, 4320, 33, 4320, 540, 540, 540, 4320, 540, 33, 33, 540, 540, 33, 540, 33, 33, 33, 4320, 540]
Prompts retrieved: 107073 . Total input tokens: 23891210 . Total output tokens: 21397833
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 3.5916522098705173,
    "estimated_duration": 3599.924177266097,
    "input_throughput": 2469.0897814270775,
    "output_throughput": 2170.1659855327907,
    "total_throughput": 4639.255766959868,
    "itl": 25.573174522288912,
    "ttft": 27431.332210092853,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2279,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.548398387580925,
    "arrivals": 35929,
    "finished_requests": 35759,
    "scheduler_time": 8.560960056718537
}
#Debug simulation 
Total elapsed time: 3.591741875279695. Arrivals time: 0.10027421917766333 Scheduler time: 3.1302385325543582 Scheduler overhead time: 0.13348601618781686 Adapter cache time: 0.0327394506894052 Engine time: 0.13177066948264837 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-16/adapters_64_slots_16_rate_0.4-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-16/adapters_64_slots_16_rate_0.4-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 540, 4320, 4320, 33, 4320, 33, 540, 33, 4320, 540, 4320, 33, 540, 4320, 4320, 4320, 33, 4320, 540, 540, 33, 33, 33, 4320, 33, 33, 33, 4320, 540, 33, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 33, 540, 540, 4320, 4320, 540, 4320, 33, 4320, 540, 540, 540, 4320, 540, 33, 33, 540, 540, 33, 540, 33, 33, 33, 4320, 540]
Prompts retrieved: 107073 . Total input tokens: 23891210 . Total output tokens: 21397833
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 3.573434534948319,
    "estimated_duration": 3599.9324535565324,
    "input_throughput": 2469.084104958309,
    "output_throughput": 2170.1609962936254,
    "total_throughput": 4639.245101251934,
    "itl": 25.56548773625988,
    "ttft": 27372.96670082135,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2285,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.832264923851265,
    "arrivals": 35929,
    "finished_requests": 35759,
    "scheduler_time": 8.547596848821442
}
#Debug simulation 
Total elapsed time: 3.57353508612141. Arrivals time: 0.10016357712447643 Scheduler time: 3.1118061039596796 Scheduler overhead time: 0.13499168306589127 Adapter cache time: 0.03305632760748267 Engine time: 0.13019420579075813 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-32/adapters_64_slots_16_rate_0.4-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-32/adapters_64_slots_16_rate_0.4-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 540, 4320, 4320, 33, 4320, 33, 540, 33, 4320, 540, 4320, 33, 540, 4320, 4320, 4320, 33, 4320, 540, 540, 33, 33, 33, 4320, 33, 33, 33, 4320, 540, 33, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 33, 540, 540, 4320, 4320, 540, 4320, 33, 4320, 540, 540, 540, 4320, 540, 33, 33, 540, 540, 33, 540, 33, 33, 33, 4320, 540]
Prompts retrieved: 107073 . Total input tokens: 23891210 . Total output tokens: 21397833
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.5440672929398715,
    "estimated_duration": 3599.9301055291867,
    "input_throughput": 2468.445980757099,
    "output_throughput": 2168.18404002114,
    "total_throughput": 4636.630020778239,
    "itl": 25.575283285367675,
    "ttft": 28382.370566696092,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2289,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.665283577777143,
    "arrivals": 35929,
    "finished_requests": 35749,
    "scheduler_time": 8.557691322887033
}
#Debug simulation 
Total elapsed time: 3.5441582431085408. Arrivals time: 0.09732483373954892 Scheduler time: 3.0869678426533937 Scheduler overhead time: 0.13390887062996626 Adapter cache time: 0.032845898531377316 Engine time: 0.13001316506415606 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-8/adapters_64_slots_16_rate_0.4-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-8/adapters_64_slots_16_rate_0.4-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 4320, 4320, 135, 4320, 135, 270, 135, 4320, 270, 4320, 135, 270, 4320, 4320, 4320, 135, 4320, 270, 270, 135, 135, 135, 4320, 135, 135, 135, 4320, 270, 135, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 135, 270, 270, 4320, 4320, 270, 4320, 135, 4320, 270, 270, 270, 4320, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 4320, 270]
Prompts retrieved: 103545 . Total input tokens: 23082393 . Total output tokens: 20692227
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 3.412752374075353,
    "estimated_duration": 3599.8819152312403,
    "input_throughput": 2366.4156771244507,
    "output_throughput": 2106.2782553835364,
    "total_throughput": 4472.693932507987,
    "itl": 25.357211375092067,
    "ttft": 25297.275135787408,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2601,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.960328621969333,
    "arrivals": 34705,
    "finished_requests": 34548,
    "scheduler_time": 7.229750621695503
}
#Debug simulation 
Total elapsed time: 3.4128479310311377. Arrivals time: 0.09531420934945345 Scheduler time: 2.954285817220807 Scheduler overhead time: 0.1344960224814713 Adapter cache time: 0.034031754825264215 Engine time: 0.13115043425932527 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-16/adapters_64_slots_16_rate_0.4-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-16/adapters_64_slots_16_rate_0.4-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 4320, 4320, 135, 4320, 135, 270, 135, 4320, 270, 4320, 135, 270, 4320, 4320, 4320, 135, 4320, 270, 270, 135, 135, 135, 4320, 135, 135, 135, 4320, 270, 135, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 135, 270, 270, 4320, 4320, 270, 4320, 135, 4320, 270, 270, 270, 4320, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 4320, 270]
Prompts retrieved: 103545 . Total input tokens: 23082393 . Total output tokens: 20692227
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.4261157121509314,
    "estimated_duration": 3599.903931593758,
    "input_throughput": 2366.63093290608,
    "output_throughput": 2106.988448617286,
    "total_throughput": 4473.6193815233655,
    "itl": 25.36220866977416,
    "ttft": 24748.96529050337,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2600,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.476097523825905,
    "arrivals": 34705,
    "finished_requests": 34553,
    "scheduler_time": 7.249967733625419
}
#Debug simulation 
Total elapsed time: 3.4262132551521063. Arrivals time: 0.09762368444353342 Scheduler time: 2.963965518400073 Scheduler overhead time: 0.1342953061684966 Adapter cache time: 0.03399862302467227 Engine time: 0.1329671354033053 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-32/adapters_64_slots_16_rate_0.4-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-32/adapters_64_slots_16_rate_0.4-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 4320, 4320, 135, 4320, 135, 270, 135, 4320, 270, 4320, 135, 270, 4320, 4320, 4320, 135, 4320, 270, 270, 135, 135, 135, 4320, 135, 135, 135, 4320, 270, 135, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 135, 270, 270, 4320, 4320, 270, 4320, 135, 4320, 270, 270, 270, 4320, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 4320, 270]
Prompts retrieved: 103545 . Total input tokens: 23082393 . Total output tokens: 20692227
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.4031124357134104,
    "estimated_duration": 3599.8825369372485,
    "input_throughput": 2366.5980521820866,
    "output_throughput": 2107.2390340974707,
    "total_throughput": 4473.837086279557,
    "itl": 25.36135290988063,
    "ttft": 24873.0105144942,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2602,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.499301735088103,
    "arrivals": 34705,
    "finished_requests": 34552,
    "scheduler_time": 7.256836637710396
}
#Debug simulation 
Total elapsed time: 3.403196267783642. Arrivals time: 0.09519379632547498 Scheduler time: 2.945565940346569 Scheduler overhead time: 0.13399446057155728 Adapter cache time: 0.03413502546027303 Engine time: 0.1308525614440441 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-16/adapters_64_slots_16_rate_0.4-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-16/adapters_64_slots_16_rate_0.4-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 4320, 4320, 135, 4320, 135, 270, 135, 4320, 270, 4320, 135, 270, 4320, 4320, 4320, 135, 4320, 270, 270, 135, 135, 135, 4320, 135, 135, 135, 4320, 270, 135, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 135, 270, 270, 4320, 4320, 270, 4320, 135, 4320, 270, 270, 270, 4320, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 4320, 270]
Prompts retrieved: 103545 . Total input tokens: 23082393 . Total output tokens: 20692227
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 3.469902110286057,
    "estimated_duration": 3599.8947599867897,
    "input_throughput": 2367.139199377948,
    "output_throughput": 2107.2421572756857,
    "total_throughput": 4474.381356653634,
    "itl": 25.36207018201359,
    "ttft": 24429.969432897757,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2611,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.154735935982048,
    "arrivals": 34705,
    "finished_requests": 34556,
    "scheduler_time": 7.236186976170603
}
#Debug simulation 
Total elapsed time: 3.4699872699566185. Arrivals time: 0.09651384362950921 Scheduler time: 3.007564684841782 Scheduler overhead time: 0.1353867701254785 Adapter cache time: 0.03466416848823428 Engine time: 0.1324838581494987 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-32/adapters_64_slots_16_rate_0.4-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-32/adapters_64_slots_16_rate_0.4-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 4320, 4320, 135, 4320, 135, 270, 135, 4320, 270, 4320, 135, 270, 4320, 4320, 4320, 135, 4320, 270, 270, 135, 135, 135, 4320, 135, 135, 135, 4320, 270, 135, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 135, 270, 270, 4320, 4320, 270, 4320, 135, 4320, 270, 270, 270, 4320, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 4320, 270]
Prompts retrieved: 103545 . Total input tokens: 23082393 . Total output tokens: 20692227
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 3.3861569887958467,
    "estimated_duration": 3599.887468454352,
    "input_throughput": 2366.5948101588638,
    "output_throughput": 2107.236147372419,
    "total_throughput": 4473.830957531283,
    "itl": 25.363579042703957,
    "ttft": 24862.25473509503,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2597,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.592438178676835,
    "arrivals": 34705,
    "finished_requests": 34552,
    "scheduler_time": 7.253629773278061
}
#Debug simulation 
Total elapsed time: 3.386282623745501. Arrivals time: 0.09785668924450874 Scheduler time: 2.9222877165302634 Scheduler overhead time: 0.13454960705712438 Adapter cache time: 0.034630725625902414 Engine time: 0.13318296009674668 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-16/adapters_64_slots_16_rate_0.4-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-16/adapters_64_slots_16_rate_0.4-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 4320, 4320, 135, 4320, 135, 270, 135, 4320, 270, 4320, 135, 270, 4320, 4320, 4320, 135, 4320, 270, 270, 135, 135, 135, 4320, 135, 135, 135, 4320, 270, 135, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 135, 270, 270, 4320, 4320, 270, 4320, 135, 4320, 270, 270, 270, 4320, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 4320, 270]
Prompts retrieved: 103545 . Total input tokens: 23082393 . Total output tokens: 20692227
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 3.4182298821397126,
    "estimated_duration": 3599.88813408031,
    "input_throughput": 2367.1435563030454,
    "output_throughput": 2107.2460358377257,
    "total_throughput": 4474.389592140771,
    "itl": 25.354197120769236,
    "ttft": 24430.62029022696,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2612,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.810011370284242,
    "arrivals": 34705,
    "finished_requests": 34556,
    "scheduler_time": 7.22778924615895
}
#Debug simulation 
Total elapsed time: 3.418319020885974. Arrivals time: 0.09561591502279043 Scheduler time: 2.952905807644129 Scheduler overhead time: 0.13560346001759171 Adapter cache time: 0.034573815297335386 Engine time: 0.13622528640553355 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-32/adapters_64_slots_16_rate_0.4-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-32/adapters_64_slots_16_rate_0.4-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 4320, 4320, 135, 4320, 135, 270, 135, 4320, 270, 4320, 135, 270, 4320, 4320, 4320, 135, 4320, 270, 270, 135, 135, 135, 4320, 135, 135, 135, 4320, 270, 135, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 135, 270, 270, 4320, 4320, 270, 4320, 135, 4320, 270, 270, 270, 4320, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 4320, 270]
Prompts retrieved: 103545 . Total input tokens: 23082393 . Total output tokens: 20692227
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.4130964991636574,
    "estimated_duration": 3599.903296455897,
    "input_throughput": 2367.133586168652,
    "output_throughput": 2107.2371603615757,
    "total_throughput": 4474.370746530228,
    "itl": 25.363460775699657,
    "ttft": 24434.131059114585,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2612,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.749274445175717,
    "arrivals": 34705,
    "finished_requests": 34556,
    "scheduler_time": 7.23538205667799
}
#Debug simulation 
Total elapsed time: 3.4131885850802064. Arrivals time: 0.09743798803538084 Scheduler time: 2.948666205164045 Scheduler overhead time: 0.1345462896861136 Adapter cache time: 0.036465165205299854 Engine time: 0.13248960301280022 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_64_slots_16_rate_0.4-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_64_slots_16_rate_0.4-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 4320, 4320, 66, 4320, 66, 270, 66, 4320, 270, 4320, 66, 270, 4320, 4320, 4320, 66, 4320, 270, 270, 66, 66, 66, 4320, 66, 66, 66, 4320, 270, 66, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 66, 270, 270, 4320, 4320, 270, 4320, 66, 4320, 270, 270, 270, 4320, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 4320, 270]
Prompts retrieved: 102096 . Total input tokens: 22764722 . Total output tokens: 20398109
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 3.337986331898719,
    "estimated_duration": 3599.7487385763916,
    "input_throughput": 2365.2525824252925,
    "output_throughput": 2106.2683955543243,
    "total_throughput": 4471.520977979617,
    "itl": 25.31648264225704,
    "ttft": 23679.209429665272,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2336,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.149299369827125,
    "arrivals": 34232,
    "finished_requests": 34081,
    "scheduler_time": 6.903846375861691
}
#Debug simulation 
Total elapsed time: 3.3380712191574275. Arrivals time: 0.09427144704386592 Scheduler time: 2.8800090295262635 Scheduler overhead time: 0.13491140119731426 Adapter cache time: 0.03302782913669944 Engine time: 0.13228867668658495 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_64_slots_16_rate_0.4-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_64_slots_16_rate_0.4-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 4320, 4320, 66, 4320, 66, 270, 66, 4320, 270, 4320, 66, 270, 4320, 4320, 4320, 66, 4320, 270, 270, 66, 66, 66, 4320, 66, 66, 66, 4320, 270, 66, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 66, 270, 270, 4320, 4320, 270, 4320, 66, 4320, 270, 270, 270, 4320, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 4320, 270]
Prompts retrieved: 102096 . Total input tokens: 22764722 . Total output tokens: 20398109
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.3426956310868263,
    "estimated_duration": 3599.7375115195396,
    "input_throughput": 2365.1743975093405,
    "output_throughput": 2106.1207867902754,
    "total_throughput": 4471.295184299615,
    "itl": 25.31786551255307,
    "ttft": 24098.545803006004,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2325,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.588458441777301,
    "arrivals": 34232,
    "finished_requests": 34077,
    "scheduler_time": 6.902272577169203
}
#Debug simulation 
Total elapsed time: 3.342834701295942. Arrivals time: 0.09468999318778515 Scheduler time: 2.884374041110277 Scheduler overhead time: 0.1350099192932248 Adapter cache time: 0.03301979834213853 Engine time: 0.13220476126298308 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-32/adapters_64_slots_16_rate_0.4-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-32/adapters_64_slots_16_rate_0.4-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 4320, 4320, 66, 4320, 66, 270, 66, 4320, 270, 4320, 66, 270, 4320, 4320, 4320, 66, 4320, 270, 270, 66, 66, 66, 4320, 66, 66, 66, 4320, 270, 66, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 66, 270, 270, 4320, 4320, 270, 4320, 66, 4320, 270, 270, 270, 4320, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 4320, 270]
Prompts retrieved: 102096 . Total input tokens: 22764722 . Total output tokens: 20398109
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.3382721757516265,
    "estimated_duration": 3599.733021161102,
    "input_throughput": 2365.2629097625936,
    "output_throughput": 2106.277592096093,
    "total_throughput": 4471.540501858686,
    "itl": 25.323436179245494,
    "ttft": 23672.05082210121,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2331,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.622234765421563,
    "arrivals": 34232,
    "finished_requests": 34081,
    "scheduler_time": 6.917087494512239
}
#Debug simulation 
Total elapsed time: 3.3383866315707564. Arrivals time: 0.09622712526470423 Scheduler time: 2.878863742109388 Scheduler overhead time: 0.13449192233383656 Adapter cache time: 0.033205746207386255 Engine time: 0.13207948300987482 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_64_slots_16_rate_0.4-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_64_slots_16_rate_0.4-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 4320, 4320, 66, 4320, 66, 270, 66, 4320, 270, 4320, 66, 270, 4320, 4320, 4320, 66, 4320, 270, 270, 66, 66, 66, 4320, 66, 66, 66, 4320, 270, 66, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 66, 270, 270, 4320, 4320, 270, 4320, 66, 4320, 270, 270, 270, 4320, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 4320, 270]
Prompts retrieved: 102096 . Total input tokens: 22764722 . Total output tokens: 20398109
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 3.3594858068972826,
    "estimated_duration": 3599.7487316712118,
    "input_throughput": 2365.2525869624133,
    "output_throughput": 2106.268399594652,
    "total_throughput": 4471.520986557065,
    "itl": 25.316598007674692,
    "ttft": 23657.47280291092,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2337,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.286022121647584,
    "arrivals": 34232,
    "finished_requests": 34081,
    "scheduler_time": 6.896914698980927
}
#Debug simulation 
Total elapsed time: 3.359587066806853. Arrivals time: 0.0977722778916359 Scheduler time: 2.897927171550691 Scheduler overhead time: 0.1345975981093943 Adapter cache time: 0.033434111159294844 Engine time: 0.132427588570863 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-32/adapters_64_slots_16_rate_0.4-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-32/adapters_64_slots_16_rate_0.4-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 4320, 4320, 66, 4320, 66, 270, 66, 4320, 270, 4320, 66, 270, 4320, 4320, 4320, 66, 4320, 270, 270, 66, 66, 66, 4320, 66, 66, 66, 4320, 270, 66, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 66, 270, 270, 4320, 4320, 270, 4320, 66, 4320, 270, 270, 270, 4320, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 4320, 270]
Prompts retrieved: 102096 . Total input tokens: 22764722 . Total output tokens: 20398109
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 3.340928110294044,
    "estimated_duration": 3599.739392425886,
    "input_throughput": 2365.25872342724,
    "output_throughput": 2106.273864145043,
    "total_throughput": 4471.532587572283,
    "itl": 25.319606980905053,
    "ttft": 23683.653741631857,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2332,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.731460206061419,
    "arrivals": 34232,
    "finished_requests": 34081,
    "scheduler_time": 6.921131147024088
}
#Debug simulation 
Total elapsed time: 3.341012488119304. Arrivals time: 0.0948102418333292 Scheduler time: 2.8827892965637147 Scheduler overhead time: 0.13476245431229472 Adapter cache time: 0.032966801431030035 Engine time: 0.13226093677803874 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_64_slots_16_rate_0.4-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_64_slots_16_rate_0.4-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 4320, 4320, 66, 4320, 66, 270, 66, 4320, 270, 4320, 66, 270, 4320, 4320, 4320, 66, 4320, 270, 270, 66, 66, 66, 4320, 66, 66, 66, 4320, 270, 66, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 66, 270, 270, 4320, 4320, 270, 4320, 66, 4320, 270, 270, 270, 4320, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 4320, 270]
Prompts retrieved: 102096 . Total input tokens: 22764722 . Total output tokens: 20398109
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 3.3426028806716204,
    "estimated_duration": 3599.7248515266388,
    "input_throughput": 2365.268277765477,
    "output_throughput": 2106.282372327559,
    "total_throughput": 4471.550650093036,
    "itl": 25.318280776507184,
    "ttft": 23670.30873944754,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2331,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.96980723741676,
    "arrivals": 34232,
    "finished_requests": 34081,
    "scheduler_time": 6.91175525478676
}
#Debug simulation 
Total elapsed time: 3.3427076456137. Arrivals time: 0.09663852257654071 Scheduler time: 2.882211218122393 Scheduler overhead time: 0.1348437280394137 Adapter cache time: 0.033532360568642616 Engine time: 0.13202610099688172 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-32/adapters_64_slots_16_rate_0.4-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-32/adapters_64_slots_16_rate_0.4-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 4320, 4320, 66, 4320, 66, 270, 66, 4320, 270, 4320, 66, 270, 4320, 4320, 4320, 66, 4320, 270, 270, 66, 66, 66, 4320, 66, 66, 66, 4320, 270, 66, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 66, 270, 270, 4320, 4320, 270, 4320, 66, 4320, 270, 270, 270, 4320, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 4320, 270]
Prompts retrieved: 102096 . Total input tokens: 22764722 . Total output tokens: 20398109
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.3489628578536212,
    "estimated_duration": 3599.7255551583526,
    "input_throughput": 2365.26781543085,
    "output_throughput": 2106.2819606164294,
    "total_throughput": 4471.549776047279,
    "itl": 25.32356825253698,
    "ttft": 23667.941025175976,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2330,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.815532921030804,
    "arrivals": 34232,
    "finished_requests": 34081,
    "scheduler_time": 6.913723798491023
}
#Debug simulation 
Total elapsed time: 3.349057008046657. Arrivals time: 0.09633210068568587 Scheduler time: 2.890297554899007 Scheduler overhead time: 0.13409432722255588 Adapter cache time: 0.033168173395097256 Engine time: 0.1315710535272956 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_64_slots_16_rate_0.4-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_64_slots_16_rate_0.4-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 4320, 4320, 33, 4320, 33, 270, 33, 4320, 270, 4320, 33, 270, 4320, 4320, 4320, 33, 4320, 270, 270, 33, 33, 33, 4320, 33, 33, 33, 4320, 270, 33, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 33, 270, 270, 4320, 4320, 270, 4320, 33, 4320, 270, 270, 270, 4320, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 4320, 270]
Prompts retrieved: 101403 . Total input tokens: 22599607 . Total output tokens: 20263556
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 3.251418465282768,
    "estimated_duration": 3600.0219451173075,
    "input_throughput": 2325.4647131677984,
    "output_throughput": 2069.343218894531,
    "total_throughput": 4394.80793206233,
    "itl": 25.146462360551006,
    "ttft": 22308.93604573952,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2345,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.176843759522521,
    "arrivals": 33997,
    "finished_requests": 33852,
    "scheduler_time": 6.142317728036759
}
#Debug simulation 
Total elapsed time: 3.251524285878986. Arrivals time: 0.09392303368076682 Scheduler time: 2.7920823451131582 Scheduler overhead time: 0.13518485240638256 Adapter cache time: 0.03356910543516278 Engine time: 0.1331923333927989 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_64_slots_16_rate_0.4-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_64_slots_16_rate_0.4-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 4320, 4320, 33, 4320, 33, 270, 33, 4320, 270, 4320, 33, 270, 4320, 4320, 4320, 33, 4320, 270, 270, 33, 33, 33, 4320, 33, 33, 33, 4320, 270, 33, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 33, 270, 270, 4320, 4320, 270, 4320, 33, 4320, 270, 270, 270, 4320, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 4320, 270]
Prompts retrieved: 101403 . Total input tokens: 22599607 . Total output tokens: 20263556
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.23382615391165,
    "estimated_duration": 3600.0059426115427,
    "input_throughput": 2325.008384271761,
    "output_throughput": 2068.989640221745,
    "total_throughput": 4393.998024493506,
    "itl": 25.144019029334952,
    "ttft": 22708.72370654229,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2356,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.673386689868893,
    "arrivals": 33997,
    "finished_requests": 33848,
    "scheduler_time": 6.14603867588857
}
#Debug simulation 
Total elapsed time: 3.2339230310171843. Arrivals time: 0.096811861731112 Scheduler time: 2.771710990462452 Scheduler overhead time: 0.13476907927542925 Adapter cache time: 0.033200249541550875 Engine time: 0.13362192455679178 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-32/adapters_64_slots_16_rate_0.4-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-32/adapters_64_slots_16_rate_0.4-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 4320, 4320, 33, 4320, 33, 270, 33, 4320, 270, 4320, 33, 270, 4320, 4320, 4320, 33, 4320, 270, 270, 33, 33, 33, 4320, 33, 33, 33, 4320, 270, 33, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 33, 270, 270, 4320, 4320, 270, 4320, 33, 4320, 270, 270, 270, 4320, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 4320, 270]
Prompts retrieved: 101403 . Total input tokens: 22599607 . Total output tokens: 20263556
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.2465027449652553,
    "estimated_duration": 3600.003340772806,
    "input_throughput": 2325.3950642731684,
    "output_throughput": 2069.2328019898127,
    "total_throughput": 4394.627866262981,
    "itl": 25.15125232142142,
    "ttft": 22306.533153687575,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2343,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.647627824284095,
    "arrivals": 33997,
    "finished_requests": 33851,
    "scheduler_time": 6.154781464238297
}
#Debug simulation 
Total elapsed time: 3.246592772193253. Arrivals time: 0.09398303600028157 Scheduler time: 2.786722706630826 Scheduler overhead time: 0.1364669012837112 Adapter cache time: 0.03342849062755704 Engine time: 0.1318445191718638 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_64_slots_16_rate_0.4-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_64_slots_16_rate_0.4-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 4320, 4320, 33, 4320, 33, 270, 33, 4320, 270, 4320, 33, 270, 4320, 4320, 4320, 33, 4320, 270, 270, 33, 33, 33, 4320, 33, 33, 33, 4320, 270, 33, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 33, 270, 270, 4320, 4320, 270, 4320, 33, 4320, 270, 270, 270, 4320, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 4320, 270]
Prompts retrieved: 101403 . Total input tokens: 22599607 . Total output tokens: 20263556
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 3.263246363028884,
    "estimated_duration": 3600.0040578755684,
    "input_throughput": 2325.0134903846,
    "output_throughput": 2068.6732237726296,
    "total_throughput": 4393.68671415723,
    "itl": 25.156343279306263,
    "ttft": 23663.794970954597,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2220,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.908401755490108,
    "arrivals": 33997,
    "finished_requests": 33844,
    "scheduler_time": 6.293489375521742
}
#Debug simulation 
Total elapsed time: 3.2633376540616155. Arrivals time: 0.09566035401076078 Scheduler time: 2.8022310361266136 Scheduler overhead time: 0.13547208905220032 Adapter cache time: 0.03243492031469941 Engine time: 0.13370487932115793 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-32/adapters_64_slots_16_rate_0.4-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-32/adapters_64_slots_16_rate_0.4-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 4320, 4320, 33, 4320, 33, 270, 33, 4320, 270, 4320, 33, 270, 4320, 4320, 4320, 33, 4320, 270, 270, 33, 33, 33, 4320, 33, 33, 33, 4320, 270, 33, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 33, 270, 270, 4320, 4320, 270, 4320, 33, 4320, 270, 270, 270, 4320, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 4320, 270]
Prompts retrieved: 101403 . Total input tokens: 22599607 . Total output tokens: 20263556
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 3.2711125630885363,
    "estimated_duration": 3600.0058496972147,
    "input_throughput": 2325.3934436534582,
    "output_throughput": 2069.231359895299,
    "total_throughput": 4394.624803548758,
    "itl": 25.149799869776807,
    "ttft": 22403.262074510338,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2346,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.762900288756743,
    "arrivals": 33997,
    "finished_requests": 33851,
    "scheduler_time": 6.150438448853602
}
#Debug simulation 
Total elapsed time: 3.2712094830349088. Arrivals time: 0.09646791033446789 Scheduler time: 2.805598369333893 Scheduler overhead time: 0.13717316603288054 Adapter cache time: 0.03339351946488023 Engine time: 0.13462061993777752 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_64_slots_16_rate_0.4-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_64_slots_16_rate_0.4-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 4320, 4320, 33, 4320, 33, 270, 33, 4320, 270, 4320, 33, 270, 4320, 4320, 4320, 33, 4320, 270, 270, 33, 33, 33, 4320, 33, 33, 33, 4320, 270, 33, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 33, 270, 270, 4320, 4320, 270, 4320, 33, 4320, 270, 270, 270, 4320, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 4320, 270]
Prompts retrieved: 101403 . Total input tokens: 22599607 . Total output tokens: 20263556
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 3.229949932079762,
    "estimated_duration": 3600.015210879818,
    "input_throughput": 2325.0023985188723,
    "output_throughput": 2068.9843135911838,
    "total_throughput": 4393.986712110056,
    "itl": 25.140352311076807,
    "ttft": 22720.280378888572,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2349,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.023628142724998,
    "arrivals": 33997,
    "finished_requests": 33848,
    "scheduler_time": 6.131616604089401
}
#Debug simulation 
Total elapsed time: 3.2300368109717965. Arrivals time: 0.09299257351085544 Scheduler time: 2.7728833938017488 Scheduler overhead time: 0.13516983995214105 Adapter cache time: 0.032971317414194345 Engine time: 0.1324776615947485 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-32/adapters_64_slots_16_rate_0.4-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-32/adapters_64_slots_16_rate_0.4-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 4320, 4320, 33, 4320, 33, 270, 33, 4320, 270, 4320, 33, 270, 4320, 4320, 4320, 33, 4320, 270, 270, 33, 33, 33, 4320, 33, 33, 33, 4320, 270, 33, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 33, 270, 270, 4320, 4320, 270, 4320, 33, 4320, 270, 270, 270, 4320, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 4320, 270]
Prompts retrieved: 101403 . Total input tokens: 22599607 . Total output tokens: 20263556
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.2219958170317113,
    "estimated_duration": 3600.010697895819,
    "input_throughput": 2325.005313148717,
    "output_throughput": 2068.9869072760043,
    "total_throughput": 4393.992220424721,
    "itl": 25.146842385626734,
    "ttft": 22721.351251462278,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2349,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.859932742006754,
    "arrivals": 33997,
    "finished_requests": 33848,
    "scheduler_time": 6.137567422819614
}
#Debug simulation 
Total elapsed time: 3.222090792376548. Arrivals time: 0.09609750704839826 Scheduler time: 2.762765564955771 Scheduler overhead time: 0.13495377963408828 Adapter cache time: 0.0334628582932055 Engine time: 0.13106725458055735 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_64_slots_16_rate_0.4-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_64_slots_16_rate_0.4-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 4320, 4320, 66, 4320, 66, 135, 66, 4320, 135, 4320, 66, 135, 4320, 4320, 4320, 66, 4320, 135, 135, 66, 66, 66, 4320, 66, 66, 66, 4320, 135, 66, 4320, 4320, 4320, 4320, 135, 135, 135, 4320, 66, 135, 135, 4320, 4320, 135, 4320, 66, 4320, 135, 135, 135, 4320, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 4320, 135]
Prompts retrieved: 99261 . Total input tokens: 22115311 . Total output tokens: 19830516
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 3.0598965040408075,
    "estimated_duration": 3599.910499203288,
    "input_throughput": 2259.562009055564,
    "output_throughput": 2022.461114411405,
    "total_throughput": 4282.023123466969,
    "itl": 24.963679403377945,
    "ttft": 15296.923424733026,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2298,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.033000835557677,
    "arrivals": 33294,
    "finished_requests": 33202,
    "scheduler_time": 5.013968636188503
}
#Debug simulation 
Total elapsed time: 3.0600547227077186. Arrivals time: 0.09173728572204709 Scheduler time: 2.605248022824526 Scheduler overhead time: 0.13539362978190184 Adapter cache time: 0.032743054907768965 Engine time: 0.13087040605023503 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_64_slots_16_rate_0.4-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_64_slots_16_rate_0.4-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 4320, 4320, 66, 4320, 66, 135, 66, 4320, 135, 4320, 66, 135, 4320, 4320, 4320, 66, 4320, 135, 135, 66, 66, 66, 4320, 66, 66, 66, 4320, 135, 66, 4320, 4320, 4320, 4320, 135, 135, 135, 4320, 66, 135, 135, 4320, 4320, 135, 4320, 66, 4320, 135, 135, 135, 4320, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 4320, 135]
Prompts retrieved: 99261 . Total input tokens: 22115311 . Total output tokens: 19830516
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.092577924951911,
    "estimated_duration": 3599.917988373449,
    "input_throughput": 2259.5573083250392,
    "output_throughput": 2022.4569069390463,
    "total_throughput": 4282.014215264086,
    "itl": 24.971986131255072,
    "ttft": 15272.922635325109,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2306,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.513260696844356,
    "arrivals": 33294,
    "finished_requests": 33202,
    "scheduler_time": 5.017708792448139
}
#Debug simulation 
Total elapsed time: 3.0926845157518983. Arrivals time: 0.0952877881936729 Scheduler time: 2.629984403960407 Scheduler overhead time: 0.1360806510783732 Adapter cache time: 0.03304698318243027 Engine time: 0.13407609099522233 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-32/adapters_64_slots_16_rate_0.4-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-32/adapters_64_slots_16_rate_0.4-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 4320, 4320, 66, 4320, 66, 135, 66, 4320, 135, 4320, 66, 135, 4320, 4320, 4320, 66, 4320, 135, 135, 66, 66, 66, 4320, 66, 66, 66, 4320, 135, 66, 4320, 4320, 4320, 4320, 135, 135, 135, 4320, 66, 135, 135, 4320, 4320, 135, 4320, 66, 4320, 135, 135, 135, 4320, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 4320, 135]
Prompts retrieved: 99261 . Total input tokens: 22115311 . Total output tokens: 19830516
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.072216567117721,
    "estimated_duration": 3599.9293275359532,
    "input_throughput": 2259.550191105456,
    "output_throughput": 2022.4505365452308,
    "total_throughput": 4282.000727650687,
    "itl": 24.970521425188277,
    "ttft": 15272.596113281226,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2306,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.528609924483989,
    "arrivals": 33294,
    "finished_requests": 33202,
    "scheduler_time": 5.011998071386157
}
#Debug simulation 
Total elapsed time: 3.07231321092695. Arrivals time: 0.09471066808328032 Scheduler time: 2.6115533923730254 Scheduler overhead time: 0.13620423479005694 Adapter cache time: 0.03302106959745288 Engine time: 0.13258777977898717 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_64_slots_16_rate_0.4-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_64_slots_16_rate_0.4-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 4320, 4320, 66, 4320, 66, 135, 66, 4320, 135, 4320, 66, 135, 4320, 4320, 4320, 66, 4320, 135, 135, 66, 66, 66, 4320, 66, 66, 66, 4320, 135, 66, 4320, 4320, 4320, 4320, 135, 135, 135, 4320, 66, 135, 135, 4320, 4320, 135, 4320, 66, 4320, 135, 135, 135, 4320, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 4320, 135]
Prompts retrieved: 99261 . Total input tokens: 22115311 . Total output tokens: 19830516
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 3.0985071752220392,
    "estimated_duration": 3599.9096259010075,
    "input_throughput": 2259.2047704432134,
    "output_throughput": 2022.4229929599362,
    "total_throughput": 4281.627763403149,
    "itl": 24.964854608862094,
    "ttft": 15297.62287822205,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2299,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.190378404452676,
    "arrivals": 33294,
    "finished_requests": 33202,
    "scheduler_time": 5.0172112781273315
}
#Debug simulation 
Total elapsed time: 3.0986017799004912. Arrivals time: 0.09279062692075968 Scheduler time: 2.6402726168744266 Scheduler overhead time: 0.13571211975067854 Adapter cache time: 0.033304179552942514 Engine time: 0.13252752274274826 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-32/adapters_64_slots_16_rate_0.4-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-32/adapters_64_slots_16_rate_0.4-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 4320, 4320, 66, 4320, 66, 135, 66, 4320, 135, 4320, 66, 135, 4320, 4320, 4320, 66, 4320, 135, 135, 66, 66, 66, 4320, 66, 66, 66, 4320, 135, 66, 4320, 4320, 4320, 4320, 135, 135, 135, 4320, 66, 135, 135, 4320, 4320, 135, 4320, 66, 4320, 135, 135, 135, 4320, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 4320, 135]
Prompts retrieved: 99261 . Total input tokens: 22115311 . Total output tokens: 19830516
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 3.0716178682632744,
    "estimated_duration": 3599.9274228933505,
    "input_throughput": 2259.551386583879,
    "output_throughput": 2022.451606579429,
    "total_throughput": 4282.002993163308,
    "itl": 24.969544936493175,
    "ttft": 15297.409572907341,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2299,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.598385335579344,
    "arrivals": 33294,
    "finished_requests": 33202,
    "scheduler_time": 5.025916311203925
}
#Debug simulation 
Total elapsed time: 3.0717106042429805. Arrivals time: 0.09353198483586311 Scheduler time: 2.6149696395732462 Scheduler overhead time: 0.13531232438981533 Adapter cache time: 0.032975520472973585 Engine time: 0.1308938916772604 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_64_slots_16_rate_0.4-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_64_slots_16_rate_0.4-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 4320, 4320, 66, 4320, 66, 135, 66, 4320, 135, 4320, 66, 135, 4320, 4320, 4320, 66, 4320, 135, 135, 66, 66, 66, 4320, 66, 66, 66, 4320, 135, 66, 4320, 4320, 4320, 4320, 135, 135, 135, 4320, 66, 135, 135, 4320, 4320, 135, 4320, 66, 4320, 135, 135, 135, 4320, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 4320, 135]
Prompts retrieved: 99261 . Total input tokens: 22115311 . Total output tokens: 19830516
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 3.07498566666618,
    "estimated_duration": 3599.9297587932006,
    "input_throughput": 2259.549920420343,
    "output_throughput": 2022.4502942637114,
    "total_throughput": 4282.000214684054,
    "itl": 24.965776409114746,
    "ttft": 15272.278155833632,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2307,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.898046030339111,
    "arrivals": 33294,
    "finished_requests": 33202,
    "scheduler_time": 5.0133840882729315
}
#Debug simulation 
Total elapsed time: 3.075074279680848. Arrivals time: 0.09366177394986153 Scheduler time: 2.614598634187132 Scheduler overhead time: 0.1359731536358595 Adapter cache time: 0.03295289445668459 Engine time: 0.13377694925293326 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-32/adapters_64_slots_16_rate_0.4-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-32/adapters_64_slots_16_rate_0.4-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 4320, 4320, 66, 4320, 66, 135, 66, 4320, 135, 4320, 66, 135, 4320, 4320, 4320, 66, 4320, 135, 135, 66, 66, 66, 4320, 66, 66, 66, 4320, 135, 66, 4320, 4320, 4320, 4320, 135, 135, 135, 4320, 66, 135, 135, 4320, 4320, 135, 4320, 66, 4320, 135, 135, 135, 4320, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 4320, 135]
Prompts retrieved: 99261 . Total input tokens: 22115311 . Total output tokens: 19830516
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.090553526300937,
    "estimated_duration": 3599.92575801679,
    "input_throughput": 2259.5524315704683,
    "output_throughput": 2022.4525419132387,
    "total_throughput": 4282.0049734837075,
    "itl": 24.972361249579468,
    "ttft": 15273.238181632843,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2306,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.71887540332942,
    "arrivals": 33294,
    "finished_requests": 33202,
    "scheduler_time": 5.013360236961377
}
#Debug simulation 
Total elapsed time: 3.0906832511536777. Arrivals time: 0.09494773391634226 Scheduler time: 2.6311114728450775 Scheduler overhead time: 0.13566137105226517 Adapter cache time: 0.0329552385956049 Engine time: 0.13200206914916635 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_64_slots_16_rate_0.4-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_64_slots_16_rate_0.4-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 4320, 4320, 33, 4320, 33, 135, 33, 4320, 135, 4320, 33, 135, 4320, 4320, 4320, 33, 4320, 135, 135, 33, 33, 33, 4320, 33, 33, 33, 4320, 135, 33, 4320, 4320, 4320, 4320, 135, 135, 135, 4320, 33, 135, 135, 4320, 4320, 135, 4320, 33, 4320, 135, 135, 135, 4320, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 4320, 135]
Prompts retrieved: 98568 . Total input tokens: 21979772 . Total output tokens: 19688007
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 3.0270498860627413,
    "estimated_duration": 3599.6722558653114,
    "input_throughput": 2283.1495246848144,
    "output_throughput": 2005.1931084111666,
    "total_throughput": 4288.342633095981,
    "itl": 24.86185996160673,
    "ttft": 15393.464569663263,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2151,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.583109137199546,
    "arrivals": 33045,
    "finished_requests": 32948,
    "scheduler_time": 4.636438034045679
}
#Debug simulation 
Total elapsed time: 3.0271341437473893. Arrivals time: 0.09116621222347021 Scheduler time: 2.5706851459108293 Scheduler overhead time: 0.13630894757807255 Adapter cache time: 0.032566220965236425 Engine time: 0.13177446695044637 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_64_slots_16_rate_0.4-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_64_slots_16_rate_0.4-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 4320, 4320, 33, 4320, 33, 135, 33, 4320, 135, 4320, 33, 135, 4320, 4320, 4320, 33, 4320, 135, 135, 33, 33, 33, 4320, 33, 33, 33, 4320, 135, 33, 4320, 4320, 4320, 4320, 135, 135, 135, 4320, 33, 135, 135, 4320, 4320, 135, 4320, 33, 4320, 135, 135, 135, 4320, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 4320, 135]
Prompts retrieved: 98568 . Total input tokens: 21979772 . Total output tokens: 19688007
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.0521422368474305,
    "estimated_duration": 3599.6776193872624,
    "input_throughput": 2283.146122790565,
    "output_throughput": 2005.190120672155,
    "total_throughput": 4288.33624346272,
    "itl": 24.864257072363735,
    "ttft": 15423.017933399768,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2142,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.980807130681087,
    "arrivals": 33045,
    "finished_requests": 32948,
    "scheduler_time": 4.65631320131254
}
#Debug simulation 
Total elapsed time: 3.05223748087883. Arrivals time: 0.09350626915693283 Scheduler time: 2.5927256448194385 Scheduler overhead time: 0.1364791220985353 Adapter cache time: 0.032584859523922205 Engine time: 0.13272095611318946 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-32/adapters_64_slots_16_rate_0.4-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-32/adapters_64_slots_16_rate_0.4-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 4320, 4320, 33, 4320, 33, 135, 33, 4320, 135, 4320, 33, 135, 4320, 4320, 4320, 33, 4320, 135, 135, 33, 33, 33, 4320, 33, 33, 33, 4320, 135, 33, 4320, 4320, 4320, 4320, 135, 135, 135, 4320, 33, 135, 135, 4320, 4320, 135, 4320, 33, 4320, 135, 135, 135, 4320, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 4320, 135]
Prompts retrieved: 98568 . Total input tokens: 21979772 . Total output tokens: 19688007
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.048948585987091,
    "estimated_duration": 3599.678261452297,
    "input_throughput": 2283.1457155518656,
    "output_throughput": 2005.1897630117278,
    "total_throughput": 4288.335478563593,
    "itl": 24.86512747993777,
    "ttft": 15422.042362885259,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2145,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.004541392885103,
    "arrivals": 33045,
    "finished_requests": 32948,
    "scheduler_time": 4.654420500317463
}
#Debug simulation 
Total elapsed time: 3.049041927792132. Arrivals time: 0.09379292605444789 Scheduler time: 2.5897996337153018 Scheduler overhead time: 0.13547552796080709 Adapter cache time: 0.032715334091335535 Engine time: 0.13325219647958875 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_64_slots_16_rate_0.4-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_64_slots_16_rate_0.4-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 4320, 4320, 33, 4320, 33, 135, 33, 4320, 135, 4320, 33, 135, 4320, 4320, 4320, 33, 4320, 135, 135, 33, 33, 33, 4320, 33, 33, 33, 4320, 135, 33, 4320, 4320, 4320, 4320, 135, 135, 135, 4320, 33, 135, 135, 4320, 4320, 135, 4320, 33, 4320, 135, 135, 135, 4320, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 4320, 135]
Prompts retrieved: 98568 . Total input tokens: 21979772 . Total output tokens: 19688007
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 3.0636900761164725,
    "estimated_duration": 3599.678736806924,
    "input_throughput": 2283.14541405166,
    "output_throughput": 2005.1894982169222,
    "total_throughput": 4288.334912268582,
    "itl": 24.8665698944349,
    "ttft": 15414.194135898735,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2149,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.721032498976927,
    "arrivals": 33045,
    "finished_requests": 32948,
    "scheduler_time": 4.655895501594047
}
#Debug simulation 
Total elapsed time: 3.063775224145502. Arrivals time: 0.09157317597419024 Scheduler time: 2.606565081514418 Scheduler overhead time: 0.1363352001644671 Adapter cache time: 0.03242228599265218 Engine time: 0.13283025566488504 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-32/adapters_64_slots_16_rate_0.4-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-32/adapters_64_slots_16_rate_0.4-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 4320, 4320, 33, 4320, 33, 135, 33, 4320, 135, 4320, 33, 135, 4320, 4320, 4320, 33, 4320, 135, 135, 33, 33, 33, 4320, 33, 33, 33, 4320, 135, 33, 4320, 4320, 4320, 4320, 135, 135, 135, 4320, 33, 135, 135, 4320, 4320, 135, 4320, 33, 4320, 135, 135, 135, 4320, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 4320, 135]
Prompts retrieved: 98568 . Total input tokens: 21979772 . Total output tokens: 19688007
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 3.0569430822506547,
    "estimated_duration": 3599.6741336314967,
    "input_throughput": 2283.148333682292,
    "output_throughput": 2005.1920624043132,
    "total_throughput": 4288.340396086605,
    "itl": 24.86542536130259,
    "ttft": 15395.693596061788,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2148,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.102505560889688,
    "arrivals": 33045,
    "finished_requests": 32948,
    "scheduler_time": 4.63984067250947
}
#Debug simulation 
Total elapsed time: 3.0570488460361958. Arrivals time: 0.09626226499676704 Scheduler time: 2.593928494490683 Scheduler overhead time: 0.13642407627776265 Adapter cache time: 0.03230907628312707 Engine time: 0.13303582649677992 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_64_slots_16_rate_0.4-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_64_slots_16_rate_0.4-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 4320, 4320, 33, 4320, 33, 135, 33, 4320, 135, 4320, 33, 135, 4320, 4320, 4320, 33, 4320, 135, 135, 33, 33, 33, 4320, 33, 33, 33, 4320, 135, 33, 4320, 4320, 4320, 4320, 135, 135, 135, 4320, 33, 135, 135, 4320, 4320, 135, 4320, 33, 4320, 135, 135, 135, 4320, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 4320, 135]
Prompts retrieved: 98568 . Total input tokens: 21979772 . Total output tokens: 19688007
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 3.0276479707099497,
    "estimated_duration": 3599.668693784939,
    "input_throughput": 2283.1517839933235,
    "output_throughput": 2005.195092665725,
    "total_throughput": 4288.346876659049,
    "itl": 24.860494444256233,
    "ttft": 15392.141874273906,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2151,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.431598184334388,
    "arrivals": 33045,
    "finished_requests": 32948,
    "scheduler_time": 4.633489468268031
}
#Debug simulation 
Total elapsed time: 3.027741591911763. Arrivals time: 0.09138152003288269 Scheduler time: 2.572149216197431 Scheduler overhead time: 0.13562886882573366 Adapter cache time: 0.03227755893021822 Engine time: 0.13239873014390469 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-32/adapters_64_slots_16_rate_0.4-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-32/adapters_64_slots_16_rate_0.4-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 4320, 4320, 33, 4320, 33, 135, 33, 4320, 135, 4320, 33, 135, 4320, 4320, 4320, 33, 4320, 135, 135, 33, 33, 33, 4320, 33, 33, 33, 4320, 135, 33, 4320, 4320, 4320, 4320, 135, 135, 135, 4320, 33, 135, 135, 4320, 4320, 135, 4320, 33, 4320, 135, 135, 135, 4320, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 4320, 135]
Prompts retrieved: 98568 . Total input tokens: 21979772 . Total output tokens: 19688007
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.025028984993696,
    "estimated_duration": 3599.676643152599,
    "input_throughput": 2283.1467419812893,
    "output_throughput": 2005.190664481029,
    "total_throughput": 4288.3374064623185,
    "itl": 24.870324966945088,
    "ttft": 15420.121182712848,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2148,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.19308830097292,
    "arrivals": 33045,
    "finished_requests": 32948,
    "scheduler_time": 4.659585296844717
}
#Debug simulation 
Total elapsed time: 3.025176894851029. Arrivals time: 0.09379104105755687 Scheduler time: 2.5664853816851974 Scheduler overhead time: 0.13562207948416471 Adapter cache time: 0.03260431159287691 Engine time: 0.13265514094382524 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_64_slots_16_rate_0.4-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_64_slots_16_rate_0.4-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 4320, 4320, 33, 4320, 33, 66, 33, 4320, 66, 4320, 33, 66, 4320, 4320, 4320, 33, 4320, 66, 66, 33, 33, 33, 4320, 33, 33, 33, 4320, 66, 33, 4320, 4320, 4320, 4320, 66, 66, 66, 4320, 33, 66, 66, 4320, 4320, 66, 4320, 33, 4320, 66, 66, 66, 4320, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 4320, 66]
Prompts retrieved: 97119 . Total input tokens: 21643986 . Total output tokens: 19399276
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 2.8911692551337183,
    "estimated_duration": 3599.92670812469,
    "input_throughput": 2208.9241378312445,
    "output_throughput": 1969.873159916115,
    "total_throughput": 4178.797297747359,
    "itl": 24.745632115180825,
    "ttft": 10351.590952881545,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2002,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.12709646335355,
    "arrivals": 32548,
    "finished_requests": 32486,
    "scheduler_time": 3.81286339500385
}
#Debug simulation 
Total elapsed time: 2.8912549521774054. Arrivals time: 0.09372904244810343 Scheduler time: 2.4337393986061215 Scheduler overhead time: 0.13652494503185153 Adapter cache time: 0.03192050335928798 Engine time: 0.13117825658991933 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_64_slots_16_rate_0.4-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_64_slots_16_rate_0.4-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 4320, 4320, 33, 4320, 33, 66, 33, 4320, 66, 4320, 33, 66, 4320, 4320, 4320, 33, 4320, 66, 66, 33, 33, 33, 4320, 33, 33, 33, 4320, 66, 33, 4320, 4320, 4320, 4320, 66, 66, 66, 4320, 33, 66, 66, 4320, 4320, 66, 4320, 33, 4320, 66, 66, 66, 4320, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 4320, 66]
Prompts retrieved: 97119 . Total input tokens: 21643986 . Total output tokens: 19399276
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 2.9117418378591537,
    "estimated_duration": 3599.9261832541238,
    "input_throughput": 2208.9244598931987,
    "output_throughput": 1969.8734471243486,
    "total_throughput": 4178.797907017547,
    "itl": 24.749066201580163,
    "ttft": 10351.70707118009,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2003,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.514115724884682,
    "arrivals": 32548,
    "finished_requests": 32486,
    "scheduler_time": 3.81581689477089
}
#Debug simulation 
Total elapsed time: 2.9118330418132246. Arrivals time: 0.09080228675156832 Scheduler time: 2.4555285992100835 Scheduler overhead time: 0.13631024025380611 Adapter cache time: 0.03181265573948622 Engine time: 0.13286426616832614 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-32/adapters_64_slots_16_rate_0.4-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-32/adapters_64_slots_16_rate_0.4-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 4320, 4320, 33, 4320, 33, 66, 33, 4320, 66, 4320, 33, 66, 4320, 4320, 4320, 33, 4320, 66, 66, 33, 33, 33, 4320, 33, 33, 33, 4320, 66, 33, 4320, 4320, 4320, 4320, 66, 66, 66, 4320, 33, 66, 66, 4320, 4320, 66, 4320, 33, 4320, 66, 66, 66, 4320, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 4320, 66]
Prompts retrieved: 97119 . Total input tokens: 21643986 . Total output tokens: 19399276
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 2.8965548290871084,
    "estimated_duration": 3599.926816802325,
    "input_throughput": 2208.9240711463744,
    "output_throughput": 1969.873100447918,
    "total_throughput": 4178.797171594292,
    "itl": 24.748046885153016,
    "ttft": 10381.9865529733,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1994,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.50011612994591,
    "arrivals": 32548,
    "finished_requests": 32486,
    "scheduler_time": 3.8074498471982454
}
#Debug simulation 
Total elapsed time: 2.8966436362825334. Arrivals time: 0.09184082597494125 Scheduler time: 2.441775750834495 Scheduler overhead time: 0.13582600839436054 Adapter cache time: 0.031755912117660046 Engine time: 0.1306246304884553 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_64_slots_16_rate_0.4-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_64_slots_16_rate_0.4-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 4320, 4320, 33, 4320, 33, 66, 33, 4320, 66, 4320, 33, 66, 4320, 4320, 4320, 33, 4320, 66, 66, 33, 33, 33, 4320, 33, 33, 33, 4320, 66, 33, 4320, 4320, 4320, 4320, 66, 66, 66, 4320, 33, 66, 66, 4320, 4320, 66, 4320, 33, 4320, 66, 66, 66, 4320, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 4320, 66]
Prompts retrieved: 97119 . Total input tokens: 21643986 . Total output tokens: 19399276
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 2.9007924129255116,
    "estimated_duration": 3599.9433806573784,
    "input_throughput": 2208.913907570376,
    "output_throughput": 1969.8640367796713,
    "total_throughput": 4178.777944350048,
    "itl": 24.748653715584474,
    "ttft": 10387.006949226527,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1994,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.24940279689831,
    "arrivals": 32548,
    "finished_requests": 32486,
    "scheduler_time": 3.8120282453466166
}
#Debug simulation 
Total elapsed time: 2.9008850059472024. Arrivals time: 0.09337918926030397 Scheduler time: 2.439316388219595 Scheduler overhead time: 0.13739871978759766 Adapter cache time: 0.032004864420741796 Engine time: 0.13411088287830353 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-32/adapters_64_slots_16_rate_0.4-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-32/adapters_64_slots_16_rate_0.4-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 4320, 4320, 33, 4320, 33, 66, 33, 4320, 66, 4320, 33, 66, 4320, 4320, 4320, 33, 4320, 66, 66, 33, 33, 33, 4320, 33, 33, 33, 4320, 66, 33, 4320, 4320, 4320, 4320, 66, 66, 66, 4320, 33, 66, 66, 4320, 4320, 66, 4320, 33, 4320, 66, 66, 66, 4320, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 4320, 66]
Prompts retrieved: 97119 . Total input tokens: 21643986 . Total output tokens: 19399276
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 2.8911166321486235,
    "estimated_duration": 3599.9408884656764,
    "input_throughput": 2208.9154367724054,
    "output_throughput": 1969.8654004906205,
    "total_throughput": 4178.780837263026,
    "itl": 24.747160442661464,
    "ttft": 10347.365920669157,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2004,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.604671736881015,
    "arrivals": 32548,
    "finished_requests": 32486,
    "scheduler_time": 3.802464158629714
}
#Debug simulation 
Total elapsed time: 2.8912046630866826. Arrivals time: 0.09023335902020335 Scheduler time: 2.435982453171164 Scheduler overhead time: 0.1359622562304139 Adapter cache time: 0.032280981075018644 Engine time: 0.1323992065154016 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_64_slots_16_rate_0.4-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_64_slots_16_rate_0.4-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 4320, 4320, 33, 4320, 33, 66, 33, 4320, 66, 4320, 33, 66, 4320, 4320, 4320, 33, 4320, 66, 66, 33, 33, 33, 4320, 33, 33, 33, 4320, 66, 33, 4320, 4320, 4320, 4320, 66, 66, 66, 4320, 33, 66, 66, 4320, 4320, 66, 4320, 33, 4320, 66, 66, 66, 4320, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 4320, 66]
Prompts retrieved: 97119 . Total input tokens: 21643986 . Total output tokens: 19399276
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 2.937783865723759,
    "estimated_duration": 3599.940419439865,
    "input_throughput": 2208.9157245656,
    "output_throughput": 1969.8656571386787,
    "total_throughput": 4178.781381704279,
    "itl": 24.743761314350746,
    "ttft": 10351.685946927453,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2003,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.989070740688882,
    "arrivals": 32548,
    "finished_requests": 32486,
    "scheduler_time": 3.810195927675183
}
#Debug simulation 
Total elapsed time: 2.9378783139400184. Arrivals time: 0.0928196543827653 Scheduler time: 2.4745439486578107 Scheduler overhead time: 0.13711617048829794 Adapter cache time: 0.03252063039690256 Engine time: 0.13456449704244733 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-32/adapters_64_slots_16_rate_0.4-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-32/adapters_64_slots_16_rate_0.4-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 4320, 4320, 33, 4320, 33, 66, 33, 4320, 66, 4320, 33, 66, 4320, 4320, 4320, 33, 4320, 66, 66, 33, 33, 33, 4320, 33, 33, 33, 4320, 66, 33, 4320, 4320, 4320, 4320, 66, 66, 66, 4320, 33, 66, 66, 4320, 4320, 66, 4320, 33, 4320, 66, 66, 66, 4320, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 4320, 66]
Prompts retrieved: 97119 . Total input tokens: 21643986 . Total output tokens: 19399276
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 2.899834255222231,
    "estimated_duration": 3599.922118840932,
    "input_throughput": 2208.9269538309613,
    "output_throughput": 1969.875671166803,
    "total_throughput": 4178.802624997765,
    "itl": 24.75032231797789,
    "ttft": 10392.419230309768,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1991,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.650435662381144,
    "arrivals": 32548,
    "finished_requests": 32486,
    "scheduler_time": 3.826830174984576
}
#Debug simulation 
Total elapsed time: 2.8999319281429052. Arrivals time: 0.09159795101732016 Scheduler time: 2.441710098646581 Scheduler overhead time: 0.1366353896446526 Adapter cache time: 0.03213104326277971 Engine time: 0.1334291324019432 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_64_slots_16_rate_0.1-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_64_slots_16_rate_0.1-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [21 21 22]
Adapter prompts. [270, 540, 1080, 1080, 270, 1080, 270, 540, 270, 1080, 540, 1080, 270, 540, 1080, 1080, 1080, 270, 1080, 540, 540, 270, 270, 270, 1080, 270, 270, 270, 1080, 540, 270, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 270, 540, 540, 1080, 1080, 540, 1080, 270, 1080, 540, 540, 540, 1080, 540, 270, 270, 540, 540, 270, 540, 270, 270, 270, 1080, 540]
Prompts retrieved: 40770 . Total input tokens: 9017193 . Total output tokens: 8172157
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.5335564082488418,
    "estimated_duration": 3599.615797245354,
    "input_throughput": 945.8345534002377,
    "output_throughput": 849.3384217114578,
    "total_throughput": 1795.1729751116957,
    "itl": 21.62007220772815,
    "ttft": 7573.348839516646,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7877,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.107461958959135,
    "arrivals": 13796,
    "finished_requests": 13775,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.533652300015092. Arrivals time: 0.047169458121061325 Scheduler time: 1.074980579316616 Scheduler overhead time: 0.14471782464534044 Adapter cache time: 0.056726901326328516 Engine time: 0.14014303078874946 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_64_slots_16_rate_0.1-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_64_slots_16_rate_0.1-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [21 21 22]
Adapter prompts. [270, 540, 1080, 1080, 270, 1080, 270, 540, 270, 1080, 540, 1080, 270, 540, 1080, 1080, 1080, 270, 1080, 540, 540, 270, 270, 270, 1080, 270, 270, 270, 1080, 540, 270, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 270, 540, 540, 1080, 1080, 540, 1080, 270, 1080, 540, 540, 540, 1080, 540, 270, 270, 540, 540, 270, 540, 270, 270, 270, 1080, 540]
Prompts retrieved: 40770 . Total input tokens: 9017193 . Total output tokens: 8172157
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.5176898390054703,
    "estimated_duration": 3599.6035562552975,
    "input_throughput": 945.8377698520447,
    "output_throughput": 849.3413100137424,
    "total_throughput": 1795.1790798657871,
    "itl": 21.630540811216235,
    "ttft": 7581.777444029266,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7872,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.657468433536053,
    "arrivals": 13796,
    "finished_requests": 13775,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.517792223021388. Arrivals time: 0.046923897229135036 Scheduler time: 1.0609831451438367 Scheduler overhead time: 0.1406091540120542 Adapter cache time: 0.05677885375916958 Engine time: 0.14315488282591105 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-32/adapters_64_slots_16_rate_0.1-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-32/adapters_64_slots_16_rate_0.1-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [21 21 22]
Adapter prompts. [270, 540, 1080, 1080, 270, 1080, 270, 540, 270, 1080, 540, 1080, 270, 540, 1080, 1080, 1080, 270, 1080, 540, 540, 270, 270, 270, 1080, 270, 270, 270, 1080, 540, 270, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 270, 540, 540, 1080, 1080, 540, 1080, 270, 1080, 540, 540, 540, 1080, 540, 270, 270, 540, 540, 270, 540, 270, 270, 270, 1080, 540]
Prompts retrieved: 40770 . Total input tokens: 9017193 . Total output tokens: 8172157
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.517814225051552,
    "estimated_duration": 3599.6110726699812,
    "input_throughput": 945.8357948306443,
    "output_throughput": 849.3395364883905,
    "total_throughput": 1795.1753313190347,
    "itl": 21.63233501473199,
    "ttft": 7580.812736809416,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7871,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.7041651177969,
    "arrivals": 13796,
    "finished_requests": 13775,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5179575132206082. Arrivals time: 0.04738887446001172 Scheduler time: 1.06166101526469 Scheduler overhead time: 0.1413573333993554 Adapter cache time: 0.057151265908032656 Engine time: 0.14104727655649185 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_64_slots_16_rate_0.1-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_64_slots_16_rate_0.1-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [21 21 22]
Adapter prompts. [270, 540, 1080, 1080, 270, 1080, 270, 540, 270, 1080, 540, 1080, 270, 540, 1080, 1080, 1080, 270, 1080, 540, 540, 270, 270, 270, 1080, 270, 270, 270, 1080, 540, 270, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 270, 540, 540, 1080, 1080, 540, 1080, 270, 1080, 540, 540, 540, 1080, 540, 270, 270, 540, 540, 270, 540, 270, 270, 270, 1080, 540]
Prompts retrieved: 40770 . Total input tokens: 9017193 . Total output tokens: 8172157
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 1.5210025082342327,
    "estimated_duration": 3599.616819648584,
    "input_throughput": 945.8342847537814,
    "output_throughput": 849.3381804729069,
    "total_throughput": 1795.1724652266882,
    "itl": 21.623282353037233,
    "ttft": 7577.8592842879425,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7875,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.63596119131504,
    "arrivals": 13796,
    "finished_requests": 13775,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5210985131561756. Arrivals time: 0.04691658588126302 Scheduler time: 1.0653819902800024 Scheduler overhead time: 0.1425266251899302 Adapter cache time: 0.05687498953193426 Engine time: 0.1399334347806871 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-32/adapters_64_slots_16_rate_0.1-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-32/adapters_64_slots_16_rate_0.1-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [21 21 22]
Adapter prompts. [270, 540, 1080, 1080, 270, 1080, 270, 540, 270, 1080, 540, 1080, 270, 540, 1080, 1080, 1080, 270, 1080, 540, 540, 270, 270, 270, 1080, 270, 270, 270, 1080, 540, 270, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 270, 540, 540, 1080, 1080, 540, 1080, 270, 1080, 540, 540, 540, 1080, 540, 270, 270, 540, 540, 270, 540, 270, 270, 270, 1080, 540]
Prompts retrieved: 40770 . Total input tokens: 9017193 . Total output tokens: 8172157
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 1.5001984401606023,
    "estimated_duration": 3599.606038278067,
    "input_throughput": 945.8371176720962,
    "output_throughput": 849.3407243706336,
    "total_throughput": 1795.1778420427297,
    "itl": 21.63623997320214,
    "ttft": 7583.317003689877,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7872,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.024445425904474,
    "arrivals": 13796,
    "finished_requests": 13775,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.50028420612216. Arrivals time: 0.04660622822120786 Scheduler time: 1.047890279442072 Scheduler overhead time: 0.1407044897787273 Adapter cache time: 0.05647168820723891 Engine time: 0.13944728439673781 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_64_slots_16_rate_0.1-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_64_slots_16_rate_0.1-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [21 21 22]
Adapter prompts. [270, 540, 1080, 1080, 270, 1080, 270, 540, 270, 1080, 540, 1080, 270, 540, 1080, 1080, 1080, 270, 1080, 540, 540, 270, 270, 270, 1080, 270, 270, 270, 1080, 540, 270, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 270, 540, 540, 1080, 1080, 540, 1080, 270, 1080, 540, 540, 540, 1080, 540, 270, 270, 540, 540, 270, 540, 270, 270, 270, 1080, 540]
Prompts retrieved: 40770 . Total input tokens: 9017193 . Total output tokens: 8172157
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.5053266491740942,
    "estimated_duration": 3599.6147915659985,
    "input_throughput": 945.8348176524811,
    "output_throughput": 849.3386590041033,
    "total_throughput": 1795.1734766565844,
    "itl": 21.61720375166565,
    "ttft": 7573.670784846768,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7875,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.546646072353965,
    "arrivals": 13796,
    "finished_requests": 13775,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5054110679775476. Arrivals time: 0.046722127590328455 Scheduler time: 1.0533305522985756 Scheduler overhead time: 0.14124192157760262 Adapter cache time: 0.056367268320173025 Engine time: 0.13838296197354794 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-32/adapters_64_slots_16_rate_0.1-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-32/adapters_64_slots_16_rate_0.1-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [21 21 22]
Adapter prompts. [270, 540, 1080, 1080, 270, 1080, 270, 540, 270, 1080, 540, 1080, 270, 540, 1080, 1080, 1080, 270, 1080, 540, 540, 270, 270, 270, 1080, 270, 270, 270, 1080, 540, 270, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 270, 540, 540, 1080, 1080, 540, 1080, 270, 1080, 540, 540, 540, 1080, 540, 270, 270, 540, 540, 270, 540, 270, 270, 270, 1080, 540]
Prompts retrieved: 40770 . Total input tokens: 9017193 . Total output tokens: 8172157
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.5197352492250502,
    "estimated_duration": 3599.621331463352,
    "input_throughput": 945.833099232111,
    "output_throughput": 849.3371159007775,
    "total_throughput": 1795.1702151328884,
    "itl": 21.636961191514143,
    "ttft": 7589.447406359177,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7866,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.340517904830804,
    "arrivals": 13796,
    "finished_requests": 13775,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5198279689066112. Arrivals time: 0.04745773086324334 Scheduler time: 1.0646838312968612 Scheduler overhead time: 0.140799755230546 Adapter cache time: 0.05665866006165743 Engine time: 0.14116752007976174 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_64_slots_16_rate_0.1-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_64_slots_16_rate_0.1-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [21 21 22]
Adapter prompts. [135, 540, 1080, 1080, 135, 1080, 135, 540, 135, 1080, 540, 1080, 135, 540, 1080, 1080, 1080, 135, 1080, 540, 540, 135, 135, 135, 1080, 135, 135, 135, 1080, 540, 135, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 135, 540, 540, 1080, 1080, 540, 1080, 135, 1080, 540, 540, 540, 1080, 540, 135, 135, 540, 540, 135, 540, 135, 135, 135, 1080, 540]
Prompts retrieved: 37935 . Total input tokens: 8385449 . Total output tokens: 7584892
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.4144387990236282,
    "estimated_duration": 3599.5261534607207,
    "input_throughput": 868.5420987965925,
    "output_throughput": 784.0851488984183,
    "total_throughput": 1652.6272476950107,
    "itl": 21.397226863655447,
    "ttft": 5037.537540138287,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7625,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.33621904748783,
    "arrivals": 12790,
    "finished_requests": 12775,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4145338758826256. Arrivals time: 0.04489541565999389 Scheduler time: 0.9616572340019047 Scheduler overhead time: 0.1412534578703344 Adapter cache time: 0.05614202981814742 Engine time: 0.1409268733114004 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_64_slots_16_rate_0.1-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_64_slots_16_rate_0.1-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [21 21 22]
Adapter prompts. [135, 540, 1080, 1080, 135, 1080, 135, 540, 135, 1080, 540, 1080, 135, 540, 1080, 1080, 1080, 135, 1080, 540, 540, 135, 135, 135, 1080, 135, 135, 135, 1080, 540, 135, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 135, 540, 540, 1080, 1080, 540, 1080, 135, 1080, 540, 540, 540, 1080, 540, 135, 135, 540, 540, 135, 540, 135, 135, 135, 1080, 540]
Prompts retrieved: 37935 . Total input tokens: 8385449 . Total output tokens: 7584892
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.405423761345446,
    "estimated_duration": 3599.5214666601546,
    "input_throughput": 868.5432296923624,
    "output_throughput": 784.0861698259927,
    "total_throughput": 1652.629399518355,
    "itl": 21.406658459692274,
    "ttft": 5039.8865373558765,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7628,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.847811479165905,
    "arrivals": 12790,
    "finished_requests": 12775,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.405511463060975. Arrivals time: 0.044416215270757675 Scheduler time: 0.9552632267586887 Scheduler overhead time: 0.14136908343061805 Adapter cache time: 0.055527739226818085 Engine time: 0.1395067828707397 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-32/adapters_64_slots_16_rate_0.1-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-32/adapters_64_slots_16_rate_0.1-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [21 21 22]
Adapter prompts. [135, 540, 1080, 1080, 135, 1080, 135, 540, 135, 1080, 540, 1080, 135, 540, 1080, 1080, 1080, 135, 1080, 540, 540, 135, 135, 135, 1080, 135, 135, 135, 1080, 540, 135, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 135, 540, 540, 1080, 1080, 540, 1080, 135, 1080, 540, 540, 540, 1080, 540, 135, 135, 540, 540, 135, 540, 135, 135, 135, 1080, 540]
Prompts retrieved: 37935 . Total input tokens: 8385449 . Total output tokens: 7584892
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.4084700718522072,
    "estimated_duration": 3599.5230403933374,
    "input_throughput": 868.542849960024,
    "output_throughput": 784.0858270187902,
    "total_throughput": 1652.6286769788142,
    "itl": 21.407911022726587,
    "ttft": 5039.47131582128,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7627,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.89645775225034,
    "arrivals": 12790,
    "finished_requests": 12775,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4085662770085037. Arrivals time: 0.044592217076569796 Scheduler time: 0.957548139616847 Scheduler overhead time: 0.14193579414859414 Adapter cache time: 0.05524144880473614 Engine time: 0.13952361606061459 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_64_slots_16_rate_0.1-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_64_slots_16_rate_0.1-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [21 21 22]
Adapter prompts. [135, 540, 1080, 1080, 135, 1080, 135, 540, 135, 1080, 540, 1080, 135, 540, 1080, 1080, 1080, 135, 1080, 540, 540, 135, 135, 135, 1080, 135, 135, 135, 1080, 540, 135, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 135, 540, 540, 1080, 1080, 540, 1080, 135, 1080, 540, 540, 540, 1080, 540, 135, 135, 540, 540, 135, 540, 135, 135, 135, 1080, 540]
Prompts retrieved: 37935 . Total input tokens: 8385449 . Total output tokens: 7584892
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 1.4339158339425921,
    "estimated_duration": 3599.53017025517,
    "input_throughput": 868.5411295714669,
    "output_throughput": 784.0842739206504,
    "total_throughput": 1652.6254034921174,
    "itl": 21.400419181748806,
    "ttft": 5037.696442309148,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7627,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.78778534006669,
    "arrivals": 12790,
    "finished_requests": 12775,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4340123431757092. Arrivals time: 0.045553422532975674 Scheduler time: 0.9794059311971068 Scheduler overhead time: 0.14188630180433393 Adapter cache time: 0.056395656894892454 Engine time: 0.14136608876287937 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-32/adapters_64_slots_16_rate_0.1-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-32/adapters_64_slots_16_rate_0.1-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [21 21 22]
Adapter prompts. [135, 540, 1080, 1080, 135, 1080, 135, 540, 135, 1080, 540, 1080, 135, 540, 1080, 1080, 1080, 135, 1080, 540, 540, 135, 135, 135, 1080, 135, 135, 135, 1080, 540, 135, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 135, 540, 540, 1080, 1080, 540, 1080, 135, 1080, 540, 540, 540, 1080, 540, 135, 135, 540, 540, 135, 540, 135, 135, 135, 1080, 540]
Prompts retrieved: 37935 . Total input tokens: 8385449 . Total output tokens: 7584892
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 1.4252486121840775,
    "estimated_duration": 3599.5367738046134,
    "input_throughput": 868.5395361846915,
    "output_throughput": 784.0828354746513,
    "total_throughput": 1652.622371659343,
    "itl": 21.40894270412295,
    "ttft": 5041.015840546452,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7623,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.208345472252915,
    "arrivals": 12790,
    "finished_requests": 12775,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.425327841192484. Arrivals time: 0.0445746760815382 Scheduler time: 0.9708574251271784 Scheduler overhead time: 0.1418862296268344 Adapter cache time: 0.0562654179520905 Engine time: 0.14196311216801405 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_64_slots_16_rate_0.1-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_64_slots_16_rate_0.1-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [21 21 22]
Adapter prompts. [135, 540, 1080, 1080, 135, 1080, 135, 540, 135, 1080, 540, 1080, 135, 540, 1080, 1080, 1080, 135, 1080, 540, 540, 135, 135, 135, 1080, 135, 135, 135, 1080, 540, 135, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 135, 540, 540, 1080, 1080, 540, 1080, 135, 1080, 540, 540, 540, 1080, 540, 135, 135, 540, 540, 135, 540, 135, 135, 135, 1080, 540]
Prompts retrieved: 37935 . Total input tokens: 8385449 . Total output tokens: 7584892
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.4114094660617411,
    "estimated_duration": 3599.522432006004,
    "input_throughput": 868.542996760184,
    "output_throughput": 784.0859595441167,
    "total_throughput": 1652.6289563043006,
    "itl": 21.39299682669182,
    "ttft": 5036.0759716590355,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7626,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.80212354892357,
    "arrivals": 12790,
    "finished_requests": 12775,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4115542471408844. Arrivals time: 0.04467240534722805 Scheduler time: 0.9594699461013079 Scheduler overhead time: 0.14191848039627075 Adapter cache time: 0.055798623245209455 Engine time: 0.14033087017014623 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-32/adapters_64_slots_16_rate_0.1-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-32/adapters_64_slots_16_rate_0.1-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [21 21 22]
Adapter prompts. [135, 540, 1080, 1080, 135, 1080, 135, 540, 135, 1080, 540, 1080, 135, 540, 1080, 1080, 1080, 135, 1080, 540, 540, 135, 135, 135, 1080, 135, 135, 135, 1080, 540, 135, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 135, 540, 540, 1080, 1080, 540, 1080, 135, 1080, 540, 540, 540, 1080, 540, 135, 135, 540, 540, 135, 540, 135, 135, 135, 1080, 540]
Prompts retrieved: 37935 . Total input tokens: 8385449 . Total output tokens: 7584892
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.4452235512435436,
    "estimated_duration": 3599.5242396247454,
    "input_throughput": 868.5425605929312,
    "output_throughput": 784.0855657897255,
    "total_throughput": 1652.6281263826568,
    "itl": 21.411799610105458,
    "ttft": 5040.855467649346,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7626,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.521640136463354,
    "arrivals": 12790,
    "finished_requests": 12775,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4453166560269892. Arrivals time: 0.04515271773561835 Scheduler time: 0.9888005317188799 Scheduler overhead time: 0.14179088780656457 Adapter cache time: 0.05574704520404339 Engine time: 0.14160051010549068 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_64_slots_16_rate_0.1-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_64_slots_16_rate_0.1-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 540, 1080, 1080, 66, 1080, 66, 540, 66, 1080, 540, 1080, 66, 540, 1080, 1080, 1080, 66, 1080, 540, 540, 66, 66, 66, 1080, 66, 66, 66, 1080, 540, 66, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 66, 540, 540, 1080, 1080, 540, 1080, 66, 1080, 540, 540, 540, 1080, 540, 66, 66, 540, 540, 66, 540, 66, 66, 66, 1080, 540]
Prompts retrieved: 36486 . Total input tokens: 8062787 . Total output tokens: 7286246
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.4008927289396524,
    "estimated_duration": 3599.5580138505875,
    "input_throughput": 838.839654307995,
    "output_throughput": 745.0356376201797,
    "total_throughput": 1583.8752919281746,
    "itl": 21.156399650390586,
    "ttft": 4871.8582127008185,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7348,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.488463942418182,
    "arrivals": 12326,
    "finished_requests": 12311,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.400982053950429. Arrivals time: 0.04316902672871947 Scheduler time: 0.934067071415484 Scheduler overhead time: 0.1553837126120925 Adapter cache time: 0.05557610234245658 Engine time: 0.14237318420782685 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_64_slots_16_rate_0.1-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_64_slots_16_rate_0.1-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 540, 1080, 1080, 66, 1080, 66, 540, 66, 1080, 540, 1080, 66, 540, 1080, 1080, 1080, 66, 1080, 540, 540, 66, 66, 66, 1080, 66, 66, 66, 1080, 540, 66, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 66, 540, 540, 1080, 1080, 540, 1080, 66, 1080, 540, 540, 540, 1080, 540, 66, 66, 540, 540, 66, 540, 66, 66, 66, 1080, 540]
Prompts retrieved: 36486 . Total input tokens: 8062787 . Total output tokens: 7286246
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.4003383950330317,
    "estimated_duration": 3599.5394630961428,
    "input_throughput": 838.8439773911575,
    "output_throughput": 745.0394772705871,
    "total_throughput": 1583.8834546617445,
    "itl": 21.164004076970336,
    "ttft": 4873.276540146809,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7353,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.952817681385756,
    "arrivals": 12326,
    "finished_requests": 12311,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4004354290664196. Arrivals time: 0.04423242388293147 Scheduler time: 0.9440252995118499 Scheduler overhead time: 0.14287718199193478 Adapter cache time: 0.05561113730072975 Engine time: 0.14299281314015388 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-32/adapters_64_slots_16_rate_0.1-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-32/adapters_64_slots_16_rate_0.1-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 540, 1080, 1080, 66, 1080, 66, 540, 66, 1080, 540, 1080, 66, 540, 1080, 1080, 1080, 66, 1080, 540, 540, 66, 66, 66, 1080, 66, 66, 66, 1080, 540, 66, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 66, 540, 540, 1080, 1080, 540, 1080, 66, 1080, 540, 540, 540, 1080, 540, 66, 66, 540, 540, 66, 540, 66, 66, 66, 1080, 540]
Prompts retrieved: 36486 . Total input tokens: 8062787 . Total output tokens: 7286246
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.3647966459393501,
    "estimated_duration": 3599.543616109665,
    "input_throughput": 838.8430095655795,
    "output_throughput": 745.0386176729954,
    "total_throughput": 1583.8816272385748,
    "itl": 21.164121912629835,
    "ttft": 4873.421634688839,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7350,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.992698482126034,
    "arrivals": 12326,
    "finished_requests": 12311,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3648911900818348. Arrivals time: 0.043481271248310804 Scheduler time: 0.9133485448546708 Scheduler overhead time: 0.14185260003432631 Adapter cache time: 0.05488177575170994 Engine time: 0.14170809695497155 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_64_slots_16_rate_0.1-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_64_slots_16_rate_0.1-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 540, 1080, 1080, 66, 1080, 66, 540, 66, 1080, 540, 1080, 66, 540, 1080, 1080, 1080, 66, 1080, 540, 540, 66, 66, 66, 1080, 66, 66, 66, 1080, 540, 66, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 66, 540, 540, 1080, 1080, 540, 1080, 66, 1080, 540, 540, 540, 1080, 540, 66, 66, 540, 540, 66, 540, 66, 66, 66, 1080, 540]
Prompts retrieved: 36486 . Total input tokens: 8062787 . Total output tokens: 7286246
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 1.3590053799562156,
    "estimated_duration": 3599.55648030415,
    "input_throughput": 838.8400116852359,
    "output_throughput": 745.0359550333816,
    "total_throughput": 1583.8759667186175,
    "itl": 21.157867426729457,
    "ttft": 4871.9798382414265,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7350,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.91459592335066,
    "arrivals": 12326,
    "finished_requests": 12311,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.359142730012536. Arrivals time: 0.042870324570685625 Scheduler time: 0.9088042601943016 Scheduler overhead time: 0.1417499058879912 Adapter cache time: 0.05480872793123126 Engine time: 0.14077035104855895 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-32/adapters_64_slots_16_rate_0.1-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-32/adapters_64_slots_16_rate_0.1-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 540, 1080, 1080, 66, 1080, 66, 540, 66, 1080, 540, 1080, 66, 540, 1080, 1080, 1080, 66, 1080, 540, 540, 66, 66, 66, 1080, 66, 66, 66, 1080, 540, 66, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 66, 540, 540, 1080, 1080, 540, 1080, 66, 1080, 540, 540, 540, 1080, 540, 66, 66, 540, 540, 66, 540, 66, 66, 66, 1080, 540]
Prompts retrieved: 36486 . Total input tokens: 8062787 . Total output tokens: 7286246
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 1.400011070072651,
    "estimated_duration": 3599.5391245237583,
    "input_throughput": 838.8440562927601,
    "output_throughput": 745.0395473489453,
    "total_throughput": 1583.8836036417056,
    "itl": 21.1676846538754,
    "ttft": 4873.647947321284,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7350,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.309683763812206,
    "arrivals": 12326,
    "finished_requests": 12311,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4000954059883952. Arrivals time: 0.04346494376659393 Scheduler time: 0.9443600745871663 Scheduler overhead time: 0.14266426721587777 Adapter cache time: 0.055710011161863804 Engine time: 0.14340719860047102 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_64_slots_16_rate_0.1-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_64_slots_16_rate_0.1-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 540, 1080, 1080, 66, 1080, 66, 540, 66, 1080, 540, 1080, 66, 540, 1080, 1080, 1080, 66, 1080, 540, 540, 66, 66, 66, 1080, 66, 66, 66, 1080, 540, 66, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 66, 540, 540, 1080, 1080, 540, 1080, 66, 1080, 540, 540, 540, 1080, 540, 66, 66, 540, 540, 66, 540, 66, 66, 66, 1080, 540]
Prompts retrieved: 36486 . Total input tokens: 8062787 . Total output tokens: 7286246
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.3875675480812788,
    "estimated_duration": 3599.544315245987,
    "input_throughput": 838.8428466378405,
    "output_throughput": 745.0384729648009,
    "total_throughput": 1583.8813196026413,
    "itl": 21.152105930261335,
    "ttft": 4871.398081799721,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7350,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.976869667530845,
    "arrivals": 12326,
    "finished_requests": 12311,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3876630240119994. Arrivals time: 0.044389457907527685 Scheduler time: 0.930867095477879 Scheduler overhead time: 0.14203243143856525 Adapter cache time: 0.05573763744905591 Engine time: 0.14422407979145646 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-32/adapters_64_slots_16_rate_0.1-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-32/adapters_64_slots_16_rate_0.1-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 540, 1080, 1080, 66, 1080, 66, 540, 66, 1080, 540, 1080, 66, 540, 1080, 1080, 1080, 66, 1080, 540, 540, 66, 66, 66, 1080, 66, 66, 66, 1080, 540, 66, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 66, 540, 540, 1080, 1080, 540, 1080, 66, 1080, 540, 540, 540, 1080, 540, 66, 66, 540, 540, 66, 540, 66, 66, 66, 1080, 540]
Prompts retrieved: 36486 . Total input tokens: 8062787 . Total output tokens: 7286246
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.363751872908324,
    "estimated_duration": 3599.5573948583437,
    "input_throughput": 838.839798557741,
    "output_throughput": 745.035765739065,
    "total_throughput": 1583.875564296806,
    "itl": 21.169955703052064,
    "ttft": 4874.006759747615,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7350,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.598288703633347,
    "arrivals": 12326,
    "finished_requests": 12311,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.363845869898796. Arrivals time: 0.044142686296254396 Scheduler time: 0.910914896056056 Scheduler overhead time: 0.1431624684482813 Adapter cache time: 0.054424673318862915 Engine time: 0.14086524723097682 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_64_slots_16_rate_0.1-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_64_slots_16_rate_0.1-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 540, 1080, 1080, 33, 1080, 33, 540, 33, 1080, 540, 1080, 33, 540, 1080, 1080, 1080, 33, 1080, 540, 540, 33, 33, 33, 1080, 33, 33, 33, 1080, 540, 33, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 33, 540, 540, 1080, 1080, 540, 1080, 33, 1080, 540, 540, 540, 1080, 540, 33, 33, 540, 540, 33, 540, 33, 33, 33, 1080, 540]
Prompts retrieved: 35793 . Total input tokens: 7921893 . Total output tokens: 7141485
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.3520403420552611,
    "estimated_duration": 3599.611586158224,
    "input_throughput": 810.6477407787008,
    "output_throughput": 728.9497594934852,
    "total_throughput": 1539.597500272186,
    "itl": 21.019674902771918,
    "ttft": 6657.414725209442,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7014,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.46626103594431,
    "arrivals": 12061,
    "finished_requests": 12040,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3521240279078484. Arrivals time: 0.042950904462486506 Scheduler time: 0.9005504818633199 Scheduler overhead time: 0.14200519677251577 Adapter cache time: 0.05388444662094116 Engine time: 0.1424947059713304 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_64_slots_16_rate_0.1-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_64_slots_16_rate_0.1-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 540, 1080, 1080, 33, 1080, 33, 540, 33, 1080, 540, 1080, 33, 540, 1080, 1080, 1080, 33, 1080, 540, 540, 33, 33, 33, 1080, 33, 33, 33, 1080, 540, 33, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 33, 540, 540, 1080, 1080, 540, 1080, 33, 1080, 540, 540, 540, 1080, 540, 33, 33, 540, 540, 33, 540, 33, 33, 33, 1080, 540]
Prompts retrieved: 35793 . Total input tokens: 7921893 . Total output tokens: 7141485
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.3634421406313777,
    "estimated_duration": 3599.6094150569083,
    "input_throughput": 810.6482297201868,
    "output_throughput": 728.9501991589042,
    "total_throughput": 1539.598428879091,
    "itl": 21.026447796536324,
    "ttft": 6658.83153978935,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7011,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.827663055601093,
    "arrivals": 12061,
    "finished_requests": 12040,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3636310510337353. Arrivals time: 0.04309312254190445 Scheduler time: 0.912286180537194 Scheduler overhead time: 0.14222646644338965 Adapter cache time: 0.05402665212750435 Engine time: 0.1418134174309671 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-32/adapters_64_slots_16_rate_0.1-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-32/adapters_64_slots_16_rate_0.1-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 540, 1080, 1080, 33, 1080, 33, 540, 33, 1080, 540, 1080, 33, 540, 1080, 1080, 1080, 33, 1080, 540, 540, 33, 33, 33, 1080, 33, 33, 33, 1080, 540, 33, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 33, 540, 540, 1080, 1080, 540, 1080, 33, 1080, 540, 540, 540, 1080, 540, 33, 33, 540, 540, 33, 540, 33, 33, 33, 1080, 540]
Prompts retrieved: 35793 . Total input tokens: 7921893 . Total output tokens: 7141485
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.3655498810112476,
    "estimated_duration": 3599.6252683852945,
    "input_throughput": 810.644659495057,
    "output_throughput": 728.9469887450354,
    "total_throughput": 1539.5916482400924,
    "itl": 21.028249217908193,
    "ttft": 6658.817498503449,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7013,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.883732498939874,
    "arrivals": 12061,
    "finished_requests": 12040,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.36565032415092. Arrivals time: 0.042735498398542404 Scheduler time: 0.9120275457389653 Scheduler overhead time: 0.1435807915404439 Adapter cache time: 0.05407344829291105 Engine time: 0.1426785457879305 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_64_slots_16_rate_0.1-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_64_slots_16_rate_0.1-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 540, 1080, 1080, 33, 1080, 33, 540, 33, 1080, 540, 1080, 33, 540, 1080, 1080, 1080, 33, 1080, 540, 540, 33, 33, 33, 1080, 33, 33, 33, 1080, 540, 33, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 33, 540, 540, 1080, 1080, 540, 1080, 33, 1080, 540, 540, 540, 1080, 540, 33, 33, 540, 540, 33, 540, 33, 33, 33, 1080, 540]
Prompts retrieved: 35793 . Total input tokens: 7921893 . Total output tokens: 7141485
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 1.337816049810499,
    "estimated_duration": 3599.624230924595,
    "input_throughput": 810.6448931338819,
    "output_throughput": 728.9471988374795,
    "total_throughput": 1539.5920919713615,
    "itl": 21.022555974120234,
    "ttft": 6657.706321208744,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7014,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.873574040922698,
    "arrivals": 12061,
    "finished_requests": 12040,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.337896031793207. Arrivals time: 0.04248863738030195 Scheduler time: 0.886269910261035 Scheduler overhead time: 0.14226868329569697 Adapter cache time: 0.053653777576982975 Engine time: 0.14308645157143474 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-32/adapters_64_slots_16_rate_0.1-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-32/adapters_64_slots_16_rate_0.1-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 540, 1080, 1080, 33, 1080, 33, 540, 33, 1080, 540, 1080, 33, 540, 1080, 1080, 1080, 33, 1080, 540, 540, 33, 33, 33, 1080, 33, 33, 33, 1080, 540, 33, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 33, 540, 540, 1080, 1080, 540, 1080, 33, 1080, 540, 540, 540, 1080, 540, 33, 33, 540, 540, 33, 540, 33, 33, 33, 1080, 540]
Prompts retrieved: 35793 . Total input tokens: 7921893 . Total output tokens: 7141485
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 1.3458097949624062,
    "estimated_duration": 3599.610704065598,
    "input_throughput": 810.6479394297365,
    "output_throughput": 728.9499381242484,
    "total_throughput": 1539.597877553985,
    "itl": 21.03078301861195,
    "ttft": 6659.110360453152,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7014,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.183892201221436,
    "arrivals": 12061,
    "finished_requests": 12040,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3459059703163803. Arrivals time: 0.04311681352555752 Scheduler time: 0.8929586135782301 Scheduler overhead time: 0.14211792312562466 Adapter cache time: 0.05346937105059624 Engine time: 0.14404850313439965 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_64_slots_16_rate_0.1-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_64_slots_16_rate_0.1-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 540, 1080, 1080, 33, 1080, 33, 540, 33, 1080, 540, 1080, 33, 540, 1080, 1080, 1080, 33, 1080, 540, 540, 33, 33, 33, 1080, 33, 33, 33, 1080, 540, 33, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 33, 540, 540, 1080, 1080, 540, 1080, 33, 1080, 540, 540, 540, 1080, 540, 33, 33, 540, 540, 33, 540, 33, 33, 33, 1080, 540]
Prompts retrieved: 35793 . Total input tokens: 7921893 . Total output tokens: 7141485
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.3675393052399158,
    "estimated_duration": 3599.618134718584,
    "input_throughput": 810.6462660179172,
    "output_throughput": 728.9484333607342,
    "total_throughput": 1539.5946993786513,
    "itl": 21.014964785824525,
    "ttft": 6656.965342418297,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7014,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.97221276844405,
    "arrivals": 12061,
    "finished_requests": 12040,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3676368510350585. Arrivals time: 0.043288420885801315 Scheduler time: 0.9149947091937065 Scheduler overhead time: 0.14191163424402475 Adapter cache time: 0.05422006640583277 Engine time: 0.14313645754009485 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-32/adapters_64_slots_16_rate_0.1-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-32/adapters_64_slots_16_rate_0.1-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 540, 1080, 1080, 33, 1080, 33, 540, 33, 1080, 540, 1080, 33, 540, 1080, 1080, 1080, 33, 1080, 540, 540, 33, 33, 33, 1080, 33, 33, 33, 1080, 540, 33, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 33, 540, 540, 1080, 1080, 540, 1080, 33, 1080, 540, 540, 540, 1080, 540, 33, 33, 540, 540, 33, 540, 33, 33, 33, 1080, 540]
Prompts retrieved: 35793 . Total input tokens: 7921893 . Total output tokens: 7141485
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.3656169562600553,
    "estimated_duration": 3599.618480877871,
    "input_throughput": 810.646188061674,
    "output_throughput": 728.9483632610079,
    "total_throughput": 1539.5945513226818,
    "itl": 21.031445441992496,
    "ttft": 6659.3581176465705,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7014,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.46130505405179,
    "arrivals": 12061,
    "finished_requests": 12040,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3657100051641464. Arrivals time: 0.043274523224681616 Scheduler time: 0.911184552591294 Scheduler overhead time: 0.14224054850637913 Adapter cache time: 0.05383711215108633 Engine time: 0.14412174047902226 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_64_slots_16_rate_0.1-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_64_slots_16_rate_0.1-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 1080, 1080, 135, 1080, 135, 270, 135, 1080, 270, 1080, 135, 270, 1080, 1080, 1080, 135, 1080, 270, 270, 135, 135, 135, 1080, 135, 135, 135, 1080, 270, 135, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 135, 270, 270, 1080, 1080, 270, 1080, 135, 1080, 270, 270, 270, 1080, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 1080, 270]
Prompts retrieved: 32265 . Total input tokens: 7128362 . Total output tokens: 6458112
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.2593978918157518,
    "estimated_duration": 3599.3462132308337,
    "input_throughput": 744.6546792713626,
    "output_throughput": 664.8832477417817,
    "total_throughput": 1409.5379270131443,
    "itl": 20.774453873297976,
    "ttft": 5759.207485096771,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6387,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.54733522049785,
    "arrivals": 10900,
    "finished_requests": 10883,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2594858705997467. Arrivals time: 0.03966319281607866 Scheduler time: 0.8132629590108991 Scheduler overhead time: 0.14217907609418035 Adapter cache time: 0.05174081027507782 Engine time: 0.14201844204217196 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_64_slots_16_rate_0.1-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_64_slots_16_rate_0.1-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 1080, 1080, 135, 1080, 135, 270, 135, 1080, 270, 1080, 135, 270, 1080, 1080, 1080, 135, 1080, 270, 270, 135, 135, 135, 1080, 135, 135, 135, 1080, 270, 135, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 135, 270, 270, 1080, 1080, 270, 1080, 135, 1080, 270, 270, 270, 1080, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 1080, 270]
Prompts retrieved: 32265 . Total input tokens: 7128362 . Total output tokens: 6458112
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.289326321799308,
    "estimated_duration": 3599.354425154012,
    "input_throughput": 744.6529803425275,
    "output_throughput": 664.8817308113802,
    "total_throughput": 1409.5347111539077,
    "itl": 20.784191657237255,
    "ttft": 5759.768350026505,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6385,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.79163625298006,
    "arrivals": 10900,
    "finished_requests": 10883,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2894222866743803. Arrivals time: 0.04045536182820797 Scheduler time: 0.8363795238547027 Scheduler overhead time: 0.14338377118110657 Adapter cache time: 0.052776109892874956 Engine time: 0.14521181117743254 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-32/adapters_64_slots_16_rate_0.1-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-32/adapters_64_slots_16_rate_0.1-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 1080, 1080, 135, 1080, 135, 270, 135, 1080, 270, 1080, 135, 270, 1080, 1080, 1080, 135, 1080, 270, 270, 135, 135, 135, 1080, 135, 135, 135, 1080, 270, 135, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 135, 270, 270, 1080, 1080, 270, 1080, 135, 1080, 270, 270, 270, 1080, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 1080, 270]
Prompts retrieved: 32265 . Total input tokens: 7128362 . Total output tokens: 6458112
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.2912232959643006,
    "estimated_duration": 3599.342112095795,
    "input_throughput": 744.6555277401387,
    "output_throughput": 664.8840053179995,
    "total_throughput": 1409.5395330581382,
    "itl": 20.786241943339157,
    "ttft": 5759.819205767964,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6386,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.839872687961385,
    "arrivals": 10900,
    "finished_requests": 10883,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2913108109496534. Arrivals time: 0.04036152409389615 Scheduler time: 0.8406270006671548 Scheduler overhead time: 0.1430131746456027 Adapter cache time: 0.05246605956926942 Engine time: 0.1437298790551722 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_64_slots_16_rate_0.1-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_64_slots_16_rate_0.1-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 1080, 1080, 135, 1080, 135, 270, 135, 1080, 270, 1080, 135, 270, 1080, 1080, 1080, 135, 1080, 270, 270, 135, 135, 135, 1080, 135, 135, 135, 1080, 270, 135, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 135, 270, 270, 1080, 1080, 270, 1080, 135, 1080, 270, 270, 270, 1080, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 1080, 270]
Prompts retrieved: 32265 . Total input tokens: 7128362 . Total output tokens: 6458112
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 1.2889989390969276,
    "estimated_duration": 3599.335715211371,
    "input_throughput": 744.6568511719395,
    "output_throughput": 664.8851869766371,
    "total_throughput": 1409.5420381485765,
    "itl": 20.77844083602961,
    "ttft": 5759.303098777714,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6390,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.000019345853996,
    "arrivals": 10900,
    "finished_requests": 10883,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2891179858706892. Arrivals time: 0.04065469838678837 Scheduler time: 0.8357286718674004 Scheduler overhead time: 0.14342214167118073 Adapter cache time: 0.052811992820352316 Engine time: 0.1456487737596035 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-32/adapters_64_slots_16_rate_0.1-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-32/adapters_64_slots_16_rate_0.1-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 1080, 1080, 135, 1080, 135, 270, 135, 1080, 270, 1080, 135, 270, 1080, 1080, 1080, 135, 1080, 270, 270, 135, 135, 135, 1080, 135, 135, 135, 1080, 270, 135, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 135, 270, 270, 1080, 1080, 270, 1080, 135, 1080, 270, 270, 270, 1080, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 1080, 270]
Prompts retrieved: 32265 . Total input tokens: 7128362 . Total output tokens: 6458112
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 1.2623083610087633,
    "estimated_duration": 3599.3381517904413,
    "input_throughput": 744.6563470750134,
    "output_throughput": 664.8847368812966,
    "total_throughput": 1409.5410839563099,
    "itl": 20.786016135092854,
    "ttft": 5760.057038116042,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6389,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.098292975238422,
    "arrivals": 10900,
    "finished_requests": 10883,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2624289910309017. Arrivals time: 0.03931062202900648 Scheduler time: 0.8149283179081976 Scheduler overhead time: 0.14352433942258358 Adapter cache time: 0.05171569064259529 Engine time: 0.14222494838759303 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_64_slots_16_rate_0.1-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_64_slots_16_rate_0.1-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 1080, 1080, 135, 1080, 135, 270, 135, 1080, 270, 1080, 135, 270, 1080, 1080, 1080, 135, 1080, 270, 270, 135, 135, 135, 1080, 135, 135, 135, 1080, 270, 135, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 135, 270, 270, 1080, 1080, 270, 1080, 135, 1080, 270, 270, 270, 1080, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 1080, 270]
Prompts retrieved: 32265 . Total input tokens: 7128362 . Total output tokens: 6458112
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.2658887598663568,
    "estimated_duration": 3599.347385432765,
    "input_throughput": 744.6544367591625,
    "output_throughput": 664.8830312087985,
    "total_throughput": 1409.537467967961,
    "itl": 20.77301788924735,
    "ttft": 5758.953409586137,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6388,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.10044128383591,
    "arrivals": 10900,
    "finished_requests": 10883,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2659686929546297. Arrivals time: 0.03954449715092778 Scheduler time: 0.816921042278409 Scheduler overhead time: 0.14402239629998803 Adapter cache time: 0.05161802191287279 Engine time: 0.1427107099443674 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-32/adapters_64_slots_16_rate_0.1-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-32/adapters_64_slots_16_rate_0.1-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 1080, 1080, 135, 1080, 135, 270, 135, 1080, 270, 1080, 135, 270, 1080, 1080, 1080, 135, 1080, 270, 270, 135, 135, 135, 1080, 135, 135, 135, 1080, 270, 135, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 135, 270, 270, 1080, 1080, 270, 1080, 135, 1080, 270, 270, 270, 1080, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 1080, 270]
Prompts retrieved: 32265 . Total input tokens: 7128362 . Total output tokens: 6458112
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.2973489686846733,
    "estimated_duration": 3599.351667544051,
    "input_throughput": 744.6535508515152,
    "output_throughput": 664.8822402043635,
    "total_throughput": 1409.5357910558787,
    "itl": 20.787733422669135,
    "ttft": 5760.228406259663,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6387,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.366429219654023,
    "arrivals": 10900,
    "finished_requests": 10883,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2974263108335435. Arrivals time: 0.04039189824834466 Scheduler time: 0.843770198058337 Scheduler overhead time: 0.14326112577691674 Adapter cache time: 0.052909917663782835 Engine time: 0.14577881759032607 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_64_slots_16_rate_0.1-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_64_slots_16_rate_0.1-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 1080, 1080, 66, 1080, 66, 270, 66, 1080, 270, 1080, 66, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 1080, 66, 66, 66, 1080, 270, 66, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 66, 270, 270, 1080, 1080, 270, 1080, 66, 1080, 270, 270, 270, 1080, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 1080, 270]
Prompts retrieved: 30816 . Total input tokens: 6815025 . Total output tokens: 6168815
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.2443923680111766,
    "estimated_duration": 3599.8676295509817,
    "input_throughput": 705.0334237752439,
    "output_throughput": 628.3253254737396,
    "total_throughput": 1333.3587492489835,
    "itl": 20.406396035159066,
    "ttft": 5988.234695119593,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5766,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.646772331514992,
    "arrivals": 10387,
    "finished_requests": 10370,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2444740463979542. Arrivals time: 0.03864432638511062 Scheduler time: 0.792486663442105 Scheduler overhead time: 0.1448009628802538 Adapter cache time: 0.05041665444150567 Engine time: 0.1460896534845233 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_64_slots_16_rate_0.1-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_64_slots_16_rate_0.1-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 1080, 1080, 66, 1080, 66, 270, 66, 1080, 270, 1080, 66, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 1080, 66, 66, 66, 1080, 270, 66, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 66, 270, 270, 1080, 1080, 270, 1080, 66, 1080, 270, 270, 270, 1080, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 1080, 270]
Prompts retrieved: 30816 . Total input tokens: 6815025 . Total output tokens: 6168815
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.2218393059447408,
    "estimated_duration": 3599.8814074290012,
    "input_throughput": 705.0307253906548,
    "output_throughput": 628.3229206751612,
    "total_throughput": 1333.353646065816,
    "itl": 20.416325730609966,
    "ttft": 5988.491532109241,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5762,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.77356869824939,
    "arrivals": 10387,
    "finished_requests": 10370,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2219174476340413. Arrivals time: 0.03778625838458538 Scheduler time: 0.7753904806450009 Scheduler overhead time: 0.1439277045428753 Adapter cache time: 0.0501847923733294 Engine time: 0.14319658977910876 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_64_slots_16_rate_0.1-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_64_slots_16_rate_0.1-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 1080, 1080, 66, 1080, 66, 270, 66, 1080, 270, 1080, 66, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 1080, 66, 66, 66, 1080, 270, 66, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 66, 270, 270, 1080, 1080, 270, 1080, 66, 1080, 270, 270, 270, 1080, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 1080, 270]
Prompts retrieved: 30816 . Total input tokens: 6815025 . Total output tokens: 6168815
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.2257358292117715,
    "estimated_duration": 3599.864659449107,
    "input_throughput": 705.0340054696385,
    "output_throughput": 628.325843879403,
    "total_throughput": 1333.3598493490415,
    "itl": 20.415314007551892,
    "ttft": 5988.464411377854,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5764,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.818987163602433,
    "arrivals": 10387,
    "finished_requests": 10370,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2259053201414645. Arrivals time: 0.03860185667872429 Scheduler time: 0.7772771799936891 Scheduler overhead time: 0.14391029998660088 Adapter cache time: 0.05005767848342657 Engine time: 0.14459563745185733 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_64_slots_16_rate_0.1-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_64_slots_16_rate_0.1-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 1080, 1080, 66, 1080, 66, 270, 66, 1080, 270, 1080, 66, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 1080, 66, 66, 66, 1080, 270, 66, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 66, 270, 270, 1080, 1080, 270, 1080, 66, 1080, 270, 270, 270, 1080, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 1080, 270]
Prompts retrieved: 30816 . Total input tokens: 6815025 . Total output tokens: 6168815
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 1.240532890893519,
    "estimated_duration": 3599.871599670423,
    "input_throughput": 705.0326462289273,
    "output_throughput": 628.3246325249715,
    "total_throughput": 1333.3572787538988,
    "itl": 20.410192506748015,
    "ttft": 5988.360267005442,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5766,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.038208062002234,
    "arrivals": 10387,
    "finished_requests": 10370,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2406878960318863. Arrivals time: 0.03869020938873291 Scheduler time: 0.7909658858552575 Scheduler overhead time: 0.14459079504013062 Adapter cache time: 0.050390833523124456 Engine time: 0.14481086982414126 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_64_slots_16_rate_0.1-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_64_slots_16_rate_0.1-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 1080, 1080, 66, 1080, 66, 270, 66, 1080, 270, 1080, 66, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 1080, 66, 66, 66, 1080, 270, 66, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 66, 270, 270, 1080, 1080, 270, 1080, 66, 1080, 270, 270, 270, 1080, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 1080, 270]
Prompts retrieved: 30816 . Total input tokens: 6815025 . Total output tokens: 6168815
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 1.259117587003857,
    "estimated_duration": 3599.883685583827,
    "input_throughput": 705.030279218142,
    "output_throughput": 628.3225230465101,
    "total_throughput": 1333.3528022646522,
    "itl": 20.418007198327484,
    "ttft": 5988.498105712793,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5770,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.06838944831751,
    "arrivals": 10387,
    "finished_requests": 10370,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2592016719281673. Arrivals time: 0.03889913531020284 Scheduler time: 0.8056846898980439 Scheduler overhead time: 0.1437148731201887 Adapter cache time: 0.051550593227148056 Engine time: 0.14726420771330595 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_64_slots_16_rate_0.1-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_64_slots_16_rate_0.1-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 1080, 1080, 66, 1080, 66, 270, 66, 1080, 270, 1080, 66, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 1080, 66, 66, 66, 1080, 270, 66, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 66, 270, 270, 1080, 1080, 270, 1080, 66, 1080, 270, 270, 270, 1080, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 1080, 270]
Prompts retrieved: 30816 . Total input tokens: 6815025 . Total output tokens: 6168815
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.2335105780512094,
    "estimated_duration": 3599.8655510704916,
    "input_throughput": 705.0338308455067,
    "output_throughput": 628.3256882544912,
    "total_throughput": 1333.359519099998,
    "itl": 20.405430271443485,
    "ttft": 5988.112084233635,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5761,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.22567974893287,
    "arrivals": 10387,
    "finished_requests": 10370,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2335825110785663. Arrivals time: 0.03849917696788907 Scheduler time: 0.7848657853901386 Scheduler overhead time: 0.1443286556750536 Adapter cache time: 0.04991042660549283 Engine time: 0.14451940217986703 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_64_slots_16_rate_0.1-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_64_slots_16_rate_0.1-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 1080, 1080, 66, 1080, 66, 270, 66, 1080, 270, 1080, 66, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 1080, 66, 66, 66, 1080, 270, 66, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 66, 270, 270, 1080, 1080, 270, 1080, 66, 1080, 270, 270, 270, 1080, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 1080, 270]
Prompts retrieved: 30816 . Total input tokens: 6815025 . Total output tokens: 6168815
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.2134466310963035,
    "estimated_duration": 3599.8687224302703,
    "input_throughput": 705.033209735098,
    "output_throughput": 628.3251347213018,
    "total_throughput": 1333.3583444563997,
    "itl": 20.419637190453756,
    "ttft": 5988.639160616264,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5767,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.30489605050388,
    "arrivals": 10387,
    "finished_requests": 10370,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2135273511521518. Arrivals time: 0.03804540727287531 Scheduler time: 0.7668048455379903 Scheduler overhead time: 0.14516636868938804 Adapter cache time: 0.04965232126414776 Engine time: 0.14227681839838624 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_64_slots_16_rate_0.1-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_64_slots_16_rate_0.1-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 1080, 1080, 33, 1080, 33, 270, 33, 1080, 270, 1080, 33, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 1080, 33, 33, 33, 1080, 270, 33, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 33, 270, 270, 1080, 1080, 270, 1080, 33, 1080, 270, 270, 270, 1080, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 1080, 270]
Prompts retrieved: 30123 . Total input tokens: 6646577 . Total output tokens: 6036268
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.2417146298103034,
    "estimated_duration": 3599.7646431962476,
    "input_throughput": 696.2866321656228,
    "output_throughput": 611.8338886856857,
    "total_throughput": 1308.1205208513086,
    "itl": 20.46149366582341,
    "ttft": 5404.677842355506,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5460,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.710263081871265,
    "arrivals": 10134,
    "finished_requests": 10119,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2419305639341474. Arrivals time: 0.03850763104856014 Scheduler time: 0.7886948636732996 Scheduler overhead time: 0.1450555194169283 Adapter cache time: 0.05006895773112774 Engine time: 0.14743100432679057 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_64_slots_16_rate_0.1-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_64_slots_16_rate_0.1-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 1080, 1080, 33, 1080, 33, 270, 33, 1080, 270, 1080, 33, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 1080, 33, 33, 33, 1080, 270, 33, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 33, 270, 270, 1080, 1080, 270, 1080, 33, 1080, 270, 270, 270, 1080, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 1080, 270]
Prompts retrieved: 30123 . Total input tokens: 6646577 . Total output tokens: 6036268
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.2245988682843745,
    "estimated_duration": 3599.775506735106,
    "input_throughput": 696.2845308854538,
    "output_throughput": 611.8320422702045,
    "total_throughput": 1308.1165731556582,
    "itl": 20.46772836688643,
    "ttft": 5405.081124852756,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5462,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.773587589532138,
    "arrivals": 10134,
    "finished_requests": 10119,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.224691501352936. Arrivals time: 0.038167436607182026 Scheduler time: 0.7710147714242339 Scheduler overhead time: 0.1502799498848617 Adapter cache time: 0.04912804253399372 Engine time: 0.14341547340154648 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_64_slots_16_rate_0.1-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_64_slots_16_rate_0.1-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 1080, 1080, 33, 1080, 33, 270, 33, 1080, 270, 1080, 33, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 1080, 33, 33, 33, 1080, 270, 33, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 33, 270, 270, 1080, 1080, 270, 1080, 33, 1080, 270, 270, 270, 1080, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 1080, 270]
Prompts retrieved: 30123 . Total input tokens: 6646577 . Total output tokens: 6036268
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.2048040269874036,
    "estimated_duration": 3599.7753856370186,
    "input_throughput": 696.2845543087833,
    "output_throughput": 611.8320628525137,
    "total_throughput": 1308.116617161297,
    "itl": 20.469262381887212,
    "ttft": 5404.974803457927,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5467,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.830075696891946,
    "arrivals": 10134,
    "finished_requests": 10119,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2048856862820685. Arrivals time: 0.037579458206892014 Scheduler time: 0.7579606035724282 Scheduler overhead time: 0.14412726322188973 Adapter cache time: 0.0490814377553761 Engine time: 0.14453027117997408 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_64_slots_16_rate_0.1-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_64_slots_16_rate_0.1-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 1080, 1080, 33, 1080, 33, 270, 33, 1080, 270, 1080, 33, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 1080, 33, 33, 33, 1080, 270, 33, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 33, 270, 270, 1080, 1080, 270, 1080, 33, 1080, 270, 270, 270, 1080, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 1080, 270]
Prompts retrieved: 30123 . Total input tokens: 6646577 . Total output tokens: 6036268
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 1.2020737892016768,
    "estimated_duration": 3599.7671178081555,
    "input_throughput": 696.2861535126614,
    "output_throughput": 611.8334680886368,
    "total_throughput": 1308.1196216012981,
    "itl": 20.464721425681397,
    "ttft": 5404.8839564154605,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5463,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.07665385933933,
    "arrivals": 10134,
    "finished_requests": 10119,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2021611011587083. Arrivals time: 0.03841149155050516 Scheduler time: 0.7550445855595171 Scheduler overhead time: 0.14447658276185393 Adapter cache time: 0.04886143794283271 Engine time: 0.14367982046678662 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_64_slots_16_rate_0.1-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_64_slots_16_rate_0.1-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 1080, 1080, 33, 1080, 33, 270, 33, 1080, 270, 1080, 33, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 1080, 33, 33, 33, 1080, 270, 33, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 33, 270, 270, 1080, 1080, 270, 1080, 33, 1080, 270, 270, 270, 1080, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 1080, 270]
Prompts retrieved: 30123 . Total input tokens: 6646577 . Total output tokens: 6036268
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 1.2208446087315679,
    "estimated_duration": 3599.760340631665,
    "input_throughput": 696.2874643927489,
    "output_throughput": 611.8346199718189,
    "total_throughput": 1308.1220843645679,
    "itl": 20.47020124090432,
    "ttft": 5405.129973841496,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5464,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.035898375193305,
    "arrivals": 10134,
    "finished_requests": 10119,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.22092214692384. Arrivals time: 0.03814989374950528 Scheduler time: 0.7699089972302318 Scheduler overhead time: 0.14693900058045983 Adapter cache time: 0.04937343392521143 Engine time: 0.14435878209769726 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_64_slots_16_rate_0.1-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_64_slots_16_rate_0.1-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 1080, 1080, 33, 1080, 33, 270, 33, 1080, 270, 1080, 33, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 1080, 33, 33, 33, 1080, 270, 33, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 33, 270, 270, 1080, 1080, 270, 1080, 33, 1080, 270, 270, 270, 1080, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 1080, 270]
Prompts retrieved: 30123 . Total input tokens: 6646577 . Total output tokens: 6036268
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.2105975868180394,
    "estimated_duration": 3599.763657706914,
    "input_throughput": 696.2868227845396,
    "output_throughput": 611.8340561843963,
    "total_throughput": 1308.120878968936,
    "itl": 20.458840471039895,
    "ttft": 5404.561226452805,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5459,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.322684559872712,
    "arrivals": 10134,
    "finished_requests": 10119,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.210663974750787. Arrivals time: 0.03812215756624937 Scheduler time: 0.7634538533166051 Scheduler overhead time: 0.14494340866804123 Adapter cache time: 0.04861538205295801 Engine time: 0.14363001054152846 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_64_slots_16_rate_0.1-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_64_slots_16_rate_0.1-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 1080, 1080, 33, 1080, 33, 270, 33, 1080, 270, 1080, 33, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 1080, 33, 33, 33, 1080, 270, 33, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 33, 270, 270, 1080, 1080, 270, 1080, 33, 1080, 270, 270, 270, 1080, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 1080, 270]
Prompts retrieved: 30123 . Total input tokens: 6646577 . Total output tokens: 6036268
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.2090239417739213,
    "estimated_duration": 3599.768749111765,
    "input_throughput": 696.2858379773605,
    "output_throughput": 611.833190824675,
    "total_throughput": 1308.1190288020355,
    "itl": 20.47083704358869,
    "ttft": 5405.164073359197,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5465,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.267225030249485,
    "arrivals": 10134,
    "finished_requests": 10119,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2090892638079822. Arrivals time: 0.037836219649761915 Scheduler time: 0.7614445281215012 Scheduler overhead time: 0.14523640647530556 Adapter cache time: 0.04879964282736182 Engine time: 0.14389686519280076 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_64_slots_16_rate_0.1-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_64_slots_16_rate_0.1-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 1080, 1080, 66, 1080, 66, 135, 66, 1080, 135, 1080, 66, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 1080, 66, 66, 66, 1080, 135, 66, 1080, 1080, 1080, 1080, 135, 135, 135, 1080, 66, 135, 135, 1080, 1080, 135, 1080, 66, 1080, 135, 135, 135, 1080, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 1080, 135]
Prompts retrieved: 27981 . Total input tokens: 6178389 . Total output tokens: 5605039
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.1652435190044343,
    "estimated_duration": 3600.0148020245606,
    "input_throughput": 640.5490329381895,
    "output_throughput": 574.2498610942922,
    "total_throughput": 1214.7988940324817,
    "itl": 20.07470949124239,
    "ttft": 5008.361309986078,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4608,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.102727524040812,
    "arrivals": 9465,
    "finished_requests": 9451,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1653235792182386. Arrivals time: 0.03602323727682233 Scheduler time: 0.7191553213633597 Scheduler overhead time: 0.145565717946738 Adapter cache time: 0.04677642975002527 Engine time: 0.1452979426831007 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_64_slots_16_rate_0.1-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_64_slots_16_rate_0.1-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 1080, 1080, 66, 1080, 66, 135, 66, 1080, 135, 1080, 66, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 1080, 66, 66, 66, 1080, 135, 66, 1080, 1080, 1080, 1080, 135, 135, 135, 1080, 66, 135, 135, 1080, 1080, 135, 1080, 66, 1080, 135, 135, 135, 1080, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 1080, 135]
Prompts retrieved: 27981 . Total input tokens: 6178389 . Total output tokens: 5605039
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.1852974873036146,
    "estimated_duration": 3600.0026627306697,
    "input_throughput": 640.551192884637,
    "output_throughput": 574.2517974783685,
    "total_throughput": 1214.8029903630056,
    "itl": 20.07978889902159,
    "ttft": 5008.590864631932,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4608,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.006389286141836,
    "arrivals": 9465,
    "finished_requests": 9451,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1853852500207722. Arrivals time: 0.036803971510380507 Scheduler time: 0.7363491249270737 Scheduler overhead time: 0.1466778996400535 Adapter cache time: 0.04733714833855629 Engine time: 0.14567421795800328 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_64_slots_16_rate_0.1-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_64_slots_16_rate_0.1-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 1080, 1080, 66, 1080, 66, 135, 66, 1080, 135, 1080, 66, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 1080, 66, 66, 66, 1080, 135, 66, 1080, 1080, 1080, 1080, 135, 135, 135, 1080, 66, 135, 135, 1080, 1080, 135, 1080, 66, 1080, 135, 135, 135, 1080, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 1080, 135]
Prompts retrieved: 27981 . Total input tokens: 6178389 . Total output tokens: 5605039
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.1724026016891003,
    "estimated_duration": 3600.012745585108,
    "input_throughput": 640.5493988397559,
    "output_throughput": 574.2501891237059,
    "total_throughput": 1214.7995879634618,
    "itl": 20.07919312131071,
    "ttft": 5008.524991469562,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4607,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.035257304831068,
    "arrivals": 9465,
    "finished_requests": 9451,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.172487594652921. Arrivals time: 0.03653775295242667 Scheduler time: 0.7254188437946141 Scheduler overhead time: 0.14569459250196815 Adapter cache time: 0.04681431921198964 Engine time: 0.14535425370559096 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_64_slots_16_rate_0.1-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_64_slots_16_rate_0.1-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 1080, 1080, 66, 1080, 66, 135, 66, 1080, 135, 1080, 66, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 1080, 66, 66, 66, 1080, 135, 66, 1080, 1080, 1080, 1080, 135, 135, 135, 1080, 66, 135, 135, 1080, 1080, 135, 1080, 66, 1080, 135, 135, 135, 1080, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 1080, 135]
Prompts retrieved: 27981 . Total input tokens: 6178389 . Total output tokens: 5605039
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 1.1711795190349221,
    "estimated_duration": 3600.0000437997132,
    "input_throughput": 640.5516588733392,
    "output_throughput": 574.2522152355327,
    "total_throughput": 1214.803874108872,
    "itl": 20.076287260570208,
    "ttft": 5008.6190912843185,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4608,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.476032562806425,
    "arrivals": 9465,
    "finished_requests": 9451,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.171343952883035. Arrivals time: 0.036325300578027964 Scheduler time: 0.7246324927546084 Scheduler overhead time: 0.14600603561848402 Adapter cache time: 0.046911502722650766 Engine time: 0.14520407794043422 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_64_slots_16_rate_0.1-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_64_slots_16_rate_0.1-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 1080, 1080, 66, 1080, 66, 135, 66, 1080, 135, 1080, 66, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 1080, 66, 66, 66, 1080, 135, 66, 1080, 1080, 1080, 1080, 135, 135, 135, 1080, 66, 135, 135, 1080, 1080, 135, 1080, 66, 1080, 135, 135, 135, 1080, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 1080, 135]
Prompts retrieved: 27981 . Total input tokens: 6178389 . Total output tokens: 5605039
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 1.1723218481056392,
    "estimated_duration": 3600.003302783897,
    "input_throughput": 640.551078999503,
    "output_throughput": 574.2516953807632,
    "total_throughput": 1214.8027743802663,
    "itl": 20.080997785700575,
    "ttft": 5008.586618345394,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4609,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.20537300607071,
    "arrivals": 9465,
    "finished_requests": 9451,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.172402654774487. Arrivals time: 0.03592221857979894 Scheduler time: 0.7249543867073953 Scheduler overhead time: 0.14587480248883367 Adapter cache time: 0.04740104917436838 Engine time: 0.14586264686658978 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_64_slots_16_rate_0.1-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_64_slots_16_rate_0.1-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 1080, 1080, 66, 1080, 66, 135, 66, 1080, 135, 1080, 66, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 1080, 66, 66, 66, 1080, 135, 66, 1080, 1080, 1080, 1080, 135, 135, 135, 1080, 66, 135, 135, 1080, 1080, 135, 1080, 66, 1080, 135, 135, 135, 1080, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 1080, 135]
Prompts retrieved: 27981 . Total input tokens: 6178389 . Total output tokens: 5605039
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.1788117759861052,
    "estimated_duration": 3600.017589083049,
    "input_throughput": 640.5485370384959,
    "output_throughput": 574.2494165220338,
    "total_throughput": 1214.7979535605298,
    "itl": 20.072374714788797,
    "ttft": 5008.326683257076,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4608,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.778151758910488,
    "arrivals": 9465,
    "finished_requests": 9451,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1788992136716843. Arrivals time: 0.036408116575330496 Scheduler time: 0.7297621215693653 Scheduler overhead time: 0.14633751520887017 Adapter cache time: 0.047354831360280514 Engine time: 0.14598668087273836 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_64_slots_16_rate_0.1-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_64_slots_16_rate_0.1-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 1080, 1080, 66, 1080, 66, 135, 66, 1080, 135, 1080, 66, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 1080, 66, 66, 66, 1080, 135, 66, 1080, 1080, 1080, 1080, 135, 135, 135, 1080, 66, 135, 135, 1080, 1080, 135, 1080, 66, 1080, 135, 135, 135, 1080, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 1080, 135]
Prompts retrieved: 27981 . Total input tokens: 6178389 . Total output tokens: 5605039
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.1807228499092162,
    "estimated_duration": 3600.01167757494,
    "input_throughput": 640.5495888706037,
    "output_throughput": 574.2503594856646,
    "total_throughput": 1214.7999483562683,
    "itl": 20.083591385845388,
    "ttft": 5008.561955194628,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4609,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.420286227053818,
    "arrivals": 9465,
    "finished_requests": 9451,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1808146797120571. Arrivals time: 0.037771266885101795 Scheduler time: 0.7255507567897439 Scheduler overhead time: 0.15056048007681966 Adapter cache time: 0.0472065475769341 Engine time: 0.14683669060468674 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_64_slots_16_rate_0.1-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_64_slots_16_rate_0.1-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 1080, 1080, 33, 1080, 33, 135, 33, 1080, 135, 1080, 33, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 1080, 33, 33, 33, 1080, 135, 33, 1080, 1080, 1080, 1080, 135, 135, 135, 1080, 33, 135, 135, 1080, 1080, 135, 1080, 33, 1080, 135, 135, 135, 1080, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 1080, 135]
Prompts retrieved: 27288 . Total input tokens: 6016089 . Total output tokens: 5465738
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.1646841098554432,
    "estimated_duration": 3599.007415509557,
    "input_throughput": 628.6772264623559,
    "output_throughput": 558.4489743862998,
    "total_throughput": 1187.1262008486558,
    "itl": 19.9384573629666,
    "ttft": 7096.244442449328,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4340,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.282516808667044,
    "arrivals": 9201,
    "finished_requests": 9183,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1647653011605144. Arrivals time: 0.036029023583978415 Scheduler time: 0.716110238339752 Scheduler overhead time: 0.1460641799494624 Adapter cache time: 0.046418444719165564 Engine time: 0.14770450396463275 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_64_slots_16_rate_0.1-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_64_slots_16_rate_0.1-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 1080, 1080, 33, 1080, 33, 135, 33, 1080, 135, 1080, 33, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 1080, 33, 33, 33, 1080, 135, 33, 1080, 1080, 1080, 1080, 135, 135, 135, 1080, 33, 135, 135, 1080, 1080, 135, 1080, 33, 1080, 135, 135, 135, 1080, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 1080, 135]
Prompts retrieved: 27288 . Total input tokens: 6016089 . Total output tokens: 5465738
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.1606937730684876,
    "estimated_duration": 3598.9943220641508,
    "input_throughput": 628.6333896471406,
    "output_throughput": 558.3793193781481,
    "total_throughput": 1187.0127090252888,
    "itl": 19.945275904614924,
    "ttft": 7487.579748361246,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4343,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.135167061533615,
    "arrivals": 9201,
    "finished_requests": 9182,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1607758910395205. Arrivals time: 0.03574476297944784 Scheduler time: 0.7129047247581184 Scheduler overhead time: 0.14581073494628072 Adapter cache time: 0.046053079422563314 Engine time: 0.14746641786769032 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_64_slots_16_rate_0.1-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_64_slots_16_rate_0.1-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 1080, 1080, 33, 1080, 33, 135, 33, 1080, 135, 1080, 33, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 1080, 33, 33, 33, 1080, 135, 33, 1080, 1080, 1080, 1080, 135, 135, 135, 1080, 33, 135, 135, 1080, 1080, 135, 1080, 33, 1080, 135, 135, 135, 1080, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 1080, 135]
Prompts retrieved: 27288 . Total input tokens: 6016089 . Total output tokens: 5465738
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.1594107085838914,
    "estimated_duration": 3599.0102125115545,
    "input_throughput": 628.6767378803975,
    "output_throughput": 558.4485403828365,
    "total_throughput": 1187.125278263234,
    "itl": 19.943273006900053,
    "ttft": 7096.414623824197,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4342,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.163973290956399,
    "arrivals": 9201,
    "finished_requests": 9183,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1595078436657786. Arrivals time: 0.03561249375343323 Scheduler time: 0.7122687757946551 Scheduler overhead time: 0.14679530868306756 Adapter cache time: 0.04599964385852218 Engine time: 0.14599883975461125 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_64_slots_16_rate_0.1-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_64_slots_16_rate_0.1-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 1080, 1080, 33, 1080, 33, 135, 33, 1080, 135, 1080, 33, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 1080, 33, 33, 33, 1080, 135, 33, 1080, 1080, 1080, 1080, 135, 135, 135, 1080, 33, 135, 135, 1080, 1080, 135, 1080, 33, 1080, 135, 135, 135, 1080, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 1080, 135]
Prompts retrieved: 27288 . Total input tokens: 6016089 . Total output tokens: 5465738
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 1.1574395978823304,
    "estimated_duration": 3599.011782644507,
    "input_throughput": 628.67646360898,
    "output_throughput": 558.4482967497204,
    "total_throughput": 1187.1247603587005,
    "itl": 19.940734314661462,
    "ttft": 7096.264520664478,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4345,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.632854585983775,
    "arrivals": 9201,
    "finished_requests": 9183,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1575050270184875. Arrivals time: 0.03581493394449353 Scheduler time: 0.7091173436492682 Scheduler overhead time: 0.14595545595511794 Adapter cache time: 0.04583571571856737 Engine time: 0.14734329096972942 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_64_slots_16_rate_0.1-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_64_slots_16_rate_0.1-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 1080, 1080, 33, 1080, 33, 135, 33, 1080, 135, 1080, 33, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 1080, 33, 33, 33, 1080, 135, 33, 1080, 1080, 1080, 1080, 135, 135, 135, 1080, 33, 135, 135, 1080, 1080, 135, 1080, 33, 1080, 135, 135, 135, 1080, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 1080, 135]
Prompts retrieved: 27288 . Total input tokens: 6016089 . Total output tokens: 5465738
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 1.1572781060822308,
    "estimated_duration": 3599.0103172508716,
    "input_throughput": 628.6767195844865,
    "output_throughput": 558.4485241307245,
    "total_throughput": 1187.1252437152111,
    "itl": 19.944066597732505,
    "ttft": 7096.304613965081,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4342,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.320199507548349,
    "arrivals": 9201,
    "finished_requests": 9183,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1573724742047489. Arrivals time: 0.03631060430780053 Scheduler time: 0.7076852493919432 Scheduler overhead time: 0.14637295808643103 Adapter cache time: 0.04632260790094733 Engine time: 0.14778332319110632 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_64_slots_16_rate_0.1-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_64_slots_16_rate_0.1-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 1080, 1080, 33, 1080, 33, 135, 33, 1080, 135, 1080, 33, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 1080, 33, 33, 33, 1080, 135, 33, 1080, 1080, 1080, 1080, 135, 135, 135, 1080, 33, 135, 135, 1080, 1080, 135, 1080, 33, 1080, 135, 135, 135, 1080, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 1080, 135]
Prompts retrieved: 27288 . Total input tokens: 6016089 . Total output tokens: 5465738
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.16440710099414,
    "estimated_duration": 3598.9990966695727,
    "input_throughput": 628.6325556718297,
    "output_throughput": 558.3785786052681,
    "total_throughput": 1187.0111342770979,
    "itl": 19.935732585703924,
    "ttft": 7487.4115673899,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4341,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.979808330171398,
    "arrivals": 9201,
    "finished_requests": 9182,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1644981228746474. Arrivals time: 0.03619903512299061 Scheduler time: 0.7150646620430052 Scheduler overhead time: 0.14756385888904333 Adapter cache time: 0.046230117324739695 Engine time: 0.14635673258453608 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_64_slots_16_rate_0.1-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_64_slots_16_rate_0.1-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 1080, 1080, 33, 1080, 33, 135, 33, 1080, 135, 1080, 33, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 1080, 33, 33, 33, 1080, 135, 33, 1080, 1080, 1080, 1080, 135, 135, 135, 1080, 33, 135, 135, 1080, 1080, 135, 1080, 33, 1080, 135, 135, 135, 1080, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 1080, 135]
Prompts retrieved: 27288 . Total input tokens: 6016089 . Total output tokens: 5465738
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.1644851667806506,
    "estimated_duration": 3599.009496367706,
    "input_throughput": 628.6768629767549,
    "output_throughput": 558.4486515049348,
    "total_throughput": 1187.1255144816896,
    "itl": 19.945748053248515,
    "ttft": 7096.415446883527,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4347,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.533988042733572,
    "arrivals": 9201,
    "finished_requests": 9183,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1647331551648676. Arrivals time: 0.03596487594768405 Scheduler time: 0.71777169033885 Scheduler overhead time: 0.14546027360484004 Adapter cache time: 0.04612873028963804 Engine time: 0.14684166060760617 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_64_slots_16_rate_0.1-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_64_slots_16_rate_0.1-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 1080, 1080, 33, 1080, 33, 66, 33, 1080, 66, 1080, 33, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 1080, 33, 33, 33, 1080, 66, 33, 1080, 1080, 1080, 1080, 66, 66, 66, 1080, 33, 66, 66, 1080, 1080, 66, 1080, 33, 1080, 66, 66, 66, 1080, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 1080, 66]
Prompts retrieved: 25839 . Total input tokens: 5688973 . Total output tokens: 5166475
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.129213725682348,
    "estimated_duration": 3599.82251845847,
    "input_throughput": 596.7185851484311,
    "output_throughput": 526.5054013861838,
    "total_throughput": 1123.223986534615,
    "itl": 19.73820491688651,
    "ttft": 5794.966747010875,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3542,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.84024758900933,
    "arrivals": 8753,
    "finished_requests": 8739,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1292790789157152. Arrivals time: 0.034741862677037716 Scheduler time: 0.679870008956641 Scheduler overhead time: 0.14919100841507316 Adapter cache time: 0.04371117381379008 Engine time: 0.14832580275833607 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_64_slots_16_rate_0.1-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_64_slots_16_rate_0.1-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 1080, 1080, 33, 1080, 33, 66, 33, 1080, 66, 1080, 33, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 1080, 33, 33, 33, 1080, 66, 33, 1080, 1080, 1080, 1080, 66, 66, 66, 1080, 33, 66, 66, 1080, 1080, 66, 1080, 33, 1080, 66, 66, 66, 1080, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 1080, 66]
Prompts retrieved: 25839 . Total input tokens: 5688973 . Total output tokens: 5166475
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.1136834300123155,
    "estimated_duration": 3599.817506477748,
    "input_throughput": 596.719415952226,
    "output_throughput": 526.5061344330445,
    "total_throughput": 1123.2255503852705,
    "itl": 19.742652104097793,
    "ttft": 5795.0469742398245,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3545,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.525196691695905,
    "arrivals": 8753,
    "finished_requests": 8739,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1137579521164298. Arrivals time: 0.0345032406039536 Scheduler time: 0.6681594350375235 Scheduler overhead time: 0.14711011853069067 Adapter cache time: 0.04393054032698274 Engine time: 0.1467218603938818 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_64_slots_16_rate_0.1-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_64_slots_16_rate_0.1-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 1080, 1080, 33, 1080, 33, 66, 33, 1080, 66, 1080, 33, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 1080, 33, 33, 33, 1080, 66, 33, 1080, 1080, 1080, 1080, 66, 66, 66, 1080, 33, 66, 66, 1080, 1080, 66, 1080, 33, 1080, 66, 66, 66, 1080, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 1080, 66]
Prompts retrieved: 25839 . Total input tokens: 5688973 . Total output tokens: 5166475
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.1267363498918712,
    "estimated_duration": 3599.8233733404495,
    "input_throughput": 596.718443440377,
    "output_throughput": 526.5052763522772,
    "total_throughput": 1123.223719792654,
    "itl": 19.742995375811784,
    "ttft": 5795.104497148631,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3543,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.546715608797298,
    "arrivals": 8753,
    "finished_requests": 8739,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1268310290761292. Arrivals time: 0.03517327876761556 Scheduler time: 0.6766596687957644 Scheduler overhead time: 0.14663012325763702 Adapter cache time: 0.0443171919323504 Engine time: 0.15027944138273597 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_64_slots_16_rate_0.1-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_64_slots_16_rate_0.1-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 1080, 1080, 33, 1080, 33, 66, 33, 1080, 66, 1080, 33, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 1080, 33, 33, 33, 1080, 66, 33, 1080, 1080, 1080, 1080, 66, 66, 66, 1080, 33, 66, 66, 1080, 1080, 66, 1080, 33, 1080, 66, 66, 66, 1080, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 1080, 66]
Prompts retrieved: 25839 . Total input tokens: 5688973 . Total output tokens: 5166475
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 1.1263706241734326,
    "estimated_duration": 3599.814699482989,
    "input_throughput": 596.7198812506963,
    "output_throughput": 526.506544981943,
    "total_throughput": 1123.2264262326394,
    "itl": 19.740080985246795,
    "ttft": 5795.0001457229355,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3542,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.143587610393656,
    "arrivals": 8753,
    "finished_requests": 8739,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.126449470873922. Arrivals time: 0.03458068426698446 Scheduler time: 0.6790595264174044 Scheduler overhead time: 0.14721348881721497 Adapter cache time: 0.04419977776706219 Engine time: 0.148150488268584 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_64_slots_16_rate_0.1-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_64_slots_16_rate_0.1-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 1080, 1080, 33, 1080, 33, 66, 33, 1080, 66, 1080, 33, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 1080, 33, 33, 33, 1080, 66, 33, 1080, 1080, 1080, 1080, 66, 66, 66, 1080, 33, 66, 66, 1080, 1080, 66, 1080, 33, 1080, 66, 66, 66, 1080, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 1080, 66]
Prompts retrieved: 25839 . Total input tokens: 5688973 . Total output tokens: 5166475
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 1.1133660129271448,
    "estimated_duration": 3599.815287523502,
    "input_throughput": 596.7197837747324,
    "output_throughput": 526.506458975536,
    "total_throughput": 1123.2262427502683,
    "itl": 19.743927250063035,
    "ttft": 5795.02078839897,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3543,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.660814306940201,
    "arrivals": 8753,
    "finished_requests": 8739,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1135143809951842. Arrivals time: 0.03457334218546748 Scheduler time: 0.6685487660579383 Scheduler overhead time: 0.14693372650071979 Adapter cache time: 0.04369623027741909 Engine time: 0.14609453594312072 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_64_slots_16_rate_0.1-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_64_slots_16_rate_0.1-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 1080, 1080, 33, 1080, 33, 66, 33, 1080, 66, 1080, 33, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 1080, 33, 33, 33, 1080, 66, 33, 1080, 1080, 1080, 1080, 66, 66, 66, 1080, 33, 66, 66, 1080, 1080, 66, 1080, 33, 1080, 66, 66, 66, 1080, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 1080, 66]
Prompts retrieved: 25839 . Total input tokens: 5688973 . Total output tokens: 5166475
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.1106018689461052,
    "estimated_duration": 3599.820200048102,
    "input_throughput": 596.7189694561125,
    "output_throughput": 526.5057404741143,
    "total_throughput": 1123.2247099302267,
    "itl": 19.736636392486037,
    "ttft": 5794.915654192142,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3542,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.590758144543935,
    "arrivals": 8753,
    "finished_requests": 8739,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.110691698268056. Arrivals time: 0.03438803181052208 Scheduler time: 0.6662754556164145 Scheduler overhead time: 0.1475130980834365 Adapter cache time: 0.043841772712767124 Engine time: 0.14593626139685512 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_64_slots_16_rate_0.1-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_64_slots_16_rate_0.1-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 1080, 1080, 33, 1080, 33, 66, 33, 1080, 66, 1080, 33, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 1080, 33, 33, 33, 1080, 66, 33, 1080, 1080, 1080, 1080, 66, 66, 66, 1080, 33, 66, 66, 1080, 1080, 66, 1080, 33, 1080, 66, 66, 66, 1080, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 1080, 66]
Prompts retrieved: 25839 . Total input tokens: 5688973 . Total output tokens: 5166475
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.1243995730765164,
    "estimated_duration": 3599.8227002349727,
    "input_throughput": 596.7185550165533,
    "output_throughput": 526.5053747997882,
    "total_throughput": 1123.2239298163415,
    "itl": 19.745281920024226,
    "ttft": 5795.057375707055,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3544,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.834465700089204,
    "arrivals": 8753,
    "finished_requests": 8739,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1244897791184485. Arrivals time: 0.034573227632790804 Scheduler time: 0.6773013076744974 Scheduler overhead time: 0.1478896103799343 Adapter cache time: 0.04430930595844984 Engine time: 0.14638557936996222 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_64_slots_16_rate_0.05-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_64_slots_16_rate_0.05-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 540, 540, 135, 540, 135, 270, 135, 540, 270, 540, 135, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 540, 135, 135, 135, 540, 270, 135, 540, 540, 540, 540, 270, 270, 270, 540, 135, 270, 270, 540, 540, 270, 540, 135, 540, 270, 270, 270, 540, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 540, 270]
Prompts retrieved: 20385 . Total input tokens: 4475713 . Total output tokens: 4106726
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.012740665115416,
    "estimated_duration": 3599.7383149880516,
    "input_throughput": 470.5053122745179,
    "output_throughput": 415.3310238622061,
    "total_throughput": 885.836336136724,
    "itl": 19.5428727466277,
    "ttft": 5274.688460830707,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4748,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.531195808191288,
    "arrivals": 6874,
    "finished_requests": 6864,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0127999791875482. Arrivals time: 0.030609040521085262 Scheduler time: 0.5658815489150584 Scheduler overhead time: 0.14664559997618198 Adapter cache time: 0.04576503671705723 Engine time: 0.15012533264234662 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_64_slots_16_rate_0.05-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_64_slots_16_rate_0.05-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 540, 540, 135, 540, 135, 270, 135, 540, 270, 540, 135, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 540, 135, 135, 135, 540, 270, 135, 540, 540, 540, 540, 270, 270, 270, 540, 135, 270, 270, 540, 540, 270, 540, 135, 540, 270, 270, 270, 540, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 540, 270]
Prompts retrieved: 20385 . Total input tokens: 4475713 . Total output tokens: 4106726
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.0089312572963536,
    "estimated_duration": 3599.745762522916,
    "input_throughput": 470.5043388433513,
    "output_throughput": 415.3301645814445,
    "total_throughput": 885.8345034247958,
    "itl": 19.548379156726373,
    "ttft": 5274.802243700283,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4745,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.460563066253517,
    "arrivals": 6874,
    "finished_requests": 6864,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.009001700207591. Arrivals time: 0.03072967752814293 Scheduler time: 0.562752771191299 Scheduler overhead time: 0.14672494353726506 Adapter cache time: 0.0453971759416163 Engine time: 0.14933746634051204 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_64_slots_16_rate_0.05-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_64_slots_16_rate_0.05-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 540, 540, 135, 540, 135, 270, 135, 540, 270, 540, 135, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 540, 135, 135, 135, 540, 270, 135, 540, 540, 540, 540, 270, 270, 270, 540, 135, 270, 270, 540, 540, 270, 540, 135, 540, 270, 270, 270, 540, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 540, 270]
Prompts retrieved: 20385 . Total input tokens: 4475713 . Total output tokens: 4106726
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.0036165029741824,
    "estimated_duration": 3599.731219999822,
    "input_throughput": 470.5062396297699,
    "output_throughput": 415.33184247019256,
    "total_throughput": 885.8380820999624,
    "itl": 19.548558093756437,
    "ttft": 5274.84290731927,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4746,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.495066401714968,
    "arrivals": 6874,
    "finished_requests": 6864,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0036890199407935. Arrivals time: 0.030673456378281116 Scheduler time: 0.559052815195173 Scheduler overhead time: 0.14702675072476268 Adapter cache time: 0.04513807874172926 Engine time: 0.1483395816758275 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_64_slots_16_rate_0.05-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_64_slots_16_rate_0.05-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 540, 540, 135, 540, 135, 270, 135, 540, 270, 540, 135, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 540, 135, 135, 135, 540, 270, 135, 540, 540, 540, 540, 270, 270, 270, 540, 135, 270, 270, 540, 540, 270, 540, 135, 540, 270, 270, 270, 540, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 540, 270]
Prompts retrieved: 20385 . Total input tokens: 4475713 . Total output tokens: 4106726
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 1.0121247950010002,
    "estimated_duration": 3599.7384782542636,
    "input_throughput": 470.50529093473983,
    "output_throughput": 415.33100502485905,
    "total_throughput": 885.8362959595989,
    "itl": 19.543960998990684,
    "ttft": 5274.865908894104,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4745,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.823562964805213,
    "arrivals": 6874,
    "finished_requests": 6864,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0121825998649001. Arrivals time: 0.030620628036558628 Scheduler time: 0.5636877701617777 Scheduler overhead time: 0.14929197682067752 Adapter cache time: 0.04550212295725942 Engine time: 0.14873785804957151 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_64_slots_16_rate_0.05-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_64_slots_16_rate_0.05-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 540, 540, 135, 540, 135, 270, 135, 540, 270, 540, 135, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 540, 135, 135, 135, 540, 270, 135, 540, 540, 540, 540, 270, 270, 270, 540, 135, 270, 270, 540, 540, 270, 540, 135, 540, 270, 270, 270, 540, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 540, 270]
Prompts retrieved: 20385 . Total input tokens: 4475713 . Total output tokens: 4106726
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 1.0157282310537994,
    "estimated_duration": 3599.7312444759655,
    "input_throughput": 470.5062364305926,
    "output_throughput": 415.33183964617007,
    "total_throughput": 885.8380760767627,
    "itl": 19.551484324060162,
    "ttft": 5274.920170519272,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4746,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.690865047163022,
    "arrivals": 6874,
    "finished_requests": 6864,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0158184617757797. Arrivals time: 0.031168693210929632 Scheduler time: 0.5675926953554153 Scheduler overhead time: 0.1468057413585484 Adapter cache time: 0.04579483484849334 Engine time: 0.1501681013032794 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_64_slots_16_rate_0.05-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_64_slots_16_rate_0.05-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 540, 540, 135, 540, 135, 270, 135, 540, 270, 540, 135, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 540, 135, 135, 135, 540, 270, 135, 540, 540, 540, 540, 270, 270, 270, 540, 135, 270, 270, 540, 540, 270, 540, 135, 540, 270, 270, 270, 540, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 540, 270]
Prompts retrieved: 20385 . Total input tokens: 4475713 . Total output tokens: 4106726
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.003422910347581,
    "estimated_duration": 3599.734269579819,
    "input_throughput": 470.5058410318986,
    "output_throughput": 415.3314906143098,
    "total_throughput": 885.8373316462084,
    "itl": 19.540657910415046,
    "ttft": 5274.737373888918,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4748,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.196758800196902,
    "arrivals": 6874,
    "finished_requests": 6864,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.003496234305203. Arrivals time: 0.03014488099142909 Scheduler time: 0.557613919954747 Scheduler overhead time: 0.14744969457387924 Adapter cache time: 0.04541611624881625 Engine time: 0.14845694741234183 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_64_slots_16_rate_0.05-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_64_slots_16_rate_0.05-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 540, 540, 135, 540, 135, 270, 135, 540, 270, 540, 135, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 540, 135, 135, 135, 540, 270, 135, 540, 540, 540, 540, 270, 270, 270, 540, 135, 270, 270, 540, 540, 270, 540, 135, 540, 270, 270, 270, 540, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 540, 270]
Prompts retrieved: 20385 . Total input tokens: 4475713 . Total output tokens: 4106726
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.0024327361024916,
    "estimated_duration": 3599.728774921678,
    "input_throughput": 470.5065592162151,
    "output_throughput": 415.33212458000526,
    "total_throughput": 885.8386837962204,
    "itl": 19.55122190882527,
    "ttft": 5274.910392790503,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4746,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.886789446397492,
    "arrivals": 6874,
    "finished_requests": 6864,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0025113713927567. Arrivals time: 0.030530895572155714 Scheduler time: 0.5569393890909851 Scheduler overhead time: 0.14726229012012482 Adapter cache time: 0.045194986276328564 Engine time: 0.14894338743761182 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_64_slots_16_rate_0.05-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_64_slots_16_rate_0.05-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 540, 540, 66, 540, 66, 270, 66, 540, 270, 540, 66, 270, 540, 540, 540, 66, 540, 270, 270, 66, 66, 66, 540, 66, 66, 66, 540, 270, 66, 540, 540, 540, 540, 270, 270, 270, 540, 66, 270, 270, 540, 540, 270, 540, 66, 540, 270, 270, 270, 540, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 540, 270]
Prompts retrieved: 18936 . Total input tokens: 4146856 . Total output tokens: 3813691
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.974744759965688,
    "estimated_duration": 3599.619594842187,
    "input_throughput": 437.7748699495805,
    "output_throughput": 389.0222183495456,
    "total_throughput": 826.797088299126,
    "itl": 19.187606355381263,
    "ttft": 3407.0404150139248,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4170,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.762233892198608,
    "arrivals": 6405,
    "finished_requests": 6399,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9750005598179996. Arrivals time: 0.029908696189522743 Scheduler time: 0.5288186543621123 Scheduler overhead time: 0.15041981358081102 Adapter cache time: 0.043380267918109894 Engine time: 0.14785620430484414 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_64_slots_16_rate_0.05-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_64_slots_16_rate_0.05-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 540, 540, 66, 540, 66, 270, 66, 540, 270, 540, 66, 270, 540, 540, 540, 66, 540, 270, 270, 66, 66, 66, 540, 66, 66, 66, 540, 270, 66, 540, 540, 540, 540, 270, 270, 270, 540, 66, 270, 270, 540, 540, 270, 540, 66, 540, 270, 270, 270, 540, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 540, 270]
Prompts retrieved: 18936 . Total input tokens: 4146856 . Total output tokens: 3813691
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.9838557583279908,
    "estimated_duration": 3599.621503898995,
    "input_throughput": 437.774637775977,
    "output_throughput": 389.0220120318776,
    "total_throughput": 826.7966498078546,
    "itl": 19.192250919384115,
    "ttft": 3407.092364566989,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4169,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.58874820984035,
    "arrivals": 6405,
    "finished_requests": 6399,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9839191962964833. Arrivals time: 0.02976445062085986 Scheduler time: 0.5364260482601821 Scheduler overhead time: 0.14897097134962678 Adapter cache time: 0.04410056257620454 Engine time: 0.1501534916460514 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_64_slots_16_rate_0.05-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_64_slots_16_rate_0.05-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 540, 540, 66, 540, 66, 270, 66, 540, 270, 540, 66, 270, 540, 540, 540, 66, 540, 270, 270, 66, 66, 66, 540, 66, 66, 66, 540, 270, 66, 540, 540, 540, 540, 270, 270, 270, 540, 66, 270, 270, 540, 540, 270, 540, 66, 540, 270, 270, 270, 540, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 540, 270]
Prompts retrieved: 18936 . Total input tokens: 4146856 . Total output tokens: 3813691
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.9733691210858524,
    "estimated_duration": 3599.627285848898,
    "input_throughput": 437.77393459455755,
    "output_throughput": 389.0213871600211,
    "total_throughput": 826.7953217545786,
    "itl": 19.19216863365037,
    "ttft": 3407.1283489426582,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4169,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.61552344297887,
    "arrivals": 6405,
    "finished_requests": 6399,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9735882808454335. Arrivals time: 0.029590888414531946 Scheduler time: 0.5301626189611852 Scheduler overhead time: 0.14768268028274179 Adapter cache time: 0.04350614454597235 Engine time: 0.14832004951313138 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_64_slots_16_rate_0.05-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_64_slots_16_rate_0.05-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 540, 540, 66, 540, 66, 270, 66, 540, 270, 540, 66, 270, 540, 540, 540, 66, 540, 270, 270, 66, 66, 66, 540, 66, 66, 66, 540, 270, 66, 540, 540, 540, 540, 270, 270, 270, 540, 66, 270, 270, 540, 540, 270, 540, 66, 540, 270, 270, 270, 540, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 540, 270]
Prompts retrieved: 18936 . Total input tokens: 4146856 . Total output tokens: 3813691
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 0.9701789189130068,
    "estimated_duration": 3599.625753296984,
    "input_throughput": 437.7741209781783,
    "output_throughput": 389.02155278709245,
    "total_throughput": 826.7956737652707,
    "itl": 19.18807184020489,
    "ttft": 3406.949406965462,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4167,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.008691686841994,
    "arrivals": 6405,
    "finished_requests": 6399,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9702372318133712. Arrivals time: 0.029059266205877066 Scheduler time: 0.5258345911279321 Scheduler overhead time: 0.14944912726059556 Adapter cache time: 0.04356529610231519 Engine time: 0.14807631075382233 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_64_slots_16_rate_0.05-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_64_slots_16_rate_0.05-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 540, 540, 66, 540, 66, 270, 66, 540, 270, 540, 66, 270, 540, 540, 540, 66, 540, 270, 270, 66, 66, 66, 540, 66, 66, 66, 540, 270, 66, 540, 540, 540, 540, 270, 270, 270, 540, 66, 270, 270, 540, 540, 270, 540, 66, 540, 270, 270, 270, 540, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 540, 270]
Prompts retrieved: 18936 . Total input tokens: 4146856 . Total output tokens: 3813691
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 0.9790757927112281,
    "estimated_duration": 3599.6216102424482,
    "input_throughput": 437.77462484282125,
    "output_throughput": 389.0220005390184,
    "total_throughput": 826.7966253818397,
    "itl": 19.193898347909634,
    "ttft": 3407.2913907894253,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4170,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.795251031740522,
    "arrivals": 6405,
    "finished_requests": 6399,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.979164354968816. Arrivals time: 0.02930569928139448 Scheduler time: 0.5342909996397793 Scheduler overhead time: 0.149019131436944 Adapter cache time: 0.04351144516840577 Engine time: 0.1486802427098155 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_64_slots_16_rate_0.05-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_64_slots_16_rate_0.05-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 540, 540, 66, 540, 66, 270, 66, 540, 270, 540, 66, 270, 540, 540, 540, 66, 540, 270, 270, 66, 66, 66, 540, 66, 66, 66, 540, 270, 66, 540, 540, 540, 540, 270, 270, 270, 540, 66, 270, 270, 540, 540, 270, 540, 66, 540, 270, 270, 270, 540, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 540, 270]
Prompts retrieved: 18936 . Total input tokens: 4146856 . Total output tokens: 3813691
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.9883833792991936,
    "estimated_duration": 3599.6319887702393,
    "input_throughput": 437.77336264265074,
    "output_throughput": 389.0208789033466,
    "total_throughput": 826.7942415459974,
    "itl": 19.183229294006946,
    "ttft": 3406.958883163935,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4171,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.471499780037895,
    "arrivals": 6405,
    "finished_requests": 6399,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9884487641975284. Arrivals time: 0.02950819581747055 Scheduler time: 0.536792523227632 Scheduler overhead time: 0.15382177801802754 Adapter cache time: 0.04394212691113353 Engine time: 0.14962171064689755 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_64_slots_16_rate_0.05-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_64_slots_16_rate_0.05-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 540, 540, 66, 540, 66, 270, 66, 540, 270, 540, 66, 270, 540, 540, 540, 66, 540, 270, 270, 66, 66, 66, 540, 66, 66, 66, 540, 270, 66, 540, 540, 540, 540, 270, 270, 270, 540, 66, 270, 270, 540, 540, 270, 540, 66, 540, 270, 270, 270, 540, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 540, 270]
Prompts retrieved: 18936 . Total input tokens: 4146856 . Total output tokens: 3813691
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.9822120200842619,
    "estimated_duration": 3599.6362963670686,
    "input_throughput": 437.7728387699609,
    "output_throughput": 389.0204133715633,
    "total_throughput": 826.7932521415241,
    "itl": 19.19535840301445,
    "ttft": 3407.3511711141173,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4169,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.960757600552409,
    "arrivals": 6405,
    "finished_requests": 6399,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9823022382333875. Arrivals time: 0.0295833395794034 Scheduler time: 0.5345101137645543 Scheduler overhead time: 0.14824592974036932 Adapter cache time: 0.04328931123018265 Engine time: 0.15204112464562058 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_64_slots_16_rate_0.05-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_64_slots_16_rate_0.05-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 540, 540, 33, 540, 33, 270, 33, 540, 270, 540, 33, 270, 540, 540, 540, 33, 540, 270, 270, 33, 33, 33, 540, 33, 33, 33, 540, 270, 33, 540, 540, 540, 540, 270, 270, 270, 540, 33, 270, 270, 540, 540, 270, 540, 33, 540, 270, 270, 270, 540, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 540, 270]
Prompts retrieved: 18243 . Total input tokens: 3999459 . Total output tokens: 3674488
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.9659506883472204,
    "estimated_duration": 3597.8501964993175,
    "input_throughput": 414.68874981278924,
    "output_throughput": 380.4977765144313,
    "total_throughput": 795.1865263272205,
    "itl": 19.186216607397814,
    "ttft": 5310.929012256957,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3831,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.72472854700567,
    "arrivals": 6141,
    "finished_requests": 6132,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9660120620392263. Arrivals time: 0.02897481992840767 Scheduler time: 0.522863473277539 Scheduler overhead time: 0.14841478131711483 Adapter cache time: 0.042494773864746094 Engine time: 0.1487384084612131 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_64_slots_16_rate_0.05-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_64_slots_16_rate_0.05-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 540, 540, 33, 540, 33, 270, 33, 540, 270, 540, 33, 270, 540, 540, 540, 33, 540, 270, 270, 33, 33, 33, 540, 33, 33, 33, 540, 270, 33, 540, 540, 540, 540, 270, 270, 270, 540, 33, 270, 270, 540, 540, 270, 540, 33, 540, 270, 270, 270, 540, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 540, 270]
Prompts retrieved: 18243 . Total input tokens: 3999459 . Total output tokens: 3674488
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.9701218190602958,
    "estimated_duration": 3597.8465751798476,
    "input_throughput": 414.6891672070311,
    "output_throughput": 380.4981594946328,
    "total_throughput": 795.1873267016639,
    "itl": 19.19326811316668,
    "ttft": 5311.294542004988,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3831,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.482908500966616,
    "arrivals": 6141,
    "finished_requests": 6132,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9702031440101564. Arrivals time: 0.028460083529353142 Scheduler time: 0.5216020760126412 Scheduler overhead time: 0.14728393126279116 Adapter cache time: 0.04265667172148824 Engine time: 0.1557335969991982 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-32/adapters_64_slots_16_rate_0.05-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-32/adapters_64_slots_16_rate_0.05-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 540, 540, 33, 540, 33, 270, 33, 540, 270, 540, 33, 270, 540, 540, 540, 33, 540, 270, 270, 33, 33, 33, 540, 33, 33, 33, 540, 270, 33, 540, 540, 540, 540, 270, 270, 270, 540, 33, 270, 270, 540, 540, 270, 540, 33, 540, 270, 270, 270, 540, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 540, 270]
Prompts retrieved: 18243 . Total input tokens: 3999459 . Total output tokens: 3674488
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.9687669677659869,
    "estimated_duration": 3597.838323598835,
    "input_throughput": 414.6901182895842,
    "output_throughput": 380.4990321606911,
    "total_throughput": 795.1891504502753,
    "itl": 19.19104313696807,
    "ttft": 5311.176038910964,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3831,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.508235405868966,
    "arrivals": 6141,
    "finished_requests": 6132,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9689214685931802. Arrivals time: 0.028959215618669987 Scheduler time: 0.5227202754467726 Scheduler overhead time: 0.14810989145189524 Adapter cache time: 0.04308941215276718 Engine time: 0.15086976252496243 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_64_slots_16_rate_0.05-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_64_slots_16_rate_0.05-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 540, 540, 33, 540, 33, 270, 33, 540, 270, 540, 33, 270, 540, 540, 540, 33, 540, 270, 270, 33, 33, 33, 540, 33, 33, 33, 540, 270, 33, 540, 540, 540, 540, 270, 270, 270, 540, 33, 270, 270, 540, 540, 270, 540, 33, 540, 270, 270, 270, 540, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 540, 270]
Prompts retrieved: 18243 . Total input tokens: 3999459 . Total output tokens: 3674488
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 0.9662628620862961,
    "estimated_duration": 3597.8389303375907,
    "input_throughput": 414.69004835633496,
    "output_throughput": 380.49896799341906,
    "total_throughput": 795.1890163497541,
    "itl": 19.187379645195488,
    "ttft": 5311.0813699724895,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3830,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.94874453669937,
    "arrivals": 6141,
    "finished_requests": 6132,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9663596339523792. Arrivals time: 0.029110371600836515 Scheduler time: 0.5224625645205379 Scheduler overhead time: 0.14832259574905038 Adapter cache time: 0.04270752565935254 Engine time: 0.14932600082829595 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-32/adapters_64_slots_16_rate_0.05-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-32/adapters_64_slots_16_rate_0.05-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 540, 540, 33, 540, 33, 270, 33, 540, 270, 540, 33, 270, 540, 540, 540, 33, 540, 270, 270, 33, 33, 33, 540, 33, 33, 33, 540, 270, 33, 540, 540, 540, 540, 270, 270, 270, 540, 33, 270, 270, 540, 540, 270, 540, 33, 540, 270, 270, 270, 540, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 540, 270]
Prompts retrieved: 18243 . Total input tokens: 3999459 . Total output tokens: 3674488
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 0.9693750338628888,
    "estimated_duration": 3597.831178751505,
    "input_throughput": 414.6909418128228,
    "output_throughput": 380.49978778466533,
    "total_throughput": 795.1907295974881,
    "itl": 19.192454276342776,
    "ttft": 5311.0747873869705,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3829,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.664702287948813,
    "arrivals": 6141,
    "finished_requests": 6132,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9694374850951135. Arrivals time: 0.029339457862079144 Scheduler time: 0.5247883787378669 Scheduler overhead time: 0.1478387974202633 Adapter cache time: 0.04284444684162736 Engine time: 0.149992308113724 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_64_slots_16_rate_0.05-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_64_slots_16_rate_0.05-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 540, 540, 33, 540, 33, 270, 33, 540, 270, 540, 33, 270, 540, 540, 540, 33, 540, 270, 270, 33, 33, 33, 540, 33, 33, 33, 540, 270, 33, 540, 540, 540, 540, 270, 270, 270, 540, 33, 270, 270, 540, 540, 270, 540, 33, 540, 270, 270, 270, 540, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 540, 270]
Prompts retrieved: 18243 . Total input tokens: 3999459 . Total output tokens: 3674488
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.9709476842544973,
    "estimated_duration": 3597.835655886016,
    "input_throughput": 414.69042577281857,
    "output_throughput": 380.49931429201746,
    "total_throughput": 795.1897400648361,
    "itl": 19.185379006174966,
    "ttft": 5310.986011206795,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3832,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.457872730065793,
    "arrivals": 6141,
    "finished_requests": 6132,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.971019544173032. Arrivals time: 0.028761596884578466 Scheduler time: 0.527249017264694 Scheduler overhead time: 0.14871401013806462 Adapter cache time: 0.04262483771890402 Engine time: 0.14891934487968683 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-32/adapters_64_slots_16_rate_0.05-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-32/adapters_64_slots_16_rate_0.05-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 540, 540, 33, 540, 33, 270, 33, 540, 270, 540, 33, 270, 540, 540, 540, 33, 540, 270, 270, 33, 33, 33, 540, 33, 33, 33, 540, 270, 33, 540, 540, 540, 540, 270, 270, 270, 540, 33, 270, 270, 540, 540, 270, 540, 33, 540, 270, 270, 270, 540, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 540, 270]
Prompts retrieved: 18243 . Total input tokens: 3999459 . Total output tokens: 3674488
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.9704964463599026,
    "estimated_duration": 3597.846525086398,
    "input_throughput": 414.6891729808213,
    "output_throughput": 380.4981647923756,
    "total_throughput": 795.1873377731969,
    "itl": 19.194846087096348,
    "ttft": 5311.289871839575,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3832,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.827675451337475,
    "arrivals": 6141,
    "finished_requests": 6132,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9705713791772723. Arrivals time: 0.028830510564148426 Scheduler time: 0.5261273705400527 Scheduler overhead time: 0.14753204444423318 Adapter cache time: 0.042721137404441833 Engine time: 0.15108079742640257 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_64_slots_16_rate_0.05-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_64_slots_16_rate_0.05-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 540, 540, 66, 540, 66, 135, 66, 540, 135, 540, 66, 135, 540, 540, 540, 66, 540, 135, 135, 66, 66, 66, 540, 66, 66, 66, 540, 135, 66, 540, 540, 540, 540, 135, 135, 135, 540, 66, 135, 135, 540, 540, 135, 540, 66, 540, 135, 135, 135, 540, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 540, 135]
Prompts retrieved: 16101 . Total input tokens: 3531683 . Total output tokens: 3251275
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.9219533610157669,
    "estimated_duration": 3599.893340127127,
    "input_throughput": 358.7917413004208,
    "output_throughput": 327.6563743853439,
    "total_throughput": 686.4481156857647,
    "itl": 18.898371020751544,
    "ttft": 4016.5559181118365,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3263,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.98637150845231,
    "arrivals": 5423,
    "finished_requests": 5417,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9222403462044895. Arrivals time: 0.02770909294486046 Scheduler time: 0.47046528942883015 Scheduler overhead time: 0.1494207321666181 Adapter cache time: 0.04085493879392743 Engine time: 0.15816881181672215 
