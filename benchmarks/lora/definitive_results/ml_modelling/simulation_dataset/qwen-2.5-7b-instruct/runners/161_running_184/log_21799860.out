INFO 06-01 00:47:15 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:47:15 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-8/adapters_256_slots_256_rate_1.6-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-8/adapters_256_slots_256_rate_1.6-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 66, 17280, 17280, 66, 17280, 540, 17280, 66, 540, 66, 17280, 540, 540, 540, 540, 17280, 66, 66, 66, 540, 17280, 66, 17280, 17280, 540, 540, 540, 66, 17280, 66, 540, 540, 66, 540, 66, 66, 540, 540, 17280, 540, 66, 540, 17280, 540, 540, 17280, 540, 17280, 66, 17280, 17280, 540, 66, 66, 17280, 540, 66, 540, 540, 17280, 540, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 17280, 17280, 66, 17280, 66, 540, 17280, 17280, 17280, 540, 66, 17280, 540, 66, 66, 66, 66, 66, 17280, 540, 66, 17280, 66, 17280, 66, 66, 540, 540, 17280, 540, 17280, 66, 540, 66, 17280, 17280, 66, 17280, 540, 66, 17280, 66, 66, 17280, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 66, 540, 17280, 17280, 66, 17280, 540, 66, 540, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 540, 17280, 17280, 540, 66, 17280, 66, 540, 540, 66, 540, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 540, 17280, 540, 17280, 66, 17280, 66, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 540, 540, 66, 540, 17280, 540, 540, 17280, 66, 17280, 17280, 540, 66, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 66, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 17280, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 17280, 540, 66, 66, 66, 66]
Prompts retrieved: 1537590 . Total input tokens: 342761459 . Total output tokens: 307388398
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.346959691029042,
    "estimated_duration": 3600.15066389706,
    "input_throughput": 5054.307916186779,
    "output_throughput": 4429.450733802947,
    "total_throughput": 9483.758649989726,
    "itl": 193.09938805336589,
    "ttft": 2061209.1870325785,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 255,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7804243747028512,
    "arrivals": 512803,
    "finished_requests": 73237,
    "scheduler_time": 44.922552267403056
}
#Debug simulation 
Total elapsed time: 5.347077629063278. Arrivals time: 0.2655296614393592 Scheduler time: 4.962632047943771 Scheduler overhead time: 0.02907031774520874 Adapter cache time: 0.04569281544536352 Engine time: 0.03050210326910019 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-16/adapters_256_slots_256_rate_1.6-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-16/adapters_256_slots_256_rate_1.6-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 66, 17280, 17280, 66, 17280, 540, 17280, 66, 540, 66, 17280, 540, 540, 540, 540, 17280, 66, 66, 66, 540, 17280, 66, 17280, 17280, 540, 540, 540, 66, 17280, 66, 540, 540, 66, 540, 66, 66, 540, 540, 17280, 540, 66, 540, 17280, 540, 540, 17280, 540, 17280, 66, 17280, 17280, 540, 66, 66, 17280, 540, 66, 540, 540, 17280, 540, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 17280, 17280, 66, 17280, 66, 540, 17280, 17280, 17280, 540, 66, 17280, 540, 66, 66, 66, 66, 66, 17280, 540, 66, 17280, 66, 17280, 66, 66, 540, 540, 17280, 540, 17280, 66, 540, 66, 17280, 17280, 66, 17280, 540, 66, 17280, 66, 66, 17280, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 66, 540, 17280, 17280, 66, 17280, 540, 66, 540, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 540, 17280, 17280, 540, 66, 17280, 66, 540, 540, 66, 540, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 540, 17280, 540, 17280, 66, 17280, 66, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 540, 540, 66, 540, 17280, 540, 540, 17280, 66, 17280, 17280, 540, 66, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 66, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 17280, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 17280, 540, 66, 66, 66, 66]
Prompts retrieved: 1537590 . Total input tokens: 342761459 . Total output tokens: 307388398
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.322053016163409,
    "estimated_duration": 3600.0403186714043,
    "input_throughput": 4961.751930209538,
    "output_throughput": 4352.686807069695,
    "total_throughput": 9314.438737279232,
    "itl": 161.25233921981467,
    "ttft": 2074400.467110182,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 253,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8251267381082326,
    "arrivals": 512803,
    "finished_requests": 71895,
    "scheduler_time": 39.626477305386054
}
#Debug simulation 
Total elapsed time: 5.322164725046605. Arrivals time: 0.2392894788645208 Scheduler time: 4.945263382047415 Scheduler overhead time: 0.03439141809940338 Adapter cache time: 0.05168149108067155 Engine time: 0.035518170334398746 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-16/adapters_256_slots_256_rate_1.6-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-16/adapters_256_slots_256_rate_1.6-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 66, 17280, 17280, 66, 17280, 540, 17280, 66, 540, 66, 17280, 540, 540, 540, 540, 17280, 66, 66, 66, 540, 17280, 66, 17280, 17280, 540, 540, 540, 66, 17280, 66, 540, 540, 66, 540, 66, 66, 540, 540, 17280, 540, 66, 540, 17280, 540, 540, 17280, 540, 17280, 66, 17280, 17280, 540, 66, 66, 17280, 540, 66, 540, 540, 17280, 540, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 17280, 17280, 66, 17280, 66, 540, 17280, 17280, 17280, 540, 66, 17280, 540, 66, 66, 66, 66, 66, 17280, 540, 66, 17280, 66, 17280, 66, 66, 540, 540, 17280, 540, 17280, 66, 540, 66, 17280, 17280, 66, 17280, 540, 66, 17280, 66, 66, 17280, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 66, 540, 17280, 17280, 66, 17280, 540, 66, 540, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 540, 17280, 17280, 540, 66, 17280, 66, 540, 540, 66, 540, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 540, 17280, 540, 17280, 66, 17280, 66, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 540, 540, 66, 540, 17280, 540, 540, 17280, 66, 17280, 17280, 540, 66, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 66, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 17280, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 17280, 540, 66, 66, 66, 66]
Prompts retrieved: 1537590 . Total input tokens: 342761459 . Total output tokens: 307388398
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.312800488900393,
    "estimated_duration": 3600.1402307019,
    "input_throughput": 4961.6689504668,
    "output_throughput": 4352.612119485385,
    "total_throughput": 9314.281069952185,
    "itl": 161.25478632680864,
    "ttft": 2074374.4726500995,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 253,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7912133266776822,
    "arrivals": 512803,
    "finished_requests": 71897,
    "scheduler_time": 39.62909407053145
}
#Debug simulation 
Total elapsed time: 5.3128968281671405. Arrivals time: 0.23826589388772845 Scheduler time: 4.937755902297795 Scheduler overhead time: 0.03414881508797407 Adapter cache time: 0.051729494240134954 Engine time: 0.035010932479053736 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-16/adapters_256_slots_256_rate_1.6-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-16/adapters_256_slots_256_rate_1.6-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 66, 17280, 17280, 66, 17280, 540, 17280, 66, 540, 66, 17280, 540, 540, 540, 540, 17280, 66, 66, 66, 540, 17280, 66, 17280, 17280, 540, 540, 540, 66, 17280, 66, 540, 540, 66, 540, 66, 66, 540, 540, 17280, 540, 66, 540, 17280, 540, 540, 17280, 540, 17280, 66, 17280, 17280, 540, 66, 66, 17280, 540, 66, 540, 540, 17280, 540, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 17280, 17280, 66, 17280, 66, 540, 17280, 17280, 17280, 540, 66, 17280, 540, 66, 66, 66, 66, 66, 17280, 540, 66, 17280, 66, 17280, 66, 66, 540, 540, 17280, 540, 17280, 66, 540, 66, 17280, 17280, 66, 17280, 540, 66, 17280, 66, 66, 17280, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 66, 540, 17280, 17280, 66, 17280, 540, 66, 540, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 540, 17280, 17280, 540, 66, 17280, 66, 540, 540, 66, 540, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 540, 17280, 540, 17280, 66, 17280, 66, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 540, 540, 66, 540, 17280, 540, 540, 17280, 66, 17280, 17280, 540, 66, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 66, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 17280, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 17280, 540, 66, 66, 66, 66]
Prompts retrieved: 1537590 . Total input tokens: 342761459 . Total output tokens: 307388398
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.275126122869551,
    "estimated_duration": 3600.095291798132,
    "input_throughput": 4961.644776652094,
    "output_throughput": 4352.595620371331,
    "total_throughput": 9314.240397023426,
    "itl": 161.2444699828581,
    "ttft": 2074366.1812670499,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 253,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7564827246102515,
    "arrivals": 512803,
    "finished_requests": 71896,
    "scheduler_time": 39.62727019817154
}
#Debug simulation 
Total elapsed time: 5.275226044934243. Arrivals time: 0.24169310834258795 Scheduler time: 4.896591620054096 Scheduler overhead time: 0.03421404026448727 Adapter cache time: 0.05139999510720372 Engine time: 0.035322803538292646 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-8/adapters_256_slots_256_rate_1.6-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-8/adapters_256_slots_256_rate_1.6-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 33, 17280, 17280, 33, 17280, 540, 17280, 33, 540, 33, 17280, 540, 540, 540, 540, 17280, 33, 33, 33, 540, 17280, 33, 17280, 17280, 540, 540, 540, 33, 17280, 33, 540, 540, 33, 540, 33, 33, 540, 540, 17280, 540, 33, 540, 17280, 540, 540, 17280, 540, 17280, 33, 17280, 17280, 540, 33, 33, 17280, 540, 33, 540, 540, 17280, 540, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 17280, 17280, 33, 17280, 33, 540, 17280, 17280, 17280, 540, 33, 17280, 540, 33, 33, 33, 33, 33, 17280, 540, 33, 17280, 33, 17280, 33, 33, 540, 540, 17280, 540, 17280, 33, 540, 33, 17280, 17280, 33, 17280, 540, 33, 17280, 33, 33, 17280, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 33, 540, 17280, 17280, 33, 17280, 540, 33, 540, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 540, 17280, 17280, 540, 33, 17280, 33, 540, 540, 33, 540, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 540, 17280, 540, 17280, 33, 17280, 33, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 540, 540, 33, 540, 17280, 540, 540, 17280, 33, 17280, 17280, 540, 33, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 33, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 17280, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 17280, 540, 33, 33, 33, 33]
Prompts retrieved: 1534785 . Total input tokens: 342133886 . Total output tokens: 306836984
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.399122097995132,
    "estimated_duration": 3600.222269281806,
    "input_throughput": 5014.597335847671,
    "output_throughput": 4445.9038367075655,
    "total_throughput": 9460.501172555238,
    "itl": 193.25977314753308,
    "ttft": 2058089.7707635649,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 247,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7559404727513892,
    "arrivals": 511802,
    "finished_requests": 73168,
    "scheduler_time": 45.23831104256364
}
#Debug simulation 
Total elapsed time: 5.399218872655183. Arrivals time: 0.24833491863682866 Scheduler time: 5.036875396966934 Scheduler overhead time: 0.029236968606710434 Adapter cache time: 0.040866025257855654 Engine time: 0.030292504001408815 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-16/adapters_256_slots_256_rate_1.6-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-16/adapters_256_slots_256_rate_1.6-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 33, 17280, 17280, 33, 17280, 540, 17280, 33, 540, 33, 17280, 540, 540, 540, 540, 17280, 33, 33, 33, 540, 17280, 33, 17280, 17280, 540, 540, 540, 33, 17280, 33, 540, 540, 33, 540, 33, 33, 540, 540, 17280, 540, 33, 540, 17280, 540, 540, 17280, 540, 17280, 33, 17280, 17280, 540, 33, 33, 17280, 540, 33, 540, 540, 17280, 540, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 17280, 17280, 33, 17280, 33, 540, 17280, 17280, 17280, 540, 33, 17280, 540, 33, 33, 33, 33, 33, 17280, 540, 33, 17280, 33, 17280, 33, 33, 540, 540, 17280, 540, 17280, 33, 540, 33, 17280, 17280, 33, 17280, 540, 33, 17280, 33, 33, 17280, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 33, 540, 17280, 17280, 33, 17280, 540, 33, 540, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 540, 17280, 17280, 540, 33, 17280, 33, 540, 540, 33, 540, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 540, 17280, 540, 17280, 33, 17280, 33, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 540, 540, 33, 540, 17280, 540, 540, 17280, 33, 17280, 17280, 540, 33, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 33, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 17280, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 17280, 540, 33, 33, 33, 33]
Prompts retrieved: 1534785 . Total input tokens: 342133886 . Total output tokens: 306836984
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.268717926926911,
    "estimated_duration": 3600.093645500738,
    "input_throughput": 4908.803697949911,
    "output_throughput": 4361.267385258849,
    "total_throughput": 9270.071083208759,
    "itl": 157.47052814496604,
    "ttft": 2071499.896558588,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 247,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8059606503834981,
    "arrivals": 511802,
    "finished_requests": 71604,
    "scheduler_time": 39.08103888994613
}
#Debug simulation 
Total elapsed time: 5.268815614283085. Arrivals time: 0.26433561416342854 Scheduler time: 4.871966396458447 Scheduler overhead time: 0.03496960178017616 Adapter cache time: 0.04542638687416911 Engine time: 0.035838913172483444 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-16/adapters_256_slots_256_rate_1.6-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-16/adapters_256_slots_256_rate_1.6-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 33, 17280, 17280, 33, 17280, 540, 17280, 33, 540, 33, 17280, 540, 540, 540, 540, 17280, 33, 33, 33, 540, 17280, 33, 17280, 17280, 540, 540, 540, 33, 17280, 33, 540, 540, 33, 540, 33, 33, 540, 540, 17280, 540, 33, 540, 17280, 540, 540, 17280, 540, 17280, 33, 17280, 17280, 540, 33, 33, 17280, 540, 33, 540, 540, 17280, 540, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 17280, 17280, 33, 17280, 33, 540, 17280, 17280, 17280, 540, 33, 17280, 540, 33, 33, 33, 33, 33, 17280, 540, 33, 17280, 33, 17280, 33, 33, 540, 540, 17280, 540, 17280, 33, 540, 33, 17280, 17280, 33, 17280, 540, 33, 17280, 33, 33, 17280, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 33, 540, 17280, 17280, 33, 17280, 540, 33, 540, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 540, 17280, 17280, 540, 33, 17280, 33, 540, 540, 33, 540, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 540, 17280, 540, 17280, 33, 17280, 33, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 540, 540, 33, 540, 17280, 540, 540, 17280, 33, 17280, 17280, 540, 33, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 33, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 17280, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 17280, 540, 33, 33, 33, 33]
Prompts retrieved: 1534785 . Total input tokens: 342133886 . Total output tokens: 306836984
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.452411903068423,
    "estimated_duration": 3600.0663810894803,
    "input_throughput": 4920.055667040144,
    "output_throughput": 4369.919977764149,
    "total_throughput": 9289.975644804292,
    "itl": 160.00584811900086,
    "ttft": 2073151.8845034842,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 247,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7728644295898286,
    "arrivals": 511802,
    "finished_requests": 71772,
    "scheduler_time": 39.67938161550274
}
#Debug simulation 
Total elapsed time: 5.452513040043414. Arrivals time: 0.23916767071932554 Scheduler time: 5.081989417318255 Scheduler overhead time: 0.0343246441334486 Adapter cache time: 0.04556855279952288 Engine time: 0.03538789600133896 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-16/adapters_256_slots_256_rate_1.6-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-16/adapters_256_slots_256_rate_1.6-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 33, 17280, 17280, 33, 17280, 540, 17280, 33, 540, 33, 17280, 540, 540, 540, 540, 17280, 33, 33, 33, 540, 17280, 33, 17280, 17280, 540, 540, 540, 33, 17280, 33, 540, 540, 33, 540, 33, 33, 540, 540, 17280, 540, 33, 540, 17280, 540, 540, 17280, 540, 17280, 33, 17280, 17280, 540, 33, 33, 17280, 540, 33, 540, 540, 17280, 540, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 17280, 17280, 33, 17280, 33, 540, 17280, 17280, 17280, 540, 33, 17280, 540, 33, 33, 33, 33, 33, 17280, 540, 33, 17280, 33, 17280, 33, 33, 540, 540, 17280, 540, 17280, 33, 540, 33, 17280, 17280, 33, 17280, 540, 33, 17280, 33, 33, 17280, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 33, 540, 17280, 17280, 33, 17280, 540, 33, 540, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 540, 17280, 17280, 540, 33, 17280, 33, 540, 540, 33, 540, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 540, 17280, 540, 17280, 33, 17280, 33, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 540, 540, 33, 540, 17280, 540, 540, 17280, 33, 17280, 17280, 540, 33, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 33, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 17280, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 17280, 540, 33, 33, 33, 33]
Prompts retrieved: 1534785 . Total input tokens: 342133886 . Total output tokens: 306836984
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.336659226100892,
    "estimated_duration": 3600.1627479088843,
    "input_throughput": 4920.213679309008,
    "output_throughput": 4369.935222827924,
    "total_throughput": 9290.14890213693,
    "itl": 160.01663091115418,
    "ttft": 2073142.3672363616,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 247,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7385424228408384,
    "arrivals": 511802,
    "finished_requests": 71775,
    "scheduler_time": 39.68177261823629
}
#Debug simulation 
Total elapsed time: 5.336755995173007. Arrivals time: 0.2422140510752797 Scheduler time: 4.962702439632267 Scheduler overhead time: 0.03460892289876938 Adapter cache time: 0.045339752454310656 Engine time: 0.035715196281671524 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-8/adapters_256_slots_256_rate_1.6-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-8/adapters_256_slots_256_rate_1.6-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 135, 17280, 17280, 135, 17280, 270, 17280, 135, 270, 135, 17280, 270, 270, 270, 270, 17280, 135, 135, 135, 270, 17280, 135, 17280, 17280, 270, 270, 270, 135, 17280, 135, 270, 270, 135, 270, 135, 135, 270, 270, 17280, 270, 135, 270, 17280, 270, 270, 17280, 270, 17280, 135, 17280, 17280, 270, 135, 135, 17280, 270, 135, 270, 270, 17280, 270, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 17280, 17280, 135, 17280, 135, 270, 17280, 17280, 17280, 270, 135, 17280, 270, 135, 135, 135, 135, 135, 17280, 270, 135, 17280, 135, 17280, 135, 135, 270, 270, 17280, 270, 17280, 135, 270, 135, 17280, 17280, 135, 17280, 270, 135, 17280, 135, 135, 17280, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 135, 270, 17280, 17280, 135, 17280, 270, 135, 270, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 270, 17280, 17280, 270, 135, 17280, 135, 270, 270, 135, 270, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 270, 17280, 270, 135, 270, 17280, 270, 17280, 135, 17280, 135, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 135, 17280, 135, 17280, 270, 270, 135, 270, 17280, 270, 270, 17280, 135, 17280, 17280, 270, 135, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 135, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 17280, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 17280, 270, 135, 135, 135, 135]
Prompts retrieved: 1520505 . Total input tokens: 338953303 . Total output tokens: 303979113
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.473402147181332,
    "estimated_duration": 3600.1660822031445,
    "input_throughput": 5218.860900023284,
    "output_throughput": 4596.659326858859,
    "total_throughput": 9815.520226882141,
    "itl": 186.69927039480538,
    "ttft": 2033818.7574481983,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.783484862446784,
    "arrivals": 507065,
    "finished_requests": 76100,
    "scheduler_time": 46.68937608943236
}
#Debug simulation 
Total elapsed time: 5.473527884110808. Arrivals time: 0.25607723370194435 Scheduler time: 5.101985351648182 Scheduler overhead time: 0.030015465337783098 Adapter cache time: 0.03994845226407051 Engine time: 0.03147558541968465 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-16/adapters_256_slots_256_rate_1.6-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-16/adapters_256_slots_256_rate_1.6-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 135, 17280, 17280, 135, 17280, 270, 17280, 135, 270, 135, 17280, 270, 270, 270, 270, 17280, 135, 135, 135, 270, 17280, 135, 17280, 17280, 270, 270, 270, 135, 17280, 135, 270, 270, 135, 270, 135, 135, 270, 270, 17280, 270, 135, 270, 17280, 270, 270, 17280, 270, 17280, 135, 17280, 17280, 270, 135, 135, 17280, 270, 135, 270, 270, 17280, 270, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 17280, 17280, 135, 17280, 135, 270, 17280, 17280, 17280, 270, 135, 17280, 270, 135, 135, 135, 135, 135, 17280, 270, 135, 17280, 135, 17280, 135, 135, 270, 270, 17280, 270, 17280, 135, 270, 135, 17280, 17280, 135, 17280, 270, 135, 17280, 135, 135, 17280, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 135, 270, 17280, 17280, 135, 17280, 270, 135, 270, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 270, 17280, 17280, 270, 135, 17280, 135, 270, 270, 135, 270, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 270, 17280, 270, 135, 270, 17280, 270, 17280, 135, 17280, 135, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 135, 17280, 135, 17280, 270, 270, 135, 270, 17280, 270, 270, 17280, 135, 17280, 17280, 270, 135, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 135, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 17280, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 17280, 270, 135, 135, 135, 135]
Prompts retrieved: 1520505 . Total input tokens: 338953303 . Total output tokens: 303979113
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.56468773027882,
    "estimated_duration": 3600.062949663925,
    "input_throughput": 5104.2163031386435,
    "output_throughput": 4503.4090310874935,
    "total_throughput": 9607.625334226137,
    "itl": 157.00046534089648,
    "ttft": 2048792.0009459825,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8353226749482605,
    "arrivals": 507065,
    "finished_requests": 74413,
    "scheduler_time": 41.22135290825148
}
#Debug simulation 
Total elapsed time: 5.564785420894623. Arrivals time: 0.24811807787045836 Scheduler time: 5.185734609607607 Scheduler overhead time: 0.03507075272500515 Adapter cache time: 0.043040208518505096 Engine time: 0.03641253104433417 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-16/adapters_256_slots_256_rate_1.6-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-16/adapters_256_slots_256_rate_1.6-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 135, 17280, 17280, 135, 17280, 270, 17280, 135, 270, 135, 17280, 270, 270, 270, 270, 17280, 135, 135, 135, 270, 17280, 135, 17280, 17280, 270, 270, 270, 135, 17280, 135, 270, 270, 135, 270, 135, 135, 270, 270, 17280, 270, 135, 270, 17280, 270, 270, 17280, 270, 17280, 135, 17280, 17280, 270, 135, 135, 17280, 270, 135, 270, 270, 17280, 270, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 17280, 17280, 135, 17280, 135, 270, 17280, 17280, 17280, 270, 135, 17280, 270, 135, 135, 135, 135, 135, 17280, 270, 135, 17280, 135, 17280, 135, 135, 270, 270, 17280, 270, 17280, 135, 270, 135, 17280, 17280, 135, 17280, 270, 135, 17280, 135, 135, 17280, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 135, 270, 17280, 17280, 135, 17280, 270, 135, 270, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 270, 17280, 17280, 270, 135, 17280, 135, 270, 270, 135, 270, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 270, 17280, 270, 135, 270, 17280, 270, 17280, 135, 17280, 135, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 135, 17280, 135, 17280, 270, 270, 135, 270, 17280, 270, 270, 17280, 135, 17280, 17280, 270, 135, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 135, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 17280, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 17280, 270, 135, 135, 135, 135]
Prompts retrieved: 1520505 . Total input tokens: 338953303 . Total output tokens: 303979113
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.479721590876579,
    "estimated_duration": 3600.0198519066116,
    "input_throughput": 5104.277408433769,
    "output_throughput": 4503.462943798392,
    "total_throughput": 9607.74035223216,
    "itl": 157.00839300128956,
    "ttft": 2048775.8374089831,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.800592072880829,
    "arrivals": 507065,
    "finished_requests": 74413,
    "scheduler_time": 41.222701688555226
}
#Debug simulation 
Total elapsed time: 5.479817816987634. Arrivals time: 0.2768137068487704 Scheduler time: 5.072214346844703 Scheduler overhead time: 0.03515919344499707 Adapter cache time: 0.04309564828872681 Engine time: 0.03612559475004673 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-16/adapters_256_slots_256_rate_1.6-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-16/adapters_256_slots_256_rate_1.6-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 135, 17280, 17280, 135, 17280, 270, 17280, 135, 270, 135, 17280, 270, 270, 270, 270, 17280, 135, 135, 135, 270, 17280, 135, 17280, 17280, 270, 270, 270, 135, 17280, 135, 270, 270, 135, 270, 135, 135, 270, 270, 17280, 270, 135, 270, 17280, 270, 270, 17280, 270, 17280, 135, 17280, 17280, 270, 135, 135, 17280, 270, 135, 270, 270, 17280, 270, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 17280, 17280, 135, 17280, 135, 270, 17280, 17280, 17280, 270, 135, 17280, 270, 135, 135, 135, 135, 135, 17280, 270, 135, 17280, 135, 17280, 135, 135, 270, 270, 17280, 270, 17280, 135, 270, 135, 17280, 17280, 135, 17280, 270, 135, 17280, 135, 135, 17280, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 135, 270, 17280, 17280, 135, 17280, 270, 135, 270, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 270, 17280, 17280, 270, 135, 17280, 135, 270, 270, 135, 270, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 270, 17280, 270, 135, 270, 17280, 270, 17280, 135, 17280, 135, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 135, 17280, 135, 17280, 270, 270, 135, 270, 17280, 270, 270, 17280, 135, 17280, 17280, 270, 135, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 135, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 17280, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 17280, 270, 135, 135, 135, 135]
Prompts retrieved: 1520505 . Total input tokens: 338953303 . Total output tokens: 303979113
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.434579359833151,
    "estimated_duration": 3600.1498573078807,
    "input_throughput": 5104.509181110018,
    "output_throughput": 4503.468367320652,
    "total_throughput": 9607.97754843067,
    "itl": 157.00149321246877,
    "ttft": 2048810.4952261138,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.765452875494958,
    "arrivals": 507065,
    "finished_requests": 74415,
    "scheduler_time": 41.22387363994582
}
#Debug simulation 
Total elapsed time: 5.434703995939344. Arrivals time: 0.24430986447259784 Scheduler time: 5.0607267753221095 Scheduler overhead time: 0.0351855643093586 Adapter cache time: 0.04181089950725436 Engine time: 0.03624175302684307 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-8/adapters_256_slots_256_rate_1.6-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-8/adapters_256_slots_256_rate_1.6-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 66, 17280, 17280, 66, 17280, 270, 17280, 66, 270, 66, 17280, 270, 270, 270, 270, 17280, 66, 66, 66, 270, 17280, 66, 17280, 17280, 270, 270, 270, 66, 17280, 66, 270, 270, 66, 270, 66, 66, 270, 270, 17280, 270, 66, 270, 17280, 270, 270, 17280, 270, 17280, 66, 17280, 17280, 270, 66, 66, 17280, 270, 66, 270, 270, 17280, 270, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 17280, 17280, 66, 17280, 66, 270, 17280, 17280, 17280, 270, 66, 17280, 270, 66, 66, 66, 66, 66, 17280, 270, 66, 17280, 66, 17280, 66, 66, 270, 270, 17280, 270, 17280, 66, 270, 66, 17280, 17280, 66, 17280, 270, 66, 17280, 66, 66, 17280, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 66, 270, 17280, 17280, 66, 17280, 270, 66, 270, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 270, 17280, 17280, 270, 66, 17280, 66, 270, 270, 66, 270, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 270, 17280, 270, 66, 270, 17280, 270, 17280, 66, 17280, 66, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 66, 17280, 66, 17280, 270, 270, 66, 270, 17280, 270, 270, 17280, 66, 17280, 17280, 270, 66, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 66, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 17280, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 17280, 270, 66, 66, 66, 66]
Prompts retrieved: 1514640 . Total input tokens: 337655110 . Total output tokens: 302796901
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.598237641621381,
    "estimated_duration": 3600.045610964711,
    "input_throughput": 5313.114351035786,
    "output_throughput": 4655.453516742759,
    "total_throughput": 9968.567867778545,
    "itl": 183.62950180960397,
    "ttft": 2029331.895501864,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 254,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7773638869589184,
    "arrivals": 505172,
    "finished_requests": 76978,
    "scheduler_time": 47.20512626988315
}
#Debug simulation 
Total elapsed time: 5.598335704766214. Arrivals time: 0.3011182602494955 Scheduler time: 5.1866071545518935 Scheduler overhead time: 0.03052016068249941 Adapter cache time: 0.03423653868958354 Engine time: 0.03156233439221978 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-16/adapters_256_slots_256_rate_1.6-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-16/adapters_256_slots_256_rate_1.6-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 66, 17280, 17280, 66, 17280, 270, 17280, 66, 270, 66, 17280, 270, 270, 270, 270, 17280, 66, 66, 66, 270, 17280, 66, 17280, 17280, 270, 270, 270, 66, 17280, 66, 270, 270, 66, 270, 66, 66, 270, 270, 17280, 270, 66, 270, 17280, 270, 270, 17280, 270, 17280, 66, 17280, 17280, 270, 66, 66, 17280, 270, 66, 270, 270, 17280, 270, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 17280, 17280, 66, 17280, 66, 270, 17280, 17280, 17280, 270, 66, 17280, 270, 66, 66, 66, 66, 66, 17280, 270, 66, 17280, 66, 17280, 66, 66, 270, 270, 17280, 270, 17280, 66, 270, 66, 17280, 17280, 66, 17280, 270, 66, 17280, 66, 66, 17280, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 66, 270, 17280, 17280, 66, 17280, 270, 66, 270, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 270, 17280, 17280, 270, 66, 17280, 66, 270, 270, 66, 270, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 270, 17280, 270, 66, 270, 17280, 270, 17280, 66, 17280, 66, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 66, 17280, 66, 17280, 270, 270, 66, 270, 17280, 270, 270, 17280, 66, 17280, 17280, 270, 66, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 66, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 17280, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 17280, 270, 66, 66, 66, 66]
Prompts retrieved: 1514640 . Total input tokens: 337655110 . Total output tokens: 302796901
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.576251708902419,
    "estimated_duration": 3600.0319079736228,
    "input_throughput": 5179.681313018136,
    "output_throughput": 4542.184463360542,
    "total_throughput": 9721.86577637868,
    "itl": 153.66818428708487,
    "ttft": 2045133.8731572132,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 254,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8289339790400154,
    "arrivals": 505172,
    "finished_requests": 75050,
    "scheduler_time": 41.26459507265312
}
#Debug simulation 
Total elapsed time: 5.576349560171366. Arrivals time: 0.30347889568656683 Scheduler time: 5.146076800767332 Scheduler overhead time: 0.03602364053949714 Adapter cache time: 0.03705013403669 Engine time: 0.03692500712350011 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-16/adapters_256_slots_256_rate_1.6-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-16/adapters_256_slots_256_rate_1.6-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 66, 17280, 17280, 66, 17280, 270, 17280, 66, 270, 66, 17280, 270, 270, 270, 270, 17280, 66, 66, 66, 270, 17280, 66, 17280, 17280, 270, 270, 270, 66, 17280, 66, 270, 270, 66, 270, 66, 66, 270, 270, 17280, 270, 66, 270, 17280, 270, 270, 17280, 270, 17280, 66, 17280, 17280, 270, 66, 66, 17280, 270, 66, 270, 270, 17280, 270, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 17280, 17280, 66, 17280, 66, 270, 17280, 17280, 17280, 270, 66, 17280, 270, 66, 66, 66, 66, 66, 17280, 270, 66, 17280, 66, 17280, 66, 66, 270, 270, 17280, 270, 17280, 66, 270, 66, 17280, 17280, 66, 17280, 270, 66, 17280, 66, 66, 17280, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 66, 270, 17280, 17280, 66, 17280, 270, 66, 270, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 270, 17280, 17280, 270, 66, 17280, 66, 270, 270, 66, 270, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 270, 17280, 270, 66, 270, 17280, 270, 17280, 66, 17280, 66, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 66, 17280, 66, 17280, 270, 270, 66, 270, 17280, 270, 270, 17280, 66, 17280, 17280, 270, 66, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 66, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 17280, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 17280, 270, 66, 66, 66, 66]
Prompts retrieved: 1514640 . Total input tokens: 337655110 . Total output tokens: 302796901
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.679089543875307,
    "estimated_duration": 3600.1305607621425,
    "input_throughput": 5179.820477414085,
    "output_throughput": 4542.25054452974,
    "total_throughput": 9722.071021943826,
    "itl": 153.66230366326494,
    "ttft": 2045140.4319142366,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 254,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7946119722910251,
    "arrivals": 505172,
    "finished_requests": 75052,
    "scheduler_time": 41.264852359012615
}
#Debug simulation 
Total elapsed time: 5.679211290087551. Arrivals time: 0.2508176569826901 Scheduler time: 5.301917896140367 Scheduler overhead time: 0.03624262614175677 Adapter cache time: 0.03635859163478017 Engine time: 0.03699499135836959 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-16/adapters_256_slots_256_rate_1.6-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-16/adapters_256_slots_256_rate_1.6-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 66, 17280, 17280, 66, 17280, 270, 17280, 66, 270, 66, 17280, 270, 270, 270, 270, 17280, 66, 66, 66, 270, 17280, 66, 17280, 17280, 270, 270, 270, 66, 17280, 66, 270, 270, 66, 270, 66, 66, 270, 270, 17280, 270, 66, 270, 17280, 270, 270, 17280, 270, 17280, 66, 17280, 17280, 270, 66, 66, 17280, 270, 66, 270, 270, 17280, 270, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 17280, 17280, 66, 17280, 66, 270, 17280, 17280, 17280, 270, 66, 17280, 270, 66, 66, 66, 66, 66, 17280, 270, 66, 17280, 66, 17280, 66, 66, 270, 270, 17280, 270, 17280, 66, 270, 66, 17280, 17280, 66, 17280, 270, 66, 17280, 66, 66, 17280, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 66, 270, 17280, 17280, 66, 17280, 270, 66, 270, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 270, 17280, 17280, 270, 66, 17280, 66, 270, 270, 66, 270, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 270, 17280, 270, 66, 270, 17280, 270, 17280, 66, 17280, 66, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 66, 17280, 66, 17280, 270, 270, 66, 270, 17280, 270, 270, 17280, 66, 17280, 17280, 270, 66, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 66, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 17280, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 17280, 270, 66, 66, 66, 66]
Prompts retrieved: 1514640 . Total input tokens: 337655110 . Total output tokens: 302796901
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.527829410042614,
    "estimated_duration": 3600.152036594699,
    "input_throughput": 5179.601530839265,
    "output_throughput": 4542.147618706509,
    "total_throughput": 9721.749149545774,
    "itl": 153.6585741726016,
    "ttft": 2045118.3290173586,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 254,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7594727749051536,
    "arrivals": 505172,
    "finished_requests": 75051,
    "scheduler_time": 41.26493728491461
}
#Debug simulation 
Total elapsed time: 5.52792780008167. Arrivals time: 0.2962854471988976 Scheduler time: 5.105451944749802 Scheduler overhead time: 0.035847654566168785 Adapter cache time: 0.036604543682187796 Engine time: 0.03699462069198489 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-8/adapters_256_slots_256_rate_1.6-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-8/adapters_256_slots_256_rate_1.6-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 33, 17280, 17280, 33, 17280, 270, 17280, 33, 270, 33, 17280, 270, 270, 270, 270, 17280, 33, 33, 33, 270, 17280, 33, 17280, 17280, 270, 270, 270, 33, 17280, 33, 270, 270, 33, 270, 33, 33, 270, 270, 17280, 270, 33, 270, 17280, 270, 270, 17280, 270, 17280, 33, 17280, 17280, 270, 33, 33, 17280, 270, 33, 270, 270, 17280, 270, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 17280, 17280, 33, 17280, 33, 270, 17280, 17280, 17280, 270, 33, 17280, 270, 33, 33, 33, 33, 33, 17280, 270, 33, 17280, 33, 17280, 33, 33, 270, 270, 17280, 270, 17280, 33, 270, 33, 17280, 17280, 33, 17280, 270, 33, 17280, 33, 33, 17280, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 33, 270, 17280, 17280, 33, 17280, 270, 33, 270, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 270, 17280, 17280, 270, 33, 17280, 33, 270, 270, 33, 270, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 270, 17280, 270, 33, 270, 17280, 270, 17280, 33, 17280, 33, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 33, 17280, 33, 17280, 270, 270, 33, 270, 17280, 270, 270, 17280, 33, 17280, 17280, 270, 33, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 33, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 17280, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 17280, 270, 33, 33, 33, 33]
Prompts retrieved: 1511835 . Total input tokens: 337040131 . Total output tokens: 302236107
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.637855134904385,
    "estimated_duration": 3600.1265155826623,
    "input_throughput": 5328.313301482794,
    "output_throughput": 4690.558214248475,
    "total_throughput": 10018.871515731269,
    "itl": 182.81764969583344,
    "ttft": 2019553.0166532935,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 246,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7528799850074565,
    "arrivals": 504244,
    "finished_requests": 77679,
    "scheduler_time": 47.597151187471226
}
#Debug simulation 
Total elapsed time: 5.637954181060195. Arrivals time: 0.26213411847129464 Scheduler time: 5.267744332551956 Scheduler overhead time: 0.030893388204276562 Adapter cache time: 0.03103521838784218 Engine time: 0.03175994101911783 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-16/adapters_256_slots_256_rate_1.6-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-16/adapters_256_slots_256_rate_1.6-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 33, 17280, 17280, 33, 17280, 270, 17280, 33, 270, 33, 17280, 270, 270, 270, 270, 17280, 33, 33, 33, 270, 17280, 33, 17280, 17280, 270, 270, 270, 33, 17280, 33, 270, 270, 33, 270, 33, 33, 270, 270, 17280, 270, 33, 270, 17280, 270, 270, 17280, 270, 17280, 33, 17280, 17280, 270, 33, 33, 17280, 270, 33, 270, 270, 17280, 270, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 17280, 17280, 33, 17280, 33, 270, 17280, 17280, 17280, 270, 33, 17280, 270, 33, 33, 33, 33, 33, 17280, 270, 33, 17280, 33, 17280, 33, 33, 270, 270, 17280, 270, 17280, 33, 270, 33, 17280, 17280, 33, 17280, 270, 33, 17280, 33, 33, 17280, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 33, 270, 17280, 17280, 33, 17280, 270, 33, 270, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 270, 17280, 17280, 270, 33, 17280, 33, 270, 270, 33, 270, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 270, 17280, 270, 33, 270, 17280, 270, 17280, 33, 17280, 33, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 33, 17280, 33, 17280, 270, 270, 33, 270, 17280, 270, 270, 17280, 33, 17280, 17280, 270, 33, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 33, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 17280, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 17280, 270, 33, 33, 33, 33]
Prompts retrieved: 1511835 . Total input tokens: 337040131 . Total output tokens: 302236107
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.474378203973174,
    "estimated_duration": 3600.122054967569,
    "input_throughput": 5186.5722091936705,
    "output_throughput": 4568.395945716945,
    "total_throughput": 9754.968154910615,
    "itl": 153.26239617973235,
    "ttft": 2036686.8873131338,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 245,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7999805497936937,
    "arrivals": 504244,
    "finished_requests": 75581,
    "scheduler_time": 41.605242605724264
}
#Debug simulation 
Total elapsed time: 5.474478119052947. Arrivals time: 0.24755272408947349 Scheduler time: 5.103905868716538 Scheduler overhead time: 0.0358882169239223 Adapter cache time: 0.033380118664354086 Engine time: 0.03700027847662568 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-16/adapters_256_slots_256_rate_1.6-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-16/adapters_256_slots_256_rate_1.6-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 33, 17280, 17280, 33, 17280, 270, 17280, 33, 270, 33, 17280, 270, 270, 270, 270, 17280, 33, 33, 33, 270, 17280, 33, 17280, 17280, 270, 270, 270, 33, 17280, 33, 270, 270, 33, 270, 33, 33, 270, 270, 17280, 270, 33, 270, 17280, 270, 270, 17280, 270, 17280, 33, 17280, 17280, 270, 33, 33, 17280, 270, 33, 270, 270, 17280, 270, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 17280, 17280, 33, 17280, 33, 270, 17280, 17280, 17280, 270, 33, 17280, 270, 33, 33, 33, 33, 33, 17280, 270, 33, 17280, 33, 17280, 33, 33, 270, 270, 17280, 270, 17280, 33, 270, 33, 17280, 17280, 33, 17280, 270, 33, 17280, 33, 33, 17280, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 33, 270, 17280, 17280, 33, 17280, 270, 33, 270, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 270, 17280, 17280, 270, 33, 17280, 33, 270, 270, 33, 270, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 270, 17280, 270, 33, 270, 17280, 270, 17280, 33, 17280, 33, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 33, 17280, 33, 17280, 270, 270, 33, 270, 17280, 270, 270, 17280, 33, 17280, 17280, 270, 33, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 33, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 17280, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 17280, 270, 33, 33, 33, 33]
Prompts retrieved: 1511835 . Total input tokens: 337040131 . Total output tokens: 302236107
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.5143549451604486,
    "estimated_duration": 3600.0448488958064,
    "input_throughput": 5186.752327745911,
    "output_throughput": 4568.530029575754,
    "total_throughput": 9755.282357321665,
    "itl": 153.26084590270224,
    "ttft": 2036638.6041424389,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 245,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7660671383631434,
    "arrivals": 504244,
    "finished_requests": 75582,
    "scheduler_time": 41.603705824626026
}
#Debug simulation 
Total elapsed time: 5.514446712099016. Arrivals time: 0.25197812216356397 Scheduler time: 5.1382597126066685 Scheduler overhead time: 0.03598697762936354 Adapter cache time: 0.034445613622665405 Engine time: 0.03691513789817691 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-16/adapters_256_slots_256_rate_1.6-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-16/adapters_256_slots_256_rate_1.6-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 33, 17280, 17280, 33, 17280, 270, 17280, 33, 270, 33, 17280, 270, 270, 270, 270, 17280, 33, 33, 33, 270, 17280, 33, 17280, 17280, 270, 270, 270, 33, 17280, 33, 270, 270, 33, 270, 33, 33, 270, 270, 17280, 270, 33, 270, 17280, 270, 270, 17280, 270, 17280, 33, 17280, 17280, 270, 33, 33, 17280, 270, 33, 270, 270, 17280, 270, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 17280, 17280, 33, 17280, 33, 270, 17280, 17280, 17280, 270, 33, 17280, 270, 33, 33, 33, 33, 33, 17280, 270, 33, 17280, 33, 17280, 33, 33, 270, 270, 17280, 270, 17280, 33, 270, 33, 17280, 17280, 33, 17280, 270, 33, 17280, 33, 33, 17280, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 33, 270, 17280, 17280, 33, 17280, 270, 33, 270, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 270, 17280, 17280, 270, 33, 17280, 33, 270, 270, 33, 270, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 270, 17280, 270, 33, 270, 17280, 270, 17280, 33, 17280, 33, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 33, 17280, 33, 17280, 270, 270, 33, 270, 17280, 270, 270, 17280, 33, 17280, 17280, 270, 33, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 33, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 17280, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 17280, 270, 33, 33, 33, 33]
Prompts retrieved: 1511835 . Total input tokens: 337040131 . Total output tokens: 302236107
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.5605905735865235,
    "estimated_duration": 3600.123025658751,
    "input_throughput": 5186.909410292477,
    "output_throughput": 4568.8399765144895,
    "total_throughput": 9755.749386806967,
    "itl": 153.26690763206963,
    "ttft": 2036679.9797234107,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 245,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.732562322251034,
    "arrivals": 504244,
    "finished_requests": 75585,
    "scheduler_time": 41.60705615514777
}
#Debug simulation 
Total elapsed time: 5.560689891688526. Arrivals time: 0.25398725271224976 Scheduler time: 5.182065951172262 Scheduler overhead time: 0.036130912601947784 Adapter cache time: 0.034603726118803024 Engine time: 0.037092667538672686 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-8/adapters_256_slots_256_rate_1.6-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-8/adapters_256_slots_256_rate_1.6-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 17280, 66, 17280, 17280, 66, 17280, 135, 17280, 66, 135, 66, 17280, 135, 135, 135, 135, 17280, 66, 66, 66, 135, 17280, 66, 17280, 17280, 135, 135, 135, 66, 17280, 66, 135, 135, 66, 135, 66, 66, 135, 135, 17280, 135, 66, 135, 17280, 135, 135, 17280, 135, 17280, 66, 17280, 17280, 135, 66, 66, 17280, 135, 66, 135, 135, 17280, 135, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 17280, 17280, 66, 17280, 66, 135, 17280, 17280, 17280, 135, 66, 17280, 135, 66, 66, 66, 66, 66, 17280, 135, 66, 17280, 66, 17280, 66, 66, 135, 135, 17280, 135, 17280, 66, 135, 66, 17280, 17280, 66, 17280, 135, 66, 17280, 66, 66, 17280, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 66, 135, 17280, 17280, 66, 17280, 135, 66, 135, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 135, 17280, 17280, 135, 66, 17280, 66, 135, 135, 66, 135, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 135, 17280, 135, 66, 135, 17280, 135, 17280, 66, 17280, 66, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 135, 66, 17280, 66, 17280, 135, 135, 66, 135, 17280, 135, 135, 17280, 66, 17280, 17280, 135, 66, 17280, 17280, 135, 135, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 17280, 66, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 17280, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 17280, 135, 66, 66, 66, 66]
Prompts retrieved: 1503165 . Total input tokens: 335100538 . Total output tokens: 300507985
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.756528102327138,
    "estimated_duration": 3600.0988999821234,
    "input_throughput": 5387.020062170042,
    "output_throughput": 4779.432865048635,
    "total_throughput": 10166.452927218677,
    "itl": 180.49074327881576,
    "ttft": 2012231.4463084093,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 254,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7773638869589184,
    "arrivals": 501368,
    "finished_requests": 78612,
    "scheduler_time": 48.61838693127409
}
#Debug simulation 
Total elapsed time: 5.756652909331024. Arrivals time: 0.25782437762245536 Scheduler time: 5.394358380697668 Scheduler overhead time: 0.031130346469581127 Adapter cache time: 0.026597230695188046 Engine time: 0.03220668248832226 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-16/adapters_256_slots_256_rate_1.6-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-16/adapters_256_slots_256_rate_1.6-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 17280, 66, 17280, 17280, 66, 17280, 135, 17280, 66, 135, 66, 17280, 135, 135, 135, 135, 17280, 66, 66, 66, 135, 17280, 66, 17280, 17280, 135, 135, 135, 66, 17280, 66, 135, 135, 66, 135, 66, 66, 135, 135, 17280, 135, 66, 135, 17280, 135, 135, 17280, 135, 17280, 66, 17280, 17280, 135, 66, 66, 17280, 135, 66, 135, 135, 17280, 135, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 17280, 17280, 66, 17280, 66, 135, 17280, 17280, 17280, 135, 66, 17280, 135, 66, 66, 66, 66, 66, 17280, 135, 66, 17280, 66, 17280, 66, 66, 135, 135, 17280, 135, 17280, 66, 135, 66, 17280, 17280, 66, 17280, 135, 66, 17280, 66, 66, 17280, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 66, 135, 17280, 17280, 66, 17280, 135, 66, 135, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 135, 17280, 17280, 135, 66, 17280, 66, 135, 135, 66, 135, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 135, 17280, 135, 66, 135, 17280, 135, 17280, 66, 17280, 66, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 135, 66, 17280, 66, 17280, 135, 135, 66, 135, 17280, 135, 135, 17280, 66, 17280, 17280, 135, 66, 17280, 17280, 135, 135, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 17280, 66, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 17280, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 17280, 135, 66, 66, 66, 66]
Prompts retrieved: 1503165 . Total input tokens: 335100538 . Total output tokens: 300507985
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.700333991087973,
    "estimated_duration": 3600.023559026878,
    "input_throughput": 5230.580492392664,
    "output_throughput": 4649.723738064856,
    "total_throughput": 9880.30423045752,
    "itl": 151.73038205902637,
    "ttft": 2030774.9921633382,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 254,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8285253837215754,
    "arrivals": 501368,
    "finished_requests": 76366,
    "scheduler_time": 42.41370056533063
}
#Debug simulation 
Total elapsed time: 5.7004492320120335. Arrivals time: 0.31009971909224987 Scheduler time: 5.270632832311094 Scheduler overhead time: 0.03646075865253806 Adapter cache time: 0.028845184948295355 Engine time: 0.0374016473069787 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-16/adapters_256_slots_256_rate_1.6-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-16/adapters_256_slots_256_rate_1.6-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 17280, 66, 17280, 17280, 66, 17280, 135, 17280, 66, 135, 66, 17280, 135, 135, 135, 135, 17280, 66, 66, 66, 135, 17280, 66, 17280, 17280, 135, 135, 135, 66, 17280, 66, 135, 135, 66, 135, 66, 66, 135, 135, 17280, 135, 66, 135, 17280, 135, 135, 17280, 135, 17280, 66, 17280, 17280, 135, 66, 66, 17280, 135, 66, 135, 135, 17280, 135, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 17280, 17280, 66, 17280, 66, 135, 17280, 17280, 17280, 135, 66, 17280, 135, 66, 66, 66, 66, 66, 17280, 135, 66, 17280, 66, 17280, 66, 66, 135, 135, 17280, 135, 17280, 66, 135, 66, 17280, 17280, 66, 17280, 135, 66, 17280, 66, 66, 17280, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 66, 135, 17280, 17280, 66, 17280, 135, 66, 135, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 135, 17280, 17280, 135, 66, 17280, 66, 135, 135, 66, 135, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 135, 17280, 135, 66, 135, 17280, 135, 17280, 66, 17280, 66, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 135, 66, 17280, 66, 17280, 135, 135, 66, 135, 17280, 135, 135, 17280, 66, 17280, 17280, 135, 66, 17280, 17280, 135, 135, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 17280, 66, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 17280, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 17280, 135, 66, 66, 66, 66]
Prompts retrieved: 1503165 . Total input tokens: 335100538 . Total output tokens: 300507985
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.6893608323298395,
    "estimated_duration": 3600.0474823296986,
    "input_throughput": 5230.243237740606,
    "output_throughput": 4649.454786959691,
    "total_throughput": 9879.698024700298,
    "itl": 151.7316347011581,
    "ttft": 2030825.3082499043,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 254,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7937947816541443,
    "arrivals": 501368,
    "finished_requests": 76364,
    "scheduler_time": 42.41478415258415
}
#Debug simulation 
Total elapsed time: 5.6894620959647. Arrivals time: 0.3001133152283728 Scheduler time: 5.269373647402972 Scheduler overhead time: 0.036413528956472874 Adapter cache time: 0.028869807720184326 Engine time: 0.03759072441607714 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-16/adapters_256_slots_256_rate_1.6-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-16/adapters_256_slots_256_rate_1.6-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 17280, 66, 17280, 17280, 66, 17280, 135, 17280, 66, 135, 66, 17280, 135, 135, 135, 135, 17280, 66, 66, 66, 135, 17280, 66, 17280, 17280, 135, 135, 135, 66, 17280, 66, 135, 135, 66, 135, 66, 66, 135, 135, 17280, 135, 66, 135, 17280, 135, 135, 17280, 135, 17280, 66, 17280, 17280, 135, 66, 66, 17280, 135, 66, 135, 135, 17280, 135, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 17280, 17280, 66, 17280, 66, 135, 17280, 17280, 17280, 135, 66, 17280, 135, 66, 66, 66, 66, 66, 17280, 135, 66, 17280, 66, 17280, 66, 66, 135, 135, 17280, 135, 17280, 66, 135, 66, 17280, 17280, 66, 17280, 135, 66, 17280, 66, 66, 17280, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 66, 135, 17280, 17280, 66, 17280, 135, 66, 135, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 135, 17280, 17280, 135, 66, 17280, 66, 135, 135, 66, 135, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 135, 17280, 135, 66, 135, 17280, 135, 17280, 66, 17280, 66, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 135, 66, 17280, 66, 17280, 135, 135, 66, 135, 17280, 135, 135, 17280, 66, 17280, 17280, 135, 66, 17280, 17280, 135, 135, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 17280, 66, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 17280, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 17280, 135, 66, 66, 66, 66]
Prompts retrieved: 1503165 . Total input tokens: 335100538 . Total output tokens: 300507985
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.626104806084186,
    "estimated_duration": 3600.1221783885876,
    "input_throughput": 5230.793030593469,
    "output_throughput": 4649.9805202425205,
    "total_throughput": 9880.77355083599,
    "itl": 151.73003923793217,
    "ttft": 2030741.0047945005,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 254,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7594727749051536,
    "arrivals": 501368,
    "finished_requests": 76370,
    "scheduler_time": 42.41580148569338
}
#Debug simulation 
Total elapsed time: 5.626218854915351. Arrivals time: 0.25900912983343005 Scheduler time: 5.247938782442361 Scheduler overhead time: 0.03638833062723279 Adapter cache time: 0.02878293488174677 Engine time: 0.037055117543786764 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-8/adapters_256_slots_256_rate_1.6-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-8/adapters_256_slots_256_rate_1.6-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 17280, 33, 17280, 17280, 33, 17280, 135, 17280, 33, 135, 33, 17280, 135, 135, 135, 135, 17280, 33, 33, 33, 135, 17280, 33, 17280, 17280, 135, 135, 135, 33, 17280, 33, 135, 135, 33, 135, 33, 33, 135, 135, 17280, 135, 33, 135, 17280, 135, 135, 17280, 135, 17280, 33, 17280, 17280, 135, 33, 33, 17280, 135, 33, 135, 135, 17280, 135, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 17280, 17280, 33, 17280, 33, 135, 17280, 17280, 17280, 135, 33, 17280, 135, 33, 33, 33, 33, 33, 17280, 135, 33, 17280, 33, 17280, 33, 33, 135, 135, 17280, 135, 17280, 33, 135, 33, 17280, 17280, 33, 17280, 135, 33, 17280, 33, 33, 17280, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 33, 135, 17280, 17280, 33, 17280, 135, 33, 135, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 135, 17280, 17280, 135, 33, 17280, 33, 135, 135, 33, 135, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 135, 17280, 135, 33, 135, 17280, 135, 17280, 33, 17280, 33, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 135, 33, 17280, 33, 17280, 135, 135, 33, 135, 17280, 135, 135, 17280, 33, 17280, 17280, 135, 33, 17280, 17280, 135, 135, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 17280, 33, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 17280, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 17280, 135, 33, 33, 33, 33]
Prompts retrieved: 1500360 . Total input tokens: 334451225 . Total output tokens: 299936524
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.8824690650217235,
    "estimated_duration": 3600.1724414609075,
    "input_throughput": 5492.3149714396,
    "output_throughput": 4845.709555212546,
    "total_throughput": 10338.024526652147,
    "itl": 177.53924362202267,
    "ttft": 2005574.1328338932,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 242,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7406380340317255,
    "arrivals": 500381,
    "finished_requests": 79641,
    "scheduler_time": 49.20549089062811
}
#Debug simulation 
Total elapsed time: 5.8825933719053864. Arrivals time: 0.26185578387230635 Scheduler time: 5.519620222505182 Scheduler overhead time: 0.03162742080166936 Adapter cache time: 0.021865138318389654 Engine time: 0.03281652461737394 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-16/adapters_256_slots_256_rate_1.6-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-16/adapters_256_slots_256_rate_1.6-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 17280, 33, 17280, 17280, 33, 17280, 135, 17280, 33, 135, 33, 17280, 135, 135, 135, 135, 17280, 33, 33, 33, 135, 17280, 33, 17280, 17280, 135, 135, 135, 33, 17280, 33, 135, 135, 33, 135, 33, 33, 135, 135, 17280, 135, 33, 135, 17280, 135, 135, 17280, 135, 17280, 33, 17280, 17280, 135, 33, 33, 17280, 135, 33, 135, 135, 17280, 135, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 17280, 17280, 33, 17280, 33, 135, 17280, 17280, 17280, 135, 33, 17280, 135, 33, 33, 33, 33, 33, 17280, 135, 33, 17280, 33, 17280, 33, 33, 135, 135, 17280, 135, 17280, 33, 135, 33, 17280, 17280, 33, 17280, 135, 33, 17280, 33, 33, 17280, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 33, 135, 17280, 17280, 33, 17280, 135, 33, 135, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 135, 17280, 17280, 135, 33, 17280, 33, 135, 135, 33, 135, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 135, 17280, 135, 33, 135, 17280, 135, 17280, 33, 17280, 33, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 135, 33, 17280, 33, 17280, 135, 135, 33, 135, 17280, 135, 135, 17280, 33, 17280, 17280, 135, 33, 17280, 17280, 135, 135, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 17280, 33, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 17280, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 17280, 135, 33, 33, 33, 33]
Prompts retrieved: 1500360 . Total input tokens: 334451225 . Total output tokens: 299936524
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.6706665037199855,
    "estimated_duration": 3600.136683806292,
    "input_throughput": 5321.469067042459,
    "output_throughput": 4704.993028790069,
    "total_throughput": 10026.462095832529,
    "itl": 149.40080486501478,
    "ttft": 2026463.031554093,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 242,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7897846129536661,
    "arrivals": 500381,
    "finished_requests": 77196,
    "scheduler_time": 42.800451661920775
}
#Debug simulation 
Total elapsed time: 5.670762594789267. Arrivals time: 0.2560948529280722 Scheduler time: 5.300261554773897 Scheduler overhead time: 0.036806443240493536 Adapter cache time: 0.02278614044189453 Engine time: 0.03759892610833049 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-16/adapters_256_slots_256_rate_1.6-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-16/adapters_256_slots_256_rate_1.6-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 17280, 33, 17280, 17280, 33, 17280, 135, 17280, 33, 135, 33, 17280, 135, 135, 135, 135, 17280, 33, 33, 33, 135, 17280, 33, 17280, 17280, 135, 135, 135, 33, 17280, 33, 135, 135, 33, 135, 33, 33, 135, 135, 17280, 135, 33, 135, 17280, 135, 135, 17280, 135, 17280, 33, 17280, 17280, 135, 33, 33, 17280, 135, 33, 135, 135, 17280, 135, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 17280, 17280, 33, 17280, 33, 135, 17280, 17280, 17280, 135, 33, 17280, 135, 33, 33, 33, 33, 33, 17280, 135, 33, 17280, 33, 17280, 33, 33, 135, 135, 17280, 135, 17280, 33, 135, 33, 17280, 17280, 33, 17280, 135, 33, 17280, 33, 33, 17280, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 33, 135, 17280, 17280, 33, 17280, 135, 33, 135, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 135, 17280, 17280, 135, 33, 17280, 33, 135, 135, 33, 135, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 135, 17280, 135, 33, 135, 17280, 135, 17280, 33, 17280, 33, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 135, 33, 17280, 33, 17280, 135, 135, 33, 135, 17280, 135, 135, 17280, 33, 17280, 17280, 135, 33, 17280, 17280, 135, 135, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 17280, 33, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 17280, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 17280, 135, 33, 33, 33, 33]
Prompts retrieved: 1500360 . Total input tokens: 334451225 . Total output tokens: 299936524
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.712471453938633,
    "estimated_duration": 3600.1117055765426,
    "input_throughput": 5321.785701905536,
    "output_throughput": 4705.129836321924,
    "total_throughput": 10026.91553822746,
    "itl": 149.39884326880033,
    "ttft": 2026471.837535318,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 242,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7566883921599966,
    "arrivals": 500381,
    "finished_requests": 77200,
    "scheduler_time": 42.80081578837476
}
#Debug simulation 
Total elapsed time: 5.712585838045925. Arrivals time: 0.2633679364807904 Scheduler time: 5.334079058840871 Scheduler overhead time: 0.03695036889985204 Adapter cache time: 0.023004245478659868 Engine time: 0.03788779862225056 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-16/adapters_256_slots_256_rate_1.6-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-16/adapters_256_slots_256_rate_1.6-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 17280, 33, 17280, 17280, 33, 17280, 135, 17280, 33, 135, 33, 17280, 135, 135, 135, 135, 17280, 33, 33, 33, 135, 17280, 33, 17280, 17280, 135, 135, 135, 33, 17280, 33, 135, 135, 33, 135, 33, 33, 135, 135, 17280, 135, 33, 135, 17280, 135, 135, 17280, 135, 17280, 33, 17280, 17280, 135, 33, 33, 17280, 135, 33, 135, 135, 17280, 135, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 17280, 17280, 33, 17280, 33, 135, 17280, 17280, 17280, 135, 33, 17280, 135, 33, 33, 33, 33, 33, 17280, 135, 33, 17280, 33, 17280, 33, 33, 135, 135, 17280, 135, 17280, 33, 135, 33, 17280, 17280, 33, 17280, 135, 33, 17280, 33, 33, 17280, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 33, 135, 17280, 17280, 33, 17280, 135, 33, 135, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 135, 17280, 17280, 135, 33, 17280, 33, 135, 135, 33, 135, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 135, 17280, 135, 33, 135, 17280, 135, 17280, 33, 17280, 33, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 135, 33, 17280, 33, 17280, 135, 135, 33, 135, 17280, 135, 135, 17280, 33, 17280, 17280, 135, 33, 17280, 17280, 135, 135, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 17280, 33, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 17280, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 17280, 135, 33, 33, 33, 33]
Prompts retrieved: 1500360 . Total input tokens: 334451225 . Total output tokens: 299936524
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.619745878968388,
    "estimated_duration": 3600.0110659648412,
    "input_throughput": 5321.426698133126,
    "output_throughput": 4705.0522039049265,
    "total_throughput": 10026.478902038052,
    "itl": 149.39681997939937,
    "ttft": 2026420.6463472643,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 242,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7235921713663275,
    "arrivals": 500381,
    "finished_requests": 77193,
    "scheduler_time": 42.79938873809508
}
#Debug simulation 
Total elapsed time: 5.6198666538111866. Arrivals time: 0.25934714870527387 Scheduler time: 5.24577061785385 Scheduler overhead time: 0.036912341602146626 Adapter cache time: 0.022741772700101137 Engine time: 0.03789775026962161 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-8/adapters_256_slots_256_rate_1.6-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-8/adapters_256_slots_256_rate_1.6-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 17280, 33, 17280, 17280, 33, 17280, 66, 17280, 33, 66, 33, 17280, 66, 66, 66, 66, 17280, 33, 33, 33, 66, 17280, 33, 17280, 17280, 66, 66, 66, 33, 17280, 33, 66, 66, 33, 66, 33, 33, 66, 66, 17280, 66, 33, 66, 17280, 66, 66, 17280, 66, 17280, 33, 17280, 17280, 66, 33, 33, 17280, 66, 33, 66, 66, 17280, 66, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 17280, 17280, 33, 17280, 33, 66, 17280, 17280, 17280, 66, 33, 17280, 66, 33, 33, 33, 33, 33, 17280, 66, 33, 17280, 33, 17280, 33, 33, 66, 66, 17280, 66, 17280, 33, 66, 33, 17280, 17280, 33, 17280, 66, 33, 17280, 33, 33, 17280, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 33, 66, 17280, 17280, 33, 17280, 66, 33, 66, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 66, 17280, 17280, 66, 33, 17280, 33, 66, 66, 33, 66, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 66, 17280, 66, 33, 66, 17280, 66, 17280, 33, 17280, 33, 66, 17280, 66, 17280, 66, 17280, 66, 17280, 66, 33, 17280, 33, 17280, 66, 66, 33, 66, 17280, 66, 66, 17280, 33, 17280, 17280, 66, 33, 17280, 17280, 66, 66, 17280, 17280, 66, 66, 66, 66, 17280, 17280, 66, 66, 17280, 33, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 17280, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 17280, 66, 33, 33, 33, 33]
Prompts retrieved: 1494495 . Total input tokens: 333126301 . Total output tokens: 298768414
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.8629958080127835,
    "estimated_duration": 3600.1835634353088,
    "input_throughput": 5581.20069322989,
    "output_throughput": 4928.595358362437,
    "total_throughput": 10509.796051592326,
    "itl": 174.45953987149073,
    "ttft": 1993007.0898424906,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 242,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7406380340317255,
    "arrivals": 498436,
    "finished_requests": 81342,
    "scheduler_time": 50.08027704567517
}
#Debug simulation 
Total elapsed time: 5.863095156848431. Arrivals time: 0.2719483897089958 Scheduler time: 5.493742510210723 Scheduler overhead time: 0.03238021954894066 Adapter cache time: 0.01699593709781766 Engine time: 0.03306594351306558 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-16/adapters_256_slots_256_rate_1.6-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-16/adapters_256_slots_256_rate_1.6-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 17280, 33, 17280, 17280, 33, 17280, 66, 17280, 33, 66, 33, 17280, 66, 66, 66, 66, 17280, 33, 33, 33, 66, 17280, 33, 17280, 17280, 66, 66, 66, 33, 17280, 33, 66, 66, 33, 66, 33, 33, 66, 66, 17280, 66, 33, 66, 17280, 66, 66, 17280, 66, 17280, 33, 17280, 17280, 66, 33, 33, 17280, 66, 33, 66, 66, 17280, 66, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 17280, 17280, 33, 17280, 33, 66, 17280, 17280, 17280, 66, 33, 17280, 66, 33, 33, 33, 33, 33, 17280, 66, 33, 17280, 33, 17280, 33, 33, 66, 66, 17280, 66, 17280, 33, 66, 33, 17280, 17280, 33, 17280, 66, 33, 17280, 33, 33, 17280, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 33, 66, 17280, 17280, 33, 17280, 66, 33, 66, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 66, 17280, 17280, 66, 33, 17280, 33, 66, 66, 33, 66, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 66, 17280, 66, 33, 66, 17280, 66, 17280, 33, 17280, 33, 66, 17280, 66, 17280, 66, 17280, 66, 17280, 66, 33, 17280, 33, 17280, 66, 66, 33, 66, 17280, 66, 66, 17280, 33, 17280, 17280, 66, 33, 17280, 17280, 66, 66, 17280, 17280, 66, 66, 66, 66, 17280, 17280, 66, 66, 17280, 33, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 17280, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 17280, 66, 33, 33, 33, 33]
Prompts retrieved: 1494495 . Total input tokens: 333126301 . Total output tokens: 298768414
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.782763701863587,
    "estimated_duration": 3600.103111679722,
    "input_throughput": 5386.710435344121,
    "output_throughput": 4767.085127179211,
    "total_throughput": 10153.795562523332,
    "itl": 147.2448151000797,
    "ttft": 2014619.0382826028,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 241,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7859773720218832,
    "arrivals": 498436,
    "finished_requests": 78516,
    "scheduler_time": 43.41315929100268
}
#Debug simulation 
Total elapsed time: 5.782879827078432. Arrivals time: 0.2677018786780536 Scheduler time: 5.404068263247609 Scheduler overhead time: 0.03739695344120264 Adapter cache time: 0.01795606967061758 Engine time: 0.038314834237098694 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-16/adapters_256_slots_256_rate_1.6-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-16/adapters_256_slots_256_rate_1.6-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 17280, 33, 17280, 17280, 33, 17280, 66, 17280, 33, 66, 33, 17280, 66, 66, 66, 66, 17280, 33, 33, 33, 66, 17280, 33, 17280, 17280, 66, 66, 66, 33, 17280, 33, 66, 66, 33, 66, 33, 33, 66, 66, 17280, 66, 33, 66, 17280, 66, 66, 17280, 66, 17280, 33, 17280, 17280, 66, 33, 33, 17280, 66, 33, 66, 66, 17280, 66, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 17280, 17280, 33, 17280, 33, 66, 17280, 17280, 17280, 66, 33, 17280, 66, 33, 33, 33, 33, 33, 17280, 66, 33, 17280, 33, 17280, 33, 33, 66, 66, 17280, 66, 17280, 33, 66, 33, 17280, 17280, 33, 17280, 66, 33, 17280, 33, 33, 17280, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 33, 66, 17280, 17280, 33, 17280, 66, 33, 66, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 66, 17280, 17280, 66, 33, 17280, 33, 66, 66, 33, 66, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 66, 17280, 66, 33, 66, 17280, 66, 17280, 33, 17280, 33, 66, 17280, 66, 17280, 66, 17280, 66, 17280, 66, 33, 17280, 33, 17280, 66, 66, 33, 66, 17280, 66, 66, 17280, 33, 17280, 17280, 66, 33, 17280, 17280, 66, 66, 17280, 17280, 66, 66, 66, 66, 17280, 17280, 66, 66, 17280, 33, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 17280, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 17280, 66, 33, 33, 33, 33]
Prompts retrieved: 1494495 . Total input tokens: 333126301 . Total output tokens: 298768414
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.729609172791243,
    "estimated_duration": 3600.022029378642,
    "input_throughput": 5386.560371506111,
    "output_throughput": 4767.102773246662,
    "total_throughput": 10153.663144752772,
    "itl": 147.24634401544424,
    "ttft": 2014595.1237133977,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 241,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.752881151228214,
    "arrivals": 498436,
    "finished_requests": 78513,
    "scheduler_time": 43.41259192654856
}
#Debug simulation 
Total elapsed time: 5.729704838711768. Arrivals time: 0.2563404468819499 Scheduler time: 5.361549414694309 Scheduler overhead time: 0.03745694598183036 Adapter cache time: 0.01865808805450797 Engine time: 0.038285963237285614 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-16/adapters_256_slots_256_rate_1.6-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-16/adapters_256_slots_256_rate_1.6-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 17280, 33, 17280, 17280, 33, 17280, 66, 17280, 33, 66, 33, 17280, 66, 66, 66, 66, 17280, 33, 33, 33, 66, 17280, 33, 17280, 17280, 66, 66, 66, 33, 17280, 33, 66, 66, 33, 66, 33, 33, 66, 66, 17280, 66, 33, 66, 17280, 66, 66, 17280, 66, 17280, 33, 17280, 17280, 66, 33, 33, 17280, 66, 33, 66, 66, 17280, 66, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 17280, 17280, 33, 17280, 33, 66, 17280, 17280, 17280, 66, 33, 17280, 66, 33, 33, 33, 33, 33, 17280, 66, 33, 17280, 33, 17280, 33, 33, 66, 66, 17280, 66, 17280, 33, 66, 33, 17280, 17280, 33, 17280, 66, 33, 17280, 33, 33, 17280, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 33, 66, 17280, 17280, 33, 17280, 66, 33, 66, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 66, 17280, 17280, 66, 33, 17280, 33, 66, 66, 33, 66, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 66, 17280, 66, 33, 66, 17280, 66, 17280, 33, 17280, 33, 66, 17280, 66, 17280, 66, 17280, 66, 17280, 66, 33, 17280, 33, 17280, 66, 66, 33, 66, 17280, 66, 66, 17280, 33, 17280, 17280, 66, 33, 17280, 17280, 66, 66, 17280, 17280, 66, 66, 66, 66, 17280, 17280, 66, 66, 17280, 33, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 17280, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 17280, 66, 33, 33, 33, 33]
Prompts retrieved: 1494495 . Total input tokens: 333126301 . Total output tokens: 298768414
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.756884993985295,
    "estimated_duration": 3600.1093847147426,
    "input_throughput": 5386.809379275743,
    "output_throughput": 4767.067376581904,
    "total_throughput": 10153.876755857647,
    "itl": 147.24298045403347,
    "ttft": 2014616.023940497,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 241,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7206021210714253,
    "arrivals": 498436,
    "finished_requests": 78516,
    "scheduler_time": 43.413425130121475
}
#Debug simulation 
Total elapsed time: 5.757014644797891. Arrivals time: 0.257386249024421 Scheduler time: 5.38785454723984 Scheduler overhead time: 0.0374418911524117 Adapter cache time: 0.018511845730245113 Engine time: 0.03834011172875762 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-8/adapters_256_slots_256_rate_0.8-0.4-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-8/adapters_256_slots_256_rate_0.8-0.4-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 1080, 8640, 8640, 1080, 8640, 4320, 8640, 1080, 4320, 1080, 8640, 4320, 4320, 4320, 4320, 8640, 1080, 1080, 1080, 4320, 8640, 1080, 8640, 8640, 4320, 4320, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 1080, 8640, 8640, 4320, 1080, 1080, 8640, 4320, 1080, 4320, 4320, 8640, 4320, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 4320, 1080, 4320, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 8640, 8640, 1080, 8640, 1080, 4320, 8640, 8640, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 1080, 1080, 1080, 8640, 4320, 1080, 8640, 1080, 8640, 1080, 1080, 4320, 4320, 8640, 4320, 8640, 1080, 4320, 1080, 8640, 8640, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 1080, 4320, 8640, 8640, 1080, 8640, 4320, 1080, 4320, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 1080, 1080, 8640, 1080, 4320, 8640, 8640, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 8640, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 8640, 1080, 8640, 1080, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 8640, 4320, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 1080, 8640, 8640, 4320, 1080, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 8640, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 1080, 1080, 1080, 1080]
Prompts retrieved: 1202040 . Total input tokens: 267960373 . Total output tokens: 240348610
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 3.752619395032525,
    "estimated_duration": 3600.152396358948,
    "input_throughput": 3448.5706806624144,
    "output_throughput": 2992.8133072636006,
    "total_throughput": 6441.383987926015,
    "itl": 282.44450492844425,
    "ttft": 2241596.4650609177,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.783484862446784,
    "arrivals": 401058,
    "finished_requests": 49730,
    "scheduler_time": 30.58144078034339
}
#Debug simulation 
Total elapsed time: 3.7527190377004445. Arrivals time: 0.19026250997558236 Scheduler time: 3.4413226093165576 Scheduler overhead time: 0.020381140988320112 Adapter cache time: 0.07027442427352071 Engine time: 0.021050056908279657 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-16/adapters_256_slots_256_rate_0.8-0.4-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-16/adapters_256_slots_256_rate_0.8-0.4-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 1080, 8640, 8640, 1080, 8640, 4320, 8640, 1080, 4320, 1080, 8640, 4320, 4320, 4320, 4320, 8640, 1080, 1080, 1080, 4320, 8640, 1080, 8640, 8640, 4320, 4320, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 1080, 8640, 8640, 4320, 1080, 1080, 8640, 4320, 1080, 4320, 4320, 8640, 4320, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 4320, 1080, 4320, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 8640, 8640, 1080, 8640, 1080, 4320, 8640, 8640, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 1080, 1080, 1080, 8640, 4320, 1080, 8640, 1080, 8640, 1080, 1080, 4320, 4320, 8640, 4320, 8640, 1080, 4320, 1080, 8640, 8640, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 1080, 4320, 8640, 8640, 1080, 8640, 4320, 1080, 4320, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 1080, 1080, 8640, 1080, 4320, 8640, 8640, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 8640, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 8640, 1080, 8640, 1080, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 8640, 4320, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 1080, 8640, 8640, 4320, 1080, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 8640, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 1080, 1080, 1080, 1080]
Prompts retrieved: 1202040 . Total input tokens: 267960373 . Total output tokens: 240348610
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.8282456751912832,
    "estimated_duration": 3600.1813096439864,
    "input_throughput": 3410.7896085973202,
    "output_throughput": 2965.8095194810808,
    "total_throughput": 6376.599128078401,
    "itl": 232.81308077027677,
    "ttft": 2252275.126932939,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8353226749482602,
    "arrivals": 401058,
    "finished_requests": 49174,
    "scheduler_time": 27.089548615222416
}
#Debug simulation 
Total elapsed time: 3.8283566390164196. Arrivals time: 0.1947756316512823 Scheduler time: 3.4791406909935176 Scheduler overhead time: 0.02425631880760193 Adapter cache time: 0.09373663598671556 Engine time: 0.025165162980556488 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-16-16/adapters_256_slots_256_rate_0.8-0.4-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-16-16/adapters_256_slots_256_rate_0.8-0.4-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 1080, 8640, 8640, 1080, 8640, 4320, 8640, 1080, 4320, 1080, 8640, 4320, 4320, 4320, 4320, 8640, 1080, 1080, 1080, 4320, 8640, 1080, 8640, 8640, 4320, 4320, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 1080, 8640, 8640, 4320, 1080, 1080, 8640, 4320, 1080, 4320, 4320, 8640, 4320, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 4320, 1080, 4320, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 8640, 8640, 1080, 8640, 1080, 4320, 8640, 8640, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 1080, 1080, 1080, 8640, 4320, 1080, 8640, 1080, 8640, 1080, 1080, 4320, 4320, 8640, 4320, 8640, 1080, 4320, 1080, 8640, 8640, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 1080, 4320, 8640, 8640, 1080, 8640, 4320, 1080, 4320, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 1080, 1080, 8640, 1080, 4320, 8640, 8640, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 8640, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 8640, 1080, 8640, 1080, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 8640, 4320, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 1080, 8640, 8640, 4320, 1080, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 8640, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 1080, 1080, 1080, 1080]
Prompts retrieved: 1202040 . Total input tokens: 267960373 . Total output tokens: 240348610
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 3.7860661651939154,
    "estimated_duration": 3600.211272559938,
    "input_throughput": 3406.870894906848,
    "output_throughput": 2961.616747680045,
    "total_throughput": 6368.487642586893,
    "itl": 232.48589878839297,
    "ttft": 2252702.767109912,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8005920728808293,
    "arrivals": 401058,
    "finished_requests": 49105,
    "scheduler_time": 27.00841678095461
}
#Debug simulation 
Total elapsed time: 3.786210692021996. Arrivals time: 0.19384285993874073 Scheduler time: 3.4384863851591945 Scheduler overhead time: 0.024196778889745474 Adapter cache time: 0.09328946890309453 Engine time: 0.025093143340200186 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_16-16-16/adapters_256_slots_256_rate_0.8-0.4-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_16-16-16/adapters_256_slots_256_rate_0.8-0.4-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 1080, 8640, 8640, 1080, 8640, 4320, 8640, 1080, 4320, 1080, 8640, 4320, 4320, 4320, 4320, 8640, 1080, 1080, 1080, 4320, 8640, 1080, 8640, 8640, 4320, 4320, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 1080, 8640, 8640, 4320, 1080, 1080, 8640, 4320, 1080, 4320, 4320, 8640, 4320, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 4320, 1080, 4320, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 8640, 8640, 1080, 8640, 1080, 4320, 8640, 8640, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 1080, 1080, 1080, 8640, 4320, 1080, 8640, 1080, 8640, 1080, 1080, 4320, 4320, 8640, 4320, 8640, 1080, 4320, 1080, 8640, 8640, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 1080, 4320, 8640, 8640, 1080, 8640, 4320, 1080, 4320, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 1080, 1080, 8640, 1080, 4320, 8640, 8640, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 8640, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 8640, 1080, 8640, 1080, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 8640, 4320, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 1080, 8640, 8640, 4320, 1080, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 8640, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 1080, 1080, 1080, 1080]
Prompts retrieved: 1202040 . Total input tokens: 267960373 . Total output tokens: 240348610
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 3.8010073606856167,
    "estimated_duration": 3600.065664252534,
    "input_throughput": 3411.554439674372,
    "output_throughput": 2966.381170777136,
    "total_throughput": 6377.935610451508,
    "itl": 233.36442716479397,
    "ttft": 2251967.0820292043,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.765452875494958,
    "arrivals": 401058,
    "finished_requests": 49182,
    "scheduler_time": 27.1368852137629
}
#Debug simulation 
Total elapsed time: 3.8011083216406405. Arrivals time: 0.1906206114217639 Scheduler time: 3.456156308762729 Scheduler overhead time: 0.024171186611056328 Adapter cache time: 0.09358811471611261 Engine time: 0.02534728217869997 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-8/adapters_256_slots_256_rate_0.8-0.4-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-8/adapters_256_slots_256_rate_0.8-0.4-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 540, 8640, 8640, 540, 8640, 4320, 8640, 540, 4320, 540, 8640, 4320, 4320, 4320, 4320, 8640, 540, 540, 540, 4320, 8640, 540, 8640, 8640, 4320, 4320, 4320, 540, 8640, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 8640, 4320, 540, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 540, 8640, 8640, 4320, 540, 540, 8640, 4320, 540, 4320, 4320, 8640, 4320, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 8640, 8640, 540, 8640, 540, 4320, 8640, 8640, 8640, 4320, 540, 8640, 4320, 540, 540, 540, 540, 540, 8640, 4320, 540, 8640, 540, 8640, 540, 540, 4320, 4320, 8640, 4320, 8640, 540, 4320, 540, 8640, 8640, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 540, 4320, 8640, 8640, 540, 8640, 4320, 540, 4320, 8640, 540, 540, 540, 540, 540, 540, 8640, 540, 540, 540, 8640, 540, 4320, 8640, 8640, 4320, 540, 8640, 540, 4320, 4320, 540, 4320, 540, 8640, 540, 540, 8640, 540, 8640, 8640, 4320, 8640, 4320, 540, 4320, 8640, 4320, 8640, 540, 8640, 540, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 540, 8640, 540, 8640, 4320, 4320, 540, 4320, 8640, 4320, 4320, 8640, 540, 8640, 8640, 4320, 540, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 540, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 8640, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 540, 540, 540, 540]
Prompts retrieved: 1156140 . Total input tokens: 257714928 . Total output tokens: 231188240
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 3.9562233071774244,
    "estimated_duration": 3600.180177830904,
    "input_throughput": 3624.6633100075123,
    "output_throughput": 3190.817801491588,
    "total_throughput": 6815.481111499101,
    "itl": 267.4862255721239,
    "ttft": 2202235.330017424,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.783484862446784,
    "arrivals": 385672,
    "finished_requests": 52803,
    "scheduler_time": 32.68756530543683
}
#Debug simulation 
Total elapsed time: 3.956320355180651. Arrivals time: 0.1991782747209072 Scheduler time: 3.647407306358218 Scheduler overhead time: 0.021471844986081123 Adapter cache time: 0.05609252443537116 Engine time: 0.022232819348573685 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-16/adapters_256_slots_256_rate_0.8-0.4-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-16/adapters_256_slots_256_rate_0.8-0.4-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 540, 8640, 8640, 540, 8640, 4320, 8640, 540, 4320, 540, 8640, 4320, 4320, 4320, 4320, 8640, 540, 540, 540, 4320, 8640, 540, 8640, 8640, 4320, 4320, 4320, 540, 8640, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 8640, 4320, 540, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 540, 8640, 8640, 4320, 540, 540, 8640, 4320, 540, 4320, 4320, 8640, 4320, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 8640, 8640, 540, 8640, 540, 4320, 8640, 8640, 8640, 4320, 540, 8640, 4320, 540, 540, 540, 540, 540, 8640, 4320, 540, 8640, 540, 8640, 540, 540, 4320, 4320, 8640, 4320, 8640, 540, 4320, 540, 8640, 8640, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 540, 4320, 8640, 8640, 540, 8640, 4320, 540, 4320, 8640, 540, 540, 540, 540, 540, 540, 8640, 540, 540, 540, 8640, 540, 4320, 8640, 8640, 4320, 540, 8640, 540, 4320, 4320, 540, 4320, 540, 8640, 540, 540, 8640, 540, 8640, 8640, 4320, 8640, 4320, 540, 4320, 8640, 4320, 8640, 540, 8640, 540, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 540, 8640, 540, 8640, 4320, 4320, 540, 4320, 8640, 4320, 4320, 8640, 540, 8640, 8640, 4320, 540, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 540, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 8640, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 540, 540, 540, 540]
Prompts retrieved: 1156140 . Total input tokens: 257714928 . Total output tokens: 231188240
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.9590691891498864,
    "estimated_duration": 3600.232545370846,
    "input_throughput": 3565.082210176483,
    "output_throughput": 3146.921721644783,
    "total_throughput": 6712.003931821266,
    "itl": 222.29236242198144,
    "ttft": 2216038.789496478,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8353226749482604,
    "arrivals": 385672,
    "finished_requests": 51951,
    "scheduler_time": 28.92473476564653
}
#Debug simulation 
Total elapsed time: 3.959168184082955. Arrivals time: 0.19566420558840036 Scheduler time: 3.625036775134504 Scheduler overhead time: 0.025187392719089985 Adapter cache time: 0.07543157553300261 Engine time: 0.026091934647411108 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-16-16/adapters_256_slots_256_rate_0.8-0.4-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-16-16/adapters_256_slots_256_rate_0.8-0.4-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 540, 8640, 8640, 540, 8640, 4320, 8640, 540, 4320, 540, 8640, 4320, 4320, 4320, 4320, 8640, 540, 540, 540, 4320, 8640, 540, 8640, 8640, 4320, 4320, 4320, 540, 8640, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 8640, 4320, 540, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 540, 8640, 8640, 4320, 540, 540, 8640, 4320, 540, 4320, 4320, 8640, 4320, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 8640, 8640, 540, 8640, 540, 4320, 8640, 8640, 8640, 4320, 540, 8640, 4320, 540, 540, 540, 540, 540, 8640, 4320, 540, 8640, 540, 8640, 540, 540, 4320, 4320, 8640, 4320, 8640, 540, 4320, 540, 8640, 8640, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 540, 4320, 8640, 8640, 540, 8640, 4320, 540, 4320, 8640, 540, 540, 540, 540, 540, 540, 8640, 540, 540, 540, 8640, 540, 4320, 8640, 8640, 4320, 540, 8640, 540, 4320, 4320, 540, 4320, 540, 8640, 540, 540, 8640, 540, 8640, 8640, 4320, 8640, 4320, 540, 4320, 8640, 4320, 8640, 540, 8640, 540, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 540, 8640, 540, 8640, 4320, 4320, 540, 4320, 8640, 4320, 4320, 8640, 540, 8640, 8640, 4320, 540, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 540, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 8640, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 540, 540, 540, 540]
Prompts retrieved: 1156140 . Total input tokens: 257714928 . Total output tokens: 231188240
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 3.953550510108471,
    "estimated_duration": 3600.1705887887433,
    "input_throughput": 3565.206059949059,
    "output_throughput": 3147.0842063103255,
    "total_throughput": 6712.290266259385,
    "itl": 222.29709047044074,
    "ttft": 2216016.3733063918,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8005920728808292,
    "arrivals": 385672,
    "finished_requests": 51953,
    "scheduler_time": 28.924624151213493
}
#Debug simulation 
Total elapsed time: 3.953652727883309. Arrivals time: 0.1950282147154212 Scheduler time: 3.620798065327108 Scheduler overhead time: 0.0252319173887372 Adapter cache time: 0.07467597583308816 Engine time: 0.026120256632566452 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_16-16-16/adapters_256_slots_256_rate_0.8-0.4-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_16-16-16/adapters_256_slots_256_rate_0.8-0.4-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 540, 8640, 8640, 540, 8640, 4320, 8640, 540, 4320, 540, 8640, 4320, 4320, 4320, 4320, 8640, 540, 540, 540, 4320, 8640, 540, 8640, 8640, 4320, 4320, 4320, 540, 8640, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 8640, 4320, 540, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 540, 8640, 8640, 4320, 540, 540, 8640, 4320, 540, 4320, 4320, 8640, 4320, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 8640, 8640, 540, 8640, 540, 4320, 8640, 8640, 8640, 4320, 540, 8640, 4320, 540, 540, 540, 540, 540, 8640, 4320, 540, 8640, 540, 8640, 540, 540, 4320, 4320, 8640, 4320, 8640, 540, 4320, 540, 8640, 8640, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 540, 4320, 8640, 8640, 540, 8640, 4320, 540, 4320, 8640, 540, 540, 540, 540, 540, 540, 8640, 540, 540, 540, 8640, 540, 4320, 8640, 8640, 4320, 540, 8640, 540, 4320, 4320, 540, 4320, 540, 8640, 540, 540, 8640, 540, 8640, 8640, 4320, 8640, 4320, 540, 4320, 8640, 4320, 8640, 540, 8640, 540, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 540, 8640, 540, 8640, 4320, 4320, 540, 4320, 8640, 4320, 4320, 8640, 540, 8640, 8640, 4320, 540, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 540, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 8640, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 540, 540, 540, 540]
Prompts retrieved: 1156140 . Total input tokens: 257714928 . Total output tokens: 231188240
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 3.969361579976976,
    "estimated_duration": 3600.1025526811964,
    "input_throughput": 3565.2109383497896,
    "output_throughput": 3147.0353508574863,
    "total_throughput": 6712.246289207275,
    "itl": 222.28172082247374,
    "ttft": 2215961.0188702564,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.765452875494958,
    "arrivals": 385672,
    "finished_requests": 51951,
    "scheduler_time": 28.92261693969328
}
#Debug simulation 
Total elapsed time: 3.969461491331458. Arrivals time: 0.19542759051546454 Scheduler time: 3.635517990216613 Scheduler overhead time: 0.025233829393982887 Adapter cache time: 0.0754037438891828 Engine time: 0.026106431148946285 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-8/adapters_256_slots_256_rate_0.8-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-8/adapters_256_slots_256_rate_0.8-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 270, 8640, 8640, 270, 8640, 4320, 8640, 270, 4320, 270, 8640, 4320, 4320, 4320, 4320, 8640, 270, 270, 270, 4320, 8640, 270, 8640, 8640, 4320, 4320, 4320, 270, 8640, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 8640, 4320, 270, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 270, 8640, 8640, 4320, 270, 270, 8640, 4320, 270, 4320, 4320, 8640, 4320, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 8640, 8640, 270, 8640, 270, 4320, 8640, 8640, 8640, 4320, 270, 8640, 4320, 270, 270, 270, 270, 270, 8640, 4320, 270, 8640, 270, 8640, 270, 270, 4320, 4320, 8640, 4320, 8640, 270, 4320, 270, 8640, 8640, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 270, 4320, 8640, 8640, 270, 8640, 4320, 270, 4320, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 4320, 8640, 8640, 4320, 270, 8640, 270, 4320, 4320, 270, 4320, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 4320, 8640, 4320, 270, 4320, 8640, 4320, 8640, 270, 8640, 270, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 270, 8640, 270, 8640, 4320, 4320, 270, 4320, 8640, 4320, 4320, 8640, 270, 8640, 8640, 4320, 270, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 270, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 8640, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 270, 270, 270, 270]
Prompts retrieved: 1133190 . Total input tokens: 252615163 . Total output tokens: 226586703
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.100025920663029,
    "estimated_duration": 3600.089264756682,
    "input_throughput": 3789.68880954181,
    "output_throughput": 3330.657969340771,
    "total_throughput": 7120.346778882581,
    "itl": 256.5754994689452,
    "ttft": 2173600.3771321103,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.783484862446784,
    "arrivals": 378122,
    "finished_requests": 55196,
    "scheduler_time": 34.090939378155895
}
#Debug simulation 
Total elapsed time: 4.1001297677867115. Arrivals time: 0.20541710406541824 Scheduler time: 3.7952314103022218 Scheduler overhead time: 0.022407117299735546 Adapter cache time: 0.04385324800387025 Engine time: 0.022764708381146193 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-16/adapters_256_slots_256_rate_0.8-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-16/adapters_256_slots_256_rate_0.8-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 270, 8640, 8640, 270, 8640, 4320, 8640, 270, 4320, 270, 8640, 4320, 4320, 4320, 4320, 8640, 270, 270, 270, 4320, 8640, 270, 8640, 8640, 4320, 4320, 4320, 270, 8640, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 8640, 4320, 270, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 270, 8640, 8640, 4320, 270, 270, 8640, 4320, 270, 4320, 4320, 8640, 4320, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 8640, 8640, 270, 8640, 270, 4320, 8640, 8640, 8640, 4320, 270, 8640, 4320, 270, 270, 270, 270, 270, 8640, 4320, 270, 8640, 270, 8640, 270, 270, 4320, 4320, 8640, 4320, 8640, 270, 4320, 270, 8640, 8640, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 270, 4320, 8640, 8640, 270, 8640, 4320, 270, 4320, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 4320, 8640, 8640, 4320, 270, 8640, 270, 4320, 4320, 270, 4320, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 4320, 8640, 4320, 270, 4320, 8640, 4320, 8640, 270, 8640, 270, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 270, 8640, 270, 8640, 4320, 4320, 270, 4320, 8640, 4320, 4320, 8640, 270, 8640, 8640, 4320, 270, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 270, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 8640, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 270, 270, 270, 270]
Prompts retrieved: 1133190 . Total input tokens: 252615163 . Total output tokens: 226586703
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.073867979925126,
    "estimated_duration": 3600.2280209706355,
    "input_throughput": 3698.9862648781987,
    "output_throughput": 3261.4900866290914,
    "total_throughput": 6960.47635150729,
    "itl": 214.20333419632163,
    "ttft": 2189859.4857291216,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8353226749482602,
    "arrivals": 378122,
    "finished_requests": 53899,
    "scheduler_time": 29.898518228112472
}
#Debug simulation 
Total elapsed time: 4.073968117125332. Arrivals time: 0.19929202925413847 Scheduler time: 3.7523978305980563 Scheduler overhead time: 0.02616273984313011 Adapter cache time: 0.056961549911648035 Engine time: 0.026980810798704624 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-16-16/adapters_256_slots_256_rate_0.8-0.4-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-16-16/adapters_256_slots_256_rate_0.8-0.4-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 270, 8640, 8640, 270, 8640, 4320, 8640, 270, 4320, 270, 8640, 4320, 4320, 4320, 4320, 8640, 270, 270, 270, 4320, 8640, 270, 8640, 8640, 4320, 4320, 4320, 270, 8640, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 8640, 4320, 270, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 270, 8640, 8640, 4320, 270, 270, 8640, 4320, 270, 4320, 4320, 8640, 4320, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 8640, 8640, 270, 8640, 270, 4320, 8640, 8640, 8640, 4320, 270, 8640, 4320, 270, 270, 270, 270, 270, 8640, 4320, 270, 8640, 270, 8640, 270, 270, 4320, 4320, 8640, 4320, 8640, 270, 4320, 270, 8640, 8640, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 270, 4320, 8640, 8640, 270, 8640, 4320, 270, 4320, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 4320, 8640, 8640, 4320, 270, 8640, 270, 4320, 4320, 270, 4320, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 4320, 8640, 4320, 270, 4320, 8640, 4320, 8640, 270, 8640, 270, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 270, 8640, 270, 8640, 4320, 4320, 270, 4320, 8640, 4320, 4320, 8640, 270, 8640, 8640, 4320, 270, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 270, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 8640, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 270, 270, 270, 270]
Prompts retrieved: 1133190 . Total input tokens: 252615163 . Total output tokens: 226586703
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.074850557371974,
    "estimated_duration": 3600.1019710830765,
    "input_throughput": 3702.8931699924833,
    "output_throughput": 3264.34420313502,
    "total_throughput": 6967.237373127503,
    "itl": 215.00348877599538,
    "ttft": 2189314.9637674117,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8005920728808293,
    "arrivals": 378122,
    "finished_requests": 53951,
    "scheduler_time": 30.00538825345989
}
#Debug simulation 
Total elapsed time: 4.074972799047828. Arrivals time: 0.1995980069041252 Scheduler time: 3.753333867061883 Scheduler overhead time: 0.026056386530399323 Adapter cache time: 0.05692559387534857 Engine time: 0.026869879569858313 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_16-16-16/adapters_256_slots_256_rate_0.8-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_16-16-16/adapters_256_slots_256_rate_0.8-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 270, 8640, 8640, 270, 8640, 4320, 8640, 270, 4320, 270, 8640, 4320, 4320, 4320, 4320, 8640, 270, 270, 270, 4320, 8640, 270, 8640, 8640, 4320, 4320, 4320, 270, 8640, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 8640, 4320, 270, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 270, 8640, 8640, 4320, 270, 270, 8640, 4320, 270, 4320, 4320, 8640, 4320, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 8640, 8640, 270, 8640, 270, 4320, 8640, 8640, 8640, 4320, 270, 8640, 4320, 270, 270, 270, 270, 270, 8640, 4320, 270, 8640, 270, 8640, 270, 270, 4320, 4320, 8640, 4320, 8640, 270, 4320, 270, 8640, 8640, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 270, 4320, 8640, 8640, 270, 8640, 4320, 270, 4320, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 4320, 8640, 8640, 4320, 270, 8640, 270, 4320, 4320, 270, 4320, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 4320, 8640, 4320, 270, 4320, 8640, 4320, 8640, 270, 8640, 270, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 270, 8640, 270, 8640, 4320, 4320, 270, 4320, 8640, 4320, 4320, 8640, 270, 8640, 8640, 4320, 270, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 270, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 8640, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 270, 270, 270, 270]
Prompts retrieved: 1133190 . Total input tokens: 252615163 . Total output tokens: 226586703
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.060769827105105,
    "estimated_duration": 3600.231870811938,
    "input_throughput": 3703.308975205851,
    "output_throughput": 3264.564734090134,
    "total_throughput": 6967.873709295985,
    "itl": 215.1589256746105,
    "ttft": 2189253.359543549,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.765452875494958,
    "arrivals": 378122,
    "finished_requests": 53957,
    "scheduler_time": 30.025092539020452
}
#Debug simulation 
Total elapsed time: 4.060870599001646. Arrivals time: 0.1994342184625566 Scheduler time: 3.7387787783518434 Scheduler overhead time: 0.026067971251904964 Adapter cache time: 0.05770797561854124 Engine time: 0.026726324576884508 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-8/adapters_256_slots_256_rate_0.8-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-8/adapters_256_slots_256_rate_0.8-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 135, 8640, 8640, 135, 8640, 4320, 8640, 135, 4320, 135, 8640, 4320, 4320, 4320, 4320, 8640, 135, 135, 135, 4320, 8640, 135, 8640, 8640, 4320, 4320, 4320, 135, 8640, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 8640, 4320, 135, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 135, 8640, 8640, 4320, 135, 135, 8640, 4320, 135, 4320, 4320, 8640, 4320, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 8640, 8640, 135, 8640, 135, 4320, 8640, 8640, 8640, 4320, 135, 8640, 4320, 135, 135, 135, 135, 135, 8640, 4320, 135, 8640, 135, 8640, 135, 135, 4320, 4320, 8640, 4320, 8640, 135, 4320, 135, 8640, 8640, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 135, 4320, 8640, 8640, 135, 8640, 4320, 135, 4320, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 4320, 8640, 8640, 4320, 135, 8640, 135, 4320, 4320, 135, 4320, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 4320, 8640, 4320, 135, 4320, 8640, 4320, 8640, 135, 8640, 135, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 135, 8640, 135, 8640, 4320, 4320, 135, 4320, 8640, 4320, 4320, 8640, 135, 8640, 8640, 4320, 135, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 135, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 8640, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 135, 135, 135, 135]
Prompts retrieved: 1121715 . Total input tokens: 250060486 . Total output tokens: 224302544
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.253078357782215,
    "estimated_duration": 3600.0679472485285,
    "input_throughput": 3890.4890699922953,
    "output_throughput": 3419.0154686961737,
    "total_throughput": 7309.504538688469,
    "itl": 249.1365504956416,
    "ttft": 2155051.5229546097,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.783484862446784,
    "arrivals": 374287,
    "finished_requests": 56487,
    "scheduler_time": 35.05763329179996
}
#Debug simulation 
Total elapsed time: 4.253177964128554. Arrivals time: 0.21111747808754444 Scheduler time: 3.949652453418821 Scheduler overhead time: 0.02288535190746188 Adapter cache time: 0.03496196959167719 Engine time: 0.0239191222935915 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-16/adapters_256_slots_256_rate_0.8-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-16/adapters_256_slots_256_rate_0.8-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 135, 8640, 8640, 135, 8640, 4320, 8640, 135, 4320, 135, 8640, 4320, 4320, 4320, 4320, 8640, 135, 135, 135, 4320, 8640, 135, 8640, 8640, 4320, 4320, 4320, 135, 8640, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 8640, 4320, 135, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 135, 8640, 8640, 4320, 135, 135, 8640, 4320, 135, 4320, 4320, 8640, 4320, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 8640, 8640, 135, 8640, 135, 4320, 8640, 8640, 8640, 4320, 135, 8640, 4320, 135, 135, 135, 135, 135, 8640, 4320, 135, 8640, 135, 8640, 135, 135, 4320, 4320, 8640, 4320, 8640, 135, 4320, 135, 8640, 8640, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 135, 4320, 8640, 8640, 135, 8640, 4320, 135, 4320, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 4320, 8640, 8640, 4320, 135, 8640, 135, 4320, 4320, 135, 4320, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 4320, 8640, 4320, 135, 4320, 8640, 4320, 8640, 135, 8640, 135, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 135, 8640, 135, 8640, 4320, 4320, 135, 4320, 8640, 4320, 4320, 8640, 135, 8640, 8640, 4320, 135, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 135, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 8640, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 135, 135, 135, 135]
Prompts retrieved: 1121715 . Total input tokens: 250060486 . Total output tokens: 224302544
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.49367418885231,
    "estimated_duration": 3600.1419670173564,
    "input_throughput": 3793.940662655582,
    "output_throughput": 3339.4210867635043,
    "total_throughput": 7133.361749419087,
    "itl": 207.80331823401454,
    "ttft": 2175117.6656604647,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8353226749482602,
    "arrivals": 374287,
    "finished_requests": 55066,
    "scheduler_time": 30.556448387833772
}
#Debug simulation 
Total elapsed time: 4.493761093821377. Arrivals time: 0.5052452348172665 Scheduler time: 3.871625581290573 Scheduler overhead time: 0.026737784035503864 Adapter cache time: 0.04986970080062747 Engine time: 0.027850480284541845 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-16/adapters_256_slots_256_rate_0.8-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-16/adapters_256_slots_256_rate_0.8-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 135, 8640, 8640, 135, 8640, 4320, 8640, 135, 4320, 135, 8640, 4320, 4320, 4320, 4320, 8640, 135, 135, 135, 4320, 8640, 135, 8640, 8640, 4320, 4320, 4320, 135, 8640, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 8640, 4320, 135, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 135, 8640, 8640, 4320, 135, 135, 8640, 4320, 135, 4320, 4320, 8640, 4320, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 8640, 8640, 135, 8640, 135, 4320, 8640, 8640, 8640, 4320, 135, 8640, 4320, 135, 135, 135, 135, 135, 8640, 4320, 135, 8640, 135, 8640, 135, 135, 4320, 4320, 8640, 4320, 8640, 135, 4320, 135, 8640, 8640, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 135, 4320, 8640, 8640, 135, 8640, 4320, 135, 4320, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 4320, 8640, 8640, 4320, 135, 8640, 135, 4320, 4320, 135, 4320, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 4320, 8640, 4320, 135, 4320, 8640, 4320, 8640, 135, 8640, 135, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 135, 8640, 135, 8640, 4320, 4320, 135, 4320, 8640, 4320, 4320, 8640, 135, 8640, 8640, 4320, 135, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 135, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 8640, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 135, 135, 135, 135]
Prompts retrieved: 1121715 . Total input tokens: 250060486 . Total output tokens: 224302544
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.16472726687789,
    "estimated_duration": 3600.2269334297853,
    "input_throughput": 3794.810786270246,
    "output_throughput": 3339.9300161739407,
    "total_throughput": 7134.740802444187,
    "itl": 207.97080231418087,
    "ttft": 2175083.64727033,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8005920728808292,
    "arrivals": 374287,
    "finished_requests": 55081,
    "scheduler_time": 30.580702442835538
}
#Debug simulation 
Total elapsed time: 4.164846236817539. Arrivals time: 0.23231934616342187 Scheduler time: 3.8147810106165707 Scheduler overhead time: 0.02678707055747509 Adapter cache time: 0.05067953001707792 Engine time: 0.027728740125894547 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-16/adapters_256_slots_256_rate_0.8-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-16/adapters_256_slots_256_rate_0.8-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 135, 8640, 8640, 135, 8640, 4320, 8640, 135, 4320, 135, 8640, 4320, 4320, 4320, 4320, 8640, 135, 135, 135, 4320, 8640, 135, 8640, 8640, 4320, 4320, 4320, 135, 8640, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 8640, 4320, 135, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 135, 8640, 8640, 4320, 135, 135, 8640, 4320, 135, 4320, 4320, 8640, 4320, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 8640, 8640, 135, 8640, 135, 4320, 8640, 8640, 8640, 4320, 135, 8640, 4320, 135, 135, 135, 135, 135, 8640, 4320, 135, 8640, 135, 8640, 135, 135, 4320, 4320, 8640, 4320, 8640, 135, 4320, 135, 8640, 8640, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 135, 4320, 8640, 8640, 135, 8640, 4320, 135, 4320, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 4320, 8640, 8640, 4320, 135, 8640, 135, 4320, 4320, 135, 4320, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 4320, 8640, 4320, 135, 4320, 8640, 4320, 8640, 135, 8640, 135, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 135, 8640, 135, 8640, 4320, 4320, 135, 4320, 8640, 4320, 4320, 8640, 135, 8640, 8640, 4320, 135, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 135, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 8640, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 135, 135, 135, 135]
Prompts retrieved: 1121715 . Total input tokens: 250060486 . Total output tokens: 224302544
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.451170795131475,
    "estimated_duration": 3600.177617998066,
    "input_throughput": 3794.7772164632515,
    "output_throughput": 3339.7921646671543,
    "total_throughput": 7134.569381130405,
    "itl": 207.98609895853193,
    "ttft": 2175158.334768166,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.765452875494958,
    "arrivals": 374287,
    "finished_requests": 55078,
    "scheduler_time": 30.58390275024751
}
#Debug simulation 
Total elapsed time: 4.451234519015998. Arrivals time: 0.24124926840886474 Scheduler time: 4.093590678181499 Scheduler overhead time: 0.026799208018928766 Adapter cache time: 0.049634525552392006 Engine time: 0.027492199558764696 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-8/adapters_256_slots_256_rate_0.8-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-8/adapters_256_slots_256_rate_0.8-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 66, 8640, 8640, 66, 8640, 4320, 8640, 66, 4320, 66, 8640, 4320, 4320, 4320, 4320, 8640, 66, 66, 66, 4320, 8640, 66, 8640, 8640, 4320, 4320, 4320, 66, 8640, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 8640, 4320, 66, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 66, 8640, 8640, 4320, 66, 66, 8640, 4320, 66, 4320, 4320, 8640, 4320, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 8640, 8640, 66, 8640, 66, 4320, 8640, 8640, 8640, 4320, 66, 8640, 4320, 66, 66, 66, 66, 66, 8640, 4320, 66, 8640, 66, 8640, 66, 66, 4320, 4320, 8640, 4320, 8640, 66, 4320, 66, 8640, 8640, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 66, 4320, 8640, 8640, 66, 8640, 4320, 66, 4320, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 4320, 8640, 8640, 4320, 66, 8640, 66, 4320, 4320, 66, 4320, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 4320, 8640, 4320, 66, 4320, 8640, 4320, 8640, 66, 8640, 66, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 66, 8640, 66, 8640, 4320, 4320, 66, 4320, 8640, 4320, 4320, 8640, 66, 8640, 8640, 4320, 66, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 66, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 8640, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 66, 66, 66, 66]
Prompts retrieved: 1115850 . Total input tokens: 248770296 . Total output tokens: 223140963
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.236818014178425,
    "estimated_duration": 3600.054238978438,
    "input_throughput": 3940.341466640042,
    "output_throughput": 3484.263060314166,
    "total_throughput": 7424.604526954208,
    "itl": 245.71293486825041,
    "ttft": 2145914.0820240066,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 252,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.771242911471053,
    "arrivals": 372356,
    "finished_requests": 57337,
    "scheduler_time": 35.76324463261984
}
#Debug simulation 
Total elapsed time: 4.236915457993746. Arrivals time: 0.22295855032280087 Scheduler time: 3.928706728387624 Scheduler overhead time: 0.023163448553532362 Adapter cache time: 0.027575078420341015 Engine time: 0.023785492405295372 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-16/adapters_256_slots_256_rate_0.8-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-16/adapters_256_slots_256_rate_0.8-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 66, 8640, 8640, 66, 8640, 4320, 8640, 66, 4320, 66, 8640, 4320, 4320, 4320, 4320, 8640, 66, 66, 66, 4320, 8640, 66, 8640, 8640, 4320, 4320, 4320, 66, 8640, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 8640, 4320, 66, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 66, 8640, 8640, 4320, 66, 66, 8640, 4320, 66, 4320, 4320, 8640, 4320, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 8640, 8640, 66, 8640, 66, 4320, 8640, 8640, 8640, 4320, 66, 8640, 4320, 66, 66, 66, 66, 66, 8640, 4320, 66, 8640, 66, 8640, 66, 66, 4320, 4320, 8640, 4320, 8640, 66, 4320, 66, 8640, 8640, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 66, 4320, 8640, 8640, 66, 8640, 4320, 66, 4320, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 4320, 8640, 8640, 4320, 66, 8640, 66, 4320, 4320, 66, 4320, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 4320, 8640, 4320, 66, 4320, 8640, 4320, 8640, 66, 8640, 66, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 66, 8640, 66, 8640, 4320, 4320, 66, 4320, 8640, 4320, 4320, 8640, 66, 8640, 8640, 4320, 66, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 66, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 8640, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 66, 66, 66, 66]
Prompts retrieved: 1115850 . Total input tokens: 248770296 . Total output tokens: 223140963
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.199667125940323,
    "estimated_duration": 3600.126806676377,
    "input_throughput": 3829.1881759372745,
    "output_throughput": 3390.8383386278188,
    "total_throughput": 7220.026514565093,
    "itl": 205.6352956225013,
    "ttft": 2167065.8322397405,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 252,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8221366878133305,
    "arrivals": 372356,
    "finished_requests": 55661,
    "scheduler_time": 31.09608696429213
}
#Debug simulation 
Total elapsed time: 4.199763901997358. Arrivals time: 0.20201457291841507 Scheduler time: 3.888480550609529 Scheduler overhead time: 0.027129209134727716 Adapter cache time: 0.04163394123315811 Engine time: 0.027882182504981756 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-16/adapters_256_slots_256_rate_0.8-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-16/adapters_256_slots_256_rate_0.8-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 66, 8640, 8640, 66, 8640, 4320, 8640, 66, 4320, 66, 8640, 4320, 4320, 4320, 4320, 8640, 66, 66, 66, 4320, 8640, 66, 8640, 8640, 4320, 4320, 4320, 66, 8640, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 8640, 4320, 66, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 66, 8640, 8640, 4320, 66, 66, 8640, 4320, 66, 4320, 4320, 8640, 4320, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 8640, 8640, 66, 8640, 66, 4320, 8640, 8640, 8640, 4320, 66, 8640, 4320, 66, 66, 66, 66, 66, 8640, 4320, 66, 8640, 66, 8640, 66, 66, 4320, 4320, 8640, 4320, 8640, 66, 4320, 66, 8640, 8640, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 66, 4320, 8640, 8640, 66, 8640, 4320, 66, 4320, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 4320, 8640, 8640, 4320, 66, 8640, 66, 4320, 4320, 66, 4320, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 4320, 8640, 4320, 66, 4320, 8640, 4320, 8640, 66, 8640, 66, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 66, 8640, 66, 8640, 4320, 4320, 66, 4320, 8640, 4320, 4320, 8640, 66, 8640, 8640, 4320, 66, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 66, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 8640, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 66, 66, 66, 66]
Prompts retrieved: 1115850 . Total input tokens: 248770296 . Total output tokens: 223140963
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.175196326803416,
    "estimated_duration": 3600.164802121318,
    "input_throughput": 3829.6449628850614,
    "output_throughput": 3391.373359576711,
    "total_throughput": 7221.018322461772,
    "itl": 205.79467511989196,
    "ttft": 2167010.9469030583,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 252,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7878146810643397,
    "arrivals": 372356,
    "finished_requests": 55671,
    "scheduler_time": 31.122235461340495
}
#Debug simulation 
Total elapsed time: 4.1752969599328935. Arrivals time: 0.20816057501360774 Scheduler time: 3.858025599271059 Scheduler overhead time: 0.02700942475348711 Adapter cache time: 0.04162970604375005 Engine time: 0.02777817752212286 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-16/adapters_256_slots_256_rate_0.8-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-16/adapters_256_slots_256_rate_0.8-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 66, 8640, 8640, 66, 8640, 4320, 8640, 66, 4320, 66, 8640, 4320, 4320, 4320, 4320, 8640, 66, 66, 66, 4320, 8640, 66, 8640, 8640, 4320, 4320, 4320, 66, 8640, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 8640, 4320, 66, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 66, 8640, 8640, 4320, 66, 66, 8640, 4320, 66, 4320, 4320, 8640, 4320, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 8640, 8640, 66, 8640, 66, 4320, 8640, 8640, 8640, 4320, 66, 8640, 4320, 66, 66, 66, 66, 66, 8640, 4320, 66, 8640, 66, 8640, 66, 66, 4320, 4320, 8640, 4320, 8640, 66, 4320, 66, 8640, 8640, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 66, 4320, 8640, 8640, 66, 8640, 4320, 66, 4320, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 4320, 8640, 8640, 4320, 66, 8640, 66, 4320, 4320, 66, 4320, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 4320, 8640, 4320, 66, 4320, 8640, 4320, 8640, 66, 8640, 66, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 66, 8640, 66, 8640, 4320, 4320, 66, 4320, 8640, 4320, 4320, 8640, 66, 8640, 8640, 4320, 66, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 66, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 8640, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 66, 66, 66, 66]
Prompts retrieved: 1115850 . Total input tokens: 248770296 . Total output tokens: 223140963
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.200933967716992,
    "estimated_duration": 3600.029777922064,
    "input_throughput": 3829.5922118615495,
    "output_throughput": 3391.044172708586,
    "total_throughput": 7220.636384570135,
    "itl": 205.83051262364998,
    "ttft": 2167014.1580838347,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 252,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7534926743153493,
    "arrivals": 372356,
    "finished_requests": 55666,
    "scheduler_time": 31.123200188371417
}
#Debug simulation 
Total elapsed time: 4.201031319797039. Arrivals time: 0.20412136893719435 Scheduler time: 3.8871423532254994 Scheduler overhead time: 0.02708866400644183 Adapter cache time: 0.04228792665526271 Engine time: 0.027785858605057 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-8/adapters_256_slots_256_rate_0.8-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-8/adapters_256_slots_256_rate_0.8-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 33, 8640, 8640, 33, 8640, 4320, 8640, 33, 4320, 33, 8640, 4320, 4320, 4320, 4320, 8640, 33, 33, 33, 4320, 8640, 33, 8640, 8640, 4320, 4320, 4320, 33, 8640, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 8640, 4320, 33, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 33, 8640, 8640, 4320, 33, 33, 8640, 4320, 33, 4320, 4320, 8640, 4320, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 8640, 8640, 33, 8640, 33, 4320, 8640, 8640, 8640, 4320, 33, 8640, 4320, 33, 33, 33, 33, 33, 8640, 4320, 33, 8640, 33, 8640, 33, 33, 4320, 4320, 8640, 4320, 8640, 33, 4320, 33, 8640, 8640, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 33, 4320, 8640, 8640, 33, 8640, 4320, 33, 4320, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 4320, 8640, 8640, 4320, 33, 8640, 33, 4320, 4320, 33, 4320, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 4320, 8640, 4320, 33, 4320, 8640, 4320, 8640, 33, 8640, 33, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 33, 8640, 33, 8640, 4320, 4320, 33, 4320, 8640, 4320, 4320, 8640, 33, 8640, 8640, 4320, 33, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 33, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 8640, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 33, 33, 33, 33]
Prompts retrieved: 1113045 . Total input tokens: 248170653 . Total output tokens: 222577894
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.25364151597023,
    "estimated_duration": 3600.235092812373,
    "input_throughput": 3992.442890381295,
    "output_throughput": 3504.767792856351,
    "total_throughput": 7497.210683237646,
    "itl": 243.04321114160592,
    "ttft": 2130797.399236947,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 239,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7314565707999272,
    "arrivals": 371350,
    "finished_requests": 58166,
    "scheduler_time": 35.894226013806254
}
#Debug simulation 
Total elapsed time: 4.253744715824723. Arrivals time: 0.2098580519668758 Scheduler time: 3.964033880736679 Scheduler overhead time: 0.02324409084394574 Adapter cache time: 0.021944040898233652 Engine time: 0.023868330288678408 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-16/adapters_256_slots_256_rate_0.8-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-16/adapters_256_slots_256_rate_0.8-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 33, 8640, 8640, 33, 8640, 4320, 8640, 33, 4320, 33, 8640, 4320, 4320, 4320, 4320, 8640, 33, 33, 33, 4320, 8640, 33, 8640, 8640, 4320, 4320, 4320, 33, 8640, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 8640, 4320, 33, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 33, 8640, 8640, 4320, 33, 33, 8640, 4320, 33, 4320, 4320, 8640, 4320, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 8640, 8640, 33, 8640, 33, 4320, 8640, 8640, 8640, 4320, 33, 8640, 4320, 33, 33, 33, 33, 33, 8640, 4320, 33, 8640, 33, 8640, 33, 33, 4320, 4320, 8640, 4320, 8640, 33, 4320, 33, 8640, 8640, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 33, 4320, 8640, 8640, 33, 8640, 4320, 33, 4320, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 4320, 8640, 8640, 4320, 33, 8640, 33, 4320, 4320, 33, 4320, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 4320, 8640, 4320, 33, 4320, 8640, 4320, 8640, 33, 8640, 33, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 33, 8640, 33, 8640, 4320, 4320, 33, 4320, 8640, 4320, 4320, 8640, 33, 8640, 8640, 4320, 33, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 33, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 8640, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 33, 33, 33, 33]
Prompts retrieved: 1113045 . Total input tokens: 248170653 . Total output tokens: 222577894
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.193054518196732,
    "estimated_duration": 3600.1855976252223,
    "input_throughput": 3876.275436801173,
    "output_throughput": 3405.140281680603,
    "total_throughput": 7281.415718481776,
    "itl": 204.25034175281746,
    "ttft": 2152879.1842083316,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 238,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7770072211371766,
    "arrivals": 371350,
    "finished_requests": 56423,
    "scheduler_time": 31.23025759917192
}
#Debug simulation 
Total elapsed time: 4.193177774082869. Arrivals time: 0.20903209131211042 Scheduler time: 3.8799651516601443 Scheduler overhead time: 0.027149256318807602 Adapter cache time: 0.036198565736413 Engine time: 0.02814170904457569 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-16/adapters_256_slots_256_rate_0.8-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-16/adapters_256_slots_256_rate_0.8-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 33, 8640, 8640, 33, 8640, 4320, 8640, 33, 4320, 33, 8640, 4320, 4320, 4320, 4320, 8640, 33, 33, 33, 4320, 8640, 33, 8640, 8640, 4320, 4320, 4320, 33, 8640, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 8640, 4320, 33, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 33, 8640, 8640, 4320, 33, 33, 8640, 4320, 33, 4320, 4320, 8640, 4320, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 8640, 8640, 33, 8640, 33, 4320, 8640, 8640, 8640, 4320, 33, 8640, 4320, 33, 33, 33, 33, 33, 8640, 4320, 33, 8640, 33, 8640, 33, 33, 4320, 4320, 8640, 4320, 8640, 33, 4320, 33, 8640, 8640, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 33, 4320, 8640, 8640, 33, 8640, 4320, 33, 4320, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 4320, 8640, 8640, 4320, 33, 8640, 33, 4320, 4320, 33, 4320, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 4320, 8640, 4320, 33, 4320, 8640, 4320, 8640, 33, 8640, 33, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 33, 8640, 33, 8640, 4320, 4320, 33, 4320, 8640, 4320, 4320, 8640, 33, 8640, 8640, 4320, 33, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 33, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 8640, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 33, 33, 33, 33]
Prompts retrieved: 1113045 . Total input tokens: 248170653 . Total output tokens: 222577894
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.234341674018651,
    "estimated_duration": 3600.116168672739,
    "input_throughput": 3876.6021278544636,
    "output_throughput": 3405.333724139176,
    "total_throughput": 7281.9358519936395,
    "itl": 204.2753525739594,
    "ttft": 2152910.5339841633,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 238,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.744728190980388,
    "arrivals": 371350,
    "finished_requests": 56426,
    "scheduler_time": 31.23617385218534
}
#Debug simulation 
Total elapsed time: 4.2344386470504105. Arrivals time: 0.20736673148348927 Scheduler time: 3.922995474655181 Scheduler overhead time: 0.027152811642736197 Adapter cache time: 0.03620707616209984 Engine time: 0.02797514107078314 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-16/adapters_256_slots_256_rate_0.8-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-16/adapters_256_slots_256_rate_0.8-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 33, 8640, 8640, 33, 8640, 4320, 8640, 33, 4320, 33, 8640, 4320, 4320, 4320, 4320, 8640, 33, 33, 33, 4320, 8640, 33, 8640, 8640, 4320, 4320, 4320, 33, 8640, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 8640, 4320, 33, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 33, 8640, 8640, 4320, 33, 33, 8640, 4320, 33, 4320, 4320, 8640, 4320, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 8640, 8640, 33, 8640, 33, 4320, 8640, 8640, 8640, 4320, 33, 8640, 4320, 33, 33, 33, 33, 33, 8640, 4320, 33, 8640, 33, 8640, 33, 33, 4320, 4320, 8640, 4320, 8640, 33, 4320, 33, 8640, 8640, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 33, 4320, 8640, 8640, 33, 8640, 4320, 33, 4320, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 4320, 8640, 8640, 4320, 33, 8640, 33, 4320, 4320, 33, 4320, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 4320, 8640, 4320, 33, 4320, 8640, 4320, 8640, 33, 8640, 33, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 33, 8640, 33, 8640, 4320, 4320, 33, 4320, 8640, 4320, 4320, 8640, 33, 8640, 8640, 4320, 33, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 33, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 8640, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 33, 33, 33, 33]
Prompts retrieved: 1113045 . Total input tokens: 248170653 . Total output tokens: 222577894
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.213659994769841,
    "estimated_duration": 3600.2119339049173,
    "input_throughput": 3876.470123485954,
    "output_throughput": 3405.182590654613,
    "total_throughput": 7281.652714140567,
    "itl": 204.2380757937374,
    "ttft": 2152851.1105218017,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 238,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7116319701867188,
    "arrivals": 371350,
    "finished_requests": 56425,
    "scheduler_time": 31.229367816805066
}
#Debug simulation 
Total elapsed time: 4.213762689847499. Arrivals time: 0.2053336058743298 Scheduler time: 3.9029650548473 Scheduler overhead time: 0.02725111274048686 Adapter cache time: 0.03669831156730652 Engine time: 0.028872239869087934 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-8/adapters_256_slots_256_rate_0.8-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-8/adapters_256_slots_256_rate_0.8-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 540, 8640, 8640, 540, 8640, 1080, 8640, 540, 1080, 540, 8640, 1080, 1080, 1080, 1080, 8640, 540, 540, 540, 1080, 8640, 540, 8640, 8640, 1080, 1080, 1080, 540, 8640, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 8640, 1080, 540, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 540, 8640, 8640, 1080, 540, 540, 8640, 1080, 540, 1080, 1080, 8640, 1080, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 8640, 8640, 540, 8640, 540, 1080, 8640, 8640, 8640, 1080, 540, 8640, 1080, 540, 540, 540, 540, 540, 8640, 1080, 540, 8640, 540, 8640, 540, 540, 1080, 1080, 8640, 1080, 8640, 540, 1080, 540, 8640, 8640, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 540, 1080, 8640, 8640, 540, 8640, 1080, 540, 1080, 8640, 540, 540, 540, 540, 540, 540, 8640, 540, 540, 540, 8640, 540, 1080, 8640, 8640, 1080, 540, 8640, 540, 1080, 1080, 540, 1080, 540, 8640, 540, 540, 8640, 540, 8640, 8640, 1080, 8640, 1080, 540, 1080, 8640, 1080, 8640, 540, 8640, 540, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 540, 8640, 540, 8640, 1080, 1080, 540, 1080, 8640, 1080, 1080, 8640, 540, 8640, 8640, 1080, 540, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 540, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 8640, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 540, 540, 540, 540]
Prompts retrieved: 880740 . Total input tokens: 196366859 . Total output tokens: 176168866
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.18967640819028,
    "estimated_duration": 3600.2479947007864,
    "input_throughput": 3789.0809244471907,
    "output_throughput": 3349.30371956284,
    "total_throughput": 7138.384644010031,
    "itl": 255.58936778777706,
    "ttft": 2113561.805255535,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.783484862446784,
    "arrivals": 293562,
    "finished_requests": 55255,
    "scheduler_time": 34.54278177929428
}
#Debug simulation 
Total elapsed time: 4.189778126310557. Arrivals time: 0.20318892318755388 Scheduler time: 3.8397196079604328 Scheduler overhead time: 0.02253582328557968 Adapter cache time: 0.09029493201524019 Engine time: 0.02355268457904458 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-16/adapters_256_slots_256_rate_0.8-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-16/adapters_256_slots_256_rate_0.8-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 540, 8640, 8640, 540, 8640, 1080, 8640, 540, 1080, 540, 8640, 1080, 1080, 1080, 1080, 8640, 540, 540, 540, 1080, 8640, 540, 8640, 8640, 1080, 1080, 1080, 540, 8640, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 8640, 1080, 540, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 540, 8640, 8640, 1080, 540, 540, 8640, 1080, 540, 1080, 1080, 8640, 1080, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 8640, 8640, 540, 8640, 540, 1080, 8640, 8640, 8640, 1080, 540, 8640, 1080, 540, 540, 540, 540, 540, 8640, 1080, 540, 8640, 540, 8640, 540, 540, 1080, 1080, 8640, 1080, 8640, 540, 1080, 540, 8640, 8640, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 540, 1080, 8640, 8640, 540, 8640, 1080, 540, 1080, 8640, 540, 540, 540, 540, 540, 540, 8640, 540, 540, 540, 8640, 540, 1080, 8640, 8640, 1080, 540, 8640, 540, 1080, 1080, 540, 1080, 540, 8640, 540, 540, 8640, 540, 8640, 8640, 1080, 8640, 1080, 540, 1080, 8640, 1080, 8640, 540, 8640, 540, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 540, 8640, 540, 8640, 1080, 1080, 540, 1080, 8640, 1080, 1080, 8640, 540, 8640, 8640, 1080, 540, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 540, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 8640, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 540, 540, 540, 540]
Prompts retrieved: 880740 . Total input tokens: 196366859 . Total output tokens: 176168866
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.249840684235096,
    "estimated_duration": 3600.0813197884972,
    "input_throughput": 3801.5285723612583,
    "output_throughput": 3367.85753514932,
    "total_throughput": 7169.386107510579,
    "itl": 206.75682561872927,
    "ttft": 2115902.0242613885,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8353226749482604,
    "arrivals": 293562,
    "finished_requests": 55421,
    "scheduler_time": 31.05183547953821
}
#Debug simulation 
Total elapsed time: 4.249965046998113. Arrivals time: 0.1961272326298058 Scheduler time: 3.876986331772059 Scheduler overhead time: 0.027126160915941 Adapter cache time: 0.10884014796465635 Engine time: 0.028197365812957287 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-16-16/adapters_256_slots_256_rate_0.8-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-16-16/adapters_256_slots_256_rate_0.8-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 540, 8640, 8640, 540, 8640, 1080, 8640, 540, 1080, 540, 8640, 1080, 1080, 1080, 1080, 8640, 540, 540, 540, 1080, 8640, 540, 8640, 8640, 1080, 1080, 1080, 540, 8640, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 8640, 1080, 540, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 540, 8640, 8640, 1080, 540, 540, 8640, 1080, 540, 1080, 1080, 8640, 1080, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 8640, 8640, 540, 8640, 540, 1080, 8640, 8640, 8640, 1080, 540, 8640, 1080, 540, 540, 540, 540, 540, 8640, 1080, 540, 8640, 540, 8640, 540, 540, 1080, 1080, 8640, 1080, 8640, 540, 1080, 540, 8640, 8640, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 540, 1080, 8640, 8640, 540, 8640, 1080, 540, 1080, 8640, 540, 540, 540, 540, 540, 540, 8640, 540, 540, 540, 8640, 540, 1080, 8640, 8640, 1080, 540, 8640, 540, 1080, 1080, 540, 1080, 540, 8640, 540, 540, 8640, 540, 8640, 8640, 1080, 8640, 1080, 540, 1080, 8640, 1080, 8640, 540, 8640, 540, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 540, 8640, 540, 8640, 1080, 1080, 540, 1080, 8640, 1080, 1080, 8640, 540, 8640, 8640, 1080, 540, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 540, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 8640, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 540, 540, 540, 540]
Prompts retrieved: 880740 . Total input tokens: 196366859 . Total output tokens: 176168866
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.237616227939725,
    "estimated_duration": 3600.178815978711,
    "input_throughput": 3801.7228308920016,
    "output_throughput": 3367.763830559603,
    "total_throughput": 7169.486661451605,
    "itl": 207.61994845229657,
    "ttft": 2115933.9891346805,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8005920728808297,
    "arrivals": 293562,
    "finished_requests": 55424,
    "scheduler_time": 31.13449812044599
}
#Debug simulation 
Total elapsed time: 4.237713786773384. Arrivals time: 0.19610422616824508 Scheduler time: 3.865824450738728 Scheduler overhead time: 0.027042318135499954 Adapter cache time: 0.10838894825428724 Engine time: 0.027815830428153276 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_16-16-16/adapters_256_slots_256_rate_0.8-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_16-16-16/adapters_256_slots_256_rate_0.8-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 540, 8640, 8640, 540, 8640, 1080, 8640, 540, 1080, 540, 8640, 1080, 1080, 1080, 1080, 8640, 540, 540, 540, 1080, 8640, 540, 8640, 8640, 1080, 1080, 1080, 540, 8640, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 8640, 1080, 540, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 540, 8640, 8640, 1080, 540, 540, 8640, 1080, 540, 1080, 1080, 8640, 1080, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 8640, 8640, 540, 8640, 540, 1080, 8640, 8640, 8640, 1080, 540, 8640, 1080, 540, 540, 540, 540, 540, 8640, 1080, 540, 8640, 540, 8640, 540, 540, 1080, 1080, 8640, 1080, 8640, 540, 1080, 540, 8640, 8640, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 540, 1080, 8640, 8640, 540, 8640, 1080, 540, 1080, 8640, 540, 540, 540, 540, 540, 540, 8640, 540, 540, 540, 8640, 540, 1080, 8640, 8640, 1080, 540, 8640, 540, 1080, 1080, 540, 1080, 540, 8640, 540, 540, 8640, 540, 8640, 8640, 1080, 8640, 1080, 540, 1080, 8640, 1080, 8640, 540, 8640, 540, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 540, 8640, 540, 8640, 1080, 1080, 540, 1080, 8640, 1080, 1080, 8640, 540, 8640, 8640, 1080, 540, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 540, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 8640, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 540, 540, 540, 540]
Prompts retrieved: 880740 . Total input tokens: 196366859 . Total output tokens: 176168866
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.270987547934055,
    "estimated_duration": 3600.1603876983872,
    "input_throughput": 3801.63312911453,
    "output_throughput": 3367.574134037637,
    "total_throughput": 7169.207263152167,
    "itl": 207.62228335877631,
    "ttft": 2115930.3519403227,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.765452875494958,
    "arrivals": 293562,
    "finished_requests": 55423,
    "scheduler_time": 31.134796461917244
}
#Debug simulation 
Total elapsed time: 4.271089675836265. Arrivals time: 0.2080455096438527 Scheduler time: 3.884971479419619 Scheduler overhead time: 0.027271614409983158 Adapter cache time: 0.11004209099337459 Engine time: 0.028077589813619852 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-8/adapters_256_slots_256_rate_0.8-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-8/adapters_256_slots_256_rate_0.8-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 270, 8640, 8640, 270, 8640, 1080, 8640, 270, 1080, 270, 8640, 1080, 1080, 1080, 1080, 8640, 270, 270, 270, 1080, 8640, 270, 8640, 8640, 1080, 1080, 1080, 270, 8640, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 8640, 1080, 270, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 270, 8640, 8640, 1080, 270, 270, 8640, 1080, 270, 1080, 1080, 8640, 1080, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 8640, 8640, 270, 8640, 270, 1080, 8640, 8640, 8640, 1080, 270, 8640, 1080, 270, 270, 270, 270, 270, 8640, 1080, 270, 8640, 270, 8640, 270, 270, 1080, 1080, 8640, 1080, 8640, 270, 1080, 270, 8640, 8640, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 270, 1080, 8640, 8640, 270, 8640, 1080, 270, 1080, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 1080, 8640, 8640, 1080, 270, 8640, 270, 1080, 1080, 270, 1080, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 1080, 8640, 1080, 270, 1080, 8640, 1080, 8640, 270, 8640, 270, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 270, 8640, 270, 8640, 1080, 1080, 270, 1080, 8640, 1080, 1080, 8640, 270, 8640, 8640, 1080, 270, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 270, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 8640, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 270, 270, 270, 270]
Prompts retrieved: 857790 . Total input tokens: 191327038 . Total output tokens: 171596853
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.440835081972182,
    "estimated_duration": 3600.057841402989,
    "input_throughput": 4030.6677390341642,
    "output_throughput": 3558.074498883068,
    "total_throughput": 7588.742237917232,
    "itl": 240.74441505135573,
    "ttft": 2069415.574715595,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.783484862446784,
    "arrivals": 285871,
    "finished_requests": 58638,
    "scheduler_time": 36.67047090811323
}
#Debug simulation 
Total elapsed time: 4.440933133941144. Arrivals time: 0.22836976451799273 Scheduler time: 4.0714891026727855 Scheduler overhead time: 0.023661088664084673 Adapter cache time: 0.0817496757954359 Engine time: 0.024616756476461887 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-16/adapters_256_slots_256_rate_0.8-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-16/adapters_256_slots_256_rate_0.8-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 270, 8640, 8640, 270, 8640, 1080, 8640, 270, 1080, 270, 8640, 1080, 1080, 1080, 1080, 8640, 270, 270, 270, 1080, 8640, 270, 8640, 8640, 1080, 1080, 1080, 270, 8640, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 8640, 1080, 270, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 270, 8640, 8640, 1080, 270, 270, 8640, 1080, 270, 1080, 1080, 8640, 1080, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 8640, 8640, 270, 8640, 270, 1080, 8640, 8640, 8640, 1080, 270, 8640, 1080, 270, 270, 270, 270, 270, 8640, 1080, 270, 8640, 270, 8640, 270, 270, 1080, 1080, 8640, 1080, 8640, 270, 1080, 270, 8640, 8640, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 270, 1080, 8640, 8640, 270, 8640, 1080, 270, 1080, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 1080, 8640, 8640, 1080, 270, 8640, 270, 1080, 1080, 270, 1080, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 1080, 8640, 1080, 270, 1080, 8640, 1080, 8640, 270, 8640, 270, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 270, 8640, 270, 8640, 1080, 1080, 270, 1080, 8640, 1080, 1080, 8640, 270, 8640, 8640, 1080, 270, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 270, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 8640, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 270, 270, 270, 270]
Prompts retrieved: 857790 . Total input tokens: 191327038 . Total output tokens: 171596853
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.707559056114405,
    "estimated_duration": 3600.145751678869,
    "input_throughput": 4015.9776845861584,
    "output_throughput": 3553.945557352335,
    "total_throughput": 7569.923241938493,
    "itl": 196.29044011396226,
    "ttft": 2075238.215342038,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8353226749482604,
    "arrivals": 285871,
    "finished_requests": 58444,
    "scheduler_time": 32.86851998277882
}
#Debug simulation 
Total elapsed time: 4.707624381873757. Arrivals time: 0.4532365072518587 Scheduler time: 4.085230570286512 Scheduler overhead time: 0.028696270659565926 Adapter cache time: 0.09756932407617569 Engine time: 0.02955740876495838 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-16-16/adapters_256_slots_256_rate_0.8-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-16-16/adapters_256_slots_256_rate_0.8-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 270, 8640, 8640, 270, 8640, 1080, 8640, 270, 1080, 270, 8640, 1080, 1080, 1080, 1080, 8640, 270, 270, 270, 1080, 8640, 270, 8640, 8640, 1080, 1080, 1080, 270, 8640, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 8640, 1080, 270, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 270, 8640, 8640, 1080, 270, 270, 8640, 1080, 270, 1080, 1080, 8640, 1080, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 8640, 8640, 270, 8640, 270, 1080, 8640, 8640, 8640, 1080, 270, 8640, 1080, 270, 270, 270, 270, 270, 8640, 1080, 270, 8640, 270, 8640, 270, 270, 1080, 1080, 8640, 1080, 8640, 270, 1080, 270, 8640, 8640, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 270, 1080, 8640, 8640, 270, 8640, 1080, 270, 1080, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 1080, 8640, 8640, 1080, 270, 8640, 270, 1080, 1080, 270, 1080, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 1080, 8640, 1080, 270, 1080, 8640, 1080, 8640, 270, 8640, 270, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 270, 8640, 270, 8640, 1080, 1080, 270, 1080, 8640, 1080, 1080, 8640, 270, 8640, 8640, 1080, 270, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 270, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 8640, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 270, 270, 270, 270]
Prompts retrieved: 857790 . Total input tokens: 191327038 . Total output tokens: 171596853
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.466157342772931,
    "estimated_duration": 3600.212960444081,
    "input_throughput": 4015.9027143262697,
    "output_throughput": 3553.879212306871,
    "total_throughput": 7569.781926633141,
    "itl": 196.30040167633987,
    "ttft": 2075279.4669320337,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8005920728808291,
    "arrivals": 285871,
    "finished_requests": 58444,
    "scheduler_time": 32.87027723261689
}
#Debug simulation 
Total elapsed time: 4.466257380787283. Arrivals time: 0.23495054431259632 Scheduler time: 4.062441750429571 Scheduler overhead time: 0.028475334867835045 Adapter cache time: 0.09769557835534215 Engine time: 0.029419927392154932 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_16-16-16/adapters_256_slots_256_rate_0.8-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_16-16-16/adapters_256_slots_256_rate_0.8-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 270, 8640, 8640, 270, 8640, 1080, 8640, 270, 1080, 270, 8640, 1080, 1080, 1080, 1080, 8640, 270, 270, 270, 1080, 8640, 270, 8640, 8640, 1080, 1080, 1080, 270, 8640, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 8640, 1080, 270, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 270, 8640, 8640, 1080, 270, 270, 8640, 1080, 270, 1080, 1080, 8640, 1080, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 8640, 8640, 270, 8640, 270, 1080, 8640, 8640, 8640, 1080, 270, 8640, 1080, 270, 270, 270, 270, 270, 8640, 1080, 270, 8640, 270, 8640, 270, 270, 1080, 1080, 8640, 1080, 8640, 270, 1080, 270, 8640, 8640, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 270, 1080, 8640, 8640, 270, 8640, 1080, 270, 1080, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 1080, 8640, 8640, 1080, 270, 8640, 270, 1080, 1080, 270, 1080, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 1080, 8640, 1080, 270, 1080, 8640, 1080, 8640, 270, 8640, 270, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 270, 8640, 270, 8640, 1080, 1080, 270, 1080, 8640, 1080, 1080, 8640, 270, 8640, 8640, 1080, 270, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 270, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 8640, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 270, 270, 270, 270]
Prompts retrieved: 857790 . Total input tokens: 191327038 . Total output tokens: 171596853
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.723159116692841,
    "estimated_duration": 3600.0778027737747,
    "input_throughput": 4016.0534833053807,
    "output_throughput": 3554.0126355441457,
    "total_throughput": 7570.066118849527,
    "itl": 196.29745857226328,
    "ttft": 2075193.44620228,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.765452875494958,
    "arrivals": 285871,
    "finished_requests": 58444,
    "scheduler_time": 32.869836167638454
}
#Debug simulation 
Total elapsed time: 4.723221874795854. Arrivals time: 0.20715845935046673 Scheduler time: 4.34606948075816 Scheduler overhead time: 0.028754927217960358 Adapter cache time: 0.09778351802378893 Engine time: 0.02986188605427742 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-8/adapters_256_slots_256_rate_0.8-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-8/adapters_256_slots_256_rate_0.8-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 135, 8640, 8640, 135, 8640, 1080, 8640, 135, 1080, 135, 8640, 1080, 1080, 1080, 1080, 8640, 135, 135, 135, 1080, 8640, 135, 8640, 8640, 1080, 1080, 1080, 135, 8640, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 8640, 1080, 135, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 135, 8640, 8640, 1080, 135, 135, 8640, 1080, 135, 1080, 1080, 8640, 1080, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 8640, 8640, 135, 8640, 135, 1080, 8640, 8640, 8640, 1080, 135, 8640, 1080, 135, 135, 135, 135, 135, 8640, 1080, 135, 8640, 135, 8640, 135, 135, 1080, 1080, 8640, 1080, 8640, 135, 1080, 135, 8640, 8640, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 135, 1080, 8640, 8640, 135, 8640, 1080, 135, 1080, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 1080, 8640, 8640, 1080, 135, 8640, 135, 1080, 1080, 135, 1080, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 1080, 8640, 1080, 135, 1080, 8640, 1080, 8640, 135, 8640, 135, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 135, 8640, 135, 8640, 1080, 1080, 135, 1080, 8640, 1080, 1080, 8640, 135, 8640, 8640, 1080, 135, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 135, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 8640, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 135, 135, 135, 135]
Prompts retrieved: 846315 . Total input tokens: 188744173 . Total output tokens: 169308446
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.524311936926097,
    "estimated_duration": 3600.249032007342,
    "input_throughput": 4152.540523471631,
    "output_throughput": 3674.5069250456845,
    "total_throughput": 7827.047448517315,
    "itl": 233.33515296890175,
    "ttft": 2040506.4483444227,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.783484862446784,
    "arrivals": 281942,
    "finished_requests": 60613,
    "scheduler_time": 37.93035893040654
}
#Debug simulation 
Total elapsed time: 4.524418883025646. Arrivals time: 0.20858010929077864 Scheduler time: 4.185799685772508 Scheduler overhead time: 0.024579328019171953 Adapter cache time: 0.06843139789998531 Engine time: 0.025638578459620476 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-16/adapters_256_slots_256_rate_0.8-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-16/adapters_256_slots_256_rate_0.8-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 135, 8640, 8640, 135, 8640, 1080, 8640, 135, 1080, 135, 8640, 1080, 1080, 1080, 1080, 8640, 135, 135, 135, 1080, 8640, 135, 8640, 8640, 1080, 1080, 1080, 135, 8640, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 8640, 1080, 135, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 135, 8640, 8640, 1080, 135, 135, 8640, 1080, 135, 1080, 1080, 8640, 1080, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 8640, 8640, 135, 8640, 135, 1080, 8640, 8640, 8640, 1080, 135, 8640, 1080, 135, 135, 135, 135, 135, 8640, 1080, 135, 8640, 135, 8640, 135, 135, 1080, 1080, 8640, 1080, 8640, 135, 1080, 135, 8640, 8640, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 135, 1080, 8640, 8640, 135, 8640, 1080, 135, 1080, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 1080, 8640, 8640, 1080, 135, 8640, 135, 1080, 1080, 135, 1080, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 1080, 8640, 1080, 135, 1080, 8640, 1080, 8640, 135, 8640, 135, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 135, 8640, 135, 8640, 1080, 1080, 135, 1080, 8640, 1080, 1080, 8640, 135, 8640, 8640, 1080, 135, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 135, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 8640, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 135, 135, 135, 135]
Prompts retrieved: 846315 . Total input tokens: 188744173 . Total output tokens: 169308446
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.536653239745647,
    "estimated_duration": 3600.181430968121,
    "input_throughput": 4123.328305709338,
    "output_throughput": 3657.1479111427557,
    "total_throughput": 7780.476216852093,
    "itl": 191.8320922889557,
    "ttft": 2048834.7289800877,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8353226749482601,
    "arrivals": 281942,
    "finished_requests": 60221,
    "scheduler_time": 33.92874774499542
}
#Debug simulation 
Total elapsed time: 4.536751587875187. Arrivals time: 0.20651330472901464 Scheduler time: 4.17558820778504 Scheduler overhead time: 0.02933206409215927 Adapter cache time: 0.08152340119704604 Engine time: 0.03011858183890581 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-16/adapters_256_slots_256_rate_0.8-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-16/adapters_256_slots_256_rate_0.8-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 135, 8640, 8640, 135, 8640, 1080, 8640, 135, 1080, 135, 8640, 1080, 1080, 1080, 1080, 8640, 135, 135, 135, 1080, 8640, 135, 8640, 8640, 1080, 1080, 1080, 135, 8640, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 8640, 1080, 135, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 135, 8640, 8640, 1080, 135, 135, 8640, 1080, 135, 1080, 1080, 8640, 1080, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 8640, 8640, 135, 8640, 135, 1080, 8640, 8640, 8640, 1080, 135, 8640, 1080, 135, 135, 135, 135, 135, 8640, 1080, 135, 8640, 135, 8640, 135, 135, 1080, 1080, 8640, 1080, 8640, 135, 1080, 135, 8640, 8640, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 135, 1080, 8640, 8640, 135, 8640, 1080, 135, 1080, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 1080, 8640, 8640, 1080, 135, 8640, 135, 1080, 1080, 135, 1080, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 1080, 8640, 1080, 135, 1080, 8640, 1080, 8640, 135, 8640, 135, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 135, 8640, 135, 8640, 1080, 1080, 135, 1080, 8640, 1080, 1080, 8640, 135, 8640, 8640, 1080, 135, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 135, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 8640, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 135, 135, 135, 135]
Prompts retrieved: 846315 . Total input tokens: 188744173 . Total output tokens: 169308446
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.538869017735124,
    "estimated_duration": 3600.059700751472,
    "input_throughput": 4123.387175190842,
    "output_throughput": 3656.972409999725,
    "total_throughput": 7780.359585190567,
    "itl": 191.8295780063063,
    "ttft": 2048840.8652383613,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.800592072880829,
    "arrivals": 281942,
    "finished_requests": 60218,
    "scheduler_time": 33.92815507246971
}
#Debug simulation 
Total elapsed time: 4.538980911951512. Arrivals time: 0.20909548876807094 Scheduler time: 4.17495298339054 Scheduler overhead time: 0.029234466142952442 Adapter cache time: 0.08162855263799429 Engine time: 0.030389919877052307 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-16/adapters_256_slots_256_rate_0.8-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-16/adapters_256_slots_256_rate_0.8-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 135, 8640, 8640, 135, 8640, 1080, 8640, 135, 1080, 135, 8640, 1080, 1080, 1080, 1080, 8640, 135, 135, 135, 1080, 8640, 135, 8640, 8640, 1080, 1080, 1080, 135, 8640, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 8640, 1080, 135, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 135, 8640, 8640, 1080, 135, 135, 8640, 1080, 135, 1080, 1080, 8640, 1080, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 8640, 8640, 135, 8640, 135, 1080, 8640, 8640, 8640, 1080, 135, 8640, 1080, 135, 135, 135, 135, 135, 8640, 1080, 135, 8640, 135, 8640, 135, 135, 1080, 1080, 8640, 1080, 8640, 135, 1080, 135, 8640, 8640, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 135, 1080, 8640, 8640, 135, 8640, 1080, 135, 1080, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 1080, 8640, 8640, 1080, 135, 8640, 135, 1080, 1080, 135, 1080, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 1080, 8640, 1080, 135, 1080, 8640, 1080, 8640, 135, 8640, 135, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 135, 8640, 135, 8640, 1080, 1080, 135, 1080, 8640, 1080, 1080, 8640, 135, 8640, 8640, 1080, 135, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 135, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 8640, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 135, 135, 135, 135]
Prompts retrieved: 846315 . Total input tokens: 188744173 . Total output tokens: 169308446
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.562031053006649,
    "estimated_duration": 3600.0103139198723,
    "input_throughput": 4123.388742138586,
    "output_throughput": 3657.0534115122623,
    "total_throughput": 7780.442153650849,
    "itl": 191.83028380344203,
    "ttft": 2048811.932144873,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.765452875494958,
    "arrivals": 281942,
    "finished_requests": 60218,
    "scheduler_time": 33.92792653817912
}
#Debug simulation 
Total elapsed time: 4.562131385784596. Arrivals time: 0.20963226910680532 Scheduler time: 4.19603730365634 Scheduler overhead time: 0.029270737897604704 Adapter cache time: 0.08304928475990891 Engine time: 0.03049214882776141 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-8/adapters_256_slots_256_rate_0.8-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-8/adapters_256_slots_256_rate_0.8-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 66, 8640, 8640, 66, 8640, 1080, 8640, 66, 1080, 66, 8640, 1080, 1080, 1080, 1080, 8640, 66, 66, 66, 1080, 8640, 66, 8640, 8640, 1080, 1080, 1080, 66, 8640, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 8640, 1080, 66, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 66, 8640, 8640, 1080, 66, 66, 8640, 1080, 66, 1080, 1080, 8640, 1080, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 8640, 8640, 66, 8640, 66, 1080, 8640, 8640, 8640, 1080, 66, 8640, 1080, 66, 66, 66, 66, 66, 8640, 1080, 66, 8640, 66, 8640, 66, 66, 1080, 1080, 8640, 1080, 8640, 66, 1080, 66, 8640, 8640, 66, 8640, 1080, 66, 8640, 66, 66, 8640, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 66, 1080, 8640, 8640, 66, 8640, 1080, 66, 1080, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 1080, 8640, 8640, 1080, 66, 8640, 66, 1080, 1080, 66, 1080, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 1080, 8640, 1080, 66, 1080, 8640, 1080, 8640, 66, 8640, 66, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 66, 8640, 66, 8640, 1080, 1080, 66, 1080, 8640, 1080, 1080, 8640, 66, 8640, 8640, 1080, 66, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 66, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 8640, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 66, 66, 66, 66]
Prompts retrieved: 840450 . Total input tokens: 187460075 . Total output tokens: 168134870
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.59045547619462,
    "estimated_duration": 3600.049692777284,
    "input_throughput": 4277.643175563993,
    "output_throughput": 3750.642394489672,
    "total_throughput": 8028.285570053666,
    "itl": 227.53956640132884,
    "ttft": 2023669.620731675,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.783484862446784,
    "arrivals": 279961,
    "finished_requests": 61980,
    "scheduler_time": 38.64042635733725
}
#Debug simulation 
Total elapsed time: 4.59055762225762. Arrivals time: 0.21251265238970518 Scheduler time: 4.252903383225203 Scheduler overhead time: 0.025276685133576393 Adapter cache time: 0.062226531095802784 Engine time: 0.02599154505878687 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-16/adapters_256_slots_256_rate_0.8-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-16/adapters_256_slots_256_rate_0.8-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 66, 8640, 8640, 66, 8640, 1080, 8640, 66, 1080, 66, 8640, 1080, 1080, 1080, 1080, 8640, 66, 66, 66, 1080, 8640, 66, 8640, 8640, 1080, 1080, 1080, 66, 8640, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 8640, 1080, 66, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 66, 8640, 8640, 1080, 66, 66, 8640, 1080, 66, 1080, 1080, 8640, 1080, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 8640, 8640, 66, 8640, 66, 1080, 8640, 8640, 8640, 1080, 66, 8640, 1080, 66, 66, 66, 66, 66, 8640, 1080, 66, 8640, 66, 8640, 66, 66, 1080, 1080, 8640, 1080, 8640, 66, 1080, 66, 8640, 8640, 66, 8640, 1080, 66, 8640, 66, 66, 8640, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 66, 1080, 8640, 8640, 66, 8640, 1080, 66, 1080, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 1080, 8640, 8640, 1080, 66, 8640, 66, 1080, 1080, 66, 1080, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 1080, 8640, 1080, 66, 1080, 8640, 1080, 8640, 66, 8640, 66, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 66, 8640, 66, 8640, 1080, 1080, 66, 1080, 8640, 1080, 1080, 8640, 66, 8640, 8640, 1080, 66, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 66, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 8640, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 66, 66, 66, 66]
Prompts retrieved: 840450 . Total input tokens: 187460075 . Total output tokens: 168134870
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.6057827160693705,
    "estimated_duration": 3600.061803178435,
    "input_throughput": 4235.938945974856,
    "output_throughput": 3721.4525006686285,
    "total_throughput": 7957.391446643484,
    "itl": 187.63803935155642,
    "ttft": 2034112.057695191,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8353226749482602,
    "arrivals": 279961,
    "finished_requests": 61374,
    "scheduler_time": 34.44700047306151
}
#Debug simulation 
Total elapsed time: 4.605886966921389. Arrivals time: 0.21867761621251702 Scheduler time: 4.235816700849682 Scheduler overhead time: 0.0297972965054214 Adapter cache time: 0.07665834203362465 Engine time: 0.03106509894132614 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-16/adapters_256_slots_256_rate_0.8-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-16/adapters_256_slots_256_rate_0.8-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 66, 8640, 8640, 66, 8640, 1080, 8640, 66, 1080, 66, 8640, 1080, 1080, 1080, 1080, 8640, 66, 66, 66, 1080, 8640, 66, 8640, 8640, 1080, 1080, 1080, 66, 8640, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 8640, 1080, 66, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 66, 8640, 8640, 1080, 66, 66, 8640, 1080, 66, 1080, 1080, 8640, 1080, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 8640, 8640, 66, 8640, 66, 1080, 8640, 8640, 8640, 1080, 66, 8640, 1080, 66, 66, 66, 66, 66, 8640, 1080, 66, 8640, 66, 8640, 66, 66, 1080, 1080, 8640, 1080, 8640, 66, 1080, 66, 8640, 8640, 66, 8640, 1080, 66, 8640, 66, 66, 8640, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 66, 1080, 8640, 8640, 66, 8640, 1080, 66, 1080, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 1080, 8640, 8640, 1080, 66, 8640, 66, 1080, 1080, 66, 1080, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 1080, 8640, 1080, 66, 1080, 8640, 1080, 8640, 66, 8640, 66, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 66, 8640, 66, 8640, 1080, 1080, 66, 1080, 8640, 1080, 1080, 8640, 66, 8640, 8640, 1080, 66, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 66, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 8640, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 66, 66, 66, 66]
Prompts retrieved: 840450 . Total input tokens: 187460075 . Total output tokens: 168134870
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.603966534137726,
    "estimated_duration": 3600.128290903696,
    "input_throughput": 4236.035987531965,
    "output_throughput": 3721.607653219713,
    "total_throughput": 7957.643640751678,
    "itl": 187.64949362813238,
    "ttft": 2033965.1227150748,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8005920728808291,
    "arrivals": 279961,
    "finished_requests": 61378,
    "scheduler_time": 34.44869470340375
}
#Debug simulation 
Total elapsed time: 4.604064808227122. Arrivals time: 0.2155125429853797 Scheduler time: 4.236154307145625 Scheduler overhead time: 0.029968302231281996 Adapter cache time: 0.07766644936054945 Engine time: 0.03077986091375351 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-16/adapters_256_slots_256_rate_0.8-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-16/adapters_256_slots_256_rate_0.8-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 66, 8640, 8640, 66, 8640, 1080, 8640, 66, 1080, 66, 8640, 1080, 1080, 1080, 1080, 8640, 66, 66, 66, 1080, 8640, 66, 8640, 8640, 1080, 1080, 1080, 66, 8640, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 8640, 1080, 66, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 66, 8640, 8640, 1080, 66, 66, 8640, 1080, 66, 1080, 1080, 8640, 1080, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 8640, 8640, 66, 8640, 66, 1080, 8640, 8640, 8640, 1080, 66, 8640, 1080, 66, 66, 66, 66, 66, 8640, 1080, 66, 8640, 66, 8640, 66, 66, 1080, 1080, 8640, 1080, 8640, 66, 1080, 66, 8640, 8640, 66, 8640, 1080, 66, 8640, 66, 66, 8640, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 66, 1080, 8640, 8640, 66, 8640, 1080, 66, 1080, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 1080, 8640, 8640, 1080, 66, 8640, 66, 1080, 1080, 66, 1080, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 1080, 8640, 1080, 66, 1080, 8640, 1080, 8640, 66, 8640, 66, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 66, 8640, 66, 8640, 1080, 1080, 66, 1080, 8640, 1080, 1080, 8640, 66, 8640, 8640, 1080, 66, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 66, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 8640, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 66, 66, 66, 66]
Prompts retrieved: 840450 . Total input tokens: 187460075 . Total output tokens: 168134870
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.610060287173837,
    "estimated_duration": 3600.0988615976325,
    "input_throughput": 4236.147002149878,
    "output_throughput": 3721.8394591680376,
    "total_throughput": 7957.986461317915,
    "itl": 187.64311901350916,
    "ttft": 2034042.11337465,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.765452875494958,
    "arrivals": 279961,
    "finished_requests": 61381,
    "scheduler_time": 34.44873571021071
}
#Debug simulation 
Total elapsed time: 4.6101850788109004. Arrivals time: 0.2125052441842854 Scheduler time: 4.246463533025235 Scheduler overhead time: 0.02997557120397687 Adapter cache time: 0.07628821255639195 Engine time: 0.03091650316491723 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-8/adapters_256_slots_256_rate_0.8-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-8/adapters_256_slots_256_rate_0.8-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 33, 8640, 8640, 33, 8640, 1080, 8640, 33, 1080, 33, 8640, 1080, 1080, 1080, 1080, 8640, 33, 33, 33, 1080, 8640, 33, 8640, 8640, 1080, 1080, 1080, 33, 8640, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 8640, 1080, 33, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 33, 8640, 8640, 1080, 33, 33, 8640, 1080, 33, 1080, 1080, 8640, 1080, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 8640, 8640, 33, 8640, 33, 1080, 8640, 8640, 8640, 1080, 33, 8640, 1080, 33, 33, 33, 33, 33, 8640, 1080, 33, 8640, 33, 8640, 33, 33, 1080, 1080, 8640, 1080, 8640, 33, 1080, 33, 8640, 8640, 33, 8640, 1080, 33, 8640, 33, 33, 8640, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 33, 1080, 8640, 8640, 33, 8640, 1080, 33, 1080, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 1080, 8640, 8640, 1080, 33, 8640, 33, 1080, 1080, 33, 1080, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 1080, 8640, 1080, 33, 1080, 8640, 1080, 8640, 33, 8640, 33, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 33, 8640, 33, 8640, 1080, 1080, 33, 1080, 8640, 1080, 1080, 8640, 33, 8640, 8640, 1080, 33, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 33, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 8640, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 33, 33, 33, 33]
Prompts retrieved: 837645 . Total input tokens: 186835947 . Total output tokens: 167577567
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.643811235204339,
    "estimated_duration": 3600.1126248104856,
    "input_throughput": 4296.71363428923,
    "output_throughput": 3794.3196292974526,
    "total_throughput": 8091.033263586683,
    "itl": 225.53416852291716,
    "ttft": 2018745.7586690865,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 251,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7681824237271202,
    "arrivals": 278999,
    "finished_requests": 62373,
    "scheduler_time": 39.155240937644315
}
#Debug simulation 
Total elapsed time: 4.643915871158242. Arrivals time: 0.21827569836750627 Scheduler time: 4.305046070367098 Scheduler overhead time: 0.0253202049061656 Adapter cache time: 0.057529397774487734 Engine time: 0.025970617309212685 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-16/adapters_256_slots_256_rate_0.8-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-16/adapters_256_slots_256_rate_0.8-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 33, 8640, 8640, 33, 8640, 1080, 8640, 33, 1080, 33, 8640, 1080, 1080, 1080, 1080, 8640, 33, 33, 33, 1080, 8640, 33, 8640, 8640, 1080, 1080, 1080, 33, 8640, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 8640, 1080, 33, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 33, 8640, 8640, 1080, 33, 33, 8640, 1080, 33, 1080, 1080, 8640, 1080, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 8640, 8640, 33, 8640, 33, 1080, 8640, 8640, 8640, 1080, 33, 8640, 1080, 33, 33, 33, 33, 33, 8640, 1080, 33, 8640, 33, 8640, 33, 33, 1080, 1080, 8640, 1080, 8640, 33, 1080, 33, 8640, 8640, 33, 8640, 1080, 33, 8640, 33, 33, 8640, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 33, 1080, 8640, 8640, 33, 8640, 1080, 33, 1080, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 1080, 8640, 8640, 1080, 33, 8640, 33, 1080, 1080, 33, 1080, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 1080, 8640, 1080, 33, 1080, 8640, 1080, 8640, 33, 8640, 33, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 33, 8640, 33, 8640, 1080, 1080, 33, 1080, 8640, 1080, 1080, 8640, 33, 8640, 8640, 1080, 33, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 33, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 8640, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 33, 33, 33, 33]
Prompts retrieved: 837645 . Total input tokens: 186835947 . Total output tokens: 167577567
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.649377606343478,
    "estimated_duration": 3600.100678701487,
    "input_throughput": 4249.043947714662,
    "output_throughput": 3758.5046107322937,
    "total_throughput": 8007.548558446955,
    "itl": 185.64341593788262,
    "ttft": 2031685.4099843304,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 251,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8187380421999877,
    "arrivals": 278999,
    "finished_requests": 61694,
    "scheduler_time": 34.756171779377595
}
#Debug simulation 
Total elapsed time: 4.649475380312651. Arrivals time: 0.2115345043130219 Scheduler time: 4.290988903492689 Scheduler overhead time: 0.03005540743470192 Adapter cache time: 0.07163594244048 Engine time: 0.031192838214337826 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-16/adapters_256_slots_256_rate_0.8-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-16/adapters_256_slots_256_rate_0.8-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 33, 8640, 8640, 33, 8640, 1080, 8640, 33, 1080, 33, 8640, 1080, 1080, 1080, 1080, 8640, 33, 33, 33, 1080, 8640, 33, 8640, 8640, 1080, 1080, 1080, 33, 8640, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 8640, 1080, 33, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 33, 8640, 8640, 1080, 33, 33, 8640, 1080, 33, 1080, 1080, 8640, 1080, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 8640, 8640, 33, 8640, 33, 1080, 8640, 8640, 8640, 1080, 33, 8640, 1080, 33, 33, 33, 33, 33, 8640, 1080, 33, 8640, 33, 8640, 33, 33, 1080, 1080, 8640, 1080, 8640, 33, 1080, 33, 8640, 8640, 33, 8640, 1080, 33, 8640, 33, 33, 8640, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 33, 1080, 8640, 8640, 33, 8640, 1080, 33, 1080, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 1080, 8640, 8640, 1080, 33, 8640, 33, 1080, 1080, 33, 1080, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 1080, 8640, 1080, 33, 1080, 8640, 1080, 8640, 33, 8640, 33, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 33, 8640, 33, 8640, 1080, 1080, 33, 1080, 8640, 1080, 1080, 8640, 33, 8640, 8640, 1080, 33, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 33, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 8640, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 33, 33, 33, 33]
Prompts retrieved: 837645 . Total input tokens: 186835947 . Total output tokens: 167577567
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.628422308247536,
    "estimated_duration": 3600.0298067660033,
    "input_throughput": 4248.9542645595775,
    "output_throughput": 3758.4527701882625,
    "total_throughput": 8007.407034747839,
    "itl": 185.56043015088463,
    "ttft": 2031620.5083377543,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 251,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7844160354509971,
    "arrivals": 278999,
    "finished_requests": 61692,
    "scheduler_time": 34.74517605511951
}
#Debug simulation 
Total elapsed time: 4.628548928070813. Arrivals time: 0.21015247516334057 Scheduler time: 4.271807293407619 Scheduler overhead time: 0.030200235079973936 Adapter cache time: 0.07130793575197458 Engine time: 0.031018497422337532 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-16/adapters_256_slots_256_rate_0.8-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-16/adapters_256_slots_256_rate_0.8-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 33, 8640, 8640, 33, 8640, 1080, 8640, 33, 1080, 33, 8640, 1080, 1080, 1080, 1080, 8640, 33, 33, 33, 1080, 8640, 33, 8640, 8640, 1080, 1080, 1080, 33, 8640, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 8640, 1080, 33, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 33, 8640, 8640, 1080, 33, 33, 8640, 1080, 33, 1080, 1080, 8640, 1080, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 8640, 8640, 33, 8640, 33, 1080, 8640, 8640, 8640, 1080, 33, 8640, 1080, 33, 33, 33, 33, 33, 8640, 1080, 33, 8640, 33, 8640, 33, 33, 1080, 1080, 8640, 1080, 8640, 33, 1080, 33, 8640, 8640, 33, 8640, 1080, 33, 8640, 33, 33, 8640, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 33, 1080, 8640, 8640, 33, 8640, 1080, 33, 1080, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 1080, 8640, 8640, 1080, 33, 8640, 33, 1080, 1080, 33, 1080, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 1080, 8640, 1080, 33, 1080, 8640, 1080, 8640, 33, 8640, 33, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 33, 8640, 33, 8640, 1080, 1080, 33, 1080, 8640, 1080, 1080, 8640, 33, 8640, 8640, 1080, 33, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 33, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 8640, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 33, 33, 33, 33]
Prompts retrieved: 837645 . Total input tokens: 186835947 . Total output tokens: 167577567
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.630810189060867,
    "estimated_duration": 3600.1653465805966,
    "input_throughput": 4249.124283841427,
    "output_throughput": 3758.5662594225164,
    "total_throughput": 8007.690543263943,
    "itl": 185.88794985684055,
    "ttft": 2031409.8747118695,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 251,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7505026240204471,
    "arrivals": 278999,
    "finished_requests": 61697,
    "scheduler_time": 34.791020679052814
}
#Debug simulation 
Total elapsed time: 4.630906044971198. Arrivals time: 0.21344036562368274 Scheduler time: 4.2705222722142935 Scheduler overhead time: 0.030134941451251507 Adapter cache time: 0.07177516957744956 Engine time: 0.030972059816122055 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-8/adapters_256_slots_256_rate_0.8-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-8/adapters_256_slots_256_rate_0.8-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 270, 8640, 8640, 270, 8640, 540, 8640, 270, 540, 270, 8640, 540, 540, 540, 540, 8640, 270, 270, 270, 540, 8640, 270, 8640, 8640, 540, 540, 540, 270, 8640, 270, 540, 540, 270, 540, 270, 270, 540, 540, 8640, 540, 270, 540, 8640, 540, 540, 8640, 540, 8640, 270, 8640, 8640, 540, 270, 270, 8640, 540, 270, 540, 540, 8640, 540, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 8640, 8640, 270, 8640, 270, 540, 8640, 8640, 8640, 540, 270, 8640, 540, 270, 270, 270, 270, 270, 8640, 540, 270, 8640, 270, 8640, 270, 270, 540, 540, 8640, 540, 8640, 270, 540, 270, 8640, 8640, 270, 8640, 540, 270, 8640, 270, 270, 8640, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 270, 540, 8640, 8640, 270, 8640, 540, 270, 540, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 540, 8640, 8640, 540, 270, 8640, 270, 540, 540, 270, 540, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 540, 8640, 540, 270, 540, 8640, 540, 8640, 270, 8640, 270, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 270, 8640, 270, 8640, 540, 540, 270, 540, 8640, 540, 540, 8640, 270, 8640, 8640, 540, 270, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 270, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 8640, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 8640, 540, 270, 270, 270, 270]
Prompts retrieved: 811890 . Total input tokens: 181009391 . Total output tokens: 162494279
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.672890836838633,
    "estimated_duration": 3600.0570949823154,
    "input_throughput": 4321.7547915240575,
    "output_throughput": 3809.0040347172217,
    "total_throughput": 8130.758826241279,
    "itl": 224.66412951625958,
    "ttft": 2011914.0445017416,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.783484862446784,
    "arrivals": 270522,
    "finished_requests": 62836,
    "scheduler_time": 39.258810519001536
}
#Debug simulation 
Total elapsed time: 4.67298972979188. Arrivals time: 0.21234280988574028 Scheduler time: 4.31586467474699 Scheduler overhead time: 0.025521610397845507 Adapter cache time: 0.08111948939040303 Engine time: 0.02625722298398614 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-16/adapters_256_slots_256_rate_0.8-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-16/adapters_256_slots_256_rate_0.8-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 270, 8640, 8640, 270, 8640, 540, 8640, 270, 540, 270, 8640, 540, 540, 540, 540, 8640, 270, 270, 270, 540, 8640, 270, 8640, 8640, 540, 540, 540, 270, 8640, 270, 540, 540, 270, 540, 270, 270, 540, 540, 8640, 540, 270, 540, 8640, 540, 540, 8640, 540, 8640, 270, 8640, 8640, 540, 270, 270, 8640, 540, 270, 540, 540, 8640, 540, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 8640, 8640, 270, 8640, 270, 540, 8640, 8640, 8640, 540, 270, 8640, 540, 270, 270, 270, 270, 270, 8640, 540, 270, 8640, 270, 8640, 270, 270, 540, 540, 8640, 540, 8640, 270, 540, 270, 8640, 8640, 270, 8640, 540, 270, 8640, 270, 270, 8640, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 270, 540, 8640, 8640, 270, 8640, 540, 270, 540, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 540, 8640, 8640, 540, 270, 8640, 270, 540, 540, 270, 540, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 540, 8640, 540, 270, 540, 8640, 540, 8640, 270, 8640, 270, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 270, 8640, 270, 8640, 540, 540, 270, 540, 8640, 540, 540, 8640, 270, 8640, 8640, 540, 270, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 270, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 8640, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 8640, 540, 270, 270, 270, 270]
Prompts retrieved: 811890 . Total input tokens: 181009391 . Total output tokens: 162494279
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.742900932673365,
    "estimated_duration": 3600.0941430129083,
    "input_throughput": 4307.869845598199,
    "output_throughput": 3803.9130244908424,
    "total_throughput": 8111.782870089042,
    "itl": 183.2642097766085,
    "ttft": 2017776.4678495042,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8353226749482601,
    "arrivals": 270522,
    "finished_requests": 62643,
    "scheduler_time": 35.19166416577984
}
#Debug simulation 
Total elapsed time: 4.743006464093924. Arrivals time: 0.2178287305869162 Scheduler time: 4.356334768235683 Scheduler overhead time: 0.030817475635558367 Adapter cache time: 0.09189951186999679 Engine time: 0.031781739089637995 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-16-16/adapters_256_slots_256_rate_0.8-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-16-16/adapters_256_slots_256_rate_0.8-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 270, 8640, 8640, 270, 8640, 540, 8640, 270, 540, 270, 8640, 540, 540, 540, 540, 8640, 270, 270, 270, 540, 8640, 270, 8640, 8640, 540, 540, 540, 270, 8640, 270, 540, 540, 270, 540, 270, 270, 540, 540, 8640, 540, 270, 540, 8640, 540, 540, 8640, 540, 8640, 270, 8640, 8640, 540, 270, 270, 8640, 540, 270, 540, 540, 8640, 540, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 8640, 8640, 270, 8640, 270, 540, 8640, 8640, 8640, 540, 270, 8640, 540, 270, 270, 270, 270, 270, 8640, 540, 270, 8640, 270, 8640, 270, 270, 540, 540, 8640, 540, 8640, 270, 540, 270, 8640, 8640, 270, 8640, 540, 270, 8640, 270, 270, 8640, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 270, 540, 8640, 8640, 270, 8640, 540, 270, 540, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 540, 8640, 8640, 540, 270, 8640, 270, 540, 540, 270, 540, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 540, 8640, 540, 270, 540, 8640, 540, 8640, 270, 8640, 270, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 270, 8640, 270, 8640, 540, 540, 270, 540, 8640, 540, 540, 8640, 270, 8640, 8640, 540, 270, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 270, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 8640, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 8640, 540, 270, 270, 270, 270]
Prompts retrieved: 811890 . Total input tokens: 181009391 . Total output tokens: 162494279
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.661922248080373,
    "estimated_duration": 3600.0955096281004,
    "input_throughput": 4270.501979428928,
    "output_throughput": 3771.40772062533,
    "total_throughput": 8041.909700054259,
    "itl": 180.4888256692253,
    "ttft": 2019197.1294465272,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8005920728808291,
    "arrivals": 270522,
    "finished_requests": 62086,
    "scheduler_time": 34.332179586533115
}
#Debug simulation 
Total elapsed time: 4.662020566873252. Arrivals time: 0.20951335597783327 Scheduler time: 4.283549435436726 Scheduler overhead time: 0.030947627499699593 Adapter cache time: 0.0917856520973146 Engine time: 0.031819922383874655 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_16-16-16/adapters_256_slots_256_rate_0.8-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_16-16-16/adapters_256_slots_256_rate_0.8-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 270, 8640, 8640, 270, 8640, 540, 8640, 270, 540, 270, 8640, 540, 540, 540, 540, 8640, 270, 270, 270, 540, 8640, 270, 8640, 8640, 540, 540, 540, 270, 8640, 270, 540, 540, 270, 540, 270, 270, 540, 540, 8640, 540, 270, 540, 8640, 540, 540, 8640, 540, 8640, 270, 8640, 8640, 540, 270, 270, 8640, 540, 270, 540, 540, 8640, 540, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 8640, 8640, 270, 8640, 270, 540, 8640, 8640, 8640, 540, 270, 8640, 540, 270, 270, 270, 270, 270, 8640, 540, 270, 8640, 270, 8640, 270, 270, 540, 540, 8640, 540, 8640, 270, 540, 270, 8640, 8640, 270, 8640, 540, 270, 8640, 270, 270, 8640, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 270, 540, 8640, 8640, 270, 8640, 540, 270, 540, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 540, 8640, 8640, 540, 270, 8640, 270, 540, 540, 270, 540, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 540, 8640, 540, 270, 540, 8640, 540, 8640, 270, 8640, 270, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 270, 8640, 270, 8640, 540, 540, 270, 540, 8640, 540, 540, 8640, 270, 8640, 8640, 540, 270, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 270, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 8640, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 8640, 540, 270, 270, 270, 270]
Prompts retrieved: 811890 . Total input tokens: 181009391 . Total output tokens: 162494279
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.703753754030913,
    "estimated_duration": 3600.192021174643,
    "input_throughput": 4308.065488945659,
    "output_throughput": 3804.010708165407,
    "total_throughput": 8112.076197111066,
    "itl": 183.26800177444602,
    "ttft": 2017737.2603335378,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.765452875494958,
    "arrivals": 270522,
    "finished_requests": 62647,
    "scheduler_time": 35.19303537025319
}
#Debug simulation 
Total elapsed time: 4.703851156868041. Arrivals time: 0.21219281945377588 Scheduler time: 4.3228464955464005 Scheduler overhead time: 0.03056671004742384 Adapter cache time: 0.09248806722462177 Engine time: 0.031535941176116467 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-8/adapters_256_slots_256_rate_0.8-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-8/adapters_256_slots_256_rate_0.8-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 135, 8640, 8640, 135, 8640, 540, 8640, 135, 540, 135, 8640, 540, 540, 540, 540, 8640, 135, 135, 135, 540, 8640, 135, 8640, 8640, 540, 540, 540, 135, 8640, 135, 540, 540, 135, 540, 135, 135, 540, 540, 8640, 540, 135, 540, 8640, 540, 540, 8640, 540, 8640, 135, 8640, 8640, 540, 135, 135, 8640, 540, 135, 540, 540, 8640, 540, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 8640, 8640, 135, 8640, 135, 540, 8640, 8640, 8640, 540, 135, 8640, 540, 135, 135, 135, 135, 135, 8640, 540, 135, 8640, 135, 8640, 135, 135, 540, 540, 8640, 540, 8640, 135, 540, 135, 8640, 8640, 135, 8640, 540, 135, 8640, 135, 135, 8640, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 135, 540, 8640, 8640, 135, 8640, 540, 135, 540, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 540, 8640, 8640, 540, 135, 8640, 135, 540, 540, 135, 540, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 540, 8640, 540, 135, 540, 8640, 540, 8640, 135, 8640, 135, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 135, 8640, 135, 8640, 540, 540, 135, 540, 8640, 540, 540, 8640, 135, 8640, 8640, 540, 135, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 135, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 8640, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 8640, 540, 135, 135, 135, 135]
Prompts retrieved: 800415 . Total input tokens: 178436095 . Total output tokens: 160189560
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.885198075324297,
    "estimated_duration": 3600.007101941719,
    "input_throughput": 4506.323887875105,
    "output_throughput": 3975.3068798895065,
    "total_throughput": 8481.630767764613,
    "itl": 215.8683306321883,
    "ttft": 1975342.1466561807,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.783484862446784,
    "arrivals": 266663,
    "finished_requests": 65257,
    "scheduler_time": 41.02391222337591
}
#Debug simulation 
Total elapsed time: 4.885300958063453. Arrivals time: 0.2255496676079929 Scheduler time: 4.523841382935643 Scheduler overhead time: 0.026528677437454462 Adapter cache time: 0.06944926688447595 Engine time: 0.027579065412282944 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-16/adapters_256_slots_256_rate_0.8-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-16/adapters_256_slots_256_rate_0.8-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 135, 8640, 8640, 135, 8640, 540, 8640, 135, 540, 135, 8640, 540, 540, 540, 540, 8640, 135, 135, 135, 540, 8640, 135, 8640, 8640, 540, 540, 540, 135, 8640, 135, 540, 540, 135, 540, 135, 135, 540, 540, 8640, 540, 135, 540, 8640, 540, 540, 8640, 540, 8640, 135, 8640, 8640, 540, 135, 135, 8640, 540, 135, 540, 540, 8640, 540, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 8640, 8640, 135, 8640, 135, 540, 8640, 8640, 8640, 540, 135, 8640, 540, 135, 135, 135, 135, 135, 8640, 540, 135, 8640, 135, 8640, 135, 135, 540, 540, 8640, 540, 8640, 135, 540, 135, 8640, 8640, 135, 8640, 540, 135, 8640, 135, 135, 8640, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 135, 540, 8640, 8640, 135, 8640, 540, 135, 540, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 540, 8640, 8640, 540, 135, 8640, 135, 540, 540, 135, 540, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 540, 8640, 540, 135, 540, 8640, 540, 8640, 135, 8640, 135, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 135, 8640, 135, 8640, 540, 540, 135, 540, 8640, 540, 540, 8640, 135, 8640, 8640, 540, 135, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 135, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 8640, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 8640, 540, 135, 135, 135, 135]
Prompts retrieved: 800415 . Total input tokens: 178436095 . Total output tokens: 160189560
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.840967861004174,
    "estimated_duration": 3600.114176400305,
    "input_throughput": 4471.4937391502435,
    "output_throughput": 3951.269682847494,
    "total_throughput": 8422.763421997737,
    "itl": 177.01028604496986,
    "ttft": 1983565.760443081,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8353226749482602,
    "arrivals": 266663,
    "finished_requests": 64750,
    "scheduler_time": 36.624844024586466
}
#Debug simulation 
Total elapsed time: 4.841087786015123. Arrivals time: 0.21713040582835674 Scheduler time: 4.4667571359314024 Scheduler overhead time: 0.0316867446526885 Adapter cache time: 0.07823452726006508 Engine time: 0.03252431843429804 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-16/adapters_256_slots_256_rate_0.8-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-16/adapters_256_slots_256_rate_0.8-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 135, 8640, 8640, 135, 8640, 540, 8640, 135, 540, 135, 8640, 540, 540, 540, 540, 8640, 135, 135, 135, 540, 8640, 135, 8640, 8640, 540, 540, 540, 135, 8640, 135, 540, 540, 135, 540, 135, 135, 540, 540, 8640, 540, 135, 540, 8640, 540, 540, 8640, 540, 8640, 135, 8640, 8640, 540, 135, 135, 8640, 540, 135, 540, 540, 8640, 540, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 8640, 8640, 135, 8640, 135, 540, 8640, 8640, 8640, 540, 135, 8640, 540, 135, 135, 135, 135, 135, 8640, 540, 135, 8640, 135, 8640, 135, 135, 540, 540, 8640, 540, 8640, 135, 540, 135, 8640, 8640, 135, 8640, 540, 135, 8640, 135, 135, 8640, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 135, 540, 8640, 8640, 135, 8640, 540, 135, 540, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 540, 8640, 8640, 540, 135, 8640, 135, 540, 540, 135, 540, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 540, 8640, 540, 135, 540, 8640, 540, 8640, 135, 8640, 135, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 135, 8640, 135, 8640, 540, 540, 135, 540, 8640, 540, 540, 8640, 135, 8640, 8640, 540, 135, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 135, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 8640, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 8640, 540, 135, 135, 135, 135]
Prompts retrieved: 800415 . Total input tokens: 178436095 . Total output tokens: 160189560
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.05690247612074,
    "estimated_duration": 3600.006974501329,
    "input_throughput": 4471.6268923978605,
    "output_throughput": 3951.387344734365,
    "total_throughput": 8423.014237132225,
    "itl": 176.99910735112604,
    "ttft": 1983657.1940707858,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8005920728808292,
    "arrivals": 266663,
    "finished_requests": 64750,
    "scheduler_time": 36.622646991325944
}
#Debug simulation 
Total elapsed time: 5.057001994922757. Arrivals time: 0.21935497922822833 Scheduler time: 4.680124577600509 Scheduler overhead time: 0.03157963650301099 Adapter cache time: 0.07861343817785382 Engine time: 0.032627967186272144 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-16/adapters_256_slots_256_rate_0.8-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-16/adapters_256_slots_256_rate_0.8-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 135, 8640, 8640, 135, 8640, 540, 8640, 135, 540, 135, 8640, 540, 540, 540, 540, 8640, 135, 135, 135, 540, 8640, 135, 8640, 8640, 540, 540, 540, 135, 8640, 135, 540, 540, 135, 540, 135, 135, 540, 540, 8640, 540, 135, 540, 8640, 540, 540, 8640, 540, 8640, 135, 8640, 8640, 540, 135, 135, 8640, 540, 135, 540, 540, 8640, 540, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 8640, 8640, 135, 8640, 135, 540, 8640, 8640, 8640, 540, 135, 8640, 540, 135, 135, 135, 135, 135, 8640, 540, 135, 8640, 135, 8640, 135, 135, 540, 540, 8640, 540, 8640, 135, 540, 135, 8640, 8640, 135, 8640, 540, 135, 8640, 135, 135, 8640, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 135, 540, 8640, 8640, 135, 8640, 540, 135, 540, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 540, 8640, 8640, 540, 135, 8640, 135, 540, 540, 135, 540, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 540, 8640, 540, 135, 540, 8640, 540, 8640, 135, 8640, 135, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 135, 8640, 135, 8640, 540, 540, 135, 540, 8640, 540, 540, 8640, 135, 8640, 8640, 540, 135, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 135, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 8640, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 8640, 540, 135, 135, 135, 135]
Prompts retrieved: 800415 . Total input tokens: 178436095 . Total output tokens: 160189560
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.8796630701981485,
    "estimated_duration": 3600.084427521836,
    "input_throughput": 4471.530688818091,
    "output_throughput": 3951.302333704428,
    "total_throughput": 8422.83302252252,
    "itl": 176.99477636075957,
    "ttft": 1983640.6729860923,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.765452875494958,
    "arrivals": 266663,
    "finished_requests": 64750,
    "scheduler_time": 36.62375904683293
}
#Debug simulation 
Total elapsed time: 4.879762050230056. Arrivals time: 0.21646147780120373 Scheduler time: 4.506098128855228 Scheduler overhead time: 0.03168156370520592 Adapter cache time: 0.07823020126670599 Engine time: 0.032574794720858335 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-8/adapters_256_slots_256_rate_0.8-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-8/adapters_256_slots_256_rate_0.8-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 66, 8640, 8640, 66, 8640, 540, 8640, 66, 540, 66, 8640, 540, 540, 540, 540, 8640, 66, 66, 66, 540, 8640, 66, 8640, 8640, 540, 540, 540, 66, 8640, 66, 540, 540, 66, 540, 66, 66, 540, 540, 8640, 540, 66, 540, 8640, 540, 540, 8640, 540, 8640, 66, 8640, 8640, 540, 66, 66, 8640, 540, 66, 540, 540, 8640, 540, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 8640, 8640, 66, 8640, 66, 540, 8640, 8640, 8640, 540, 66, 8640, 540, 66, 66, 66, 66, 66, 8640, 540, 66, 8640, 66, 8640, 66, 66, 540, 540, 8640, 540, 8640, 66, 540, 66, 8640, 8640, 66, 8640, 540, 66, 8640, 66, 66, 8640, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 66, 540, 8640, 8640, 66, 8640, 540, 66, 540, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 540, 8640, 8640, 540, 66, 8640, 66, 540, 540, 66, 540, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 540, 8640, 540, 66, 540, 8640, 540, 8640, 66, 8640, 66, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 66, 8640, 66, 8640, 540, 540, 66, 540, 8640, 540, 540, 8640, 66, 8640, 8640, 540, 66, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 66, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 8640, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 8640, 540, 66, 66, 66, 66]
Prompts retrieved: 794550 . Total input tokens: 177125970 . Total output tokens: 159040310
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.0954729546792805,
    "estimated_duration": 3600.011144511361,
    "input_throughput": 4623.701797528552,
    "output_throughput": 4071.8748947066597,
    "total_throughput": 8695.576692235212,
    "itl": 210.12455177657625,
    "ttft": 1949242.6918880534,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.783484862446784,
    "arrivals": 264754,
    "finished_requests": 67264,
    "scheduler_time": 42.01560093536516
}
#Debug simulation 
Total elapsed time: 5.095572886057198. Arrivals time: 0.22669342020526528 Scheduler time: 4.739163043443114 Scheduler overhead time: 0.02700063632801175 Adapter cache time: 0.062266798224300146 Engine time: 0.027929506730288267 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-16/adapters_256_slots_256_rate_0.8-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-16/adapters_256_slots_256_rate_0.8-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 66, 8640, 8640, 66, 8640, 540, 8640, 66, 540, 66, 8640, 540, 540, 540, 540, 8640, 66, 66, 66, 540, 8640, 66, 8640, 8640, 540, 540, 540, 66, 8640, 66, 540, 540, 66, 540, 66, 66, 540, 540, 8640, 540, 66, 540, 8640, 540, 540, 8640, 540, 8640, 66, 8640, 8640, 540, 66, 66, 8640, 540, 66, 540, 540, 8640, 540, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 8640, 8640, 66, 8640, 66, 540, 8640, 8640, 8640, 540, 66, 8640, 540, 66, 66, 66, 66, 66, 8640, 540, 66, 8640, 66, 8640, 66, 66, 540, 540, 8640, 540, 8640, 66, 540, 66, 8640, 8640, 66, 8640, 540, 66, 8640, 66, 66, 8640, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 66, 540, 8640, 8640, 66, 8640, 540, 66, 540, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 540, 8640, 8640, 540, 66, 8640, 66, 540, 540, 66, 540, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 540, 8640, 540, 66, 540, 8640, 540, 8640, 66, 8640, 66, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 66, 8640, 66, 8640, 540, 540, 66, 540, 8640, 540, 540, 8640, 66, 8640, 8640, 540, 66, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 66, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 8640, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 8640, 540, 66, 66, 66, 66]
Prompts retrieved: 794550 . Total input tokens: 177125970 . Total output tokens: 159040310
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.941331213340163,
    "estimated_duration": 3600.0683536872834,
    "input_throughput": 4578.0027990634135,
    "output_throughput": 4038.613040529769,
    "total_throughput": 8616.615839593183,
    "itl": 173.3466252174308,
    "ttft": 1960098.1416719286,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8353226749482604,
    "arrivals": 264754,
    "finished_requests": 66603,
    "scheduler_time": 37.46102331709197
}
#Debug simulation 
Total elapsed time: 4.941444084979594. Arrivals time: 0.2316700122319162 Scheduler time: 4.557767680380493 Scheduler overhead time: 0.032127243001013994 Adapter cache time: 0.07190915010869503 Engine time: 0.03300831140950322 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-16/adapters_256_slots_256_rate_0.8-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-16/adapters_256_slots_256_rate_0.8-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 66, 8640, 8640, 66, 8640, 540, 8640, 66, 540, 66, 8640, 540, 540, 540, 540, 8640, 66, 66, 66, 540, 8640, 66, 8640, 8640, 540, 540, 540, 66, 8640, 66, 540, 540, 66, 540, 66, 66, 540, 540, 8640, 540, 66, 540, 8640, 540, 540, 8640, 540, 8640, 66, 8640, 8640, 540, 66, 66, 8640, 540, 66, 540, 540, 8640, 540, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 8640, 8640, 66, 8640, 66, 540, 8640, 8640, 8640, 540, 66, 8640, 540, 66, 66, 66, 66, 66, 8640, 540, 66, 8640, 66, 8640, 66, 66, 540, 540, 8640, 540, 8640, 66, 540, 66, 8640, 8640, 66, 8640, 540, 66, 8640, 66, 66, 8640, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 66, 540, 8640, 8640, 66, 8640, 540, 66, 540, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 540, 8640, 8640, 540, 66, 8640, 66, 540, 540, 66, 540, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 540, 8640, 540, 66, 540, 8640, 540, 8640, 66, 8640, 66, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 66, 8640, 66, 8640, 540, 540, 66, 540, 8640, 540, 540, 8640, 66, 8640, 8640, 540, 66, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 66, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 8640, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 8640, 540, 66, 66, 66, 66]
Prompts retrieved: 794550 . Total input tokens: 177125970 . Total output tokens: 159040310
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.972884106915444,
    "estimated_duration": 3600.1822019506612,
    "input_throughput": 4577.989133736035,
    "output_throughput": 4038.5075489018973,
    "total_throughput": 8616.496682637933,
    "itl": 173.34530858695044,
    "ttft": 1960156.2740983807,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8005920728808293,
    "arrivals": 264754,
    "finished_requests": 66604,
    "scheduler_time": 37.46304529640473
}
#Debug simulation 
Total elapsed time: 4.9729795111343265. Arrivals time: 0.22347345296293497 Scheduler time: 4.598013553768396 Scheduler overhead time: 0.03225862002000213 Adapter cache time: 0.07096425956115127 Engine time: 0.033217139076441526 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-16/adapters_256_slots_256_rate_0.8-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-16/adapters_256_slots_256_rate_0.8-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 66, 8640, 8640, 66, 8640, 540, 8640, 66, 540, 66, 8640, 540, 540, 540, 540, 8640, 66, 66, 66, 540, 8640, 66, 8640, 8640, 540, 540, 540, 66, 8640, 66, 540, 540, 66, 540, 66, 66, 540, 540, 8640, 540, 66, 540, 8640, 540, 540, 8640, 540, 8640, 66, 8640, 8640, 540, 66, 66, 8640, 540, 66, 540, 540, 8640, 540, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 8640, 8640, 66, 8640, 66, 540, 8640, 8640, 8640, 540, 66, 8640, 540, 66, 66, 66, 66, 66, 8640, 540, 66, 8640, 66, 8640, 66, 66, 540, 540, 8640, 540, 8640, 66, 540, 66, 8640, 8640, 66, 8640, 540, 66, 8640, 66, 66, 8640, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 66, 540, 8640, 8640, 66, 8640, 540, 66, 540, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 540, 8640, 8640, 540, 66, 8640, 66, 540, 540, 66, 540, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 540, 8640, 540, 66, 540, 8640, 540, 8640, 66, 8640, 66, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 66, 8640, 66, 8640, 540, 540, 66, 540, 8640, 540, 540, 8640, 66, 8640, 8640, 540, 66, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 66, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 8640, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 8640, 540, 66, 66, 66, 66]
Prompts retrieved: 794550 . Total input tokens: 177125970 . Total output tokens: 159040310
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.959179302211851,
    "estimated_duration": 3600.0638347178415,
    "input_throughput": 4577.929658097772,
    "output_throughput": 4038.5883882915987,
    "total_throughput": 8616.51804638937,
    "itl": 173.3438141670892,
    "ttft": 1960168.438828667,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.765452875494958,
    "arrivals": 264754,
    "finished_requests": 66602,
    "scheduler_time": 37.460952360302564
}
#Debug simulation 
Total elapsed time: 4.959277673158795. Arrivals time: 0.22637651721015573 Scheduler time: 4.581079520750791 Scheduler overhead time: 0.0321127325296402 Adapter cache time: 0.07148382067680359 Engine time: 0.03315419191494584 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-8/adapters_256_slots_256_rate_0.8-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-8/adapters_256_slots_256_rate_0.8-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 33, 8640, 8640, 33, 8640, 540, 8640, 33, 540, 33, 8640, 540, 540, 540, 540, 8640, 33, 33, 33, 540, 8640, 33, 8640, 8640, 540, 540, 540, 33, 8640, 33, 540, 540, 33, 540, 33, 33, 540, 540, 8640, 540, 33, 540, 8640, 540, 540, 8640, 540, 8640, 33, 8640, 8640, 540, 33, 33, 8640, 540, 33, 540, 540, 8640, 540, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 8640, 8640, 33, 8640, 33, 540, 8640, 8640, 8640, 540, 33, 8640, 540, 33, 33, 33, 33, 33, 8640, 540, 33, 8640, 33, 8640, 33, 33, 540, 540, 8640, 540, 8640, 33, 540, 33, 8640, 8640, 33, 8640, 540, 33, 8640, 33, 33, 8640, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 33, 540, 8640, 8640, 33, 8640, 540, 33, 540, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 540, 8640, 8640, 540, 33, 8640, 33, 540, 540, 33, 540, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 540, 8640, 540, 33, 540, 8640, 540, 8640, 33, 8640, 33, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 33, 8640, 33, 8640, 540, 540, 33, 540, 8640, 540, 540, 8640, 33, 8640, 8640, 540, 33, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 33, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 8640, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 8640, 540, 33, 33, 33, 33]
Prompts retrieved: 791745 . Total input tokens: 176476708 . Total output tokens: 158497887
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.043163888156414,
    "estimated_duration": 3600.2197362153206,
    "input_throughput": 4698.334057182212,
    "output_throughput": 4117.801991604146,
    "total_throughput": 8816.136048786359,
    "itl": 207.58505466552288,
    "ttft": 1938482.9047381396,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 251,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7681824237271202,
    "arrivals": 263766,
    "finished_requests": 68061,
    "scheduler_time": 42.42620156231675
}
#Debug simulation 
Total elapsed time: 5.043260305188596. Arrivals time: 0.2504717339761555 Scheduler time: 4.6653762217611074 Scheduler overhead time: 0.02744378987699747 Adapter cache time: 0.058932768646627665 Engine time: 0.028290370013564825 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-16/adapters_256_slots_256_rate_0.8-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-16/adapters_256_slots_256_rate_0.8-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 33, 8640, 8640, 33, 8640, 540, 8640, 33, 540, 33, 8640, 540, 540, 540, 540, 8640, 33, 33, 33, 540, 8640, 33, 8640, 8640, 540, 540, 540, 33, 8640, 33, 540, 540, 33, 540, 33, 33, 540, 540, 8640, 540, 33, 540, 8640, 540, 540, 8640, 540, 8640, 33, 8640, 8640, 540, 33, 33, 8640, 540, 33, 540, 540, 8640, 540, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 8640, 8640, 33, 8640, 33, 540, 8640, 8640, 8640, 540, 33, 8640, 540, 33, 33, 33, 33, 33, 8640, 540, 33, 8640, 33, 8640, 33, 33, 540, 540, 8640, 540, 8640, 33, 540, 33, 8640, 8640, 33, 8640, 540, 33, 8640, 33, 33, 8640, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 33, 540, 8640, 8640, 33, 8640, 540, 33, 540, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 540, 8640, 8640, 540, 33, 8640, 33, 540, 540, 33, 540, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 540, 8640, 540, 33, 540, 8640, 540, 8640, 33, 8640, 33, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 33, 8640, 33, 8640, 540, 540, 33, 540, 8640, 540, 540, 8640, 33, 8640, 8640, 540, 33, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 33, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 8640, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 8640, 540, 33, 33, 33, 33]
Prompts retrieved: 791745 . Total input tokens: 176476708 . Total output tokens: 158497887
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.009156639222056,
    "estimated_duration": 3600.100731169556,
    "input_throughput": 4642.025112050376,
    "output_throughput": 4075.240971169653,
    "total_throughput": 8717.266083220029,
    "itl": 171.4334630389919,
    "ttft": 1951207.6090724512,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 251,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8195552328368687,
    "arrivals": 263766,
    "finished_requests": 67261,
    "scheduler_time": 37.75449181999997
}
#Debug simulation 
Total elapsed time: 5.009273767005652. Arrivals time: 0.22159677417948842 Scheduler time: 4.640164800919592 Scheduler overhead time: 0.03256605705246329 Adapter cache time: 0.06638611620292068 Engine time: 0.033431359101086855 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-16/adapters_256_slots_256_rate_0.8-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-16/adapters_256_slots_256_rate_0.8-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 33, 8640, 8640, 33, 8640, 540, 8640, 33, 540, 33, 8640, 540, 540, 540, 540, 8640, 33, 33, 33, 540, 8640, 33, 8640, 8640, 540, 540, 540, 33, 8640, 33, 540, 540, 33, 540, 33, 33, 540, 540, 8640, 540, 33, 540, 8640, 540, 540, 8640, 540, 8640, 33, 8640, 8640, 540, 33, 33, 8640, 540, 33, 540, 540, 8640, 540, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 8640, 8640, 33, 8640, 33, 540, 8640, 8640, 8640, 540, 33, 8640, 540, 33, 33, 33, 33, 33, 8640, 540, 33, 8640, 33, 8640, 33, 33, 540, 540, 8640, 540, 8640, 33, 540, 33, 8640, 8640, 33, 8640, 540, 33, 8640, 33, 33, 8640, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 33, 540, 8640, 8640, 33, 8640, 540, 33, 540, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 540, 8640, 8640, 540, 33, 8640, 33, 540, 540, 33, 540, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 540, 8640, 540, 33, 540, 8640, 540, 8640, 33, 8640, 33, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 33, 8640, 33, 8640, 540, 540, 33, 540, 8640, 540, 540, 8640, 33, 8640, 8640, 540, 33, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 33, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 8640, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 8640, 540, 33, 33, 33, 33]
Prompts retrieved: 791745 . Total input tokens: 176476708 . Total output tokens: 158497887
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.196035757660866,
    "estimated_duration": 3600.1405557400617,
    "input_throughput": 4641.6373864505695,
    "output_throughput": 4075.183391550698,
    "total_throughput": 8716.820778001267,
    "itl": 171.2548820388419,
    "ttft": 1951111.0363801897,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 251,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.785233226087878,
    "arrivals": 263766,
    "finished_requests": 67255,
    "scheduler_time": 37.72460193784835
}
#Debug simulation 
Total elapsed time: 5.196132309734821. Arrivals time: 0.2214420479722321 Scheduler time: 4.826586371753365 Scheduler overhead time: 0.03264032257720828 Adapter cache time: 0.06638882448896766 Engine time: 0.03380816709250212 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-16/adapters_256_slots_256_rate_0.8-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-16/adapters_256_slots_256_rate_0.8-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 33, 8640, 8640, 33, 8640, 540, 8640, 33, 540, 33, 8640, 540, 540, 540, 540, 8640, 33, 33, 33, 540, 8640, 33, 8640, 8640, 540, 540, 540, 33, 8640, 33, 540, 540, 33, 540, 33, 33, 540, 540, 8640, 540, 33, 540, 8640, 540, 540, 8640, 540, 8640, 33, 8640, 8640, 540, 33, 33, 8640, 540, 33, 540, 540, 8640, 540, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 8640, 8640, 33, 8640, 33, 540, 8640, 8640, 8640, 540, 33, 8640, 540, 33, 33, 33, 33, 33, 8640, 540, 33, 8640, 33, 8640, 33, 33, 540, 540, 8640, 540, 8640, 33, 540, 33, 8640, 8640, 33, 8640, 540, 33, 8640, 33, 33, 8640, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 33, 540, 8640, 8640, 33, 8640, 540, 33, 540, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 540, 8640, 8640, 540, 33, 8640, 33, 540, 540, 33, 540, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 540, 8640, 540, 33, 540, 8640, 540, 8640, 33, 8640, 33, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 33, 8640, 33, 8640, 540, 540, 33, 540, 8640, 540, 540, 8640, 33, 8640, 8640, 540, 33, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 33, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 8640, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 8640, 540, 33, 33, 33, 33]
Prompts retrieved: 791745 . Total input tokens: 176476708 . Total output tokens: 158497887
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.021728004794568,
    "estimated_duration": 3600.181739830684,
    "input_throughput": 4641.756224447137,
    "output_throughput": 4075.1417734511333,
    "total_throughput": 8716.89799789827,
    "itl": 171.3377194941475,
    "ttft": 1951208.9931954138,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 251,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7505026240204471,
    "arrivals": 263766,
    "finished_requests": 67257,
    "scheduler_time": 37.738863125798154
}
#Debug simulation 
Total elapsed time: 5.021822732873261. Arrivals time: 0.24716121377423406 Scheduler time: 4.6260186661966145 Scheduler overhead time: 0.03262412967160344 Adapter cache time: 0.06706815399229527 Engine time: 0.03377997549250722 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-8/adapters_256_slots_256_rate_0.8-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-8/adapters_256_slots_256_rate_0.8-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 8640, 135, 8640, 8640, 135, 8640, 270, 8640, 135, 270, 135, 8640, 270, 270, 270, 270, 8640, 135, 135, 135, 270, 8640, 135, 8640, 8640, 270, 270, 270, 135, 8640, 135, 270, 270, 135, 270, 135, 135, 270, 270, 8640, 270, 135, 270, 8640, 270, 270, 8640, 270, 8640, 135, 8640, 8640, 270, 135, 135, 8640, 270, 135, 270, 270, 8640, 270, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 8640, 8640, 135, 8640, 135, 270, 8640, 8640, 8640, 270, 135, 8640, 270, 135, 135, 135, 135, 135, 8640, 270, 135, 8640, 135, 8640, 135, 135, 270, 270, 8640, 270, 8640, 135, 270, 135, 8640, 8640, 135, 8640, 270, 135, 8640, 135, 135, 8640, 8640, 270, 8640, 8640, 135, 8640, 270, 270, 135, 270, 8640, 8640, 135, 8640, 270, 135, 270, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 270, 8640, 8640, 270, 135, 8640, 135, 270, 270, 135, 270, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 270, 8640, 270, 135, 270, 8640, 270, 8640, 135, 8640, 135, 270, 8640, 270, 8640, 270, 8640, 270, 8640, 270, 135, 8640, 135, 8640, 270, 270, 135, 270, 8640, 270, 270, 8640, 135, 8640, 8640, 270, 135, 8640, 8640, 270, 270, 8640, 8640, 270, 270, 270, 270, 8640, 8640, 270, 270, 8640, 135, 8640, 270, 8640, 8640, 135, 8640, 270, 270, 8640, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 8640, 270, 135, 135, 135, 135]
Prompts retrieved: 777465 . Total input tokens: 173287228 . Total output tokens: 155617124
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.121743260417134,
    "estimated_duration": 3600.0374404901727,
    "input_throughput": 4790.815730419647,
    "output_throughput": 4240.948115784375,
    "total_throughput": 9031.763846204021,
    "itl": 202.82045242708966,
    "ttft": 1909395.798535027,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.783484862446784,
    "arrivals": 258949,
    "finished_requests": 69554,
    "scheduler_time": 43.8424450057784
}
#Debug simulation 
Total elapsed time: 5.121841113083065. Arrivals time: 0.22820610413327813 Scheduler time: 4.764050125610083 Scheduler overhead time: 0.02805424528196454 Adapter cache time: 0.05923655116930604 Engine time: 0.029212934896349907 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-16/adapters_256_slots_256_rate_0.8-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-16/adapters_256_slots_256_rate_0.8-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 8640, 135, 8640, 8640, 135, 8640, 270, 8640, 135, 270, 135, 8640, 270, 270, 270, 270, 8640, 135, 135, 135, 270, 8640, 135, 8640, 8640, 270, 270, 270, 135, 8640, 135, 270, 270, 135, 270, 135, 135, 270, 270, 8640, 270, 135, 270, 8640, 270, 270, 8640, 270, 8640, 135, 8640, 8640, 270, 135, 135, 8640, 270, 135, 270, 270, 8640, 270, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 8640, 8640, 135, 8640, 135, 270, 8640, 8640, 8640, 270, 135, 8640, 270, 135, 135, 135, 135, 135, 8640, 270, 135, 8640, 135, 8640, 135, 135, 270, 270, 8640, 270, 8640, 135, 270, 135, 8640, 8640, 135, 8640, 270, 135, 8640, 135, 135, 8640, 8640, 270, 8640, 8640, 135, 8640, 270, 270, 135, 270, 8640, 8640, 135, 8640, 270, 135, 270, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 270, 8640, 8640, 270, 135, 8640, 135, 270, 270, 135, 270, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 270, 8640, 270, 135, 270, 8640, 270, 8640, 135, 8640, 135, 270, 8640, 270, 8640, 270, 8640, 270, 8640, 270, 135, 8640, 135, 8640, 270, 270, 135, 270, 8640, 270, 270, 8640, 135, 8640, 8640, 270, 135, 8640, 8640, 270, 270, 8640, 8640, 270, 270, 270, 270, 8640, 8640, 270, 270, 8640, 135, 8640, 270, 8640, 8640, 135, 8640, 270, 270, 8640, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 8640, 270, 135, 135, 135, 135]
Prompts retrieved: 777465 . Total input tokens: 173287228 . Total output tokens: 155617124
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.1762537700124085,
    "estimated_duration": 3600.0588230546887,
    "input_throughput": 4733.582376729161,
    "output_throughput": 4197.431692846106,
    "total_throughput": 8931.014069575267,
    "itl": 167.15559222743832,
    "ttft": 1921825.62290352,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8353226749482602,
    "arrivals": 258949,
    "finished_requests": 68727,
    "scheduler_time": 39.01274331503574
}
#Debug simulation 
Total elapsed time: 5.176348579116166. Arrivals time: 0.22549446439370513 Scheduler time: 4.801347967237234 Scheduler overhead time: 0.03346262266859412 Adapter cache time: 0.06606102269142866 Engine time: 0.03441849863156676 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-16/adapters_256_slots_256_rate_0.8-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-16/adapters_256_slots_256_rate_0.8-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 8640, 135, 8640, 8640, 135, 8640, 270, 8640, 135, 270, 135, 8640, 270, 270, 270, 270, 8640, 135, 135, 135, 270, 8640, 135, 8640, 8640, 270, 270, 270, 135, 8640, 135, 270, 270, 135, 270, 135, 135, 270, 270, 8640, 270, 135, 270, 8640, 270, 270, 8640, 270, 8640, 135, 8640, 8640, 270, 135, 135, 8640, 270, 135, 270, 270, 8640, 270, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 8640, 8640, 135, 8640, 135, 270, 8640, 8640, 8640, 270, 135, 8640, 270, 135, 135, 135, 135, 135, 8640, 270, 135, 8640, 135, 8640, 135, 135, 270, 270, 8640, 270, 8640, 135, 270, 135, 8640, 8640, 135, 8640, 270, 135, 8640, 135, 135, 8640, 8640, 270, 8640, 8640, 135, 8640, 270, 270, 135, 270, 8640, 8640, 135, 8640, 270, 135, 270, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 270, 8640, 8640, 270, 135, 8640, 135, 270, 270, 135, 270, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 270, 8640, 270, 135, 270, 8640, 270, 8640, 135, 8640, 135, 270, 8640, 270, 8640, 270, 8640, 270, 8640, 270, 135, 8640, 135, 8640, 270, 270, 135, 270, 8640, 270, 270, 8640, 135, 8640, 8640, 270, 135, 8640, 8640, 270, 270, 8640, 8640, 270, 270, 270, 270, 8640, 8640, 270, 270, 8640, 135, 8640, 270, 8640, 8640, 135, 8640, 270, 270, 8640, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 8640, 270, 135, 135, 135, 135]
Prompts retrieved: 777465 . Total input tokens: 173287228 . Total output tokens: 155617124
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.135755365714431,
    "estimated_duration": 3600.1002011454484,
    "input_throughput": 4733.43963997949,
    "output_throughput": 4197.382893729489,
    "total_throughput": 8930.822533708979,
    "itl": 167.1618874430302,
    "ttft": 1921782.0302600206,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8005920728808292,
    "arrivals": 258949,
    "finished_requests": 68726,
    "scheduler_time": 39.013921999285024
}
#Debug simulation 
Total elapsed time: 5.135855477768928. Arrivals time: 0.2294237408787012 Scheduler time: 4.7579884440638125 Scheduler overhead time: 0.03336630342528224 Adapter cache time: 0.06515911500900984 Engine time: 0.034334948752075434 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-16/adapters_256_slots_256_rate_0.8-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-16/adapters_256_slots_256_rate_0.8-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 8640, 135, 8640, 8640, 135, 8640, 270, 8640, 135, 270, 135, 8640, 270, 270, 270, 270, 8640, 135, 135, 135, 270, 8640, 135, 8640, 8640, 270, 270, 270, 135, 8640, 135, 270, 270, 135, 270, 135, 135, 270, 270, 8640, 270, 135, 270, 8640, 270, 270, 8640, 270, 8640, 135, 8640, 8640, 270, 135, 135, 8640, 270, 135, 270, 270, 8640, 270, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 8640, 8640, 135, 8640, 135, 270, 8640, 8640, 8640, 270, 135, 8640, 270, 135, 135, 135, 135, 135, 8640, 270, 135, 8640, 135, 8640, 135, 135, 270, 270, 8640, 270, 8640, 135, 270, 135, 8640, 8640, 135, 8640, 270, 135, 8640, 135, 135, 8640, 8640, 270, 8640, 8640, 135, 8640, 270, 270, 135, 270, 8640, 8640, 135, 8640, 270, 135, 270, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 270, 8640, 8640, 270, 135, 8640, 135, 270, 270, 135, 270, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 270, 8640, 270, 135, 270, 8640, 270, 8640, 135, 8640, 135, 270, 8640, 270, 8640, 270, 8640, 270, 8640, 270, 135, 8640, 135, 8640, 270, 270, 135, 270, 8640, 270, 270, 8640, 135, 8640, 8640, 270, 135, 8640, 8640, 270, 270, 8640, 8640, 270, 270, 270, 270, 8640, 8640, 270, 270, 8640, 135, 8640, 270, 8640, 8640, 135, 8640, 270, 270, 8640, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 8640, 270, 135, 135, 135, 135]
Prompts retrieved: 777465 . Total input tokens: 173287228 . Total output tokens: 155617124
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.1346693858504295,
    "estimated_duration": 3600.1621903897444,
    "input_throughput": 4733.446466797976,
    "output_throughput": 4197.311176795654,
    "total_throughput": 8930.757643593632,
    "itl": 167.15650009900827,
    "ttft": 1921833.9328859576,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.765452875494958,
    "arrivals": 258949,
    "finished_requests": 68727,
    "scheduler_time": 39.014657161816515
}
#Debug simulation 
Total elapsed time: 5.134765259921551. Arrivals time: 0.22352388594299555 Scheduler time: 4.762304151896387 Scheduler overhead time: 0.03343136142939329 Adapter cache time: 0.06573872594162822 Engine time: 0.034227877389639616 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-8/adapters_256_slots_256_rate_0.8-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-8/adapters_256_slots_256_rate_0.8-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 8640, 66, 8640, 8640, 66, 8640, 270, 8640, 66, 270, 66, 8640, 270, 270, 270, 270, 8640, 66, 66, 66, 270, 8640, 66, 8640, 8640, 270, 270, 270, 66, 8640, 66, 270, 270, 66, 270, 66, 66, 270, 270, 8640, 270, 66, 270, 8640, 270, 270, 8640, 270, 8640, 66, 8640, 8640, 270, 66, 66, 8640, 270, 66, 270, 270, 8640, 270, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 8640, 8640, 66, 8640, 66, 270, 8640, 8640, 8640, 270, 66, 8640, 270, 66, 66, 66, 66, 66, 8640, 270, 66, 8640, 66, 8640, 66, 66, 270, 270, 8640, 270, 8640, 66, 270, 66, 8640, 8640, 66, 8640, 270, 66, 8640, 66, 66, 8640, 8640, 270, 8640, 8640, 66, 8640, 270, 270, 66, 270, 8640, 8640, 66, 8640, 270, 66, 270, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 270, 8640, 8640, 270, 66, 8640, 66, 270, 270, 66, 270, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 270, 8640, 270, 66, 270, 8640, 270, 8640, 66, 8640, 66, 270, 8640, 270, 8640, 270, 8640, 270, 8640, 270, 66, 8640, 66, 8640, 270, 270, 66, 270, 8640, 270, 270, 8640, 66, 8640, 8640, 270, 66, 8640, 8640, 270, 270, 8640, 8640, 270, 270, 270, 270, 8640, 8640, 270, 270, 8640, 66, 8640, 270, 8640, 8640, 66, 8640, 270, 270, 8640, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 8640, 270, 66, 66, 66, 66]
Prompts retrieved: 771600 . Total input tokens: 171990632 . Total output tokens: 154422380
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.276269419584423,
    "estimated_duration": 3600.1213822271397,
    "input_throughput": 4932.978951119022,
    "output_throughput": 4351.086904272523,
    "total_throughput": 9284.065855391545,
    "itl": 197.16816895308105,
    "ttft": 1890414.5840449238,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.783484862446784,
    "arrivals": 257044,
    "finished_requests": 71608,
    "scheduler_time": 44.936044876230966
}
#Debug simulation 
Total elapsed time: 5.276392791885883. Arrivals time: 0.23434853134676814 Scheduler time: 4.916869434993714 Scheduler overhead time: 0.0289337201975286 Adapter cache time: 0.05274925660341978 Engine time: 0.029959972016513348 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-16/adapters_256_slots_256_rate_0.8-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-16/adapters_256_slots_256_rate_0.8-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 8640, 66, 8640, 8640, 66, 8640, 270, 8640, 66, 270, 66, 8640, 270, 270, 270, 270, 8640, 66, 66, 66, 270, 8640, 66, 8640, 8640, 270, 270, 270, 66, 8640, 66, 270, 270, 66, 270, 66, 66, 270, 270, 8640, 270, 66, 270, 8640, 270, 270, 8640, 270, 8640, 66, 8640, 8640, 270, 66, 66, 8640, 270, 66, 270, 270, 8640, 270, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 8640, 8640, 66, 8640, 66, 270, 8640, 8640, 8640, 270, 66, 8640, 270, 66, 66, 66, 66, 66, 8640, 270, 66, 8640, 66, 8640, 66, 66, 270, 270, 8640, 270, 8640, 66, 270, 66, 8640, 8640, 66, 8640, 270, 66, 8640, 66, 66, 8640, 8640, 270, 8640, 8640, 66, 8640, 270, 270, 66, 270, 8640, 8640, 66, 8640, 270, 66, 270, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 270, 8640, 8640, 270, 66, 8640, 66, 270, 270, 66, 270, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 270, 8640, 270, 66, 270, 8640, 270, 8640, 66, 8640, 66, 270, 8640, 270, 8640, 270, 8640, 270, 8640, 270, 66, 8640, 66, 8640, 270, 270, 66, 270, 8640, 270, 270, 8640, 66, 8640, 8640, 270, 66, 8640, 8640, 270, 270, 8640, 8640, 270, 270, 270, 270, 8640, 8640, 270, 270, 8640, 66, 8640, 270, 8640, 8640, 66, 8640, 270, 270, 8640, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 8640, 270, 66, 66, 66, 66]
Prompts retrieved: 771600 . Total input tokens: 171990632 . Total output tokens: 154422380
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.451843748334795,
    "estimated_duration": 3600.14287433002,
    "input_throughput": 4852.6640774642,
    "output_throughput": 4285.362147709515,
    "total_throughput": 9138.026225173715,
    "itl": 163.190707906403,
    "ttft": 1905284.8958443892,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8353226749482603,
    "arrivals": 257044,
    "finished_requests": 70411,
    "scheduler_time": 39.7895821306444
}
#Debug simulation 
Total elapsed time: 5.451943974941969. Arrivals time: 0.2393007418140769 Scheduler time: 5.069669112097472 Scheduler overhead time: 0.03405437571927905 Adapter cache time: 0.05766962841153145 Engine time: 0.0351419048383832 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-16/adapters_256_slots_256_rate_0.8-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-16/adapters_256_slots_256_rate_0.8-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 8640, 66, 8640, 8640, 66, 8640, 270, 8640, 66, 270, 66, 8640, 270, 270, 270, 270, 8640, 66, 66, 66, 270, 8640, 66, 8640, 8640, 270, 270, 270, 66, 8640, 66, 270, 270, 66, 270, 66, 66, 270, 270, 8640, 270, 66, 270, 8640, 270, 270, 8640, 270, 8640, 66, 8640, 8640, 270, 66, 66, 8640, 270, 66, 270, 270, 8640, 270, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 8640, 8640, 66, 8640, 66, 270, 8640, 8640, 8640, 270, 66, 8640, 270, 66, 66, 66, 66, 66, 8640, 270, 66, 8640, 66, 8640, 66, 66, 270, 270, 8640, 270, 8640, 66, 270, 66, 8640, 8640, 66, 8640, 270, 66, 8640, 66, 66, 8640, 8640, 270, 8640, 8640, 66, 8640, 270, 270, 66, 270, 8640, 8640, 66, 8640, 270, 66, 270, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 270, 8640, 8640, 270, 66, 8640, 66, 270, 270, 66, 270, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 270, 8640, 270, 66, 270, 8640, 270, 8640, 66, 8640, 66, 270, 8640, 270, 8640, 270, 8640, 270, 8640, 270, 66, 8640, 66, 8640, 270, 270, 66, 270, 8640, 270, 270, 8640, 66, 8640, 8640, 270, 66, 8640, 8640, 270, 270, 8640, 8640, 270, 270, 270, 270, 8640, 8640, 270, 270, 8640, 66, 8640, 270, 8640, 8640, 66, 8640, 270, 270, 8640, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 8640, 270, 66, 66, 66, 66]
Prompts retrieved: 771600 . Total input tokens: 171990632 . Total output tokens: 154422380
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.217567381914705,
    "estimated_duration": 3600.1403101105293,
    "input_throughput": 4852.667533800547,
    "output_throughput": 4285.365199981981,
    "total_throughput": 9138.03273378253,
    "itl": 163.19437957384483,
    "ttft": 1905231.486820188,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8005920728808293,
    "arrivals": 257044,
    "finished_requests": 70411,
    "scheduler_time": 39.79190430146056
}
#Debug simulation 
Total elapsed time: 5.217669561039656. Arrivals time: 0.2310092868283391 Scheduler time: 4.843126637395471 Scheduler overhead time: 0.034156379755586386 Adapter cache time: 0.05823768908157945 Engine time: 0.03509626351296902 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-16/adapters_256_slots_256_rate_0.8-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-16/adapters_256_slots_256_rate_0.8-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 8640, 66, 8640, 8640, 66, 8640, 270, 8640, 66, 270, 66, 8640, 270, 270, 270, 270, 8640, 66, 66, 66, 270, 8640, 66, 8640, 8640, 270, 270, 270, 66, 8640, 66, 270, 270, 66, 270, 66, 66, 270, 270, 8640, 270, 66, 270, 8640, 270, 270, 8640, 270, 8640, 66, 8640, 8640, 270, 66, 66, 8640, 270, 66, 270, 270, 8640, 270, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 8640, 8640, 66, 8640, 66, 270, 8640, 8640, 8640, 270, 66, 8640, 270, 66, 66, 66, 66, 66, 8640, 270, 66, 8640, 66, 8640, 66, 66, 270, 270, 8640, 270, 8640, 66, 270, 66, 8640, 8640, 66, 8640, 270, 66, 8640, 66, 66, 8640, 8640, 270, 8640, 8640, 66, 8640, 270, 270, 66, 270, 8640, 8640, 66, 8640, 270, 66, 270, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 270, 8640, 8640, 270, 66, 8640, 66, 270, 270, 66, 270, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 270, 8640, 270, 66, 270, 8640, 270, 8640, 66, 8640, 66, 270, 8640, 270, 8640, 270, 8640, 270, 8640, 270, 66, 8640, 66, 8640, 270, 270, 66, 270, 8640, 270, 270, 8640, 66, 8640, 8640, 270, 66, 8640, 8640, 270, 270, 8640, 8640, 270, 270, 270, 270, 8640, 8640, 270, 270, 8640, 66, 8640, 270, 8640, 8640, 66, 8640, 270, 270, 8640, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 8640, 270, 66, 66, 66, 66]
Prompts retrieved: 771600 . Total input tokens: 171990632 . Total output tokens: 154422380
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.220555707812309,
    "estimated_duration": 3600.108611971118,
    "input_throughput": 4852.869422301796,
    "output_throughput": 4285.488206855181,
    "total_throughput": 9138.357629156977,
    "itl": 163.19668571075292,
    "ttft": 1905239.8094242911,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.765452875494958,
    "arrivals": 257044,
    "finished_requests": 70412,
    "scheduler_time": 39.79256153317541
}
#Debug simulation 
Total elapsed time: 5.220651397015899. Arrivals time: 0.2327362848445773 Scheduler time: 4.845246512442827 Scheduler overhead time: 0.03420513262972236 Adapter cache time: 0.05766082229092717 Engine time: 0.03491829661652446 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-8/adapters_256_slots_256_rate_0.8-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-8/adapters_256_slots_256_rate_0.8-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 8640, 33, 8640, 8640, 33, 8640, 270, 8640, 33, 270, 33, 8640, 270, 270, 270, 270, 8640, 33, 33, 33, 270, 8640, 33, 8640, 8640, 270, 270, 270, 33, 8640, 33, 270, 270, 33, 270, 33, 33, 270, 270, 8640, 270, 33, 270, 8640, 270, 270, 8640, 270, 8640, 33, 8640, 8640, 270, 33, 33, 8640, 270, 33, 270, 270, 8640, 270, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 8640, 8640, 33, 8640, 33, 270, 8640, 8640, 8640, 270, 33, 8640, 270, 33, 33, 33, 33, 33, 8640, 270, 33, 8640, 33, 8640, 33, 33, 270, 270, 8640, 270, 8640, 33, 270, 33, 8640, 8640, 33, 8640, 270, 33, 8640, 33, 33, 8640, 8640, 270, 8640, 8640, 33, 8640, 270, 270, 33, 270, 8640, 8640, 33, 8640, 270, 33, 270, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 270, 8640, 8640, 270, 33, 8640, 33, 270, 270, 33, 270, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 270, 8640, 270, 33, 270, 8640, 270, 8640, 33, 8640, 33, 270, 8640, 270, 8640, 270, 8640, 270, 8640, 270, 33, 8640, 33, 8640, 270, 270, 33, 270, 8640, 270, 270, 8640, 33, 8640, 8640, 270, 33, 8640, 8640, 270, 270, 8640, 8640, 270, 270, 270, 270, 8640, 8640, 270, 270, 8640, 33, 8640, 270, 8640, 8640, 33, 8640, 270, 270, 8640, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 8640, 270, 33, 33, 33, 33]
Prompts retrieved: 768795 . Total input tokens: 171373016 . Total output tokens: 153854187
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.347864194773138,
    "estimated_duration": 3600.1887591648406,
    "input_throughput": 5032.198368455183,
    "output_throughput": 4430.73823820848,
    "total_throughput": 9462.936606663663,
    "itl": 193.3312484238068,
    "ttft": 1878550.5885633517,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 254,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7773638869589184,
    "arrivals": 255937,
    "finished_requests": 72847,
    "scheduler_time": 45.77252601020924
}
#Debug simulation 
Total elapsed time: 5.347963517997414. Arrivals time: 0.23522552475333214 Scheduler time: 4.991823890246451 Scheduler overhead time: 0.029286975041031837 Adapter cache time: 0.04768939595669508 Engine time: 0.030276576057076454 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-16/adapters_256_slots_256_rate_0.8-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-16/adapters_256_slots_256_rate_0.8-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 8640, 33, 8640, 8640, 33, 8640, 270, 8640, 33, 270, 33, 8640, 270, 270, 270, 270, 8640, 33, 33, 33, 270, 8640, 33, 8640, 8640, 270, 270, 270, 33, 8640, 33, 270, 270, 33, 270, 33, 33, 270, 270, 8640, 270, 33, 270, 8640, 270, 270, 8640, 270, 8640, 33, 8640, 8640, 270, 33, 33, 8640, 270, 33, 270, 270, 8640, 270, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 8640, 8640, 33, 8640, 33, 270, 8640, 8640, 8640, 270, 33, 8640, 270, 33, 33, 33, 33, 33, 8640, 270, 33, 8640, 33, 8640, 33, 33, 270, 270, 8640, 270, 8640, 33, 270, 33, 8640, 8640, 33, 8640, 270, 33, 8640, 33, 33, 8640, 8640, 270, 8640, 8640, 33, 8640, 270, 270, 33, 270, 8640, 8640, 33, 8640, 270, 33, 270, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 270, 8640, 8640, 270, 33, 8640, 33, 270, 270, 33, 270, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 270, 8640, 270, 33, 270, 8640, 270, 8640, 33, 8640, 33, 270, 8640, 270, 8640, 270, 8640, 270, 8640, 270, 33, 8640, 33, 8640, 270, 270, 33, 270, 8640, 270, 270, 8640, 33, 8640, 8640, 270, 33, 8640, 8640, 270, 270, 8640, 8640, 270, 270, 270, 270, 8640, 8640, 270, 270, 8640, 33, 8640, 270, 8640, 8640, 33, 8640, 270, 270, 8640, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 8640, 270, 33, 33, 33, 33]
Prompts retrieved: 768795 . Total input tokens: 171373016 . Total output tokens: 153854187
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.315287863835692,
    "estimated_duration": 3600.1123471254646,
    "input_throughput": 4942.63825244448,
    "output_throughput": 4353.000542472752,
    "total_throughput": 9295.638794917231,
    "itl": 160.0415457064074,
    "ttft": 1896112.9463780243,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 254,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8285253837215754,
    "arrivals": 255937,
    "finished_requests": 71468,
    "scheduler_time": 40.39215502573683
}
#Debug simulation 
Total elapsed time: 5.315390519797802. Arrivals time: 0.237184158526361 Scheduler time: 4.939000705722719 Scheduler overhead time: 0.034755135886371136 Adapter cache time: 0.0525709125213325 Engine time: 0.03570162458345294 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-16-16/adapters_256_slots_256_rate_0.8-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-16-16/adapters_256_slots_256_rate_0.8-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 8640, 33, 8640, 8640, 33, 8640, 270, 8640, 33, 270, 33, 8640, 270, 270, 270, 270, 8640, 33, 33, 33, 270, 8640, 33, 8640, 8640, 270, 270, 270, 33, 8640, 33, 270, 270, 33, 270, 33, 33, 270, 270, 8640, 270, 33, 270, 8640, 270, 270, 8640, 270, 8640, 33, 8640, 8640, 270, 33, 33, 8640, 270, 33, 270, 270, 8640, 270, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 8640, 8640, 33, 8640, 33, 270, 8640, 8640, 8640, 270, 33, 8640, 270, 33, 33, 33, 33, 33, 8640, 270, 33, 8640, 33, 8640, 33, 33, 270, 270, 8640, 270, 8640, 33, 270, 33, 8640, 8640, 33, 8640, 270, 33, 8640, 33, 33, 8640, 8640, 270, 8640, 8640, 33, 8640, 270, 270, 33, 270, 8640, 8640, 33, 8640, 270, 33, 270, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 270, 8640, 8640, 270, 33, 8640, 33, 270, 270, 33, 270, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 270, 8640, 270, 33, 270, 8640, 270, 8640, 33, 8640, 33, 270, 8640, 270, 8640, 270, 8640, 270, 8640, 270, 33, 8640, 33, 8640, 270, 270, 33, 270, 8640, 270, 270, 8640, 33, 8640, 8640, 270, 33, 8640, 8640, 270, 270, 8640, 8640, 270, 270, 270, 270, 8640, 8640, 270, 270, 8640, 33, 8640, 270, 8640, 8640, 33, 8640, 270, 270, 8640, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 8640, 270, 33, 33, 33, 33]
Prompts retrieved: 768795 . Total input tokens: 171373016 . Total output tokens: 153854187
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.361709177028388,
    "estimated_duration": 3600.0964887465466,
    "input_throughput": 4942.540305689208,
    "output_throughput": 4352.8672214716435,
    "total_throughput": 9295.40752716085,
    "itl": 160.03535348039497,
    "ttft": 1896116.7067841296,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 254,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7942033769725845,
    "arrivals": 255937,
    "finished_requests": 71467,
    "scheduler_time": 40.392525271701444
}
#Debug simulation 
Total elapsed time: 5.361804387066513. Arrivals time: 0.23325236467644572 Scheduler time: 4.989199454896152 Scheduler overhead time: 0.03477660194039345 Adapter cache time: 0.052372852340340614 Engine time: 0.035969313234090805 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_16-16-16/adapters_256_slots_256_rate_0.8-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_16-16-16/adapters_256_slots_256_rate_0.8-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 8640, 33, 8640, 8640, 33, 8640, 270, 8640, 33, 270, 33, 8640, 270, 270, 270, 270, 8640, 33, 33, 33, 270, 8640, 33, 8640, 8640, 270, 270, 270, 33, 8640, 33, 270, 270, 33, 270, 33, 33, 270, 270, 8640, 270, 33, 270, 8640, 270, 270, 8640, 270, 8640, 33, 8640, 8640, 270, 33, 33, 8640, 270, 33, 270, 270, 8640, 270, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 8640, 8640, 33, 8640, 33, 270, 8640, 8640, 8640, 270, 33, 8640, 270, 33, 33, 33, 33, 33, 8640, 270, 33, 8640, 33, 8640, 33, 33, 270, 270, 8640, 270, 8640, 33, 270, 33, 8640, 8640, 33, 8640, 270, 33, 8640, 33, 33, 8640, 8640, 270, 8640, 8640, 33, 8640, 270, 270, 33, 270, 8640, 8640, 33, 8640, 270, 33, 270, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 270, 8640, 8640, 270, 33, 8640, 33, 270, 270, 33, 270, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 270, 8640, 270, 33, 270, 8640, 270, 8640, 33, 8640, 33, 270, 8640, 270, 8640, 270, 8640, 270, 8640, 270, 33, 8640, 33, 8640, 270, 270, 33, 270, 8640, 270, 270, 8640, 33, 8640, 8640, 270, 33, 8640, 8640, 270, 270, 8640, 8640, 270, 270, 270, 270, 8640, 8640, 270, 270, 8640, 33, 8640, 270, 8640, 8640, 33, 8640, 270, 270, 8640, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 8640, 270, 33, 33, 33, 33]
Prompts retrieved: 768795 . Total input tokens: 171373016 . Total output tokens: 153854187
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.314622214995325,
    "estimated_duration": 3600.041929711238,
    "input_throughput": 4942.809652616267,
    "output_throughput": 4352.9640226320835,
    "total_throughput": 9295.77367524835,
    "itl": 160.03204887173382,
    "ttft": 1896095.3642884067,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 254,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7594727749051536,
    "arrivals": 255937,
    "finished_requests": 71470,
    "scheduler_time": 40.39174005221196
}
#Debug simulation 
Total elapsed time: 5.314719393849373. Arrivals time: 0.2323685814626515 Scheduler time: 4.944076003972441 Scheduler overhead time: 0.034648864064365625 Adapter cache time: 0.051849279552698135 Engine time: 0.03562322212383151 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-8/adapters_256_slots_256_rate_0.8-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-8/adapters_256_slots_256_rate_0.8-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 8640, 66, 8640, 8640, 66, 8640, 135, 8640, 66, 135, 66, 8640, 135, 135, 135, 135, 8640, 66, 66, 66, 135, 8640, 66, 8640, 8640, 135, 135, 135, 66, 8640, 66, 135, 135, 66, 135, 66, 66, 135, 135, 8640, 135, 66, 135, 8640, 135, 135, 8640, 135, 8640, 66, 8640, 8640, 135, 66, 66, 8640, 135, 66, 135, 135, 8640, 135, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 8640, 8640, 66, 8640, 66, 135, 8640, 8640, 8640, 135, 66, 8640, 135, 66, 66, 66, 66, 66, 8640, 135, 66, 8640, 66, 8640, 66, 66, 135, 135, 8640, 135, 8640, 66, 135, 66, 8640, 8640, 66, 8640, 135, 66, 8640, 66, 66, 8640, 8640, 135, 8640, 8640, 66, 8640, 135, 135, 66, 135, 8640, 8640, 66, 8640, 135, 66, 135, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 135, 8640, 8640, 135, 66, 8640, 66, 135, 135, 66, 135, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 135, 8640, 135, 66, 135, 8640, 135, 8640, 66, 8640, 66, 135, 8640, 135, 8640, 135, 8640, 135, 8640, 135, 66, 8640, 66, 8640, 135, 135, 66, 135, 8640, 135, 135, 8640, 66, 8640, 8640, 135, 66, 8640, 8640, 135, 135, 8640, 8640, 135, 135, 135, 135, 8640, 8640, 135, 135, 8640, 66, 8640, 135, 8640, 8640, 66, 8640, 135, 135, 8640, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 8640, 135, 66, 66, 66, 66]
Prompts retrieved: 760125 . Total input tokens: 169433666 . Total output tokens: 152092898
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.511412043124437,
    "estimated_duration": 3600.0670499771177,
    "input_throughput": 5205.9472059330465,
    "output_throughput": 4549.596930452755,
    "total_throughput": 9755.5441363858,
    "itl": 187.39521660228783,
    "ttft": 1846718.776180869,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.783484862446784,
    "arrivals": 253041,
    "finished_requests": 75348,
    "scheduler_time": 46.91965450787177
}
#Debug simulation 
Total elapsed time: 5.511520492378622. Arrivals time: 0.24778626207262278 Scheduler time: 5.145287600811571 Scheduler overhead time: 0.030211365316063166 Adapter cache time: 0.042726697865873575 Engine time: 0.03135798964649439 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-16/adapters_256_slots_256_rate_0.8-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-16/adapters_256_slots_256_rate_0.8-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 8640, 66, 8640, 8640, 66, 8640, 135, 8640, 66, 135, 66, 8640, 135, 135, 135, 135, 8640, 66, 66, 66, 135, 8640, 66, 8640, 8640, 135, 135, 135, 66, 8640, 66, 135, 135, 66, 135, 66, 66, 135, 135, 8640, 135, 66, 135, 8640, 135, 135, 8640, 135, 8640, 66, 8640, 8640, 135, 66, 66, 8640, 135, 66, 135, 135, 8640, 135, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 8640, 8640, 66, 8640, 66, 135, 8640, 8640, 8640, 135, 66, 8640, 135, 66, 66, 66, 66, 66, 8640, 135, 66, 8640, 66, 8640, 66, 66, 135, 135, 8640, 135, 8640, 66, 135, 66, 8640, 8640, 66, 8640, 135, 66, 8640, 66, 66, 8640, 8640, 135, 8640, 8640, 66, 8640, 135, 135, 66, 135, 8640, 8640, 66, 8640, 135, 66, 135, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 135, 8640, 8640, 135, 66, 8640, 66, 135, 135, 66, 135, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 135, 8640, 135, 66, 135, 8640, 135, 8640, 66, 8640, 66, 135, 8640, 135, 8640, 135, 8640, 135, 8640, 135, 66, 8640, 66, 8640, 135, 135, 66, 135, 8640, 135, 135, 8640, 66, 8640, 8640, 135, 66, 8640, 8640, 135, 135, 8640, 8640, 135, 135, 135, 135, 8640, 8640, 135, 135, 8640, 66, 8640, 135, 8640, 8640, 66, 8640, 135, 135, 8640, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 8640, 135, 66, 66, 66, 66]
Prompts retrieved: 760125 . Total input tokens: 169433666 . Total output tokens: 152092898
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.427387131378055,
    "estimated_duration": 3600.173751328732,
    "input_throughput": 5098.838352794781,
    "output_throughput": 4460.622489143206,
    "total_throughput": 9559.460841937986,
    "itl": 156.5823707852195,
    "ttft": 1866853.6443964806,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8353226749482606,
    "arrivals": 253041,
    "finished_requests": 73750,
    "scheduler_time": 41.470741899407756
}
#Debug simulation 
Total elapsed time: 5.427483475301415. Arrivals time: 0.23717656917870045 Scheduler time: 5.056704914662987 Scheduler overhead time: 0.03526724735274911 Adapter cache time: 0.04539131326600909 Engine time: 0.03640987863764167 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-16-16/adapters_256_slots_256_rate_0.8-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-16-16/adapters_256_slots_256_rate_0.8-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 8640, 66, 8640, 8640, 66, 8640, 135, 8640, 66, 135, 66, 8640, 135, 135, 135, 135, 8640, 66, 66, 66, 135, 8640, 66, 8640, 8640, 135, 135, 135, 66, 8640, 66, 135, 135, 66, 135, 66, 66, 135, 135, 8640, 135, 66, 135, 8640, 135, 135, 8640, 135, 8640, 66, 8640, 8640, 135, 66, 66, 8640, 135, 66, 135, 135, 8640, 135, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 8640, 8640, 66, 8640, 66, 135, 8640, 8640, 8640, 135, 66, 8640, 135, 66, 66, 66, 66, 66, 8640, 135, 66, 8640, 66, 8640, 66, 66, 135, 135, 8640, 135, 8640, 66, 135, 66, 8640, 8640, 66, 8640, 135, 66, 8640, 66, 66, 8640, 8640, 135, 8640, 8640, 66, 8640, 135, 135, 66, 135, 8640, 8640, 66, 8640, 135, 66, 135, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 135, 8640, 8640, 135, 66, 8640, 66, 135, 135, 66, 135, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 135, 8640, 135, 66, 135, 8640, 135, 8640, 66, 8640, 66, 135, 8640, 135, 8640, 135, 8640, 135, 8640, 135, 66, 8640, 66, 8640, 135, 135, 66, 135, 8640, 135, 135, 8640, 66, 8640, 8640, 135, 66, 8640, 8640, 135, 135, 8640, 8640, 135, 135, 135, 135, 8640, 8640, 135, 135, 8640, 66, 8640, 135, 8640, 8640, 66, 8640, 135, 135, 8640, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 8640, 135, 66, 66, 66, 66]
Prompts retrieved: 760125 . Total input tokens: 169433666 . Total output tokens: 152092898
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.543422575108707,
    "estimated_duration": 3600.163034364805,
    "input_throughput": 5099.007968465202,
    "output_throughput": 4460.8296476310825,
    "total_throughput": 9559.837616096283,
    "itl": 156.584503212334,
    "ttft": 1866777.2527360471,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8005920728808295,
    "arrivals": 253041,
    "finished_requests": 73752,
    "scheduler_time": 41.471445491264454
}
#Debug simulation 
Total elapsed time: 5.543522312305868. Arrivals time: 0.24533254373818636 Scheduler time: 5.165031750220805 Scheduler overhead time: 0.03526195976883173 Adapter cache time: 0.04521868284791708 Engine time: 0.036198573652654886 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_16-16-16/adapters_256_slots_256_rate_0.8-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_16-16-16/adapters_256_slots_256_rate_0.8-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 8640, 66, 8640, 8640, 66, 8640, 135, 8640, 66, 135, 66, 8640, 135, 135, 135, 135, 8640, 66, 66, 66, 135, 8640, 66, 8640, 8640, 135, 135, 135, 66, 8640, 66, 135, 135, 66, 135, 66, 66, 135, 135, 8640, 135, 66, 135, 8640, 135, 135, 8640, 135, 8640, 66, 8640, 8640, 135, 66, 66, 8640, 135, 66, 135, 135, 8640, 135, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 8640, 8640, 66, 8640, 66, 135, 8640, 8640, 8640, 135, 66, 8640, 135, 66, 66, 66, 66, 66, 8640, 135, 66, 8640, 66, 8640, 66, 66, 135, 135, 8640, 135, 8640, 66, 135, 66, 8640, 8640, 66, 8640, 135, 66, 8640, 66, 66, 8640, 8640, 135, 8640, 8640, 66, 8640, 135, 135, 66, 135, 8640, 8640, 66, 8640, 135, 66, 135, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 135, 8640, 8640, 135, 66, 8640, 66, 135, 135, 66, 135, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 135, 8640, 135, 66, 135, 8640, 135, 8640, 66, 8640, 66, 135, 8640, 135, 8640, 135, 8640, 135, 8640, 135, 66, 8640, 66, 8640, 135, 135, 66, 135, 8640, 135, 135, 8640, 66, 8640, 8640, 135, 66, 8640, 8640, 135, 135, 8640, 8640, 135, 135, 135, 135, 8640, 8640, 135, 135, 8640, 66, 8640, 135, 8640, 8640, 66, 8640, 135, 135, 8640, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 8640, 135, 66, 66, 66, 66]
Prompts retrieved: 760125 . Total input tokens: 169433666 . Total output tokens: 152092898
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.420492722187191,
    "estimated_duration": 3600.026222023245,
    "input_throughput": 5099.047303517523,
    "output_throughput": 4460.805285738918,
    "total_throughput": 9559.852589256441,
    "itl": 156.58228731049266,
    "ttft": 1866708.7220053687,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.765452875494958,
    "arrivals": 253041,
    "finished_requests": 73750,
    "scheduler_time": 41.47037009928307
}
#Debug simulation 
Total elapsed time: 5.420588525943458. Arrivals time: 0.24847297463566065 Scheduler time: 5.038966428954154 Scheduler overhead time: 0.035287912003695965 Adapter cache time: 0.04458905570209026 Engine time: 0.036666274070739746 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-8/adapters_256_slots_256_rate_0.8-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-8/adapters_256_slots_256_rate_0.8-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 8640, 33, 8640, 8640, 33, 8640, 135, 8640, 33, 135, 33, 8640, 135, 135, 135, 135, 8640, 33, 33, 33, 135, 8640, 33, 8640, 8640, 135, 135, 135, 33, 8640, 33, 135, 135, 33, 135, 33, 33, 135, 135, 8640, 135, 33, 135, 8640, 135, 135, 8640, 135, 8640, 33, 8640, 8640, 135, 33, 33, 8640, 135, 33, 135, 135, 8640, 135, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 8640, 8640, 33, 8640, 33, 135, 8640, 8640, 8640, 135, 33, 8640, 135, 33, 33, 33, 33, 33, 8640, 135, 33, 8640, 33, 8640, 33, 33, 135, 135, 8640, 135, 8640, 33, 135, 33, 8640, 8640, 33, 8640, 135, 33, 8640, 33, 33, 8640, 8640, 135, 8640, 8640, 33, 8640, 135, 135, 33, 135, 8640, 8640, 33, 8640, 135, 33, 135, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 135, 8640, 8640, 135, 33, 8640, 33, 135, 135, 33, 135, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 135, 8640, 135, 33, 135, 8640, 135, 8640, 33, 8640, 33, 135, 8640, 135, 8640, 135, 8640, 135, 8640, 135, 33, 8640, 33, 8640, 135, 135, 33, 135, 8640, 135, 135, 8640, 33, 8640, 8640, 135, 33, 8640, 8640, 135, 135, 8640, 8640, 135, 135, 135, 135, 8640, 8640, 135, 135, 8640, 33, 8640, 135, 8640, 8640, 33, 8640, 135, 135, 8640, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 8640, 135, 33, 33, 33, 33]
Prompts retrieved: 757320 . Total input tokens: 168812283 . Total output tokens: 151525896
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.545340007636696,
    "estimated_duration": 3600.040492709557,
    "input_throughput": 5272.004867288369,
    "output_throughput": 4653.640711521746,
    "total_throughput": 9925.645578810114,
    "itl": 184.6989239971056,
    "ttft": 1828860.4804240144,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 253,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7743033992149857,
    "arrivals": 252137,
    "finished_requests": 76339,
    "scheduler_time": 48.105976256235806
}
#Debug simulation 
Total elapsed time: 5.545463460031897. Arrivals time: 0.24560648016631603 Scheduler time: 5.190705543849617 Scheduler overhead time: 0.030422528740018606 Adapter cache time: 0.032925513572990894 Engine time: 0.03157120617106557 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-16/adapters_256_slots_256_rate_0.8-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-16/adapters_256_slots_256_rate_0.8-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 8640, 33, 8640, 8640, 33, 8640, 135, 8640, 33, 135, 33, 8640, 135, 135, 135, 135, 8640, 33, 33, 33, 135, 8640, 33, 8640, 8640, 135, 135, 135, 33, 8640, 33, 135, 135, 33, 135, 33, 33, 135, 135, 8640, 135, 33, 135, 8640, 135, 135, 8640, 135, 8640, 33, 8640, 8640, 135, 33, 33, 8640, 135, 33, 135, 135, 8640, 135, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 8640, 8640, 33, 8640, 33, 135, 8640, 8640, 8640, 135, 33, 8640, 135, 33, 33, 33, 33, 33, 8640, 135, 33, 8640, 33, 8640, 33, 33, 135, 135, 8640, 135, 8640, 33, 135, 33, 8640, 8640, 33, 8640, 135, 33, 8640, 33, 33, 8640, 8640, 135, 8640, 8640, 33, 8640, 135, 135, 33, 135, 8640, 8640, 33, 8640, 135, 33, 135, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 135, 8640, 8640, 135, 33, 8640, 33, 135, 135, 33, 135, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 135, 8640, 135, 33, 135, 8640, 135, 8640, 33, 8640, 33, 135, 8640, 135, 8640, 135, 8640, 135, 8640, 135, 33, 8640, 33, 8640, 135, 135, 33, 135, 8640, 135, 135, 8640, 33, 8640, 8640, 135, 33, 8640, 8640, 135, 135, 8640, 8640, 135, 135, 135, 135, 8640, 8640, 135, 135, 8640, 33, 8640, 135, 8640, 8640, 33, 8640, 135, 135, 8640, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 8640, 135, 33, 33, 33, 33]
Prompts retrieved: 757320 . Total input tokens: 168812283 . Total output tokens: 151525896
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.545650151092559,
    "estimated_duration": 3600.166910548237,
    "input_throughput": 5133.45393677474,
    "output_throughput": 4540.993072321322,
    "total_throughput": 9674.447009096062,
    "itl": 153.89071281014049,
    "ttft": 1853040.1927342415,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 253,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8251267381082324,
    "arrivals": 252137,
    "finished_requests": 74384,
    "scheduler_time": 42.20941522491935
}
#Debug simulation 
Total elapsed time: 5.5457575540058315. Arrivals time: 0.24918580008670688 Scheduler time: 5.170464851427823 Scheduler overhead time: 0.036126716528087854 Adapter cache time: 0.036052913405001163 Engine time: 0.03713985765352845 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-16/adapters_256_slots_256_rate_0.8-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-16/adapters_256_slots_256_rate_0.8-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 8640, 33, 8640, 8640, 33, 8640, 135, 8640, 33, 135, 33, 8640, 135, 135, 135, 135, 8640, 33, 33, 33, 135, 8640, 33, 8640, 8640, 135, 135, 135, 33, 8640, 33, 135, 135, 33, 135, 33, 33, 135, 135, 8640, 135, 33, 135, 8640, 135, 135, 8640, 135, 8640, 33, 8640, 8640, 135, 33, 33, 8640, 135, 33, 135, 135, 8640, 135, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 8640, 8640, 33, 8640, 33, 135, 8640, 8640, 8640, 135, 33, 8640, 135, 33, 33, 33, 33, 33, 8640, 135, 33, 8640, 33, 8640, 33, 33, 135, 135, 8640, 135, 8640, 33, 135, 33, 8640, 8640, 33, 8640, 135, 33, 8640, 33, 33, 8640, 8640, 135, 8640, 8640, 33, 8640, 135, 135, 33, 135, 8640, 8640, 33, 8640, 135, 33, 135, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 135, 8640, 8640, 135, 33, 8640, 33, 135, 135, 33, 135, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 135, 8640, 135, 33, 135, 8640, 135, 8640, 33, 8640, 33, 135, 8640, 135, 8640, 135, 8640, 135, 8640, 135, 33, 8640, 33, 8640, 135, 135, 33, 135, 8640, 135, 135, 8640, 33, 8640, 8640, 135, 33, 8640, 8640, 135, 135, 8640, 8640, 135, 135, 135, 135, 8640, 8640, 135, 135, 8640, 33, 8640, 135, 8640, 8640, 33, 8640, 135, 135, 8640, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 8640, 135, 33, 33, 33, 33]
Prompts retrieved: 757320 . Total input tokens: 168812283 . Total output tokens: 151525896
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.4899963471107185,
    "estimated_duration": 3600.068704764239,
    "input_throughput": 5133.373420219281,
    "output_throughput": 4541.090834840224,
    "total_throughput": 9674.464255059505,
    "itl": 153.88379803878107,
    "ttft": 1852937.1266084686,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 253,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7912133266776823,
    "arrivals": 252137,
    "finished_requests": 74381,
    "scheduler_time": 42.2068876789449
}
#Debug simulation 
Total elapsed time: 5.490091081243008. Arrivals time: 0.23920352337881923 Scheduler time: 5.125125151127577 Scheduler overhead time: 0.03615164756774902 Adapter cache time: 0.03576608840376139 Engine time: 0.03697256185114384 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-16/adapters_256_slots_256_rate_0.8-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-16/adapters_256_slots_256_rate_0.8-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 8640, 33, 8640, 8640, 33, 8640, 135, 8640, 33, 135, 33, 8640, 135, 135, 135, 135, 8640, 33, 33, 33, 135, 8640, 33, 8640, 8640, 135, 135, 135, 33, 8640, 33, 135, 135, 33, 135, 33, 33, 135, 135, 8640, 135, 33, 135, 8640, 135, 135, 8640, 135, 8640, 33, 8640, 8640, 135, 33, 33, 8640, 135, 33, 135, 135, 8640, 135, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 8640, 8640, 33, 8640, 33, 135, 8640, 8640, 8640, 135, 33, 8640, 135, 33, 33, 33, 33, 33, 8640, 135, 33, 8640, 33, 8640, 33, 33, 135, 135, 8640, 135, 8640, 33, 135, 33, 8640, 8640, 33, 8640, 135, 33, 8640, 33, 33, 8640, 8640, 135, 8640, 8640, 33, 8640, 135, 135, 33, 135, 8640, 8640, 33, 8640, 135, 33, 135, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 135, 8640, 8640, 135, 33, 8640, 33, 135, 135, 33, 135, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 135, 8640, 135, 33, 135, 8640, 135, 8640, 33, 8640, 33, 135, 8640, 135, 8640, 135, 8640, 135, 8640, 135, 33, 8640, 33, 8640, 135, 135, 33, 135, 8640, 135, 135, 8640, 33, 8640, 8640, 135, 33, 8640, 8640, 135, 135, 8640, 8640, 135, 135, 135, 135, 8640, 8640, 135, 135, 8640, 33, 8640, 135, 8640, 8640, 33, 8640, 135, 135, 8640, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 8640, 135, 33, 33, 33, 33]
Prompts retrieved: 757320 . Total input tokens: 168812283 . Total output tokens: 151525896
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.534098776988685,
    "estimated_duration": 3600.0903344341195,
    "input_throughput": 5133.3425784452875,
    "output_throughput": 4541.063551553825,
    "total_throughput": 9674.406129999112,
    "itl": 153.88672135344683,
    "ttft": 1852936.618024341,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 253,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7564827246102515,
    "arrivals": 252137,
    "finished_requests": 74381,
    "scheduler_time": 42.208069544605756
}
#Debug simulation 
Total elapsed time: 5.534206285141408. Arrivals time: 0.24607912823557854 Scheduler time: 5.162107263691723 Scheduler overhead time: 0.03597080148756504 Adapter cache time: 0.03610484302043915 Engine time: 0.03713738638907671 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-8/adapters_256_slots_256_rate_0.8-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-8/adapters_256_slots_256_rate_0.8-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 8640, 33, 8640, 8640, 33, 8640, 66, 8640, 33, 66, 33, 8640, 66, 66, 66, 66, 8640, 33, 33, 33, 66, 8640, 33, 8640, 8640, 66, 66, 66, 33, 8640, 33, 66, 66, 33, 66, 33, 33, 66, 66, 8640, 66, 33, 66, 8640, 66, 66, 8640, 66, 8640, 33, 8640, 8640, 66, 33, 33, 8640, 66, 33, 66, 66, 8640, 66, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 8640, 8640, 33, 8640, 33, 66, 8640, 8640, 8640, 66, 33, 8640, 66, 33, 33, 33, 33, 33, 8640, 66, 33, 8640, 33, 8640, 33, 33, 66, 66, 8640, 66, 8640, 33, 66, 33, 8640, 8640, 33, 8640, 66, 33, 8640, 33, 33, 8640, 8640, 66, 8640, 8640, 33, 8640, 66, 66, 33, 66, 8640, 8640, 33, 8640, 66, 33, 66, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 66, 8640, 8640, 66, 33, 8640, 33, 66, 66, 33, 66, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 66, 8640, 66, 33, 66, 8640, 66, 8640, 33, 8640, 33, 66, 8640, 66, 8640, 66, 8640, 66, 8640, 66, 33, 8640, 33, 8640, 66, 66, 33, 66, 8640, 66, 66, 8640, 33, 8640, 8640, 66, 33, 8640, 8640, 66, 66, 8640, 8640, 66, 66, 66, 66, 8640, 8640, 66, 66, 8640, 33, 8640, 66, 8640, 8640, 33, 8640, 66, 66, 8640, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 8640, 66, 33, 33, 33, 33]
Prompts retrieved: 751455 . Total input tokens: 167503193 . Total output tokens: 150337789
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.715430128853768,
    "estimated_duration": 3600.1573430229455,
    "input_throughput": 5437.683171803314,
    "output_throughput": 4792.159996405479,
    "total_throughput": 10229.843168208794,
    "itl": 179.0278148700882,
    "ttft": 1793935.645580713,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 253,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7743033992149857,
    "arrivals": 250206,
    "finished_requests": 79073,
    "scheduler_time": 49.57376036539315
}
#Debug simulation 
Total elapsed time: 5.71555564366281. Arrivals time: 0.24969490338116884 Scheduler time: 5.361306884326041 Scheduler overhead time: 0.031525618862360716 Adapter cache time: 0.025934951845556498 Engine time: 0.03241866547614336 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-16/adapters_256_slots_256_rate_0.8-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-16/adapters_256_slots_256_rate_0.8-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 8640, 33, 8640, 8640, 33, 8640, 66, 8640, 33, 66, 33, 8640, 66, 66, 66, 66, 8640, 33, 33, 33, 66, 8640, 33, 8640, 8640, 66, 66, 66, 33, 8640, 33, 66, 66, 33, 66, 33, 33, 66, 66, 8640, 66, 33, 66, 8640, 66, 66, 8640, 66, 8640, 33, 8640, 8640, 66, 33, 33, 8640, 66, 33, 66, 66, 8640, 66, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 8640, 8640, 33, 8640, 33, 66, 8640, 8640, 8640, 66, 33, 8640, 66, 33, 33, 33, 33, 33, 8640, 66, 33, 8640, 33, 8640, 33, 33, 66, 66, 8640, 66, 8640, 33, 66, 33, 8640, 8640, 33, 8640, 66, 33, 8640, 33, 33, 8640, 8640, 66, 8640, 8640, 33, 8640, 66, 66, 33, 66, 8640, 8640, 33, 8640, 66, 33, 66, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 66, 8640, 8640, 66, 33, 8640, 33, 66, 66, 33, 66, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 66, 8640, 66, 33, 66, 8640, 66, 8640, 33, 8640, 33, 66, 8640, 66, 8640, 66, 8640, 66, 8640, 66, 33, 8640, 33, 8640, 66, 66, 33, 66, 8640, 66, 66, 8640, 33, 8640, 8640, 66, 33, 8640, 8640, 66, 66, 8640, 8640, 66, 66, 66, 66, 8640, 8640, 66, 66, 8640, 33, 8640, 66, 8640, 8640, 33, 8640, 66, 66, 8640, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 8640, 66, 33, 33, 33, 33]
Prompts retrieved: 751455 . Total input tokens: 167503193 . Total output tokens: 150337789
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.633010129444301,
    "estimated_duration": 3600.0437993399823,
    "input_throughput": 5274.966377765062,
    "output_throughput": 4659.767751457782,
    "total_throughput": 9934.734129222845,
    "itl": 150.15228583589237,
    "ttft": 1821700.374875429,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 253,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8251267381082326,
    "arrivals": 250206,
    "finished_requests": 76745,
    "scheduler_time": 43.368194685543735
}
#Debug simulation 
Total elapsed time: 5.633106866385788. Arrivals time: 0.24799346644431353 Scheduler time: 5.265085211955011 Scheduler overhead time: 0.036999878007918596 Adapter cache time: 0.027660242281854153 Engine time: 0.03809265838935971 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-16/adapters_256_slots_256_rate_0.8-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-16/adapters_256_slots_256_rate_0.8-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 8640, 33, 8640, 8640, 33, 8640, 66, 8640, 33, 66, 33, 8640, 66, 66, 66, 66, 8640, 33, 33, 33, 66, 8640, 33, 8640, 8640, 66, 66, 66, 33, 8640, 33, 66, 66, 33, 66, 33, 33, 66, 66, 8640, 66, 33, 66, 8640, 66, 66, 8640, 66, 8640, 33, 8640, 8640, 66, 33, 33, 8640, 66, 33, 66, 66, 8640, 66, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 8640, 8640, 33, 8640, 33, 66, 8640, 8640, 8640, 66, 33, 8640, 66, 33, 33, 33, 33, 33, 8640, 66, 33, 8640, 33, 8640, 33, 33, 66, 66, 8640, 66, 8640, 33, 66, 33, 8640, 8640, 33, 8640, 66, 33, 8640, 33, 33, 8640, 8640, 66, 8640, 8640, 33, 8640, 66, 66, 33, 66, 8640, 8640, 33, 8640, 66, 33, 66, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 66, 8640, 8640, 66, 33, 8640, 33, 66, 66, 33, 66, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 66, 8640, 66, 33, 66, 8640, 66, 8640, 33, 8640, 33, 66, 8640, 66, 8640, 66, 8640, 66, 8640, 66, 33, 8640, 33, 8640, 66, 66, 33, 66, 8640, 66, 66, 8640, 33, 8640, 8640, 66, 33, 8640, 8640, 66, 66, 8640, 8640, 66, 66, 66, 66, 8640, 8640, 66, 66, 8640, 33, 8640, 66, 8640, 8640, 33, 8640, 66, 66, 8640, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 8640, 66, 33, 33, 33, 33]
Prompts retrieved: 751455 . Total input tokens: 167503193 . Total output tokens: 150337789
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.618571000173688,
    "estimated_duration": 3600.1576436891123,
    "input_throughput": 5275.23733114616,
    "output_throughput": 4659.882888575171,
    "total_throughput": 9935.12021972133,
    "itl": 150.15469293529426,
    "ttft": 1821674.7052918784,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 253,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7912133266776826,
    "arrivals": 250206,
    "finished_requests": 76750,
    "scheduler_time": 43.370049703738786
}
#Debug simulation 
Total elapsed time: 5.618666106835008. Arrivals time: 0.25176268722862005 Scheduler time: 5.247793518472463 Scheduler overhead time: 0.03672175761312246 Adapter cache time: 0.027438053395599127 Engine time: 0.037677816580981016 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-16/adapters_256_slots_256_rate_0.8-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-16/adapters_256_slots_256_rate_0.8-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 8640, 33, 8640, 8640, 33, 8640, 66, 8640, 33, 66, 33, 8640, 66, 66, 66, 66, 8640, 33, 33, 33, 66, 8640, 33, 8640, 8640, 66, 66, 66, 33, 8640, 33, 66, 66, 33, 66, 33, 33, 66, 66, 8640, 66, 33, 66, 8640, 66, 66, 8640, 66, 8640, 33, 8640, 8640, 66, 33, 33, 8640, 66, 33, 66, 66, 8640, 66, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 8640, 8640, 33, 8640, 33, 66, 8640, 8640, 8640, 66, 33, 8640, 66, 33, 33, 33, 33, 33, 8640, 66, 33, 8640, 33, 8640, 33, 33, 66, 66, 8640, 66, 8640, 33, 66, 33, 8640, 8640, 33, 8640, 66, 33, 8640, 33, 33, 8640, 8640, 66, 8640, 8640, 33, 8640, 66, 66, 33, 66, 8640, 8640, 33, 8640, 66, 33, 66, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 66, 8640, 8640, 66, 33, 8640, 33, 66, 66, 33, 66, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 66, 8640, 66, 33, 66, 8640, 66, 8640, 33, 8640, 33, 66, 8640, 66, 8640, 66, 8640, 66, 8640, 66, 33, 8640, 33, 8640, 66, 66, 33, 66, 8640, 66, 66, 8640, 33, 8640, 8640, 66, 33, 8640, 8640, 66, 66, 8640, 8640, 66, 66, 66, 66, 8640, 8640, 66, 66, 8640, 33, 8640, 66, 8640, 8640, 33, 8640, 66, 66, 8640, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 8640, 66, 33, 33, 33, 33]
Prompts retrieved: 751455 . Total input tokens: 167503193 . Total output tokens: 150337789
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.591096034273505,
    "estimated_duration": 3600.0016672457505,
    "input_throughput": 5275.105056973197,
    "output_throughput": 4659.837564140451,
    "total_throughput": 9934.942621113649,
    "itl": 150.15652007232552,
    "ttft": 1821694.0453691343,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 253,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7564827246102515,
    "arrivals": 250206,
    "finished_requests": 76745,
    "scheduler_time": 43.36960408796744
}
#Debug simulation 
Total elapsed time: 5.591223001014441. Arrivals time: 0.24338863184675574 Scheduler time: 5.2282475521788 Scheduler overhead time: 0.03664061054587364 Adapter cache time: 0.027893914841115475 Engine time: 0.0378830386325717 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-8/adapters_256_slots_256_rate_0.4-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-8/adapters_256_slots_256_rate_0.4-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 540, 4320, 4320, 540, 4320, 1080, 4320, 540, 1080, 540, 4320, 1080, 1080, 1080, 1080, 4320, 540, 540, 540, 1080, 4320, 540, 4320, 4320, 1080, 1080, 1080, 540, 4320, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 4320, 1080, 540, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 540, 4320, 4320, 1080, 540, 540, 4320, 1080, 540, 1080, 1080, 4320, 1080, 540, 540, 4320, 4320, 4320, 4320, 4320, 4320, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 4320, 4320, 540, 4320, 540, 1080, 4320, 4320, 4320, 1080, 540, 4320, 1080, 540, 540, 540, 540, 540, 4320, 1080, 540, 4320, 540, 4320, 540, 540, 1080, 1080, 4320, 1080, 4320, 540, 1080, 540, 4320, 4320, 540, 4320, 1080, 540, 4320, 540, 540, 4320, 4320, 1080, 4320, 4320, 540, 4320, 1080, 1080, 540, 1080, 4320, 4320, 540, 4320, 1080, 540, 1080, 4320, 540, 540, 540, 540, 540, 540, 4320, 540, 540, 540, 4320, 540, 1080, 4320, 4320, 1080, 540, 4320, 540, 1080, 1080, 540, 1080, 540, 4320, 540, 540, 4320, 540, 4320, 4320, 1080, 4320, 1080, 540, 1080, 4320, 1080, 4320, 540, 4320, 540, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 540, 4320, 540, 4320, 1080, 1080, 540, 1080, 4320, 1080, 1080, 4320, 540, 4320, 4320, 1080, 540, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 540, 4320, 1080, 4320, 4320, 540, 4320, 1080, 1080, 4320, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 540, 540, 540, 540]
Prompts retrieved: 509220 . Total input tokens: 113498046 . Total output tokens: 101959663
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 3.8133559902198613,
    "estimated_duration": 3600.1368436845555,
    "input_throughput": 3430.0901705063084,
    "output_throughput": 3030.7947930203864,
    "total_throughput": 6460.884963526695,
    "itl": 281.66993138397277,
    "ttft": 2036002.2022971178,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.783484862446784,
    "arrivals": 169450,
    "finished_requests": 49872,
    "scheduler_time": 31.98624037150053
}
#Debug simulation 
Total elapsed time: 3.8134513520635664. Arrivals time: 0.1809577369131148 Scheduler time: 3.4988525230437517 Scheduler overhead time: 0.020548840519040823 Adapter cache time: 0.08238070644438267 Engine time: 0.021191599313169718 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-16/adapters_256_slots_256_rate_0.4-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-16/adapters_256_slots_256_rate_0.4-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 540, 4320, 4320, 540, 4320, 1080, 4320, 540, 1080, 540, 4320, 1080, 1080, 1080, 1080, 4320, 540, 540, 540, 1080, 4320, 540, 4320, 4320, 1080, 1080, 1080, 540, 4320, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 4320, 1080, 540, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 540, 4320, 4320, 1080, 540, 540, 4320, 1080, 540, 1080, 1080, 4320, 1080, 540, 540, 4320, 4320, 4320, 4320, 4320, 4320, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 4320, 4320, 540, 4320, 540, 1080, 4320, 4320, 4320, 1080, 540, 4320, 1080, 540, 540, 540, 540, 540, 4320, 1080, 540, 4320, 540, 4320, 540, 540, 1080, 1080, 4320, 1080, 4320, 540, 1080, 540, 4320, 4320, 540, 4320, 1080, 540, 4320, 540, 540, 4320, 4320, 1080, 4320, 4320, 540, 4320, 1080, 1080, 540, 1080, 4320, 4320, 540, 4320, 1080, 540, 1080, 4320, 540, 540, 540, 540, 540, 540, 4320, 540, 540, 540, 4320, 540, 1080, 4320, 4320, 1080, 540, 4320, 540, 1080, 1080, 540, 1080, 540, 4320, 540, 540, 4320, 540, 4320, 4320, 1080, 4320, 1080, 540, 1080, 4320, 1080, 4320, 540, 4320, 540, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 540, 4320, 540, 4320, 1080, 1080, 540, 1080, 4320, 1080, 1080, 4320, 540, 4320, 4320, 1080, 540, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 540, 4320, 1080, 4320, 4320, 540, 4320, 1080, 1080, 4320, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 540, 540, 540, 540]
Prompts retrieved: 509220 . Total input tokens: 113498046 . Total output tokens: 101959663
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.853822272270918,
    "estimated_duration": 3600.244327257018,
    "input_throughput": 3419.3090471110063,
    "output_throughput": 3029.156359593217,
    "total_throughput": 6448.465406704223,
    "itl": 228.97426478717745,
    "ttft": 2042227.103204123,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8353226749482603,
    "arrivals": 169450,
    "finished_requests": 49730,
    "scheduler_time": 28.7890049421382
}
#Debug simulation 
Total elapsed time: 3.8539190790615976. Arrivals time: 0.18054756429046392 Scheduler time: 3.502668971195817 Scheduler overhead time: 0.02480411808937788 Adapter cache time: 0.10879448521882296 Engine time: 0.025612193625420332 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-16-16/adapters_256_slots_256_rate_0.4-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-16-16/adapters_256_slots_256_rate_0.4-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 540, 4320, 4320, 540, 4320, 1080, 4320, 540, 1080, 540, 4320, 1080, 1080, 1080, 1080, 4320, 540, 540, 540, 1080, 4320, 540, 4320, 4320, 1080, 1080, 1080, 540, 4320, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 4320, 1080, 540, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 540, 4320, 4320, 1080, 540, 540, 4320, 1080, 540, 1080, 1080, 4320, 1080, 540, 540, 4320, 4320, 4320, 4320, 4320, 4320, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 4320, 4320, 540, 4320, 540, 1080, 4320, 4320, 4320, 1080, 540, 4320, 1080, 540, 540, 540, 540, 540, 4320, 1080, 540, 4320, 540, 4320, 540, 540, 1080, 1080, 4320, 1080, 4320, 540, 1080, 540, 4320, 4320, 540, 4320, 1080, 540, 4320, 540, 540, 4320, 4320, 1080, 4320, 4320, 540, 4320, 1080, 1080, 540, 1080, 4320, 4320, 540, 4320, 1080, 540, 1080, 4320, 540, 540, 540, 540, 540, 540, 4320, 540, 540, 540, 4320, 540, 1080, 4320, 4320, 1080, 540, 4320, 540, 1080, 1080, 540, 1080, 540, 4320, 540, 540, 4320, 540, 4320, 4320, 1080, 4320, 1080, 540, 1080, 4320, 1080, 4320, 540, 4320, 540, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 540, 4320, 540, 4320, 1080, 1080, 540, 1080, 4320, 1080, 1080, 4320, 540, 4320, 4320, 1080, 540, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 540, 4320, 1080, 4320, 4320, 540, 4320, 1080, 1080, 4320, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 540, 540, 540, 540]
Prompts retrieved: 509220 . Total input tokens: 113498046 . Total output tokens: 101959663
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 3.8664558134041727,
    "estimated_duration": 3600.137741266987,
    "input_throughput": 3419.1211238678934,
    "output_throughput": 3028.9391083582186,
    "total_throughput": 6448.060232226112,
    "itl": 228.95407208871876,
    "ttft": 2042309.5188388575,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8005920728808293,
    "arrivals": 169450,
    "finished_requests": 49728,
    "scheduler_time": 28.787171429275624
}
#Debug simulation 
Total elapsed time: 3.866551026236266. Arrivals time: 0.1814166740514338 Scheduler time: 3.513809414114803 Scheduler overhead time: 0.02514781430363655 Adapter cache time: 0.10895826807245612 Engine time: 0.025690337643027306 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_16-16-16/adapters_256_slots_256_rate_0.4-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_16-16-16/adapters_256_slots_256_rate_0.4-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 540, 4320, 4320, 540, 4320, 1080, 4320, 540, 1080, 540, 4320, 1080, 1080, 1080, 1080, 4320, 540, 540, 540, 1080, 4320, 540, 4320, 4320, 1080, 1080, 1080, 540, 4320, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 4320, 1080, 540, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 540, 4320, 4320, 1080, 540, 540, 4320, 1080, 540, 1080, 1080, 4320, 1080, 540, 540, 4320, 4320, 4320, 4320, 4320, 4320, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 4320, 4320, 540, 4320, 540, 1080, 4320, 4320, 4320, 1080, 540, 4320, 1080, 540, 540, 540, 540, 540, 4320, 1080, 540, 4320, 540, 4320, 540, 540, 1080, 1080, 4320, 1080, 4320, 540, 1080, 540, 4320, 4320, 540, 4320, 1080, 540, 4320, 540, 540, 4320, 4320, 1080, 4320, 4320, 540, 4320, 1080, 1080, 540, 1080, 4320, 4320, 540, 4320, 1080, 540, 1080, 4320, 540, 540, 540, 540, 540, 540, 4320, 540, 540, 540, 4320, 540, 1080, 4320, 4320, 1080, 540, 4320, 540, 1080, 1080, 540, 1080, 540, 4320, 540, 540, 4320, 540, 4320, 4320, 1080, 4320, 1080, 540, 1080, 4320, 1080, 4320, 540, 4320, 540, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 540, 4320, 540, 4320, 1080, 1080, 540, 1080, 4320, 1080, 1080, 4320, 540, 4320, 4320, 1080, 540, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 540, 4320, 1080, 4320, 4320, 540, 4320, 1080, 1080, 4320, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 540, 540, 540, 540]
Prompts retrieved: 509220 . Total input tokens: 113498046 . Total output tokens: 101959663
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.02377643994987,
    "estimated_duration": 3600.226389669964,
    "input_throughput": 3419.3188615365098,
    "output_throughput": 3029.1183996903364,
    "total_throughput": 6448.437261226846,
    "itl": 228.95193739494664,
    "ttft": 2042247.8884899323,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.765452875494958,
    "arrivals": 169450,
    "finished_requests": 49732,
    "scheduler_time": 28.787867285115812
}
#Debug simulation 
Total elapsed time: 4.023873351980001. Arrivals time: 0.17984338430687785 Scheduler time: 3.6723244916647673 Scheduler overhead time: 0.02497266512364149 Adapter cache time: 0.1094769942574203 Engine time: 0.025737222749739885 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-8/adapters_256_slots_256_rate_0.4-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-8/adapters_256_slots_256_rate_0.4-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 270, 4320, 4320, 270, 4320, 1080, 4320, 270, 1080, 270, 4320, 1080, 1080, 1080, 1080, 4320, 270, 270, 270, 1080, 4320, 270, 4320, 4320, 1080, 1080, 1080, 270, 4320, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 4320, 1080, 270, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 270, 4320, 4320, 1080, 270, 270, 4320, 1080, 270, 1080, 1080, 4320, 1080, 270, 270, 4320, 4320, 4320, 4320, 4320, 4320, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 4320, 4320, 270, 4320, 270, 1080, 4320, 4320, 4320, 1080, 270, 4320, 1080, 270, 270, 270, 270, 270, 4320, 1080, 270, 4320, 270, 4320, 270, 270, 1080, 1080, 4320, 1080, 4320, 270, 1080, 270, 4320, 4320, 270, 4320, 1080, 270, 4320, 270, 270, 4320, 4320, 1080, 4320, 4320, 270, 4320, 1080, 1080, 270, 1080, 4320, 4320, 270, 4320, 1080, 270, 1080, 4320, 270, 270, 270, 270, 270, 270, 4320, 270, 270, 270, 4320, 270, 1080, 4320, 4320, 1080, 270, 4320, 270, 1080, 1080, 270, 1080, 270, 4320, 270, 270, 4320, 270, 4320, 4320, 1080, 4320, 1080, 270, 1080, 4320, 1080, 4320, 270, 4320, 270, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 270, 4320, 270, 4320, 1080, 1080, 270, 1080, 4320, 1080, 1080, 4320, 270, 4320, 4320, 1080, 270, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 270, 4320, 1080, 4320, 4320, 270, 4320, 1080, 1080, 4320, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 270, 270, 270, 270]
Prompts retrieved: 486270 . Total input tokens: 108366334 . Total output tokens: 97337453
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.020997533109039,
    "estimated_duration": 3600.260727896946,
    "input_throughput": 3655.2761020969842,
    "output_throughput": 3214.978823703492,
    "total_throughput": 6870.2549258004765,
    "itl": 265.09575466903186,
    "ttft": 1962618.8172330705,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.783484862446784,
    "arrivals": 161934,
    "finished_requests": 53233,
    "scheduler_time": 34.0436571153064
}
#Debug simulation 
Total elapsed time: 4.021093199029565. Arrivals time: 0.18744007823988795 Scheduler time: 3.701464484911412 Scheduler overhead time: 0.021792603190988302 Adapter cache time: 0.07738444861024618 Engine time: 0.022863215766847134 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-16/adapters_256_slots_256_rate_0.4-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-16/adapters_256_slots_256_rate_0.4-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 270, 4320, 4320, 270, 4320, 1080, 4320, 270, 1080, 270, 4320, 1080, 1080, 1080, 1080, 4320, 270, 270, 270, 1080, 4320, 270, 4320, 4320, 1080, 1080, 1080, 270, 4320, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 4320, 1080, 270, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 270, 4320, 4320, 1080, 270, 270, 4320, 1080, 270, 1080, 1080, 4320, 1080, 270, 270, 4320, 4320, 4320, 4320, 4320, 4320, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 4320, 4320, 270, 4320, 270, 1080, 4320, 4320, 4320, 1080, 270, 4320, 1080, 270, 270, 270, 270, 270, 4320, 1080, 270, 4320, 270, 4320, 270, 270, 1080, 1080, 4320, 1080, 4320, 270, 1080, 270, 4320, 4320, 270, 4320, 1080, 270, 4320, 270, 270, 4320, 4320, 1080, 4320, 4320, 270, 4320, 1080, 1080, 270, 1080, 4320, 4320, 270, 4320, 1080, 270, 1080, 4320, 270, 270, 270, 270, 270, 270, 4320, 270, 270, 270, 4320, 270, 1080, 4320, 4320, 1080, 270, 4320, 270, 1080, 1080, 270, 1080, 270, 4320, 270, 270, 4320, 270, 4320, 4320, 1080, 4320, 1080, 270, 1080, 4320, 1080, 4320, 270, 4320, 270, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 270, 4320, 270, 4320, 1080, 1080, 270, 1080, 4320, 1080, 1080, 4320, 270, 4320, 4320, 1080, 270, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 270, 4320, 1080, 4320, 4320, 270, 4320, 1080, 1080, 4320, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 270, 270, 270, 270]
Prompts retrieved: 486270 . Total input tokens: 108366334 . Total output tokens: 97337453
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.063274260144681,
    "estimated_duration": 3600.1646580679135,
    "input_throughput": 3635.9556418247216,
    "output_throughput": 3205.522273582161,
    "total_throughput": 6841.477915406882,
    "itl": 217.7689049080521,
    "ttft": 1970912.9714066638,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8353226749482602,
    "arrivals": 161934,
    "finished_requests": 52943,
    "scheduler_time": 30.741239521458546
}
#Debug simulation 
Total elapsed time: 4.063369322102517. Arrivals time: 0.18985489290207624 Scheduler time: 3.7099866257049143 Scheduler overhead time: 0.025922933127731085 Adapter cache time: 0.09869464486837387 Engine time: 0.026868449989706278 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-16-16/adapters_256_slots_256_rate_0.4-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-16-16/adapters_256_slots_256_rate_0.4-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 270, 4320, 4320, 270, 4320, 1080, 4320, 270, 1080, 270, 4320, 1080, 1080, 1080, 1080, 4320, 270, 270, 270, 1080, 4320, 270, 4320, 4320, 1080, 1080, 1080, 270, 4320, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 4320, 1080, 270, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 270, 4320, 4320, 1080, 270, 270, 4320, 1080, 270, 1080, 1080, 4320, 1080, 270, 270, 4320, 4320, 4320, 4320, 4320, 4320, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 4320, 4320, 270, 4320, 270, 1080, 4320, 4320, 4320, 1080, 270, 4320, 1080, 270, 270, 270, 270, 270, 4320, 1080, 270, 4320, 270, 4320, 270, 270, 1080, 1080, 4320, 1080, 4320, 270, 1080, 270, 4320, 4320, 270, 4320, 1080, 270, 4320, 270, 270, 4320, 4320, 1080, 4320, 4320, 270, 4320, 1080, 1080, 270, 1080, 4320, 4320, 270, 4320, 1080, 270, 1080, 4320, 270, 270, 270, 270, 270, 270, 4320, 270, 270, 270, 4320, 270, 1080, 4320, 4320, 1080, 270, 4320, 270, 1080, 1080, 270, 1080, 270, 4320, 270, 270, 4320, 270, 4320, 4320, 1080, 4320, 1080, 270, 1080, 4320, 1080, 4320, 270, 4320, 270, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 270, 4320, 270, 4320, 1080, 1080, 270, 1080, 4320, 1080, 1080, 4320, 270, 4320, 4320, 1080, 270, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 270, 4320, 1080, 4320, 4320, 270, 4320, 1080, 1080, 4320, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 270, 270, 270, 270]
Prompts retrieved: 486270 . Total input tokens: 108366334 . Total output tokens: 97337453
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.052502296864986,
    "estimated_duration": 3600.2382812525207,
    "input_throughput": 3636.0243343242837,
    "output_throughput": 3205.5278285594504,
    "total_throughput": 6841.552162883734,
    "itl": 217.7526380493613,
    "ttft": 1970920.3198260479,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8005920728808291,
    "arrivals": 161934,
    "finished_requests": 52944,
    "scheduler_time": 30.741807333290858
}
#Debug simulation 
Total elapsed time: 4.052598783746362. Arrivals time: 0.18486485537141562 Scheduler time: 3.704565982799977 Scheduler overhead time: 0.02599055040627718 Adapter cache time: 0.09820401156321168 Engine time: 0.026849623769521713 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_16-16-16/adapters_256_slots_256_rate_0.4-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_16-16-16/adapters_256_slots_256_rate_0.4-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 270, 4320, 4320, 270, 4320, 1080, 4320, 270, 1080, 270, 4320, 1080, 1080, 1080, 1080, 4320, 270, 270, 270, 1080, 4320, 270, 4320, 4320, 1080, 1080, 1080, 270, 4320, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 4320, 1080, 270, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 270, 4320, 4320, 1080, 270, 270, 4320, 1080, 270, 1080, 1080, 4320, 1080, 270, 270, 4320, 4320, 4320, 4320, 4320, 4320, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 4320, 4320, 270, 4320, 270, 1080, 4320, 4320, 4320, 1080, 270, 4320, 1080, 270, 270, 270, 270, 270, 4320, 1080, 270, 4320, 270, 4320, 270, 270, 1080, 1080, 4320, 1080, 4320, 270, 1080, 270, 4320, 4320, 270, 4320, 1080, 270, 4320, 270, 270, 4320, 4320, 1080, 4320, 4320, 270, 4320, 1080, 1080, 270, 1080, 4320, 4320, 270, 4320, 1080, 270, 1080, 4320, 270, 270, 270, 270, 270, 270, 4320, 270, 270, 270, 4320, 270, 1080, 4320, 4320, 1080, 270, 4320, 270, 1080, 1080, 270, 1080, 270, 4320, 270, 270, 4320, 270, 4320, 4320, 1080, 4320, 1080, 270, 1080, 4320, 1080, 4320, 270, 4320, 270, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 270, 4320, 270, 4320, 1080, 1080, 270, 1080, 4320, 1080, 1080, 4320, 270, 4320, 4320, 1080, 270, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 270, 4320, 1080, 4320, 4320, 270, 4320, 1080, 1080, 4320, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 270, 270, 270, 270]
Prompts retrieved: 486270 . Total input tokens: 108366334 . Total output tokens: 97337453
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.075705032795668,
    "estimated_duration": 3600.004225600212,
    "input_throughput": 3635.9754543948193,
    "output_throughput": 3205.58929290589,
    "total_throughput": 6841.564747300709,
    "itl": 217.74288005790433,
    "ttft": 1970948.145819256,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.765452875494958,
    "arrivals": 161934,
    "finished_requests": 52941,
    "scheduler_time": 30.738997740325846
}
#Debug simulation 
Total elapsed time: 4.075831086840481. Arrivals time: 0.19069939060136676 Scheduler time: 3.7211736030876637 Scheduler overhead time: 0.02605138160288334 Adapter cache time: 0.09865805972367525 Engine time: 0.027017608750611544 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-8/adapters_256_slots_256_rate_0.4-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-8/adapters_256_slots_256_rate_0.4-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 135, 4320, 4320, 135, 4320, 1080, 4320, 135, 1080, 135, 4320, 1080, 1080, 1080, 1080, 4320, 135, 135, 135, 1080, 4320, 135, 4320, 4320, 1080, 1080, 1080, 135, 4320, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 4320, 1080, 135, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 135, 4320, 4320, 1080, 135, 135, 4320, 1080, 135, 1080, 1080, 4320, 1080, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 4320, 4320, 135, 4320, 135, 1080, 4320, 4320, 4320, 1080, 135, 4320, 1080, 135, 135, 135, 135, 135, 4320, 1080, 135, 4320, 135, 4320, 135, 135, 1080, 1080, 4320, 1080, 4320, 135, 1080, 135, 4320, 4320, 135, 4320, 1080, 135, 4320, 135, 135, 4320, 4320, 1080, 4320, 4320, 135, 4320, 1080, 1080, 135, 1080, 4320, 4320, 135, 4320, 1080, 135, 1080, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 1080, 4320, 4320, 1080, 135, 4320, 135, 1080, 1080, 135, 1080, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 4320, 135, 4320, 135, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 1080, 1080, 135, 1080, 4320, 1080, 1080, 4320, 135, 4320, 4320, 1080, 135, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 135, 4320, 1080, 4320, 4320, 135, 4320, 1080, 1080, 4320, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 135, 135, 135, 135]
Prompts retrieved: 474795 . Total input tokens: 105806663 . Total output tokens: 95022632
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.210415306966752,
    "estimated_duration": 3600.0119257320707,
    "input_throughput": 3822.6248367778862,
    "output_throughput": 3372.632716357181,
    "total_throughput": 7195.257553135067,
    "itl": 252.87548085032878,
    "ttft": 1910319.9775394392,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.783484862446784,
    "arrivals": 158124,
    "finished_requests": 55729,
    "scheduler_time": 35.78030646818926
}
#Debug simulation 
Total elapsed time: 4.210518653038889. Arrivals time: 0.21295621758326888 Scheduler time: 3.8750093653798103 Scheduler overhead time: 0.02277214452624321 Adapter cache time: 0.0654977667145431 Engine time: 0.023721571546047926 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-16/adapters_256_slots_256_rate_0.4-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-16/adapters_256_slots_256_rate_0.4-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 135, 4320, 4320, 135, 4320, 1080, 4320, 135, 1080, 135, 4320, 1080, 1080, 1080, 1080, 4320, 135, 135, 135, 1080, 4320, 135, 4320, 4320, 1080, 1080, 1080, 135, 4320, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 4320, 1080, 135, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 135, 4320, 4320, 1080, 135, 135, 4320, 1080, 135, 1080, 1080, 4320, 1080, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 4320, 4320, 135, 4320, 135, 1080, 4320, 4320, 4320, 1080, 135, 4320, 1080, 135, 135, 135, 135, 135, 4320, 1080, 135, 4320, 135, 4320, 135, 135, 1080, 1080, 4320, 1080, 4320, 135, 1080, 135, 4320, 4320, 135, 4320, 1080, 135, 4320, 135, 135, 4320, 4320, 1080, 4320, 4320, 135, 4320, 1080, 1080, 135, 1080, 4320, 4320, 135, 4320, 1080, 135, 1080, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 1080, 4320, 4320, 1080, 135, 4320, 135, 1080, 1080, 135, 1080, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 4320, 135, 4320, 135, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 1080, 1080, 135, 1080, 4320, 1080, 1080, 4320, 135, 4320, 4320, 1080, 135, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 135, 4320, 1080, 4320, 4320, 135, 4320, 1080, 1080, 4320, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 135, 135, 135, 135]
Prompts retrieved: 474795 . Total input tokens: 105806663 . Total output tokens: 95022632
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.213919539004564,
    "estimated_duration": 3600.18911035046,
    "input_throughput": 3782.8685056697636,
    "output_throughput": 3343.797125931569,
    "total_throughput": 7126.665631601332,
    "itl": 208.75942079299966,
    "ttft": 1924000.3136769454,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8353226749482604,
    "arrivals": 158124,
    "finished_requests": 55130,
    "scheduler_time": 32.123737001042514
}
#Debug simulation 
Total elapsed time: 4.214009718038142. Arrivals time: 0.2036401336081326 Scheduler time: 3.8592242770828307 Scheduler overhead time: 0.026983282063156366 Adapter cache time: 0.08351240633055568 Engine time: 0.028050999157130718 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-16/adapters_256_slots_256_rate_0.4-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-16/adapters_256_slots_256_rate_0.4-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 135, 4320, 4320, 135, 4320, 1080, 4320, 135, 1080, 135, 4320, 1080, 1080, 1080, 1080, 4320, 135, 135, 135, 1080, 4320, 135, 4320, 4320, 1080, 1080, 1080, 135, 4320, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 4320, 1080, 135, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 135, 4320, 4320, 1080, 135, 135, 4320, 1080, 135, 1080, 1080, 4320, 1080, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 4320, 4320, 135, 4320, 135, 1080, 4320, 4320, 4320, 1080, 135, 4320, 1080, 135, 135, 135, 135, 135, 4320, 1080, 135, 4320, 135, 4320, 135, 135, 1080, 1080, 4320, 1080, 4320, 135, 1080, 135, 4320, 4320, 135, 4320, 1080, 135, 4320, 135, 135, 4320, 4320, 1080, 4320, 4320, 135, 4320, 1080, 1080, 135, 1080, 4320, 4320, 135, 4320, 1080, 135, 1080, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 1080, 4320, 4320, 1080, 135, 4320, 135, 1080, 1080, 135, 1080, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 4320, 135, 4320, 135, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 1080, 1080, 135, 1080, 4320, 1080, 1080, 4320, 135, 4320, 4320, 1080, 135, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 135, 4320, 1080, 4320, 4320, 135, 4320, 1080, 1080, 4320, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 135, 135, 135, 135]
Prompts retrieved: 474795 . Total input tokens: 105806663 . Total output tokens: 95022632
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.230366946198046,
    "estimated_duration": 3600.1939417452336,
    "input_throughput": 3782.6581624095447,
    "output_throughput": 3343.5882051855956,
    "total_throughput": 7126.24636759514,
    "itl": 208.7536675757278,
    "ttft": 1923946.5381630042,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8005920728808293,
    "arrivals": 158124,
    "finished_requests": 55128,
    "scheduler_time": 32.12458016781319
}
#Debug simulation 
Total elapsed time: 4.230461486149579. Arrivals time: 0.20447580888867378 Scheduler time: 3.8750512953847647 Scheduler overhead time: 0.02697350224480033 Adapter cache time: 0.08316095033660531 Engine time: 0.028177740518003702 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-16/adapters_256_slots_256_rate_0.4-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-16/adapters_256_slots_256_rate_0.4-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 135, 4320, 4320, 135, 4320, 1080, 4320, 135, 1080, 135, 4320, 1080, 1080, 1080, 1080, 4320, 135, 135, 135, 1080, 4320, 135, 4320, 4320, 1080, 1080, 1080, 135, 4320, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 4320, 1080, 135, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 135, 4320, 4320, 1080, 135, 135, 4320, 1080, 135, 1080, 1080, 4320, 1080, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 4320, 4320, 135, 4320, 135, 1080, 4320, 4320, 4320, 1080, 135, 4320, 1080, 135, 135, 135, 135, 135, 4320, 1080, 135, 4320, 135, 4320, 135, 135, 1080, 1080, 4320, 1080, 4320, 135, 1080, 135, 4320, 4320, 135, 4320, 1080, 135, 4320, 135, 135, 4320, 4320, 1080, 4320, 4320, 135, 4320, 1080, 1080, 135, 1080, 4320, 4320, 135, 4320, 1080, 135, 1080, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 1080, 4320, 4320, 1080, 135, 4320, 135, 1080, 1080, 135, 1080, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 4320, 135, 4320, 135, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 1080, 1080, 135, 1080, 4320, 1080, 1080, 4320, 135, 4320, 4320, 1080, 135, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 135, 4320, 1080, 4320, 4320, 135, 4320, 1080, 1080, 4320, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 135, 135, 135, 135]
Prompts retrieved: 474795 . Total input tokens: 105806663 . Total output tokens: 95022632
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.183353844098747,
    "estimated_duration": 3600.0291662080535,
    "input_throughput": 3782.9429627495815,
    "output_throughput": 3343.7854095719604,
    "total_throughput": 7126.728372321542,
    "itl": 208.76491320314008,
    "ttft": 1923905.029627834,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.765452875494958,
    "arrivals": 158124,
    "finished_requests": 55129,
    "scheduler_time": 32.12487810313301
}
#Debug simulation 
Total elapsed time: 4.183477689977735. Arrivals time: 0.19242772599682212 Scheduler time: 3.842018326744437 Scheduler overhead time: 0.026913850102573633 Adapter cache time: 0.08202625997364521 Engine time: 0.027532536536455154 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-8/adapters_256_slots_256_rate_0.4-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-8/adapters_256_slots_256_rate_0.4-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 66, 4320, 4320, 66, 4320, 1080, 4320, 66, 1080, 66, 4320, 1080, 1080, 1080, 1080, 4320, 66, 66, 66, 1080, 4320, 66, 4320, 4320, 1080, 1080, 1080, 66, 4320, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 4320, 1080, 66, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 66, 4320, 4320, 1080, 66, 66, 4320, 1080, 66, 1080, 1080, 4320, 1080, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 4320, 4320, 66, 4320, 66, 1080, 4320, 4320, 4320, 1080, 66, 4320, 1080, 66, 66, 66, 66, 66, 4320, 1080, 66, 4320, 66, 4320, 66, 66, 1080, 1080, 4320, 1080, 4320, 66, 1080, 66, 4320, 4320, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 66, 1080, 4320, 4320, 66, 4320, 1080, 66, 1080, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 1080, 4320, 4320, 1080, 66, 4320, 66, 1080, 1080, 66, 1080, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 4320, 66, 4320, 66, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 1080, 1080, 66, 1080, 4320, 1080, 1080, 4320, 66, 4320, 4320, 1080, 66, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 66, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 4320, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 66, 66, 66, 66]
Prompts retrieved: 468930 . Total input tokens: 104482091 . Total output tokens: 93835645
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.272233281284571,
    "estimated_duration": 3600.1679545514594,
    "input_throughput": 3949.6299004671214,
    "output_throughput": 3486.24318599706,
    "total_throughput": 7435.873086464182,
    "itl": 245.01071740698836,
    "ttft": 1872814.8684596112,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.783484862446784,
    "arrivals": 156118,
    "finished_requests": 57471,
    "scheduler_time": 36.98297760597337
}
#Debug simulation 
Total elapsed time: 4.272331995423883. Arrivals time: 0.1958304480649531 Scheduler time: 3.9633249868638813 Scheduler overhead time: 0.02338530123233795 Adapter cache time: 0.05462327226996422 Engine time: 0.024199821054935455 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-16/adapters_256_slots_256_rate_0.4-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-16/adapters_256_slots_256_rate_0.4-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 66, 4320, 4320, 66, 4320, 1080, 4320, 66, 1080, 66, 4320, 1080, 1080, 1080, 1080, 4320, 66, 66, 66, 1080, 4320, 66, 4320, 4320, 1080, 1080, 1080, 66, 4320, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 4320, 1080, 66, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 66, 4320, 4320, 1080, 66, 66, 4320, 1080, 66, 1080, 1080, 4320, 1080, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 4320, 4320, 66, 4320, 66, 1080, 4320, 4320, 4320, 1080, 66, 4320, 1080, 66, 66, 66, 66, 66, 4320, 1080, 66, 4320, 66, 4320, 66, 66, 1080, 1080, 4320, 1080, 4320, 66, 1080, 66, 4320, 4320, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 66, 1080, 4320, 4320, 66, 4320, 1080, 66, 1080, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 1080, 4320, 4320, 1080, 66, 4320, 66, 1080, 1080, 66, 1080, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 4320, 66, 4320, 66, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 1080, 1080, 66, 1080, 4320, 1080, 1080, 4320, 66, 4320, 4320, 1080, 66, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 66, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 4320, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 66, 66, 66, 66]
Prompts retrieved: 468930 . Total input tokens: 104482091 . Total output tokens: 93835645
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.274642173666507,
    "estimated_duration": 3600.1614248520677,
    "input_throughput": 3890.3133352070463,
    "output_throughput": 3437.633633472015,
    "total_throughput": 7327.946968679062,
    "itl": 202.5525564269902,
    "ttft": 1890758.917737271,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8353226749482603,
    "arrivals": 156118,
    "finished_requests": 56581,
    "scheduler_time": 33.03355882154624
}
#Debug simulation 
Total elapsed time: 4.274737985804677. Arrivals time: 0.19338811514899135 Scheduler time: 3.9396220021881163 Scheduler overhead time: 0.02778802253305912 Adapter cache time: 0.07246503420174122 Engine time: 0.02858943259343505 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-16/adapters_256_slots_256_rate_0.4-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-16/adapters_256_slots_256_rate_0.4-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 66, 4320, 4320, 66, 4320, 1080, 4320, 66, 1080, 66, 4320, 1080, 1080, 1080, 1080, 4320, 66, 66, 66, 1080, 4320, 66, 4320, 4320, 1080, 1080, 1080, 66, 4320, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 4320, 1080, 66, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 66, 4320, 4320, 1080, 66, 66, 4320, 1080, 66, 1080, 1080, 4320, 1080, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 4320, 4320, 66, 4320, 66, 1080, 4320, 4320, 4320, 1080, 66, 4320, 1080, 66, 66, 66, 66, 66, 4320, 1080, 66, 4320, 66, 4320, 66, 66, 1080, 1080, 4320, 1080, 4320, 66, 1080, 66, 4320, 4320, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 66, 1080, 4320, 4320, 66, 4320, 1080, 66, 1080, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 1080, 4320, 4320, 1080, 66, 4320, 66, 1080, 1080, 66, 1080, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 4320, 66, 4320, 66, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 1080, 1080, 66, 1080, 4320, 1080, 1080, 4320, 66, 4320, 4320, 1080, 66, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 66, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 4320, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 66, 66, 66, 66]
Prompts retrieved: 468930 . Total input tokens: 104482091 . Total output tokens: 93835645
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.302350284066051,
    "estimated_duration": 3600.069049997944,
    "input_throughput": 3889.8115023677105,
    "output_throughput": 3437.376291437262,
    "total_throughput": 7327.187793804973,
    "itl": 202.55966115107316,
    "ttft": 1890767.9673629738,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8005920728808292,
    "arrivals": 156118,
    "finished_requests": 56573,
    "scheduler_time": 33.033472540450035
}
#Debug simulation 
Total elapsed time: 4.302457105368376. Arrivals time: 0.2067362223751843 Scheduler time: 3.9536216068081558 Scheduler overhead time: 0.027887751813977957 Adapter cache time: 0.0725263711065054 Engine time: 0.028669836930930614 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-16/adapters_256_slots_256_rate_0.4-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-16/adapters_256_slots_256_rate_0.4-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 66, 4320, 4320, 66, 4320, 1080, 4320, 66, 1080, 66, 4320, 1080, 1080, 1080, 1080, 4320, 66, 66, 66, 1080, 4320, 66, 4320, 4320, 1080, 1080, 1080, 66, 4320, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 4320, 1080, 66, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 66, 4320, 4320, 1080, 66, 66, 4320, 1080, 66, 1080, 1080, 4320, 1080, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 4320, 4320, 66, 4320, 66, 1080, 4320, 4320, 4320, 1080, 66, 4320, 1080, 66, 66, 66, 66, 66, 4320, 1080, 66, 4320, 66, 4320, 66, 66, 1080, 1080, 4320, 1080, 4320, 66, 1080, 66, 4320, 4320, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 66, 1080, 4320, 4320, 66, 4320, 1080, 66, 1080, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 1080, 4320, 4320, 1080, 66, 4320, 66, 1080, 1080, 66, 1080, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 4320, 66, 4320, 66, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 1080, 1080, 66, 1080, 4320, 1080, 1080, 4320, 66, 4320, 4320, 1080, 66, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 66, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 4320, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 66, 66, 66, 66]
Prompts retrieved: 468930 . Total input tokens: 104482091 . Total output tokens: 93835645
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.337842789012939,
    "estimated_duration": 3600.2026870403865,
    "input_throughput": 3890.1776420575425,
    "output_throughput": 3437.4314658860135,
    "total_throughput": 7327.609107943556,
    "itl": 202.55592469334613,
    "ttft": 1890772.9282888568,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.765452875494958,
    "arrivals": 156118,
    "finished_requests": 56580,
    "scheduler_time": 33.03529113209912
}
#Debug simulation 
Total elapsed time: 4.3379729222506285. Arrivals time: 0.19752069655805826 Scheduler time: 3.996945629362017 Scheduler overhead time: 0.02780220890417695 Adapter cache time: 0.07378729619085789 Engine time: 0.02888424275442958 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-8/adapters_256_slots_256_rate_0.4-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-8/adapters_256_slots_256_rate_0.4-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 33, 4320, 4320, 33, 4320, 1080, 4320, 33, 1080, 33, 4320, 1080, 1080, 1080, 1080, 4320, 33, 33, 33, 1080, 4320, 33, 4320, 4320, 1080, 1080, 1080, 33, 4320, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 4320, 1080, 33, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 33, 4320, 4320, 1080, 33, 33, 4320, 1080, 33, 1080, 1080, 4320, 1080, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 4320, 4320, 33, 4320, 33, 1080, 4320, 4320, 4320, 1080, 33, 4320, 1080, 33, 33, 33, 33, 33, 4320, 1080, 33, 4320, 33, 4320, 33, 33, 1080, 1080, 4320, 1080, 4320, 33, 1080, 33, 4320, 4320, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 33, 1080, 4320, 4320, 33, 4320, 1080, 33, 1080, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 1080, 4320, 4320, 1080, 33, 4320, 33, 1080, 1080, 33, 1080, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 4320, 33, 4320, 33, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 1080, 1080, 33, 1080, 4320, 1080, 1080, 4320, 33, 4320, 4320, 1080, 33, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 33, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 4320, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 33, 33, 33, 33]
Prompts retrieved: 466125 . Total input tokens: 103857742 . Total output tokens: 93269464
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.320189076010138,
    "estimated_duration": 3600.1574955349415,
    "input_throughput": 3996.5423784500526,
    "output_throughput": 3545.8537621846945,
    "total_throughput": 7542.396140634747,
    "itl": 241.72285566610367,
    "ttft": 1861257.1982262803,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 253,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7743033992149857,
    "arrivals": 155196,
    "finished_requests": 58291,
    "scheduler_time": 37.715501357135146
}
#Debug simulation 
Total elapsed time: 4.3202861081808805. Arrivals time: 0.19885958870872855 Scheduler time: 4.017206782009453 Scheduler overhead time: 0.023645826615393162 Adapter cache time: 0.04504060372710228 Engine time: 0.024493147153407335 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-16/adapters_256_slots_256_rate_0.4-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-16/adapters_256_slots_256_rate_0.4-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 33, 4320, 4320, 33, 4320, 1080, 4320, 33, 1080, 33, 4320, 1080, 1080, 1080, 1080, 4320, 33, 33, 33, 1080, 4320, 33, 4320, 4320, 1080, 1080, 1080, 33, 4320, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 4320, 1080, 33, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 33, 4320, 4320, 1080, 33, 33, 4320, 1080, 33, 1080, 1080, 4320, 1080, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 4320, 4320, 33, 4320, 33, 1080, 4320, 4320, 4320, 1080, 33, 4320, 1080, 33, 33, 33, 33, 33, 4320, 1080, 33, 4320, 33, 4320, 33, 33, 1080, 1080, 4320, 1080, 4320, 33, 1080, 33, 4320, 4320, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 33, 1080, 4320, 4320, 33, 4320, 1080, 33, 1080, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 1080, 4320, 4320, 1080, 33, 4320, 33, 1080, 1080, 33, 1080, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 4320, 33, 4320, 33, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 1080, 1080, 33, 1080, 4320, 1080, 1080, 4320, 33, 4320, 4320, 1080, 33, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 33, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 4320, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 33, 33, 33, 33]
Prompts retrieved: 466125 . Total input tokens: 103857742 . Total output tokens: 93269464
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.334219831041992,
    "estimated_duration": 3600.180625701377,
    "input_throughput": 3925.5458182036946,
    "output_throughput": 3486.7028366262894,
    "total_throughput": 7412.248654829984,
    "itl": 199.79551615047413,
    "ttft": 1883548.264424964,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 253,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8259439287451132,
    "arrivals": 155196,
    "finished_requests": 57231,
    "scheduler_time": 33.51766796107818
}
#Debug simulation 
Total elapsed time: 4.334323415067047. Arrivals time: 0.1974365133792162 Scheduler time: 4.001800920814276 Scheduler overhead time: 0.028182924259454012 Adapter cache time: 0.06486051622778177 Engine time: 0.02885840367525816 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-16/adapters_256_slots_256_rate_0.4-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-16/adapters_256_slots_256_rate_0.4-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 33, 4320, 4320, 33, 4320, 1080, 4320, 33, 1080, 33, 4320, 1080, 1080, 1080, 1080, 4320, 33, 33, 33, 1080, 4320, 33, 4320, 4320, 1080, 1080, 1080, 33, 4320, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 4320, 1080, 33, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 33, 4320, 4320, 1080, 33, 33, 4320, 1080, 33, 1080, 1080, 4320, 1080, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 4320, 4320, 33, 4320, 33, 1080, 4320, 4320, 4320, 1080, 33, 4320, 1080, 33, 33, 33, 33, 33, 4320, 1080, 33, 4320, 33, 4320, 33, 33, 1080, 1080, 4320, 1080, 4320, 33, 1080, 33, 4320, 4320, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 33, 1080, 4320, 4320, 33, 4320, 1080, 33, 1080, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 1080, 4320, 4320, 1080, 33, 4320, 33, 1080, 1080, 33, 1080, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 4320, 33, 4320, 33, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 1080, 1080, 33, 1080, 4320, 1080, 1080, 4320, 33, 4320, 4320, 1080, 33, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 33, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 4320, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 33, 33, 33, 33]
Prompts retrieved: 466125 . Total input tokens: 103857742 . Total output tokens: 93269464
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.445862085092813,
    "estimated_duration": 3600.029172518954,
    "input_throughput": 3925.37485747988,
    "output_throughput": 3486.6225795657533,
    "total_throughput": 7411.997437045634,
    "itl": 199.79095400448153,
    "ttft": 1883610.1080979977,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 253,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7916219219961226,
    "arrivals": 155196,
    "finished_requests": 57227,
    "scheduler_time": 33.51636009519762
}
#Debug simulation 
Total elapsed time: 4.445957777090371. Arrivals time: 0.19641574705019593 Scheduler time: 4.114226056728512 Scheduler overhead time: 0.028006752021610737 Adapter cache time: 0.06508389348164201 Engine time: 0.02915745321661234 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-16/adapters_256_slots_256_rate_0.4-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-16/adapters_256_slots_256_rate_0.4-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 33, 4320, 4320, 33, 4320, 1080, 4320, 33, 1080, 33, 4320, 1080, 1080, 1080, 1080, 4320, 33, 33, 33, 1080, 4320, 33, 4320, 4320, 1080, 1080, 1080, 33, 4320, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 4320, 1080, 33, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 33, 4320, 4320, 1080, 33, 33, 4320, 1080, 33, 1080, 1080, 4320, 1080, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 4320, 4320, 33, 4320, 33, 1080, 4320, 4320, 4320, 1080, 33, 4320, 1080, 33, 33, 33, 33, 33, 4320, 1080, 33, 4320, 33, 4320, 33, 33, 1080, 1080, 4320, 1080, 4320, 33, 1080, 33, 4320, 4320, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 33, 1080, 4320, 4320, 33, 4320, 1080, 33, 1080, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 1080, 4320, 4320, 1080, 33, 4320, 33, 1080, 1080, 33, 1080, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 4320, 33, 4320, 33, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 1080, 1080, 33, 1080, 4320, 1080, 1080, 4320, 33, 4320, 4320, 1080, 33, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 33, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 4320, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 33, 33, 33, 33]
Prompts retrieved: 466125 . Total input tokens: 103857742 . Total output tokens: 93269464
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.3322303695604205,
    "estimated_duration": 3600.201950543149,
    "input_throughput": 3924.387074416332,
    "output_throughput": 3485.76195791092,
    "total_throughput": 7410.149032327252,
    "itl": 199.1119000859903,
    "ttft": 1883848.5626812098,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 253,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7564827246102515,
    "arrivals": 155196,
    "finished_requests": 57213,
    "scheduler_time": 33.434693619102184
}
#Debug simulation 
Total elapsed time: 4.332330098841339. Arrivals time: 0.19527762942016125 Scheduler time: 4.00096835102886 Scheduler overhead time: 0.02822719607502222 Adapter cache time: 0.06556978449225426 Engine time: 0.029169101268053055 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-8/adapters_256_slots_256_rate_0.4-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-8/adapters_256_slots_256_rate_0.4-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 270, 4320, 4320, 270, 4320, 540, 4320, 270, 540, 270, 4320, 540, 540, 540, 540, 4320, 270, 270, 270, 540, 4320, 270, 4320, 4320, 540, 540, 540, 270, 4320, 270, 540, 540, 270, 540, 270, 270, 540, 540, 4320, 540, 270, 540, 4320, 540, 540, 4320, 540, 4320, 270, 4320, 4320, 540, 270, 270, 4320, 540, 270, 540, 540, 4320, 540, 270, 270, 4320, 4320, 4320, 4320, 4320, 4320, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 4320, 4320, 270, 4320, 270, 540, 4320, 4320, 4320, 540, 270, 4320, 540, 270, 270, 270, 270, 270, 4320, 540, 270, 4320, 270, 4320, 270, 270, 540, 540, 4320, 540, 4320, 270, 540, 270, 4320, 4320, 270, 4320, 540, 270, 4320, 270, 270, 4320, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 270, 540, 4320, 4320, 270, 4320, 540, 270, 540, 4320, 270, 270, 270, 270, 270, 270, 4320, 270, 270, 270, 4320, 270, 540, 4320, 4320, 540, 270, 4320, 270, 540, 540, 270, 540, 270, 4320, 270, 270, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 540, 4320, 540, 4320, 270, 4320, 270, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 540, 540, 270, 540, 4320, 540, 540, 4320, 270, 4320, 4320, 540, 270, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 270, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 4320, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 4320, 540, 270, 270, 270, 270]
Prompts retrieved: 440370 . Total input tokens: 98122611 . Total output tokens: 88123439
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.196591483429074,
    "estimated_duration": 3600.236500379867,
    "input_throughput": 3777.415177743208,
    "output_throughput": 3359.935937187369,
    "total_throughput": 7137.351114930577,
    "itl": 255.4451906315136,
    "ttft": 1894582.74597828,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.783484862446784,
    "arrivals": 146502,
    "finished_requests": 55043,
    "scheduler_time": 35.862895649115515
}
#Debug simulation 
Total elapsed time: 4.1966923722065985. Arrivals time: 0.1911354218609631 Scheduler time: 3.858373085036874 Scheduler overhead time: 0.022647143341600895 Adapter cache time: 0.0905885617248714 Engine time: 0.023355341982096434 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-16/adapters_256_slots_256_rate_0.4-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-16/adapters_256_slots_256_rate_0.4-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 270, 4320, 4320, 270, 4320, 540, 4320, 270, 540, 270, 4320, 540, 540, 540, 540, 4320, 270, 270, 270, 540, 4320, 270, 4320, 4320, 540, 540, 540, 270, 4320, 270, 540, 540, 270, 540, 270, 270, 540, 540, 4320, 540, 270, 540, 4320, 540, 540, 4320, 540, 4320, 270, 4320, 4320, 540, 270, 270, 4320, 540, 270, 540, 540, 4320, 540, 270, 270, 4320, 4320, 4320, 4320, 4320, 4320, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 4320, 4320, 270, 4320, 270, 540, 4320, 4320, 4320, 540, 270, 4320, 540, 270, 270, 270, 270, 270, 4320, 540, 270, 4320, 270, 4320, 270, 270, 540, 540, 4320, 540, 4320, 270, 540, 270, 4320, 4320, 270, 4320, 540, 270, 4320, 270, 270, 4320, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 270, 540, 4320, 4320, 270, 4320, 540, 270, 540, 4320, 270, 270, 270, 270, 270, 270, 4320, 270, 270, 270, 4320, 270, 540, 4320, 4320, 540, 270, 4320, 270, 540, 540, 270, 540, 270, 4320, 270, 270, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 540, 4320, 540, 4320, 270, 4320, 270, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 540, 540, 270, 540, 4320, 540, 540, 4320, 270, 4320, 4320, 540, 270, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 270, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 4320, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 4320, 540, 270, 270, 270, 270]
Prompts retrieved: 440370 . Total input tokens: 98122611 . Total output tokens: 88123439
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.260579328984022,
    "estimated_duration": 3600.094127965391,
    "input_throughput": 3787.5381907600727,
    "output_throughput": 3378.845821143746,
    "total_throughput": 7166.384011903819,
    "itl": 206.89792625255544,
    "ttft": 1895802.8633577642,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8353226749482603,
    "arrivals": 146502,
    "finished_requests": 55187,
    "scheduler_time": 32.64130116702978
}
#Debug simulation 
Total elapsed time: 4.260674549266696. Arrivals time: 0.19038082659244537 Scheduler time: 3.89039998780936 Scheduler overhead time: 0.02925719041377306 Adapter cache time: 0.10958646470680833 Engine time: 0.028275154065340757 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-16/adapters_256_slots_256_rate_0.4-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-16/adapters_256_slots_256_rate_0.4-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 270, 4320, 4320, 270, 4320, 540, 4320, 270, 540, 270, 4320, 540, 540, 540, 540, 4320, 270, 270, 270, 540, 4320, 270, 4320, 4320, 540, 540, 540, 270, 4320, 270, 540, 540, 270, 540, 270, 270, 540, 540, 4320, 540, 270, 540, 4320, 540, 540, 4320, 540, 4320, 270, 4320, 4320, 540, 270, 270, 4320, 540, 270, 540, 540, 4320, 540, 270, 270, 4320, 4320, 4320, 4320, 4320, 4320, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 4320, 4320, 270, 4320, 270, 540, 4320, 4320, 4320, 540, 270, 4320, 540, 270, 270, 270, 270, 270, 4320, 540, 270, 4320, 270, 4320, 270, 270, 540, 540, 4320, 540, 4320, 270, 540, 270, 4320, 4320, 270, 4320, 540, 270, 4320, 270, 270, 4320, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 270, 540, 4320, 4320, 270, 4320, 540, 270, 540, 4320, 270, 270, 270, 270, 270, 270, 4320, 270, 270, 270, 4320, 270, 540, 4320, 4320, 540, 270, 4320, 270, 540, 540, 270, 540, 270, 4320, 270, 270, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 540, 4320, 540, 4320, 270, 4320, 270, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 540, 540, 270, 540, 4320, 540, 540, 4320, 270, 4320, 4320, 540, 270, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 270, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 4320, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 4320, 540, 270, 270, 270, 270]
Prompts retrieved: 440370 . Total input tokens: 98122611 . Total output tokens: 88123439
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.262186098843813,
    "estimated_duration": 3600.0636354973867,
    "input_throughput": 3787.7644343683987,
    "output_throughput": 3379.0352703916337,
    "total_throughput": 7166.799704760032,
    "itl": 206.90122124254685,
    "ttft": 1895777.8801957958,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8005920728808292,
    "arrivals": 146502,
    "finished_requests": 55189,
    "scheduler_time": 32.64120313775705
}
#Debug simulation 
Total elapsed time: 4.262291807681322. Arrivals time: 0.1979681458324194 Scheduler time: 3.8870616611093283 Scheduler overhead time: 0.02757735690101981 Adapter cache time: 0.10846632765606046 Engine time: 0.028451957274228334 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-16/adapters_256_slots_256_rate_0.4-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-16/adapters_256_slots_256_rate_0.4-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 270, 4320, 4320, 270, 4320, 540, 4320, 270, 540, 270, 4320, 540, 540, 540, 540, 4320, 270, 270, 270, 540, 4320, 270, 4320, 4320, 540, 540, 540, 270, 4320, 270, 540, 540, 270, 540, 270, 270, 540, 540, 4320, 540, 270, 540, 4320, 540, 540, 4320, 540, 4320, 270, 4320, 4320, 540, 270, 270, 4320, 540, 270, 540, 540, 4320, 540, 270, 270, 4320, 4320, 4320, 4320, 4320, 4320, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 4320, 4320, 270, 4320, 270, 540, 4320, 4320, 4320, 540, 270, 4320, 540, 270, 270, 270, 270, 270, 4320, 540, 270, 4320, 270, 4320, 270, 270, 540, 540, 4320, 540, 4320, 270, 540, 270, 4320, 4320, 270, 4320, 540, 270, 4320, 270, 270, 4320, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 270, 540, 4320, 4320, 270, 4320, 540, 270, 540, 4320, 270, 270, 270, 270, 270, 270, 4320, 270, 270, 270, 4320, 270, 540, 4320, 4320, 540, 270, 4320, 270, 540, 540, 270, 540, 270, 4320, 270, 270, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 540, 4320, 540, 4320, 270, 4320, 270, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 540, 540, 270, 540, 4320, 540, 540, 4320, 270, 4320, 4320, 540, 270, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 270, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 4320, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 4320, 540, 270, 270, 270, 270]
Prompts retrieved: 440370 . Total input tokens: 98122611 . Total output tokens: 88123439
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.273568687029183,
    "estimated_duration": 3600.146463787763,
    "input_throughput": 3787.8322832601066,
    "output_throughput": 3379.1075230869196,
    "total_throughput": 7166.939806347026,
    "itl": 206.88870362692055,
    "ttft": 1895690.2827521786,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.765452875494958,
    "arrivals": 146502,
    "finished_requests": 55192,
    "scheduler_time": 32.6415362921067
}
#Debug simulation 
Total elapsed time: 4.273662420921028. Arrivals time: 0.1926341992802918 Scheduler time: 3.901622706092894 Scheduler overhead time: 0.02766833920031786 Adapter cache time: 0.11008754465728998 Engine time: 0.028850476257503033 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-8/adapters_256_slots_256_rate_0.4-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-8/adapters_256_slots_256_rate_0.4-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 135, 4320, 4320, 135, 4320, 540, 4320, 135, 540, 135, 4320, 540, 540, 540, 540, 4320, 135, 135, 135, 540, 4320, 135, 4320, 4320, 540, 540, 540, 135, 4320, 135, 540, 540, 135, 540, 135, 135, 540, 540, 4320, 540, 135, 540, 4320, 540, 540, 4320, 540, 4320, 135, 4320, 4320, 540, 135, 135, 4320, 540, 135, 540, 540, 4320, 540, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 4320, 4320, 135, 4320, 135, 540, 4320, 4320, 4320, 540, 135, 4320, 540, 135, 135, 135, 135, 135, 4320, 540, 135, 4320, 135, 4320, 135, 135, 540, 540, 4320, 540, 4320, 135, 540, 135, 4320, 4320, 135, 4320, 540, 135, 4320, 135, 135, 4320, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 135, 540, 4320, 4320, 135, 4320, 540, 135, 540, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 540, 4320, 4320, 540, 135, 4320, 135, 540, 540, 135, 540, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 540, 4320, 540, 4320, 135, 4320, 135, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 540, 540, 135, 540, 4320, 540, 540, 4320, 135, 4320, 4320, 540, 135, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 135, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 4320, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 4320, 540, 135, 135, 135, 135]
Prompts retrieved: 428895 . Total input tokens: 95549549 . Total output tokens: 85845104
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.433848619926721,
    "estimated_duration": 3600.223902972973,
    "input_throughput": 4014.6280868988783,
    "output_throughput": 3532.9027701573714,
    "total_throughput": 7547.53085705625,
    "itl": 240.92318934394044,
    "ttft": 1829256.0044237534,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.783484862446784,
    "arrivals": 142715,
    "finished_requests": 58198,
    "scheduler_time": 37.79371242013529
}
#Debug simulation 
Total elapsed time: 4.433946734759957. Arrivals time: 0.19957211101427674 Scheduler time: 4.09281862527132 Scheduler overhead time: 0.024004696868360043 Adapter cache time: 0.08146042749285698 Engine time: 0.024947951082140207 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-16/adapters_256_slots_256_rate_0.4-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-16/adapters_256_slots_256_rate_0.4-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 135, 4320, 4320, 135, 4320, 540, 4320, 135, 540, 135, 4320, 540, 540, 540, 540, 4320, 135, 135, 135, 540, 4320, 135, 4320, 4320, 540, 540, 540, 135, 4320, 135, 540, 540, 135, 540, 135, 135, 540, 540, 4320, 540, 135, 540, 4320, 540, 540, 4320, 540, 4320, 135, 4320, 4320, 540, 135, 135, 4320, 540, 135, 540, 540, 4320, 540, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 4320, 4320, 135, 4320, 135, 540, 4320, 4320, 4320, 540, 135, 4320, 540, 135, 135, 135, 135, 135, 4320, 540, 135, 4320, 135, 4320, 135, 135, 540, 540, 4320, 540, 4320, 135, 540, 135, 4320, 4320, 135, 4320, 540, 135, 4320, 135, 135, 4320, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 135, 540, 4320, 4320, 135, 4320, 540, 135, 540, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 540, 4320, 4320, 540, 135, 4320, 135, 540, 540, 135, 540, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 540, 4320, 540, 4320, 135, 4320, 135, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 540, 540, 135, 540, 4320, 540, 540, 4320, 135, 4320, 4320, 540, 135, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 135, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 4320, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 4320, 540, 135, 135, 135, 135]
Prompts retrieved: 428895 . Total input tokens: 95549549 . Total output tokens: 85845104
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.4733073632232845,
    "estimated_duration": 3600.0277020408257,
    "input_throughput": 4005.197513293048,
    "output_throughput": 3533.0744796184795,
    "total_throughput": 7538.271992911527,
    "itl": 196.12508066226022,
    "ttft": 1835455.213410122,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8353226749482602,
    "arrivals": 142715,
    "finished_requests": 58064,
    "scheduler_time": 34.28894903683959
}
#Debug simulation 
Total elapsed time: 4.473403538111597. Arrivals time: 0.19574486138299108 Scheduler time: 4.1071853642351925 Scheduler overhead time: 0.02886630641296506 Adapter cache time: 0.09846892906352878 Engine time: 0.029740130063146353 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-16/adapters_256_slots_256_rate_0.4-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-16/adapters_256_slots_256_rate_0.4-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 135, 4320, 4320, 135, 4320, 540, 4320, 135, 540, 135, 4320, 540, 540, 540, 540, 4320, 135, 135, 135, 540, 4320, 135, 4320, 4320, 540, 540, 540, 135, 4320, 135, 540, 540, 135, 540, 135, 135, 540, 540, 4320, 540, 135, 540, 4320, 540, 540, 4320, 540, 4320, 135, 4320, 4320, 540, 135, 135, 4320, 540, 135, 540, 540, 4320, 540, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 4320, 4320, 135, 4320, 135, 540, 4320, 4320, 4320, 540, 135, 4320, 540, 135, 135, 135, 135, 135, 4320, 540, 135, 4320, 135, 4320, 135, 135, 540, 540, 4320, 540, 4320, 135, 540, 135, 4320, 4320, 135, 4320, 540, 135, 4320, 135, 135, 4320, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 135, 540, 4320, 4320, 135, 4320, 540, 135, 540, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 540, 4320, 4320, 540, 135, 4320, 135, 540, 540, 135, 540, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 540, 4320, 540, 4320, 135, 4320, 135, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 540, 540, 135, 540, 4320, 540, 540, 4320, 135, 4320, 4320, 540, 135, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 135, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 4320, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 4320, 540, 135, 135, 135, 135]
Prompts retrieved: 428895 . Total input tokens: 95549549 . Total output tokens: 85845104
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.480958596337587,
    "estimated_duration": 3600.2170245455604,
    "input_throughput": 4005.2368792462275,
    "output_throughput": 3532.889798943575,
    "total_throughput": 7538.126678189802,
    "itl": 196.00212519832357,
    "ttft": 1835518.1058180977,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8005920728808292,
    "arrivals": 142715,
    "finished_requests": 58066,
    "scheduler_time": 34.27777950127413
}
#Debug simulation 
Total elapsed time: 4.48107646824792. Arrivals time: 0.197348621673882 Scheduler time: 4.112566561438143 Scheduler overhead time: 0.028844062704592943 Adapter cache time: 0.09911084454506636 Engine time: 0.029728975612670183 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-16/adapters_256_slots_256_rate_0.4-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-16/adapters_256_slots_256_rate_0.4-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 135, 4320, 4320, 135, 4320, 540, 4320, 135, 540, 135, 4320, 540, 540, 540, 540, 4320, 135, 135, 135, 540, 4320, 135, 4320, 4320, 540, 540, 540, 135, 4320, 135, 540, 540, 135, 540, 135, 135, 540, 540, 4320, 540, 135, 540, 4320, 540, 540, 4320, 540, 4320, 135, 4320, 4320, 540, 135, 135, 4320, 540, 135, 540, 540, 4320, 540, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 4320, 4320, 135, 4320, 135, 540, 4320, 4320, 4320, 540, 135, 4320, 540, 135, 135, 135, 135, 135, 4320, 540, 135, 4320, 135, 4320, 135, 135, 540, 540, 4320, 540, 4320, 135, 540, 135, 4320, 4320, 135, 4320, 540, 135, 4320, 135, 135, 4320, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 135, 540, 4320, 4320, 135, 4320, 540, 135, 540, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 540, 4320, 4320, 540, 135, 4320, 135, 540, 540, 135, 540, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 540, 4320, 540, 4320, 135, 4320, 135, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 540, 540, 135, 540, 4320, 540, 540, 4320, 135, 4320, 4320, 540, 135, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 135, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 4320, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 4320, 540, 135, 135, 135, 135]
Prompts retrieved: 428895 . Total input tokens: 95549549 . Total output tokens: 85845104
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.425637369044125,
    "estimated_duration": 3600.188505034816,
    "input_throughput": 4004.5891985482513,
    "output_throughput": 3532.6000241970687,
    "total_throughput": 7537.18922274532,
    "itl": 195.38587854072128,
    "ttft": 1835653.5596038618,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.765452875494958,
    "arrivals": 142715,
    "finished_requests": 58058,
    "scheduler_time": 34.21212338419561
}
#Debug simulation 
Total elapsed time: 4.425732524134219. Arrivals time: 0.1979496837593615 Scheduler time: 4.0563359200023115 Scheduler overhead time: 0.028778263833373785 Adapter cache time: 0.09914476331323385 Engine time: 0.030131776351481676 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-8/adapters_256_slots_256_rate_0.4-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-8/adapters_256_slots_256_rate_0.4-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 66, 4320, 4320, 66, 4320, 540, 4320, 66, 540, 66, 4320, 540, 540, 540, 540, 4320, 66, 66, 66, 540, 4320, 66, 4320, 4320, 540, 540, 540, 66, 4320, 66, 540, 540, 66, 540, 66, 66, 540, 540, 4320, 540, 66, 540, 4320, 540, 540, 4320, 540, 4320, 66, 4320, 4320, 540, 66, 66, 4320, 540, 66, 540, 540, 4320, 540, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 4320, 4320, 66, 4320, 66, 540, 4320, 4320, 4320, 540, 66, 4320, 540, 66, 66, 66, 66, 66, 4320, 540, 66, 4320, 66, 4320, 66, 66, 540, 540, 4320, 540, 4320, 66, 540, 66, 4320, 4320, 66, 4320, 540, 66, 4320, 66, 66, 4320, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 66, 540, 4320, 4320, 66, 4320, 540, 66, 540, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 540, 4320, 4320, 540, 66, 4320, 66, 540, 540, 66, 540, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 540, 4320, 540, 4320, 66, 4320, 66, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 540, 540, 66, 540, 4320, 540, 540, 4320, 66, 4320, 4320, 540, 66, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 66, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 4320, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 4320, 540, 66, 66, 66, 66]
Prompts retrieved: 423030 . Total input tokens: 94249363 . Total output tokens: 84650939
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.51981651969254,
    "estimated_duration": 3600.043504391873,
    "input_throughput": 4195.781795851261,
    "output_throughput": 3686.0746221014356,
    "total_throughput": 7881.856417952697,
    "itl": 231.21465892238632,
    "ttft": 1775670.1563995143,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.783484862446784,
    "arrivals": 140795,
    "finished_requests": 60573,
    "scheduler_time": 39.486667645869325
}
#Debug simulation 
Total elapsed time: 4.519915791694075. Arrivals time: 0.20868272241204977 Scheduler time: 4.178111860062927 Scheduler overhead time: 0.024822847452014685 Adapter cache time: 0.07075109798461199 Engine time: 0.025799795519560575 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-16/adapters_256_slots_256_rate_0.4-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-16/adapters_256_slots_256_rate_0.4-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 66, 4320, 4320, 66, 4320, 540, 4320, 66, 540, 66, 4320, 540, 540, 540, 540, 4320, 66, 66, 66, 540, 4320, 66, 4320, 4320, 540, 540, 540, 66, 4320, 66, 540, 540, 66, 540, 66, 66, 540, 540, 4320, 540, 66, 540, 4320, 540, 540, 4320, 540, 4320, 66, 4320, 4320, 540, 66, 66, 4320, 540, 66, 540, 540, 4320, 540, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 4320, 4320, 66, 4320, 66, 540, 4320, 4320, 4320, 540, 66, 4320, 540, 66, 66, 66, 66, 66, 4320, 540, 66, 4320, 66, 4320, 66, 66, 540, 540, 4320, 540, 4320, 66, 540, 66, 4320, 4320, 66, 4320, 540, 66, 4320, 66, 66, 4320, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 66, 540, 4320, 4320, 66, 4320, 540, 66, 540, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 540, 4320, 4320, 540, 66, 4320, 66, 540, 540, 66, 540, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 540, 4320, 540, 4320, 66, 4320, 66, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 540, 540, 66, 540, 4320, 540, 540, 4320, 66, 4320, 4320, 540, 66, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 66, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 4320, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 4320, 540, 66, 66, 66, 66]
Prompts retrieved: 423030 . Total input tokens: 94249363 . Total output tokens: 84650939
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.610344835091382,
    "estimated_duration": 3600.07187586135,
    "input_throughput": 4161.788852178192,
    "output_throughput": 3664.536280082895,
    "total_throughput": 7826.325132261088,
    "itl": 188.49900457828556,
    "ttft": 1787275.463367564,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8353226749482601,
    "arrivals": 140795,
    "finished_requests": 60094,
    "scheduler_time": 35.519802634166034
}
#Debug simulation 
Total elapsed time: 4.610442465171218. Arrivals time: 0.20116581348702312 Scheduler time: 4.250051515176892 Scheduler overhead time: 0.029819497372955084 Adapter cache time: 0.08473591832444072 Engine time: 0.030805558431893587 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-16/adapters_256_slots_256_rate_0.4-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-16/adapters_256_slots_256_rate_0.4-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 66, 4320, 4320, 66, 4320, 540, 4320, 66, 540, 66, 4320, 540, 540, 540, 540, 4320, 66, 66, 66, 540, 4320, 66, 4320, 4320, 540, 540, 540, 66, 4320, 66, 540, 540, 66, 540, 66, 66, 540, 540, 4320, 540, 66, 540, 4320, 540, 540, 4320, 540, 4320, 66, 4320, 4320, 540, 66, 66, 4320, 540, 66, 540, 540, 4320, 540, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 4320, 4320, 66, 4320, 66, 540, 4320, 4320, 4320, 540, 66, 4320, 540, 66, 66, 66, 66, 66, 4320, 540, 66, 4320, 66, 4320, 66, 66, 540, 540, 4320, 540, 4320, 66, 540, 66, 4320, 4320, 66, 4320, 540, 66, 4320, 66, 66, 4320, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 66, 540, 4320, 4320, 66, 4320, 540, 66, 540, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 540, 4320, 4320, 540, 66, 4320, 66, 540, 540, 66, 540, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 540, 4320, 540, 4320, 66, 4320, 66, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 540, 540, 66, 540, 4320, 540, 540, 4320, 66, 4320, 4320, 540, 66, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 66, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 4320, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 4320, 540, 66, 66, 66, 66]
Prompts retrieved: 423030 . Total input tokens: 94249363 . Total output tokens: 84650939
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.570030729752034,
    "estimated_duration": 3600.012385301608,
    "input_throughput": 4162.331513408004,
    "output_throughput": 3664.6648922277827,
    "total_throughput": 7826.996405635787,
    "itl": 188.98799097025295,
    "ttft": 1787176.362040514,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.800592072880829,
    "arrivals": 140795,
    "finished_requests": 60099,
    "scheduler_time": 35.583013156087816
}
#Debug simulation 
Total elapsed time: 4.5701246089302. Arrivals time: 0.1996439667418599 Scheduler time: 4.211627289187163 Scheduler overhead time: 0.029694527853280306 Adapter cache time: 0.08443379029631615 Engine time: 0.030883231200277805 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-16/adapters_256_slots_256_rate_0.4-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-16/adapters_256_slots_256_rate_0.4-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 66, 4320, 4320, 66, 4320, 540, 4320, 66, 540, 66, 4320, 540, 540, 540, 540, 4320, 66, 66, 66, 540, 4320, 66, 4320, 4320, 540, 540, 540, 66, 4320, 66, 540, 540, 66, 540, 66, 66, 540, 540, 4320, 540, 66, 540, 4320, 540, 540, 4320, 540, 4320, 66, 4320, 4320, 540, 66, 66, 4320, 540, 66, 540, 540, 4320, 540, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 4320, 4320, 66, 4320, 66, 540, 4320, 4320, 4320, 540, 66, 4320, 540, 66, 66, 66, 66, 66, 4320, 540, 66, 4320, 66, 4320, 66, 66, 540, 540, 4320, 540, 4320, 66, 540, 66, 4320, 4320, 66, 4320, 540, 66, 4320, 66, 66, 4320, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 66, 540, 4320, 4320, 66, 4320, 540, 66, 540, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 540, 4320, 4320, 540, 66, 4320, 66, 540, 540, 66, 540, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 540, 4320, 540, 4320, 66, 4320, 66, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 540, 540, 66, 540, 4320, 540, 540, 4320, 66, 4320, 4320, 540, 66, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 66, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 4320, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 4320, 540, 66, 66, 66, 66]
Prompts retrieved: 423030 . Total input tokens: 94249363 . Total output tokens: 84650939
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.585936432238668,
    "estimated_duration": 3600.024517430364,
    "input_throughput": 4156.091973140128,
    "output_throughput": 3659.0611914505666,
    "total_throughput": 7815.153164590695,
    "itl": 189.03353575649513,
    "ttft": 1788193.7042710665,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.765452875494958,
    "arrivals": 140795,
    "finished_requests": 60001,
    "scheduler_time": 35.50074030756175
}
#Debug simulation 
Total elapsed time: 4.586053834296763. Arrivals time: 0.2189641729928553 Scheduler time: 4.208846962545067 Scheduler overhead time: 0.029734220821410418 Adapter cache time: 0.08399069495499134 Engine time: 0.030676748137921095 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-8/adapters_256_slots_256_rate_0.4-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-8/adapters_256_slots_256_rate_0.4-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 33, 4320, 4320, 33, 4320, 540, 4320, 33, 540, 33, 4320, 540, 540, 540, 540, 4320, 33, 33, 33, 540, 4320, 33, 4320, 4320, 540, 540, 540, 33, 4320, 33, 540, 540, 33, 540, 33, 33, 540, 540, 4320, 540, 33, 540, 4320, 540, 540, 4320, 540, 4320, 33, 4320, 4320, 540, 33, 33, 4320, 540, 33, 540, 540, 4320, 540, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 4320, 4320, 33, 4320, 33, 540, 4320, 4320, 4320, 540, 33, 4320, 540, 33, 33, 33, 33, 33, 4320, 540, 33, 4320, 33, 4320, 33, 33, 540, 540, 4320, 540, 4320, 33, 540, 33, 4320, 4320, 33, 4320, 540, 33, 4320, 33, 33, 4320, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 33, 540, 4320, 4320, 33, 4320, 540, 33, 540, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 540, 4320, 4320, 540, 33, 4320, 33, 540, 540, 33, 540, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 540, 4320, 540, 4320, 33, 4320, 33, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 540, 540, 33, 540, 4320, 540, 540, 4320, 33, 4320, 4320, 540, 33, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 33, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 4320, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 4320, 540, 33, 33, 33, 33]
Prompts retrieved: 420225 . Total input tokens: 93627813 . Total output tokens: 84090312
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.650932349730283,
    "estimated_duration": 3600.2426374678694,
    "input_throughput": 4262.8985169716825,
    "output_throughput": 3755.9393523294666,
    "total_throughput": 8018.837869301149,
    "itl": 226.9562090743822,
    "ttft": 1752789.9280818698,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.783484862446784,
    "arrivals": 139799,
    "finished_requests": 61893,
    "scheduler_time": 40.27192552081332
}
#Debug simulation 
Total elapsed time: 4.651026618666947. Arrivals time: 0.21106704184785485 Scheduler time: 4.310891138855368 Scheduler overhead time: 0.025481474585831165 Adapter cache time: 0.06545144831761718 Engine time: 0.026305233594030142 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-16/adapters_256_slots_256_rate_0.4-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-16/adapters_256_slots_256_rate_0.4-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 33, 4320, 4320, 33, 4320, 540, 4320, 33, 540, 33, 4320, 540, 540, 540, 540, 4320, 33, 33, 33, 540, 4320, 33, 4320, 4320, 540, 540, 540, 33, 4320, 33, 540, 540, 33, 540, 33, 33, 540, 540, 4320, 540, 33, 540, 4320, 540, 540, 4320, 540, 4320, 33, 4320, 4320, 540, 33, 33, 4320, 540, 33, 540, 540, 4320, 540, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 4320, 4320, 33, 4320, 33, 540, 4320, 4320, 4320, 540, 33, 4320, 540, 33, 33, 33, 33, 33, 4320, 540, 33, 4320, 33, 4320, 33, 33, 540, 540, 4320, 540, 4320, 33, 540, 33, 4320, 4320, 33, 4320, 540, 33, 4320, 33, 33, 4320, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 33, 540, 4320, 4320, 33, 4320, 540, 33, 540, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 540, 4320, 4320, 540, 33, 4320, 33, 540, 540, 33, 540, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 540, 4320, 540, 4320, 33, 4320, 33, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 540, 540, 33, 540, 4320, 540, 540, 4320, 33, 4320, 4320, 540, 33, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 33, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 4320, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 4320, 540, 33, 33, 33, 33]
Prompts retrieved: 420225 . Total input tokens: 93627813 . Total output tokens: 84090312
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.6278184819966555,
    "estimated_duration": 3600.0980942699807,
    "input_throughput": 4223.532971004575,
    "output_throughput": 3726.907058825772,
    "total_throughput": 7950.440029830347,
    "itl": 186.59696473590623,
    "ttft": 1766710.0517042112,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8353226749482604,
    "arrivals": 139799,
    "finished_requests": 61291,
    "scheduler_time": 36.32892125524851
}
#Debug simulation 
Total elapsed time: 4.627922926098108. Arrivals time: 0.21028742287307978 Scheduler time: 4.26361932605505 Scheduler overhead time: 0.03017303626984358 Adapter cache time: 0.07901985431089997 Engine time: 0.03081268584355712 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-16/adapters_256_slots_256_rate_0.4-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-16/adapters_256_slots_256_rate_0.4-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 33, 4320, 4320, 33, 4320, 540, 4320, 33, 540, 33, 4320, 540, 540, 540, 540, 4320, 33, 33, 33, 540, 4320, 33, 4320, 4320, 540, 540, 540, 33, 4320, 33, 540, 540, 33, 540, 33, 33, 540, 540, 4320, 540, 33, 540, 4320, 540, 540, 4320, 540, 4320, 33, 4320, 4320, 540, 33, 33, 4320, 540, 33, 540, 540, 4320, 540, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 4320, 4320, 33, 4320, 33, 540, 4320, 4320, 4320, 540, 33, 4320, 540, 33, 33, 33, 33, 33, 4320, 540, 33, 4320, 33, 4320, 33, 33, 540, 540, 4320, 540, 4320, 33, 540, 33, 4320, 4320, 33, 4320, 540, 33, 4320, 33, 33, 4320, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 33, 540, 4320, 4320, 33, 4320, 540, 33, 540, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 540, 4320, 4320, 540, 33, 4320, 33, 540, 540, 33, 540, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 540, 4320, 540, 4320, 33, 4320, 33, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 540, 540, 33, 540, 4320, 540, 540, 4320, 33, 4320, 4320, 540, 33, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 33, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 4320, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 4320, 540, 33, 33, 33, 33]
Prompts retrieved: 420225 . Total input tokens: 93627813 . Total output tokens: 84090312
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.628085895907134,
    "estimated_duration": 3600.1052639424124,
    "input_throughput": 4223.776774612454,
    "output_throughput": 3727.0590764077815,
    "total_throughput": 7950.835851020235,
    "itl": 186.59121758176104,
    "ttft": 1766721.868024852,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8005920728808292,
    "arrivals": 139799,
    "finished_requests": 61295,
    "scheduler_time": 36.33007675321899
}
#Debug simulation 
Total elapsed time: 4.62818397488445. Arrivals time: 0.2050359402783215 Scheduler time: 4.269373571034521 Scheduler overhead time: 0.030141099356114864 Adapter cache time: 0.07864735182374716 Engine time: 0.03096824185922742 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-16/adapters_256_slots_256_rate_0.4-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-16/adapters_256_slots_256_rate_0.4-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 33, 4320, 4320, 33, 4320, 540, 4320, 33, 540, 33, 4320, 540, 540, 540, 540, 4320, 33, 33, 33, 540, 4320, 33, 4320, 4320, 540, 540, 540, 33, 4320, 33, 540, 540, 33, 540, 33, 33, 540, 540, 4320, 540, 33, 540, 4320, 540, 540, 4320, 540, 4320, 33, 4320, 4320, 540, 33, 33, 4320, 540, 33, 540, 540, 4320, 540, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 4320, 4320, 33, 4320, 33, 540, 4320, 4320, 4320, 540, 33, 4320, 540, 33, 33, 33, 33, 33, 4320, 540, 33, 4320, 33, 4320, 33, 33, 540, 540, 4320, 540, 4320, 33, 540, 33, 4320, 4320, 33, 4320, 540, 33, 4320, 33, 33, 4320, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 33, 540, 4320, 4320, 33, 4320, 540, 33, 540, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 540, 4320, 4320, 540, 33, 4320, 33, 540, 540, 33, 540, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 540, 4320, 540, 4320, 33, 4320, 33, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 540, 540, 33, 540, 4320, 540, 540, 4320, 33, 4320, 4320, 540, 33, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 33, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 4320, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 4320, 540, 33, 33, 33, 33]
Prompts retrieved: 420225 . Total input tokens: 93627813 . Total output tokens: 84090312
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.6549696628935635,
    "estimated_duration": 3600.045823280501,
    "input_throughput": 4223.520962337289,
    "output_throughput": 3726.8906171238486,
    "total_throughput": 7950.411579461138,
    "itl": 186.5935705668653,
    "ttft": 1766648.4341086596,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.765452875494958,
    "arrivals": 139799,
    "finished_requests": 61290,
    "scheduler_time": 36.3299684510461
}
#Debug simulation 
Total elapsed time: 4.655091540887952. Arrivals time: 0.20175675861537457 Scheduler time: 4.2993477541022 Scheduler overhead time: 0.030221072491258383 Adapter cache time: 0.07868986623361707 Engine time: 0.031032737344503403 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-8/adapters_256_slots_256_rate_0.4-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-8/adapters_256_slots_256_rate_0.4-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 135, 4320, 4320, 135, 4320, 270, 4320, 135, 270, 135, 4320, 270, 270, 270, 270, 4320, 135, 135, 135, 270, 4320, 135, 4320, 4320, 270, 270, 270, 135, 4320, 135, 270, 270, 135, 270, 135, 135, 270, 270, 4320, 270, 135, 270, 4320, 270, 270, 4320, 270, 4320, 135, 4320, 4320, 270, 135, 135, 4320, 270, 135, 270, 270, 4320, 270, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 4320, 4320, 135, 4320, 135, 270, 4320, 4320, 4320, 270, 135, 4320, 270, 135, 135, 135, 135, 135, 4320, 270, 135, 4320, 135, 4320, 135, 135, 270, 270, 4320, 270, 4320, 135, 270, 135, 4320, 4320, 135, 4320, 270, 135, 4320, 135, 135, 4320, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 135, 270, 4320, 4320, 135, 4320, 270, 135, 270, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 270, 4320, 4320, 270, 135, 4320, 135, 270, 270, 135, 270, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 270, 4320, 270, 4320, 135, 4320, 135, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 270, 270, 135, 270, 4320, 270, 270, 4320, 135, 4320, 4320, 270, 135, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 135, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 4320, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 4320, 270, 135, 135, 135, 135]
Prompts retrieved: 405945 . Total input tokens: 90403984 . Total output tokens: 81246146
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.690552046988159,
    "estimated_duration": 3600.0899027900946,
    "input_throughput": 4317.907724457834,
    "output_throughput": 3813.0042223004925,
    "total_throughput": 8130.911946758326,
    "itl": 223.98525363802398,
    "ttft": 1716971.3306799077,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.783484862446784,
    "arrivals": 135085,
    "finished_requests": 62649,
    "scheduler_time": 41.09486875123507
}
#Debug simulation 
Total elapsed time: 4.690645817667246. Arrivals time: 0.2045760676264763 Scheduler time: 4.3409690000116825 Scheduler overhead time: 0.02564909216016531 Adapter cache time: 0.08080534357577562 Engine time: 0.026723855640739202 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-16/adapters_256_slots_256_rate_0.4-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-16/adapters_256_slots_256_rate_0.4-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 135, 4320, 4320, 135, 4320, 270, 4320, 135, 270, 135, 4320, 270, 270, 270, 270, 4320, 135, 135, 135, 270, 4320, 135, 4320, 4320, 270, 270, 270, 135, 4320, 135, 270, 270, 135, 270, 135, 135, 270, 270, 4320, 270, 135, 270, 4320, 270, 270, 4320, 270, 4320, 135, 4320, 4320, 270, 135, 135, 4320, 270, 135, 270, 270, 4320, 270, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 4320, 4320, 135, 4320, 135, 270, 4320, 4320, 4320, 270, 135, 4320, 270, 135, 135, 135, 135, 135, 4320, 270, 135, 4320, 135, 4320, 135, 135, 270, 270, 4320, 270, 4320, 135, 270, 135, 4320, 4320, 135, 4320, 270, 135, 4320, 135, 135, 4320, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 135, 270, 4320, 4320, 135, 4320, 270, 135, 270, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 270, 4320, 4320, 270, 135, 4320, 135, 270, 270, 135, 270, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 270, 4320, 270, 4320, 135, 4320, 135, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 270, 270, 135, 270, 4320, 270, 270, 4320, 135, 4320, 4320, 270, 135, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 135, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 4320, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 4320, 270, 135, 135, 135, 135]
Prompts retrieved: 405945 . Total input tokens: 90403984 . Total output tokens: 81246146
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.725833335425705,
    "estimated_duration": 3600.1371465743414,
    "input_throughput": 4307.517844078825,
    "output_throughput": 3810.4517804421166,
    "total_throughput": 8117.969624520942,
    "itl": 182.62359988872353,
    "ttft": 1721706.134951592,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8353226749482603,
    "arrivals": 135085,
    "finished_requests": 62502,
    "scheduler_time": 37.40484517767869
}
#Debug simulation 
Total elapsed time: 4.725931114982814. Arrivals time: 0.21031056437641382 Scheduler time: 4.3484824895858765 Scheduler overhead time: 0.030624130740761757 Adapter cache time: 0.0907506630755961 Engine time: 0.03146705497056246 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-16/adapters_256_slots_256_rate_0.4-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-16/adapters_256_slots_256_rate_0.4-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 135, 4320, 4320, 135, 4320, 270, 4320, 135, 270, 135, 4320, 270, 270, 270, 270, 4320, 135, 135, 135, 270, 4320, 135, 4320, 4320, 270, 270, 270, 135, 4320, 135, 270, 270, 135, 270, 135, 135, 270, 270, 4320, 270, 135, 270, 4320, 270, 270, 4320, 270, 4320, 135, 4320, 4320, 270, 135, 135, 4320, 270, 135, 270, 270, 4320, 270, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 4320, 4320, 135, 4320, 135, 270, 4320, 4320, 4320, 270, 135, 4320, 270, 135, 135, 135, 135, 135, 4320, 270, 135, 4320, 135, 4320, 135, 135, 270, 270, 4320, 270, 4320, 135, 270, 135, 4320, 4320, 135, 4320, 270, 135, 4320, 135, 135, 4320, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 135, 270, 4320, 4320, 135, 4320, 270, 135, 270, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 270, 4320, 4320, 270, 135, 4320, 135, 270, 270, 135, 270, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 270, 4320, 270, 4320, 135, 4320, 135, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 270, 270, 135, 270, 4320, 270, 270, 4320, 135, 4320, 4320, 270, 135, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 135, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 4320, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 4320, 270, 135, 135, 135, 135]
Prompts retrieved: 405945 . Total input tokens: 90403984 . Total output tokens: 81246146
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.687300005927682,
    "estimated_duration": 3600.024534000234,
    "input_throughput": 4307.727309504772,
    "output_throughput": 3810.618475079289,
    "total_throughput": 8118.345784584062,
    "itl": 182.62403720585883,
    "ttft": 1721684.581260894,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8005920728808293,
    "arrivals": 135085,
    "finished_requests": 62503,
    "scheduler_time": 37.40490923334053
}
#Debug simulation 
Total elapsed time: 4.687397432047874. Arrivals time: 0.20627532014623284 Scheduler time: 4.31415280001238 Scheduler overhead time: 0.03072208445519209 Adapter cache time: 0.09028374776244164 Engine time: 0.03168345056474209 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-16/adapters_256_slots_256_rate_0.4-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-16/adapters_256_slots_256_rate_0.4-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 135, 4320, 4320, 135, 4320, 270, 4320, 135, 270, 135, 4320, 270, 270, 270, 270, 4320, 135, 135, 135, 270, 4320, 135, 4320, 4320, 270, 270, 270, 135, 4320, 135, 270, 270, 135, 270, 135, 135, 270, 270, 4320, 270, 135, 270, 4320, 270, 270, 4320, 270, 4320, 135, 4320, 4320, 270, 135, 135, 4320, 270, 135, 270, 270, 4320, 270, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 4320, 4320, 135, 4320, 135, 270, 4320, 4320, 4320, 270, 135, 4320, 270, 135, 135, 135, 135, 135, 4320, 270, 135, 4320, 135, 4320, 135, 135, 270, 270, 4320, 270, 4320, 135, 270, 135, 4320, 4320, 135, 4320, 270, 135, 4320, 135, 135, 4320, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 135, 270, 4320, 4320, 135, 4320, 270, 135, 270, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 270, 4320, 4320, 270, 135, 4320, 135, 270, 270, 135, 270, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 270, 4320, 270, 4320, 135, 4320, 135, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 270, 270, 135, 270, 4320, 270, 270, 4320, 135, 4320, 4320, 270, 135, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 135, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 4320, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 4320, 270, 135, 135, 135, 135]
Prompts retrieved: 405945 . Total input tokens: 90403984 . Total output tokens: 81246146
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.729898444842547,
    "estimated_duration": 3600.103723864383,
    "input_throughput": 4307.734773639595,
    "output_throughput": 3810.6335406565045,
    "total_throughput": 8118.368314296099,
    "itl": 182.6340088449347,
    "ttft": 1721722.4459473686,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.765452875494958,
    "arrivals": 135085,
    "finished_requests": 62503,
    "scheduler_time": 37.40565868515645
}
#Debug simulation 
Total elapsed time: 4.729994578287005. Arrivals time: 0.20525697758421302 Scheduler time: 4.356263090856373 Scheduler overhead time: 0.030754744075238705 Adapter cache time: 0.09171933215111494 Engine time: 0.03168726246803999 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_256_slots_256_rate_0.4-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_256_slots_256_rate_0.4-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 66, 4320, 4320, 66, 4320, 270, 4320, 66, 270, 66, 4320, 270, 270, 270, 270, 4320, 66, 66, 66, 270, 4320, 66, 4320, 4320, 270, 270, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 66, 270, 270, 4320, 270, 66, 270, 4320, 270, 270, 4320, 270, 4320, 66, 4320, 4320, 270, 66, 66, 4320, 270, 66, 270, 270, 4320, 270, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 4320, 4320, 66, 4320, 66, 270, 4320, 4320, 4320, 270, 66, 4320, 270, 66, 66, 66, 66, 66, 4320, 270, 66, 4320, 66, 4320, 66, 66, 270, 270, 4320, 270, 4320, 66, 270, 66, 4320, 4320, 66, 4320, 270, 66, 4320, 66, 66, 4320, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 66, 270, 4320, 4320, 66, 4320, 270, 66, 270, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 270, 4320, 4320, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 270, 4320, 270, 4320, 66, 4320, 66, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 270, 270, 66, 270, 4320, 270, 270, 4320, 66, 4320, 4320, 270, 66, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 66, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 4320, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 4320, 270, 66, 66, 66, 66]
Prompts retrieved: 400080 . Total input tokens: 89083538 . Total output tokens: 80076302
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.783877096604556,
    "estimated_duration": 3600.1702230229316,
    "input_throughput": 4492.469243973574,
    "output_throughput": 3938.825422563825,
    "total_throughput": 8431.294666537398,
    "itl": 216.30790444657546,
    "ttft": 1658021.622849968,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.783484862446784,
    "arrivals": 133166,
    "finished_requests": 65314,
    "scheduler_time": 42.63428914338229
}
#Debug simulation 
Total elapsed time: 4.783974354621023. Arrivals time: 0.2118982537649572 Scheduler time: 4.436873151920736 Scheduler overhead time: 0.026639409363269806 Adapter cache time: 0.0688277492299676 Engine time: 0.027323040645569563 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_256_slots_256_rate_0.4-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_256_slots_256_rate_0.4-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 66, 4320, 4320, 66, 4320, 270, 4320, 66, 270, 66, 4320, 270, 270, 270, 270, 4320, 66, 66, 66, 270, 4320, 66, 4320, 4320, 270, 270, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 66, 270, 270, 4320, 270, 66, 270, 4320, 270, 270, 4320, 270, 4320, 66, 4320, 4320, 270, 66, 66, 4320, 270, 66, 270, 270, 4320, 270, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 4320, 4320, 66, 4320, 66, 270, 4320, 4320, 4320, 270, 66, 4320, 270, 66, 66, 66, 66, 66, 4320, 270, 66, 4320, 66, 4320, 66, 66, 270, 270, 4320, 270, 4320, 66, 270, 66, 4320, 4320, 66, 4320, 270, 66, 4320, 66, 66, 4320, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 66, 270, 4320, 4320, 66, 4320, 270, 66, 270, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 270, 4320, 4320, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 270, 4320, 270, 4320, 66, 4320, 66, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 270, 270, 66, 270, 4320, 270, 270, 4320, 66, 4320, 4320, 270, 66, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 66, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 4320, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 4320, 270, 66, 66, 66, 66]
Prompts retrieved: 400080 . Total input tokens: 89083538 . Total output tokens: 80076302
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.823071425314993,
    "estimated_duration": 3600.052000824687,
    "input_throughput": 4461.843050133824,
    "output_throughput": 3920.2142071189664,
    "total_throughput": 8382.05725725279,
    "itl": 177.49043619846904,
    "ttft": 1668428.9099081259,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8353226749482603,
    "arrivals": 133166,
    "finished_requests": 64872,
    "scheduler_time": 38.6960787568834
}
#Debug simulation 
Total elapsed time: 4.8231921922415495. Arrivals time: 0.20831865351647139 Scheduler time: 4.458890189416707 Scheduler overhead time: 0.03155404515564442 Adapter cache time: 0.07738359877839684 Engine time: 0.03236995078623295 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_256_slots_256_rate_0.4-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_256_slots_256_rate_0.4-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 66, 4320, 4320, 66, 4320, 270, 4320, 66, 270, 66, 4320, 270, 270, 270, 270, 4320, 66, 66, 66, 270, 4320, 66, 4320, 4320, 270, 270, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 66, 270, 270, 4320, 270, 66, 270, 4320, 270, 270, 4320, 270, 4320, 66, 4320, 4320, 270, 66, 66, 4320, 270, 66, 270, 270, 4320, 270, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 4320, 4320, 66, 4320, 66, 270, 4320, 4320, 4320, 270, 66, 4320, 270, 66, 66, 66, 66, 66, 4320, 270, 66, 4320, 66, 4320, 66, 66, 270, 270, 4320, 270, 4320, 66, 270, 66, 4320, 4320, 66, 4320, 270, 66, 4320, 66, 66, 4320, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 66, 270, 4320, 4320, 66, 4320, 270, 66, 270, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 270, 4320, 4320, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 270, 4320, 270, 4320, 66, 4320, 66, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 270, 270, 66, 270, 4320, 270, 270, 4320, 66, 4320, 4320, 270, 66, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 66, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 4320, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 4320, 270, 66, 66, 66, 66]
Prompts retrieved: 400080 . Total input tokens: 89083538 . Total output tokens: 80076302
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.971818242687732,
    "estimated_duration": 3600.128409770912,
    "input_throughput": 4462.339442226247,
    "output_throughput": 3920.594877030556,
    "total_throughput": 8382.934319256803,
    "itl": 177.76596009005286,
    "ttft": 1668237.2754929713,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8005920728808293,
    "arrivals": 133166,
    "finished_requests": 64880,
    "scheduler_time": 38.733098697908474
}
#Debug simulation 
Total elapsed time: 4.9719123179093. Arrivals time: 0.2127939905039966 Scheduler time: 4.603492700960487 Scheduler overhead time: 0.03154358547180891 Adapter cache time: 0.07666275696828961 Engine time: 0.03259642655029893 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_256_slots_256_rate_0.4-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_256_slots_256_rate_0.4-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 66, 4320, 4320, 66, 4320, 270, 4320, 66, 270, 66, 4320, 270, 270, 270, 270, 4320, 66, 66, 66, 270, 4320, 66, 4320, 4320, 270, 270, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 66, 270, 270, 4320, 270, 66, 270, 4320, 270, 270, 4320, 270, 4320, 66, 4320, 4320, 270, 66, 66, 4320, 270, 66, 270, 270, 4320, 270, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 4320, 4320, 66, 4320, 66, 270, 4320, 4320, 4320, 270, 66, 4320, 270, 66, 66, 66, 66, 66, 4320, 270, 66, 4320, 66, 4320, 66, 66, 270, 270, 4320, 270, 4320, 66, 270, 66, 4320, 4320, 66, 4320, 270, 66, 4320, 66, 66, 4320, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 66, 270, 4320, 4320, 66, 4320, 270, 66, 270, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 270, 4320, 4320, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 270, 4320, 270, 4320, 66, 4320, 66, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 270, 270, 66, 270, 4320, 270, 270, 4320, 66, 4320, 4320, 270, 66, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 66, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 4320, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 4320, 270, 66, 66, 66, 66]
Prompts retrieved: 400080 . Total input tokens: 89083538 . Total output tokens: 80076302
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.001629389356822,
    "estimated_duration": 3600.119131700646,
    "input_throughput": 4462.36455303386,
    "output_throughput": 3920.526372507171,
    "total_throughput": 8382.89092554103,
    "itl": 177.76529305544335,
    "ttft": 1668315.6159355114,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.765452875494958,
    "arrivals": 133166,
    "finished_requests": 64880,
    "scheduler_time": 38.7341576242657
}
#Debug simulation 
Total elapsed time: 5.00172359123826. Arrivals time: 0.21822430239990354 Scheduler time: 4.628098434768617 Scheduler overhead time: 0.031429474242031574 Adapter cache time: 0.0771013512276113 Engine time: 0.03221945930272341 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_256_slots_256_rate_0.4-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_256_slots_256_rate_0.4-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 33, 4320, 4320, 33, 4320, 270, 4320, 33, 270, 33, 4320, 270, 270, 270, 270, 4320, 33, 33, 33, 270, 4320, 33, 4320, 4320, 270, 270, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 33, 270, 270, 4320, 270, 33, 270, 4320, 270, 270, 4320, 270, 4320, 33, 4320, 4320, 270, 33, 33, 4320, 270, 33, 270, 270, 4320, 270, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 4320, 4320, 33, 4320, 33, 270, 4320, 4320, 4320, 270, 33, 4320, 270, 33, 33, 33, 33, 33, 4320, 270, 33, 4320, 33, 4320, 33, 33, 270, 270, 4320, 270, 4320, 33, 270, 33, 4320, 4320, 33, 4320, 270, 33, 4320, 33, 33, 4320, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 33, 270, 4320, 4320, 33, 4320, 270, 33, 270, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 270, 4320, 4320, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 270, 4320, 270, 4320, 33, 4320, 33, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 270, 270, 33, 270, 4320, 270, 270, 4320, 33, 4320, 4320, 270, 33, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 33, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 4320, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 4320, 270, 33, 33, 33, 33]
Prompts retrieved: 397275 . Total input tokens: 88477227 . Total output tokens: 79493181
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.926712267100811,
    "estimated_duration": 3600.2043360596663,
    "input_throughput": 4577.591564715807,
    "output_throughput": 4046.337829797717,
    "total_throughput": 8623.929394513523,
    "itl": 211.27960881693892,
    "ttft": 1627920.9020091307,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.783484862446784,
    "arrivals": 132222,
    "finished_requests": 66754,
    "scheduler_time": 43.97593774724534
}
#Debug simulation 
Total elapsed time: 4.92681095097214. Arrivals time: 0.21504225628450513 Scheduler time: 4.58062902232632 Scheduler overhead time: 0.02707755658775568 Adapter cache time: 0.06295146606862545 Engine time: 0.02838840987533331 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_256_slots_256_rate_0.4-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_256_slots_256_rate_0.4-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 33, 4320, 4320, 33, 4320, 270, 4320, 33, 270, 33, 4320, 270, 270, 270, 270, 4320, 33, 33, 33, 270, 4320, 33, 4320, 4320, 270, 270, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 33, 270, 270, 4320, 270, 33, 270, 4320, 270, 270, 4320, 270, 4320, 33, 4320, 4320, 270, 33, 33, 4320, 270, 33, 270, 270, 4320, 270, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 4320, 4320, 33, 4320, 33, 270, 4320, 4320, 4320, 270, 33, 4320, 270, 33, 33, 33, 33, 33, 4320, 270, 33, 4320, 33, 4320, 33, 33, 270, 270, 4320, 270, 4320, 33, 270, 33, 4320, 4320, 33, 4320, 270, 33, 4320, 33, 33, 4320, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 33, 270, 4320, 4320, 33, 4320, 270, 33, 270, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 270, 4320, 4320, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 270, 4320, 270, 4320, 33, 4320, 33, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 270, 270, 33, 270, 4320, 270, 270, 4320, 33, 4320, 4320, 270, 33, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 33, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 4320, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 4320, 270, 33, 33, 33, 33]
Prompts retrieved: 397275 . Total input tokens: 88477227 . Total output tokens: 79493181
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.8846122729592025,
    "estimated_duration": 3600.0953863928285,
    "input_throughput": 4533.215442480841,
    "output_throughput": 4013.5558781617683,
    "total_throughput": 8546.771320642609,
    "itl": 174.05331237983324,
    "ttft": 1642111.0771035864,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8353226749482603,
    "arrivals": 132222,
    "finished_requests": 66097,
    "scheduler_time": 39.85353299114501
}
#Debug simulation 
Total elapsed time: 4.884737866930664. Arrivals time: 0.21056873258203268 Scheduler time: 4.5236746347509325 Scheduler overhead time: 0.03196906205266714 Adapter cache time: 0.07064843596890569 Engine time: 0.03288271417841315 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_256_slots_256_rate_0.4-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_256_slots_256_rate_0.4-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 33, 4320, 4320, 33, 4320, 270, 4320, 33, 270, 33, 4320, 270, 270, 270, 270, 4320, 33, 33, 33, 270, 4320, 33, 4320, 4320, 270, 270, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 33, 270, 270, 4320, 270, 33, 270, 4320, 270, 270, 4320, 270, 4320, 33, 4320, 4320, 270, 33, 33, 4320, 270, 33, 270, 270, 4320, 270, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 4320, 4320, 33, 4320, 33, 270, 4320, 4320, 4320, 270, 33, 4320, 270, 33, 33, 33, 33, 33, 4320, 270, 33, 4320, 33, 4320, 33, 33, 270, 270, 4320, 270, 4320, 33, 270, 33, 4320, 4320, 33, 4320, 270, 33, 4320, 33, 33, 4320, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 33, 270, 4320, 4320, 33, 4320, 270, 33, 270, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 270, 4320, 4320, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 270, 4320, 270, 4320, 33, 4320, 33, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 270, 270, 33, 270, 4320, 270, 270, 4320, 33, 4320, 4320, 270, 33, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 33, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 4320, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 4320, 270, 33, 33, 33, 33]
Prompts retrieved: 397275 . Total input tokens: 88477227 . Total output tokens: 79493181
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.9489130158908665,
    "estimated_duration": 3600.177800128923,
    "input_throughput": 4533.034729400194,
    "output_throughput": 4013.442613718293,
    "total_throughput": 8546.477343118488,
    "itl": 174.05247999378045,
    "ttft": 1642159.1239460555,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8005920728808293,
    "arrivals": 132222,
    "finished_requests": 66096,
    "scheduler_time": 39.85431679391306
}
#Debug simulation 
Total elapsed time: 4.949013833887875. Arrivals time: 0.21769225830212235 Scheduler time: 4.578972816932946 Scheduler overhead time: 0.03222837019711733 Adapter cache time: 0.07179155852645636 Engine time: 0.03330588527023792 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_256_slots_256_rate_0.4-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_256_slots_256_rate_0.4-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 33, 4320, 4320, 33, 4320, 270, 4320, 33, 270, 33, 4320, 270, 270, 270, 270, 4320, 33, 33, 33, 270, 4320, 33, 4320, 4320, 270, 270, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 33, 270, 270, 4320, 270, 33, 270, 4320, 270, 270, 4320, 270, 4320, 33, 4320, 4320, 270, 33, 33, 4320, 270, 33, 270, 270, 4320, 270, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 4320, 4320, 33, 4320, 33, 270, 4320, 4320, 4320, 270, 33, 4320, 270, 33, 33, 33, 33, 33, 4320, 270, 33, 4320, 33, 4320, 33, 33, 270, 270, 4320, 270, 4320, 33, 270, 33, 4320, 4320, 33, 4320, 270, 33, 4320, 33, 33, 4320, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 33, 270, 4320, 4320, 33, 4320, 270, 33, 270, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 270, 4320, 4320, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 270, 4320, 270, 4320, 33, 4320, 33, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 270, 270, 33, 270, 4320, 270, 270, 4320, 33, 4320, 4320, 270, 33, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 33, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 4320, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 4320, 270, 33, 33, 33, 33]
Prompts retrieved: 397275 . Total input tokens: 88477227 . Total output tokens: 79493181
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.91342937014997,
    "estimated_duration": 3600.089351546893,
    "input_throughput": 4532.945826188458,
    "output_throughput": 4013.420387411126,
    "total_throughput": 8546.366213599584,
    "itl": 174.0605328811072,
    "ttft": 1642187.137520193,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.765452875494958,
    "arrivals": 132222,
    "finished_requests": 66095,
    "scheduler_time": 39.85546274266906
}
#Debug simulation 
Total elapsed time: 4.9135241261683404. Arrivals time: 0.2137803635559976 Scheduler time: 4.549026020336896 Scheduler overhead time: 0.032051504123955965 Adapter cache time: 0.0707310801371932 Engine time: 0.03295623557642102 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_256_slots_256_rate_0.4-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_256_slots_256_rate_0.4-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 66, 4320, 4320, 66, 4320, 135, 4320, 66, 135, 66, 4320, 135, 135, 135, 135, 4320, 66, 66, 66, 135, 4320, 66, 4320, 4320, 135, 135, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 66, 135, 135, 4320, 135, 66, 135, 4320, 135, 135, 4320, 135, 4320, 66, 4320, 4320, 135, 66, 66, 4320, 135, 66, 135, 135, 4320, 135, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 4320, 4320, 66, 4320, 66, 135, 4320, 4320, 4320, 135, 66, 4320, 135, 66, 66, 66, 66, 66, 4320, 135, 66, 4320, 66, 4320, 66, 66, 135, 135, 4320, 135, 4320, 66, 135, 66, 4320, 4320, 66, 4320, 135, 66, 4320, 66, 66, 4320, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 66, 135, 4320, 4320, 66, 4320, 135, 66, 135, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 135, 4320, 4320, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 135, 4320, 135, 4320, 66, 4320, 66, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 135, 135, 66, 135, 4320, 135, 135, 4320, 66, 4320, 4320, 135, 66, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 66, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 4320, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 4320, 135, 66, 66, 66, 66]
Prompts retrieved: 388605 . Total input tokens: 86555962 . Total output tokens: 77766423
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.156453790143132,
    "estimated_duration": 3600.07115375866,
    "input_throughput": 4831.130068593624,
    "output_throughput": 4223.118474790904,
    "total_throughput": 9054.248543384527,
    "itl": 201.12572298156047,
    "ttft": 1557647.819143401,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.783484862446784,
    "arrivals": 129353,
    "finished_requests": 69889,
    "scheduler_time": 46.11017118946836
}
#Debug simulation 
Total elapsed time: 5.156566040124744. Arrivals time: 0.22155552078038454 Scheduler time: 4.803230875171721 Scheduler overhead time: 0.028432689607143402 Adapter cache time: 0.06028631795197725 Engine time: 0.029721098020672798 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_256_slots_256_rate_0.4-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_256_slots_256_rate_0.4-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 66, 4320, 4320, 66, 4320, 135, 4320, 66, 135, 66, 4320, 135, 135, 135, 135, 4320, 66, 66, 66, 135, 4320, 66, 4320, 4320, 135, 135, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 66, 135, 135, 4320, 135, 66, 135, 4320, 135, 135, 4320, 135, 4320, 66, 4320, 4320, 135, 66, 66, 4320, 135, 66, 135, 135, 4320, 135, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 4320, 4320, 66, 4320, 66, 135, 4320, 4320, 4320, 135, 66, 4320, 135, 66, 66, 66, 66, 66, 4320, 135, 66, 4320, 66, 4320, 66, 66, 135, 135, 4320, 135, 4320, 66, 135, 66, 4320, 4320, 66, 4320, 135, 66, 4320, 66, 66, 4320, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 66, 135, 4320, 4320, 66, 4320, 135, 66, 135, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 135, 4320, 4320, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 135, 4320, 135, 4320, 66, 4320, 66, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 135, 135, 66, 135, 4320, 135, 135, 4320, 66, 4320, 4320, 135, 66, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 66, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 4320, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 4320, 135, 66, 66, 66, 66]
Prompts retrieved: 388605 . Total input tokens: 86555962 . Total output tokens: 77766423
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.1207026690244675,
    "estimated_duration": 3600.033682330064,
    "input_throughput": 4772.905899280037,
    "output_throughput": 4179.456451713418,
    "total_throughput": 8952.362350993455,
    "itl": 166.544360594403,
    "ttft": 1575243.9170706058,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8353226749482605,
    "arrivals": 129353,
    "finished_requests": 69054,
    "scheduler_time": 41.84634301381877
}
#Debug simulation 
Total elapsed time: 5.120801902841777. Arrivals time: 0.2383092469535768 Scheduler time: 4.733861500862986 Scheduler overhead time: 0.03350130282342434 Adapter cache time: 0.06496533332392573 Engine time: 0.03455249220132828 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_256_slots_256_rate_0.4-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_256_slots_256_rate_0.4-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 66, 4320, 4320, 66, 4320, 135, 4320, 66, 135, 66, 4320, 135, 135, 135, 135, 4320, 66, 66, 66, 135, 4320, 66, 4320, 4320, 135, 135, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 66, 135, 135, 4320, 135, 66, 135, 4320, 135, 135, 4320, 135, 4320, 66, 4320, 4320, 135, 66, 66, 4320, 135, 66, 135, 135, 4320, 135, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 4320, 4320, 66, 4320, 66, 135, 4320, 4320, 4320, 135, 66, 4320, 135, 66, 66, 66, 66, 66, 4320, 135, 66, 4320, 66, 4320, 66, 66, 135, 135, 4320, 135, 4320, 66, 135, 66, 4320, 4320, 66, 4320, 135, 66, 4320, 66, 66, 4320, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 66, 135, 4320, 4320, 66, 4320, 135, 66, 135, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 135, 4320, 4320, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 135, 4320, 135, 4320, 66, 4320, 66, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 135, 135, 66, 135, 4320, 135, 135, 4320, 66, 4320, 4320, 135, 66, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 66, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 4320, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 4320, 135, 66, 66, 66, 66]
Prompts retrieved: 388605 . Total input tokens: 86555962 . Total output tokens: 77766423
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.159606212284416,
    "estimated_duration": 3600.101559260199,
    "input_throughput": 4772.934795631439,
    "output_throughput": 4179.446816242584,
    "total_throughput": 8952.381611874021,
    "itl": 166.5433589592365,
    "ttft": 1575198.6973573999,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8005920728808292,
    "arrivals": 129353,
    "finished_requests": 69055,
    "scheduler_time": 41.8489519470025
}
#Debug simulation 
Total elapsed time: 5.159713668283075. Arrivals time: 0.23708407999947667 Scheduler time: 4.770677336957306 Scheduler overhead time: 0.03345650527626276 Adapter cache time: 0.0657500415109098 Engine time: 0.03703352343291044 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_256_slots_256_rate_0.4-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_256_slots_256_rate_0.4-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 66, 4320, 4320, 66, 4320, 135, 4320, 66, 135, 66, 4320, 135, 135, 135, 135, 4320, 66, 66, 66, 135, 4320, 66, 4320, 4320, 135, 135, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 66, 135, 135, 4320, 135, 66, 135, 4320, 135, 135, 4320, 135, 4320, 66, 4320, 4320, 135, 66, 66, 4320, 135, 66, 135, 135, 4320, 135, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 4320, 4320, 66, 4320, 66, 135, 4320, 4320, 4320, 135, 66, 4320, 135, 66, 66, 66, 66, 66, 4320, 135, 66, 4320, 66, 4320, 66, 66, 135, 135, 4320, 135, 4320, 66, 135, 66, 4320, 4320, 66, 4320, 135, 66, 4320, 66, 66, 4320, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 66, 135, 4320, 4320, 66, 4320, 135, 66, 135, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 135, 4320, 4320, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 135, 4320, 135, 4320, 66, 4320, 66, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 135, 135, 66, 135, 4320, 135, 135, 4320, 66, 4320, 4320, 135, 66, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 66, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 4320, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 4320, 135, 66, 66, 66, 66]
Prompts retrieved: 388605 . Total input tokens: 86555962 . Total output tokens: 77766423
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.139257350936532,
    "estimated_duration": 3600.1707787134064,
    "input_throughput": 4773.249952920632,
    "output_throughput": 4179.570060667346,
    "total_throughput": 8952.820013587978,
    "itl": 166.5416742257638,
    "ttft": 1575189.5455705458,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.765452875494958,
    "arrivals": 129353,
    "finished_requests": 69058,
    "scheduler_time": 41.8496492226571
}
#Debug simulation 
Total elapsed time: 5.139361086301506. Arrivals time: 0.22140154521912336 Scheduler time: 4.769419664051384 Scheduler overhead time: 0.03344454197213054 Adapter cache time: 0.06504653999581933 Engine time: 0.034454744309186935 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_256_slots_256_rate_0.4-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_256_slots_256_rate_0.4-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 33, 4320, 4320, 33, 4320, 135, 4320, 33, 135, 33, 4320, 135, 135, 135, 135, 4320, 33, 33, 33, 135, 4320, 33, 4320, 4320, 135, 135, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 33, 135, 135, 4320, 135, 33, 135, 4320, 135, 135, 4320, 135, 4320, 33, 4320, 4320, 135, 33, 33, 4320, 135, 33, 135, 135, 4320, 135, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 4320, 4320, 33, 4320, 33, 135, 4320, 4320, 4320, 135, 33, 4320, 135, 33, 33, 33, 33, 33, 4320, 135, 33, 4320, 33, 4320, 33, 33, 135, 135, 4320, 135, 4320, 33, 135, 33, 4320, 4320, 33, 4320, 135, 33, 4320, 33, 33, 4320, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 33, 135, 4320, 4320, 33, 4320, 135, 33, 135, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 135, 4320, 4320, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 135, 4320, 135, 4320, 33, 4320, 33, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 135, 135, 33, 135, 4320, 135, 135, 4320, 33, 4320, 4320, 135, 33, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 33, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 4320, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 4320, 135, 33, 33, 33, 33]
Prompts retrieved: 385800 . Total input tokens: 85943615 . Total output tokens: 77196567
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.232087818905711,
    "estimated_duration": 3600.2100320632067,
    "input_throughput": 4927.591957692913,
    "output_throughput": 4332.779160403756,
    "total_throughput": 9260.37111809667,
    "itl": 196.6434176510146,
    "ttft": 1525865.289122856,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.783484862446784,
    "arrivals": 128453,
    "finished_requests": 71476,
    "scheduler_time": 47.488047370153005
}
#Debug simulation 
Total elapsed time: 5.232196907978505. Arrivals time: 0.228573068510741 Scheduler time: 4.878910634666681 Scheduler overhead time: 0.028784605208784342 Adapter cache time: 0.052700331434607506 Engine time: 0.02981701260432601 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_256_slots_256_rate_0.4-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_256_slots_256_rate_0.4-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 33, 4320, 4320, 33, 4320, 135, 4320, 33, 135, 33, 4320, 135, 135, 135, 135, 4320, 33, 33, 33, 135, 4320, 33, 4320, 4320, 135, 135, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 33, 135, 135, 4320, 135, 33, 135, 4320, 135, 135, 4320, 135, 4320, 33, 4320, 4320, 135, 33, 33, 4320, 135, 33, 135, 135, 4320, 135, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 4320, 4320, 33, 4320, 33, 135, 4320, 4320, 4320, 135, 33, 4320, 135, 33, 33, 33, 33, 33, 4320, 135, 33, 4320, 33, 4320, 33, 33, 135, 135, 4320, 135, 4320, 33, 135, 33, 4320, 4320, 33, 4320, 135, 33, 4320, 33, 33, 4320, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 33, 135, 4320, 4320, 33, 4320, 135, 33, 135, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 135, 4320, 4320, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 135, 4320, 135, 4320, 33, 4320, 33, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 135, 135, 33, 135, 4320, 135, 135, 4320, 33, 4320, 4320, 135, 33, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 33, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 4320, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 4320, 135, 33, 33, 33, 33]
Prompts retrieved: 385800 . Total input tokens: 85943615 . Total output tokens: 77196567
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.220470720902085,
    "estimated_duration": 3600.155512494305,
    "input_throughput": 4854.03781568662,
    "output_throughput": 4276.854971004355,
    "total_throughput": 9130.892786690974,
    "itl": 162.82240184459917,
    "ttft": 1547155.4096182394,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8353226749482604,
    "arrivals": 128453,
    "finished_requests": 70440,
    "scheduler_time": 42.90271675234189
}
#Debug simulation 
Total elapsed time: 5.2205796940252185. Arrivals time: 0.22299979534000158 Scheduler time: 4.855300165247172 Scheduler overhead time: 0.03424076642841101 Adapter cache time: 0.057024800684303045 Engine time: 0.035110784228891134 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_256_slots_256_rate_0.4-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_256_slots_256_rate_0.4-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 33, 4320, 4320, 33, 4320, 135, 4320, 33, 135, 33, 4320, 135, 135, 135, 135, 4320, 33, 33, 33, 135, 4320, 33, 4320, 4320, 135, 135, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 33, 135, 135, 4320, 135, 33, 135, 4320, 135, 135, 4320, 135, 4320, 33, 4320, 4320, 135, 33, 33, 4320, 135, 33, 135, 135, 4320, 135, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 4320, 4320, 33, 4320, 33, 135, 4320, 4320, 4320, 135, 33, 4320, 135, 33, 33, 33, 33, 33, 4320, 135, 33, 4320, 33, 4320, 33, 33, 135, 135, 4320, 135, 4320, 33, 135, 33, 4320, 4320, 33, 4320, 135, 33, 4320, 33, 33, 4320, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 33, 135, 4320, 4320, 33, 4320, 135, 33, 135, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 135, 4320, 4320, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 135, 4320, 135, 4320, 33, 4320, 33, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 135, 135, 33, 135, 4320, 135, 135, 4320, 33, 4320, 4320, 135, 33, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 33, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 4320, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 4320, 135, 33, 33, 33, 33]
Prompts retrieved: 385800 . Total input tokens: 85943615 . Total output tokens: 77196567
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.412743467837572,
    "estimated_duration": 3600.072791490235,
    "input_throughput": 4853.886855095107,
    "output_throughput": 4276.872411134347,
    "total_throughput": 9130.759266229454,
    "itl": 162.82365996684942,
    "ttft": 1547059.5969798388,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8005920728808292,
    "arrivals": 128453,
    "finished_requests": 70438,
    "scheduler_time": 42.902781446201075
}
#Debug simulation 
Total elapsed time: 5.412841974757612. Arrivals time: 0.2270084577612579 Scheduler time: 5.043056425638497 Scheduler overhead time: 0.03417810844257474 Adapter cache time: 0.05726483091711998 Engine time: 0.03538562636822462 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_256_slots_256_rate_0.4-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_256_slots_256_rate_0.4-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 33, 4320, 4320, 33, 4320, 135, 4320, 33, 135, 33, 4320, 135, 135, 135, 135, 4320, 33, 33, 33, 135, 4320, 33, 4320, 4320, 135, 135, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 33, 135, 135, 4320, 135, 33, 135, 4320, 135, 135, 4320, 135, 4320, 33, 4320, 4320, 135, 33, 33, 4320, 135, 33, 135, 135, 4320, 135, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 4320, 4320, 33, 4320, 33, 135, 4320, 4320, 4320, 135, 33, 4320, 135, 33, 33, 33, 33, 33, 4320, 135, 33, 4320, 33, 4320, 33, 33, 135, 135, 4320, 135, 4320, 33, 135, 33, 4320, 4320, 33, 4320, 135, 33, 4320, 33, 33, 4320, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 33, 135, 4320, 4320, 33, 4320, 135, 33, 135, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 135, 4320, 4320, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 135, 4320, 135, 4320, 33, 4320, 33, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 135, 135, 33, 135, 4320, 135, 135, 4320, 33, 4320, 4320, 135, 33, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 33, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 4320, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 4320, 135, 33, 33, 33, 33]
Prompts retrieved: 385800 . Total input tokens: 85943615 . Total output tokens: 77196567
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.245689867064357,
    "estimated_duration": 3600.0767112867693,
    "input_throughput": 4854.196285654638,
    "output_throughput": 4276.999140525672,
    "total_throughput": 9131.19542618031,
    "itl": 162.81813520694286,
    "ttft": 1546935.3484015758,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.765452875494958,
    "arrivals": 128453,
    "finished_requests": 70441,
    "scheduler_time": 42.902975927529106
}
#Debug simulation 
Total elapsed time: 5.24579169601202. Arrivals time: 0.22628813330084085 Scheduler time: 4.877517536748201 Scheduler overhead time: 0.034087615087628365 Adapter cache time: 0.05661910632625222 Engine time: 0.035313927102833986 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_256_slots_256_rate_0.4-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_256_slots_256_rate_0.4-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 4320, 33, 4320, 4320, 33, 4320, 66, 4320, 33, 66, 33, 4320, 66, 66, 66, 66, 4320, 33, 33, 33, 66, 4320, 33, 4320, 4320, 66, 66, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 33, 66, 66, 4320, 66, 33, 66, 4320, 66, 66, 4320, 66, 4320, 33, 4320, 4320, 66, 33, 33, 4320, 66, 33, 66, 66, 4320, 66, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 4320, 4320, 33, 4320, 33, 66, 4320, 4320, 4320, 66, 33, 4320, 66, 33, 33, 33, 33, 33, 4320, 66, 33, 4320, 33, 4320, 33, 33, 66, 66, 4320, 66, 4320, 33, 66, 33, 4320, 4320, 33, 4320, 66, 33, 4320, 33, 33, 4320, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 33, 66, 4320, 4320, 33, 4320, 66, 33, 66, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 66, 4320, 4320, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 66, 4320, 66, 4320, 33, 4320, 33, 66, 4320, 66, 4320, 66, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 66, 66, 33, 66, 4320, 66, 66, 4320, 33, 4320, 4320, 66, 33, 4320, 4320, 66, 66, 4320, 4320, 66, 66, 66, 66, 4320, 4320, 66, 66, 4320, 33, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 4320, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 4320, 66, 33, 33, 33, 33]
Prompts retrieved: 379935 . Total input tokens: 84650362 . Total output tokens: 76040480
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.4734142129309475,
    "estimated_duration": 3600.070645837685,
    "input_throughput": 5190.258702729485,
    "output_throughput": 4572.754709420285,
    "total_throughput": 9763.013412149769,
    "itl": 187.07003373995084,
    "ttft": 1443406.361152404,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.783484862446784,
    "arrivals": 126425,
    "finished_requests": 75585,
    "scheduler_time": 50.545143475773415
}
#Debug simulation 
Total elapsed time: 5.47351002227515. Arrivals time: 0.23243316216394305 Scheduler time: 5.124798166565597 Scheduler overhead time: 0.03028519870713353 Adapter cache time: 0.04056354146450758 Engine time: 0.031295299995690584 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_256_slots_256_rate_0.4-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_256_slots_256_rate_0.4-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 4320, 33, 4320, 4320, 33, 4320, 66, 4320, 33, 66, 33, 4320, 66, 66, 66, 66, 4320, 33, 33, 33, 66, 4320, 33, 4320, 4320, 66, 66, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 33, 66, 66, 4320, 66, 33, 66, 4320, 66, 66, 4320, 66, 4320, 33, 4320, 4320, 66, 33, 33, 4320, 66, 33, 66, 66, 4320, 66, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 4320, 4320, 33, 4320, 33, 66, 4320, 4320, 4320, 66, 33, 4320, 66, 33, 33, 33, 33, 33, 4320, 66, 33, 4320, 33, 4320, 33, 33, 66, 66, 4320, 66, 4320, 33, 66, 33, 4320, 4320, 33, 4320, 66, 33, 4320, 33, 33, 4320, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 33, 66, 4320, 4320, 33, 4320, 66, 33, 66, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 66, 4320, 4320, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 66, 4320, 66, 4320, 33, 4320, 33, 66, 4320, 66, 4320, 66, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 66, 66, 33, 66, 4320, 66, 66, 4320, 33, 4320, 4320, 66, 33, 4320, 4320, 66, 66, 4320, 4320, 66, 66, 66, 66, 4320, 4320, 66, 66, 4320, 33, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 4320, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 4320, 66, 33, 33, 33, 33]
Prompts retrieved: 379935 . Total input tokens: 84650362 . Total output tokens: 76040480
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.39776340033859,
    "estimated_duration": 3600.0557562687277,
    "input_throughput": 5072.497271244173,
    "output_throughput": 4477.808426141689,
    "total_throughput": 9550.305697385862,
    "itl": 156.2016315570076,
    "ttft": 1475511.1761782293,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8353226749482605,
    "arrivals": 126425,
    "finished_requests": 73899,
    "scheduler_time": 45.471107254773415
}
#Debug simulation 
Total elapsed time: 5.39786061597988. Arrivals time: 0.2289237454533577 Scheduler time: 5.038466726895422 Scheduler overhead time: 0.03529902221634984 Adapter cache time: 0.04233785858377814 Engine time: 0.03636430203914642 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_256_slots_256_rate_0.4-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_256_slots_256_rate_0.4-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 4320, 33, 4320, 4320, 33, 4320, 66, 4320, 33, 66, 33, 4320, 66, 66, 66, 66, 4320, 33, 33, 33, 66, 4320, 33, 4320, 4320, 66, 66, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 33, 66, 66, 4320, 66, 33, 66, 4320, 66, 66, 4320, 66, 4320, 33, 4320, 4320, 66, 33, 33, 4320, 66, 33, 66, 66, 4320, 66, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 4320, 4320, 33, 4320, 33, 66, 4320, 4320, 4320, 66, 33, 4320, 66, 33, 33, 33, 33, 33, 4320, 66, 33, 4320, 33, 4320, 33, 33, 66, 66, 4320, 66, 4320, 33, 66, 33, 4320, 4320, 33, 4320, 66, 33, 4320, 33, 33, 4320, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 33, 66, 4320, 4320, 33, 4320, 66, 33, 66, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 66, 4320, 4320, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 66, 4320, 66, 4320, 33, 4320, 33, 66, 4320, 66, 4320, 66, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 66, 66, 33, 66, 4320, 66, 66, 4320, 33, 4320, 4320, 66, 33, 4320, 4320, 66, 66, 4320, 4320, 66, 66, 66, 66, 4320, 4320, 66, 66, 4320, 33, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 4320, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 4320, 66, 33, 33, 33, 33]
Prompts retrieved: 379935 . Total input tokens: 84650362 . Total output tokens: 76040480
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.4105772180482745,
    "estimated_duration": 3600.141556132873,
    "input_throughput": 5072.539153048236,
    "output_throughput": 4478.000586542768,
    "total_throughput": 9550.539739591004,
    "itl": 156.19934564843768,
    "ttft": 1475502.5912580772,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8005920728808293,
    "arrivals": 126425,
    "finished_requests": 73904,
    "scheduler_time": 45.473656920656396
}
#Debug simulation 
Total elapsed time: 5.410701964981854. Arrivals time: 0.2277056546881795 Scheduler time: 5.05102506512776 Scheduler overhead time: 0.035272298846393824 Adapter cache time: 0.0434252773411572 Engine time: 0.036639407742768526 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_256_slots_256_rate_0.4-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_256_slots_256_rate_0.4-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 4320, 33, 4320, 4320, 33, 4320, 66, 4320, 33, 66, 33, 4320, 66, 66, 66, 66, 4320, 33, 33, 33, 66, 4320, 33, 4320, 4320, 66, 66, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 33, 66, 66, 4320, 66, 33, 66, 4320, 66, 66, 4320, 66, 4320, 33, 4320, 4320, 66, 33, 33, 4320, 66, 33, 66, 66, 4320, 66, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 4320, 4320, 33, 4320, 33, 66, 4320, 4320, 4320, 66, 33, 4320, 66, 33, 33, 33, 33, 33, 4320, 66, 33, 4320, 33, 4320, 33, 33, 66, 66, 4320, 66, 4320, 33, 66, 33, 4320, 4320, 33, 4320, 66, 33, 4320, 33, 33, 4320, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 33, 66, 4320, 4320, 33, 4320, 66, 33, 66, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 66, 4320, 4320, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 66, 4320, 66, 4320, 33, 4320, 33, 66, 4320, 66, 4320, 66, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 66, 66, 33, 66, 4320, 66, 66, 4320, 33, 4320, 4320, 66, 33, 4320, 4320, 66, 66, 4320, 4320, 66, 66, 66, 66, 4320, 4320, 66, 66, 4320, 33, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 4320, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 4320, 66, 33, 33, 33, 33]
Prompts retrieved: 379935 . Total input tokens: 84650362 . Total output tokens: 76040480
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.363150952383876,
    "estimated_duration": 3600.0486419134945,
    "input_throughput": 5051.351747940346,
    "output_throughput": 4458.683366974823,
    "total_throughput": 9510.03511491517,
    "itl": 156.58791847772173,
    "ttft": 1481039.5403844719,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.765452875494958,
    "arrivals": 126425,
    "finished_requests": 73590,
    "scheduler_time": 45.21075058757529
}
#Debug simulation 
Total elapsed time: 5.363248746376485. Arrivals time: 0.22634440241381526 Scheduler time: 5.005424432922155 Scheduler overhead time: 0.03543556621298194 Adapter cache time: 0.042931357864290476 Engine time: 0.03667530324310064 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_256_slots_256_rate_0.1-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_256_slots_256_rate_0.1-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 270, 1080, 1080, 270, 1080, 540, 1080, 270, 540, 270, 1080, 540, 540, 540, 540, 1080, 270, 270, 270, 540, 1080, 270, 1080, 1080, 540, 540, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 270, 540, 540, 1080, 540, 270, 540, 1080, 540, 540, 1080, 540, 1080, 270, 1080, 1080, 540, 270, 270, 1080, 540, 270, 540, 540, 1080, 540, 270, 270, 1080, 1080, 1080, 1080, 1080, 1080, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 1080, 1080, 270, 1080, 270, 540, 1080, 1080, 1080, 540, 270, 1080, 540, 270, 270, 270, 270, 270, 1080, 540, 270, 1080, 270, 1080, 270, 270, 540, 540, 1080, 540, 1080, 270, 540, 270, 1080, 1080, 270, 1080, 540, 270, 1080, 270, 270, 1080, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 270, 540, 1080, 1080, 270, 1080, 540, 270, 540, 1080, 270, 270, 270, 270, 270, 270, 1080, 270, 270, 270, 1080, 270, 540, 1080, 1080, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 1080, 270, 270, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 540, 1080, 540, 1080, 270, 1080, 270, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 540, 540, 270, 540, 1080, 540, 540, 1080, 270, 1080, 1080, 540, 270, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 270, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 1080, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 1080, 540, 270, 270, 270, 270]
Prompts retrieved: 161730 . Total input tokens: 36052490 . Total output tokens: 32364050
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 3.4971823100931942,
    "estimated_duration": 3600.1412558486895,
    "input_throughput": 3236.396900002554,
    "output_throughput": 2827.4471129328995,
    "total_throughput": 6063.844012935453,
    "itl": 290.24191080188854,
    "ttft": 649289.0040433402,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.783484862446784,
    "arrivals": 54189,
    "finished_requests": 46773,
    "scheduler_time": 38.30836838179969
}
#Debug simulation 
Total elapsed time: 3.497277828399092. Arrivals time: 0.11966828210279346 Scheduler time: 3.252418616320938 Scheduler overhead time: 0.020913387648761272 Adapter cache time: 0.07385428575798869 Engine time: 0.020992529578506947 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_256_slots_256_rate_0.1-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_256_slots_256_rate_0.1-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 270, 1080, 1080, 270, 1080, 540, 1080, 270, 540, 270, 1080, 540, 540, 540, 540, 1080, 270, 270, 270, 540, 1080, 270, 1080, 1080, 540, 540, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 270, 540, 540, 1080, 540, 270, 540, 1080, 540, 540, 1080, 540, 1080, 270, 1080, 1080, 540, 270, 270, 1080, 540, 270, 540, 540, 1080, 540, 270, 270, 1080, 1080, 1080, 1080, 1080, 1080, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 1080, 1080, 270, 1080, 270, 540, 1080, 1080, 1080, 540, 270, 1080, 540, 270, 270, 270, 270, 270, 1080, 540, 270, 1080, 270, 1080, 270, 270, 540, 540, 1080, 540, 1080, 270, 540, 270, 1080, 1080, 270, 1080, 540, 270, 1080, 270, 270, 1080, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 270, 540, 1080, 1080, 270, 1080, 540, 270, 540, 1080, 270, 270, 270, 270, 270, 270, 1080, 270, 270, 270, 1080, 270, 540, 1080, 1080, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 1080, 270, 270, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 540, 1080, 540, 1080, 270, 1080, 270, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 540, 540, 270, 540, 1080, 540, 540, 1080, 270, 1080, 1080, 540, 270, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 270, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 1080, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 1080, 540, 270, 270, 270, 270]
Prompts retrieved: 161730 . Total input tokens: 36052490 . Total output tokens: 32364050
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.680562349036336,
    "estimated_duration": 3600.1149891547843,
    "input_throughput": 3193.631601944833,
    "output_throughput": 2796.282627173379,
    "total_throughput": 5989.914229118212,
    "itl": 241.9787630238992,
    "ttft": 713223.8515999488,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8353226749482603,
    "arrivals": 54189,
    "finished_requests": 46143,
    "scheduler_time": 36.84336450070579
}
#Debug simulation 
Total elapsed time: 3.6806528051383793. Arrivals time: 0.12130801053717732 Scheduler time: 3.397959914524108 Scheduler overhead time: 0.023832126520574093 Adapter cache time: 0.10166370589286089 Engine time: 0.02481876639649272 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_256_slots_256_rate_0.1-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_256_slots_256_rate_0.1-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 270, 1080, 1080, 270, 1080, 540, 1080, 270, 540, 270, 1080, 540, 540, 540, 540, 1080, 270, 270, 270, 540, 1080, 270, 1080, 1080, 540, 540, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 270, 540, 540, 1080, 540, 270, 540, 1080, 540, 540, 1080, 540, 1080, 270, 1080, 1080, 540, 270, 270, 1080, 540, 270, 540, 540, 1080, 540, 270, 270, 1080, 1080, 1080, 1080, 1080, 1080, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 1080, 1080, 270, 1080, 270, 540, 1080, 1080, 1080, 540, 270, 1080, 540, 270, 270, 270, 270, 270, 1080, 540, 270, 1080, 270, 1080, 270, 270, 540, 540, 1080, 540, 1080, 270, 540, 270, 1080, 1080, 270, 1080, 540, 270, 1080, 270, 270, 1080, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 270, 540, 1080, 1080, 270, 1080, 540, 270, 540, 1080, 270, 270, 270, 270, 270, 270, 1080, 270, 270, 270, 1080, 270, 540, 1080, 1080, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 1080, 270, 270, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 540, 1080, 540, 1080, 270, 1080, 270, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 540, 540, 270, 540, 1080, 540, 540, 1080, 270, 1080, 1080, 540, 270, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 270, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 1080, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 1080, 540, 270, 270, 270, 270]
Prompts retrieved: 161730 . Total input tokens: 36052490 . Total output tokens: 32364050
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 3.583927388768643,
    "estimated_duration": 3600.2500423441566,
    "input_throughput": 3195.1161349088266,
    "output_throughput": 2797.6029113361196,
    "total_throughput": 5992.719046244946,
    "itl": 242.48766992263938,
    "ttft": 710848.6429685379,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8005920728808296,
    "arrivals": 54189,
    "finished_requests": 46168,
    "scheduler_time": 36.88394418083411
}
#Debug simulation 
Total elapsed time: 3.5840249001048505. Arrivals time: 0.12529458617791533 Scheduler time: 3.2974693663418293 Scheduler overhead time: 0.02375199180096388 Adapter cache time: 0.10178063297644258 Engine time: 0.024625517893582582 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_256_slots_256_rate_0.1-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_256_slots_256_rate_0.1-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 270, 1080, 1080, 270, 1080, 540, 1080, 270, 540, 270, 1080, 540, 540, 540, 540, 1080, 270, 270, 270, 540, 1080, 270, 1080, 1080, 540, 540, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 270, 540, 540, 1080, 540, 270, 540, 1080, 540, 540, 1080, 540, 1080, 270, 1080, 1080, 540, 270, 270, 1080, 540, 270, 540, 540, 1080, 540, 270, 270, 1080, 1080, 1080, 1080, 1080, 1080, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 1080, 1080, 270, 1080, 270, 540, 1080, 1080, 1080, 540, 270, 1080, 540, 270, 270, 270, 270, 270, 1080, 540, 270, 1080, 270, 1080, 270, 270, 540, 540, 1080, 540, 1080, 270, 540, 270, 1080, 1080, 270, 1080, 540, 270, 1080, 270, 270, 1080, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 270, 540, 1080, 1080, 270, 1080, 540, 270, 540, 1080, 270, 270, 270, 270, 270, 270, 1080, 270, 270, 270, 1080, 270, 540, 1080, 1080, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 1080, 270, 270, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 540, 1080, 540, 1080, 270, 1080, 270, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 540, 540, 270, 540, 1080, 540, 540, 1080, 270, 1080, 1080, 540, 270, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 270, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 1080, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 1080, 540, 270, 270, 270, 270]
Prompts retrieved: 161730 . Total input tokens: 36052490 . Total output tokens: 32364050
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 3.6143294549547136,
    "estimated_duration": 3600.275267825493,
    "input_throughput": 3195.105413966799,
    "output_throughput": 2797.515814973564,
    "total_throughput": 5992.621228940363,
    "itl": 242.4705374519476,
    "ttft": 710840.7567332085,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.765452875494958,
    "arrivals": 54189,
    "finished_requests": 46168,
    "scheduler_time": 36.884069303395
}
#Debug simulation 
Total elapsed time: 3.6144320708699524. Arrivals time: 0.12544527044519782 Scheduler time: 3.32740170462057 Scheduler overhead time: 0.023991655558347702 Adapter cache time: 0.10197971574962139 Engine time: 0.02455909550189972 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_256_slots_256_rate_0.1-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_256_slots_256_rate_0.1-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 135, 1080, 1080, 135, 1080, 540, 1080, 135, 540, 135, 1080, 540, 540, 540, 540, 1080, 135, 135, 135, 540, 1080, 135, 1080, 1080, 540, 540, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 135, 540, 540, 1080, 540, 135, 540, 1080, 540, 540, 1080, 540, 1080, 135, 1080, 1080, 540, 135, 135, 1080, 540, 135, 540, 540, 1080, 540, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 1080, 1080, 135, 1080, 135, 540, 1080, 1080, 1080, 540, 135, 1080, 540, 135, 135, 135, 135, 135, 1080, 540, 135, 1080, 135, 1080, 135, 135, 540, 540, 1080, 540, 1080, 135, 540, 135, 1080, 1080, 135, 1080, 540, 135, 1080, 135, 135, 1080, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 135, 540, 1080, 1080, 135, 1080, 540, 135, 540, 1080, 135, 135, 135, 135, 135, 135, 1080, 135, 135, 135, 1080, 135, 540, 1080, 1080, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 1080, 135, 135, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 540, 1080, 540, 1080, 135, 1080, 135, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 540, 540, 135, 540, 1080, 540, 540, 1080, 135, 1080, 1080, 540, 135, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 135, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 1080, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 1080, 540, 135, 135, 135, 135]
Prompts retrieved: 150255 . Total input tokens: 33450605 . Total output tokens: 30090347
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 3.6607873970642686,
    "estimated_duration": 3600.2756299830253,
    "input_throughput": 3416.420092274433,
    "output_throughput": 2964.979656307684,
    "total_throughput": 6381.399748582116,
    "itl": 252.60549602443865,
    "ttft": 73608.98233863995,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.783484862446784,
    "arrivals": 50289,
    "finished_requests": 49321,
    "scheduler_time": 41.06934983793106
}
#Debug simulation 
Total elapsed time: 3.660876558162272. Arrivals time: 0.1087277983315289 Scheduler time: 3.4092263956554234 Scheduler overhead time: 0.023388488683849573 Adapter cache time: 0.08486385317519307 Engine time: 0.023868389893323183 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_256_slots_256_rate_0.1-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_256_slots_256_rate_0.1-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 135, 1080, 1080, 135, 1080, 540, 1080, 135, 540, 135, 1080, 540, 540, 540, 540, 1080, 135, 135, 135, 540, 1080, 135, 1080, 1080, 540, 540, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 135, 540, 540, 1080, 540, 135, 540, 1080, 540, 540, 1080, 540, 1080, 135, 1080, 1080, 540, 135, 135, 1080, 540, 135, 540, 540, 1080, 540, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 1080, 1080, 135, 1080, 135, 540, 1080, 1080, 1080, 540, 135, 1080, 540, 135, 135, 135, 135, 135, 1080, 540, 135, 1080, 135, 1080, 135, 135, 540, 540, 1080, 540, 1080, 135, 540, 135, 1080, 1080, 135, 1080, 540, 135, 1080, 135, 135, 1080, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 135, 540, 1080, 1080, 135, 1080, 540, 135, 540, 1080, 135, 135, 135, 135, 135, 135, 1080, 135, 135, 135, 1080, 135, 540, 1080, 1080, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 1080, 135, 135, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 540, 1080, 540, 1080, 135, 1080, 135, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 540, 540, 135, 540, 1080, 540, 540, 1080, 135, 1080, 1080, 540, 135, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 135, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 1080, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 1080, 540, 135, 135, 135, 135]
Prompts retrieved: 150255 . Total input tokens: 33450605 . Total output tokens: 30090347
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.760938853956759,
    "estimated_duration": 3600.179933489672,
    "input_throughput": 3387.4431904238004,
    "output_throughput": 2946.7946591537866,
    "total_throughput": 6334.237849577587,
    "itl": 224.59037773188453,
    "ttft": 117716.6799378655,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8353226749482604,
    "arrivals": 50289,
    "finished_requests": 48916,
    "scheduler_time": 40.29447811147949
}
#Debug simulation 
Total elapsed time: 3.761029101908207. Arrivals time: 0.11230131005868316 Scheduler time: 3.484877017326653 Scheduler overhead time: 0.025958155281841755 Adapter cache time: 0.09938472183421254 Engine time: 0.026516758371144533 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_256_slots_256_rate_0.1-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_256_slots_256_rate_0.1-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 135, 1080, 1080, 135, 1080, 540, 1080, 135, 540, 135, 1080, 540, 540, 540, 540, 1080, 135, 135, 135, 540, 1080, 135, 1080, 1080, 540, 540, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 135, 540, 540, 1080, 540, 135, 540, 1080, 540, 540, 1080, 540, 1080, 135, 1080, 1080, 540, 135, 135, 1080, 540, 135, 540, 540, 1080, 540, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 1080, 1080, 135, 1080, 135, 540, 1080, 1080, 1080, 540, 135, 1080, 540, 135, 135, 135, 135, 135, 1080, 540, 135, 1080, 135, 1080, 135, 135, 540, 540, 1080, 540, 1080, 135, 540, 135, 1080, 1080, 135, 1080, 540, 135, 1080, 135, 135, 1080, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 135, 540, 1080, 1080, 135, 1080, 540, 135, 540, 1080, 135, 135, 135, 135, 135, 135, 1080, 135, 135, 135, 1080, 135, 540, 1080, 1080, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 1080, 135, 135, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 540, 1080, 540, 1080, 135, 1080, 135, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 540, 540, 135, 540, 1080, 540, 540, 1080, 135, 1080, 1080, 540, 135, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 135, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 1080, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 1080, 540, 135, 135, 135, 135]
Prompts retrieved: 150255 . Total input tokens: 33450605 . Total output tokens: 30090347
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 3.7234818232245743,
    "estimated_duration": 3600.184437021704,
    "input_throughput": 3387.1911879292657,
    "output_throughput": 2946.4468239231073,
    "total_throughput": 6333.638011852373,
    "itl": 224.7522866795021,
    "ttft": 118393.36931834118,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8005920728808291,
    "arrivals": 50289,
    "finished_requests": 48911,
    "scheduler_time": 40.288009621424564
}
#Debug simulation 
Total elapsed time: 3.7235764912329614. Arrivals time: 0.11222511716187 Scheduler time: 3.44686735374853 Scheduler overhead time: 0.02584900800138712 Adapter cache time: 0.10028430726379156 Engine time: 0.0263793901540339 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_256_slots_256_rate_0.1-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 256,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_256_slots_256_rate_0.1-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 135, 1080, 1080, 135, 1080, 540, 1080, 135, 540, 135, 1080, 540, 540, 540, 540, 1080, 135, 135, 135, 540, 1080, 135, 1080, 1080, 540, 540, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 135, 540, 540, 1080, 540, 135, 540, 1080, 540, 540, 1080, 540, 1080, 135, 1080, 1080, 540, 135, 135, 1080, 540, 135, 540, 540, 1080, 540, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 1080, 1080, 135, 1080, 135, 540, 1080, 1080, 1080, 540, 135, 1080, 540, 135, 135, 135, 135, 135, 1080, 540, 135, 1080, 135, 1080, 135, 135, 540, 540, 1080, 540, 1080, 135, 540, 135, 1080, 1080, 135, 1080, 540, 135, 1080, 135, 135, 1080, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 135, 540, 1080, 1080, 135, 1080, 540, 135, 540, 1080, 135, 135, 135, 135, 135, 135, 1080, 135, 135, 135, 1080, 135, 540, 1080, 1080, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 1080, 135, 135, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 540, 1080, 540, 1080, 135, 1080, 135, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 540, 540, 135, 540, 1080, 540, 540, 1080, 135, 1080, 1080, 540, 135, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 135, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 1080, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 1080, 540, 135, 135, 135, 135]
Prompts retrieved: 150255 . Total input tokens: 33450605 . Total output tokens: 30090347
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 3.6577755850739777,
    "estimated_duration": 3600.1958527339857,
    "input_throughput": 3387.0249005314313,
    "output_throughput": 2946.28804484203,
    "total_throughput": 6333.312945373462,
    "itl": 224.75905794096454,
    "ttft": 118492.02091522436,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.765452875494958,
    "arrivals": 50289,
    "finished_requests": 48910,
    "scheduler_time": 40.28789933724536
}
#Debug simulation 
Total elapsed time: 3.657871054019779. Arrivals time: 0.11177953891456127 Scheduler time: 3.3845795607194304 Scheduler overhead time: 0.025674754288047552 Adapter cache time: 0.09778233617544174 Engine time: 0.026201555971056223 
