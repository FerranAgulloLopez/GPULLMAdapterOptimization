INFO 06-01 00:47:13 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:47:14 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-32/adapters_256_slots_192_rate_3.2-0.4-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-32/adapters_256_slots_192_rate_3.2-0.4-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 33, 34560, 34560, 33, 34560, 4320, 34560, 33, 4320, 33, 34560, 4320, 4320, 4320, 4320, 34560, 33, 33, 33, 4320, 34560, 33, 34560, 34560, 4320, 4320, 4320, 33, 34560, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 34560, 4320, 33, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 33, 34560, 34560, 4320, 33, 33, 34560, 4320, 33, 4320, 4320, 34560, 4320, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 34560, 34560, 33, 34560, 33, 4320, 34560, 34560, 34560, 4320, 33, 34560, 4320, 33, 33, 33, 33, 33, 34560, 4320, 33, 34560, 33, 34560, 33, 33, 4320, 4320, 34560, 4320, 34560, 33, 4320, 33, 34560, 34560, 33, 34560, 4320, 33, 34560, 33, 33, 34560, 34560, 4320, 34560, 34560, 33, 34560, 4320, 4320, 33, 4320, 34560, 34560, 33, 34560, 4320, 33, 4320, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 4320, 34560, 34560, 4320, 33, 34560, 33, 4320, 4320, 33, 4320, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 34560, 33, 34560, 33, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 4320, 4320, 33, 4320, 34560, 4320, 4320, 34560, 33, 34560, 34560, 4320, 33, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 33, 34560, 4320, 34560, 34560, 33, 34560, 4320, 4320, 34560, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 33, 33, 33, 33]
Prompts retrieved: 3342165 . Total input tokens: 745000425 . Total output tokens: 668483509
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 4.3891419298015535,
    "estimated_duration": 3600.021896019653,
    "input_throughput": 3815.9951235821604,
    "output_throughput": 3376.0064108048,
    "total_throughput": 7192.001534386961,
    "itl": 99.61809083847409,
    "ttft": 2306923.4148426773,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 204,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6763465182296957,
    "arrivals": 1112647,
    "finished_requests": 55332,
    "scheduler_time": 64.63574814527006
}
#Debug simulation 
Total elapsed time: 4.389301700051874. Arrivals time: 0.3183057135902345 Scheduler time: 3.8411741494201124 Scheduler overhead time: 0.049459176138043404 Adapter cache time: 0.10563351027667522 Engine time: 0.05112080555409193 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-16/adapters_256_slots_192_rate_3.2-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-16/adapters_256_slots_192_rate_3.2-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 33, 34560, 34560, 33, 34560, 4320, 34560, 33, 4320, 33, 34560, 4320, 4320, 4320, 4320, 34560, 33, 33, 33, 4320, 34560, 33, 34560, 34560, 4320, 4320, 4320, 33, 34560, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 34560, 4320, 33, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 33, 34560, 34560, 4320, 33, 33, 34560, 4320, 33, 4320, 4320, 34560, 4320, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 34560, 34560, 33, 34560, 33, 4320, 34560, 34560, 34560, 4320, 33, 34560, 4320, 33, 33, 33, 33, 33, 34560, 4320, 33, 34560, 33, 34560, 33, 33, 4320, 4320, 34560, 4320, 34560, 33, 4320, 33, 34560, 34560, 33, 34560, 4320, 33, 34560, 33, 33, 34560, 34560, 4320, 34560, 34560, 33, 34560, 4320, 4320, 33, 4320, 34560, 34560, 33, 34560, 4320, 33, 4320, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 4320, 34560, 34560, 4320, 33, 34560, 33, 4320, 4320, 33, 4320, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 34560, 33, 34560, 33, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 4320, 4320, 33, 4320, 34560, 4320, 4320, 34560, 33, 34560, 34560, 4320, 33, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 33, 34560, 4320, 34560, 34560, 33, 34560, 4320, 4320, 34560, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 33, 33, 33, 33]
Prompts retrieved: 3342165 . Total input tokens: 745000425 . Total output tokens: 668483509
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.657577591948211,
    "estimated_duration": 3600.1638277639654,
    "input_throughput": 4339.19669975202,
    "output_throughput": 3814.089485068916,
    "total_throughput": 8153.286184820936,
    "itl": 220.7548153120911,
    "ttft": 2235921.198752099,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 210,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6279105619294577,
    "arrivals": 1112647,
    "finished_requests": 62980,
    "scheduler_time": 63.041176919409196
}
#Debug simulation 
Total elapsed time: 4.657686959020793. Arrivals time: 0.36380481254309416 Scheduler time: 4.184186819940805 Scheduler overhead time: 0.025222217198461294 Adapter cache time: 0.046768094412982464 Engine time: 0.026015118695795536 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-32/adapters_256_slots_192_rate_3.2-0.4-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-32/adapters_256_slots_192_rate_3.2-0.4-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 33, 34560, 34560, 33, 34560, 4320, 34560, 33, 4320, 33, 34560, 4320, 4320, 4320, 4320, 34560, 33, 33, 33, 4320, 34560, 33, 34560, 34560, 4320, 4320, 4320, 33, 34560, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 34560, 4320, 33, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 33, 34560, 34560, 4320, 33, 33, 34560, 4320, 33, 4320, 4320, 34560, 4320, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 34560, 34560, 33, 34560, 33, 4320, 34560, 34560, 34560, 4320, 33, 34560, 4320, 33, 33, 33, 33, 33, 34560, 4320, 33, 34560, 33, 34560, 33, 33, 4320, 4320, 34560, 4320, 34560, 33, 4320, 33, 34560, 34560, 33, 34560, 4320, 33, 34560, 33, 33, 34560, 34560, 4320, 34560, 34560, 33, 34560, 4320, 4320, 33, 4320, 34560, 34560, 33, 34560, 4320, 33, 4320, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 4320, 34560, 34560, 4320, 33, 34560, 33, 4320, 4320, 33, 4320, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 34560, 33, 34560, 33, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 4320, 4320, 33, 4320, 34560, 4320, 4320, 34560, 33, 34560, 34560, 4320, 33, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 33, 34560, 4320, 34560, 34560, 33, 34560, 4320, 4320, 34560, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 33, 33, 33, 33]
Prompts retrieved: 3342165 . Total input tokens: 745000425 . Total output tokens: 668483509
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.367994029074907,
    "estimated_duration": 3600.0303576940187,
    "input_throughput": 3815.98615429443,
    "output_throughput": 3375.9984756864633,
    "total_throughput": 7191.984629980893,
    "itl": 99.61832384613211,
    "ttft": 2306928.81727071,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 204,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6847720219194908,
    "arrivals": 1112647,
    "finished_requests": 55332,
    "scheduler_time": 64.63578431594637
}
#Debug simulation 
Total elapsed time: 4.36809140117839. Arrivals time: 0.32251754216849804 Scheduler time: 3.814251090399921 Scheduler overhead time: 0.04935491597279906 Adapter cache time: 0.10733456211164594 Engine time: 0.05104917101562023 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-8/adapters_256_slots_192_rate_3.2-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-8/adapters_256_slots_192_rate_3.2-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 540, 34560, 34560, 540, 34560, 1080, 34560, 540, 1080, 540, 34560, 1080, 1080, 1080, 1080, 34560, 540, 540, 540, 1080, 34560, 540, 34560, 34560, 1080, 1080, 1080, 540, 34560, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 34560, 1080, 540, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 540, 34560, 34560, 1080, 540, 540, 34560, 1080, 540, 1080, 1080, 34560, 1080, 540, 540, 34560, 34560, 34560, 34560, 34560, 34560, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 34560, 34560, 540, 34560, 540, 1080, 34560, 34560, 34560, 1080, 540, 34560, 1080, 540, 540, 540, 540, 540, 34560, 1080, 540, 34560, 540, 34560, 540, 540, 1080, 1080, 34560, 1080, 34560, 540, 1080, 540, 34560, 34560, 540, 34560, 1080, 540, 34560, 540, 540, 34560, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 540, 1080, 34560, 34560, 540, 34560, 1080, 540, 1080, 34560, 540, 540, 540, 540, 540, 540, 34560, 540, 540, 540, 34560, 540, 1080, 34560, 34560, 1080, 540, 34560, 540, 1080, 1080, 540, 1080, 540, 34560, 540, 540, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 34560, 540, 34560, 540, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 1080, 1080, 540, 1080, 34560, 1080, 1080, 34560, 540, 34560, 34560, 1080, 540, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 540, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 34560, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 540, 540, 540, 540]
Prompts retrieved: 3109860 . Total input tokens: 693311361 . Total output tokens: 622101039
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.008653993252665,
    "estimated_duration": 3600.20315857946,
    "input_throughput": 4793.736697572838,
    "output_throughput": 4211.587605512443,
    "total_throughput": 9005.324303085281,
    "itl": 203.2085809762047,
    "ttft": 2172497.738556668,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1195,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.6572828539997317,
    "arrivals": 1035175,
    "finished_requests": 69485,
    "scheduler_time": 69.44187680733945
}
#Debug simulation 
Total elapsed time: 5.00875280238688. Arrivals time: 0.2496158187277615 Scheduler time: 4.640981141012162 Scheduler overhead time: 0.02735178731381893 Adapter cache time: 0.050276498310267925 Engine time: 0.027897201478481293 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-16/adapters_256_slots_192_rate_3.2-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-16/adapters_256_slots_192_rate_3.2-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 540, 34560, 34560, 540, 34560, 1080, 34560, 540, 1080, 540, 34560, 1080, 1080, 1080, 1080, 34560, 540, 540, 540, 1080, 34560, 540, 34560, 34560, 1080, 1080, 1080, 540, 34560, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 34560, 1080, 540, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 540, 34560, 34560, 1080, 540, 540, 34560, 1080, 540, 1080, 1080, 34560, 1080, 540, 540, 34560, 34560, 34560, 34560, 34560, 34560, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 34560, 34560, 540, 34560, 540, 1080, 34560, 34560, 34560, 1080, 540, 34560, 1080, 540, 540, 540, 540, 540, 34560, 1080, 540, 34560, 540, 34560, 540, 540, 1080, 1080, 34560, 1080, 34560, 540, 1080, 540, 34560, 34560, 540, 34560, 1080, 540, 34560, 540, 540, 34560, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 540, 1080, 34560, 34560, 540, 34560, 1080, 540, 1080, 34560, 540, 540, 540, 540, 540, 540, 34560, 540, 540, 540, 34560, 540, 1080, 34560, 34560, 1080, 540, 34560, 540, 1080, 1080, 540, 1080, 540, 34560, 540, 540, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 34560, 540, 34560, 540, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 1080, 1080, 540, 1080, 34560, 1080, 1080, 34560, 540, 34560, 34560, 1080, 540, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 540, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 34560, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 540, 540, 540, 540]
Prompts retrieved: 3109860 . Total input tokens: 693311361 . Total output tokens: 622101039
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.941777382977307,
    "estimated_duration": 3600.148918518712,
    "input_throughput": 4791.127364558308,
    "output_throughput": 4210.5716577516105,
    "total_throughput": 9001.699022309918,
    "itl": 200.7495519339403,
    "ttft": 2172865.9145278977,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1193,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.89359766125214,
    "arrivals": 1035175,
    "finished_requests": 69444,
    "scheduler_time": 69.49037430115236
}
#Debug simulation 
Total elapsed time: 4.941868455149233. Arrivals time: 0.24738146178424358 Scheduler time: 4.575504176784307 Scheduler overhead time: 0.02759735146537423 Adapter cache time: 0.05023676156997681 Engine time: 0.028285224456340075 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-32/adapters_256_slots_192_rate_3.2-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-32/adapters_256_slots_192_rate_3.2-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 540, 34560, 34560, 540, 34560, 1080, 34560, 540, 1080, 540, 34560, 1080, 1080, 1080, 1080, 34560, 540, 540, 540, 1080, 34560, 540, 34560, 34560, 1080, 1080, 1080, 540, 34560, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 34560, 1080, 540, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 540, 34560, 34560, 1080, 540, 540, 34560, 1080, 540, 1080, 1080, 34560, 1080, 540, 540, 34560, 34560, 34560, 34560, 34560, 34560, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 34560, 34560, 540, 34560, 540, 1080, 34560, 34560, 34560, 1080, 540, 34560, 1080, 540, 540, 540, 540, 540, 34560, 1080, 540, 34560, 540, 34560, 540, 540, 1080, 1080, 34560, 1080, 34560, 540, 1080, 540, 34560, 34560, 540, 34560, 1080, 540, 34560, 540, 540, 34560, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 540, 1080, 34560, 34560, 540, 34560, 1080, 540, 1080, 34560, 540, 540, 540, 540, 540, 540, 34560, 540, 540, 540, 34560, 540, 1080, 34560, 34560, 1080, 540, 34560, 540, 1080, 1080, 540, 1080, 540, 34560, 540, 540, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 34560, 540, 34560, 540, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 1080, 1080, 540, 1080, 34560, 1080, 1080, 34560, 540, 34560, 34560, 1080, 540, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 540, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 34560, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 540, 540, 540, 540]
Prompts retrieved: 3109860 . Total input tokens: 693311361 . Total output tokens: 622101039
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.555828645359725,
    "estimated_duration": 3600.024990872001,
    "input_throughput": 4145.741776193867,
    "output_throughput": 3643.629150702854,
    "total_throughput": 7789.370926896721,
    "itl": 92.39936563310447,
    "ttft": 2254998.7501251446,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1046,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.420268456973093,
    "arrivals": 1035175,
    "finished_requests": 59982,
    "scheduler_time": 69.71516767009173
}
#Debug simulation 
Total elapsed time: 4.55592784518376. Arrivals time: 0.2195072714239359 Scheduler time: 4.124025082215667 Scheduler overhead time: 0.052874977234750986 Adapter cache time: 0.07981431670486927 Engine time: 0.054522203747183084 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-16-16/adapters_256_slots_192_rate_3.2-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-16-16/adapters_256_slots_192_rate_3.2-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 540, 34560, 34560, 540, 34560, 1080, 34560, 540, 1080, 540, 34560, 1080, 1080, 1080, 1080, 34560, 540, 540, 540, 1080, 34560, 540, 34560, 34560, 1080, 1080, 1080, 540, 34560, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 34560, 1080, 540, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 540, 34560, 34560, 1080, 540, 540, 34560, 1080, 540, 1080, 1080, 34560, 1080, 540, 540, 34560, 34560, 34560, 34560, 34560, 34560, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 34560, 34560, 540, 34560, 540, 1080, 34560, 34560, 34560, 1080, 540, 34560, 1080, 540, 540, 540, 540, 540, 34560, 1080, 540, 34560, 540, 34560, 540, 540, 1080, 1080, 34560, 1080, 34560, 540, 1080, 540, 34560, 34560, 540, 34560, 1080, 540, 34560, 540, 540, 34560, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 540, 1080, 34560, 34560, 540, 34560, 1080, 540, 1080, 34560, 540, 540, 540, 540, 540, 540, 34560, 540, 540, 540, 34560, 540, 1080, 34560, 34560, 1080, 540, 34560, 540, 1080, 1080, 540, 1080, 540, 34560, 540, 540, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 34560, 540, 34560, 540, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 1080, 1080, 540, 1080, 34560, 1080, 1080, 34560, 540, 34560, 34560, 1080, 540, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 540, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 34560, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 540, 540, 540, 540]
Prompts retrieved: 3109860 . Total input tokens: 693311361 . Total output tokens: 622101039
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.942709372844547,
    "estimated_duration": 3600.208928335472,
    "input_throughput": 4791.726075735266,
    "output_throughput": 4210.832843806386,
    "total_throughput": 9002.558919541652,
    "itl": 200.73875484782155,
    "ttft": 2172857.681306555,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1193,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.738331440244762,
    "arrivals": 1035175,
    "finished_requests": 69451,
    "scheduler_time": 69.4946232343832
}
#Debug simulation 
Total elapsed time: 4.9428430600091815. Arrivals time: 0.2448362410068512 Scheduler time: 4.578375212382525 Scheduler overhead time: 0.02757763909175992 Adapter cache time: 0.05090176872909069 Engine time: 0.028287436347454786 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-16-32/adapters_256_slots_192_rate_3.2-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-16-32/adapters_256_slots_192_rate_3.2-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 540, 34560, 34560, 540, 34560, 1080, 34560, 540, 1080, 540, 34560, 1080, 1080, 1080, 1080, 34560, 540, 540, 540, 1080, 34560, 540, 34560, 34560, 1080, 1080, 1080, 540, 34560, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 34560, 1080, 540, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 540, 34560, 34560, 1080, 540, 540, 34560, 1080, 540, 1080, 1080, 34560, 1080, 540, 540, 34560, 34560, 34560, 34560, 34560, 34560, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 34560, 34560, 540, 34560, 540, 1080, 34560, 34560, 34560, 1080, 540, 34560, 1080, 540, 540, 540, 540, 540, 34560, 1080, 540, 34560, 540, 34560, 540, 540, 1080, 1080, 34560, 1080, 34560, 540, 1080, 540, 34560, 34560, 540, 34560, 1080, 540, 34560, 540, 540, 34560, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 540, 1080, 34560, 34560, 540, 34560, 1080, 540, 1080, 34560, 540, 540, 540, 540, 540, 540, 34560, 540, 540, 540, 34560, 540, 1080, 34560, 34560, 1080, 540, 34560, 540, 1080, 1080, 540, 1080, 540, 34560, 540, 540, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 34560, 540, 34560, 540, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 1080, 1080, 540, 1080, 34560, 1080, 1080, 34560, 540, 34560, 34560, 1080, 540, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 540, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 34560, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 540, 540, 540, 540]
Prompts retrieved: 3109860 . Total input tokens: 693311361 . Total output tokens: 622101039
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 4.513288625981659,
    "estimated_duration": 3600.0670321714106,
    "input_throughput": 4145.693362547751,
    "output_throughput": 3643.586600688454,
    "total_throughput": 7789.279963236206,
    "itl": 92.40044238226915,
    "ttft": 2255015.286466808,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1046,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4622702216356944,
    "arrivals": 1035175,
    "finished_requests": 59982,
    "scheduler_time": 69.71520720487563
}
#Debug simulation 
Total elapsed time: 4.513408778235316. Arrivals time: 0.22052749479189515 Scheduler time: 4.081674581859261 Scheduler overhead time: 0.052717079408466816 Adapter cache time: 0.07924359245225787 Engine time: 0.05424065887928009 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_16-16-16/adapters_256_slots_192_rate_3.2-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_16-16-16/adapters_256_slots_192_rate_3.2-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 540, 34560, 34560, 540, 34560, 1080, 34560, 540, 1080, 540, 34560, 1080, 1080, 1080, 1080, 34560, 540, 540, 540, 1080, 34560, 540, 34560, 34560, 1080, 1080, 1080, 540, 34560, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 34560, 1080, 540, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 540, 34560, 34560, 1080, 540, 540, 34560, 1080, 540, 1080, 1080, 34560, 1080, 540, 540, 34560, 34560, 34560, 34560, 34560, 34560, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 34560, 34560, 540, 34560, 540, 1080, 34560, 34560, 34560, 1080, 540, 34560, 1080, 540, 540, 540, 540, 540, 34560, 1080, 540, 34560, 540, 34560, 540, 540, 1080, 1080, 34560, 1080, 34560, 540, 1080, 540, 34560, 34560, 540, 34560, 1080, 540, 34560, 540, 540, 34560, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 540, 1080, 34560, 34560, 540, 34560, 1080, 540, 1080, 34560, 540, 540, 540, 540, 540, 540, 34560, 540, 540, 540, 34560, 540, 1080, 34560, 34560, 1080, 540, 34560, 540, 1080, 1080, 540, 1080, 540, 34560, 540, 540, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 34560, 540, 34560, 540, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 1080, 1080, 540, 1080, 34560, 1080, 1080, 34560, 540, 34560, 34560, 1080, 540, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 540, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 34560, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 540, 540, 540, 540]
Prompts retrieved: 3109860 . Total input tokens: 693311361 . Total output tokens: 622101039
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.037722080014646,
    "estimated_duration": 3600.037659823566,
    "input_throughput": 4791.954037737889,
    "output_throughput": 4211.033170342715,
    "total_throughput": 9002.987208080604,
    "itl": 200.7297129899567,
    "ttft": 2172792.0483050863,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1193,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5671300018182057,
    "arrivals": 1035175,
    "finished_requests": 69451,
    "scheduler_time": 69.49455616085801
}
#Debug simulation 
Total elapsed time: 5.037815255112946. Arrivals time: 0.24702672520652413 Scheduler time: 4.6701360787265 Scheduler overhead time: 0.027770268730819225 Adapter cache time: 0.05134492740035057 Engine time: 0.02866352628916502 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_16-16-32/adapters_256_slots_192_rate_3.2-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_16-16-32/adapters_256_slots_192_rate_3.2-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 540, 34560, 34560, 540, 34560, 1080, 34560, 540, 1080, 540, 34560, 1080, 1080, 1080, 1080, 34560, 540, 540, 540, 1080, 34560, 540, 34560, 34560, 1080, 1080, 1080, 540, 34560, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 34560, 1080, 540, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 540, 34560, 34560, 1080, 540, 540, 34560, 1080, 540, 1080, 1080, 34560, 1080, 540, 540, 34560, 34560, 34560, 34560, 34560, 34560, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 34560, 34560, 540, 34560, 540, 1080, 34560, 34560, 34560, 1080, 540, 34560, 1080, 540, 540, 540, 540, 540, 34560, 1080, 540, 34560, 540, 34560, 540, 540, 1080, 1080, 34560, 1080, 34560, 540, 1080, 540, 34560, 34560, 540, 34560, 1080, 540, 34560, 540, 540, 34560, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 540, 1080, 34560, 34560, 540, 34560, 1080, 540, 1080, 34560, 540, 540, 540, 540, 540, 540, 34560, 540, 540, 540, 34560, 540, 1080, 34560, 34560, 1080, 540, 34560, 540, 1080, 1080, 540, 1080, 540, 34560, 540, 540, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 34560, 540, 34560, 540, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 1080, 1080, 540, 1080, 34560, 1080, 1080, 34560, 540, 34560, 34560, 1080, 540, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 540, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 34560, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 540, 540, 540, 540]
Prompts retrieved: 3109860 . Total input tokens: 693311361 . Total output tokens: 622101039
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.593170286156237,
    "estimated_duration": 3600.0148033846376,
    "input_throughput": 4145.591008672708,
    "output_throughput": 3643.3355739728154,
    "total_throughput": 7788.926582645523,
    "itl": 92.40128118188795,
    "ttft": 2255043.4491421767,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1046,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5085476150364148,
    "arrivals": 1035175,
    "finished_requests": 59978,
    "scheduler_time": 69.71328004683456
}
#Debug simulation 
Total elapsed time: 4.593280523084104. Arrivals time: 0.23878534184768796 Scheduler time: 4.140867500565946 Scheduler overhead time: 0.053139214869588614 Adapter cache time: 0.08013343252241611 Engine time: 0.05479171825572848 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-8/adapters_256_slots_192_rate_3.2-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-8/adapters_256_slots_192_rate_3.2-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 270, 34560, 34560, 270, 34560, 1080, 34560, 270, 1080, 270, 34560, 1080, 1080, 1080, 1080, 34560, 270, 270, 270, 1080, 34560, 270, 34560, 34560, 1080, 1080, 1080, 270, 34560, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 34560, 1080, 270, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 270, 34560, 34560, 1080, 270, 270, 34560, 1080, 270, 1080, 1080, 34560, 1080, 270, 270, 34560, 34560, 34560, 34560, 34560, 34560, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 34560, 34560, 270, 34560, 270, 1080, 34560, 34560, 34560, 1080, 270, 34560, 1080, 270, 270, 270, 270, 270, 34560, 1080, 270, 34560, 270, 34560, 270, 270, 1080, 1080, 34560, 1080, 34560, 270, 1080, 270, 34560, 34560, 270, 34560, 1080, 270, 34560, 270, 270, 34560, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 270, 1080, 34560, 34560, 270, 34560, 1080, 270, 1080, 34560, 270, 270, 270, 270, 270, 270, 34560, 270, 270, 270, 34560, 270, 1080, 34560, 34560, 1080, 270, 34560, 270, 1080, 1080, 270, 1080, 270, 34560, 270, 270, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 34560, 270, 34560, 270, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 1080, 1080, 270, 1080, 34560, 1080, 1080, 34560, 270, 34560, 34560, 1080, 270, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 270, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 34560, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 270, 270, 270, 270]
Prompts retrieved: 3086910 . Total input tokens: 688216455 . Total output tokens: 617448558
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.143591327127069,
    "estimated_duration": 3600.221373648315,
    "input_throughput": 4879.220796969789,
    "output_throughput": 4307.683442333496,
    "total_throughput": 9186.904239303285,
    "itl": 199.26476906132262,
    "ttft": 2162064.4727507504,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 833,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5493862906960363,
    "arrivals": 1027687,
    "finished_requests": 71111,
    "scheduler_time": 70.94436346179357
}
#Debug simulation 
Total elapsed time: 5.143685644958168. Arrivals time: 0.25263048661872745 Scheduler time: 4.77726514544338 Scheduler overhead time: 0.027693462558090687 Adapter cache time: 0.04469458665698767 Engine time: 0.028556335251778364 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-16/adapters_256_slots_192_rate_3.2-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-16/adapters_256_slots_192_rate_3.2-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 270, 34560, 34560, 270, 34560, 1080, 34560, 270, 1080, 270, 34560, 1080, 1080, 1080, 1080, 34560, 270, 270, 270, 1080, 34560, 270, 34560, 34560, 1080, 1080, 1080, 270, 34560, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 34560, 1080, 270, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 270, 34560, 34560, 1080, 270, 270, 34560, 1080, 270, 1080, 1080, 34560, 1080, 270, 270, 34560, 34560, 34560, 34560, 34560, 34560, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 34560, 34560, 270, 34560, 270, 1080, 34560, 34560, 34560, 1080, 270, 34560, 1080, 270, 270, 270, 270, 270, 34560, 1080, 270, 34560, 270, 34560, 270, 270, 1080, 1080, 34560, 1080, 34560, 270, 1080, 270, 34560, 34560, 270, 34560, 1080, 270, 34560, 270, 270, 34560, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 270, 1080, 34560, 34560, 270, 34560, 1080, 270, 1080, 34560, 270, 270, 270, 270, 270, 270, 34560, 270, 270, 270, 34560, 270, 1080, 34560, 34560, 1080, 270, 34560, 270, 1080, 1080, 270, 1080, 270, 34560, 270, 270, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 34560, 270, 34560, 270, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 1080, 1080, 270, 1080, 34560, 1080, 1080, 34560, 270, 34560, 34560, 1080, 270, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 270, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 34560, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 270, 270, 270, 270]
Prompts retrieved: 3086910 . Total input tokens: 688216455 . Total output tokens: 617448558
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.14000454172492,
    "estimated_duration": 3600.1553017660895,
    "input_throughput": 4875.689388007539,
    "output_throughput": 4304.921232813796,
    "total_throughput": 9180.610620821335,
    "itl": 196.96945756049286,
    "ttft": 2162952.3869779683,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 831,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.716813935937833,
    "arrivals": 1027687,
    "finished_requests": 71060,
    "scheduler_time": 70.98225697224494
}
#Debug simulation 
Total elapsed time: 5.1400992926210165. Arrivals time: 0.32384873181581497 Scheduler time: 4.701365003827959 Scheduler overhead time: 0.028036093804985285 Adapter cache time: 0.045029610861092806 Engine time: 0.028766493313014507 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-32/adapters_256_slots_192_rate_3.2-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-32/adapters_256_slots_192_rate_3.2-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 270, 34560, 34560, 270, 34560, 1080, 34560, 270, 1080, 270, 34560, 1080, 1080, 1080, 1080, 34560, 270, 270, 270, 1080, 34560, 270, 34560, 34560, 1080, 1080, 1080, 270, 34560, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 34560, 1080, 270, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 270, 34560, 34560, 1080, 270, 270, 34560, 1080, 270, 1080, 1080, 34560, 1080, 270, 270, 34560, 34560, 34560, 34560, 34560, 34560, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 34560, 34560, 270, 34560, 270, 1080, 34560, 34560, 34560, 1080, 270, 34560, 1080, 270, 270, 270, 270, 270, 34560, 1080, 270, 34560, 270, 34560, 270, 270, 1080, 1080, 34560, 1080, 34560, 270, 1080, 270, 34560, 34560, 270, 34560, 1080, 270, 34560, 270, 270, 34560, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 270, 1080, 34560, 34560, 270, 34560, 1080, 270, 1080, 34560, 270, 270, 270, 270, 270, 270, 34560, 270, 270, 270, 34560, 270, 1080, 34560, 34560, 1080, 270, 34560, 270, 1080, 1080, 270, 1080, 270, 34560, 270, 270, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 34560, 270, 34560, 270, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 1080, 1080, 270, 1080, 34560, 1080, 1080, 34560, 270, 34560, 34560, 1080, 270, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 270, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 34560, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 270, 270, 270, 270]
Prompts retrieved: 3086910 . Total input tokens: 688216455 . Total output tokens: 617448558
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.567790686152875,
    "estimated_duration": 3600.0005003807787,
    "input_throughput": 4164.543310039604,
    "output_throughput": 3691.786709083581,
    "total_throughput": 7856.330019123186,
    "itl": 91.6521366626215,
    "ttft": 2248068.285846256,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 733,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3998603109084042,
    "arrivals": 1027687,
    "finished_requests": 60725,
    "scheduler_time": 70.52163174277155
}
#Debug simulation 
Total elapsed time: 4.5679129608906806. Arrivals time: 0.22437488893046975 Scheduler time: 4.138337025884539 Scheduler overhead time: 0.05274640070274472 Adapter cache time: 0.07267254311591387 Engine time: 0.0545454784296453 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-16-16/adapters_256_slots_192_rate_3.2-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-16-16/adapters_256_slots_192_rate_3.2-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 270, 34560, 34560, 270, 34560, 1080, 34560, 270, 1080, 270, 34560, 1080, 1080, 1080, 1080, 34560, 270, 270, 270, 1080, 34560, 270, 34560, 34560, 1080, 1080, 1080, 270, 34560, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 34560, 1080, 270, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 270, 34560, 34560, 1080, 270, 270, 34560, 1080, 270, 1080, 1080, 34560, 1080, 270, 270, 34560, 34560, 34560, 34560, 34560, 34560, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 34560, 34560, 270, 34560, 270, 1080, 34560, 34560, 34560, 1080, 270, 34560, 1080, 270, 270, 270, 270, 270, 34560, 1080, 270, 34560, 270, 34560, 270, 270, 1080, 1080, 34560, 1080, 34560, 270, 1080, 270, 34560, 34560, 270, 34560, 1080, 270, 34560, 270, 270, 34560, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 270, 1080, 34560, 34560, 270, 34560, 1080, 270, 1080, 34560, 270, 270, 270, 270, 270, 270, 34560, 270, 270, 270, 34560, 270, 1080, 34560, 34560, 1080, 270, 34560, 270, 1080, 1080, 270, 1080, 270, 34560, 270, 270, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 34560, 270, 34560, 270, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 1080, 1080, 270, 1080, 34560, 1080, 1080, 34560, 270, 34560, 34560, 1080, 270, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 270, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 34560, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 270, 270, 270, 270]
Prompts retrieved: 3086910 . Total input tokens: 688216455 . Total output tokens: 617448558
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.141448441892862,
    "estimated_duration": 3600.040006170845,
    "input_throughput": 4875.845537802889,
    "output_throughput": 4305.0591030750065,
    "total_throughput": 9180.904640877896,
    "itl": 196.96369148651146,
    "ttft": 2162902.8791282144,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 831,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6015900561376246,
    "arrivals": 1027687,
    "finished_requests": 71060,
    "scheduler_time": 70.98218525677284
}
#Debug simulation 
Total elapsed time: 5.141599595081061. Arrivals time: 0.36010813526809216 Scheduler time: 4.666423112619668 Scheduler overhead time: 0.028033467009663582 Adapter cache time: 0.045113437343388796 Engine time: 0.028899479191750288 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-16-32/adapters_256_slots_192_rate_3.2-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-16-32/adapters_256_slots_192_rate_3.2-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 270, 34560, 34560, 270, 34560, 1080, 34560, 270, 1080, 270, 34560, 1080, 1080, 1080, 1080, 34560, 270, 270, 270, 1080, 34560, 270, 34560, 34560, 1080, 1080, 1080, 270, 34560, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 34560, 1080, 270, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 270, 34560, 34560, 1080, 270, 270, 34560, 1080, 270, 1080, 1080, 34560, 1080, 270, 270, 34560, 34560, 34560, 34560, 34560, 34560, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 34560, 34560, 270, 34560, 270, 1080, 34560, 34560, 34560, 1080, 270, 34560, 1080, 270, 270, 270, 270, 270, 34560, 1080, 270, 34560, 270, 34560, 270, 270, 1080, 1080, 34560, 1080, 34560, 270, 1080, 270, 34560, 34560, 270, 34560, 1080, 270, 34560, 270, 270, 34560, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 270, 1080, 34560, 34560, 270, 34560, 1080, 270, 1080, 34560, 270, 270, 270, 270, 270, 270, 34560, 270, 270, 270, 34560, 270, 1080, 34560, 34560, 1080, 270, 34560, 270, 1080, 1080, 270, 1080, 270, 34560, 270, 270, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 34560, 270, 34560, 270, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 1080, 1080, 270, 1080, 34560, 1080, 1080, 34560, 270, 34560, 34560, 1080, 270, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 270, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 34560, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 270, 270, 270, 270]
Prompts retrieved: 3086910 . Total input tokens: 688216455 . Total output tokens: 617448558
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 4.73461680393666,
    "estimated_duration": 3600.031977345085,
    "input_throughput": 4164.506897257177,
    "output_throughput": 3691.7544298596185,
    "total_throughput": 7856.261327116796,
    "itl": 91.65294608457884,
    "ttft": 2248081.536690498,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 733,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4312987575121237,
    "arrivals": 1027687,
    "finished_requests": 60725,
    "scheduler_time": 70.52167026049966
}
#Debug simulation 
Total elapsed time: 4.73473696410656. Arrivals time: 0.35559559566900134 Scheduler time: 4.171489438042045 Scheduler overhead time: 0.05336619075387716 Adapter cache time: 0.07372204447165132 Engine time: 0.054959279019385576 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_16-16-16/adapters_256_slots_192_rate_3.2-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_16-16-16/adapters_256_slots_192_rate_3.2-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 270, 34560, 34560, 270, 34560, 1080, 34560, 270, 1080, 270, 34560, 1080, 1080, 1080, 1080, 34560, 270, 270, 270, 1080, 34560, 270, 34560, 34560, 1080, 1080, 1080, 270, 34560, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 34560, 1080, 270, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 270, 34560, 34560, 1080, 270, 270, 34560, 1080, 270, 1080, 1080, 34560, 1080, 270, 270, 34560, 34560, 34560, 34560, 34560, 34560, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 34560, 34560, 270, 34560, 270, 1080, 34560, 34560, 34560, 1080, 270, 34560, 1080, 270, 270, 270, 270, 270, 34560, 1080, 270, 34560, 270, 34560, 270, 270, 1080, 1080, 34560, 1080, 34560, 270, 1080, 270, 34560, 34560, 270, 34560, 1080, 270, 34560, 270, 270, 34560, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 270, 1080, 34560, 34560, 270, 34560, 1080, 270, 1080, 34560, 270, 270, 270, 270, 270, 270, 34560, 270, 270, 270, 34560, 270, 1080, 34560, 34560, 1080, 270, 34560, 270, 1080, 1080, 270, 1080, 270, 34560, 270, 270, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 34560, 270, 34560, 270, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 1080, 1080, 270, 1080, 34560, 1080, 1080, 34560, 270, 34560, 34560, 1080, 270, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 270, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 34560, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 270, 270, 270, 270]
Prompts retrieved: 3086910 . Total input tokens: 688216455 . Total output tokens: 617448558
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.097689198795706,
    "estimated_duration": 3600.147981810843,
    "input_throughput": 4876.016788390542,
    "output_throughput": 4305.316636513299,
    "total_throughput": 9181.333424903842,
    "itl": 196.95939491399594,
    "ttft": 2162866.694417679,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 831,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4847317950636567,
    "arrivals": 1027687,
    "finished_requests": 71065,
    "scheduler_time": 70.98650591934617
}
#Debug simulation 
Total elapsed time: 5.097788988146931. Arrivals time: 0.31723674945533276 Scheduler time: 4.665328344330192 Scheduler overhead time: 0.028089179191738367 Adapter cache time: 0.045428707264363766 Engine time: 0.028693159110844135 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_16-16-32/adapters_256_slots_192_rate_3.2-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_16-16-32/adapters_256_slots_192_rate_3.2-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 270, 34560, 34560, 270, 34560, 1080, 34560, 270, 1080, 270, 34560, 1080, 1080, 1080, 1080, 34560, 270, 270, 270, 1080, 34560, 270, 34560, 34560, 1080, 1080, 1080, 270, 34560, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 34560, 1080, 270, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 270, 34560, 34560, 1080, 270, 270, 34560, 1080, 270, 1080, 1080, 34560, 1080, 270, 270, 34560, 34560, 34560, 34560, 34560, 34560, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 34560, 34560, 270, 34560, 270, 1080, 34560, 34560, 34560, 1080, 270, 34560, 1080, 270, 270, 270, 270, 270, 34560, 1080, 270, 34560, 270, 34560, 270, 270, 1080, 1080, 34560, 1080, 34560, 270, 1080, 270, 34560, 34560, 270, 34560, 1080, 270, 34560, 270, 270, 34560, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 270, 1080, 34560, 34560, 270, 34560, 1080, 270, 1080, 34560, 270, 270, 270, 270, 270, 270, 34560, 270, 270, 270, 34560, 270, 1080, 34560, 34560, 1080, 270, 34560, 270, 1080, 1080, 270, 1080, 270, 34560, 270, 270, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 34560, 270, 34560, 270, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 1080, 1080, 270, 1080, 34560, 1080, 1080, 34560, 270, 34560, 34560, 1080, 270, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 270, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 34560, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 270, 270, 270, 270]
Prompts retrieved: 3086910 . Total input tokens: 688216455 . Total output tokens: 617448558
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.616193221881986,
    "estimated_duration": 3600.063576777308,
    "input_throughput": 4164.470343443436,
    "output_throughput": 3691.7220256141377,
    "total_throughput": 7856.192369057573,
    "itl": 91.65376527732514,
    "ttft": 2248094.9021826684,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 733,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4628629579022623,
    "arrivals": 1027687,
    "finished_requests": 60725,
    "scheduler_time": 70.52170549235524
}
#Debug simulation 
Total elapsed time: 4.616298678796738. Arrivals time: 0.23670080164447427 Scheduler time: 4.173420746345073 Scheduler overhead time: 0.05306088924407959 Adapter cache time: 0.07306066853925586 Engine time: 0.05472154403105378 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-8/adapters_256_slots_192_rate_3.2-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-8/adapters_256_slots_192_rate_3.2-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 135, 34560, 34560, 135, 34560, 1080, 34560, 135, 1080, 135, 34560, 1080, 1080, 1080, 1080, 34560, 135, 135, 135, 1080, 34560, 135, 34560, 34560, 1080, 1080, 1080, 135, 34560, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 34560, 1080, 135, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 135, 34560, 34560, 1080, 135, 135, 34560, 1080, 135, 1080, 1080, 34560, 1080, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 34560, 34560, 135, 34560, 135, 1080, 34560, 34560, 34560, 1080, 135, 34560, 1080, 135, 135, 135, 135, 135, 34560, 1080, 135, 34560, 135, 34560, 135, 135, 1080, 1080, 34560, 1080, 34560, 135, 1080, 135, 34560, 34560, 135, 34560, 1080, 135, 34560, 135, 135, 34560, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 135, 1080, 34560, 34560, 135, 34560, 1080, 135, 1080, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 1080, 34560, 34560, 1080, 135, 34560, 135, 1080, 1080, 135, 1080, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 34560, 135, 34560, 135, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 1080, 1080, 135, 1080, 34560, 1080, 1080, 34560, 135, 34560, 34560, 1080, 135, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 135, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 34560, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 135, 135, 135, 135]
Prompts retrieved: 3075435 . Total input tokens: 685649461 . Total output tokens: 615185283
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.243322428315878,
    "estimated_duration": 3600.1771028136145,
    "input_throughput": 5022.165711200586,
    "output_throughput": 4394.244101946066,
    "total_throughput": 9416.40981314665,
    "itl": 194.43013176103776,
    "ttft": 2154877.720974875,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 469,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4353687519044753,
    "arrivals": 1023854,
    "finished_requests": 72628,
    "scheduler_time": 72.42303736901417
}
#Debug simulation 
Total elapsed time: 5.243419589009136. Arrivals time: 0.3616004018113017 Scheduler time: 4.7712663151323795 Scheduler overhead time: 0.02845187298953533 Adapter cache time: 0.039660933427512646 Engine time: 0.029228917323052883 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-16/adapters_256_slots_192_rate_3.2-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-16/adapters_256_slots_192_rate_3.2-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 135, 34560, 34560, 135, 34560, 1080, 34560, 135, 1080, 135, 34560, 1080, 1080, 1080, 1080, 34560, 135, 135, 135, 1080, 34560, 135, 34560, 34560, 1080, 1080, 1080, 135, 34560, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 34560, 1080, 135, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 135, 34560, 34560, 1080, 135, 135, 34560, 1080, 135, 1080, 1080, 34560, 1080, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 34560, 34560, 135, 34560, 135, 1080, 34560, 34560, 34560, 1080, 135, 34560, 1080, 135, 135, 135, 135, 135, 34560, 1080, 135, 34560, 135, 34560, 135, 135, 1080, 1080, 34560, 1080, 34560, 135, 1080, 135, 34560, 34560, 135, 34560, 1080, 135, 34560, 135, 135, 34560, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 135, 1080, 34560, 34560, 135, 34560, 1080, 135, 1080, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 1080, 34560, 34560, 1080, 135, 34560, 135, 1080, 1080, 135, 1080, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 34560, 135, 34560, 135, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 1080, 1080, 135, 1080, 34560, 1080, 1080, 34560, 135, 34560, 34560, 1080, 135, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 135, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 34560, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 135, 135, 135, 135]
Prompts retrieved: 3075435 . Total input tokens: 685649461 . Total output tokens: 615185283
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.262768792919815,
    "estimated_duration": 3600.1492848494086,
    "input_throughput": 5017.404715970154,
    "output_throughput": 4390.4951571087895,
    "total_throughput": 9407.899873078943,
    "itl": 192.3863926189302,
    "ttft": 2155558.6981647364,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 469,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5289981370256334,
    "arrivals": 1023854,
    "finished_requests": 72564,
    "scheduler_time": 72.44626109234969
}
#Debug simulation 
Total elapsed time: 5.262864758726209. Arrivals time: 0.3710603453218937 Scheduler time: 4.780182970222086 Scheduler overhead time: 0.028594993520528078 Adapter cache time: 0.040425100829452276 Engine time: 0.029280458576977253 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-32/adapters_256_slots_192_rate_3.2-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-32/adapters_256_slots_192_rate_3.2-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 135, 34560, 34560, 135, 34560, 1080, 34560, 135, 1080, 135, 34560, 1080, 1080, 1080, 1080, 34560, 135, 135, 135, 1080, 34560, 135, 34560, 34560, 1080, 1080, 1080, 135, 34560, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 34560, 1080, 135, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 135, 34560, 34560, 1080, 135, 135, 34560, 1080, 135, 1080, 1080, 34560, 1080, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 34560, 34560, 135, 34560, 135, 1080, 34560, 34560, 34560, 1080, 135, 34560, 1080, 135, 135, 135, 135, 135, 34560, 1080, 135, 34560, 135, 34560, 135, 135, 1080, 1080, 34560, 1080, 34560, 135, 1080, 135, 34560, 34560, 135, 34560, 1080, 135, 34560, 135, 135, 34560, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 135, 1080, 34560, 34560, 135, 34560, 1080, 135, 1080, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 1080, 34560, 34560, 1080, 135, 34560, 135, 1080, 1080, 135, 1080, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 34560, 135, 34560, 135, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 1080, 1080, 135, 1080, 34560, 1080, 1080, 34560, 135, 34560, 34560, 1080, 135, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 135, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 34560, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 135, 135, 135, 135]
Prompts retrieved: 3075435 . Total input tokens: 685649461 . Total output tokens: 615185283
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.726860452909023,
    "estimated_duration": 3600.0175775206367,
    "input_throughput": 4234.141826190186,
    "output_throughput": 3720.196002271666,
    "total_throughput": 7954.337828461853,
    "itl": 90.81867154026752,
    "ttft": 2246180.1001755293,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 412,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3466728266887444,
    "arrivals": 1023854,
    "finished_requests": 61234,
    "scheduler_time": 71.07805639938819
}
#Debug simulation 
Total elapsed time: 4.7269804938696325. Arrivals time: 0.332057764288038 Scheduler time: 4.191654562018812 Scheduler overhead time: 0.05388283496722579 Adapter cache time: 0.06837684428319335 Engine time: 0.05541393952444196 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-16/adapters_256_slots_192_rate_3.2-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-16/adapters_256_slots_192_rate_3.2-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 135, 34560, 34560, 135, 34560, 1080, 34560, 135, 1080, 135, 34560, 1080, 1080, 1080, 1080, 34560, 135, 135, 135, 1080, 34560, 135, 34560, 34560, 1080, 1080, 1080, 135, 34560, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 34560, 1080, 135, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 135, 34560, 34560, 1080, 135, 135, 34560, 1080, 135, 1080, 1080, 34560, 1080, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 34560, 34560, 135, 34560, 135, 1080, 34560, 34560, 34560, 1080, 135, 34560, 1080, 135, 135, 135, 135, 135, 34560, 1080, 135, 34560, 135, 34560, 135, 135, 1080, 1080, 34560, 1080, 34560, 135, 1080, 135, 34560, 34560, 135, 34560, 1080, 135, 34560, 135, 135, 34560, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 135, 1080, 34560, 34560, 135, 34560, 1080, 135, 1080, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 1080, 34560, 34560, 1080, 135, 34560, 135, 1080, 1080, 135, 1080, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 34560, 135, 34560, 135, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 1080, 1080, 135, 1080, 34560, 1080, 1080, 34560, 135, 34560, 34560, 1080, 135, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 135, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 34560, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 135, 135, 135, 135]
Prompts retrieved: 3075435 . Total input tokens: 685649461 . Total output tokens: 615185283
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.258345250040293,
    "estimated_duration": 3600.087102081834,
    "input_throughput": 5017.491379459796,
    "output_throughput": 4390.57099225726,
    "total_throughput": 9408.062371717055,
    "itl": 192.38370623812366,
    "ttft": 2155528.6367061823,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 469,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4668916486226906,
    "arrivals": 1023854,
    "finished_requests": 72564,
    "scheduler_time": 72.44618481316571
}
#Debug simulation 
Total elapsed time: 5.258489235304296. Arrivals time: 0.2582449410110712 Scheduler time: 4.888593312352896 Scheduler overhead time: 0.02893186593428254 Adapter cache time: 0.03982420265674591 Engine time: 0.029457513242959976 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-32/adapters_256_slots_192_rate_3.2-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-32/adapters_256_slots_192_rate_3.2-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 135, 34560, 34560, 135, 34560, 1080, 34560, 135, 1080, 135, 34560, 1080, 1080, 1080, 1080, 34560, 135, 135, 135, 1080, 34560, 135, 34560, 34560, 1080, 1080, 1080, 135, 34560, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 34560, 1080, 135, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 135, 34560, 34560, 1080, 135, 135, 34560, 1080, 135, 1080, 1080, 34560, 1080, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 34560, 34560, 135, 34560, 135, 1080, 34560, 34560, 34560, 1080, 135, 34560, 1080, 135, 135, 135, 135, 135, 34560, 1080, 135, 34560, 135, 34560, 135, 135, 1080, 1080, 34560, 1080, 34560, 135, 1080, 135, 34560, 34560, 135, 34560, 1080, 135, 34560, 135, 135, 34560, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 135, 1080, 34560, 34560, 135, 34560, 1080, 135, 1080, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 1080, 34560, 34560, 1080, 135, 34560, 135, 1080, 1080, 135, 1080, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 34560, 135, 34560, 135, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 1080, 1080, 135, 1080, 34560, 1080, 1080, 34560, 135, 34560, 34560, 1080, 135, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 135, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 34560, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 135, 135, 135, 135]
Prompts retrieved: 3075435 . Total input tokens: 685649461 . Total output tokens: 615185283
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 4.793251004070044,
    "estimated_duration": 3600.034720065853,
    "input_throughput": 4234.121664171386,
    "output_throughput": 3720.1782875457975,
    "total_throughput": 7954.299951717184,
    "itl": 90.8190962650882,
    "ttft": 2246188.460954005,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 412,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3637753416411627,
    "arrivals": 1023854,
    "finished_requests": 61234,
    "scheduler_time": 71.0780964296608
}
#Debug simulation 
Total elapsed time: 4.793376698158681. Arrivals time: 0.4010972692631185 Scheduler time: 4.189890852663666 Scheduler overhead time: 0.05368754547089338 Adapter cache time: 0.06799229187890887 Engine time: 0.05520226713269949 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-16/adapters_256_slots_192_rate_3.2-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-16/adapters_256_slots_192_rate_3.2-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 135, 34560, 34560, 135, 34560, 1080, 34560, 135, 1080, 135, 34560, 1080, 1080, 1080, 1080, 34560, 135, 135, 135, 1080, 34560, 135, 34560, 34560, 1080, 1080, 1080, 135, 34560, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 34560, 1080, 135, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 135, 34560, 34560, 1080, 135, 135, 34560, 1080, 135, 1080, 1080, 34560, 1080, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 34560, 34560, 135, 34560, 135, 1080, 34560, 34560, 34560, 1080, 135, 34560, 1080, 135, 135, 135, 135, 135, 34560, 1080, 135, 34560, 135, 34560, 135, 135, 1080, 1080, 34560, 1080, 34560, 135, 1080, 135, 34560, 34560, 135, 34560, 1080, 135, 34560, 135, 135, 34560, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 135, 1080, 34560, 34560, 135, 34560, 1080, 135, 1080, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 1080, 34560, 34560, 1080, 135, 34560, 135, 1080, 1080, 135, 1080, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 34560, 135, 34560, 135, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 1080, 1080, 135, 1080, 34560, 1080, 1080, 34560, 135, 34560, 34560, 1080, 135, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 135, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 34560, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 135, 135, 135, 135]
Prompts retrieved: 3075435 . Total input tokens: 685649461 . Total output tokens: 615185283
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.2362763080745935,
    "estimated_duration": 3600.0224758266404,
    "input_throughput": 5017.581451585872,
    "output_throughput": 4390.649810143341,
    "total_throughput": 9408.231261729214,
    "itl": 192.3807247651929,
    "ttft": 2155498.657896462,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 469,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4023335883091075,
    "arrivals": 1023854,
    "finished_requests": 72564,
    "scheduler_time": 72.44611661827132
}
#Debug simulation 
Total elapsed time: 5.23637462221086. Arrivals time: 0.36375216813758016 Scheduler time: 4.76095502031967 Scheduler overhead time: 0.02863446157425642 Adapter cache time: 0.04017490800470114 Engine time: 0.029459246899932623 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-32/adapters_256_slots_192_rate_3.2-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-32/adapters_256_slots_192_rate_3.2-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 135, 34560, 34560, 135, 34560, 1080, 34560, 135, 1080, 135, 34560, 1080, 1080, 1080, 1080, 34560, 135, 135, 135, 1080, 34560, 135, 34560, 34560, 1080, 1080, 1080, 135, 34560, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 34560, 1080, 135, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 135, 34560, 34560, 1080, 135, 135, 34560, 1080, 135, 1080, 1080, 34560, 1080, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 34560, 34560, 135, 34560, 135, 1080, 34560, 34560, 34560, 1080, 135, 34560, 1080, 135, 135, 135, 135, 135, 34560, 1080, 135, 34560, 135, 34560, 135, 135, 1080, 1080, 34560, 1080, 34560, 135, 1080, 135, 34560, 34560, 135, 34560, 1080, 135, 34560, 135, 135, 34560, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 135, 1080, 34560, 34560, 135, 34560, 1080, 135, 1080, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 1080, 34560, 34560, 1080, 135, 34560, 135, 1080, 1080, 135, 1080, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 34560, 135, 34560, 135, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 1080, 1080, 135, 1080, 34560, 1080, 1080, 34560, 135, 34560, 34560, 1080, 135, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 135, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 34560, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 135, 135, 135, 135]
Prompts retrieved: 3075435 . Total input tokens: 685649461 . Total output tokens: 615185283
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.778252302203327,
    "estimated_duration": 3600.052236117144,
    "input_throughput": 4234.101063055798,
    "output_throughput": 3720.160187021299,
    "total_throughput": 7954.2612500770965,
    "itl": 90.81955267971014,
    "ttft": 2246196.674527318,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 412,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3812551179528247,
    "arrivals": 1023854,
    "finished_requests": 61234,
    "scheduler_time": 71.07813270465051
}
#Debug simulation 
Total elapsed time: 4.778360802214593. Arrivals time: 0.2389438869431615 Scheduler time: 4.335629605222493 Scheduler overhead time: 0.054065567441284657 Adapter cache time: 0.06815319089218974 Engine time: 0.05580157553777099 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-8/adapters_256_slots_192_rate_3.2-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-8/adapters_256_slots_192_rate_3.2-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 66, 34560, 34560, 66, 34560, 1080, 34560, 66, 1080, 66, 34560, 1080, 1080, 1080, 1080, 34560, 66, 66, 66, 1080, 34560, 66, 34560, 34560, 1080, 1080, 1080, 66, 34560, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 34560, 1080, 66, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 66, 34560, 34560, 1080, 66, 66, 34560, 1080, 66, 1080, 1080, 34560, 1080, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 34560, 34560, 66, 34560, 66, 1080, 34560, 34560, 34560, 1080, 66, 34560, 1080, 66, 66, 66, 66, 66, 34560, 1080, 66, 34560, 66, 34560, 66, 66, 1080, 1080, 34560, 1080, 34560, 66, 1080, 66, 34560, 34560, 66, 34560, 1080, 66, 34560, 66, 66, 34560, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 66, 1080, 34560, 34560, 66, 34560, 1080, 66, 1080, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 1080, 34560, 34560, 1080, 66, 34560, 66, 1080, 1080, 66, 1080, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 34560, 66, 34560, 66, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 1080, 1080, 66, 1080, 34560, 1080, 1080, 34560, 66, 34560, 34560, 1080, 66, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 66, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 34560, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 66, 66, 66, 66]
Prompts retrieved: 3069570 . Total input tokens: 684327705 . Total output tokens: 614027875
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.190818265080452,
    "estimated_duration": 3600.1430233774886,
    "input_throughput": 5025.75783309452,
    "output_throughput": 4406.426327228896,
    "total_throughput": 9432.184160323415,
    "itl": 194.1386249914034,
    "ttft": 2154632.252068538,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 278,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8508155928133044,
    "arrivals": 1021838,
    "finished_requests": 73072,
    "scheduler_time": 72.55352382416199
}
#Debug simulation 
Total elapsed time: 5.19091493729502. Arrivals time: 0.31902372697368264 Scheduler time: 4.764281314332038 Scheduler overhead time: 0.028264972381293774 Adapter cache time: 0.037282660603523254 Engine time: 0.02891495916992426 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-16/adapters_256_slots_192_rate_3.2-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-16/adapters_256_slots_192_rate_3.2-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 66, 34560, 34560, 66, 34560, 1080, 34560, 66, 1080, 66, 34560, 1080, 1080, 1080, 1080, 34560, 66, 66, 66, 1080, 34560, 66, 34560, 34560, 1080, 1080, 1080, 66, 34560, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 34560, 1080, 66, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 66, 34560, 34560, 1080, 66, 66, 34560, 1080, 66, 1080, 1080, 34560, 1080, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 34560, 34560, 66, 34560, 66, 1080, 34560, 34560, 34560, 1080, 66, 34560, 1080, 66, 66, 66, 66, 66, 34560, 1080, 66, 34560, 66, 34560, 66, 66, 1080, 1080, 34560, 1080, 34560, 66, 1080, 66, 34560, 34560, 66, 34560, 1080, 66, 34560, 66, 66, 34560, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 66, 1080, 34560, 34560, 66, 34560, 1080, 66, 1080, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 1080, 34560, 34560, 1080, 66, 34560, 66, 1080, 1080, 66, 1080, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 34560, 66, 34560, 66, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 1080, 1080, 66, 1080, 34560, 1080, 1080, 34560, 66, 34560, 34560, 1080, 66, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 66, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 34560, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 66, 66, 66, 66]
Prompts retrieved: 3069570 . Total input tokens: 684327705 . Total output tokens: 614027875
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.15093263797462,
    "estimated_duration": 3600.013296446264,
    "input_throughput": 5019.579515952972,
    "output_throughput": 4402.984293321095,
    "total_throughput": 9422.563809274066,
    "itl": 192.12194497408058,
    "ttft": 2155036.264222179,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 278,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9080499018495948,
    "arrivals": 1021838,
    "finished_requests": 72985,
    "scheduler_time": 72.56573434378762
}
#Debug simulation 
Total elapsed time: 5.151025343220681. Arrivals time: 0.25654274271801114 Scheduler time: 4.785116534680128 Scheduler overhead time: 0.028798914048820734 Adapter cache time: 0.03768098447471857 Engine time: 0.029486022423952818 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-32/adapters_256_slots_192_rate_3.2-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-32/adapters_256_slots_192_rate_3.2-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 66, 34560, 34560, 66, 34560, 1080, 34560, 66, 1080, 66, 34560, 1080, 1080, 1080, 1080, 34560, 66, 66, 66, 1080, 34560, 66, 34560, 34560, 1080, 1080, 1080, 66, 34560, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 34560, 1080, 66, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 66, 34560, 34560, 1080, 66, 66, 34560, 1080, 66, 1080, 1080, 34560, 1080, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 34560, 34560, 66, 34560, 66, 1080, 34560, 34560, 34560, 1080, 66, 34560, 1080, 66, 66, 66, 66, 66, 34560, 1080, 66, 34560, 66, 34560, 66, 66, 1080, 1080, 34560, 1080, 34560, 66, 1080, 66, 34560, 34560, 66, 34560, 1080, 66, 34560, 66, 66, 34560, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 66, 1080, 34560, 34560, 66, 34560, 1080, 66, 1080, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 1080, 34560, 34560, 1080, 66, 34560, 66, 1080, 1080, 66, 1080, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 34560, 66, 34560, 66, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 1080, 1080, 66, 1080, 34560, 1080, 1080, 34560, 66, 34560, 34560, 1080, 66, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 66, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 34560, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 66, 66, 66, 66]
Prompts retrieved: 3069570 . Total input tokens: 684327705 . Total output tokens: 614027875
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.642408591229469,
    "estimated_duration": 3600.044413702992,
    "input_throughput": 4222.56429452321,
    "output_throughput": 3716.427205473862,
    "total_throughput": 7938.991499997072,
    "itl": 90.45383915285429,
    "ttft": 2241683.0521827755,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 265,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8665625489503188,
    "arrivals": 1021838,
    "finished_requests": 61270,
    "scheduler_time": 71.12741009386778
}
#Debug simulation 
Total elapsed time: 4.642531948164105. Arrivals time: 0.22529339510947466 Scheduler time: 4.215537863783538 Scheduler overhead time: 0.05446760589256883 Adapter cache time: 0.06627742759883404 Engine time: 0.055389451794326305 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-16/adapters_256_slots_192_rate_3.2-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-16/adapters_256_slots_192_rate_3.2-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 66, 34560, 34560, 66, 34560, 1080, 34560, 66, 1080, 66, 34560, 1080, 1080, 1080, 1080, 34560, 66, 66, 66, 1080, 34560, 66, 34560, 34560, 1080, 1080, 1080, 66, 34560, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 34560, 1080, 66, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 66, 34560, 34560, 1080, 66, 66, 34560, 1080, 66, 1080, 1080, 34560, 1080, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 34560, 34560, 66, 34560, 66, 1080, 34560, 34560, 34560, 1080, 66, 34560, 1080, 66, 66, 66, 66, 66, 34560, 1080, 66, 34560, 66, 34560, 66, 66, 1080, 1080, 34560, 1080, 34560, 66, 1080, 66, 34560, 34560, 66, 34560, 1080, 66, 34560, 66, 66, 34560, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 66, 1080, 34560, 34560, 66, 34560, 1080, 66, 1080, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 1080, 34560, 34560, 1080, 66, 34560, 66, 1080, 1080, 66, 1080, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 34560, 66, 34560, 66, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 1080, 1080, 66, 1080, 34560, 1080, 1080, 34560, 66, 34560, 34560, 1080, 66, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 66, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 34560, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 66, 66, 66, 66]
Prompts retrieved: 3069570 . Total input tokens: 684327705 . Total output tokens: 614027875
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.125595813151449,
    "estimated_duration": 3600.1826589737248,
    "input_throughput": 5020.148618001525,
    "output_throughput": 4403.646565121602,
    "total_throughput": 9423.795183123128,
    "itl": 192.11867594396793,
    "ttft": 2155068.845983235,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 278,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8708677278715214,
    "arrivals": 1021838,
    "finished_requests": 72995,
    "scheduler_time": 72.56990889511953
}
#Debug simulation 
Total elapsed time: 5.125687914900482. Arrivals time: 0.2529904986731708 Scheduler time: 4.763535659760237 Scheduler overhead time: 0.028725516516715288 Adapter cache time: 0.03757084580138326 Engine time: 0.02947968617081642 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-32/adapters_256_slots_192_rate_3.2-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-32/adapters_256_slots_192_rate_3.2-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 66, 34560, 34560, 66, 34560, 1080, 34560, 66, 1080, 66, 34560, 1080, 1080, 1080, 1080, 34560, 66, 66, 66, 1080, 34560, 66, 34560, 34560, 1080, 1080, 1080, 66, 34560, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 34560, 1080, 66, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 66, 34560, 34560, 1080, 66, 66, 34560, 1080, 66, 1080, 1080, 34560, 1080, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 34560, 34560, 66, 34560, 66, 1080, 34560, 34560, 34560, 1080, 66, 34560, 1080, 66, 66, 66, 66, 66, 34560, 1080, 66, 34560, 66, 34560, 66, 66, 1080, 1080, 34560, 1080, 34560, 66, 1080, 66, 34560, 34560, 66, 34560, 1080, 66, 34560, 66, 66, 34560, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 66, 1080, 34560, 34560, 66, 34560, 1080, 66, 1080, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 1080, 34560, 34560, 1080, 66, 34560, 66, 1080, 1080, 66, 1080, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 34560, 66, 34560, 66, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 1080, 1080, 66, 1080, 34560, 1080, 1080, 34560, 66, 34560, 34560, 1080, 66, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 66, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 34560, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 66, 66, 66, 66]
Prompts retrieved: 3069570 . Total input tokens: 684327705 . Total output tokens: 614027875
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 4.6456343568861485,
    "estimated_duration": 3600.05538781917,
    "input_throughput": 4222.551422801488,
    "output_throughput": 3716.415876619296,
    "total_throughput": 7938.967299420784,
    "itl": 90.45407747407315,
    "ttft": 2241689.3824612745,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 265,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8775031283684116,
    "arrivals": 1021838,
    "finished_requests": 61270,
    "scheduler_time": 71.12744363063037
}
#Debug simulation 
Total elapsed time: 4.6457469197921455. Arrivals time: 0.23814510740339756 Scheduler time: 4.2064981809817255 Scheduler overhead time: 0.053783433977514505 Adapter cache time: 0.06636873865500093 Engine time: 0.05532043753191829 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-16/adapters_256_slots_192_rate_3.2-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-16/adapters_256_slots_192_rate_3.2-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 66, 34560, 34560, 66, 34560, 1080, 34560, 66, 1080, 66, 34560, 1080, 1080, 1080, 1080, 34560, 66, 66, 66, 1080, 34560, 66, 34560, 34560, 1080, 1080, 1080, 66, 34560, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 34560, 1080, 66, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 66, 34560, 34560, 1080, 66, 66, 34560, 1080, 66, 1080, 1080, 34560, 1080, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 34560, 34560, 66, 34560, 66, 1080, 34560, 34560, 34560, 1080, 66, 34560, 1080, 66, 66, 66, 66, 66, 34560, 1080, 66, 34560, 66, 34560, 66, 66, 1080, 1080, 34560, 1080, 34560, 66, 1080, 66, 34560, 34560, 66, 34560, 1080, 66, 34560, 66, 66, 34560, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 66, 1080, 34560, 34560, 66, 34560, 1080, 66, 1080, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 1080, 34560, 34560, 1080, 66, 34560, 66, 1080, 1080, 66, 1080, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 34560, 66, 34560, 66, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 1080, 1080, 66, 1080, 34560, 1080, 1080, 34560, 66, 34560, 34560, 1080, 66, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 66, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 34560, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 66, 66, 66, 66]
Prompts retrieved: 3069570 . Total input tokens: 684327705 . Total output tokens: 614027875
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.473579523153603,
    "estimated_duration": 3600.1429533298206,
    "input_throughput": 5020.203984756667,
    "output_throughput": 4403.695132532581,
    "total_throughput": 9423.899117289247,
    "itl": 192.11702714450686,
    "ttft": 2155046.138745788,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 278,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.831233981982806,
    "arrivals": 1021838,
    "finished_requests": 72995,
    "scheduler_time": 72.56983699709895
}
#Debug simulation 
Total elapsed time: 5.473650512285531. Arrivals time: 0.6122384695336223 Scheduler time: 4.752751587890089 Scheduler overhead time: 0.02850350085645914 Adapter cache time: 0.03776279091835022 Engine time: 0.029121468774974346 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-32/adapters_256_slots_192_rate_3.2-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-32/adapters_256_slots_192_rate_3.2-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 66, 34560, 34560, 66, 34560, 1080, 34560, 66, 1080, 66, 34560, 1080, 1080, 1080, 1080, 34560, 66, 66, 66, 1080, 34560, 66, 34560, 34560, 1080, 1080, 1080, 66, 34560, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 34560, 1080, 66, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 66, 34560, 34560, 1080, 66, 66, 34560, 1080, 66, 1080, 1080, 34560, 1080, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 34560, 34560, 66, 34560, 66, 1080, 34560, 34560, 34560, 1080, 66, 34560, 1080, 66, 66, 66, 66, 66, 34560, 1080, 66, 34560, 66, 34560, 66, 66, 1080, 1080, 34560, 1080, 34560, 66, 1080, 66, 34560, 34560, 66, 34560, 1080, 66, 34560, 66, 66, 34560, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 66, 1080, 34560, 34560, 66, 34560, 1080, 66, 1080, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 1080, 34560, 34560, 1080, 66, 34560, 66, 1080, 1080, 66, 1080, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 34560, 66, 34560, 66, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 1080, 1080, 66, 1080, 34560, 1080, 1080, 34560, 66, 34560, 34560, 1080, 66, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 66, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 34560, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 66, 66, 66, 66]
Prompts retrieved: 3069570 . Total input tokens: 684327705 . Total output tokens: 614027875
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.615684610791504,
    "estimated_duration": 3600.0668663587226,
    "input_throughput": 4222.537959517244,
    "output_throughput": 3716.4040271097683,
    "total_throughput": 7938.941986627013,
    "itl": 90.45436060893414,
    "ttft": 2241695.790668488,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 265,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.888946722932164,
    "arrivals": 1021838,
    "finished_requests": 61270,
    "scheduler_time": 71.12747857562405
}
#Debug simulation 
Total elapsed time: 4.615770924836397. Arrivals time: 0.2259629056788981 Scheduler time: 4.188277232460678 Scheduler overhead time: 0.053984607104212046 Adapter cache time: 0.06610416853800416 Engine time: 0.05560226645320654 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-8/adapters_256_slots_192_rate_3.2-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-8/adapters_256_slots_192_rate_3.2-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 33, 34560, 34560, 33, 34560, 1080, 34560, 33, 1080, 33, 34560, 1080, 1080, 1080, 1080, 34560, 33, 33, 33, 1080, 34560, 33, 34560, 34560, 1080, 1080, 1080, 33, 34560, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 34560, 1080, 33, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 33, 34560, 34560, 1080, 33, 33, 34560, 1080, 33, 1080, 1080, 34560, 1080, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 34560, 34560, 33, 34560, 33, 1080, 34560, 34560, 34560, 1080, 33, 34560, 1080, 33, 33, 33, 33, 33, 34560, 1080, 33, 34560, 33, 34560, 33, 33, 1080, 1080, 34560, 1080, 34560, 33, 1080, 33, 34560, 34560, 33, 34560, 1080, 33, 34560, 33, 33, 34560, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 33, 1080, 34560, 34560, 33, 34560, 1080, 33, 1080, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 1080, 34560, 34560, 1080, 33, 34560, 33, 1080, 1080, 33, 1080, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 34560, 33, 34560, 33, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 1080, 1080, 33, 1080, 34560, 1080, 1080, 34560, 33, 34560, 34560, 1080, 33, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 33, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 34560, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 33, 33, 33, 33]
Prompts retrieved: 3066765 . Total input tokens: 683706646 . Total output tokens: 613459381
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.178400888107717,
    "estimated_duration": 3600.216437597027,
    "input_throughput": 4995.5710473907575,
    "output_throughput": 4421.258353740578,
    "total_throughput": 9416.829401131336,
    "itl": 194.33641536902218,
    "ttft": 2155648.2277003783,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 226,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6916702301288015,
    "arrivals": 1020948,
    "finished_requests": 73098,
    "scheduler_time": 72.8014188520628
}
#Debug simulation 
Total elapsed time: 5.1785282818600535. Arrivals time: 0.2562675033695996 Scheduler time: 4.8142447345890105 Scheduler overhead time: 0.028491192497313023 Adapter cache time: 0.03692557569593191 Engine time: 0.02932400582358241 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-16/adapters_256_slots_192_rate_3.2-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-16/adapters_256_slots_192_rate_3.2-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 33, 34560, 34560, 33, 34560, 1080, 34560, 33, 1080, 33, 34560, 1080, 1080, 1080, 1080, 34560, 33, 33, 33, 1080, 34560, 33, 34560, 34560, 1080, 1080, 1080, 33, 34560, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 34560, 1080, 33, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 33, 34560, 34560, 1080, 33, 33, 34560, 1080, 33, 1080, 1080, 34560, 1080, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 34560, 34560, 33, 34560, 33, 1080, 34560, 34560, 34560, 1080, 33, 34560, 1080, 33, 33, 33, 33, 33, 34560, 1080, 33, 34560, 33, 34560, 33, 33, 1080, 1080, 34560, 1080, 34560, 33, 1080, 33, 34560, 34560, 33, 34560, 1080, 33, 34560, 33, 33, 34560, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 33, 1080, 34560, 34560, 33, 34560, 1080, 33, 1080, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 1080, 34560, 34560, 1080, 33, 34560, 33, 1080, 1080, 33, 1080, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 34560, 33, 34560, 33, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 1080, 1080, 33, 1080, 34560, 1080, 1080, 34560, 33, 34560, 34560, 1080, 33, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 33, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 34560, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 33, 33, 33, 33]
Prompts retrieved: 3066765 . Total input tokens: 683706646 . Total output tokens: 613459381
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.1553452387452126,
    "estimated_duration": 3600.206708439981,
    "input_throughput": 4991.155079477728,
    "output_throughput": 4418.456296608834,
    "total_throughput": 9409.611376086561,
    "itl": 192.3901220588071,
    "ttft": 2156014.408722751,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 226,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7394922363245887,
    "arrivals": 1020948,
    "finished_requests": 73031,
    "scheduler_time": 72.82235202138209
}
#Debug simulation 
Total elapsed time: 5.155441005714238. Arrivals time: 0.25602103024721146 Scheduler time: 4.790764358825982 Scheduler overhead time: 0.028573367279022932 Adapter cache time: 0.03727153828367591 Engine time: 0.02943624835461378 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-32/adapters_256_slots_192_rate_3.2-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-32/adapters_256_slots_192_rate_3.2-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 33, 34560, 34560, 33, 34560, 1080, 34560, 33, 1080, 33, 34560, 1080, 1080, 1080, 1080, 34560, 33, 33, 33, 1080, 34560, 33, 34560, 34560, 1080, 1080, 1080, 33, 34560, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 34560, 1080, 33, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 33, 34560, 34560, 1080, 33, 33, 34560, 1080, 33, 1080, 1080, 34560, 1080, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 34560, 34560, 33, 34560, 33, 1080, 34560, 34560, 34560, 1080, 33, 34560, 1080, 33, 33, 33, 33, 33, 34560, 1080, 33, 34560, 33, 34560, 33, 33, 1080, 1080, 34560, 1080, 34560, 33, 1080, 33, 34560, 34560, 33, 34560, 1080, 33, 34560, 33, 33, 34560, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 33, 1080, 34560, 34560, 33, 34560, 1080, 33, 1080, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 1080, 34560, 34560, 1080, 33, 34560, 33, 1080, 1080, 33, 1080, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 34560, 33, 34560, 33, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 1080, 1080, 33, 1080, 34560, 1080, 1080, 34560, 33, 34560, 34560, 1080, 33, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 33, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 34560, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 33, 33, 33, 33]
Prompts retrieved: 3066765 . Total input tokens: 683706646 . Total output tokens: 613459381
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.5673530558124185,
    "estimated_duration": 3600.015620850597,
    "input_throughput": 4073.877600712958,
    "output_throughput": 3638.22449106633,
    "total_throughput": 7712.102091779288,
    "itl": 87.38187894957294,
    "ttft": 2258494.4778975868,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 221,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.72354203725234,
    "arrivals": 1020948,
    "finished_requests": 59775,
    "scheduler_time": 70.54304225737785
}
#Debug simulation 
Total elapsed time: 4.567460572812706. Arrivals time: 0.2362602953799069 Scheduler time: 4.134023992344737 Scheduler overhead time: 0.0551031744107604 Adapter cache time: 0.05845491215586662 Engine time: 0.057155828922986984 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-16/adapters_256_slots_192_rate_3.2-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-16/adapters_256_slots_192_rate_3.2-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 33, 34560, 34560, 33, 34560, 1080, 34560, 33, 1080, 33, 34560, 1080, 1080, 1080, 1080, 34560, 33, 33, 33, 1080, 34560, 33, 34560, 34560, 1080, 1080, 1080, 33, 34560, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 34560, 1080, 33, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 33, 34560, 34560, 1080, 33, 33, 34560, 1080, 33, 1080, 1080, 34560, 1080, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 34560, 34560, 33, 34560, 33, 1080, 34560, 34560, 34560, 1080, 33, 34560, 1080, 33, 33, 33, 33, 33, 34560, 1080, 33, 34560, 33, 34560, 33, 33, 1080, 1080, 34560, 1080, 34560, 33, 1080, 33, 34560, 34560, 33, 34560, 1080, 33, 34560, 33, 33, 34560, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 33, 1080, 34560, 34560, 33, 34560, 1080, 33, 1080, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 1080, 34560, 34560, 1080, 33, 34560, 33, 1080, 1080, 33, 1080, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 34560, 33, 34560, 33, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 1080, 1080, 33, 1080, 34560, 1080, 1080, 34560, 33, 34560, 34560, 1080, 33, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 33, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 34560, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 33, 33, 33, 33]
Prompts retrieved: 3066765 . Total input tokens: 683706646 . Total output tokens: 613459381
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.230741409119219,
    "estimated_duration": 3600.1772187221677,
    "input_throughput": 4991.195962952599,
    "output_throughput": 4418.4924890019975,
    "total_throughput": 9409.688451954597,
    "itl": 192.38912862075009,
    "ttft": 2155994.852052719,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 226,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7100733733968827,
    "arrivals": 1020948,
    "finished_requests": 73031,
    "scheduler_time": 72.82228116649564
}
#Debug simulation 
Total elapsed time: 5.230835946276784. Arrivals time: 0.32301002088934183 Scheduler time: 4.799393513705581 Scheduler overhead time: 0.028511150274425745 Adapter cache time: 0.03701982460916042 Engine time: 0.029476383235305548 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-32/adapters_256_slots_192_rate_3.2-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-32/adapters_256_slots_192_rate_3.2-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 33, 34560, 34560, 33, 34560, 1080, 34560, 33, 1080, 33, 34560, 1080, 1080, 1080, 1080, 34560, 33, 33, 33, 1080, 34560, 33, 34560, 34560, 1080, 1080, 1080, 33, 34560, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 34560, 1080, 33, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 33, 34560, 34560, 1080, 33, 33, 34560, 1080, 33, 1080, 1080, 34560, 1080, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 34560, 34560, 33, 34560, 33, 1080, 34560, 34560, 34560, 1080, 33, 34560, 1080, 33, 33, 33, 33, 33, 34560, 1080, 33, 34560, 33, 34560, 33, 33, 1080, 1080, 34560, 1080, 34560, 33, 1080, 33, 34560, 34560, 33, 34560, 1080, 33, 34560, 33, 33, 34560, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 33, 1080, 34560, 34560, 33, 34560, 1080, 33, 1080, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 1080, 34560, 34560, 1080, 33, 34560, 33, 1080, 1080, 33, 1080, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 34560, 33, 34560, 33, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 1080, 1080, 33, 1080, 34560, 1080, 1080, 34560, 33, 34560, 34560, 1080, 33, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 33, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 34560, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 33, 33, 33, 33]
Prompts retrieved: 3066765 . Total input tokens: 683706646 . Total output tokens: 613459381
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 4.88546854397282,
    "estimated_duration": 3600.0244591604405,
    "input_throughput": 4073.8675990607726,
    "output_throughput": 3638.215558972757,
    "total_throughput": 7712.08315803353,
    "itl": 87.38207040581284,
    "ttft": 2258500.094746655,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 221,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7323448023013799,
    "arrivals": 1020948,
    "finished_requests": 59775,
    "scheduler_time": 70.54307780217366
}
#Debug simulation 
Total elapsed time: 4.885533930268139. Arrivals time: 0.5829954058863223 Scheduler time: 4.1053396933712065 Scheduler overhead time: 0.055479361675679684 Adapter cache time: 0.058379077818244696 Engine time: 0.05700579518452287 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-16/adapters_256_slots_192_rate_3.2-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-16/adapters_256_slots_192_rate_3.2-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 33, 34560, 34560, 33, 34560, 1080, 34560, 33, 1080, 33, 34560, 1080, 1080, 1080, 1080, 34560, 33, 33, 33, 1080, 34560, 33, 34560, 34560, 1080, 1080, 1080, 33, 34560, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 34560, 1080, 33, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 33, 34560, 34560, 1080, 33, 33, 34560, 1080, 33, 1080, 1080, 34560, 1080, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 34560, 34560, 33, 34560, 33, 1080, 34560, 34560, 34560, 1080, 33, 34560, 1080, 33, 33, 33, 33, 33, 34560, 1080, 33, 34560, 33, 34560, 33, 33, 1080, 1080, 34560, 1080, 34560, 33, 1080, 33, 34560, 34560, 33, 34560, 1080, 33, 34560, 33, 33, 34560, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 33, 1080, 34560, 34560, 33, 34560, 1080, 33, 1080, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 1080, 34560, 34560, 1080, 33, 34560, 33, 1080, 1080, 33, 1080, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 34560, 33, 34560, 33, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 1080, 1080, 33, 1080, 34560, 1080, 1080, 34560, 33, 34560, 34560, 1080, 33, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 33, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 34560, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 33, 33, 33, 33]
Prompts retrieved: 3066765 . Total input tokens: 683706646 . Total output tokens: 613459381
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.2114885351620615,
    "estimated_duration": 3600.142830632873,
    "input_throughput": 4991.2436381978705,
    "output_throughput": 4418.534693859251,
    "total_throughput": 9409.778332057122,
    "itl": 192.38778463652847,
    "ttft": 2155972.7996238414,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 226,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6757513666478926,
    "arrivals": 1020948,
    "finished_requests": 73031,
    "scheduler_time": 72.82221508394788
}
#Debug simulation 
Total elapsed time: 5.211623219773173. Arrivals time: 0.25126655539497733 Scheduler time: 4.851104695815593 Scheduler overhead time: 0.02874311851337552 Adapter cache time: 0.037735330406576395 Engine time: 0.029349859338253736 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-32/adapters_256_slots_192_rate_3.2-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-32/adapters_256_slots_192_rate_3.2-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 33, 34560, 34560, 33, 34560, 1080, 34560, 33, 1080, 33, 34560, 1080, 1080, 1080, 1080, 34560, 33, 33, 33, 1080, 34560, 33, 34560, 34560, 1080, 1080, 1080, 33, 34560, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 34560, 1080, 33, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 33, 34560, 34560, 1080, 33, 33, 34560, 1080, 33, 1080, 1080, 34560, 1080, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 34560, 34560, 33, 34560, 33, 1080, 34560, 34560, 34560, 1080, 33, 34560, 1080, 33, 33, 33, 33, 33, 34560, 1080, 33, 34560, 33, 34560, 33, 33, 1080, 1080, 34560, 1080, 34560, 33, 1080, 33, 34560, 34560, 33, 34560, 1080, 33, 34560, 33, 33, 34560, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 33, 1080, 34560, 34560, 33, 34560, 1080, 33, 1080, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 1080, 34560, 34560, 1080, 33, 34560, 33, 1080, 1080, 33, 1080, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 34560, 33, 34560, 33, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 1080, 1080, 33, 1080, 34560, 1080, 1080, 34560, 33, 34560, 34560, 1080, 33, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 33, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 34560, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 33, 33, 33, 33]
Prompts retrieved: 3066765 . Total input tokens: 683706646 . Total output tokens: 613459381
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.536712462082505,
    "estimated_duration": 3600.0346794840952,
    "input_throughput": 4073.8560335484663,
    "output_throughput": 3638.2052302554393,
    "total_throughput": 7712.061263803906,
    "itl": 87.38233099306379,
    "ttft": 2258506.4122286625,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 221,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7425308590009833,
    "arrivals": 1020948,
    "finished_requests": 59775,
    "scheduler_time": 70.54311206913015
}
#Debug simulation 
Total elapsed time: 4.536809333134443. Arrivals time: 0.22737279161810875 Scheduler time: 4.1125769931823015 Scheduler overhead time: 0.05493781249970198 Adapter cache time: 0.05877758236601949 Engine time: 0.05674215778708458 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-8/adapters_256_slots_192_rate_3.2-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-8/adapters_256_slots_192_rate_3.2-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 270, 34560, 34560, 270, 34560, 540, 34560, 270, 540, 270, 34560, 540, 540, 540, 540, 34560, 270, 270, 270, 540, 34560, 270, 34560, 34560, 540, 540, 540, 270, 34560, 270, 540, 540, 270, 540, 270, 270, 540, 540, 34560, 540, 270, 540, 34560, 540, 540, 34560, 540, 34560, 270, 34560, 34560, 540, 270, 270, 34560, 540, 270, 540, 540, 34560, 540, 270, 270, 34560, 34560, 34560, 34560, 34560, 34560, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 34560, 34560, 270, 34560, 270, 540, 34560, 34560, 34560, 540, 270, 34560, 540, 270, 270, 270, 270, 270, 34560, 540, 270, 34560, 270, 34560, 270, 270, 540, 540, 34560, 540, 34560, 270, 540, 270, 34560, 34560, 270, 34560, 540, 270, 34560, 270, 270, 34560, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 270, 540, 34560, 34560, 270, 34560, 540, 270, 540, 34560, 270, 270, 270, 270, 270, 270, 34560, 270, 270, 270, 34560, 270, 540, 34560, 34560, 540, 270, 34560, 270, 540, 540, 270, 540, 270, 34560, 270, 270, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 540, 34560, 540, 34560, 270, 34560, 270, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 540, 540, 270, 540, 34560, 540, 540, 34560, 270, 34560, 34560, 540, 270, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 270, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 34560, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 34560, 540, 270, 270, 270, 270]
Prompts retrieved: 3041010 . Total input tokens: 677979927 . Total output tokens: 608266809
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.311449544969946,
    "estimated_duration": 3600.01909846776,
    "input_throughput": 5153.824324958969,
    "output_throughput": 4547.299209320182,
    "total_throughput": 9701.123534279151,
    "itl": 188.48780187674438,
    "ttft": 2142037.603912698,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 670,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.05052678843498,
    "arrivals": 1012432,
    "finished_requests": 75087,
    "scheduler_time": 74.89939839210135
}
#Debug simulation 
Total elapsed time: 5.311574070714414. Arrivals time: 0.2642643582075834 Scheduler time: 4.940866037271917 Scheduler overhead time: 0.02927715750411153 Adapter cache time: 0.0336438175290823 Engine time: 0.029891072306782007 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-16/adapters_256_slots_192_rate_3.2-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-16/adapters_256_slots_192_rate_3.2-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 270, 34560, 34560, 270, 34560, 540, 34560, 270, 540, 270, 34560, 540, 540, 540, 540, 34560, 270, 270, 270, 540, 34560, 270, 34560, 34560, 540, 540, 540, 270, 34560, 270, 540, 540, 270, 540, 270, 270, 540, 540, 34560, 540, 270, 540, 34560, 540, 540, 34560, 540, 34560, 270, 34560, 34560, 540, 270, 270, 34560, 540, 270, 540, 540, 34560, 540, 270, 270, 34560, 34560, 34560, 34560, 34560, 34560, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 34560, 34560, 270, 34560, 270, 540, 34560, 34560, 34560, 540, 270, 34560, 540, 270, 270, 270, 270, 270, 34560, 540, 270, 34560, 270, 34560, 270, 270, 540, 540, 34560, 540, 34560, 270, 540, 270, 34560, 34560, 270, 34560, 540, 270, 34560, 270, 270, 34560, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 270, 540, 34560, 34560, 270, 34560, 540, 270, 540, 34560, 270, 270, 270, 270, 270, 270, 34560, 270, 270, 270, 34560, 270, 540, 34560, 34560, 540, 270, 34560, 270, 540, 540, 270, 540, 270, 34560, 270, 270, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 540, 34560, 540, 34560, 270, 34560, 270, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 540, 540, 270, 540, 34560, 540, 540, 34560, 270, 34560, 34560, 540, 270, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 270, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 34560, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 34560, 540, 270, 270, 270, 270]
Prompts retrieved: 3041010 . Total input tokens: 677979927 . Total output tokens: 608266809
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.307597685139626,
    "estimated_duration": 3600.1441195614734,
    "input_throughput": 5147.166997930397,
    "output_throughput": 4542.526481409866,
    "total_throughput": 9689.693479340263,
    "itl": 186.39898804870626,
    "ttft": 2142269.4727823436,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 669,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.182168563995515,
    "arrivals": 1012432,
    "finished_requests": 74993,
    "scheduler_time": 74.911534526734
}
#Debug simulation 
Total elapsed time: 5.3076911070384085. Arrivals time: 0.26197918970137835 Scheduler time: 4.937955565284938 Scheduler overhead time: 0.02953068818897009 Adapter cache time: 0.033928779885172844 Engine time: 0.030513079836964607 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-32/adapters_256_slots_192_rate_3.2-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-32/adapters_256_slots_192_rate_3.2-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 270, 34560, 34560, 270, 34560, 540, 34560, 270, 540, 270, 34560, 540, 540, 540, 540, 34560, 270, 270, 270, 540, 34560, 270, 34560, 34560, 540, 540, 540, 270, 34560, 270, 540, 540, 270, 540, 270, 270, 540, 540, 34560, 540, 270, 540, 34560, 540, 540, 34560, 540, 34560, 270, 34560, 34560, 540, 270, 270, 34560, 540, 270, 540, 540, 34560, 540, 270, 270, 34560, 34560, 34560, 34560, 34560, 34560, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 34560, 34560, 270, 34560, 270, 540, 34560, 34560, 34560, 540, 270, 34560, 540, 270, 270, 270, 270, 270, 34560, 540, 270, 34560, 270, 34560, 270, 270, 540, 540, 34560, 540, 34560, 270, 540, 270, 34560, 34560, 270, 34560, 540, 270, 34560, 270, 270, 34560, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 270, 540, 34560, 34560, 270, 34560, 540, 270, 540, 34560, 270, 270, 270, 270, 270, 270, 34560, 270, 270, 270, 34560, 270, 540, 34560, 34560, 540, 270, 34560, 270, 540, 540, 270, 540, 270, 34560, 270, 270, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 540, 34560, 540, 34560, 270, 34560, 270, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 540, 540, 270, 540, 34560, 540, 540, 34560, 270, 34560, 34560, 540, 270, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 270, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 34560, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 34560, 540, 270, 270, 270, 270]
Prompts retrieved: 3041010 . Total input tokens: 677979927 . Total output tokens: 608266809
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.675758698955178,
    "estimated_duration": 3600.0937943094677,
    "input_throughput": 4258.380163381424,
    "output_throughput": 3777.640744109719,
    "total_throughput": 8036.020907491143,
    "itl": 89.35735237237778,
    "ttft": 2236149.8022706187,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 575,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8805381184257683,
    "arrivals": 1012432,
    "finished_requests": 62085,
    "scheduler_time": 72.20092305631945
}
#Debug simulation 
Total elapsed time: 4.675849303137511. Arrivals time: 0.23046058602631092 Scheduler time: 4.252127643674612 Scheduler overhead time: 0.0543620940297842 Adapter cache time: 0.05715040769428015 Engine time: 0.05586093058809638 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-16-16/adapters_256_slots_192_rate_3.2-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-16-16/adapters_256_slots_192_rate_3.2-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 270, 34560, 34560, 270, 34560, 540, 34560, 270, 540, 270, 34560, 540, 540, 540, 540, 34560, 270, 270, 270, 540, 34560, 270, 34560, 34560, 540, 540, 540, 270, 34560, 270, 540, 540, 270, 540, 270, 270, 540, 540, 34560, 540, 270, 540, 34560, 540, 540, 34560, 540, 34560, 270, 34560, 34560, 540, 270, 270, 34560, 540, 270, 540, 540, 34560, 540, 270, 270, 34560, 34560, 34560, 34560, 34560, 34560, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 34560, 34560, 270, 34560, 270, 540, 34560, 34560, 34560, 540, 270, 34560, 540, 270, 270, 270, 270, 270, 34560, 540, 270, 34560, 270, 34560, 270, 270, 540, 540, 34560, 540, 34560, 270, 540, 270, 34560, 34560, 270, 34560, 540, 270, 34560, 270, 270, 34560, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 270, 540, 34560, 34560, 270, 34560, 540, 270, 540, 34560, 270, 270, 270, 270, 270, 270, 34560, 270, 270, 270, 34560, 270, 540, 34560, 34560, 540, 270, 34560, 270, 540, 540, 270, 540, 270, 34560, 270, 270, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 540, 34560, 540, 34560, 270, 34560, 270, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 540, 540, 270, 540, 34560, 540, 540, 34560, 270, 34560, 34560, 540, 270, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 270, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 34560, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 34560, 540, 270, 270, 270, 270]
Prompts retrieved: 3041010 . Total input tokens: 677979927 . Total output tokens: 608266809
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.325118537060916,
    "estimated_duration": 3600.0570130271267,
    "input_throughput": 5147.291538146641,
    "output_throughput": 4542.636391818935,
    "total_throughput": 9689.927929965575,
    "itl": 186.39493345055598,
    "ttft": 2142229.334275803,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 669,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.095137761167702,
    "arrivals": 1012432,
    "finished_requests": 74993,
    "scheduler_time": 74.91145879519546
}
#Debug simulation 
Total elapsed time: 5.325220840983093. Arrivals time: 0.26233645575121045 Scheduler time: 4.952565701678395 Scheduler overhead time: 0.031924169044941664 Adapter cache time: 0.03436582302674651 Engine time: 0.030279779341071844 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-16-32/adapters_256_slots_192_rate_3.2-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-16-32/adapters_256_slots_192_rate_3.2-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 270, 34560, 34560, 270, 34560, 540, 34560, 270, 540, 270, 34560, 540, 540, 540, 540, 34560, 270, 270, 270, 540, 34560, 270, 34560, 34560, 540, 540, 540, 270, 34560, 270, 540, 540, 270, 540, 270, 270, 540, 540, 34560, 540, 270, 540, 34560, 540, 540, 34560, 540, 34560, 270, 34560, 34560, 540, 270, 270, 34560, 540, 270, 540, 540, 34560, 540, 270, 270, 34560, 34560, 34560, 34560, 34560, 34560, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 34560, 34560, 270, 34560, 270, 540, 34560, 34560, 34560, 540, 270, 34560, 540, 270, 270, 270, 270, 270, 34560, 540, 270, 34560, 270, 34560, 270, 270, 540, 540, 34560, 540, 34560, 270, 540, 270, 34560, 34560, 270, 34560, 540, 270, 34560, 270, 270, 34560, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 270, 540, 34560, 34560, 270, 34560, 540, 270, 540, 34560, 270, 270, 270, 270, 270, 270, 34560, 270, 270, 270, 34560, 270, 540, 34560, 34560, 540, 270, 34560, 270, 540, 540, 270, 540, 270, 34560, 270, 270, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 540, 34560, 540, 34560, 270, 34560, 270, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 540, 540, 270, 540, 34560, 540, 540, 34560, 270, 34560, 34560, 540, 270, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 270, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 34560, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 34560, 540, 270, 270, 270, 270]
Prompts retrieved: 3041010 . Total input tokens: 677979927 . Total output tokens: 608266809
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 4.722845604177564,
    "estimated_duration": 3600.021344699376,
    "input_throughput": 4258.3308631133,
    "output_throughput": 3777.635935415724,
    "total_throughput": 8035.966798529024,
    "itl": 89.35847607035657,
    "ttft": 2236134.7024578294,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 575,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9041798302717547,
    "arrivals": 1012432,
    "finished_requests": 62083,
    "scheduler_time": 72.19900967563878
}
#Debug simulation 
Total elapsed time: 4.722934966906905. Arrivals time: 0.2925679897889495 Scheduler time: 4.237742296885699 Scheduler overhead time: 0.05413683736696839 Adapter cache time: 0.05683952150866389 Engine time: 0.05573596805334091 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_16-16-16/adapters_256_slots_192_rate_3.2-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_16-16-16/adapters_256_slots_192_rate_3.2-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 270, 34560, 34560, 270, 34560, 540, 34560, 270, 540, 270, 34560, 540, 540, 540, 540, 34560, 270, 270, 270, 540, 34560, 270, 34560, 34560, 540, 540, 540, 270, 34560, 270, 540, 540, 270, 540, 270, 270, 540, 540, 34560, 540, 270, 540, 34560, 540, 540, 34560, 540, 34560, 270, 34560, 34560, 540, 270, 270, 34560, 540, 270, 540, 540, 34560, 540, 270, 270, 34560, 34560, 34560, 34560, 34560, 34560, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 34560, 34560, 270, 34560, 270, 540, 34560, 34560, 34560, 540, 270, 34560, 540, 270, 270, 270, 270, 270, 34560, 540, 270, 34560, 270, 34560, 270, 270, 540, 540, 34560, 540, 34560, 270, 540, 270, 34560, 34560, 270, 34560, 540, 270, 34560, 270, 270, 34560, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 270, 540, 34560, 34560, 270, 34560, 540, 270, 540, 34560, 270, 270, 270, 270, 270, 270, 34560, 270, 270, 270, 34560, 270, 540, 34560, 34560, 540, 270, 34560, 270, 540, 540, 270, 540, 270, 34560, 270, 270, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 540, 34560, 540, 34560, 270, 34560, 270, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 540, 540, 270, 540, 34560, 540, 540, 34560, 270, 34560, 34560, 540, 270, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 270, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 34560, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 34560, 540, 270, 270, 270, 270]
Prompts retrieved: 3041010 . Total input tokens: 677979927 . Total output tokens: 608266809
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.28616170398891,
    "estimated_duration": 3600.1758541615795,
    "input_throughput": 5147.462999225003,
    "output_throughput": 4542.713929125194,
    "total_throughput": 9690.176928350196,
    "itl": 186.39048149497216,
    "ttft": 2142319.0638969587,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 669,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0003436472895215,
    "arrivals": 1012432,
    "finished_requests": 74997,
    "scheduler_time": 74.9157734778361
}
#Debug simulation 
Total elapsed time: 5.286290461663157. Arrivals time: 0.2646324667148292 Scheduler time: 4.914106675423682 Scheduler overhead time: 0.02959327958524227 Adapter cache time: 0.03419648064300418 Engine time: 0.030058174394071102 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_16-16-32/adapters_256_slots_192_rate_3.2-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_16-16-32/adapters_256_slots_192_rate_3.2-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 270, 34560, 34560, 270, 34560, 540, 34560, 270, 540, 270, 34560, 540, 540, 540, 540, 34560, 270, 270, 270, 540, 34560, 270, 34560, 34560, 540, 540, 540, 270, 34560, 270, 540, 540, 270, 540, 270, 270, 540, 540, 34560, 540, 270, 540, 34560, 540, 540, 34560, 540, 34560, 270, 34560, 34560, 540, 270, 270, 34560, 540, 270, 540, 540, 34560, 540, 270, 270, 34560, 34560, 34560, 34560, 34560, 34560, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 34560, 34560, 270, 34560, 270, 540, 34560, 34560, 34560, 540, 270, 34560, 540, 270, 270, 270, 270, 270, 34560, 540, 270, 34560, 270, 34560, 270, 270, 540, 540, 34560, 540, 34560, 270, 540, 270, 34560, 34560, 270, 34560, 540, 270, 34560, 270, 270, 34560, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 270, 540, 34560, 34560, 270, 34560, 540, 270, 540, 34560, 270, 270, 270, 270, 270, 270, 34560, 270, 270, 270, 34560, 270, 540, 34560, 34560, 540, 270, 34560, 270, 540, 540, 270, 540, 270, 34560, 270, 270, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 540, 34560, 540, 34560, 270, 34560, 270, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 540, 540, 270, 540, 34560, 540, 540, 34560, 270, 34560, 34560, 540, 270, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 270, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 34560, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 34560, 540, 270, 270, 270, 270]
Prompts retrieved: 3041010 . Total input tokens: 677979927 . Total output tokens: 608266809
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.646823295857757,
    "estimated_duration": 3600.046400605703,
    "input_throughput": 4258.301225623296,
    "output_throughput": 3777.6096435067866,
    "total_throughput": 8035.910869130082,
    "itl": 89.35911257302507,
    "ttft": 2236145.6333868597,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 575,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9292048337683037,
    "arrivals": 1012432,
    "finished_requests": 62083,
    "scheduler_time": 72.19904057848767
}
#Debug simulation 
Total elapsed time: 4.646913480013609. Arrivals time: 0.2263292628340423 Scheduler time: 4.227341492660344 Scheduler overhead time: 0.054525707848370075 Adapter cache time: 0.05679047107696533 Engine time: 0.056094592437148094 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-8/adapters_256_slots_192_rate_3.2-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-8/adapters_256_slots_192_rate_3.2-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 135, 34560, 34560, 135, 34560, 540, 34560, 135, 540, 135, 34560, 540, 540, 540, 540, 34560, 135, 135, 135, 540, 34560, 135, 34560, 34560, 540, 540, 540, 135, 34560, 135, 540, 540, 135, 540, 135, 135, 540, 540, 34560, 540, 135, 540, 34560, 540, 540, 34560, 540, 34560, 135, 34560, 34560, 540, 135, 135, 34560, 540, 135, 540, 540, 34560, 540, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 34560, 34560, 135, 34560, 135, 540, 34560, 34560, 34560, 540, 135, 34560, 540, 135, 135, 135, 135, 135, 34560, 540, 135, 34560, 135, 34560, 135, 135, 540, 540, 34560, 540, 34560, 135, 540, 135, 34560, 34560, 135, 34560, 540, 135, 34560, 135, 135, 34560, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 135, 540, 34560, 34560, 135, 34560, 540, 135, 540, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 540, 34560, 34560, 540, 135, 34560, 135, 540, 540, 135, 540, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 540, 34560, 540, 34560, 135, 34560, 135, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 540, 540, 135, 540, 34560, 540, 540, 34560, 135, 34560, 34560, 540, 135, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 135, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 34560, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 34560, 540, 135, 135, 135, 135]
Prompts retrieved: 3029535 . Total input tokens: 675430113 . Total output tokens: 605954314
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.408669220749289,
    "estimated_duration": 3600.1118283331216,
    "input_throughput": 5228.68591243611,
    "output_throughput": 4616.596870463134,
    "total_throughput": 9845.282782899243,
    "itl": 185.89525149874717,
    "ttft": 2129959.580232251,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 476,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4567921661120053,
    "arrivals": 1008682,
    "finished_requests": 76206,
    "scheduler_time": 76.05838108768414
}
#Debug simulation 
Total elapsed time: 5.408768606837839. Arrivals time: 0.2657860517501831 Scheduler time: 5.038671146612614 Scheduler overhead time: 0.02977589424699545 Adapter cache time: 0.030091092456132174 Engine time: 0.03060806542634964 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-16/adapters_256_slots_192_rate_3.2-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-16/adapters_256_slots_192_rate_3.2-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 135, 34560, 34560, 135, 34560, 540, 34560, 135, 540, 135, 34560, 540, 540, 540, 540, 34560, 135, 135, 135, 540, 34560, 135, 34560, 34560, 540, 540, 540, 135, 34560, 135, 540, 540, 135, 540, 135, 135, 540, 540, 34560, 540, 135, 540, 34560, 540, 540, 34560, 540, 34560, 135, 34560, 34560, 540, 135, 135, 34560, 540, 135, 540, 540, 34560, 540, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 34560, 34560, 135, 34560, 135, 540, 34560, 34560, 34560, 540, 135, 34560, 540, 135, 135, 135, 135, 135, 34560, 540, 135, 34560, 135, 34560, 135, 135, 540, 540, 34560, 540, 34560, 135, 540, 135, 34560, 34560, 135, 34560, 540, 135, 34560, 135, 135, 34560, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 135, 540, 34560, 34560, 135, 34560, 540, 135, 540, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 540, 34560, 34560, 540, 135, 34560, 135, 540, 540, 135, 540, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 540, 34560, 540, 34560, 135, 34560, 135, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 540, 540, 135, 540, 34560, 540, 540, 34560, 135, 34560, 34560, 540, 135, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 135, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 34560, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 34560, 540, 135, 135, 135, 135]
Prompts retrieved: 3029535 . Total input tokens: 675430113 . Total output tokens: 605954314
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.341642796993256,
    "estimated_duration": 3600.034835451232,
    "input_throughput": 5221.05114509096,
    "output_throughput": 4610.769828264585,
    "total_throughput": 9831.820973355545,
    "itl": 183.51229493328555,
    "ttft": 2131069.812723851,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 475,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5514329872978923,
    "arrivals": 1008682,
    "finished_requests": 76088,
    "scheduler_time": 76.05023780492981
}
#Debug simulation 
Total elapsed time: 5.34174046292901. Arrivals time: 0.2624684162437916 Scheduler time: 4.975123854819685 Scheduler overhead time: 0.029681780841201544 Adapter cache time: 0.030121661256998777 Engine time: 0.03054550103843212 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-32/adapters_256_slots_192_rate_3.2-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-32/adapters_256_slots_192_rate_3.2-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 135, 34560, 34560, 135, 34560, 540, 34560, 135, 540, 135, 34560, 540, 540, 540, 540, 34560, 135, 135, 135, 540, 34560, 135, 34560, 34560, 540, 540, 540, 135, 34560, 135, 540, 540, 135, 540, 135, 135, 540, 540, 34560, 540, 135, 540, 34560, 540, 540, 34560, 540, 34560, 135, 34560, 34560, 540, 135, 135, 34560, 540, 135, 540, 540, 34560, 540, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 34560, 34560, 135, 34560, 135, 540, 34560, 34560, 34560, 540, 135, 34560, 540, 135, 135, 135, 135, 135, 34560, 540, 135, 34560, 135, 34560, 135, 135, 540, 540, 34560, 540, 34560, 135, 540, 135, 34560, 34560, 135, 34560, 540, 135, 34560, 135, 135, 34560, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 135, 540, 34560, 34560, 135, 34560, 540, 135, 540, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 540, 34560, 34560, 540, 135, 34560, 135, 540, 540, 135, 540, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 540, 34560, 540, 34560, 135, 34560, 135, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 540, 540, 135, 540, 34560, 540, 540, 34560, 135, 34560, 34560, 540, 135, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 135, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 34560, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 34560, 540, 135, 135, 135, 135]
Prompts retrieved: 3029535 . Total input tokens: 675430113 . Total output tokens: 605954314
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.0585323120467365,
    "estimated_duration": 3600.092530971743,
    "input_throughput": 4297.00872044653,
    "output_throughput": 3809.0218187527,
    "total_throughput": 8106.03053919923,
    "itl": 88.58813103346041,
    "ttft": 2233958.544205168,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 413,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3490418505482453,
    "arrivals": 1008682,
    "finished_requests": 62714,
    "scheduler_time": 72.82059557000052
}
#Debug simulation 
Total elapsed time: 5.058596364222467. Arrivals time: 0.22904238384217024 Scheduler time: 4.637887184973806 Scheduler overhead time: 0.05498433765023947 Adapter cache time: 0.05411461507901549 Engine time: 0.05642135301604867 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-16/adapters_256_slots_192_rate_3.2-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-16/adapters_256_slots_192_rate_3.2-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 135, 34560, 34560, 135, 34560, 540, 34560, 135, 540, 135, 34560, 540, 540, 540, 540, 34560, 135, 135, 135, 540, 34560, 135, 34560, 34560, 540, 540, 540, 135, 34560, 135, 540, 540, 135, 540, 135, 135, 540, 540, 34560, 540, 135, 540, 34560, 540, 540, 34560, 540, 34560, 135, 34560, 34560, 540, 135, 135, 34560, 540, 135, 540, 540, 34560, 540, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 34560, 34560, 135, 34560, 135, 540, 34560, 34560, 34560, 540, 135, 34560, 540, 135, 135, 135, 135, 135, 34560, 540, 135, 34560, 135, 34560, 135, 135, 540, 540, 34560, 540, 34560, 135, 540, 135, 34560, 34560, 135, 34560, 540, 135, 34560, 135, 135, 34560, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 135, 540, 34560, 34560, 135, 34560, 540, 135, 540, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 540, 34560, 34560, 540, 135, 34560, 135, 540, 540, 135, 540, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 540, 34560, 540, 34560, 135, 34560, 135, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 540, 540, 135, 540, 34560, 540, 540, 34560, 135, 34560, 34560, 540, 135, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 135, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 34560, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 34560, 540, 135, 135, 135, 135]
Prompts retrieved: 3029535 . Total input tokens: 675430113 . Total output tokens: 605954314
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.767665782012045,
    "estimated_duration": 3600.1778129892123,
    "input_throughput": 5221.04350851304,
    "output_throughput": 4610.719209509705,
    "total_throughput": 9831.762718022745,
    "itl": 183.51009396592193,
    "ttft": 2131120.3804558646,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 475,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4876921176211875,
    "arrivals": 1008682,
    "finished_requests": 76090,
    "scheduler_time": 76.05460591257206
}
#Debug simulation 
Total elapsed time: 5.767733551096171. Arrivals time: 0.6233019824139774 Scheduler time: 5.038213498424739 Scheduler overhead time: 0.02979333885014057 Adapter cache time: 0.03170238807797432 Engine time: 0.03074633562937379 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-32/adapters_256_slots_192_rate_3.2-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-32/adapters_256_slots_192_rate_3.2-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 135, 34560, 34560, 135, 34560, 540, 34560, 135, 540, 135, 34560, 540, 540, 540, 540, 34560, 135, 135, 135, 540, 34560, 135, 34560, 34560, 540, 540, 540, 135, 34560, 135, 540, 540, 135, 540, 135, 135, 540, 540, 34560, 540, 135, 540, 34560, 540, 540, 34560, 540, 34560, 135, 34560, 34560, 540, 135, 135, 34560, 540, 135, 540, 540, 34560, 540, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 34560, 34560, 135, 34560, 135, 540, 34560, 34560, 34560, 540, 135, 34560, 540, 135, 135, 135, 135, 135, 34560, 540, 135, 34560, 135, 34560, 135, 135, 540, 540, 34560, 540, 34560, 135, 540, 135, 34560, 34560, 135, 34560, 540, 135, 34560, 135, 135, 34560, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 135, 540, 34560, 34560, 135, 34560, 540, 135, 540, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 540, 34560, 34560, 540, 135, 34560, 135, 540, 540, 135, 540, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 540, 34560, 540, 34560, 135, 34560, 135, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 540, 540, 135, 540, 34560, 540, 540, 34560, 135, 34560, 34560, 540, 135, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 135, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 34560, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 34560, 540, 135, 135, 135, 135]
Prompts retrieved: 3029535 . Total input tokens: 675430113 . Total output tokens: 605954314
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 5.05343575309962,
    "estimated_duration": 3600.0128814160585,
    "input_throughput": 4297.012402332066,
    "output_throughput": 3809.0758149193416,
    "total_throughput": 8106.0882172514075,
    "itl": 88.58841437588963,
    "ttft": 2233984.4258603198,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 413,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3655155965685892,
    "arrivals": 1008682,
    "finished_requests": 62713,
    "scheduler_time": 72.81865442597223
}
#Debug simulation 
Total elapsed time: 5.053534470032901. Arrivals time: 0.2294607306830585 Scheduler time: 4.6326199900358915 Scheduler overhead time: 0.05488943541422486 Adapter cache time: 0.05369419464841485 Engine time: 0.056756196077913046 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-16/adapters_256_slots_192_rate_3.2-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-16/adapters_256_slots_192_rate_3.2-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 135, 34560, 34560, 135, 34560, 540, 34560, 135, 540, 135, 34560, 540, 540, 540, 540, 34560, 135, 135, 135, 540, 34560, 135, 34560, 34560, 540, 540, 540, 135, 34560, 135, 540, 540, 135, 540, 135, 135, 540, 540, 34560, 540, 135, 540, 34560, 540, 540, 34560, 540, 34560, 135, 34560, 34560, 540, 135, 135, 34560, 540, 135, 540, 540, 34560, 540, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 34560, 34560, 135, 34560, 135, 540, 34560, 34560, 34560, 540, 135, 34560, 540, 135, 135, 135, 135, 135, 34560, 540, 135, 34560, 135, 34560, 135, 135, 540, 540, 34560, 540, 34560, 135, 540, 135, 34560, 34560, 135, 34560, 540, 135, 34560, 135, 135, 34560, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 135, 540, 34560, 34560, 135, 34560, 540, 135, 540, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 540, 34560, 34560, 540, 135, 34560, 135, 540, 540, 135, 540, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 540, 34560, 540, 34560, 135, 34560, 135, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 540, 540, 135, 540, 34560, 540, 540, 34560, 135, 34560, 34560, 540, 135, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 135, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 34560, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 34560, 540, 135, 135, 135, 135]
Prompts retrieved: 3029535 . Total input tokens: 675430113 . Total output tokens: 605954314
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.775970947928727,
    "estimated_duration": 3600.110338745381,
    "input_throughput": 5221.141362725717,
    "output_throughput": 4610.805624858933,
    "total_throughput": 9831.94698758465,
    "itl": 183.50698970625712,
    "ttft": 2131090.1419271673,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 475,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.42027389007852,
    "arrivals": 1008682,
    "finished_requests": 76090,
    "scheduler_time": 76.05454989626874
}
#Debug simulation 
Total elapsed time: 5.7760454546660185. Arrivals time: 0.6287337550893426 Scheduler time: 5.040888753253967 Scheduler overhead time: 0.029824773781001568 Adapter cache time: 0.031744097359478474 Engine time: 0.030807414557784796 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-32/adapters_256_slots_192_rate_3.2-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-32/adapters_256_slots_192_rate_3.2-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 135, 34560, 34560, 135, 34560, 540, 34560, 135, 540, 135, 34560, 540, 540, 540, 540, 34560, 135, 135, 135, 540, 34560, 135, 34560, 34560, 540, 540, 540, 135, 34560, 135, 540, 540, 135, 540, 135, 135, 540, 540, 34560, 540, 135, 540, 34560, 540, 540, 34560, 540, 34560, 135, 34560, 34560, 540, 135, 135, 34560, 540, 135, 540, 540, 34560, 540, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 34560, 34560, 135, 34560, 135, 540, 34560, 34560, 34560, 540, 135, 34560, 540, 135, 135, 135, 135, 135, 34560, 540, 135, 34560, 135, 34560, 135, 135, 540, 540, 34560, 540, 34560, 135, 540, 135, 34560, 34560, 135, 34560, 540, 135, 34560, 135, 135, 34560, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 135, 540, 34560, 34560, 135, 34560, 540, 135, 540, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 540, 34560, 34560, 540, 135, 34560, 135, 540, 540, 135, 540, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 540, 34560, 540, 34560, 135, 34560, 135, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 540, 540, 135, 540, 34560, 540, 540, 34560, 135, 34560, 34560, 540, 135, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 135, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 34560, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 34560, 540, 135, 135, 135, 135]
Prompts retrieved: 3029535 . Total input tokens: 675430113 . Total output tokens: 605954314
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.031439958140254,
    "estimated_duration": 3600.0307660967696,
    "input_throughput": 4296.991055099273,
    "output_throughput": 3809.05689171863,
    "total_throughput": 8106.047946817903,
    "itl": 88.58887889386484,
    "ttft": 2233992.3807305326,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 413,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3833726342394956,
    "arrivals": 1008682,
    "finished_requests": 62713,
    "scheduler_time": 72.81868206902692
}
#Debug simulation 
Total elapsed time: 5.031540172174573. Arrivals time: 0.5833433726802468 Scheduler time: 4.256864909082651 Scheduler overhead time: 0.05452051945030689 Adapter cache time: 0.053799069952219725 Engine time: 0.05703254463151097 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-8/adapters_256_slots_192_rate_3.2-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-8/adapters_256_slots_192_rate_3.2-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 66, 34560, 34560, 66, 34560, 540, 34560, 66, 540, 66, 34560, 540, 540, 540, 540, 34560, 66, 66, 66, 540, 34560, 66, 34560, 34560, 540, 540, 540, 66, 34560, 66, 540, 540, 66, 540, 66, 66, 540, 540, 34560, 540, 66, 540, 34560, 540, 540, 34560, 540, 34560, 66, 34560, 34560, 540, 66, 66, 34560, 540, 66, 540, 540, 34560, 540, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 34560, 34560, 66, 34560, 66, 540, 34560, 34560, 34560, 540, 66, 34560, 540, 66, 66, 66, 66, 66, 34560, 540, 66, 34560, 66, 34560, 66, 66, 540, 540, 34560, 540, 34560, 66, 540, 66, 34560, 34560, 66, 34560, 540, 66, 34560, 66, 66, 34560, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 66, 540, 34560, 34560, 66, 34560, 540, 66, 540, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 540, 34560, 34560, 540, 66, 34560, 66, 540, 540, 66, 540, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 540, 34560, 540, 34560, 66, 34560, 66, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 540, 540, 66, 540, 34560, 540, 540, 34560, 66, 34560, 34560, 540, 66, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 66, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 34560, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 34560, 540, 66, 66, 66, 66]
Prompts retrieved: 3023670 . Total input tokens: 674122022 . Total output tokens: 604779064
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.4485343298874795,
    "estimated_duration": 3600.0287810040213,
    "input_throughput": 5304.2253719634,
    "output_throughput": 4663.95576851952,
    "total_throughput": 9968.18114048292,
    "itl": 183.80158609473457,
    "ttft": 2130480.3236008417,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 342,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.046686808425002,
    "arrivals": 1006798,
    "finished_requests": 76862,
    "scheduler_time": 76.7530644591831
}
#Debug simulation 
Total elapsed time: 5.448632705025375. Arrivals time: 0.27157472679391503 Scheduler time: 5.074361415579915 Scheduler overhead time: 0.029937373474240303 Adapter cache time: 0.028091281186789274 Engine time: 0.03073930274695158 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-16/adapters_256_slots_192_rate_3.2-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-16/adapters_256_slots_192_rate_3.2-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 66, 34560, 34560, 66, 34560, 540, 34560, 66, 540, 66, 34560, 540, 540, 540, 540, 34560, 66, 66, 66, 540, 34560, 66, 34560, 34560, 540, 540, 540, 66, 34560, 66, 540, 540, 66, 540, 66, 66, 540, 540, 34560, 540, 66, 540, 34560, 540, 540, 34560, 540, 34560, 66, 34560, 34560, 540, 66, 66, 34560, 540, 66, 540, 540, 34560, 540, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 34560, 34560, 66, 34560, 66, 540, 34560, 34560, 34560, 540, 66, 34560, 540, 66, 66, 66, 66, 66, 34560, 540, 66, 34560, 66, 34560, 66, 66, 540, 540, 34560, 540, 34560, 66, 540, 66, 34560, 34560, 66, 34560, 540, 66, 34560, 66, 66, 34560, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 66, 540, 34560, 34560, 66, 34560, 540, 66, 540, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 540, 34560, 34560, 540, 66, 34560, 66, 540, 540, 66, 540, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 540, 34560, 540, 34560, 66, 34560, 66, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 540, 540, 66, 540, 34560, 540, 540, 34560, 66, 34560, 34560, 540, 66, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 66, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 34560, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 34560, 540, 66, 66, 66, 66]
Prompts retrieved: 3023670 . Total input tokens: 674122022 . Total output tokens: 604779064
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.389080625958741,
    "estimated_duration": 3600.0877813446587,
    "input_throughput": 5295.296992141573,
    "output_throughput": 4656.226741709883,
    "total_throughput": 9951.523733851456,
    "itl": 181.77684339756803,
    "ttft": 2131547.1409537084,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 341,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1107239065738448,
    "arrivals": 1006798,
    "finished_requests": 76728,
    "scheduler_time": 76.74159483643788
}
#Debug simulation 
Total elapsed time: 5.38919937890023. Arrivals time: 0.26474365312606096 Scheduler time: 5.02266961382702 Scheduler overhead time: 0.030035420320928097 Adapter cache time: 0.02703897561877966 Engine time: 0.030732471495866776 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-32/adapters_256_slots_192_rate_3.2-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-32/adapters_256_slots_192_rate_3.2-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 66, 34560, 34560, 66, 34560, 540, 34560, 66, 540, 66, 34560, 540, 540, 540, 540, 34560, 66, 66, 66, 540, 34560, 66, 34560, 34560, 540, 540, 540, 66, 34560, 66, 540, 540, 66, 540, 66, 66, 540, 540, 34560, 540, 66, 540, 34560, 540, 540, 34560, 540, 34560, 66, 34560, 34560, 540, 66, 66, 34560, 540, 66, 540, 540, 34560, 540, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 34560, 34560, 66, 34560, 66, 540, 34560, 34560, 34560, 540, 66, 34560, 540, 66, 66, 66, 66, 66, 34560, 540, 66, 34560, 66, 34560, 66, 66, 540, 540, 34560, 540, 34560, 66, 540, 66, 34560, 34560, 66, 34560, 540, 66, 34560, 66, 66, 34560, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 66, 540, 34560, 34560, 66, 34560, 540, 66, 540, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 540, 34560, 34560, 540, 66, 34560, 66, 540, 540, 66, 540, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 540, 34560, 540, 34560, 66, 34560, 66, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 540, 540, 66, 540, 34560, 540, 540, 34560, 66, 34560, 34560, 540, 66, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 66, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 34560, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 34560, 540, 66, 66, 66, 66]
Prompts retrieved: 3023670 . Total input tokens: 674122022 . Total output tokens: 604779064
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.691655285190791,
    "estimated_duration": 3600.0760241760154,
    "input_throughput": 4317.198830143401,
    "output_throughput": 3818.2413114862406,
    "total_throughput": 8135.440141629641,
    "itl": 88.33156659866427,
    "ttft": 2233765.091282775,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 308,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0062022943049722,
    "arrivals": 1006798,
    "finished_requests": 62564,
    "scheduler_time": 73.00377132023048
}
#Debug simulation 
Total elapsed time: 4.691745455842465. Arrivals time: 0.23012332990765572 Scheduler time: 4.2762672253884375 Scheduler overhead time: 0.054531754460185766 Adapter cache time: 0.04764984967187047 Engine time: 0.05709309130907059 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-16/adapters_256_slots_192_rate_3.2-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-16/adapters_256_slots_192_rate_3.2-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 66, 34560, 34560, 66, 34560, 540, 34560, 66, 540, 66, 34560, 540, 540, 540, 540, 34560, 66, 66, 66, 540, 34560, 66, 34560, 34560, 540, 540, 540, 66, 34560, 66, 540, 540, 66, 540, 66, 66, 540, 540, 34560, 540, 66, 540, 34560, 540, 540, 34560, 540, 34560, 66, 34560, 34560, 540, 66, 66, 34560, 540, 66, 540, 540, 34560, 540, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 34560, 34560, 66, 34560, 66, 540, 34560, 34560, 34560, 540, 66, 34560, 540, 66, 66, 66, 66, 66, 34560, 540, 66, 34560, 66, 34560, 66, 66, 540, 540, 34560, 540, 34560, 66, 540, 66, 34560, 34560, 66, 34560, 540, 66, 34560, 66, 66, 34560, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 66, 540, 34560, 34560, 66, 34560, 540, 66, 540, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 540, 34560, 34560, 540, 66, 34560, 66, 540, 540, 66, 540, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 540, 34560, 540, 34560, 66, 34560, 66, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 540, 540, 66, 540, 34560, 540, 540, 34560, 66, 34560, 34560, 540, 66, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 66, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 34560, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 34560, 540, 66, 66, 66, 66]
Prompts retrieved: 3023670 . Total input tokens: 674122022 . Total output tokens: 604779064
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.401639068964869,
    "estimated_duration": 3600.021111181014,
    "input_throughput": 5295.281725096939,
    "output_throughput": 4656.300472221632,
    "total_throughput": 9951.582197318572,
    "itl": 181.7658224208053,
    "ttft": 2131525.465742654,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 341,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0665956121822846,
    "arrivals": 1006798,
    "finished_requests": 76727,
    "scheduler_time": 76.74117564293493
}
#Debug simulation 
Total elapsed time: 5.401765395887196. Arrivals time: 0.26804850064218044 Scheduler time: 5.030364697799087 Scheduler overhead time: 0.03029288211837411 Adapter cache time: 0.02766908472403884 Engine time: 0.03113020397722721 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-32/adapters_256_slots_192_rate_3.2-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-32/adapters_256_slots_192_rate_3.2-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 66, 34560, 34560, 66, 34560, 540, 34560, 66, 540, 66, 34560, 540, 540, 540, 540, 34560, 66, 66, 66, 540, 34560, 66, 34560, 34560, 540, 540, 540, 66, 34560, 66, 540, 540, 66, 540, 66, 66, 540, 540, 34560, 540, 66, 540, 34560, 540, 540, 34560, 540, 34560, 66, 34560, 34560, 540, 66, 66, 34560, 540, 66, 540, 540, 34560, 540, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 34560, 34560, 66, 34560, 66, 540, 34560, 34560, 34560, 540, 66, 34560, 540, 66, 66, 66, 66, 66, 34560, 540, 66, 34560, 66, 34560, 66, 66, 540, 540, 34560, 540, 34560, 66, 540, 66, 34560, 34560, 66, 34560, 540, 66, 34560, 66, 66, 34560, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 66, 540, 34560, 34560, 66, 34560, 540, 66, 540, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 540, 34560, 34560, 540, 66, 34560, 66, 540, 540, 66, 540, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 540, 34560, 540, 34560, 66, 34560, 66, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 540, 540, 66, 540, 34560, 540, 540, 34560, 66, 34560, 34560, 540, 66, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 66, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 34560, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 34560, 540, 66, 66, 66, 66]
Prompts retrieved: 3023670 . Total input tokens: 674122022 . Total output tokens: 604779064
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 4.774042870849371,
    "estimated_duration": 3600.088762391855,
    "input_throughput": 4317.183554572672,
    "output_throughput": 3818.2278013799173,
    "total_throughput": 8135.411355952589,
    "itl": 88.33187609605113,
    "ttft": 2233771.63486087,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 308,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0189034267328732,
    "arrivals": 1006798,
    "finished_requests": 62564,
    "scheduler_time": 73.00380840364916
}
#Debug simulation 
Total elapsed time: 4.774136526975781. Arrivals time: 0.29221006808802485 Scheduler time: 4.295851292088628 Scheduler overhead time: 0.05519577581435442 Adapter cache time: 0.04755607387050986 Engine time: 0.05718996934592724 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-16/adapters_256_slots_192_rate_3.2-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-16/adapters_256_slots_192_rate_3.2-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 66, 34560, 34560, 66, 34560, 540, 34560, 66, 540, 66, 34560, 540, 540, 540, 540, 34560, 66, 66, 66, 540, 34560, 66, 34560, 34560, 540, 540, 540, 66, 34560, 66, 540, 540, 66, 540, 66, 66, 540, 540, 34560, 540, 66, 540, 34560, 540, 540, 34560, 540, 34560, 66, 34560, 34560, 540, 66, 66, 34560, 540, 66, 540, 540, 34560, 540, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 34560, 34560, 66, 34560, 66, 540, 34560, 34560, 34560, 540, 66, 34560, 540, 66, 66, 66, 66, 66, 34560, 540, 66, 34560, 66, 34560, 66, 66, 540, 540, 34560, 540, 34560, 66, 540, 66, 34560, 34560, 66, 34560, 540, 66, 34560, 66, 66, 34560, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 66, 540, 34560, 34560, 66, 34560, 540, 66, 540, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 540, 34560, 34560, 540, 66, 34560, 66, 540, 540, 66, 540, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 540, 34560, 540, 34560, 66, 34560, 66, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 540, 540, 66, 540, 34560, 540, 540, 34560, 66, 34560, 34560, 540, 66, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 66, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 34560, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 34560, 540, 66, 66, 66, 66]
Prompts retrieved: 3023670 . Total input tokens: 674122022 . Total output tokens: 604779064
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.504366718232632,
    "estimated_duration": 3600.1720523563135,
    "input_throughput": 5295.389976576926,
    "output_throughput": 4656.365517039149,
    "total_throughput": 9951.755493616074,
    "itl": 181.7649001075347,
    "ttft": 2131545.3285918296,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 341,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0196071505616426,
    "arrivals": 1006798,
    "finished_requests": 76731,
    "scheduler_time": 76.74539497135392
}
#Debug simulation 
Total elapsed time: 5.504474961198866. Arrivals time: 0.2774097169749439 Scheduler time: 5.111365221440792 Scheduler overhead time: 0.030444296076893806 Adapter cache time: 0.02712611621245742 Engine time: 0.043956085573881865 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-32/adapters_256_slots_192_rate_3.2-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-32/adapters_256_slots_192_rate_3.2-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 66, 34560, 34560, 66, 34560, 540, 34560, 66, 540, 66, 34560, 540, 540, 540, 540, 34560, 66, 66, 66, 540, 34560, 66, 34560, 34560, 540, 540, 540, 66, 34560, 66, 540, 540, 66, 540, 66, 66, 540, 540, 34560, 540, 66, 540, 34560, 540, 540, 34560, 540, 34560, 66, 34560, 34560, 540, 66, 66, 34560, 540, 66, 540, 540, 34560, 540, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 34560, 34560, 66, 34560, 66, 540, 34560, 34560, 34560, 540, 66, 34560, 540, 66, 66, 66, 66, 66, 34560, 540, 66, 34560, 66, 34560, 66, 66, 540, 540, 34560, 540, 34560, 66, 540, 66, 34560, 34560, 66, 34560, 540, 66, 34560, 66, 66, 34560, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 66, 540, 34560, 34560, 66, 34560, 540, 66, 540, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 540, 34560, 34560, 540, 66, 34560, 66, 540, 540, 66, 540, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 540, 34560, 540, 34560, 66, 34560, 66, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 540, 540, 66, 540, 34560, 540, 540, 34560, 66, 34560, 34560, 540, 66, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 66, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 34560, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 34560, 540, 66, 66, 66, 66]
Prompts retrieved: 3023670 . Total input tokens: 674122022 . Total output tokens: 604779064
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.700746160000563,
    "estimated_duration": 3600.0652209077716,
    "input_throughput": 4317.313450249345,
    "output_throughput": 3818.388878114207,
    "total_throughput": 8135.702328363551,
    "itl": 88.33006668223669,
    "ttft": 2233805.2783129932,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 308,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0318560667336034,
    "arrivals": 1006798,
    "finished_requests": 62565,
    "scheduler_time": 73.00361040547446
}
#Debug simulation 
Total elapsed time: 4.700841272249818. Arrivals time: 0.22926899790763855 Scheduler time: 4.287375146057457 Scheduler overhead time: 0.05483040772378445 Adapter cache time: 0.04687854088842869 Engine time: 0.05633388226851821 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-8/adapters_256_slots_192_rate_3.2-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-8/adapters_256_slots_192_rate_3.2-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 33, 34560, 34560, 33, 34560, 540, 34560, 33, 540, 33, 34560, 540, 540, 540, 540, 34560, 33, 33, 33, 540, 34560, 33, 34560, 34560, 540, 540, 540, 33, 34560, 33, 540, 540, 33, 540, 33, 33, 540, 540, 34560, 540, 33, 540, 34560, 540, 540, 34560, 540, 34560, 33, 34560, 34560, 540, 33, 33, 34560, 540, 33, 540, 540, 34560, 540, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 34560, 34560, 33, 34560, 33, 540, 34560, 34560, 34560, 540, 33, 34560, 540, 33, 33, 33, 33, 33, 34560, 540, 33, 34560, 33, 34560, 33, 33, 540, 540, 34560, 540, 34560, 33, 540, 33, 34560, 34560, 33, 34560, 540, 33, 34560, 33, 33, 34560, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 33, 540, 34560, 34560, 33, 34560, 540, 33, 540, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 540, 34560, 34560, 540, 33, 34560, 33, 540, 540, 33, 540, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 540, 34560, 540, 34560, 33, 34560, 33, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 540, 540, 33, 540, 34560, 540, 540, 34560, 33, 34560, 34560, 540, 33, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 33, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 34560, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 34560, 540, 33, 33, 33, 33]
Prompts retrieved: 3020865 . Total input tokens: 673492761 . Total output tokens: 604222272
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.445852464064956,
    "estimated_duration": 3600.094553226904,
    "input_throughput": 5298.126956944354,
    "output_throughput": 4677.059102491511,
    "total_throughput": 9975.186059435866,
    "itl": 183.90764105905532,
    "ttft": 2131119.777073114,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 239,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7314565707999272,
    "arrivals": 1005871,
    "finished_requests": 77054,
    "scheduler_time": 76.9495178100587
}
#Debug simulation 
Total elapsed time: 5.445944602135569. Arrivals time: 0.27823093719780445 Scheduler time: 5.068268551491201 Scheduler overhead time: 0.029869232792407274 Adapter cache time: 0.024917129892855883 Engine time: 0.030790897086262703 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-16/adapters_256_slots_192_rate_3.2-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-16/adapters_256_slots_192_rate_3.2-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 33, 34560, 34560, 33, 34560, 540, 34560, 33, 540, 33, 34560, 540, 540, 540, 540, 34560, 33, 33, 33, 540, 34560, 33, 34560, 34560, 540, 540, 540, 33, 34560, 33, 540, 540, 33, 540, 33, 33, 540, 540, 34560, 540, 33, 540, 34560, 540, 540, 34560, 540, 34560, 33, 34560, 34560, 540, 33, 33, 34560, 540, 33, 540, 540, 34560, 540, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 34560, 34560, 33, 34560, 33, 540, 34560, 34560, 34560, 540, 33, 34560, 540, 33, 33, 33, 33, 33, 34560, 540, 33, 34560, 33, 34560, 33, 33, 540, 540, 34560, 540, 34560, 33, 540, 33, 34560, 34560, 33, 34560, 540, 33, 34560, 33, 33, 34560, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 33, 540, 34560, 34560, 33, 34560, 540, 33, 540, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 540, 34560, 34560, 540, 33, 34560, 33, 540, 540, 33, 540, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 540, 34560, 540, 34560, 33, 34560, 33, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 540, 540, 33, 540, 34560, 540, 540, 34560, 33, 34560, 34560, 540, 33, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 33, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 34560, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 34560, 540, 33, 33, 33, 33]
Prompts retrieved: 3020865 . Total input tokens: 673492761 . Total output tokens: 604222272
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.415432617999613,
    "estimated_duration": 3600.174092305923,
    "input_throughput": 5292.155465681021,
    "output_throughput": 4673.063459890706,
    "total_throughput": 9965.218925571728,
    "itl": 182.14163042376106,
    "ttft": 2131944.509593029,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 239,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7804058667505193,
    "arrivals": 1005871,
    "finished_requests": 76981,
    "scheduler_time": 76.9404888132553
}
#Debug simulation 
Total elapsed time: 5.415554889012128. Arrivals time: 0.26608601957559586 Scheduler time: 5.048429116606712 Scheduler overhead time: 0.03048155503347516 Adapter cache time: 0.02507232315838337 Engine time: 0.03124235523864627 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-32/adapters_256_slots_192_rate_3.2-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-32/adapters_256_slots_192_rate_3.2-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 33, 34560, 34560, 33, 34560, 540, 34560, 33, 540, 33, 34560, 540, 540, 540, 540, 34560, 33, 33, 33, 540, 34560, 33, 34560, 34560, 540, 540, 540, 33, 34560, 33, 540, 540, 33, 540, 33, 33, 540, 540, 34560, 540, 33, 540, 34560, 540, 540, 34560, 540, 34560, 33, 34560, 34560, 540, 33, 33, 34560, 540, 33, 540, 540, 34560, 540, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 34560, 34560, 33, 34560, 33, 540, 34560, 34560, 34560, 540, 33, 34560, 540, 33, 33, 33, 33, 33, 34560, 540, 33, 34560, 33, 34560, 33, 33, 540, 540, 34560, 540, 34560, 33, 540, 33, 34560, 34560, 33, 34560, 540, 33, 34560, 33, 33, 34560, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 33, 540, 34560, 34560, 33, 34560, 540, 33, 540, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 540, 34560, 34560, 540, 33, 34560, 33, 540, 540, 33, 540, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 540, 34560, 540, 34560, 33, 34560, 33, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 540, 540, 33, 540, 34560, 540, 540, 34560, 33, 34560, 34560, 540, 33, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 33, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 34560, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 34560, 540, 33, 33, 33, 33]
Prompts retrieved: 3020865 . Total input tokens: 673492761 . Total output tokens: 604222272
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.710908907931298,
    "estimated_duration": 3600.0255415661495,
    "input_throughput": 4311.240245603356,
    "output_throughput": 3830.6903217138192,
    "total_throughput": 8141.930567317175,
    "itl": 88.65369787840949,
    "ttft": 2233362.092938109,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 220,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7191495284251901,
    "arrivals": 1005871,
    "finished_requests": 62765,
    "scheduler_time": 73.13467190921718
}
#Debug simulation 
Total elapsed time: 4.710998916998506. Arrivals time: 0.2319147470407188 Scheduler time: 4.29375687520951 Scheduler overhead time: 0.054776415694504976 Adapter cache time: 0.04759035538882017 Engine time: 0.05680139781907201 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-16/adapters_256_slots_192_rate_3.2-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-16/adapters_256_slots_192_rate_3.2-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 33, 34560, 34560, 33, 34560, 540, 34560, 33, 540, 33, 34560, 540, 540, 540, 540, 34560, 33, 33, 33, 540, 34560, 33, 34560, 34560, 540, 540, 540, 33, 34560, 33, 540, 540, 33, 540, 33, 33, 540, 540, 34560, 540, 33, 540, 34560, 540, 540, 34560, 540, 34560, 33, 34560, 34560, 540, 33, 33, 34560, 540, 33, 540, 540, 34560, 540, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 34560, 34560, 33, 34560, 33, 540, 34560, 34560, 34560, 540, 33, 34560, 540, 33, 33, 33, 33, 33, 34560, 540, 33, 34560, 33, 34560, 33, 33, 540, 540, 34560, 540, 34560, 33, 540, 33, 34560, 34560, 33, 34560, 540, 33, 34560, 33, 33, 34560, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 33, 540, 34560, 34560, 33, 34560, 540, 33, 540, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 540, 34560, 34560, 540, 33, 34560, 33, 540, 540, 33, 540, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 540, 34560, 540, 34560, 33, 34560, 33, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 540, 540, 33, 540, 34560, 540, 540, 34560, 33, 34560, 34560, 540, 33, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 33, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 34560, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 34560, 540, 33, 33, 33, 33]
Prompts retrieved: 3020865 . Total input tokens: 673492761 . Total output tokens: 604222272
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.504677694756538,
    "estimated_duration": 3600.17972313235,
    "input_throughput": 5292.147188536228,
    "output_throughput": 4673.0561510308025,
    "total_throughput": 9965.20333956703,
    "itl": 182.12691388487514,
    "ttft": 2131945.8121606368,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 239,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7464924553199689,
    "arrivals": 1005871,
    "finished_requests": 76981,
    "scheduler_time": 76.94095651284347
}
#Debug simulation 
Total elapsed time: 5.504803814925253. Arrivals time: 0.330512888263911 Scheduler time: 5.074422464240342 Scheduler overhead time: 0.030089346691966057 Adapter cache time: 0.024922558572143316 Engine time: 0.030796400737017393 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-32/adapters_256_slots_192_rate_3.2-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-32/adapters_256_slots_192_rate_3.2-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 33, 34560, 34560, 33, 34560, 540, 34560, 33, 540, 33, 34560, 540, 540, 540, 540, 34560, 33, 33, 33, 540, 34560, 33, 34560, 34560, 540, 540, 540, 33, 34560, 33, 540, 540, 33, 540, 33, 33, 540, 540, 34560, 540, 33, 540, 34560, 540, 540, 34560, 540, 34560, 33, 34560, 34560, 540, 33, 33, 34560, 540, 33, 540, 540, 34560, 540, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 34560, 34560, 33, 34560, 33, 540, 34560, 34560, 34560, 540, 33, 34560, 540, 33, 33, 33, 33, 33, 34560, 540, 33, 34560, 33, 34560, 33, 33, 540, 540, 34560, 540, 34560, 33, 540, 33, 34560, 34560, 33, 34560, 540, 33, 34560, 33, 33, 34560, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 33, 540, 34560, 34560, 33, 34560, 540, 33, 540, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 540, 34560, 34560, 540, 33, 34560, 33, 540, 540, 33, 540, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 540, 34560, 540, 34560, 33, 34560, 33, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 540, 540, 33, 540, 34560, 540, 540, 34560, 33, 34560, 34560, 540, 33, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 33, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 34560, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 34560, 540, 33, 33, 33, 33]
Prompts retrieved: 3020865 . Total input tokens: 673492761 . Total output tokens: 604222272
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 4.730349499266595,
    "estimated_duration": 3600.0351339292984,
    "input_throughput": 4311.22875822045,
    "output_throughput": 3830.6801147654674,
    "total_throughput": 8141.908872985918,
    "itl": 88.65391238705698,
    "ttft": 2233367.696433896,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 220,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7287068161927193,
    "arrivals": 1005871,
    "finished_requests": 62765,
    "scheduler_time": 73.13470698460262
}
#Debug simulation 
Total elapsed time: 4.73044848209247. Arrivals time: 0.2314820997416973 Scheduler time: 4.3124785693362355 Scheduler overhead time: 0.05522781703621149 Adapter cache time: 0.04811943881213665 Engine time: 0.05679140239953995 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-16/adapters_256_slots_192_rate_3.2-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-16/adapters_256_slots_192_rate_3.2-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 33, 34560, 34560, 33, 34560, 540, 34560, 33, 540, 33, 34560, 540, 540, 540, 540, 34560, 33, 33, 33, 540, 34560, 33, 34560, 34560, 540, 540, 540, 33, 34560, 33, 540, 540, 33, 540, 33, 33, 540, 540, 34560, 540, 33, 540, 34560, 540, 540, 34560, 540, 34560, 33, 34560, 34560, 540, 33, 33, 34560, 540, 33, 540, 540, 34560, 540, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 34560, 34560, 33, 34560, 33, 540, 34560, 34560, 34560, 540, 33, 34560, 540, 33, 33, 33, 33, 33, 34560, 540, 33, 34560, 33, 34560, 33, 33, 540, 540, 34560, 540, 34560, 33, 540, 33, 34560, 34560, 33, 34560, 540, 33, 34560, 33, 33, 34560, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 33, 540, 34560, 34560, 33, 34560, 540, 33, 540, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 540, 34560, 34560, 540, 33, 34560, 33, 540, 540, 33, 540, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 540, 34560, 540, 34560, 33, 34560, 33, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 540, 540, 33, 540, 34560, 540, 540, 34560, 33, 34560, 34560, 540, 33, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 33, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 34560, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 34560, 540, 33, 33, 33, 33]
Prompts retrieved: 3020865 . Total input tokens: 673492761 . Total output tokens: 604222272
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.458108942955732,
    "estimated_duration": 3600.121284483896,
    "input_throughput": 5292.233092844633,
    "output_throughput": 4673.13200599902,
    "total_throughput": 9965.365098843653,
    "itl": 182.13560013216446,
    "ttft": 2131910.094552639,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 239,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7146220204816209,
    "arrivals": 1005871,
    "finished_requests": 76981,
    "scheduler_time": 76.94035597582136
}
#Debug simulation 
Total elapsed time: 5.45821639103815. Arrivals time: 0.2862581736408174 Scheduler time: 5.071036010980606 Scheduler overhead time: 0.030307008884847164 Adapter cache time: 0.025187726132571697 Engine time: 0.03130378853529692 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-32/adapters_256_slots_192_rate_3.2-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-32/adapters_256_slots_192_rate_3.2-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 33, 34560, 34560, 33, 34560, 540, 34560, 33, 540, 33, 34560, 540, 540, 540, 540, 34560, 33, 33, 33, 540, 34560, 33, 34560, 34560, 540, 540, 540, 33, 34560, 33, 540, 540, 33, 540, 33, 33, 540, 540, 34560, 540, 33, 540, 34560, 540, 540, 34560, 540, 34560, 33, 34560, 34560, 540, 33, 33, 34560, 540, 33, 540, 540, 34560, 540, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 34560, 34560, 33, 34560, 33, 540, 34560, 34560, 34560, 540, 33, 34560, 540, 33, 33, 33, 33, 33, 34560, 540, 33, 34560, 33, 34560, 33, 33, 540, 540, 34560, 540, 34560, 33, 540, 33, 34560, 34560, 33, 34560, 540, 33, 34560, 33, 33, 34560, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 33, 540, 34560, 34560, 33, 34560, 540, 33, 540, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 540, 34560, 34560, 540, 33, 34560, 33, 540, 540, 33, 540, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 540, 34560, 540, 34560, 33, 34560, 33, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 540, 540, 33, 540, 34560, 540, 540, 34560, 33, 34560, 34560, 540, 33, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 33, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 34560, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 34560, 540, 33, 33, 33, 33]
Prompts retrieved: 3020865 . Total input tokens: 673492761 . Total output tokens: 604222272
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.7249499396421015,
    "estimated_duration": 3600.044088317858,
    "input_throughput": 4311.218034902478,
    "output_throughput": 3830.67058671599,
    "total_throughput": 8141.888621618468,
    "itl": 88.65411404527828,
    "ttft": 2233373.0435209638,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 220,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7376353350281741,
    "arrivals": 1005871,
    "finished_requests": 62765,
    "scheduler_time": 73.13473285432929
}
#Debug simulation 
Total elapsed time: 4.72504353383556. Arrivals time: 0.23210231540724635 Scheduler time: 4.307852883823216 Scheduler overhead time: 0.05448189377784729 Adapter cache time: 0.04803810780867934 Engine time: 0.05632995441555977 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-8/adapters_256_slots_192_rate_3.2-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-8/adapters_256_slots_192_rate_3.2-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 135, 34560, 34560, 135, 34560, 270, 34560, 135, 270, 135, 34560, 270, 270, 270, 270, 34560, 135, 135, 135, 270, 34560, 135, 34560, 34560, 270, 270, 270, 135, 34560, 135, 270, 270, 135, 270, 135, 135, 270, 270, 34560, 270, 135, 270, 34560, 270, 270, 34560, 270, 34560, 135, 34560, 34560, 270, 135, 135, 34560, 270, 135, 270, 270, 34560, 270, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 34560, 34560, 135, 34560, 135, 270, 34560, 34560, 34560, 270, 135, 34560, 270, 135, 135, 135, 135, 135, 34560, 270, 135, 34560, 135, 34560, 135, 135, 270, 270, 34560, 270, 34560, 135, 270, 135, 34560, 34560, 135, 34560, 270, 135, 34560, 135, 135, 34560, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 135, 270, 34560, 34560, 135, 34560, 270, 135, 270, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 270, 34560, 34560, 270, 135, 34560, 135, 270, 270, 135, 270, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 270, 34560, 270, 34560, 135, 34560, 135, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 270, 270, 135, 270, 34560, 270, 270, 34560, 135, 34560, 34560, 270, 135, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 135, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 34560, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 34560, 270, 135, 135, 135, 135]
Prompts retrieved: 3006585 . Total input tokens: 670334443 . Total output tokens: 601394933
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.583331448957324,
    "estimated_duration": 3600.142841756048,
    "input_throughput": 5395.877845370319,
    "output_throughput": 4770.921531441801,
    "total_throughput": 10166.79937681212,
    "itl": 180.41815805148784,
    "ttft": 2118175.0605735076,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 415,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2701024137321009,
    "arrivals": 1001073,
    "finished_requests": 78494,
    "scheduler_time": 78.44759046378856
}
#Debug simulation 
Total elapsed time: 5.58342360612005. Arrivals time: 0.3732707272283733 Scheduler time: 5.112788843922317 Scheduler overhead time: 0.030050243251025677 Adapter cache time: 0.022207072470337152 Engine time: 0.031078936997801065 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-16/adapters_256_slots_192_rate_3.2-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-16/adapters_256_slots_192_rate_3.2-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 135, 34560, 34560, 135, 34560, 270, 34560, 135, 270, 135, 34560, 270, 270, 270, 270, 34560, 135, 135, 135, 270, 34560, 135, 34560, 34560, 270, 270, 270, 135, 34560, 135, 270, 270, 135, 270, 135, 135, 270, 270, 34560, 270, 135, 270, 34560, 270, 270, 34560, 270, 34560, 135, 34560, 34560, 270, 135, 135, 34560, 270, 135, 270, 270, 34560, 270, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 34560, 34560, 135, 34560, 135, 270, 34560, 34560, 34560, 270, 135, 34560, 270, 135, 135, 135, 135, 135, 34560, 270, 135, 34560, 135, 34560, 135, 135, 270, 270, 34560, 270, 34560, 135, 270, 135, 34560, 34560, 135, 34560, 270, 135, 34560, 135, 135, 34560, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 135, 270, 34560, 34560, 135, 34560, 270, 135, 270, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 270, 34560, 34560, 270, 135, 34560, 135, 270, 270, 135, 270, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 270, 34560, 270, 34560, 135, 34560, 135, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 270, 270, 135, 270, 34560, 270, 270, 34560, 135, 34560, 34560, 270, 135, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 135, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 34560, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 34560, 270, 135, 135, 135, 135]
Prompts retrieved: 3006585 . Total input tokens: 670334443 . Total output tokens: 601394933
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.631892430130392,
    "estimated_duration": 3600.123557952401,
    "input_throughput": 5386.043197647487,
    "output_throughput": 4761.5893521581875,
    "total_throughput": 10147.632549805674,
    "itl": 178.28336503083798,
    "ttft": 2119263.3739415347,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 415,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3524173943186228,
    "arrivals": 1001073,
    "finished_requests": 78353,
    "scheduler_time": 78.42153737761967
}
#Debug simulation 
Total elapsed time: 5.632015387993306. Arrivals time: 0.2737997379153967 Scheduler time: 5.259476128965616 Scheduler overhead time: 0.030662150122225285 Adapter cache time: 0.0223630852997303 Engine time: 0.0314863626845181 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-32/adapters_256_slots_192_rate_3.2-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-32/adapters_256_slots_192_rate_3.2-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 135, 34560, 34560, 135, 34560, 270, 34560, 135, 270, 135, 34560, 270, 270, 270, 270, 34560, 135, 135, 135, 270, 34560, 135, 34560, 34560, 270, 270, 270, 135, 34560, 135, 270, 270, 135, 270, 135, 135, 270, 270, 34560, 270, 135, 270, 34560, 270, 270, 34560, 270, 34560, 135, 34560, 34560, 270, 135, 135, 34560, 270, 135, 270, 270, 34560, 270, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 34560, 34560, 135, 34560, 135, 270, 34560, 34560, 34560, 270, 135, 34560, 270, 135, 135, 135, 135, 135, 34560, 270, 135, 34560, 135, 34560, 135, 135, 270, 270, 34560, 270, 34560, 135, 270, 135, 34560, 34560, 135, 34560, 270, 135, 34560, 135, 135, 34560, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 135, 270, 34560, 34560, 135, 34560, 270, 135, 270, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 270, 34560, 34560, 270, 135, 34560, 135, 270, 270, 135, 270, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 270, 34560, 270, 34560, 135, 34560, 135, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 270, 270, 135, 270, 34560, 270, 270, 34560, 135, 34560, 34560, 270, 135, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 135, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 34560, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 34560, 270, 135, 135, 135, 135]
Prompts retrieved: 3006585 . Total input tokens: 670334443 . Total output tokens: 601394933
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.220539253670722,
    "estimated_duration": 3600.0574004621812,
    "input_throughput": 4336.921960743058,
    "output_throughput": 3856.64878516035,
    "total_throughput": 8193.57074590341,
    "itl": 87.37560842122869,
    "ttft": 2228946.5145476935,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 357,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1671383802034025,
    "arrivals": 1001073,
    "finished_requests": 63265,
    "scheduler_time": 73.71524546428277
}
#Debug simulation 
Total elapsed time: 5.220602917019278. Arrivals time: 0.5851554367691278 Scheduler time: 4.453435339033604 Scheduler overhead time: 0.05546378158032894 Adapter cache time: 0.04302174178883433 Engine time: 0.05724704638123512 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-16/adapters_256_slots_192_rate_3.2-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-16/adapters_256_slots_192_rate_3.2-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 135, 34560, 34560, 135, 34560, 270, 34560, 135, 270, 135, 34560, 270, 270, 270, 270, 34560, 135, 135, 135, 270, 34560, 135, 34560, 34560, 270, 270, 270, 135, 34560, 135, 270, 270, 135, 270, 135, 135, 270, 270, 34560, 270, 135, 270, 34560, 270, 270, 34560, 270, 34560, 135, 34560, 34560, 270, 135, 135, 34560, 270, 135, 270, 270, 34560, 270, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 34560, 34560, 135, 34560, 135, 270, 34560, 34560, 34560, 270, 135, 34560, 270, 135, 135, 135, 135, 135, 34560, 270, 135, 34560, 135, 34560, 135, 135, 270, 270, 34560, 270, 34560, 135, 270, 135, 34560, 34560, 135, 34560, 270, 135, 34560, 135, 135, 34560, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 135, 270, 34560, 34560, 135, 34560, 270, 135, 270, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 270, 34560, 34560, 270, 135, 34560, 135, 270, 270, 135, 270, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 270, 34560, 270, 34560, 135, 34560, 135, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 270, 270, 135, 270, 34560, 270, 270, 34560, 135, 34560, 34560, 270, 135, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 135, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 34560, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 34560, 270, 135, 135, 135, 135]
Prompts retrieved: 3006585 . Total input tokens: 670334443 . Total output tokens: 601394933
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.618827303871512,
    "estimated_duration": 3600.069963718644,
    "input_throughput": 5386.123379660912,
    "output_throughput": 4761.660237928565,
    "total_throughput": 10147.783617589477,
    "itl": 178.28119455731454,
    "ttft": 2119236.239989148,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 415,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2988914076029312,
    "arrivals": 1001073,
    "finished_requests": 78353,
    "scheduler_time": 78.42146913056858
}
#Debug simulation 
Total elapsed time: 5.618920447770506. Arrivals time: 0.37227774085476995 Scheduler time: 5.146722071338445 Scheduler overhead time: 0.030749722849577665 Adapter cache time: 0.023329796735197306 Engine time: 0.03156442800536752 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-32/adapters_256_slots_192_rate_3.2-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-32/adapters_256_slots_192_rate_3.2-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 135, 34560, 34560, 135, 34560, 270, 34560, 135, 270, 135, 34560, 270, 270, 270, 270, 34560, 135, 135, 135, 270, 34560, 135, 34560, 34560, 270, 270, 270, 135, 34560, 135, 270, 270, 135, 270, 135, 135, 270, 270, 34560, 270, 135, 270, 34560, 270, 270, 34560, 270, 34560, 135, 34560, 34560, 270, 135, 135, 34560, 270, 135, 270, 270, 34560, 270, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 34560, 34560, 135, 34560, 135, 270, 34560, 34560, 34560, 270, 135, 34560, 270, 135, 135, 135, 135, 135, 34560, 270, 135, 34560, 135, 34560, 135, 135, 270, 270, 34560, 270, 34560, 135, 270, 135, 34560, 34560, 135, 34560, 270, 135, 34560, 135, 135, 34560, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 135, 270, 34560, 34560, 135, 34560, 270, 135, 270, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 270, 34560, 34560, 270, 135, 34560, 135, 270, 270, 135, 270, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 270, 34560, 270, 34560, 135, 34560, 135, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 270, 270, 135, 270, 34560, 270, 270, 34560, 135, 34560, 34560, 270, 135, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 135, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 34560, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 34560, 270, 135, 135, 135, 135]
Prompts retrieved: 3006585 . Total input tokens: 670334443 . Total output tokens: 601394933
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 4.877524924930185,
    "estimated_duration": 3600.0720234461924,
    "input_throughput": 4336.90434477869,
    "output_throughput": 3856.633119997777,
    "total_throughput": 8193.537464776467,
    "itl": 87.37596709132188,
    "ttft": 2228953.6953922785,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 357,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.181725819427525,
    "arrivals": 1001073,
    "finished_requests": 63265,
    "scheduler_time": 73.7152810090786
}
#Debug simulation 
Total elapsed time: 4.877610933035612. Arrivals time: 0.23538216995075345 Scheduler time: 4.45892468560487 Scheduler overhead time: 0.055702569894492626 Adapter cache time: 0.043345572892576456 Engine time: 0.05754130519926548 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-16/adapters_256_slots_192_rate_3.2-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-16/adapters_256_slots_192_rate_3.2-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 135, 34560, 34560, 135, 34560, 270, 34560, 135, 270, 135, 34560, 270, 270, 270, 270, 34560, 135, 135, 135, 270, 34560, 135, 34560, 34560, 270, 270, 270, 135, 34560, 135, 270, 270, 135, 270, 135, 135, 270, 270, 34560, 270, 135, 270, 34560, 270, 270, 34560, 270, 34560, 135, 34560, 34560, 270, 135, 135, 34560, 270, 135, 270, 270, 34560, 270, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 34560, 34560, 135, 34560, 135, 270, 34560, 34560, 34560, 270, 135, 34560, 270, 135, 135, 135, 135, 135, 34560, 270, 135, 34560, 135, 34560, 135, 135, 270, 270, 34560, 270, 34560, 135, 270, 135, 34560, 34560, 135, 34560, 270, 135, 34560, 135, 135, 34560, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 135, 270, 34560, 34560, 135, 34560, 270, 135, 270, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 270, 34560, 34560, 270, 135, 34560, 135, 270, 270, 135, 270, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 270, 34560, 270, 34560, 135, 34560, 135, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 270, 270, 135, 270, 34560, 270, 270, 34560, 135, 34560, 34560, 270, 135, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 135, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 34560, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 34560, 270, 135, 135, 135, 135]
Prompts retrieved: 3006585 . Total input tokens: 670334443 . Total output tokens: 601394933
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.589838725980371,
    "estimated_duration": 3600.01188581106,
    "input_throughput": 5386.210272367326,
    "output_throughput": 4761.737056359175,
    "total_throughput": 10147.947328726501,
    "itl": 178.27866932818822,
    "ttft": 2119208.3694756753,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 415,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2408708723843958,
    "arrivals": 1001073,
    "finished_requests": 78353,
    "scheduler_time": 78.42141175819089
}
#Debug simulation 
Total elapsed time: 5.589968132786453. Arrivals time: 0.3784323022700846 Scheduler time: 5.112859115935862 Scheduler overhead time: 0.030637708492577076 Adapter cache time: 0.022194053512066603 Engine time: 0.03155793994665146 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-32/adapters_256_slots_192_rate_3.2-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-32/adapters_256_slots_192_rate_3.2-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 135, 34560, 34560, 135, 34560, 270, 34560, 135, 270, 135, 34560, 270, 270, 270, 270, 34560, 135, 135, 135, 270, 34560, 135, 34560, 34560, 270, 270, 270, 135, 34560, 135, 270, 270, 135, 270, 135, 135, 270, 270, 34560, 270, 135, 270, 34560, 270, 270, 34560, 270, 34560, 135, 34560, 34560, 270, 135, 135, 34560, 270, 135, 270, 270, 34560, 270, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 34560, 34560, 135, 34560, 135, 270, 34560, 34560, 34560, 270, 135, 34560, 270, 135, 135, 135, 135, 135, 34560, 270, 135, 34560, 135, 34560, 135, 135, 270, 270, 34560, 270, 34560, 135, 270, 135, 34560, 34560, 135, 34560, 270, 135, 34560, 135, 135, 34560, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 135, 270, 34560, 34560, 135, 34560, 270, 135, 270, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 270, 34560, 34560, 270, 135, 34560, 135, 270, 270, 135, 270, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 270, 34560, 270, 34560, 135, 34560, 135, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 270, 270, 135, 270, 34560, 270, 270, 34560, 135, 34560, 34560, 270, 135, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 135, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 34560, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 34560, 270, 135, 135, 135, 135]
Prompts retrieved: 3006585 . Total input tokens: 670334443 . Total output tokens: 601394933
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.857450575102121,
    "estimated_duration": 3600.087520343587,
    "input_throughput": 4336.885676187645,
    "output_throughput": 3856.616518776998,
    "total_throughput": 8193.502194964643,
    "itl": 87.37635586127169,
    "ttft": 2228960.9619040084,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 357,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.197193535156551,
    "arrivals": 1001073,
    "finished_requests": 63265,
    "scheduler_time": 73.71531019075616
}
#Debug simulation 
Total elapsed time: 4.857539732940495. Arrivals time: 0.33646900206804276 Scheduler time: 4.338081945199519 Scheduler overhead time: 0.05580003233626485 Adapter cache time: 0.043316833674907684 Engine time: 0.057365062180906534 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-8/adapters_256_slots_192_rate_3.2-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-8/adapters_256_slots_192_rate_3.2-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 66, 34560, 34560, 66, 34560, 270, 34560, 66, 270, 66, 34560, 270, 270, 270, 270, 34560, 66, 66, 66, 270, 34560, 66, 34560, 34560, 270, 270, 270, 66, 34560, 66, 270, 270, 66, 270, 66, 66, 270, 270, 34560, 270, 66, 270, 34560, 270, 270, 34560, 270, 34560, 66, 34560, 34560, 270, 66, 66, 34560, 270, 66, 270, 270, 34560, 270, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 34560, 34560, 66, 34560, 66, 270, 34560, 34560, 34560, 270, 66, 34560, 270, 66, 66, 66, 66, 66, 34560, 270, 66, 34560, 66, 34560, 66, 66, 270, 270, 34560, 270, 34560, 66, 270, 66, 34560, 34560, 66, 34560, 270, 66, 34560, 66, 66, 34560, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 66, 270, 34560, 34560, 66, 34560, 270, 66, 270, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 270, 34560, 34560, 270, 66, 34560, 66, 270, 270, 66, 270, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 270, 34560, 270, 34560, 66, 34560, 66, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 270, 270, 66, 270, 34560, 270, 270, 34560, 66, 34560, 34560, 270, 66, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 66, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 34560, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 34560, 270, 66, 66, 66, 66]
Prompts retrieved: 3000720 . Total input tokens: 669021209 . Total output tokens: 600212181
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.602185738738626,
    "estimated_duration": 3600.0833737146004,
    "input_throughput": 5435.240234397754,
    "output_throughput": 4822.297485318261,
    "total_throughput": 10257.537719716014,
    "itl": 178.83503009823724,
    "ttft": 2114910.4558116402,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 311,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9518116883630852,
    "arrivals": 999127,
    "finished_requests": 79272,
    "scheduler_time": 79.31372266938796
}
#Debug simulation 
Total elapsed time: 5.602282201871276. Arrivals time: 0.2708731945604086 Scheduler time: 5.235188173595816 Scheduler overhead time: 0.03061973536387086 Adapter cache time: 0.019823626149445772 Engine time: 0.031533678993582726 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-16/adapters_256_slots_192_rate_3.2-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-16/adapters_256_slots_192_rate_3.2-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 66, 34560, 34560, 66, 34560, 270, 34560, 66, 270, 66, 34560, 270, 270, 270, 270, 34560, 66, 66, 66, 270, 34560, 66, 34560, 34560, 270, 270, 270, 66, 34560, 66, 270, 270, 66, 270, 66, 66, 270, 270, 34560, 270, 66, 270, 34560, 270, 270, 34560, 270, 34560, 66, 34560, 34560, 270, 66, 66, 34560, 270, 66, 270, 270, 34560, 270, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 34560, 34560, 66, 34560, 66, 270, 34560, 34560, 34560, 270, 66, 34560, 270, 66, 66, 66, 66, 66, 34560, 270, 66, 34560, 66, 34560, 66, 66, 270, 270, 34560, 270, 34560, 66, 270, 66, 34560, 34560, 66, 34560, 270, 66, 34560, 66, 66, 34560, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 66, 270, 34560, 34560, 66, 34560, 270, 66, 270, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 270, 34560, 34560, 270, 66, 34560, 66, 270, 270, 66, 270, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 270, 34560, 270, 34560, 66, 34560, 66, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 270, 270, 66, 270, 34560, 270, 270, 34560, 66, 34560, 34560, 270, 66, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 66, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 34560, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 34560, 270, 66, 66, 66, 66]
Prompts retrieved: 3000720 . Total input tokens: 669021209 . Total output tokens: 600212181
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.573346097953618,
    "estimated_duration": 3600.0039711703366,
    "input_throughput": 5423.005406756054,
    "output_throughput": 4813.394690330497,
    "total_throughput": 10236.40009708655,
    "itl": 176.90075251761473,
    "ttft": 2115499.0807617935,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 312,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.016249136971315,
    "arrivals": 999127,
    "finished_requests": 79106,
    "scheduler_time": 79.27184053077077
}
#Debug simulation 
Total elapsed time: 5.573447696864605. Arrivals time: 0.2687961277551949 Scheduler time: 5.207283610478044 Scheduler overhead time: 0.03112119110301137 Adapter cache time: 0.019996780436486006 Engine time: 0.03182482812553644 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-32/adapters_256_slots_192_rate_3.2-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-32/adapters_256_slots_192_rate_3.2-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 66, 34560, 34560, 66, 34560, 270, 34560, 66, 270, 66, 34560, 270, 270, 270, 270, 34560, 66, 66, 66, 270, 34560, 66, 34560, 34560, 270, 270, 270, 66, 34560, 66, 270, 270, 66, 270, 66, 66, 270, 270, 34560, 270, 66, 270, 34560, 270, 270, 34560, 270, 34560, 66, 34560, 34560, 270, 66, 66, 34560, 270, 66, 270, 270, 34560, 270, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 34560, 34560, 66, 34560, 66, 270, 34560, 34560, 34560, 270, 66, 34560, 270, 66, 66, 66, 66, 66, 34560, 270, 66, 34560, 66, 34560, 66, 66, 270, 270, 34560, 270, 34560, 66, 270, 66, 34560, 34560, 66, 34560, 270, 66, 34560, 66, 66, 34560, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 66, 270, 34560, 34560, 66, 34560, 270, 66, 270, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 270, 34560, 34560, 270, 66, 34560, 66, 270, 270, 66, 270, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 270, 34560, 270, 34560, 66, 34560, 66, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 270, 270, 66, 270, 34560, 270, 270, 34560, 66, 34560, 34560, 270, 66, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 66, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 34560, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 34560, 270, 66, 66, 66, 66]
Prompts retrieved: 3000720 . Total input tokens: 669021209 . Total output tokens: 600212181
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.768205644097179,
    "estimated_duration": 3600.070959419535,
    "input_throughput": 4345.363237651941,
    "output_throughput": 3877.521625921164,
    "total_throughput": 8222.884863573105,
    "itl": 87.29251870579874,
    "ttft": 2224741.405863116,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 270,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8831291331723377,
    "arrivals": 999127,
    "finished_requests": 63389,
    "scheduler_time": 74.07970011062122
}
#Debug simulation 
Total elapsed time: 4.768313576001674. Arrivals time: 0.23275122931227088 Scheduler time: 4.355715184938163 Scheduler overhead time: 0.05587558355182409 Adapter cache time: 0.03971020085737109 Engine time: 0.0576026844792068 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-16/adapters_256_slots_192_rate_3.2-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-16/adapters_256_slots_192_rate_3.2-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 66, 34560, 34560, 66, 34560, 270, 34560, 66, 270, 66, 34560, 270, 270, 270, 270, 34560, 66, 66, 66, 270, 34560, 66, 34560, 34560, 270, 270, 270, 66, 34560, 66, 270, 270, 66, 270, 66, 66, 270, 270, 34560, 270, 66, 270, 34560, 270, 270, 34560, 270, 34560, 66, 34560, 34560, 270, 66, 66, 34560, 270, 66, 270, 270, 34560, 270, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 34560, 34560, 66, 34560, 66, 270, 34560, 34560, 34560, 270, 66, 34560, 270, 66, 66, 66, 66, 66, 34560, 270, 66, 34560, 66, 34560, 66, 66, 270, 270, 34560, 270, 34560, 66, 270, 66, 34560, 34560, 66, 34560, 270, 66, 34560, 66, 66, 34560, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 66, 270, 34560, 34560, 66, 34560, 270, 66, 270, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 270, 34560, 34560, 270, 66, 34560, 66, 270, 270, 66, 270, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 270, 34560, 270, 34560, 66, 34560, 66, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 270, 270, 66, 270, 34560, 270, 270, 34560, 66, 34560, 34560, 270, 66, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 66, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 34560, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 34560, 270, 66, 66, 66, 66]
Prompts retrieved: 3000720 . Total input tokens: 669021209 . Total output tokens: 600212181
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.5611422918736935,
    "estimated_duration": 3600.159764223878,
    "input_throughput": 5422.94294659139,
    "output_throughput": 4813.35749935413,
    "total_throughput": 10236.30044594552,
    "itl": 176.9000012074504,
    "ttft": 2115538.488939348,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 312,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9778411770379207,
    "arrivals": 999127,
    "finished_requests": 79109,
    "scheduler_time": 79.2760674793955
}
#Debug simulation 
Total elapsed time: 5.561241987161338. Arrivals time: 0.27163319988176227 Scheduler time: 5.191152798943222 Scheduler overhead time: 0.031145671382546425 Adapter cache time: 0.02097031380981207 Engine time: 0.03188943024724722 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-32/adapters_256_slots_192_rate_3.2-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-32/adapters_256_slots_192_rate_3.2-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 66, 34560, 34560, 66, 34560, 270, 34560, 66, 270, 66, 34560, 270, 270, 270, 270, 34560, 66, 66, 66, 270, 34560, 66, 34560, 34560, 270, 270, 270, 66, 34560, 66, 270, 270, 66, 270, 66, 66, 270, 270, 34560, 270, 66, 270, 34560, 270, 270, 34560, 270, 34560, 66, 34560, 34560, 270, 66, 66, 34560, 270, 66, 270, 270, 34560, 270, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 34560, 34560, 66, 34560, 66, 270, 34560, 34560, 34560, 270, 66, 34560, 270, 66, 66, 66, 66, 66, 34560, 270, 66, 34560, 66, 34560, 66, 66, 270, 270, 34560, 270, 34560, 66, 270, 66, 34560, 34560, 66, 34560, 270, 66, 34560, 66, 66, 34560, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 66, 270, 34560, 34560, 66, 34560, 270, 66, 270, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 270, 34560, 34560, 270, 66, 34560, 66, 270, 270, 66, 270, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 270, 34560, 270, 34560, 66, 34560, 66, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 270, 270, 66, 270, 34560, 270, 270, 34560, 66, 34560, 34560, 270, 66, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 66, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 34560, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 34560, 270, 66, 66, 66, 66]
Prompts retrieved: 3000720 . Total input tokens: 669021209 . Total output tokens: 600212181
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 4.799293532036245,
    "estimated_duration": 3600.0816803330454,
    "input_throughput": 4345.35029731681,
    "output_throughput": 3877.5100788014934,
    "total_throughput": 8222.860376118304,
    "itl": 87.2927643162872,
    "ttft": 2224747.364513824,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 270,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8938182050176009,
    "arrivals": 999127,
    "finished_requests": 63389,
    "scheduler_time": 74.07973195229083
}
#Debug simulation 
Total elapsed time: 4.799383912235498. Arrivals time: 0.23641812754794955 Scheduler time: 4.383333550300449 Scheduler overhead time: 0.055736917071044445 Adapter cache time: 0.03982084570452571 Engine time: 0.05748781794682145 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-16/adapters_256_slots_192_rate_3.2-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-16/adapters_256_slots_192_rate_3.2-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 66, 34560, 34560, 66, 34560, 270, 34560, 66, 270, 66, 34560, 270, 270, 270, 270, 34560, 66, 66, 66, 270, 34560, 66, 34560, 34560, 270, 270, 270, 66, 34560, 66, 270, 270, 66, 270, 66, 66, 270, 270, 34560, 270, 66, 270, 34560, 270, 270, 34560, 270, 34560, 66, 34560, 34560, 270, 66, 66, 34560, 270, 66, 270, 270, 34560, 270, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 34560, 34560, 66, 34560, 66, 270, 34560, 34560, 34560, 270, 66, 34560, 270, 66, 66, 66, 66, 66, 34560, 270, 66, 34560, 66, 34560, 66, 66, 270, 270, 34560, 270, 34560, 66, 270, 66, 34560, 34560, 66, 34560, 270, 66, 34560, 66, 66, 34560, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 66, 270, 34560, 34560, 66, 34560, 270, 66, 270, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 270, 34560, 34560, 270, 66, 34560, 66, 270, 270, 66, 270, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 270, 34560, 270, 34560, 66, 34560, 66, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 270, 270, 66, 270, 34560, 270, 270, 34560, 66, 34560, 34560, 270, 66, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 66, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 34560, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 34560, 270, 66, 66, 66, 66]
Prompts retrieved: 3000720 . Total input tokens: 669021209 . Total output tokens: 600212181
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.55681910738349,
    "estimated_duration": 3600.1147655650943,
    "input_throughput": 5423.010729196986,
    "output_throughput": 4813.417662611643,
    "total_throughput": 10236.42839180863,
    "itl": 176.89809735374845,
    "ttft": 2115515.0009076116,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 312,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9328956920094801,
    "arrivals": 999127,
    "finished_requests": 79109,
    "scheduler_time": 79.27601430563271
}
#Debug simulation 
Total elapsed time: 5.5569384172558784. Arrivals time: 0.2682439759373665 Scheduler time: 5.190937269944698 Scheduler overhead time: 0.031053587794303894 Adapter cache time: 0.019946258049458265 Engine time: 0.03220191365107894 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-32/adapters_256_slots_192_rate_3.2-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-32/adapters_256_slots_192_rate_3.2-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 66, 34560, 34560, 66, 34560, 270, 34560, 66, 270, 66, 34560, 270, 270, 270, 270, 34560, 66, 66, 66, 270, 34560, 66, 34560, 34560, 270, 270, 270, 66, 34560, 66, 270, 270, 66, 270, 66, 66, 270, 270, 34560, 270, 66, 270, 34560, 270, 270, 34560, 270, 34560, 66, 34560, 34560, 270, 66, 66, 34560, 270, 66, 270, 270, 34560, 270, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 34560, 34560, 66, 34560, 66, 270, 34560, 34560, 34560, 270, 66, 34560, 270, 66, 66, 66, 66, 66, 34560, 270, 66, 34560, 66, 34560, 66, 66, 270, 270, 34560, 270, 34560, 66, 270, 66, 34560, 34560, 66, 34560, 270, 66, 34560, 66, 66, 34560, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 66, 270, 34560, 34560, 66, 34560, 270, 66, 270, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 270, 34560, 34560, 270, 66, 34560, 66, 270, 270, 66, 270, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 270, 34560, 270, 34560, 66, 34560, 66, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 270, 270, 66, 270, 34560, 270, 270, 34560, 66, 34560, 34560, 270, 66, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 66, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 34560, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 34560, 270, 66, 66, 66, 66]
Prompts retrieved: 3000720 . Total input tokens: 669021209 . Total output tokens: 600212181
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.761164539959282,
    "estimated_duration": 3600.0014862585494,
    "input_throughput": 4345.447094872807,
    "output_throughput": 3877.5964546914215,
    "total_throughput": 8223.043549564229,
    "itl": 87.2930668402397,
    "ttft": 2224753.6342805945,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 270,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9060163222998425,
    "arrivals": 999127,
    "finished_requests": 63389,
    "scheduler_time": 74.07786341150695
}
#Debug simulation 
Total elapsed time: 4.761253907345235. Arrivals time: 0.22871947241947055 Scheduler time: 4.352668221574277 Scheduler overhead time: 0.05576256709173322 Adapter cache time: 0.03982393117621541 Engine time: 0.0577235990203917 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-8/adapters_256_slots_192_rate_3.2-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-8/adapters_256_slots_192_rate_3.2-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 33, 34560, 34560, 33, 34560, 270, 34560, 33, 270, 33, 34560, 270, 270, 270, 270, 34560, 33, 33, 33, 270, 34560, 33, 34560, 34560, 270, 270, 270, 33, 34560, 33, 270, 270, 33, 270, 33, 33, 270, 270, 34560, 270, 33, 270, 34560, 270, 270, 34560, 270, 34560, 33, 34560, 34560, 270, 33, 33, 34560, 270, 33, 270, 270, 34560, 270, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 34560, 34560, 33, 34560, 33, 270, 34560, 34560, 34560, 270, 33, 34560, 270, 33, 33, 33, 33, 33, 34560, 270, 33, 34560, 33, 34560, 33, 33, 270, 270, 34560, 270, 34560, 33, 270, 33, 34560, 34560, 33, 34560, 270, 33, 34560, 33, 33, 34560, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 33, 270, 34560, 34560, 33, 34560, 270, 33, 270, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 270, 34560, 34560, 270, 33, 34560, 33, 270, 270, 33, 270, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 270, 34560, 270, 34560, 33, 34560, 33, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 270, 270, 33, 270, 34560, 270, 270, 34560, 33, 34560, 34560, 270, 33, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 33, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 34560, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 34560, 270, 33, 33, 33, 33]
Prompts retrieved: 2997915 . Total input tokens: 668391315 . Total output tokens: 599640789
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.578161149751395,
    "estimated_duration": 3600.026752884299,
    "input_throughput": 5492.541960739004,
    "output_throughput": 4830.573824504826,
    "total_throughput": 10323.11578524383,
    "itl": 177.36465928163355,
    "ttft": 2110925.973266488,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 240,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.73451705854386,
    "arrivals": 998127,
    "finished_requests": 80102,
    "scheduler_time": 79.45761775106111
}
#Debug simulation 
Total elapsed time: 5.578288435935974. Arrivals time: 0.27374153258278966 Scheduler time: 5.208788211923093 Scheduler overhead time: 0.030600300524383783 Adapter cache time: 0.019278879277408123 Engine time: 0.031452450435608625 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-16/adapters_256_slots_192_rate_3.2-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-16/adapters_256_slots_192_rate_3.2-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 33, 34560, 34560, 33, 34560, 270, 34560, 33, 270, 33, 34560, 270, 270, 270, 270, 34560, 33, 33, 33, 270, 34560, 33, 34560, 34560, 270, 270, 270, 33, 34560, 33, 270, 270, 33, 270, 33, 33, 270, 270, 34560, 270, 33, 270, 34560, 270, 270, 34560, 270, 34560, 33, 34560, 34560, 270, 33, 33, 34560, 270, 33, 270, 270, 34560, 270, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 34560, 34560, 33, 34560, 33, 270, 34560, 34560, 34560, 270, 33, 34560, 270, 33, 33, 33, 33, 33, 34560, 270, 33, 34560, 33, 34560, 33, 33, 270, 270, 34560, 270, 34560, 33, 270, 33, 34560, 34560, 33, 34560, 270, 33, 34560, 33, 33, 34560, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 33, 270, 34560, 34560, 33, 34560, 270, 33, 270, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 270, 34560, 34560, 270, 33, 34560, 33, 270, 270, 33, 270, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 270, 34560, 270, 34560, 33, 34560, 33, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 270, 270, 33, 270, 34560, 270, 270, 34560, 33, 34560, 34560, 270, 33, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 33, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 34560, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 34560, 270, 33, 33, 33, 33]
Prompts retrieved: 2997915 . Total input tokens: 668391315 . Total output tokens: 599640789
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.651343864854425,
    "estimated_duration": 3600.0971077195636,
    "input_throughput": 5484.208733610075,
    "output_throughput": 4824.421808722206,
    "total_throughput": 10308.630542332281,
    "itl": 175.80470237850795,
    "ttft": 2111805.6425618,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 240,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7833959170454214,
    "arrivals": 998127,
    "finished_requests": 79994,
    "scheduler_time": 79.42376380571754
}
#Debug simulation 
Total elapsed time: 5.651438646949828. Arrivals time: 0.2710739830508828 Scheduler time: 5.283572419080883 Scheduler overhead time: 0.031089365482330322 Adapter cache time: 0.019068526569753885 Engine time: 0.03205445408821106 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-32/adapters_256_slots_192_rate_3.2-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-32/adapters_256_slots_192_rate_3.2-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 33, 34560, 34560, 33, 34560, 270, 34560, 33, 270, 33, 34560, 270, 270, 270, 270, 34560, 33, 33, 33, 270, 34560, 33, 34560, 34560, 270, 270, 270, 33, 34560, 33, 270, 270, 33, 270, 33, 33, 270, 270, 34560, 270, 33, 270, 34560, 270, 270, 34560, 270, 34560, 33, 34560, 34560, 270, 33, 33, 34560, 270, 33, 270, 270, 34560, 270, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 34560, 34560, 33, 34560, 33, 270, 34560, 34560, 34560, 270, 33, 34560, 270, 33, 33, 33, 33, 33, 34560, 270, 33, 34560, 33, 34560, 33, 33, 270, 270, 34560, 270, 34560, 33, 270, 33, 34560, 34560, 33, 34560, 270, 33, 34560, 33, 33, 34560, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 33, 270, 34560, 34560, 33, 34560, 270, 33, 270, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 270, 34560, 34560, 270, 33, 34560, 33, 270, 270, 33, 270, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 270, 34560, 270, 34560, 33, 34560, 33, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 270, 270, 33, 270, 34560, 270, 270, 34560, 33, 34560, 34560, 270, 33, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 33, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 34560, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 34560, 270, 33, 33, 33, 33]
Prompts retrieved: 2997915 . Total input tokens: 668391315 . Total output tokens: 599640789
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.804251150228083,
    "estimated_duration": 3600.0806961220665,
    "input_throughput": 4395.202312282695,
    "output_throughput": 3880.0027496734706,
    "total_throughput": 8275.205061956165,
    "itl": 87.24316645604911,
    "ttft": 2218958.6930824346,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 231,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.755326215717945,
    "arrivals": 998127,
    "finished_requests": 64044,
    "scheduler_time": 74.09570135992
}
#Debug simulation 
Total elapsed time: 4.804360398091376. Arrivals time: 0.24546049116179347 Scheduler time: 4.378226756118238 Scheduler overhead time: 0.055687632877379656 Adapter cache time: 0.039807337801903486 Engine time: 0.058406636118888855 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-16/adapters_256_slots_192_rate_3.2-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-16/adapters_256_slots_192_rate_3.2-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 33, 34560, 34560, 33, 34560, 270, 34560, 33, 270, 33, 34560, 270, 270, 270, 270, 34560, 33, 33, 33, 270, 34560, 33, 34560, 34560, 270, 270, 270, 33, 34560, 33, 270, 270, 33, 270, 33, 33, 270, 270, 34560, 270, 33, 270, 34560, 270, 270, 34560, 270, 34560, 33, 34560, 34560, 270, 33, 33, 34560, 270, 33, 270, 270, 34560, 270, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 34560, 34560, 33, 34560, 33, 270, 34560, 34560, 34560, 270, 33, 34560, 270, 33, 33, 33, 33, 33, 34560, 270, 33, 34560, 33, 34560, 33, 33, 270, 270, 34560, 270, 34560, 33, 270, 33, 34560, 34560, 33, 34560, 270, 33, 34560, 33, 33, 34560, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 33, 270, 34560, 34560, 33, 34560, 270, 33, 270, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 270, 34560, 34560, 270, 33, 34560, 33, 270, 270, 33, 270, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 270, 34560, 270, 34560, 33, 34560, 33, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 270, 270, 33, 270, 34560, 270, 270, 34560, 33, 34560, 34560, 270, 33, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 33, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 34560, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 34560, 270, 33, 33, 33, 33]
Prompts retrieved: 2997915 . Total input tokens: 668391315 . Total output tokens: 599640789
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.588574954774231,
    "estimated_duration": 3600.065987793015,
    "input_throughput": 5484.256140566931,
    "output_throughput": 4824.4635123056505,
    "total_throughput": 10308.719652872582,
    "itl": 175.80364445775425,
    "ttft": 2111786.029602749,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 240,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7523426728439537,
    "arrivals": 998127,
    "finished_requests": 79994,
    "scheduler_time": 79.42369712336766
}
#Debug simulation 
Total elapsed time: 5.588672903832048. Arrivals time: 0.27488034777343273 Scheduler time: 5.217229833360761 Scheduler overhead time: 0.031026361510157585 Adapter cache time: 0.019293272867798805 Engine time: 0.03176631359383464 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-32/adapters_256_slots_192_rate_3.2-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-32/adapters_256_slots_192_rate_3.2-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 33, 34560, 34560, 33, 34560, 270, 34560, 33, 270, 33, 34560, 270, 270, 270, 270, 34560, 33, 33, 33, 270, 34560, 33, 34560, 34560, 270, 270, 270, 33, 34560, 33, 270, 270, 33, 270, 33, 33, 270, 270, 34560, 270, 33, 270, 34560, 270, 270, 34560, 270, 34560, 33, 34560, 34560, 270, 33, 33, 34560, 270, 33, 270, 270, 34560, 270, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 34560, 34560, 33, 34560, 33, 270, 34560, 34560, 34560, 270, 33, 34560, 270, 33, 33, 33, 33, 33, 34560, 270, 33, 34560, 33, 34560, 33, 33, 270, 270, 34560, 270, 34560, 33, 270, 33, 34560, 34560, 33, 34560, 270, 33, 34560, 33, 33, 34560, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 33, 270, 34560, 34560, 33, 34560, 270, 33, 270, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 270, 34560, 34560, 270, 33, 34560, 33, 270, 270, 33, 270, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 270, 34560, 270, 34560, 33, 34560, 33, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 270, 270, 33, 270, 34560, 270, 270, 34560, 33, 34560, 34560, 270, 33, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 33, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 34560, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 34560, 270, 33, 33, 33, 33]
Prompts retrieved: 2997915 . Total input tokens: 668391315 . Total output tokens: 599640789
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 4.789763784967363,
    "estimated_duration": 3600.0899068948524,
    "input_throughput": 4395.191067227462,
    "output_throughput": 3879.992822748127,
    "total_throughput": 8275.18388997559,
    "itl": 87.24337174569266,
    "ttft": 2218964.184651237,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 231,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7645062421262295,
    "arrivals": 998127,
    "finished_requests": 64044,
    "scheduler_time": 74.09573210629878
}
#Debug simulation 
Total elapsed time: 4.78986035194248. Arrivals time: 0.23972087632864714 Scheduler time: 4.371020844206214 Scheduler overhead time: 0.05574747174978256 Adapter cache time: 0.03981404844671488 Engine time: 0.057156819850206375 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-16/adapters_256_slots_192_rate_3.2-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-16/adapters_256_slots_192_rate_3.2-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 33, 34560, 34560, 33, 34560, 270, 34560, 33, 270, 33, 34560, 270, 270, 270, 270, 34560, 33, 33, 33, 270, 34560, 33, 34560, 34560, 270, 270, 270, 33, 34560, 33, 270, 270, 33, 270, 33, 33, 270, 270, 34560, 270, 33, 270, 34560, 270, 270, 34560, 270, 34560, 33, 34560, 34560, 270, 33, 33, 34560, 270, 33, 270, 270, 34560, 270, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 34560, 34560, 33, 34560, 33, 270, 34560, 34560, 34560, 270, 33, 34560, 270, 33, 33, 33, 33, 33, 34560, 270, 33, 34560, 33, 34560, 33, 33, 270, 270, 34560, 270, 34560, 33, 270, 33, 34560, 34560, 33, 34560, 270, 33, 34560, 33, 33, 34560, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 33, 270, 34560, 34560, 33, 34560, 270, 33, 270, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 270, 34560, 34560, 270, 33, 34560, 33, 270, 270, 33, 270, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 270, 34560, 270, 34560, 33, 34560, 33, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 270, 270, 33, 270, 34560, 270, 270, 34560, 33, 34560, 34560, 270, 33, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 33, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 34560, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 34560, 270, 33, 33, 33, 33]
Prompts retrieved: 2997915 . Total input tokens: 668391315 . Total output tokens: 599640789
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.62490866985172,
    "estimated_duration": 3600.0312025307226,
    "input_throughput": 5484.30913213217,
    "output_throughput": 4824.510128631803,
    "total_throughput": 10308.819260763972,
    "itl": 175.80231670796485,
    "ttft": 2111764.3852663846,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 240,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7176120707765231,
    "arrivals": 998127,
    "finished_requests": 79994,
    "scheduler_time": 79.42364246313873
}
#Debug simulation 
Total elapsed time: 5.625030220951885. Arrivals time: 0.33787282602861524 Scheduler time: 5.1908699427731335 Scheduler overhead time: 0.03107702685520053 Adapter cache time: 0.019181689713150263 Engine time: 0.031628997065126896 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-32/adapters_256_slots_192_rate_3.2-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-32/adapters_256_slots_192_rate_3.2-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 33, 34560, 34560, 33, 34560, 270, 34560, 33, 270, 33, 34560, 270, 270, 270, 270, 34560, 33, 33, 33, 270, 34560, 33, 34560, 34560, 270, 270, 270, 33, 34560, 33, 270, 270, 33, 270, 33, 33, 270, 270, 34560, 270, 33, 270, 34560, 270, 270, 34560, 270, 34560, 33, 34560, 34560, 270, 33, 33, 34560, 270, 33, 270, 270, 34560, 270, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 34560, 34560, 33, 34560, 33, 270, 34560, 34560, 34560, 270, 33, 34560, 270, 33, 33, 33, 33, 33, 34560, 270, 33, 34560, 33, 34560, 33, 33, 270, 270, 34560, 270, 34560, 33, 270, 33, 34560, 34560, 33, 34560, 270, 33, 34560, 33, 33, 34560, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 33, 270, 34560, 34560, 33, 34560, 270, 33, 270, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 270, 34560, 34560, 270, 33, 34560, 33, 270, 270, 33, 270, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 270, 34560, 270, 34560, 33, 34560, 33, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 270, 270, 33, 270, 34560, 270, 270, 34560, 33, 34560, 34560, 270, 33, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 33, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 34560, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 34560, 270, 33, 33, 33, 33]
Prompts retrieved: 2997915 . Total input tokens: 668391315 . Total output tokens: 599640789
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.750308643095195,
    "estimated_duration": 3600.008594542613,
    "input_throughput": 4395.193951477303,
    "output_throughput": 3880.02045916634,
    "total_throughput": 8275.214410643643,
    "itl": 87.2434579651653,
    "ttft": 2218972.943257214,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 231,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.774818052612248,
    "arrivals": 998127,
    "finished_requests": 64043,
    "scheduler_time": 74.09385795600565
}
#Debug simulation 
Total elapsed time: 4.750399044714868. Arrivals time: 0.23222616594284773 Scheduler time: 4.340347319375724 Scheduler overhead time: 0.05500854877755046 Adapter cache time: 0.03971178596839309 Engine time: 0.056703096721321344 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-8/adapters_256_slots_192_rate_3.2-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-8/adapters_256_slots_192_rate_3.2-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 66, 34560, 34560, 66, 34560, 135, 34560, 66, 135, 66, 34560, 135, 135, 135, 135, 34560, 66, 66, 66, 135, 34560, 66, 34560, 34560, 135, 135, 135, 66, 34560, 66, 135, 135, 66, 135, 66, 66, 135, 135, 34560, 135, 66, 135, 34560, 135, 135, 34560, 135, 34560, 66, 34560, 34560, 135, 66, 66, 34560, 135, 66, 135, 135, 34560, 135, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 34560, 34560, 66, 34560, 66, 135, 34560, 34560, 34560, 135, 66, 34560, 135, 66, 66, 66, 66, 66, 34560, 135, 66, 34560, 66, 34560, 66, 66, 135, 135, 34560, 135, 34560, 66, 135, 66, 34560, 34560, 66, 34560, 135, 66, 34560, 66, 66, 34560, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 66, 135, 34560, 34560, 66, 34560, 135, 66, 135, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 135, 34560, 34560, 135, 66, 34560, 66, 135, 135, 66, 135, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 135, 34560, 135, 34560, 66, 34560, 66, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 135, 135, 66, 135, 34560, 135, 135, 34560, 66, 34560, 34560, 135, 66, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 66, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 34560, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 34560, 135, 66, 66, 66, 66]
Prompts retrieved: 2989245 . Total input tokens: 666447743 . Total output tokens: 597918174
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.616410608869046,
    "estimated_duration": 3600.181829155954,
    "input_throughput": 5527.239718518674,
    "output_throughput": 4886.678460938897,
    "total_throughput": 10413.91817945757,
    "itl": 176.22970968967672,
    "ttft": 2111051.020771297,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 266,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8140897398861114,
    "arrivals": 995247,
    "finished_requests": 80455,
    "scheduler_time": 80.29421655852802
}
#Debug simulation 
Total elapsed time: 5.616540847811848. Arrivals time: 0.27406704565510154 Scheduler time: 5.249355957843363 Scheduler overhead time: 0.031214790418744087 Adapter cache time: 0.01541323121637106 Engine time: 0.031904222909361124 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-16/adapters_256_slots_192_rate_3.2-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-16/adapters_256_slots_192_rate_3.2-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 66, 34560, 34560, 66, 34560, 135, 34560, 66, 135, 66, 34560, 135, 135, 135, 135, 34560, 66, 66, 66, 135, 34560, 66, 34560, 34560, 135, 135, 135, 66, 34560, 66, 135, 135, 66, 135, 66, 66, 135, 135, 34560, 135, 66, 135, 34560, 135, 135, 34560, 135, 34560, 66, 34560, 34560, 135, 66, 66, 34560, 135, 66, 135, 135, 34560, 135, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 34560, 34560, 66, 34560, 66, 135, 34560, 34560, 34560, 135, 66, 34560, 135, 66, 66, 66, 66, 66, 34560, 135, 66, 34560, 66, 34560, 66, 66, 135, 135, 34560, 135, 34560, 66, 135, 66, 34560, 34560, 66, 34560, 135, 66, 34560, 66, 66, 34560, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 66, 135, 34560, 34560, 66, 34560, 135, 66, 135, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 135, 34560, 34560, 135, 66, 34560, 66, 135, 135, 66, 135, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 135, 34560, 135, 34560, 66, 34560, 66, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 135, 135, 66, 135, 34560, 135, 135, 34560, 66, 34560, 34560, 135, 66, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 66, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 34560, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 34560, 135, 66, 66, 66, 66]
Prompts retrieved: 2989245 . Total input tokens: 666447743 . Total output tokens: 597918174
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.656862769741565,
    "estimated_duration": 3600.0766439853764,
    "input_throughput": 5513.589282373242,
    "output_throughput": 4875.395925062782,
    "total_throughput": 10388.985207436024,
    "itl": 174.32269556259226,
    "ttft": 2111966.951462635,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 266,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8668575591710436,
    "arrivals": 995247,
    "finished_requests": 80259,
    "scheduler_time": 80.24045573462911
}
#Debug simulation 
Total elapsed time: 5.656959129031748. Arrivals time: 0.3345099822618067 Scheduler time: 5.229212234728038 Scheduler overhead time: 0.03145047044381499 Adapter cache time: 0.015194492880254984 Engine time: 0.03202825179323554 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-32/adapters_256_slots_192_rate_3.2-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-32/adapters_256_slots_192_rate_3.2-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 66, 34560, 34560, 66, 34560, 135, 34560, 66, 135, 66, 34560, 135, 135, 135, 135, 34560, 66, 66, 66, 135, 34560, 66, 34560, 34560, 135, 135, 135, 66, 34560, 66, 135, 135, 66, 135, 66, 66, 135, 135, 34560, 135, 66, 135, 34560, 135, 135, 34560, 135, 34560, 66, 34560, 34560, 135, 66, 66, 34560, 135, 66, 135, 135, 34560, 135, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 34560, 34560, 66, 34560, 66, 135, 34560, 34560, 34560, 135, 66, 34560, 135, 66, 66, 66, 66, 66, 34560, 135, 66, 34560, 66, 34560, 66, 66, 135, 135, 34560, 135, 34560, 66, 135, 66, 34560, 34560, 66, 34560, 135, 66, 34560, 66, 66, 34560, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 66, 135, 34560, 34560, 66, 34560, 135, 66, 135, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 135, 34560, 34560, 135, 66, 34560, 66, 135, 135, 66, 135, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 135, 34560, 135, 34560, 66, 34560, 66, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 135, 135, 66, 135, 34560, 135, 135, 34560, 66, 34560, 34560, 135, 66, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 66, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 34560, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 34560, 135, 66, 66, 66, 66]
Prompts retrieved: 2989245 . Total input tokens: 666447743 . Total output tokens: 597918174
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.858669988811016,
    "estimated_duration": 3600.079061902484,
    "input_throughput": 4392.292982489038,
    "output_throughput": 3900.664890559111,
    "total_throughput": 8292.957873048148,
    "itl": 86.82697965127171,
    "ttft": 2224900.5916071404,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 233,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7607387584261631,
    "arrivals": 995247,
    "finished_requests": 63822,
    "scheduler_time": 74.49812026974209
}
#Debug simulation 
Total elapsed time: 4.858782391063869. Arrivals time: 0.30746694654226303 Scheduler time: 4.375964721199125 Scheduler overhead time: 0.055864498019218445 Adapter cache time: 0.03556409711018205 Engine time: 0.057497447822242975 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-16/adapters_256_slots_192_rate_3.2-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-16/adapters_256_slots_192_rate_3.2-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 66, 34560, 34560, 66, 34560, 135, 34560, 66, 135, 66, 34560, 135, 135, 135, 135, 34560, 66, 66, 66, 135, 34560, 66, 34560, 34560, 135, 135, 135, 66, 34560, 66, 135, 135, 66, 135, 66, 66, 135, 135, 34560, 135, 66, 135, 34560, 135, 135, 34560, 135, 34560, 66, 34560, 34560, 135, 66, 66, 34560, 135, 66, 135, 135, 34560, 135, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 34560, 34560, 66, 34560, 66, 135, 34560, 34560, 34560, 135, 66, 34560, 135, 66, 66, 66, 66, 66, 34560, 135, 66, 34560, 66, 34560, 66, 66, 135, 135, 34560, 135, 34560, 66, 135, 66, 34560, 34560, 66, 34560, 135, 66, 34560, 66, 66, 34560, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 66, 135, 34560, 34560, 66, 34560, 135, 66, 135, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 135, 34560, 34560, 135, 66, 34560, 66, 135, 135, 66, 135, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 135, 34560, 135, 34560, 66, 34560, 66, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 135, 135, 66, 135, 34560, 135, 135, 34560, 66, 34560, 34560, 135, 66, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 66, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 34560, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 34560, 135, 66, 66, 66, 66]
Prompts retrieved: 2989245 . Total input tokens: 666447743 . Total output tokens: 597918174
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 6.012691237963736,
    "estimated_duration": 3600.0406223493183,
    "input_throughput": 5513.644450780306,
    "output_throughput": 4875.444707772777,
    "total_throughput": 10389.089158553084,
    "itl": 174.3214266196406,
    "ttft": 2111946.5898621106,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 266,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8309011711482914,
    "arrivals": 995247,
    "finished_requests": 80259,
    "scheduler_time": 80.24039048658867
}
#Debug simulation 
Total elapsed time: 6.012759470380843. Arrivals time: 0.6268414254300296 Scheduler time: 5.291912586428225 Scheduler overhead time: 0.03150702454149723 Adapter cache time: 0.015372939873486757 Engine time: 0.032374769914895296 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-32/adapters_256_slots_192_rate_3.2-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-32/adapters_256_slots_192_rate_3.2-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 66, 34560, 34560, 66, 34560, 135, 34560, 66, 135, 66, 34560, 135, 135, 135, 135, 34560, 66, 66, 66, 135, 34560, 66, 34560, 34560, 135, 135, 135, 66, 34560, 66, 135, 135, 66, 135, 66, 66, 135, 135, 34560, 135, 66, 135, 34560, 135, 135, 34560, 135, 34560, 66, 34560, 34560, 135, 66, 66, 34560, 135, 66, 135, 135, 34560, 135, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 34560, 34560, 66, 34560, 66, 135, 34560, 34560, 34560, 135, 66, 34560, 135, 66, 66, 66, 66, 66, 34560, 135, 66, 34560, 66, 34560, 66, 66, 135, 135, 34560, 135, 34560, 66, 135, 66, 34560, 34560, 66, 34560, 135, 66, 34560, 66, 66, 34560, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 66, 135, 34560, 34560, 66, 34560, 135, 66, 135, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 135, 34560, 34560, 135, 66, 34560, 66, 135, 135, 66, 135, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 135, 34560, 135, 34560, 66, 34560, 66, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 135, 135, 66, 135, 34560, 135, 135, 34560, 66, 34560, 34560, 135, 66, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 66, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 34560, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 34560, 135, 66, 66, 66, 66]
Prompts retrieved: 2989245 . Total input tokens: 666447743 . Total output tokens: 597918174
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 4.818355342838913,
    "estimated_duration": 3600.0887792892277,
    "input_throughput": 4392.281126778744,
    "output_throughput": 3900.6543618550645,
    "total_throughput": 8292.935488633808,
    "itl": 86.82719693315964,
    "ttft": 2224906.1620754143,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 233,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7704217999801071,
    "arrivals": 995247,
    "finished_requests": 63822,
    "scheduler_time": 74.49815461493364
}
#Debug simulation 
Total elapsed time: 4.818459751084447. Arrivals time: 0.2981092049740255 Scheduler time: 4.344533798284829 Scheduler overhead time: 0.05564551195129752 Adapter cache time: 0.035895447712391615 Engine time: 0.05750567885115743 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-16/adapters_256_slots_192_rate_3.2-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-16/adapters_256_slots_192_rate_3.2-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 66, 34560, 34560, 66, 34560, 135, 34560, 66, 135, 66, 34560, 135, 135, 135, 135, 34560, 66, 66, 66, 135, 34560, 66, 34560, 34560, 135, 135, 135, 66, 34560, 66, 135, 135, 66, 135, 66, 66, 135, 135, 34560, 135, 66, 135, 34560, 135, 135, 34560, 135, 34560, 66, 34560, 34560, 135, 66, 66, 34560, 135, 66, 135, 135, 34560, 135, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 34560, 34560, 66, 34560, 66, 135, 34560, 34560, 34560, 135, 66, 34560, 135, 66, 66, 66, 66, 66, 34560, 135, 66, 34560, 66, 34560, 66, 66, 135, 135, 34560, 135, 34560, 66, 135, 66, 34560, 34560, 66, 34560, 135, 66, 34560, 66, 66, 34560, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 66, 135, 34560, 34560, 66, 34560, 135, 66, 135, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 135, 34560, 34560, 135, 66, 34560, 66, 135, 135, 66, 135, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 135, 34560, 135, 34560, 66, 34560, 66, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 135, 135, 66, 135, 34560, 135, 135, 34560, 66, 34560, 34560, 135, 66, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 66, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 34560, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 34560, 135, 66, 66, 66, 66]
Prompts retrieved: 2989245 . Total input tokens: 666447743 . Total output tokens: 597918174
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.642365835141391,
    "estimated_duration": 3600.0050281110725,
    "input_throughput": 5513.6989656969945,
    "output_throughput": 4875.492912633362,
    "total_throughput": 10389.191878330355,
    "itl": 174.32008145958793,
    "ttft": 2111927.7616142537,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 266,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7953533784439798,
    "arrivals": 995247,
    "finished_requests": 80259,
    "scheduler_time": 80.24034404104108
}
#Debug simulation 
Total elapsed time: 5.642472242936492. Arrivals time: 0.33357158256694674 Scheduler time: 5.216068984940648 Scheduler overhead time: 0.03108876058831811 Adapter cache time: 0.015336902812123299 Engine time: 0.03192764753475785 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-32/adapters_256_slots_192_rate_3.2-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-32/adapters_256_slots_192_rate_3.2-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 66, 34560, 34560, 66, 34560, 135, 34560, 66, 135, 66, 34560, 135, 135, 135, 135, 34560, 66, 66, 66, 135, 34560, 66, 34560, 34560, 135, 135, 135, 66, 34560, 66, 135, 135, 66, 135, 66, 66, 135, 135, 34560, 135, 66, 135, 34560, 135, 135, 34560, 135, 34560, 66, 34560, 34560, 135, 66, 66, 34560, 135, 66, 135, 135, 34560, 135, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 34560, 34560, 66, 34560, 66, 135, 34560, 34560, 34560, 135, 66, 34560, 135, 66, 66, 66, 66, 66, 34560, 135, 66, 34560, 66, 34560, 66, 66, 135, 135, 34560, 135, 34560, 66, 135, 66, 34560, 34560, 66, 34560, 135, 66, 34560, 66, 66, 34560, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 66, 135, 34560, 34560, 66, 34560, 135, 66, 135, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 135, 34560, 34560, 135, 66, 34560, 66, 135, 135, 66, 135, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 135, 34560, 135, 34560, 66, 34560, 66, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 135, 135, 66, 135, 34560, 135, 135, 34560, 66, 34560, 34560, 135, 66, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 66, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 34560, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 34560, 135, 66, 66, 66, 66]
Prompts retrieved: 2989245 . Total input tokens: 666447743 . Total output tokens: 597918174
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.1317273448221385,
    "estimated_duration": 3600.003986432105,
    "input_throughput": 4392.228191855701,
    "output_throughput": 3900.5965140380076,
    "total_throughput": 8292.824705893709,
    "itl": 86.82773927423835,
    "ttft": 2224919.448119527,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 233,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7799790877476364,
    "arrivals": 995247,
    "finished_requests": 63819,
    "scheduler_time": 74.49623417234567
}
#Debug simulation 
Total elapsed time: 5.1317932195961475. Arrivals time: 0.5894393711350858 Scheduler time: 4.366975520271808 Scheduler overhead time: 0.05582817690446973 Adapter cache time: 0.035627317149192095 Engine time: 0.05740736657753587 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-8/adapters_256_slots_192_rate_3.2-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-8/adapters_256_slots_192_rate_3.2-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 33, 34560, 34560, 33, 34560, 135, 34560, 33, 135, 33, 34560, 135, 135, 135, 135, 34560, 33, 33, 33, 135, 34560, 33, 34560, 34560, 135, 135, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 33, 135, 135, 34560, 135, 33, 135, 34560, 135, 135, 34560, 135, 34560, 33, 34560, 34560, 135, 33, 33, 34560, 135, 33, 135, 135, 34560, 135, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 34560, 34560, 33, 34560, 33, 135, 34560, 34560, 34560, 135, 33, 34560, 135, 33, 33, 33, 33, 33, 34560, 135, 33, 34560, 33, 34560, 33, 33, 135, 135, 34560, 135, 34560, 33, 135, 33, 34560, 34560, 33, 34560, 135, 33, 34560, 33, 33, 34560, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 33, 135, 34560, 34560, 33, 34560, 135, 33, 135, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 135, 34560, 34560, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 135, 34560, 135, 34560, 33, 34560, 33, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 135, 135, 33, 135, 34560, 135, 135, 34560, 33, 34560, 34560, 135, 33, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 33, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 34560, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 34560, 135, 33, 33, 33, 33]
Prompts retrieved: 2986440 . Total input tokens: 665820289 . Total output tokens: 597372628
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.735150491818786,
    "estimated_duration": 3600.151220639547,
    "input_throughput": 5608.928281743906,
    "output_throughput": 4904.303991114981,
    "total_throughput": 10513.232272858888,
    "itl": 174.32460696215745,
    "ttft": 2099981.82383253,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 236,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.722275107568129,
    "arrivals": 994382,
    "finished_requests": 81096,
    "scheduler_time": 80.64796037191796
}
#Debug simulation 
Total elapsed time: 5.735273859929293. Arrivals time: 0.27502856962382793 Scheduler time: 5.367758046835661 Scheduler overhead time: 0.03128828061744571 Adapter cache time: 0.014583960175514221 Engine time: 0.032097590155899525 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-16/adapters_256_slots_192_rate_3.2-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-16/adapters_256_slots_192_rate_3.2-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 33, 34560, 34560, 33, 34560, 135, 34560, 33, 135, 33, 34560, 135, 135, 135, 135, 34560, 33, 33, 33, 135, 34560, 33, 34560, 34560, 135, 135, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 33, 135, 135, 34560, 135, 33, 135, 34560, 135, 135, 34560, 135, 34560, 33, 34560, 34560, 135, 33, 33, 34560, 135, 33, 135, 135, 34560, 135, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 34560, 34560, 33, 34560, 33, 135, 34560, 34560, 34560, 135, 33, 34560, 135, 33, 33, 33, 33, 33, 34560, 135, 33, 34560, 33, 34560, 33, 33, 135, 135, 34560, 135, 34560, 33, 135, 33, 34560, 34560, 33, 34560, 135, 33, 34560, 33, 33, 34560, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 33, 135, 34560, 34560, 33, 34560, 135, 33, 135, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 135, 34560, 34560, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 135, 34560, 135, 34560, 33, 34560, 33, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 135, 135, 33, 135, 34560, 135, 135, 34560, 33, 34560, 34560, 135, 33, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 33, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 34560, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 34560, 135, 33, 33, 33, 33]
Prompts retrieved: 2986440 . Total input tokens: 665820289 . Total output tokens: 597372628
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.727953173220158,
    "estimated_duration": 3600.045177251542,
    "input_throughput": 5597.087816376616,
    "output_throughput": 4895.993003470148,
    "total_throughput": 10493.080819846764,
    "itl": 172.59866392217873,
    "ttft": 2100987.946599256,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 236,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7714357158658124,
    "arrivals": 994382,
    "finished_requests": 80928,
    "scheduler_time": 80.5918869696136
}
#Debug simulation 
Total elapsed time: 5.728047086857259. Arrivals time: 0.3753991867415607 Scheduler time: 5.259521002415568 Scheduler overhead time: 0.03163404995575547 Adapter cache time: 0.0142231909558177 Engine time: 0.03257769579067826 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-32/adapters_256_slots_192_rate_3.2-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-32/adapters_256_slots_192_rate_3.2-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 33, 34560, 34560, 33, 34560, 135, 34560, 33, 135, 33, 34560, 135, 135, 135, 135, 34560, 33, 33, 33, 135, 34560, 33, 34560, 34560, 135, 135, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 33, 135, 135, 34560, 135, 33, 135, 34560, 135, 135, 34560, 135, 34560, 33, 34560, 34560, 135, 33, 33, 34560, 135, 33, 135, 135, 34560, 135, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 34560, 34560, 33, 34560, 33, 135, 34560, 34560, 34560, 135, 33, 34560, 135, 33, 33, 33, 33, 33, 34560, 135, 33, 34560, 33, 34560, 33, 33, 135, 135, 34560, 135, 34560, 33, 135, 33, 34560, 34560, 33, 34560, 135, 33, 34560, 33, 33, 34560, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 33, 135, 34560, 34560, 33, 34560, 135, 33, 135, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 135, 34560, 34560, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 135, 34560, 135, 34560, 33, 34560, 33, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 135, 135, 33, 135, 34560, 135, 135, 34560, 33, 34560, 34560, 135, 33, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 33, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 34560, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 34560, 135, 33, 33, 33, 33]
Prompts retrieved: 2986440 . Total input tokens: 665820289 . Total output tokens: 597372628
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.9119797009043396,
    "estimated_duration": 3600.0813539054534,
    "input_throughput": 4455.207930954225,
    "output_throughput": 3902.880134849587,
    "total_throughput": 8358.088065803811,
    "itl": 86.40410614485087,
    "ttft": 2216388.3046754133,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 210,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6873653499595851,
    "arrivals": 994382,
    "finished_requests": 64392,
    "scheduler_time": 74.56412856126053
}
#Debug simulation 
Total elapsed time: 4.912093119230121. Arrivals time: 0.3447033748961985 Scheduler time: 4.393933012615889 Scheduler overhead time: 0.05598535016179085 Adapter cache time: 0.03240398783236742 Engine time: 0.05818440951406956 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-16/adapters_256_slots_192_rate_3.2-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-16/adapters_256_slots_192_rate_3.2-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 33, 34560, 34560, 33, 34560, 135, 34560, 33, 135, 33, 34560, 135, 135, 135, 135, 34560, 33, 33, 33, 135, 34560, 33, 34560, 34560, 135, 135, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 33, 135, 135, 34560, 135, 33, 135, 34560, 135, 135, 34560, 135, 34560, 33, 34560, 34560, 135, 33, 33, 34560, 135, 33, 135, 135, 34560, 135, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 34560, 34560, 33, 34560, 33, 135, 34560, 34560, 34560, 135, 33, 34560, 135, 33, 33, 33, 33, 33, 34560, 135, 33, 34560, 33, 34560, 33, 33, 135, 135, 34560, 135, 34560, 33, 135, 33, 34560, 34560, 33, 34560, 135, 33, 34560, 33, 33, 34560, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 33, 135, 34560, 34560, 33, 34560, 135, 33, 135, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 135, 34560, 34560, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 135, 34560, 135, 34560, 33, 34560, 33, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 135, 135, 33, 135, 34560, 135, 135, 34560, 33, 34560, 34560, 135, 33, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 33, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 34560, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 34560, 135, 33, 33, 33, 33]
Prompts retrieved: 2986440 . Total input tokens: 665820289 . Total output tokens: 597372628
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.746821483597159,
    "estimated_duration": 3600.0124240911687,
    "input_throughput": 5597.1387390661175,
    "output_throughput": 4896.037547550874,
    "total_throughput": 10493.17628661699,
    "itl": 172.59762004909516,
    "ttft": 2100968.812336281,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 236,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7387480903905836,
    "arrivals": 994382,
    "finished_requests": 80928,
    "scheduler_time": 80.59182143471126
}
#Debug simulation 
Total elapsed time: 5.746919829864055. Arrivals time: 0.38004307774826884 Scheduler time: 5.273703353013843 Scheduler overhead time: 0.03172453818842769 Adapter cache time: 0.014167053159326315 Engine time: 0.03253779513761401 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-32/adapters_256_slots_192_rate_3.2-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-32/adapters_256_slots_192_rate_3.2-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 33, 34560, 34560, 33, 34560, 135, 34560, 33, 135, 33, 34560, 135, 135, 135, 135, 34560, 33, 33, 33, 135, 34560, 33, 34560, 34560, 135, 135, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 33, 135, 135, 34560, 135, 33, 135, 34560, 135, 135, 34560, 135, 34560, 33, 34560, 34560, 135, 33, 33, 34560, 135, 33, 135, 135, 34560, 135, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 34560, 34560, 33, 34560, 33, 135, 34560, 34560, 34560, 135, 33, 34560, 135, 33, 33, 33, 33, 33, 34560, 135, 33, 34560, 33, 34560, 33, 33, 135, 135, 34560, 135, 34560, 33, 135, 33, 34560, 34560, 33, 34560, 135, 33, 34560, 33, 33, 34560, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 33, 135, 34560, 34560, 33, 34560, 135, 33, 135, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 135, 34560, 34560, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 135, 34560, 135, 34560, 33, 34560, 33, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 135, 135, 33, 135, 34560, 135, 135, 34560, 33, 34560, 34560, 135, 33, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 33, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 34560, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 34560, 135, 33, 33, 33, 33]
Prompts retrieved: 2986440 . Total input tokens: 665820289 . Total output tokens: 597372628
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 5.230524471029639,
    "estimated_duration": 3600.0904425493422,
    "input_throughput": 4455.196683515034,
    "output_throughput": 3902.8702817949898,
    "total_throughput": 8358.066965310023,
    "itl": 86.40428973227529,
    "ttft": 2216393.605037023,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 210,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6964196225814544,
    "arrivals": 994382,
    "finished_requests": 64392,
    "scheduler_time": 74.56416293253045
}
#Debug simulation 
Total elapsed time: 5.230591430794448. Arrivals time: 0.7046299944631755 Scheduler time: 4.352846995461732 Scheduler overhead time: 0.05598858743906021 Adapter cache time: 0.032517557963728905 Engine time: 0.058015184942632914 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-16/adapters_256_slots_192_rate_3.2-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-16/adapters_256_slots_192_rate_3.2-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 33, 34560, 34560, 33, 34560, 135, 34560, 33, 135, 33, 34560, 135, 135, 135, 135, 34560, 33, 33, 33, 135, 34560, 33, 34560, 34560, 135, 135, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 33, 135, 135, 34560, 135, 33, 135, 34560, 135, 135, 34560, 135, 34560, 33, 34560, 34560, 135, 33, 33, 34560, 135, 33, 135, 135, 34560, 135, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 34560, 34560, 33, 34560, 33, 135, 34560, 34560, 34560, 135, 33, 34560, 135, 33, 33, 33, 33, 33, 34560, 135, 33, 34560, 33, 34560, 33, 33, 135, 135, 34560, 135, 34560, 33, 135, 33, 34560, 34560, 33, 34560, 135, 33, 34560, 33, 33, 34560, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 33, 135, 34560, 34560, 33, 34560, 135, 33, 135, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 135, 34560, 34560, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 135, 34560, 135, 34560, 33, 34560, 33, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 135, 135, 33, 135, 34560, 135, 135, 34560, 33, 34560, 34560, 135, 33, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 33, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 34560, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 34560, 135, 33, 33, 33, 33]
Prompts retrieved: 2986440 . Total input tokens: 665820289 . Total output tokens: 597372628
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.751668537966907,
    "estimated_duration": 3600.012115580685,
    "input_throughput": 5597.139218724497,
    "output_throughput": 4896.037967126937,
    "total_throughput": 10493.177185851433,
    "itl": 172.60052549377218,
    "ttft": 2100969.0819885796,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 236,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7056518695969144,
    "arrivals": 994382,
    "finished_requests": 80928,
    "scheduler_time": 80.5929056386517
}
#Debug simulation 
Total elapsed time: 5.751769857015461. Arrivals time: 0.3807489308528602 Scheduler time: 5.277728472836316 Scheduler overhead time: 0.03145871590822935 Adapter cache time: 0.0147907929494977 Engine time: 0.0323963756673038 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-32/adapters_256_slots_192_rate_3.2-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-32/adapters_256_slots_192_rate_3.2-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 33, 34560, 34560, 33, 34560, 135, 34560, 33, 135, 33, 34560, 135, 135, 135, 135, 34560, 33, 33, 33, 135, 34560, 33, 34560, 34560, 135, 135, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 33, 135, 135, 34560, 135, 33, 135, 34560, 135, 135, 34560, 135, 34560, 33, 34560, 34560, 135, 33, 33, 34560, 135, 33, 135, 135, 34560, 135, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 34560, 34560, 33, 34560, 33, 135, 34560, 34560, 34560, 135, 33, 34560, 135, 33, 33, 33, 33, 33, 34560, 135, 33, 34560, 33, 34560, 33, 33, 135, 135, 34560, 135, 34560, 33, 135, 33, 34560, 34560, 33, 34560, 135, 33, 34560, 33, 33, 34560, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 33, 135, 34560, 34560, 33, 34560, 135, 33, 135, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 135, 34560, 34560, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 135, 34560, 135, 34560, 33, 34560, 33, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 135, 135, 33, 135, 34560, 135, 135, 34560, 33, 34560, 34560, 135, 33, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 33, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 34560, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 34560, 135, 33, 33, 33, 33]
Prompts retrieved: 2986440 . Total input tokens: 665820289 . Total output tokens: 597372628
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.877132225781679,
    "estimated_duration": 3600.00500311223,
    "input_throughput": 4455.233808323679,
    "output_throughput": 3902.9376314347232,
    "total_throughput": 8358.171439758402,
    "itl": 86.40433094171799,
    "ttft": 2216309.1910669673,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 210,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7053481414169093,
    "arrivals": 994382,
    "finished_requests": 64391,
    "scheduler_time": 74.56220650392376
}
#Debug simulation 
Total elapsed time: 4.877224083989859. Arrivals time: 0.33749793097376823 Scheduler time: 4.366686876863241 Scheduler overhead time: 0.05611034948378801 Adapter cache time: 0.03257908159866929 Engine time: 0.05755184683948755 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-8/adapters_256_slots_192_rate_3.2-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-8/adapters_256_slots_192_rate_3.2-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [66, 66, 34560, 33, 34560, 34560, 33, 34560, 66, 34560, 33, 66, 33, 34560, 66, 66, 66, 66, 34560, 33, 33, 33, 66, 34560, 33, 34560, 34560, 66, 66, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 33, 66, 66, 34560, 66, 33, 66, 34560, 66, 66, 34560, 66, 34560, 33, 34560, 34560, 66, 33, 33, 34560, 66, 33, 66, 66, 34560, 66, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 34560, 34560, 33, 34560, 33, 66, 34560, 34560, 34560, 66, 33, 34560, 66, 33, 33, 33, 33, 33, 34560, 66, 33, 34560, 33, 34560, 33, 33, 66, 66, 34560, 66, 34560, 33, 66, 33, 34560, 34560, 33, 34560, 66, 33, 34560, 33, 33, 34560, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 33, 66, 34560, 34560, 33, 34560, 66, 33, 66, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 66, 34560, 34560, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 66, 34560, 66, 34560, 33, 34560, 33, 66, 34560, 66, 34560, 66, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 66, 66, 33, 66, 34560, 66, 66, 34560, 33, 34560, 34560, 66, 33, 34560, 34560, 66, 66, 34560, 34560, 66, 66, 66, 66, 34560, 34560, 66, 66, 34560, 33, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 34560, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 34560, 66, 33, 33, 33, 33]
Prompts retrieved: 2980575 . Total input tokens: 664496257 . Total output tokens: 596195076
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.747891181148589,
    "estimated_duration": 3600.17024022481,
    "input_throughput": 5589.059865886654,
    "output_throughput": 4938.353970419412,
    "total_throughput": 10527.413836306067,
    "itl": 174.20418216289428,
    "ttft": 2103173.852024943,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 208,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.636581450738012,
    "arrivals": 992438,
    "finished_requests": 81531,
    "scheduler_time": 81.20108067311536
}
#Debug simulation 
Total elapsed time: 5.747989095747471. Arrivals time: 0.2754073478281498 Scheduler time: 5.3835406098514795 Scheduler overhead time: 0.031427101232111454 Adapter cache time: 0.011196311097592115 Engine time: 0.031834404449909925 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-16/adapters_256_slots_192_rate_3.2-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-16/adapters_256_slots_192_rate_3.2-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [66, 66, 34560, 33, 34560, 34560, 33, 34560, 66, 34560, 33, 66, 33, 34560, 66, 66, 66, 66, 34560, 33, 33, 33, 66, 34560, 33, 34560, 34560, 66, 66, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 33, 66, 66, 34560, 66, 33, 66, 34560, 66, 66, 34560, 66, 34560, 33, 34560, 34560, 66, 33, 33, 34560, 66, 33, 66, 66, 34560, 66, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 34560, 34560, 33, 34560, 33, 66, 34560, 34560, 34560, 66, 33, 34560, 66, 33, 33, 33, 33, 33, 34560, 66, 33, 34560, 33, 34560, 33, 33, 66, 66, 34560, 66, 34560, 33, 66, 33, 34560, 34560, 33, 34560, 66, 33, 34560, 33, 33, 34560, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 33, 66, 34560, 34560, 33, 34560, 66, 33, 66, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 66, 34560, 34560, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 66, 34560, 66, 34560, 33, 34560, 33, 66, 34560, 66, 34560, 66, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 66, 66, 33, 66, 34560, 66, 66, 34560, 33, 34560, 34560, 66, 33, 34560, 34560, 66, 66, 34560, 34560, 66, 66, 66, 66, 34560, 34560, 66, 66, 34560, 33, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 34560, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 34560, 66, 33, 33, 33, 33]
Prompts retrieved: 2980575 . Total input tokens: 664496257 . Total output tokens: 596195076
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.692604588344693,
    "estimated_duration": 3600.1186383723457,
    "input_throughput": 5577.983676970998,
    "output_throughput": 4928.728128810296,
    "total_throughput": 10506.711805781293,
    "itl": 172.4976066437998,
    "ttft": 2104553.425327668,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 208,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6779080199659823,
    "arrivals": 992438,
    "finished_requests": 81370,
    "scheduler_time": 81.1401560107541
}
#Debug simulation 
Total elapsed time: 5.692698918282986. Arrivals time: 0.28144635166972876 Scheduler time: 5.3209123611450195 Scheduler overhead time: 0.03159597795456648 Adapter cache time: 0.011414348147809505 Engine time: 0.03260938636958599 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-32/adapters_256_slots_192_rate_3.2-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-32/adapters_256_slots_192_rate_3.2-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [66, 66, 34560, 33, 34560, 34560, 33, 34560, 66, 34560, 33, 66, 33, 34560, 66, 66, 66, 66, 34560, 33, 33, 33, 66, 34560, 33, 34560, 34560, 66, 66, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 33, 66, 66, 34560, 66, 33, 66, 34560, 66, 66, 34560, 66, 34560, 33, 34560, 34560, 66, 33, 33, 34560, 66, 33, 66, 66, 34560, 66, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 34560, 34560, 33, 34560, 33, 66, 34560, 34560, 34560, 66, 33, 34560, 66, 33, 33, 33, 33, 33, 34560, 66, 33, 34560, 33, 34560, 33, 33, 66, 66, 34560, 66, 34560, 33, 66, 33, 34560, 34560, 33, 34560, 66, 33, 34560, 33, 33, 34560, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 33, 66, 34560, 34560, 33, 34560, 66, 33, 66, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 66, 34560, 34560, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 66, 34560, 66, 34560, 33, 34560, 33, 66, 34560, 66, 34560, 66, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 66, 66, 33, 66, 34560, 66, 66, 34560, 33, 34560, 34560, 66, 33, 34560, 34560, 66, 66, 34560, 34560, 66, 66, 66, 66, 34560, 34560, 66, 66, 34560, 33, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 34560, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 34560, 66, 33, 33, 33, 33]
Prompts retrieved: 2980575 . Total input tokens: 664496257 . Total output tokens: 596195076
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.7849894389510155,
    "estimated_duration": 3600.072917297106,
    "input_throughput": 4415.8886125939025,
    "output_throughput": 3919.682829811816,
    "total_throughput": 8335.571442405719,
    "itl": 86.53335551707082,
    "ttft": 2223111.154820569,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 197,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6430781400017467,
    "arrivals": 992438,
    "finished_requests": 64481,
    "scheduler_time": 74.80762226203906
}
#Debug simulation 
Total elapsed time: 4.7851127199828625. Arrivals time: 0.23050190415233374 Scheduler time: 4.38372663827613 Scheduler overhead time: 0.05630577402189374 Adapter cache time: 0.029924181289970875 Engine time: 0.05801806366071105 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-16/adapters_256_slots_192_rate_3.2-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-16/adapters_256_slots_192_rate_3.2-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [66, 66, 34560, 33, 34560, 34560, 33, 34560, 66, 34560, 33, 66, 33, 34560, 66, 66, 66, 66, 34560, 33, 33, 33, 66, 34560, 33, 34560, 34560, 66, 66, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 33, 66, 66, 34560, 66, 33, 66, 34560, 66, 66, 34560, 66, 34560, 33, 34560, 34560, 66, 33, 33, 34560, 66, 33, 66, 66, 34560, 66, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 34560, 34560, 33, 34560, 33, 66, 34560, 34560, 34560, 66, 33, 34560, 66, 33, 33, 33, 33, 33, 34560, 66, 33, 34560, 33, 34560, 33, 33, 66, 66, 34560, 66, 34560, 33, 66, 33, 34560, 34560, 33, 34560, 66, 33, 34560, 33, 33, 34560, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 33, 66, 34560, 34560, 33, 34560, 66, 33, 66, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 66, 34560, 34560, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 66, 34560, 66, 34560, 33, 34560, 33, 66, 34560, 66, 34560, 66, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 66, 66, 33, 66, 34560, 66, 66, 34560, 33, 34560, 34560, 66, 33, 34560, 34560, 66, 66, 34560, 34560, 66, 66, 66, 66, 34560, 34560, 66, 66, 34560, 33, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 34560, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 34560, 66, 33, 33, 33, 33]
Prompts retrieved: 2980575 . Total input tokens: 664496257 . Total output tokens: 596195076
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.665448299143463,
    "estimated_duration": 3600.0903839069333,
    "input_throughput": 5578.027454468245,
    "output_throughput": 4928.766810777577,
    "total_throughput": 10506.794265245822,
    "itl": 172.4967253546052,
    "ttft": 2104536.731951875,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 208,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6497149429935974,
    "arrivals": 992438,
    "finished_requests": 81370,
    "scheduler_time": 81.14009462230997
}
#Debug simulation 
Total elapsed time: 5.665540584363043. Arrivals time: 0.2729992079548538 Scheduler time: 5.3019644557498395 Scheduler overhead time: 0.031929558608680964 Adapter cache time: 0.01129284780472517 Engine time: 0.03256490593776107 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-32/adapters_256_slots_192_rate_3.2-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-32/adapters_256_slots_192_rate_3.2-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [66, 66, 34560, 33, 34560, 34560, 33, 34560, 66, 34560, 33, 66, 33, 34560, 66, 66, 66, 66, 34560, 33, 33, 33, 66, 34560, 33, 34560, 34560, 66, 66, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 33, 66, 66, 34560, 66, 33, 66, 34560, 66, 66, 34560, 66, 34560, 33, 34560, 34560, 66, 33, 33, 34560, 66, 33, 66, 66, 34560, 66, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 34560, 34560, 33, 34560, 33, 66, 34560, 34560, 34560, 66, 33, 34560, 66, 33, 33, 33, 33, 33, 34560, 66, 33, 34560, 33, 34560, 33, 33, 66, 66, 34560, 66, 34560, 33, 66, 33, 34560, 34560, 33, 34560, 66, 33, 34560, 33, 33, 34560, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 33, 66, 34560, 34560, 33, 34560, 66, 33, 66, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 66, 34560, 34560, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 66, 34560, 66, 34560, 33, 34560, 33, 66, 34560, 66, 34560, 66, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 66, 66, 33, 66, 34560, 66, 66, 34560, 33, 34560, 34560, 66, 33, 34560, 34560, 66, 66, 34560, 34560, 66, 66, 66, 66, 34560, 34560, 66, 66, 34560, 33, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 34560, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 34560, 66, 33, 33, 33, 33]
Prompts retrieved: 2980575 . Total input tokens: 664496257 . Total output tokens: 596195076
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 4.784104950260371,
    "estimated_duration": 3600.081124151945,
    "input_throughput": 4415.878545999407,
    "output_throughput": 3919.6738943831715,
    "total_throughput": 8335.552440382578,
    "itl": 86.53353245682452,
    "ttft": 2223115.730605224,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 197,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6512521361187124,
    "arrivals": 992438,
    "finished_requests": 64481,
    "scheduler_time": 74.80765512076447
}
#Debug simulation 
Total elapsed time: 4.784224766306579. Arrivals time: 0.2312621478922665 Scheduler time: 4.382863317150623 Scheduler overhead time: 0.05594659363850951 Adapter cache time: 0.02993968967348337 Engine time: 0.057485905941575766 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-16/adapters_256_slots_192_rate_3.2-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-16/adapters_256_slots_192_rate_3.2-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [66, 66, 34560, 33, 34560, 34560, 33, 34560, 66, 34560, 33, 66, 33, 34560, 66, 66, 66, 66, 34560, 33, 33, 33, 66, 34560, 33, 34560, 34560, 66, 66, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 33, 66, 66, 34560, 66, 33, 66, 34560, 66, 66, 34560, 66, 34560, 33, 34560, 34560, 66, 33, 33, 34560, 66, 33, 66, 66, 34560, 66, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 34560, 34560, 33, 34560, 33, 66, 34560, 34560, 34560, 66, 33, 34560, 66, 33, 33, 33, 33, 33, 34560, 66, 33, 34560, 33, 34560, 33, 33, 66, 66, 34560, 66, 34560, 33, 66, 33, 34560, 34560, 33, 34560, 66, 33, 34560, 33, 33, 34560, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 33, 66, 34560, 34560, 33, 34560, 66, 33, 66, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 66, 34560, 34560, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 66, 34560, 66, 34560, 33, 34560, 33, 66, 34560, 66, 34560, 66, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 66, 66, 33, 66, 34560, 66, 66, 34560, 33, 34560, 34560, 66, 33, 34560, 34560, 66, 66, 34560, 34560, 66, 66, 66, 66, 34560, 34560, 66, 66, 34560, 33, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 34560, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 34560, 66, 33, 33, 33, 33]
Prompts retrieved: 2980575 . Total input tokens: 664496257 . Total output tokens: 596195076
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.72871618391946,
    "estimated_duration": 3600.0625560048243,
    "input_throughput": 5578.070571719557,
    "output_throughput": 4928.804909348975,
    "total_throughput": 10506.875481068533,
    "itl": 172.4957271171882,
    "ttft": 2104520.166460747,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 208,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6219304613396534,
    "arrivals": 992438,
    "finished_requests": 81370,
    "scheduler_time": 81.1400512018514
}
#Debug simulation 
Total elapsed time: 5.728816237766296. Arrivals time: 0.3388382401317358 Scheduler time: 5.299899546429515 Scheduler overhead time: 0.03165002120658755 Adapter cache time: 0.011305319610983133 Engine time: 0.03248858777806163 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-32/adapters_256_slots_192_rate_3.2-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-32/adapters_256_slots_192_rate_3.2-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [66, 66, 34560, 33, 34560, 34560, 33, 34560, 66, 34560, 33, 66, 33, 34560, 66, 66, 66, 66, 34560, 33, 33, 33, 66, 34560, 33, 34560, 34560, 66, 66, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 33, 66, 66, 34560, 66, 33, 66, 34560, 66, 66, 34560, 66, 34560, 33, 34560, 34560, 66, 33, 33, 34560, 66, 33, 66, 66, 34560, 66, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 34560, 34560, 33, 34560, 33, 66, 34560, 34560, 34560, 66, 33, 34560, 66, 33, 33, 33, 33, 33, 34560, 66, 33, 34560, 33, 34560, 33, 33, 66, 66, 34560, 66, 34560, 33, 66, 33, 34560, 34560, 33, 34560, 66, 33, 34560, 33, 33, 34560, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 33, 66, 34560, 34560, 33, 34560, 66, 33, 66, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 66, 34560, 34560, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 66, 34560, 66, 34560, 33, 34560, 33, 66, 34560, 66, 34560, 66, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 66, 66, 33, 66, 34560, 66, 66, 34560, 33, 34560, 34560, 66, 33, 34560, 34560, 66, 66, 34560, 34560, 66, 66, 66, 66, 34560, 34560, 66, 66, 34560, 33, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 34560, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 34560, 66, 33, 33, 33, 33]
Prompts retrieved: 2980575 . Total input tokens: 664496257 . Total output tokens: 596195076
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.818855607882142,
    "estimated_duration": 3600.0891965167502,
    "input_throughput": 4415.868644416248,
    "output_throughput": 3919.6651054238246,
    "total_throughput": 8335.533749840073,
    "itl": 86.53371241359257,
    "ttft": 2223120.267088434,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 197,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6593003784492628,
    "arrivals": 992438,
    "finished_requests": 64481,
    "scheduler_time": 74.80767924324145
}
#Debug simulation 
Total elapsed time: 4.81895990204066. Arrivals time: 0.24417054932564497 Scheduler time: 4.404076303355396 Scheduler overhead time: 0.05610617296770215 Adapter cache time: 0.030132279731333256 Engine time: 0.057709140703082085 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-8/adapters_256_slots_192_rate_1.6-0.8-0.4_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-8/adapters_256_slots_192_rate_1.6-0.8-0.4_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 4320, 17280, 17280, 4320, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 8640, 8640, 8640, 8640, 17280, 4320, 4320, 4320, 8640, 17280, 4320, 17280, 17280, 8640, 8640, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 4320, 17280, 8640, 4320, 8640, 8640, 17280, 8640, 4320, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 17280, 17280, 4320, 17280, 4320, 8640, 17280, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 8640, 4320, 17280, 4320, 17280, 4320, 4320, 8640, 8640, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 17280, 4320, 17280, 8640, 4320, 8640, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 4320, 4320, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 17280, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 17280, 4320, 17280, 4320, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 17280, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 4320, 4320, 4320, 4320]
Prompts retrieved: 2587680 . Total input tokens: 577057570 . Total output tokens: 517693652
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.0691601750440896,
    "estimated_duration": 3600.020895074673,
    "input_throughput": 3684.974722827222,
    "output_throughput": 3241.8920167845076,
    "total_throughput": 6926.86673961173,
    "itl": 263.2433244282071,
    "ttft": 2275839.4464779045,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1102,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3726574938139757,
    "arrivals": 861811,
    "finished_requests": 53693,
    "scheduler_time": 53.55161535773404
}
#Debug simulation 
Total elapsed time: 5.06925582466647. Arrivals time: 0.22589671425521374 Scheduler time: 4.756851965561509 Scheduler overhead time: 0.022743874229490757 Adapter cache time: 0.030632661655545235 Engine time: 0.022849832195788622 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-16/adapters_256_slots_192_rate_1.6-0.8-0.4_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-16/adapters_256_slots_192_rate_1.6-0.8-0.4_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 4320, 17280, 17280, 4320, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 8640, 8640, 8640, 8640, 17280, 4320, 4320, 4320, 8640, 17280, 4320, 17280, 17280, 8640, 8640, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 4320, 17280, 8640, 4320, 8640, 8640, 17280, 8640, 4320, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 17280, 17280, 4320, 17280, 4320, 8640, 17280, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 8640, 4320, 17280, 4320, 17280, 4320, 4320, 8640, 8640, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 17280, 4320, 17280, 8640, 4320, 8640, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 4320, 4320, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 17280, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 17280, 4320, 17280, 4320, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 17280, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 4320, 4320, 4320, 4320]
Prompts retrieved: 2587680 . Total input tokens: 577057570 . Total output tokens: 517693652
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.046613511163741,
    "estimated_duration": 3600.040199501648,
    "input_throughput": 3673.246482589436,
    "output_throughput": 3234.3772165688197,
    "total_throughput": 6907.6236991582555,
    "itl": 260.73108482829275,
    "ttft": 2276806.3140757857,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1126,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.6691571677057104,
    "arrivals": 861811,
    "finished_requests": 53554,
    "scheduler_time": 53.49984265955186
}
#Debug simulation 
Total elapsed time: 5.046705387998372. Arrivals time: 0.23355582542717457 Scheduler time: 4.725935824215412 Scheduler overhead time: 0.022999120876193047 Adapter cache time: 0.0307942689396441 Engine time: 0.023024183232337236 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-32/adapters_256_slots_192_rate_1.6-0.8-0.4_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-32/adapters_256_slots_192_rate_1.6-0.8-0.4_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 4320, 17280, 17280, 4320, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 8640, 8640, 8640, 8640, 17280, 4320, 4320, 4320, 8640, 17280, 4320, 17280, 17280, 8640, 8640, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 4320, 17280, 8640, 4320, 8640, 8640, 17280, 8640, 4320, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 17280, 17280, 4320, 17280, 4320, 8640, 17280, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 8640, 4320, 17280, 4320, 17280, 4320, 4320, 8640, 8640, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 17280, 4320, 17280, 8640, 4320, 8640, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 4320, 4320, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 17280, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 17280, 4320, 17280, 4320, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 17280, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 4320, 4320, 4320, 4320]
Prompts retrieved: 2587680 . Total input tokens: 577057570 . Total output tokens: 517693652
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.5737863210961223,
    "estimated_duration": 3600.036771132754,
    "input_throughput": 2969.1213394569622,
    "output_throughput": 2627.801214659079,
    "total_throughput": 5596.922554116041,
    "itl": 129.0278326587395,
    "ttft": 2391771.918945708,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7168,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.43237034926193,
    "arrivals": 861811,
    "finished_requests": 43374,
    "scheduler_time": 50.229010559506015
}
#Debug simulation 
Total elapsed time: 3.5738816070370376. Arrivals time: 0.18915321538224816 Scheduler time: 3.076198191847652 Scheduler overhead time: 0.03937897179275751 Adapter cache time: 0.21043138252571225 Engine time: 0.040112551767379045 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-16-16/adapters_256_slots_192_rate_1.6-0.8-0.4_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-16-16/adapters_256_slots_192_rate_1.6-0.8-0.4_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 4320, 17280, 17280, 4320, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 8640, 8640, 8640, 8640, 17280, 4320, 4320, 4320, 8640, 17280, 4320, 17280, 17280, 8640, 8640, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 4320, 17280, 8640, 4320, 8640, 8640, 17280, 8640, 4320, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 17280, 17280, 4320, 17280, 4320, 8640, 17280, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 8640, 4320, 17280, 4320, 17280, 4320, 4320, 8640, 8640, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 17280, 4320, 17280, 8640, 4320, 8640, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 4320, 4320, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 17280, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 17280, 4320, 17280, 4320, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 17280, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 4320, 4320, 4320, 4320]
Prompts retrieved: 2587680 . Total input tokens: 577057570 . Total output tokens: 517693652
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.362297229003161,
    "estimated_duration": 3600.184092138818,
    "input_throughput": 3673.4552071594617,
    "output_throughput": 3234.3362733660497,
    "total_throughput": 6907.791480525511,
    "itl": 260.71993382766493,
    "ttft": 2276805.345928364,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1126,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.522880043704024,
    "arrivals": 861811,
    "finished_requests": 53557,
    "scheduler_time": 53.504091908386194
}
#Debug simulation 
Total elapsed time: 5.362413116265088. Arrivals time: 0.558597628492862 Scheduler time: 4.716348061338067 Scheduler overhead time: 0.022819326724857092 Adapter cache time: 0.031365794595330954 Engine time: 0.02299641165882349 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-16-32/adapters_256_slots_192_rate_1.6-0.8-0.4_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-16-32/adapters_256_slots_192_rate_1.6-0.8-0.4_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 4320, 17280, 17280, 4320, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 8640, 8640, 8640, 8640, 17280, 4320, 4320, 4320, 8640, 17280, 4320, 17280, 17280, 8640, 8640, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 4320, 17280, 8640, 4320, 8640, 8640, 17280, 8640, 4320, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 17280, 17280, 4320, 17280, 4320, 8640, 17280, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 8640, 4320, 17280, 4320, 17280, 4320, 4320, 8640, 8640, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 17280, 4320, 17280, 8640, 4320, 8640, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 4320, 4320, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 17280, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 17280, 4320, 17280, 4320, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 17280, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 4320, 4320, 4320, 4320]
Prompts retrieved: 2587680 . Total input tokens: 577057570 . Total output tokens: 517693652
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 3.562438868917525,
    "estimated_duration": 3600.0324584529676,
    "input_throughput": 2968.9037872155714,
    "output_throughput": 2627.7035302245977,
    "total_throughput": 5596.607317440169,
    "itl": 129.03950435896286,
    "ttft": 2391661.6817518133,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7168,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.715693630053753,
    "arrivals": 861811,
    "finished_requests": 43371,
    "scheduler_time": 50.22503715257404
}
#Debug simulation 
Total elapsed time: 3.562560509890318. Arrivals time: 0.1899949312210083 Scheduler time: 3.065347827039659 Scheduler overhead time: 0.039302677381783724 Adapter cache time: 0.20924535673111677 Engine time: 0.04019314469769597 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_16-16-16/adapters_256_slots_192_rate_1.6-0.8-0.4_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_16-16-16/adapters_256_slots_192_rate_1.6-0.8-0.4_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 4320, 17280, 17280, 4320, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 8640, 8640, 8640, 8640, 17280, 4320, 4320, 4320, 8640, 17280, 4320, 17280, 17280, 8640, 8640, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 4320, 17280, 8640, 4320, 8640, 8640, 17280, 8640, 4320, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 17280, 17280, 4320, 17280, 4320, 8640, 17280, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 8640, 4320, 17280, 4320, 17280, 4320, 4320, 8640, 8640, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 17280, 4320, 17280, 8640, 4320, 8640, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 4320, 4320, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 17280, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 17280, 4320, 17280, 4320, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 17280, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 4320, 4320, 4320, 4320]
Prompts retrieved: 2587680 . Total input tokens: 577057570 . Total output tokens: 517693652
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.0336473430506885,
    "estimated_duration": 3600.0279178963065,
    "input_throughput": 3673.614566780404,
    "output_throughput": 3234.4765833939277,
    "total_throughput": 6908.091150174331,
    "itl": 260.7098418263485,
    "ttft": 2276745.1829419434,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1126,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.366796632059767,
    "arrivals": 861811,
    "finished_requests": 53557,
    "scheduler_time": 53.50400107748097
}
#Debug simulation 
Total elapsed time: 5.033741049002856. Arrivals time: 0.2225586618296802 Scheduler time: 4.723577748518437 Scheduler overhead time: 0.022814588621258736 Adapter cache time: 0.031303069554269314 Engine time: 0.023128733038902283 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_16-16-32/adapters_256_slots_192_rate_1.6-0.8-0.4_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_16-16-32/adapters_256_slots_192_rate_1.6-0.8-0.4_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 4320, 17280, 17280, 4320, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 8640, 8640, 8640, 8640, 17280, 4320, 4320, 4320, 8640, 17280, 4320, 17280, 17280, 8640, 8640, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 4320, 17280, 8640, 4320, 8640, 8640, 17280, 8640, 4320, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 17280, 17280, 4320, 17280, 4320, 8640, 17280, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 8640, 4320, 17280, 4320, 17280, 4320, 4320, 8640, 8640, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 17280, 4320, 17280, 8640, 4320, 8640, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 4320, 4320, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 17280, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 17280, 4320, 17280, 4320, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 17280, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 4320, 4320, 4320, 4320]
Prompts retrieved: 2587680 . Total input tokens: 577057570 . Total output tokens: 517693652
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.934447650797665,
    "estimated_duration": 3600.0603167777076,
    "input_throughput": 2968.5552628644714,
    "output_throughput": 2627.4856995914242,
    "total_throughput": 5596.040962455896,
    "itl": 129.0522615279059,
    "ttft": 2391684.7847880535,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7166,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.029021209848995,
    "arrivals": 861811,
    "finished_requests": 43367,
    "scheduler_time": 50.22107831067956
}
#Debug simulation 
Total elapsed time: 3.9345475770533085. Arrivals time: 0.5316358492709696 Scheduler time: 3.0948435766622424 Scheduler overhead time: 0.03930286085233092 Adapter cache time: 0.20995768578723073 Engine time: 0.0400098143145442 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-8/adapters_256_slots_192_rate_1.6-0.8-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-8/adapters_256_slots_192_rate_1.6-0.8-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 1080, 17280, 17280, 1080, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 8640, 8640, 8640, 8640, 17280, 1080, 1080, 1080, 8640, 17280, 1080, 17280, 17280, 8640, 8640, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 1080, 17280, 8640, 1080, 8640, 8640, 17280, 8640, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 8640, 17280, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 8640, 1080, 17280, 1080, 17280, 1080, 1080, 8640, 8640, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 17280, 1080, 17280, 8640, 1080, 8640, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 17280, 1080, 17280, 1080, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 17280, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 1080, 1080, 1080, 1080]
Prompts retrieved: 2312280 . Total input tokens: 515501074 . Total output tokens: 462498738
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.044199367985129,
    "estimated_duration": 3600.078813683004,
    "input_throughput": 3706.8982904703353,
    "output_throughput": 3239.548244242112,
    "total_throughput": 6946.446534712447,
    "itl": 262.42537739308057,
    "ttft": 2272330.8026323565,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1604,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.909022341268272,
    "arrivals": 769968,
    "finished_requests": 53743,
    "scheduler_time": 53.502252972871496
}
#Debug simulation 
Total elapsed time: 4.044293075799942. Arrivals time: 0.21303607942536473 Scheduler time: 3.7346521178260446 Scheduler overhead time: 0.022106124088168144 Adapter cache time: 0.04190504178404808 Engine time: 0.022406811825931072 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-16/adapters_256_slots_192_rate_1.6-0.8-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-16/adapters_256_slots_192_rate_1.6-0.8-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 1080, 17280, 17280, 1080, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 8640, 8640, 8640, 8640, 17280, 1080, 1080, 1080, 8640, 17280, 1080, 17280, 17280, 8640, 8640, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 1080, 17280, 8640, 1080, 8640, 8640, 17280, 8640, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 8640, 17280, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 8640, 1080, 17280, 1080, 17280, 1080, 1080, 8640, 8640, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 17280, 1080, 17280, 8640, 1080, 8640, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 17280, 1080, 17280, 1080, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 17280, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 1080, 1080, 1080, 1080]
Prompts retrieved: 2312280 . Total input tokens: 515501074 . Total output tokens: 462498738
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.07002804428339,
    "estimated_duration": 3600.117125321327,
    "input_throughput": 3699.607689516828,
    "output_throughput": 3232.217340418168,
    "total_throughput": 6931.825029934997,
    "itl": 259.87874258109684,
    "ttft": 2273998.5566448597,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1654,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.401535563147506,
    "arrivals": 769968,
    "finished_requests": 53623,
    "scheduler_time": 53.44727421100172
}
#Debug simulation 
Total elapsed time: 4.0701194470748305. Arrivals time: 0.21523998863995075 Scheduler time: 3.757139638066292 Scheduler overhead time: 0.02239982597529888 Adapter cache time: 0.042539207264781 Engine time: 0.02254291670396924 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-32/adapters_256_slots_192_rate_1.6-0.8-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-32/adapters_256_slots_192_rate_1.6-0.8-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 1080, 17280, 17280, 1080, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 8640, 8640, 8640, 8640, 17280, 1080, 1080, 1080, 8640, 17280, 1080, 17280, 17280, 8640, 8640, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 1080, 17280, 8640, 1080, 8640, 8640, 17280, 8640, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 8640, 17280, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 8640, 1080, 17280, 1080, 17280, 1080, 1080, 8640, 8640, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 17280, 1080, 17280, 8640, 1080, 8640, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 17280, 1080, 17280, 1080, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 17280, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 1080, 1080, 1080, 1080]
Prompts retrieved: 2312280 . Total input tokens: 515501074 . Total output tokens: 462498738
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.7512250151485205,
    "estimated_duration": 3600.0887404963373,
    "input_throughput": 3234.6085997853884,
    "output_throughput": 2848.5508939388415,
    "total_throughput": 6083.15949372423,
    "itl": 118.17579471841506,
    "ttft": 2351724.1732334266,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2410,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.896397503931069,
    "arrivals": 769968,
    "finished_requests": 46896,
    "scheduler_time": 54.475924957187786
}
#Debug simulation 
Total elapsed time: 3.75131096271798. Arrivals time: 0.1939876745454967 Scheduler time: 3.285566983278841 Scheduler overhead time: 0.042295516934245825 Adapter cache time: 0.16563370171934366 Engine time: 0.043674292508512735 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-16-16/adapters_256_slots_192_rate_1.6-0.8-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-16-16/adapters_256_slots_192_rate_1.6-0.8-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 1080, 17280, 17280, 1080, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 8640, 8640, 8640, 8640, 17280, 1080, 1080, 1080, 8640, 17280, 1080, 17280, 17280, 8640, 8640, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 1080, 17280, 8640, 1080, 8640, 8640, 17280, 8640, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 8640, 17280, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 8640, 1080, 17280, 1080, 17280, 1080, 1080, 8640, 8640, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 17280, 1080, 17280, 8640, 1080, 8640, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 17280, 1080, 17280, 1080, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 17280, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 1080, 1080, 1080, 1080]
Prompts retrieved: 2312280 . Total input tokens: 515501074 . Total output tokens: 462498738
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.048131023999304,
    "estimated_duration": 3600.1767464039594,
    "input_throughput": 3699.7614112430706,
    "output_throughput": 3232.508518262119,
    "total_throughput": 6932.26992950519,
    "itl": 259.8584241977861,
    "ttft": 2274040.7423083433,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1654,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.172722184820909,
    "arrivals": 769968,
    "finished_requests": 53629,
    "scheduler_time": 53.45149454637764
}
#Debug simulation 
Total elapsed time: 4.048278168775141. Arrivals time: 0.22035552700981498 Scheduler time: 3.7295562853105366 Scheduler overhead time: 0.022468531504273415 Adapter cache time: 0.04280999023467302 Engine time: 0.02276874938979745 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-16-32/adapters_256_slots_192_rate_1.6-0.8-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-16-32/adapters_256_slots_192_rate_1.6-0.8-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 1080, 17280, 17280, 1080, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 8640, 8640, 8640, 8640, 17280, 1080, 1080, 1080, 8640, 17280, 1080, 17280, 17280, 8640, 8640, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 1080, 17280, 8640, 1080, 8640, 8640, 17280, 8640, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 8640, 17280, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 8640, 1080, 17280, 1080, 17280, 1080, 1080, 8640, 8640, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 17280, 1080, 17280, 8640, 1080, 8640, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 17280, 1080, 17280, 1080, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 17280, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 1080, 1080, 1080, 1080]
Prompts retrieved: 2312280 . Total input tokens: 515501074 . Total output tokens: 462498738
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 3.770734343677759,
    "estimated_duration": 3600.0468994626426,
    "input_throughput": 3234.743970068338,
    "output_throughput": 2848.584556365282,
    "total_throughput": 6083.32852643362,
    "itl": 118.1831572091073,
    "ttft": 2351809.844182368,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2407,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.989293282031859,
    "arrivals": 769968,
    "finished_requests": 46897,
    "scheduler_time": 54.47364468777003
}
#Debug simulation 
Total elapsed time: 3.7708517466671765. Arrivals time: 0.19535388564690948 Scheduler time: 3.3012368655763566 Scheduler overhead time: 0.04238521074876189 Adapter cache time: 0.16783829126507044 Engine time: 0.04380828933790326 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_16-16-16/adapters_256_slots_192_rate_1.6-0.8-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_16-16-16/adapters_256_slots_192_rate_1.6-0.8-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 1080, 17280, 17280, 1080, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 8640, 8640, 8640, 8640, 17280, 1080, 1080, 1080, 8640, 17280, 1080, 17280, 17280, 8640, 8640, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 1080, 17280, 8640, 1080, 8640, 8640, 17280, 8640, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 8640, 17280, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 8640, 1080, 17280, 1080, 17280, 1080, 1080, 8640, 8640, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 17280, 1080, 17280, 8640, 1080, 8640, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 17280, 1080, 17280, 1080, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 17280, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 1080, 1080, 1080, 1080]
Prompts retrieved: 2312280 . Total input tokens: 515501074 . Total output tokens: 462498738
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.023254929110408,
    "estimated_duration": 3600.237253261306,
    "input_throughput": 3699.7367292763906,
    "output_throughput": 3232.6166808749754,
    "total_throughput": 6932.353410151366,
    "itl": 259.84410437699364,
    "ttft": 2274016.26183896,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1654,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.94554318776806,
    "arrivals": 769968,
    "finished_requests": 53631,
    "scheduler_time": 53.45569758381544
}
#Debug simulation 
Total elapsed time: 4.023349123075604. Arrivals time: 0.2145686438307166 Scheduler time: 3.7117069480009377 Scheduler overhead time: 0.02236273791640997 Adapter cache time: 0.041762265376746655 Engine time: 0.022705318871885538 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_16-16-32/adapters_256_slots_192_rate_1.6-0.8-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_16-16-32/adapters_256_slots_192_rate_1.6-0.8-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 1080, 17280, 17280, 1080, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 8640, 8640, 8640, 8640, 17280, 1080, 1080, 1080, 8640, 17280, 1080, 17280, 17280, 8640, 8640, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 1080, 17280, 8640, 1080, 8640, 8640, 17280, 8640, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 8640, 17280, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 8640, 1080, 17280, 1080, 17280, 1080, 1080, 8640, 8640, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 17280, 1080, 17280, 8640, 1080, 8640, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 17280, 1080, 17280, 1080, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 17280, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 1080, 1080, 1080, 1080]
Prompts retrieved: 2312280 . Total input tokens: 515501074 . Total output tokens: 462498738
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.8221960542723536,
    "estimated_duration": 3600.0269769894176,
    "input_throughput": 3234.7618710731213,
    "output_throughput": 2848.6003203720284,
    "total_throughput": 6083.36219144515,
    "itl": 118.18686636547609,
    "ttft": 2351828.683765203,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2407,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.096184000484314,
    "arrivals": 769968,
    "finished_requests": 46897,
    "scheduler_time": 54.4717416836108
}
#Debug simulation 
Total elapsed time: 3.8222852433100343. Arrivals time: 0.24394300626590848 Scheduler time: 3.3030305691063404 Scheduler overhead time: 0.04242437658831477 Adapter cache time: 0.16887712059542537 Engine time: 0.04377597849816084 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-8/adapters_256_slots_192_rate_1.6-0.8-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-8/adapters_256_slots_192_rate_1.6-0.8-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 540, 17280, 17280, 540, 17280, 8640, 17280, 540, 8640, 540, 17280, 8640, 8640, 8640, 8640, 17280, 540, 540, 540, 8640, 17280, 540, 17280, 17280, 8640, 8640, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 540, 8640, 8640, 17280, 8640, 540, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 540, 17280, 17280, 8640, 540, 540, 17280, 8640, 540, 8640, 8640, 17280, 8640, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 8640, 540, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 540, 17280, 17280, 540, 17280, 540, 8640, 17280, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 540, 540, 540, 17280, 8640, 540, 17280, 540, 17280, 540, 540, 8640, 8640, 17280, 8640, 17280, 540, 8640, 540, 17280, 17280, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 17280, 540, 17280, 8640, 540, 8640, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 8640, 17280, 17280, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 17280, 540, 17280, 540, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 8640, 8640, 17280, 540, 17280, 17280, 8640, 540, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 540, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 17280, 540, 8640, 540, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 540, 540, 540, 540]
Prompts retrieved: 2266380 . Total input tokens: 505284175 . Total output tokens: 453316467
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.016205680090934,
    "estimated_duration": 3600.057904940224,
    "input_throughput": 3761.955878936029,
    "output_throughput": 3293.626467432301,
    "total_throughput": 7055.58234636833,
    "itl": 258.3651931698156,
    "ttft": 2263897.2859713454,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1326,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.0582067484549365,
    "arrivals": 754714,
    "finished_requests": 54692,
    "scheduler_time": 54.381258318834945
}
#Debug simulation 
Total elapsed time: 4.0163294821977615. Arrivals time: 0.2938169790431857 Scheduler time: 3.6275677867233753 Scheduler overhead time: 0.021652074065059423 Adapter cache time: 0.04112567147240043 Engine time: 0.022111026104539633 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-16/adapters_256_slots_192_rate_1.6-0.8-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-16/adapters_256_slots_192_rate_1.6-0.8-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 540, 17280, 17280, 540, 17280, 8640, 17280, 540, 8640, 540, 17280, 8640, 8640, 8640, 8640, 17280, 540, 540, 540, 8640, 17280, 540, 17280, 17280, 8640, 8640, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 540, 8640, 8640, 17280, 8640, 540, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 540, 17280, 17280, 8640, 540, 540, 17280, 8640, 540, 8640, 8640, 17280, 8640, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 8640, 540, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 540, 17280, 17280, 540, 17280, 540, 8640, 17280, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 540, 540, 540, 17280, 8640, 540, 17280, 540, 17280, 540, 540, 8640, 8640, 17280, 8640, 17280, 540, 8640, 540, 17280, 17280, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 17280, 540, 17280, 8640, 540, 8640, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 8640, 17280, 17280, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 17280, 540, 17280, 540, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 8640, 8640, 17280, 540, 17280, 17280, 8640, 540, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 540, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 17280, 540, 8640, 540, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 540, 540, 540, 540]
Prompts retrieved: 2266380 . Total input tokens: 505284175 . Total output tokens: 453316467
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.014021331910044,
    "estimated_duration": 3600.1480019660166,
    "input_throughput": 3756.72999904843,
    "output_throughput": 3289.4205998011594,
    "total_throughput": 7046.150598849589,
    "itl": 255.67094805070172,
    "ttft": 2265145.9083963046,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1314,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.289715753684266,
    "arrivals": 754714,
    "finished_requests": 54623,
    "scheduler_time": 54.380474699298354
}
#Debug simulation 
Total elapsed time: 4.014111193828285. Arrivals time: 0.29409174900501966 Scheduler time: 3.6243217955343425 Scheduler overhead time: 0.021782678551971912 Adapter cache time: 0.04135420313104987 Engine time: 0.022446358110755682 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-32/adapters_256_slots_192_rate_1.6-0.8-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-32/adapters_256_slots_192_rate_1.6-0.8-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 540, 17280, 17280, 540, 17280, 8640, 17280, 540, 8640, 540, 17280, 8640, 8640, 8640, 8640, 17280, 540, 540, 540, 8640, 17280, 540, 17280, 17280, 8640, 8640, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 540, 8640, 8640, 17280, 8640, 540, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 540, 17280, 17280, 8640, 540, 540, 17280, 8640, 540, 8640, 8640, 17280, 8640, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 8640, 540, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 540, 17280, 17280, 540, 17280, 540, 8640, 17280, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 540, 540, 540, 17280, 8640, 540, 17280, 540, 17280, 540, 540, 8640, 8640, 17280, 8640, 17280, 540, 8640, 540, 17280, 17280, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 17280, 540, 17280, 8640, 540, 8640, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 8640, 17280, 17280, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 17280, 540, 17280, 540, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 8640, 8640, 17280, 540, 17280, 17280, 8640, 540, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 540, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 17280, 540, 8640, 540, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 540, 540, 540, 540]
Prompts retrieved: 2266380 . Total input tokens: 505284175 . Total output tokens: 453316467
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.939439085777849,
    "estimated_duration": 3600.0839934749174,
    "input_throughput": 3297.8813887450815,
    "output_throughput": 2911.7948411758452,
    "total_throughput": 6209.676229920927,
    "itl": 115.89635691845177,
    "ttft": 2340878.5860410556,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1135,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.710701989196189,
    "arrivals": 754714,
    "finished_requests": 48004,
    "scheduler_time": 55.64078090751692
}
#Debug simulation 
Total elapsed time: 3.9395476188510656. Arrivals time: 0.284276535268873 Scheduler time: 3.3925845469348133 Scheduler overhead time: 0.04323594504967332 Adapter cache time: 0.15403783274814487 Engine time: 0.04487251536920667 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-16-16/adapters_256_slots_192_rate_1.6-0.8-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-16-16/adapters_256_slots_192_rate_1.6-0.8-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 540, 17280, 17280, 540, 17280, 8640, 17280, 540, 8640, 540, 17280, 8640, 8640, 8640, 8640, 17280, 540, 540, 540, 8640, 17280, 540, 17280, 17280, 8640, 8640, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 540, 8640, 8640, 17280, 8640, 540, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 540, 17280, 17280, 8640, 540, 540, 17280, 8640, 540, 8640, 8640, 17280, 8640, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 8640, 540, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 540, 17280, 17280, 540, 17280, 540, 8640, 17280, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 540, 540, 540, 17280, 8640, 540, 17280, 540, 17280, 540, 540, 8640, 8640, 17280, 8640, 17280, 540, 8640, 540, 17280, 17280, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 17280, 540, 17280, 8640, 540, 8640, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 8640, 17280, 17280, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 17280, 540, 17280, 540, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 8640, 8640, 17280, 540, 17280, 17280, 8640, 540, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 540, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 17280, 540, 8640, 540, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 540, 540, 540, 540]
Prompts retrieved: 2266380 . Total input tokens: 505284175 . Total output tokens: 453316467
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 3.992067702114582,
    "estimated_duration": 3600.098118481399,
    "input_throughput": 3756.78205284723,
    "output_throughput": 3289.466178492765,
    "total_throughput": 7046.248231339994,
    "itl": 255.63195324742267,
    "ttft": 2265174.365721403,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1315,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.122730151507952,
    "arrivals": 754714,
    "finished_requests": 54623,
    "scheduler_time": 54.38134760600538
}
#Debug simulation 
Total elapsed time: 3.992206502240151. Arrivals time: 0.29074804903939366 Scheduler time: 3.6055765780620277 Scheduler overhead time: 0.021910535171628 Adapter cache time: 0.04154308373108506 Engine time: 0.02228641789406538 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-16-32/adapters_256_slots_192_rate_1.6-0.8-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-16-32/adapters_256_slots_192_rate_1.6-0.8-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 540, 17280, 17280, 540, 17280, 8640, 17280, 540, 8640, 540, 17280, 8640, 8640, 8640, 8640, 17280, 540, 540, 540, 8640, 17280, 540, 17280, 17280, 8640, 8640, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 540, 8640, 8640, 17280, 8640, 540, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 540, 17280, 17280, 8640, 540, 540, 17280, 8640, 540, 8640, 8640, 17280, 8640, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 8640, 540, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 540, 17280, 17280, 540, 17280, 540, 8640, 17280, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 540, 540, 540, 17280, 8640, 540, 17280, 540, 17280, 540, 540, 8640, 8640, 17280, 8640, 17280, 540, 8640, 540, 17280, 17280, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 17280, 540, 17280, 8640, 540, 8640, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 8640, 17280, 17280, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 17280, 540, 17280, 540, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 8640, 8640, 17280, 540, 17280, 17280, 8640, 540, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 540, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 17280, 540, 8640, 540, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 540, 540, 540, 540]
Prompts retrieved: 2266380 . Total input tokens: 505284175 . Total output tokens: 453316467
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 3.9142570439726114,
    "estimated_duration": 3600.0682188030964,
    "input_throughput": 3298.014725939667,
    "output_throughput": 2911.900098239045,
    "total_throughput": 6209.9148241787125,
    "itl": 115.89157438778473,
    "ttft": 2340924.4644915867,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1135,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7572709040343724,
    "arrivals": 754714,
    "finished_requests": 48007,
    "scheduler_time": 55.642424007708726
}
#Debug simulation 
Total elapsed time: 3.914349263999611. Arrivals time: 0.19978249398991466 Scheduler time: 3.4518678579479456 Scheduler overhead time: 0.04343235120177269 Adapter cache time: 0.15403920225799084 Engine time: 0.04468162544071674 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_16-16-16/adapters_256_slots_192_rate_1.6-0.8-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_16-16-16/adapters_256_slots_192_rate_1.6-0.8-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 540, 17280, 17280, 540, 17280, 8640, 17280, 540, 8640, 540, 17280, 8640, 8640, 8640, 8640, 17280, 540, 540, 540, 8640, 17280, 540, 17280, 17280, 8640, 8640, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 540, 8640, 8640, 17280, 8640, 540, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 540, 17280, 17280, 8640, 540, 540, 17280, 8640, 540, 8640, 8640, 17280, 8640, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 8640, 540, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 540, 17280, 17280, 540, 17280, 540, 8640, 17280, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 540, 540, 540, 17280, 8640, 540, 17280, 540, 17280, 540, 540, 8640, 8640, 17280, 8640, 17280, 540, 8640, 540, 17280, 17280, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 17280, 540, 17280, 8640, 540, 8640, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 8640, 17280, 17280, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 17280, 540, 17280, 540, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 8640, 8640, 17280, 540, 17280, 17280, 8640, 540, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 540, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 17280, 540, 8640, 540, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 540, 540, 540, 540]
Prompts retrieved: 2266380 . Total input tokens: 505284175 . Total output tokens: 453316467
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.024400005117059,
    "estimated_duration": 3600.038326867996,
    "input_throughput": 3757.3105539039943,
    "output_throughput": 3290.111638979311,
    "total_throughput": 7047.422192883306,
    "itl": 255.70965269249209,
    "ttft": 2265045.2529886267,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1317,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.9378962383860623,
    "arrivals": 754714,
    "finished_requests": 54632,
    "scheduler_time": 54.3861818901705
}
#Debug simulation 
Total elapsed time: 4.0244958638213575. Arrivals time: 0.21491832565516233 Scheduler time: 3.7127104667015374 Scheduler overhead time: 0.022019512485712767 Adapter cache time: 0.04213649407029152 Engine time: 0.022512424737215042 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_16-16-32/adapters_256_slots_192_rate_1.6-0.8-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_16-16-32/adapters_256_slots_192_rate_1.6-0.8-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 540, 17280, 17280, 540, 17280, 8640, 17280, 540, 8640, 540, 17280, 8640, 8640, 8640, 8640, 17280, 540, 540, 540, 8640, 17280, 540, 17280, 17280, 8640, 8640, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 540, 8640, 8640, 17280, 8640, 540, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 540, 17280, 17280, 8640, 540, 540, 17280, 8640, 540, 8640, 8640, 17280, 8640, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 8640, 540, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 540, 17280, 17280, 540, 17280, 540, 8640, 17280, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 540, 540, 540, 17280, 8640, 540, 17280, 540, 17280, 540, 540, 8640, 8640, 17280, 8640, 17280, 540, 8640, 540, 17280, 17280, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 17280, 540, 17280, 8640, 540, 8640, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 8640, 17280, 17280, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 17280, 540, 17280, 540, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 8640, 8640, 17280, 540, 17280, 17280, 8640, 540, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 540, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 17280, 540, 8640, 540, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 540, 540, 540, 540]
Prompts retrieved: 2266380 . Total input tokens: 505284175 . Total output tokens: 453316467
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.9231231547892094,
    "estimated_duration": 3600.1168013335046,
    "input_throughput": 3297.9702201890063,
    "output_throughput": 2911.8608029931197,
    "total_throughput": 6209.831023182126,
    "itl": 115.89319158437885,
    "ttft": 2340941.879680454,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1135,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.8058118655905684,
    "arrivals": 754714,
    "finished_requests": 48007,
    "scheduler_time": 55.642465576604195
}
#Debug simulation 
Total elapsed time: 3.923217082861811. Arrivals time: 0.27730574226006866 Scheduler time: 3.3828247021883726 Scheduler overhead time: 0.04330992139875889 Adapter cache time: 0.1543533280491829 Engine time: 0.04492916399613023 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-8/adapters_256_slots_192_rate_1.6-0.8-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-8/adapters_256_slots_192_rate_1.6-0.8-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 270, 17280, 17280, 270, 17280, 8640, 17280, 270, 8640, 270, 17280, 8640, 8640, 8640, 8640, 17280, 270, 270, 270, 8640, 17280, 270, 17280, 17280, 8640, 8640, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 270, 8640, 8640, 17280, 8640, 270, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 270, 17280, 17280, 8640, 270, 270, 17280, 8640, 270, 8640, 8640, 17280, 8640, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 8640, 270, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 270, 17280, 17280, 270, 17280, 270, 8640, 17280, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 270, 270, 270, 17280, 8640, 270, 17280, 270, 17280, 270, 270, 8640, 8640, 17280, 8640, 17280, 270, 8640, 270, 17280, 17280, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 17280, 270, 17280, 8640, 270, 8640, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 8640, 17280, 17280, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 17280, 270, 17280, 270, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 8640, 8640, 17280, 270, 17280, 17280, 8640, 270, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 270, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 17280, 270, 8640, 270, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 270, 270, 270, 270]
Prompts retrieved: 2243430 . Total input tokens: 500187779 . Total output tokens: 448743425
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.102589251007885,
    "estimated_duration": 3600.045885489022,
    "input_throughput": 3844.8462714857274,
    "output_throughput": 3397.0292015705177,
    "total_throughput": 7241.875473056245,
    "itl": 252.35317065868378,
    "ttft": 2246836.5509585766,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 634,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9403492296533973,
    "arrivals": 746983,
    "finished_requests": 55932,
    "scheduler_time": 56.03545915827967
}
#Debug simulation 
Total elapsed time: 4.102683945093304. Arrivals time: 0.21694805286824703 Scheduler time: 3.8019192717038095 Scheduler overhead time: 0.022014389745891094 Adapter cache time: 0.02879228862002492 Engine time: 0.02281924430280924 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-16/adapters_256_slots_192_rate_1.6-0.8-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-16/adapters_256_slots_192_rate_1.6-0.8-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 270, 17280, 17280, 270, 17280, 8640, 17280, 270, 8640, 270, 17280, 8640, 8640, 8640, 8640, 17280, 270, 270, 270, 8640, 17280, 270, 17280, 17280, 8640, 8640, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 270, 8640, 8640, 17280, 8640, 270, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 270, 17280, 17280, 8640, 270, 270, 17280, 8640, 270, 8640, 8640, 17280, 8640, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 8640, 270, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 270, 17280, 17280, 270, 17280, 270, 8640, 17280, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 270, 270, 270, 17280, 8640, 270, 17280, 270, 17280, 270, 270, 8640, 8640, 17280, 8640, 17280, 270, 8640, 270, 17280, 17280, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 17280, 270, 17280, 8640, 270, 8640, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 8640, 17280, 17280, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 17280, 270, 17280, 270, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 8640, 8640, 17280, 270, 17280, 17280, 8640, 270, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 270, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 17280, 270, 8640, 270, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 270, 270, 270, 270]
Prompts retrieved: 2243430 . Total input tokens: 500187779 . Total output tokens: 448743425
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.117963729891926,
    "estimated_duration": 3600.102093983671,
    "input_throughput": 3840.106374511807,
    "output_throughput": 3391.9740832925913,
    "total_throughput": 7232.080457804399,
    "itl": 249.41736445526237,
    "ttft": 2247763.1718516727,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 631,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0575145791913436,
    "arrivals": 746983,
    "finished_requests": 55856,
    "scheduler_time": 56.033440385443605
}
#Debug simulation 
Total elapsed time: 4.118054022081196. Arrivals time: 0.30388419749215245 Scheduler time: 3.7290281178429723 Scheduler overhead time: 0.02222614036872983 Adapter cache time: 0.02976558730006218 Engine time: 0.022801044397056103 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-32/adapters_256_slots_192_rate_1.6-0.8-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-32/adapters_256_slots_192_rate_1.6-0.8-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 270, 17280, 17280, 270, 17280, 8640, 17280, 270, 8640, 270, 17280, 8640, 8640, 8640, 8640, 17280, 270, 270, 270, 8640, 17280, 270, 17280, 17280, 8640, 8640, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 270, 8640, 8640, 17280, 8640, 270, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 270, 17280, 17280, 8640, 270, 270, 17280, 8640, 270, 8640, 8640, 17280, 8640, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 8640, 270, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 270, 17280, 17280, 270, 17280, 270, 8640, 17280, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 270, 270, 270, 17280, 8640, 270, 17280, 270, 17280, 270, 270, 8640, 8640, 17280, 8640, 17280, 270, 8640, 270, 17280, 17280, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 17280, 270, 17280, 8640, 270, 8640, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 8640, 17280, 17280, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 17280, 270, 17280, 270, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 8640, 8640, 17280, 270, 17280, 17280, 8640, 270, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 270, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 17280, 270, 8640, 270, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 270, 270, 270, 270]
Prompts retrieved: 2243430 . Total input tokens: 500187779 . Total output tokens: 448743425
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.918707546312362,
    "estimated_duration": 3600.102655016037,
    "input_throughput": 3324.496034390632,
    "output_throughput": 2946.9654108940235,
    "total_throughput": 6271.461445284655,
    "itl": 113.96034071257783,
    "ttft": 2335596.7522253576,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 554,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.809879272710543,
    "arrivals": 746983,
    "finished_requests": 48283,
    "scheduler_time": 56.38183282354197
}
#Debug simulation 
Total elapsed time: 3.918799018021673. Arrivals time: 0.27515508653596044 Scheduler time: 3.3929752628318965 Scheduler overhead time: 0.04346931492909789 Adapter cache time: 0.1415618401952088 Engine time: 0.04494292847812176 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-16-16/adapters_256_slots_192_rate_1.6-0.8-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-16-16/adapters_256_slots_192_rate_1.6-0.8-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 270, 17280, 17280, 270, 17280, 8640, 17280, 270, 8640, 270, 17280, 8640, 8640, 8640, 8640, 17280, 270, 270, 270, 8640, 17280, 270, 17280, 17280, 8640, 8640, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 270, 8640, 8640, 17280, 8640, 270, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 270, 17280, 17280, 8640, 270, 270, 17280, 8640, 270, 8640, 8640, 17280, 8640, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 8640, 270, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 270, 17280, 17280, 270, 17280, 270, 8640, 17280, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 270, 270, 270, 17280, 8640, 270, 17280, 270, 17280, 270, 270, 8640, 8640, 17280, 8640, 17280, 270, 8640, 270, 17280, 17280, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 17280, 270, 17280, 8640, 270, 8640, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 8640, 17280, 17280, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 17280, 270, 17280, 270, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 8640, 8640, 17280, 270, 17280, 17280, 8640, 270, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 270, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 17280, 270, 8640, 270, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 270, 270, 270, 270]
Prompts retrieved: 2243430 . Total input tokens: 500187779 . Total output tokens: 448743425
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.111336186993867,
    "estimated_duration": 3600.212480452241,
    "input_throughput": 3839.101185012225,
    "output_throughput": 3391.240952108011,
    "total_throughput": 7230.342137120236,
    "itl": 249.22061630115525,
    "ttft": 2247980.176967089,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 631,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9725267529557329,
    "arrivals": 746983,
    "finished_requests": 55842,
    "scheduler_time": 56.025113319352506
}
#Debug simulation 
Total elapsed time: 4.111464695073664. Arrivals time: 0.30155753530561924 Scheduler time: 3.724924980197102 Scheduler overhead time: 0.022311748005449772 Adapter cache time: 0.029505972750484943 Engine time: 0.022755693644285202 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-16-32/adapters_256_slots_192_rate_1.6-0.8-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-16-32/adapters_256_slots_192_rate_1.6-0.8-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 270, 17280, 17280, 270, 17280, 8640, 17280, 270, 8640, 270, 17280, 8640, 8640, 8640, 8640, 17280, 270, 270, 270, 8640, 17280, 270, 17280, 17280, 8640, 8640, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 270, 8640, 8640, 17280, 8640, 270, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 270, 17280, 17280, 8640, 270, 270, 17280, 8640, 270, 8640, 8640, 17280, 8640, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 8640, 270, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 270, 17280, 17280, 270, 17280, 270, 8640, 17280, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 270, 270, 270, 17280, 8640, 270, 17280, 270, 17280, 270, 270, 8640, 8640, 17280, 8640, 17280, 270, 8640, 270, 17280, 17280, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 17280, 270, 17280, 8640, 270, 8640, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 8640, 17280, 17280, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 17280, 270, 17280, 270, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 8640, 8640, 17280, 270, 17280, 17280, 8640, 270, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 270, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 17280, 270, 8640, 270, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 270, 270, 270, 270]
Prompts retrieved: 2243430 . Total input tokens: 500187779 . Total output tokens: 448743425
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 3.9099321719259024,
    "estimated_duration": 3600.003257049847,
    "input_throughput": 3324.587825458814,
    "output_throughput": 2947.0467781449283,
    "total_throughput": 6271.634603603743,
    "itl": 113.96108082981588,
    "ttft": 2335606.2640664824,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 554,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8326407080516256,
    "arrivals": 746983,
    "finished_requests": 48283,
    "scheduler_time": 56.37993415904241
}
#Debug simulation 
Total elapsed time: 3.910041538067162. Arrivals time: 0.27711524022743106 Scheduler time: 3.3844831669703126 Scheduler overhead time: 0.04320093058049679 Adapter cache time: 0.1399978599511087 Engine time: 0.0446735811419785 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_16-16-16/adapters_256_slots_192_rate_1.6-0.8-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_16-16-16/adapters_256_slots_192_rate_1.6-0.8-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 270, 17280, 17280, 270, 17280, 8640, 17280, 270, 8640, 270, 17280, 8640, 8640, 8640, 8640, 17280, 270, 270, 270, 8640, 17280, 270, 17280, 17280, 8640, 8640, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 270, 8640, 8640, 17280, 8640, 270, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 270, 17280, 17280, 8640, 270, 270, 17280, 8640, 270, 8640, 8640, 17280, 8640, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 8640, 270, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 270, 17280, 17280, 270, 17280, 270, 8640, 17280, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 270, 270, 270, 17280, 8640, 270, 17280, 270, 17280, 270, 270, 8640, 8640, 17280, 8640, 17280, 270, 8640, 270, 17280, 17280, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 17280, 270, 17280, 8640, 270, 8640, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 8640, 17280, 17280, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 17280, 270, 17280, 270, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 8640, 8640, 17280, 270, 17280, 17280, 8640, 270, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 270, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 17280, 270, 8640, 270, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 270, 270, 270, 270]
Prompts retrieved: 2243430 . Total input tokens: 500187779 . Total output tokens: 448743425
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.0332762957550585,
    "estimated_duration": 3600.124824529451,
    "input_throughput": 3839.194659536987,
    "output_throughput": 3391.3235221214263,
    "total_throughput": 7230.518181658414,
    "itl": 249.21581800699545,
    "ttft": 2247942.8309719726,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 631,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8867217360832427,
    "arrivals": 746983,
    "finished_requests": 55842,
    "scheduler_time": 56.025022621502295
}
#Debug simulation 
Total elapsed time: 4.033400875981897. Arrivals time: 0.2740979576483369 Scheduler time: 3.6754246074706316 Scheduler overhead time: 0.02182038826867938 Adapter cache time: 0.028664891608059406 Engine time: 0.022386169992387295 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_16-16-32/adapters_256_slots_192_rate_1.6-0.8-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_16-16-32/adapters_256_slots_192_rate_1.6-0.8-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 270, 17280, 17280, 270, 17280, 8640, 17280, 270, 8640, 270, 17280, 8640, 8640, 8640, 8640, 17280, 270, 270, 270, 8640, 17280, 270, 17280, 17280, 8640, 8640, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 270, 8640, 8640, 17280, 8640, 270, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 270, 17280, 17280, 8640, 270, 270, 17280, 8640, 270, 8640, 8640, 17280, 8640, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 8640, 270, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 270, 17280, 17280, 270, 17280, 270, 8640, 17280, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 270, 270, 270, 17280, 8640, 270, 17280, 270, 17280, 270, 270, 8640, 8640, 17280, 8640, 17280, 270, 8640, 270, 17280, 17280, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 17280, 270, 17280, 8640, 270, 8640, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 8640, 17280, 17280, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 17280, 270, 17280, 270, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 8640, 8640, 17280, 270, 17280, 17280, 8640, 270, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 270, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 17280, 270, 8640, 270, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 270, 270, 270, 270]
Prompts retrieved: 2243430 . Total input tokens: 500187779 . Total output tokens: 448743425
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.920546726323664,
    "estimated_duration": 3600.026689501033,
    "input_throughput": 3324.566185829819,
    "output_throughput": 2947.0275959177593,
    "total_throughput": 6271.593781747579,
    "itl": 113.96187993364273,
    "ttft": 2335616.023622942,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 554,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8560309123247827,
    "arrivals": 746983,
    "finished_requests": 48283,
    "scheduler_time": 56.37997640597508
}
#Debug simulation 
Total elapsed time: 3.9206401011906564. Arrivals time: 0.3034146432764828 Scheduler time: 3.3686477234587073 Scheduler overhead time: 0.043368756771087646 Adapter cache time: 0.13998605078086257 Engine time: 0.0446010185405612 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-8/adapters_256_slots_192_rate_1.6-0.8-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-8/adapters_256_slots_192_rate_1.6-0.8-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 135, 17280, 17280, 135, 17280, 8640, 17280, 135, 8640, 135, 17280, 8640, 8640, 8640, 8640, 17280, 135, 135, 135, 8640, 17280, 135, 17280, 17280, 8640, 8640, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 135, 8640, 8640, 17280, 8640, 135, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 135, 17280, 17280, 8640, 135, 135, 17280, 8640, 135, 8640, 8640, 17280, 8640, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 8640, 135, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 135, 17280, 17280, 135, 17280, 135, 8640, 17280, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 135, 135, 135, 17280, 8640, 135, 17280, 135, 17280, 135, 135, 8640, 8640, 17280, 8640, 17280, 135, 8640, 135, 17280, 17280, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 17280, 135, 17280, 8640, 135, 8640, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 8640, 17280, 17280, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 17280, 135, 17280, 135, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 8640, 8640, 17280, 135, 17280, 17280, 8640, 135, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 135, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 17280, 135, 8640, 135, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 135, 135, 135, 135]
Prompts retrieved: 2231955 . Total input tokens: 497616808 . Total output tokens: 446425470
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.023165270220488,
    "estimated_duration": 3600.142489700214,
    "input_throughput": 3965.3422165489774,
    "output_throughput": 3459.145863150823,
    "total_throughput": 7424.4880796998,
    "itl": 245.60079934544527,
    "ttft": 2239398.435874845,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 370,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1323804652551221,
    "arrivals": 743226,
    "finished_requests": 57526,
    "scheduler_time": 57.09000537265758
}
#Debug simulation 
Total elapsed time: 4.023258707951754. Arrivals time: 0.20529100205749273 Scheduler time: 3.7397204325534403 Scheduler overhead time: 0.022191318683326244 Adapter cache time: 0.022781394887715578 Engine time: 0.022840420249849558 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-16/adapters_256_slots_192_rate_1.6-0.8-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-16/adapters_256_slots_192_rate_1.6-0.8-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 135, 17280, 17280, 135, 17280, 8640, 17280, 135, 8640, 135, 17280, 8640, 8640, 8640, 8640, 17280, 135, 135, 135, 8640, 17280, 135, 17280, 17280, 8640, 8640, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 135, 8640, 8640, 17280, 8640, 135, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 135, 17280, 17280, 8640, 135, 135, 17280, 8640, 135, 8640, 8640, 17280, 8640, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 8640, 135, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 135, 17280, 17280, 135, 17280, 135, 8640, 17280, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 135, 135, 135, 17280, 8640, 135, 17280, 135, 17280, 135, 135, 8640, 8640, 17280, 8640, 17280, 135, 8640, 135, 17280, 17280, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 17280, 135, 17280, 8640, 135, 8640, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 8640, 17280, 17280, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 17280, 135, 17280, 135, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 8640, 8640, 17280, 135, 17280, 17280, 8640, 135, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 135, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 17280, 135, 8640, 135, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 135, 135, 135, 135]
Prompts retrieved: 2231955 . Total input tokens: 497616808 . Total output tokens: 446425470
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.034687381703407,
    "estimated_duration": 3600.006552632191,
    "input_throughput": 3959.8111257817077,
    "output_throughput": 3454.3545458014455,
    "total_throughput": 7414.165671583153,
    "itl": 243.6634318501618,
    "ttft": 2240771.216019217,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 368,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1996271709050097,
    "arrivals": 743226,
    "finished_requests": 57442,
    "scheduler_time": 57.070713215490485
}
#Debug simulation 
Total elapsed time: 4.034802270587534. Arrivals time: 0.20249531418085098 Scheduler time: 3.753163813147694 Scheduler overhead time: 0.02234817622229457 Adapter cache time: 0.02323186956346035 Engine time: 0.02314694644883275 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-32/adapters_256_slots_192_rate_1.6-0.8-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-32/adapters_256_slots_192_rate_1.6-0.8-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 135, 17280, 17280, 135, 17280, 8640, 17280, 135, 8640, 135, 17280, 8640, 8640, 8640, 8640, 17280, 135, 135, 135, 8640, 17280, 135, 17280, 17280, 8640, 8640, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 135, 8640, 8640, 17280, 8640, 135, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 135, 17280, 17280, 8640, 135, 135, 17280, 8640, 135, 8640, 8640, 17280, 8640, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 8640, 135, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 135, 17280, 17280, 135, 17280, 135, 8640, 17280, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 135, 135, 135, 17280, 8640, 135, 17280, 135, 17280, 135, 135, 8640, 8640, 17280, 8640, 17280, 135, 8640, 135, 17280, 17280, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 17280, 135, 17280, 8640, 135, 8640, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 8640, 17280, 17280, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 17280, 135, 17280, 135, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 8640, 8640, 17280, 135, 17280, 17280, 8640, 135, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 135, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 17280, 135, 8640, 135, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 135, 135, 135, 135]
Prompts retrieved: 2231955 . Total input tokens: 497616808 . Total output tokens: 446425470
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.8361618178896606,
    "estimated_duration": 3600.0949749410847,
    "input_throughput": 3385.709011801687,
    "output_throughput": 2976.8417429530123,
    "total_throughput": 6362.5507547546995,
    "itl": 113.6589843918512,
    "ttft": 2329856.6484167203,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 348,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.137048730608082,
    "arrivals": 743226,
    "finished_requests": 49178,
    "scheduler_time": 56.816024223331254
}
#Debug simulation 
Total elapsed time: 3.8362489440478384. Arrivals time: 0.18839496979489923 Scheduler time: 3.4024445838294923 Scheduler overhead time: 0.04450617404654622 Adapter cache time: 0.13554314197972417 Engine time: 0.04470627661794424 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-16/adapters_256_slots_192_rate_1.6-0.8-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-16/adapters_256_slots_192_rate_1.6-0.8-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 135, 17280, 17280, 135, 17280, 8640, 17280, 135, 8640, 135, 17280, 8640, 8640, 8640, 8640, 17280, 135, 135, 135, 8640, 17280, 135, 17280, 17280, 8640, 8640, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 135, 8640, 8640, 17280, 8640, 135, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 135, 17280, 17280, 8640, 135, 135, 17280, 8640, 135, 8640, 8640, 17280, 8640, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 8640, 135, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 135, 17280, 17280, 135, 17280, 135, 8640, 17280, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 135, 135, 135, 17280, 8640, 135, 17280, 135, 17280, 135, 135, 8640, 8640, 17280, 8640, 17280, 135, 8640, 135, 17280, 17280, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 17280, 135, 17280, 8640, 135, 8640, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 8640, 17280, 17280, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 17280, 135, 17280, 135, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 8640, 8640, 17280, 135, 17280, 17280, 8640, 135, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 135, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 17280, 135, 8640, 135, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 135, 135, 135, 135]
Prompts retrieved: 2231955 . Total input tokens: 497616808 . Total output tokens: 446425470
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.089953972026706,
    "estimated_duration": 3600.2276412271794,
    "input_throughput": 3959.8676585740927,
    "output_throughput": 3454.2949055746267,
    "total_throughput": 7414.162564148719,
    "itl": 243.6585620555354,
    "ttft": 2240807.775558978,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 368,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.150595732692164,
    "arrivals": 743226,
    "finished_requests": 57447,
    "scheduler_time": 57.07493816407172
}
#Debug simulation 
Total elapsed time: 4.090090909041464. Arrivals time: 0.24721067072823644 Scheduler time: 3.7637919397093356 Scheduler overhead time: 0.02245939103886485 Adapter cache time: 0.023175575770437717 Engine time: 0.022921822499483824 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-32/adapters_256_slots_192_rate_1.6-0.8-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-32/adapters_256_slots_192_rate_1.6-0.8-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 135, 17280, 17280, 135, 17280, 8640, 17280, 135, 8640, 135, 17280, 8640, 8640, 8640, 8640, 17280, 135, 135, 135, 8640, 17280, 135, 17280, 17280, 8640, 8640, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 135, 8640, 8640, 17280, 8640, 135, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 135, 17280, 17280, 8640, 135, 135, 17280, 8640, 135, 8640, 8640, 17280, 8640, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 8640, 135, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 135, 17280, 17280, 135, 17280, 135, 8640, 17280, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 135, 135, 135, 17280, 8640, 135, 17280, 135, 17280, 135, 135, 8640, 8640, 17280, 8640, 17280, 135, 8640, 135, 17280, 17280, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 17280, 135, 17280, 8640, 135, 8640, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 8640, 17280, 17280, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 17280, 135, 17280, 135, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 8640, 8640, 17280, 135, 17280, 17280, 8640, 135, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 135, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 17280, 135, 8640, 135, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 135, 135, 135, 135]
Prompts retrieved: 2231955 . Total input tokens: 497616808 . Total output tokens: 446425470
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 3.819919555913657,
    "estimated_duration": 3600.109351059473,
    "input_throughput": 3385.6954918363654,
    "output_throughput": 2976.829855694836,
    "total_throughput": 6362.525347531201,
    "itl": 113.65946868568203,
    "ttft": 2329864.0105345617,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 348,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.151384662259375,
    "arrivals": 743226,
    "finished_requests": 49178,
    "scheduler_time": 56.816064410073984
}
#Debug simulation 
Total elapsed time: 3.8200098369270563. Arrivals time: 0.1851770244538784 Scheduler time: 3.389976273290813 Scheduler overhead time: 0.04329982679337263 Adapter cache time: 0.1366842081770301 Engine time: 0.04444882087409496 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-16/adapters_256_slots_192_rate_1.6-0.8-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-16/adapters_256_slots_192_rate_1.6-0.8-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 135, 17280, 17280, 135, 17280, 8640, 17280, 135, 8640, 135, 17280, 8640, 8640, 8640, 8640, 17280, 135, 135, 135, 8640, 17280, 135, 17280, 17280, 8640, 8640, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 135, 8640, 8640, 17280, 8640, 135, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 135, 17280, 17280, 8640, 135, 135, 17280, 8640, 135, 8640, 8640, 17280, 8640, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 8640, 135, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 135, 17280, 17280, 135, 17280, 135, 8640, 17280, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 135, 135, 135, 17280, 8640, 135, 17280, 135, 17280, 135, 135, 8640, 8640, 17280, 8640, 17280, 135, 8640, 135, 17280, 17280, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 17280, 135, 17280, 8640, 135, 8640, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 8640, 17280, 17280, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 17280, 135, 17280, 135, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 8640, 8640, 17280, 135, 17280, 17280, 8640, 135, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 135, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 17280, 135, 8640, 135, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 135, 135, 135, 135]
Prompts retrieved: 2231955 . Total input tokens: 497616808 . Total output tokens: 446425470
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.033141698688269,
    "estimated_duration": 3600.1773061330555,
    "input_throughput": 3959.9230226004624,
    "output_throughput": 3454.343201045771,
    "total_throughput": 7414.266223646234,
    "itl": 243.6561531483765,
    "ttft": 2240782.2399783097,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 368,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1003385085239985,
    "arrivals": 743226,
    "finished_requests": 57447,
    "scheduler_time": 57.074860294108184
}
#Debug simulation 
Total elapsed time: 4.0332656698301435. Arrivals time: 0.20331105682998896 Scheduler time: 3.7504498097114265 Scheduler overhead time: 0.022470941301435232 Adapter cache time: 0.02355895983055234 Engine time: 0.023070126306265593 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-32/adapters_256_slots_192_rate_1.6-0.8-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-32/adapters_256_slots_192_rate_1.6-0.8-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 135, 17280, 17280, 135, 17280, 8640, 17280, 135, 8640, 135, 17280, 8640, 8640, 8640, 8640, 17280, 135, 135, 135, 8640, 17280, 135, 17280, 17280, 8640, 8640, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 135, 8640, 8640, 17280, 8640, 135, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 135, 17280, 17280, 8640, 135, 135, 17280, 8640, 135, 8640, 8640, 17280, 8640, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 8640, 135, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 135, 17280, 17280, 135, 17280, 135, 8640, 17280, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 135, 135, 135, 17280, 8640, 135, 17280, 135, 17280, 135, 135, 8640, 8640, 17280, 8640, 17280, 135, 8640, 135, 17280, 17280, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 17280, 135, 17280, 8640, 135, 8640, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 8640, 17280, 17280, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 17280, 135, 17280, 135, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 8640, 8640, 17280, 135, 17280, 17280, 8640, 135, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 135, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 17280, 135, 8640, 135, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 135, 135, 135, 135]
Prompts retrieved: 2231955 . Total input tokens: 497616808 . Total output tokens: 446425470
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.812018459197134,
    "estimated_duration": 3600.003721927554,
    "input_throughput": 3385.706221846312,
    "output_throughput": 2976.8708111951396,
    "total_throughput": 6362.577033041452,
    "itl": 113.65976394926149,
    "ttft": 2329857.724213279,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 348,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1660978552699128,
    "arrivals": 743226,
    "finished_requests": 49177,
    "scheduler_time": 56.81421913650792
}
#Debug simulation 
Total elapsed time: 3.8121070619672537. Arrivals time: 0.1860149446874857 Scheduler time: 3.3821023530326784 Scheduler overhead time: 0.04327820800244808 Adapter cache time: 0.1356887947767973 Engine time: 0.04459498589858413 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-8/adapters_256_slots_192_rate_1.6-0.8-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-8/adapters_256_slots_192_rate_1.6-0.8-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 66, 17280, 17280, 66, 17280, 8640, 17280, 66, 8640, 66, 17280, 8640, 8640, 8640, 8640, 17280, 66, 66, 66, 8640, 17280, 66, 17280, 17280, 8640, 8640, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 66, 8640, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 66, 17280, 17280, 8640, 66, 66, 17280, 8640, 66, 8640, 8640, 17280, 8640, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 8640, 66, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 66, 17280, 17280, 66, 17280, 66, 8640, 17280, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 66, 66, 66, 17280, 8640, 66, 17280, 66, 17280, 66, 66, 8640, 8640, 17280, 8640, 17280, 66, 8640, 66, 17280, 17280, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 8640, 17280, 17280, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 17280, 66, 17280, 66, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 8640, 8640, 17280, 66, 17280, 17280, 8640, 66, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 66, 8640, 66, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 66, 66, 66, 66]
Prompts retrieved: 2226090 . Total input tokens: 496312659 . Total output tokens: 445233650
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.07212249469012,
    "estimated_duration": 3600.2527961022647,
    "input_throughput": 3960.049698575396,
    "output_throughput": 3481.80772571614,
    "total_throughput": 7441.857424291536,
    "itl": 245.31403323501516,
    "ttft": 2234116.258915189,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 278,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8508155928133044,
    "arrivals": 741292,
    "finished_requests": 57464,
    "scheduler_time": 57.48004500882455
}
#Debug simulation 
Total elapsed time: 4.07222650712356. Arrivals time: 0.20697631174698472 Scheduler time: 3.790406231302768 Scheduler overhead time: 0.022252808790653944 Adapter cache time: 0.019255285616964102 Engine time: 0.022939858492463827 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-16/adapters_256_slots_192_rate_1.6-0.8-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-16/adapters_256_slots_192_rate_1.6-0.8-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 66, 17280, 17280, 66, 17280, 8640, 17280, 66, 8640, 66, 17280, 8640, 8640, 8640, 8640, 17280, 66, 66, 66, 8640, 17280, 66, 17280, 17280, 8640, 8640, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 66, 8640, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 66, 17280, 17280, 8640, 66, 66, 17280, 8640, 66, 8640, 8640, 17280, 8640, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 8640, 66, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 66, 17280, 17280, 66, 17280, 66, 8640, 17280, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 66, 66, 66, 17280, 8640, 66, 17280, 66, 17280, 66, 66, 8640, 8640, 17280, 8640, 17280, 66, 8640, 66, 17280, 17280, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 8640, 17280, 17280, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 17280, 66, 17280, 66, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 8640, 8640, 17280, 66, 17280, 17280, 8640, 66, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 66, 8640, 66, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 66, 66, 66, 66]
Prompts retrieved: 2226090 . Total input tokens: 496312659 . Total output tokens: 445233650
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.052674130070955,
    "estimated_duration": 3600.180385261666,
    "input_throughput": 3951.9114259509306,
    "output_throughput": 3476.0677690571974,
    "total_throughput": 7427.979195008128,
    "itl": 242.63236107634435,
    "ttft": 2234764.3746998613,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 278,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9068241158942737,
    "arrivals": 741292,
    "finished_requests": 57341,
    "scheduler_time": 57.4508100176062
}
#Debug simulation 
Total elapsed time: 4.052768337074667. Arrivals time: 0.2019005105830729 Scheduler time: 3.7746836729347706 Scheduler overhead time: 0.022538304328918457 Adapter cache time: 0.019948932342231274 Engine time: 0.023198208771646023 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-32/adapters_256_slots_192_rate_1.6-0.8-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-32/adapters_256_slots_192_rate_1.6-0.8-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 66, 17280, 17280, 66, 17280, 8640, 17280, 66, 8640, 66, 17280, 8640, 8640, 8640, 8640, 17280, 66, 66, 66, 8640, 17280, 66, 17280, 17280, 8640, 8640, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 66, 8640, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 66, 17280, 17280, 8640, 66, 66, 17280, 8640, 66, 8640, 8640, 17280, 8640, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 8640, 66, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 66, 17280, 17280, 66, 17280, 66, 8640, 17280, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 66, 66, 66, 17280, 8640, 66, 17280, 66, 17280, 66, 66, 8640, 8640, 17280, 8640, 17280, 66, 8640, 66, 17280, 17280, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 8640, 17280, 17280, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 17280, 66, 17280, 66, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 8640, 8640, 17280, 66, 17280, 17280, 8640, 66, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 66, 8640, 66, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 66, 66, 66, 66]
Prompts retrieved: 2226090 . Total input tokens: 496312659 . Total output tokens: 445233650
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.8745129671879113,
    "estimated_duration": 3600.0201981537566,
    "input_throughput": 3376.835776153273,
    "output_throughput": 2979.794948234298,
    "total_throughput": 6356.630724387571,
    "itl": 113.14026734412846,
    "ttft": 2325418.4197465517,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 254,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8303858616575639,
    "arrivals": 741292,
    "finished_requests": 48873,
    "scheduler_time": 56.92481650144845
}
#Debug simulation 
Total elapsed time: 3.874602605123073. Arrivals time: 0.23055769642814994 Scheduler time: 3.402322927955538 Scheduler overhead time: 0.0432862713932991 Adapter cache time: 0.1333533930592239 Engine time: 0.044535374734550714 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-16/adapters_256_slots_192_rate_1.6-0.8-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-16/adapters_256_slots_192_rate_1.6-0.8-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 66, 17280, 17280, 66, 17280, 8640, 17280, 66, 8640, 66, 17280, 8640, 8640, 8640, 8640, 17280, 66, 66, 66, 8640, 17280, 66, 17280, 17280, 8640, 8640, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 66, 8640, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 66, 17280, 17280, 8640, 66, 66, 17280, 8640, 66, 8640, 8640, 17280, 8640, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 8640, 66, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 66, 17280, 17280, 66, 17280, 66, 8640, 17280, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 66, 66, 66, 17280, 8640, 66, 17280, 66, 17280, 66, 66, 8640, 8640, 17280, 8640, 17280, 66, 8640, 66, 17280, 17280, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 8640, 17280, 17280, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 17280, 66, 17280, 66, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 8640, 8640, 17280, 66, 17280, 17280, 8640, 66, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 66, 8640, 66, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 66, 66, 66, 66]
Prompts retrieved: 2226090 . Total input tokens: 496312659 . Total output tokens: 445233650
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.069623414892703,
    "estimated_duration": 3600.1435338130464,
    "input_throughput": 3951.9518781327656,
    "output_throughput": 3476.103350453213,
    "total_throughput": 7428.0552285859785,
    "itl": 242.63086567808145,
    "ttft": 2234743.643199577,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 278,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8700505372346407,
    "arrivals": 741292,
    "finished_requests": 57341,
    "scheduler_time": 57.45073214764267
}
#Debug simulation 
Total elapsed time: 4.069716711062938. Arrivals time: 0.20867885323241353 Scheduler time: 3.7849386227317154 Scheduler overhead time: 0.022403236478567123 Adapter cache time: 0.020010937936604023 Engine time: 0.023205507081001997 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-32/adapters_256_slots_192_rate_1.6-0.8-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-32/adapters_256_slots_192_rate_1.6-0.8-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 66, 17280, 17280, 66, 17280, 8640, 17280, 66, 8640, 66, 17280, 8640, 8640, 8640, 8640, 17280, 66, 66, 66, 8640, 17280, 66, 17280, 17280, 8640, 8640, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 66, 8640, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 66, 17280, 17280, 8640, 66, 66, 17280, 8640, 66, 8640, 8640, 17280, 8640, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 8640, 66, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 66, 17280, 17280, 66, 17280, 66, 8640, 17280, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 66, 66, 66, 17280, 8640, 66, 17280, 66, 17280, 66, 66, 8640, 8640, 17280, 8640, 17280, 66, 8640, 66, 17280, 17280, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 8640, 17280, 17280, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 17280, 66, 17280, 66, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 8640, 8640, 17280, 66, 17280, 17280, 8640, 66, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 66, 8640, 66, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 66, 66, 66, 66]
Prompts retrieved: 2226090 . Total input tokens: 496312659 . Total output tokens: 445233650
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 3.809577631764114,
    "estimated_duration": 3600.0305519243125,
    "input_throughput": 3376.8260642960186,
    "output_throughput": 2979.7863782755844,
    "total_throughput": 6356.612442571603,
    "itl": 113.14058048158087,
    "ttft": 2325424.35225026,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 254,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8406976721435825,
    "arrivals": 741292,
    "finished_requests": 48873,
    "scheduler_time": 56.92485846151922
}
#Debug simulation 
Total elapsed time: 3.8096618740819395. Arrivals time: 0.18652068497613072 Scheduler time: 3.3824920267798007 Scheduler overhead time: 0.043277892749756575 Adapter cache time: 0.13245610939338803 Engine time: 0.04443866852670908 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-16/adapters_256_slots_192_rate_1.6-0.8-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-16/adapters_256_slots_192_rate_1.6-0.8-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 66, 17280, 17280, 66, 17280, 8640, 17280, 66, 8640, 66, 17280, 8640, 8640, 8640, 8640, 17280, 66, 66, 66, 8640, 17280, 66, 17280, 17280, 8640, 8640, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 66, 8640, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 66, 17280, 17280, 8640, 66, 66, 17280, 8640, 66, 8640, 8640, 17280, 8640, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 8640, 66, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 66, 17280, 17280, 66, 17280, 66, 8640, 17280, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 66, 66, 66, 17280, 8640, 66, 17280, 66, 17280, 66, 66, 8640, 8640, 17280, 8640, 17280, 66, 8640, 66, 17280, 17280, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 8640, 17280, 17280, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 17280, 66, 17280, 66, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 8640, 8640, 17280, 66, 17280, 17280, 8640, 66, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 66, 8640, 66, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 66, 66, 66, 66]
Prompts retrieved: 2226090 . Total input tokens: 496312659 . Total output tokens: 445233650
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.081200804095715,
    "estimated_duration": 3600.1568681588474,
    "input_throughput": 3952.1822301250363,
    "output_throughput": 3476.2357470274014,
    "total_throughput": 7428.417977152438,
    "itl": 242.63648930562823,
    "ttft": 2234796.5812893463,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 278,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.831233981982806,
    "arrivals": 741292,
    "finished_requests": 57344,
    "scheduler_time": 57.45188051778922
}
#Debug simulation 
Total elapsed time: 4.081299379002303. Arrivals time: 0.20434533106163144 Scheduler time: 3.8011387954466045 Scheduler overhead time: 0.022537946235388517 Adapter cache time: 0.019615233410149813 Engine time: 0.023090247064828873 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-32/adapters_256_slots_192_rate_1.6-0.8-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-32/adapters_256_slots_192_rate_1.6-0.8-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 66, 17280, 17280, 66, 17280, 8640, 17280, 66, 8640, 66, 17280, 8640, 8640, 8640, 8640, 17280, 66, 66, 66, 8640, 17280, 66, 17280, 17280, 8640, 8640, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 66, 8640, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 66, 17280, 17280, 8640, 66, 66, 17280, 8640, 66, 8640, 8640, 17280, 8640, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 8640, 66, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 66, 17280, 17280, 66, 17280, 66, 8640, 17280, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 66, 66, 66, 17280, 8640, 66, 17280, 66, 17280, 66, 66, 8640, 8640, 17280, 8640, 17280, 66, 8640, 66, 17280, 17280, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 8640, 17280, 17280, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 17280, 66, 17280, 66, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 8640, 8640, 17280, 66, 17280, 17280, 8640, 66, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 66, 8640, 66, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 66, 66, 66, 66]
Prompts retrieved: 2226090 . Total input tokens: 496312659 . Total output tokens: 445233650
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.858390655834228,
    "estimated_duration": 3600.0416599568002,
    "input_throughput": 3376.8156450016963,
    "output_throughput": 2979.777184058677,
    "total_throughput": 6356.592829060373,
    "itl": 113.14094734852698,
    "ttft": 2325430.350099025,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 254,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8517640053480902,
    "arrivals": 741292,
    "finished_requests": 48873,
    "scheduler_time": 56.92490016080646
}
#Debug simulation 
Total elapsed time: 3.858474778942764. Arrivals time: 0.23224592301994562 Scheduler time: 3.3851716415956616 Scheduler overhead time: 0.04337921179831028 Adapter cache time: 0.1326336576603353 Engine time: 0.044515260960906744 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-8/adapters_256_slots_192_rate_1.6-0.8-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-8/adapters_256_slots_192_rate_1.6-0.8-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 33, 17280, 17280, 33, 17280, 8640, 17280, 33, 8640, 33, 17280, 8640, 8640, 8640, 8640, 17280, 33, 33, 33, 8640, 17280, 33, 17280, 17280, 8640, 8640, 8640, 33, 17280, 33, 8640, 8640, 33, 8640, 33, 33, 8640, 8640, 17280, 8640, 33, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 33, 17280, 17280, 8640, 33, 33, 17280, 8640, 33, 8640, 8640, 17280, 8640, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 8640, 33, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 33, 17280, 17280, 33, 17280, 33, 8640, 17280, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 33, 33, 33, 17280, 8640, 33, 17280, 33, 17280, 33, 33, 8640, 8640, 17280, 8640, 17280, 33, 8640, 33, 17280, 17280, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 33, 8640, 17280, 17280, 33, 17280, 8640, 33, 8640, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 8640, 17280, 17280, 8640, 33, 17280, 33, 8640, 8640, 33, 8640, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 17280, 33, 17280, 33, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 8640, 8640, 33, 8640, 17280, 8640, 8640, 17280, 33, 17280, 17280, 8640, 33, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 33, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 17280, 33, 8640, 33, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 33, 33, 33, 33]
Prompts retrieved: 2223285 . Total input tokens: 495676136 . Total output tokens: 444666343
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.072843516245484,
    "estimated_duration": 3600.1272005936007,
    "input_throughput": 4002.020816826805,
    "output_throughput": 3499.523016276392,
    "total_throughput": 7501.543833103196,
    "itl": 243.3115453141198,
    "ttft": 2229080.5805087085,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 227,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6947307178727342,
    "arrivals": 740358,
    "finished_requests": 58252,
    "scheduler_time": 57.73494335920594
}
#Debug simulation 
Total elapsed time: 4.072955813258886. Arrivals time: 0.20939311338588595 Scheduler time: 3.7889222051016986 Scheduler overhead time: 0.022461574990302324 Adapter cache time: 0.01868329057469964 Engine time: 0.02303222706541419 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-16/adapters_256_slots_192_rate_1.6-0.8-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-16/adapters_256_slots_192_rate_1.6-0.8-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 33, 17280, 17280, 33, 17280, 8640, 17280, 33, 8640, 33, 17280, 8640, 8640, 8640, 8640, 17280, 33, 33, 33, 8640, 17280, 33, 17280, 17280, 8640, 8640, 8640, 33, 17280, 33, 8640, 8640, 33, 8640, 33, 33, 8640, 8640, 17280, 8640, 33, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 33, 17280, 17280, 8640, 33, 33, 17280, 8640, 33, 8640, 8640, 17280, 8640, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 8640, 33, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 33, 17280, 17280, 33, 17280, 33, 8640, 17280, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 33, 33, 33, 17280, 8640, 33, 17280, 33, 17280, 33, 33, 8640, 8640, 17280, 8640, 17280, 33, 8640, 33, 17280, 17280, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 33, 8640, 17280, 17280, 33, 17280, 8640, 33, 8640, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 8640, 17280, 17280, 8640, 33, 17280, 33, 8640, 8640, 33, 8640, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 17280, 33, 17280, 33, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 8640, 8640, 33, 8640, 17280, 8640, 8640, 17280, 33, 17280, 17280, 8640, 33, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 33, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 17280, 33, 8640, 33, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 33, 33, 33, 33]
Prompts retrieved: 2223285 . Total input tokens: 495676136 . Total output tokens: 444666343
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.356251612305641,
    "estimated_duration": 3600.2623696935843,
    "input_throughput": 3996.4926226264415,
    "output_throughput": 3494.9188997775454,
    "total_throughput": 7491.411522403987,
    "itl": 241.3973766278507,
    "ttft": 2230328.5031371983,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 227,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7412565006641699,
    "arrivals": 740358,
    "finished_requests": 58177,
    "scheduler_time": 57.711376625929475
}
#Debug simulation 
Total elapsed time: 4.356319901999086. Arrivals time: 0.4800938740372658 Scheduler time: 3.8006111714057624 Scheduler overhead time: 0.022603939287364483 Adapter cache time: 0.019399584271013737 Engine time: 0.02317896345630288 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-32/adapters_256_slots_192_rate_1.6-0.8-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-32/adapters_256_slots_192_rate_1.6-0.8-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 33, 17280, 17280, 33, 17280, 8640, 17280, 33, 8640, 33, 17280, 8640, 8640, 8640, 8640, 17280, 33, 33, 33, 8640, 17280, 33, 17280, 17280, 8640, 8640, 8640, 33, 17280, 33, 8640, 8640, 33, 8640, 33, 33, 8640, 8640, 17280, 8640, 33, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 33, 17280, 17280, 8640, 33, 33, 17280, 8640, 33, 8640, 8640, 17280, 8640, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 8640, 33, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 33, 17280, 17280, 33, 17280, 33, 8640, 17280, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 33, 33, 33, 17280, 8640, 33, 17280, 33, 17280, 33, 33, 8640, 8640, 17280, 8640, 17280, 33, 8640, 33, 17280, 17280, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 33, 8640, 17280, 17280, 33, 17280, 8640, 33, 8640, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 8640, 17280, 17280, 8640, 33, 17280, 33, 8640, 8640, 33, 8640, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 17280, 33, 17280, 33, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 8640, 8640, 33, 8640, 17280, 8640, 8640, 17280, 33, 17280, 17280, 8640, 33, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 33, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 17280, 33, 8640, 33, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 33, 33, 33, 33]
Prompts retrieved: 2223285 . Total input tokens: 495676136 . Total output tokens: 444666343
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.8070228709839284,
    "estimated_duration": 3600.0245906279533,
    "input_throughput": 3398.2248431992166,
    "output_throughput": 2985.510995669404,
    "total_throughput": 6383.735838868621,
    "itl": 113.45020262503505,
    "ttft": 2325610.3805444976,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 221,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7228675422631237,
    "arrivals": 740358,
    "finished_requests": 49459,
    "scheduler_time": 56.97338251368605
}
#Debug simulation 
Total elapsed time: 3.8071100036613643. Arrivals time: 0.18645288050174713 Scheduler time: 3.381017089355737 Scheduler overhead time: 0.043234921991825104 Adapter cache time: 0.13131828559562564 Engine time: 0.04455211525782943 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-16/adapters_256_slots_192_rate_1.6-0.8-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-16/adapters_256_slots_192_rate_1.6-0.8-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 33, 17280, 17280, 33, 17280, 8640, 17280, 33, 8640, 33, 17280, 8640, 8640, 8640, 8640, 17280, 33, 33, 33, 8640, 17280, 33, 17280, 17280, 8640, 8640, 8640, 33, 17280, 33, 8640, 8640, 33, 8640, 33, 33, 8640, 8640, 17280, 8640, 33, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 33, 17280, 17280, 8640, 33, 33, 17280, 8640, 33, 8640, 8640, 17280, 8640, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 8640, 33, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 33, 17280, 17280, 33, 17280, 33, 8640, 17280, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 33, 33, 33, 17280, 8640, 33, 17280, 33, 17280, 33, 33, 8640, 8640, 17280, 8640, 17280, 33, 8640, 33, 17280, 17280, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 33, 8640, 17280, 17280, 33, 17280, 8640, 33, 8640, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 8640, 17280, 17280, 8640, 33, 17280, 33, 8640, 8640, 33, 8640, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 17280, 33, 17280, 33, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 8640, 8640, 33, 8640, 17280, 8640, 8640, 17280, 33, 17280, 17280, 8640, 33, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 33, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 17280, 33, 8640, 33, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 33, 33, 33, 33]
Prompts retrieved: 2223285 . Total input tokens: 495676136 . Total output tokens: 444666343
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.090497289318591,
    "estimated_duration": 3600.0294714686147,
    "input_throughput": 3996.353117112371,
    "output_throughput": 3494.9638884115147,
    "total_throughput": 7491.317005523886,
    "itl": 241.4194599978559,
    "ttft": 2230251.8073819852,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 227,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7106118517811427,
    "arrivals": 740358,
    "finished_requests": 58174,
    "scheduler_time": 57.70827879548089
}
#Debug simulation 
Total elapsed time: 4.090584843419492. Arrivals time: 0.2500787270255387 Scheduler time: 3.7659672838635743 Scheduler overhead time: 0.02240530075505376 Adapter cache time: 0.0188330989331007 Engine time: 0.02294235723093152 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-32/adapters_256_slots_192_rate_1.6-0.8-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-32/adapters_256_slots_192_rate_1.6-0.8-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 33, 17280, 17280, 33, 17280, 8640, 17280, 33, 8640, 33, 17280, 8640, 8640, 8640, 8640, 17280, 33, 33, 33, 8640, 17280, 33, 17280, 17280, 8640, 8640, 8640, 33, 17280, 33, 8640, 8640, 33, 8640, 33, 33, 8640, 8640, 17280, 8640, 33, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 33, 17280, 17280, 8640, 33, 33, 17280, 8640, 33, 8640, 8640, 17280, 8640, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 8640, 33, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 33, 17280, 17280, 33, 17280, 33, 8640, 17280, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 33, 33, 33, 17280, 8640, 33, 17280, 33, 17280, 33, 33, 8640, 8640, 17280, 8640, 17280, 33, 8640, 33, 17280, 17280, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 33, 8640, 17280, 17280, 33, 17280, 8640, 33, 8640, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 8640, 17280, 17280, 8640, 33, 17280, 33, 8640, 8640, 33, 8640, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 17280, 33, 17280, 33, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 8640, 8640, 33, 8640, 17280, 8640, 8640, 17280, 33, 17280, 17280, 8640, 33, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 33, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 17280, 33, 8640, 33, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 33, 33, 33, 33]
Prompts retrieved: 2223285 . Total input tokens: 495676136 . Total output tokens: 444666343
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 3.8106007701717317,
    "estimated_duration": 3600.0339346911683,
    "input_throughput": 3398.216022941316,
    "output_throughput": 2985.5032466303733,
    "total_throughput": 6383.719269571689,
    "itl": 113.45051592152048,
    "ttft": 2325615.744217503,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 221,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7321733224578232,
    "arrivals": 740358,
    "finished_requests": 49459,
    "scheduler_time": 56.97342079670898
}
#Debug simulation 
Total elapsed time: 3.810688393190503. Arrivals time: 0.1861963989213109 Scheduler time: 3.3852376686409116 Scheduler overhead time: 0.043256199918687344 Adapter cache time: 0.13136292900890112 Engine time: 0.04426604462787509 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-16/adapters_256_slots_192_rate_1.6-0.8-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-16/adapters_256_slots_192_rate_1.6-0.8-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 33, 17280, 17280, 33, 17280, 8640, 17280, 33, 8640, 33, 17280, 8640, 8640, 8640, 8640, 17280, 33, 33, 33, 8640, 17280, 33, 17280, 17280, 8640, 8640, 8640, 33, 17280, 33, 8640, 8640, 33, 8640, 33, 33, 8640, 8640, 17280, 8640, 33, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 33, 17280, 17280, 8640, 33, 33, 17280, 8640, 33, 8640, 8640, 17280, 8640, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 8640, 33, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 33, 17280, 17280, 33, 17280, 33, 8640, 17280, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 33, 33, 33, 17280, 8640, 33, 17280, 33, 17280, 33, 33, 8640, 8640, 17280, 8640, 17280, 33, 8640, 33, 17280, 17280, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 33, 8640, 17280, 17280, 33, 17280, 8640, 33, 8640, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 8640, 17280, 17280, 8640, 33, 17280, 33, 8640, 8640, 33, 8640, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 17280, 33, 17280, 33, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 8640, 8640, 33, 8640, 17280, 8640, 8640, 17280, 33, 17280, 17280, 8640, 33, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 33, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 17280, 33, 8640, 33, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 33, 33, 33, 33]
Prompts retrieved: 2223285 . Total input tokens: 495676136 . Total output tokens: 444666343
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.068928623106331,
    "estimated_duration": 3600.2080147761008,
    "input_throughput": 3996.714062338662,
    "output_throughput": 3495.1641539475227,
    "total_throughput": 7491.878216286184,
    "itl": 241.43433922095102,
    "ttft": 2230252.4720776714,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 227,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6787414169427948,
    "arrivals": 740358,
    "finished_requests": 58179,
    "scheduler_time": 57.711802293803665
}
#Debug simulation 
Total elapsed time: 4.069015773944557. Arrivals time: 0.20658620120957494 Scheduler time: 3.787150531075895 Scheduler overhead time: 0.022457776591181755 Adapter cache time: 0.019147203769534826 Engine time: 0.023202763870358467 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-32/adapters_256_slots_192_rate_1.6-0.8-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-32/adapters_256_slots_192_rate_1.6-0.8-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 33, 17280, 17280, 33, 17280, 8640, 17280, 33, 8640, 33, 17280, 8640, 8640, 8640, 8640, 17280, 33, 33, 33, 8640, 17280, 33, 17280, 17280, 8640, 8640, 8640, 33, 17280, 33, 8640, 8640, 33, 8640, 33, 33, 8640, 8640, 17280, 8640, 33, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 33, 17280, 17280, 8640, 33, 33, 17280, 8640, 33, 8640, 8640, 17280, 8640, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 8640, 33, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 33, 17280, 17280, 33, 17280, 33, 8640, 17280, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 33, 33, 33, 17280, 8640, 33, 17280, 33, 17280, 33, 33, 8640, 8640, 17280, 8640, 17280, 33, 8640, 33, 17280, 17280, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 33, 8640, 17280, 17280, 33, 17280, 8640, 33, 8640, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 8640, 17280, 17280, 8640, 33, 17280, 33, 8640, 8640, 33, 8640, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 17280, 33, 17280, 33, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 8640, 8640, 33, 8640, 17280, 8640, 8640, 17280, 33, 17280, 17280, 8640, 33, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 33, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 17280, 33, 8640, 33, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 33, 33, 33, 33]
Prompts retrieved: 2223285 . Total input tokens: 495676136 . Total output tokens: 444666343
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.8967751478776336,
    "estimated_duration": 3600.043406959535,
    "input_throughput": 3398.2070817118647,
    "output_throughput": 2985.495391311766,
    "total_throughput": 6383.702473023631,
    "itl": 113.45081103985063,
    "ttft": 2325621.227483655,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 221,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7416048564389375,
    "arrivals": 740358,
    "finished_requests": 49459,
    "scheduler_time": 56.973461531097136
}
#Debug simulation 
Total elapsed time: 3.896863047964871. Arrivals time: 0.26090904185548425 Scheduler time: 3.396267996635288 Scheduler overhead time: 0.043220001738518476 Adapter cache time: 0.13126115407794714 Engine time: 0.04466763185337186 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-8/adapters_256_slots_192_rate_1.6-0.4-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-8/adapters_256_slots_192_rate_1.6-0.4-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 1080, 17280, 17280, 1080, 17280, 4320, 17280, 1080, 4320, 1080, 17280, 4320, 4320, 4320, 4320, 17280, 1080, 1080, 1080, 4320, 17280, 1080, 17280, 17280, 4320, 4320, 4320, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 1080, 17280, 17280, 4320, 1080, 1080, 17280, 4320, 1080, 4320, 4320, 17280, 4320, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 4320, 1080, 4320, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 4320, 17280, 17280, 17280, 4320, 1080, 17280, 4320, 1080, 1080, 1080, 1080, 1080, 17280, 4320, 1080, 17280, 1080, 17280, 1080, 1080, 4320, 4320, 17280, 4320, 17280, 1080, 4320, 1080, 17280, 17280, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 1080, 4320, 17280, 17280, 1080, 17280, 4320, 1080, 4320, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 4320, 17280, 17280, 4320, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 17280, 1080, 17280, 1080, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 4320, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 1080, 17280, 17280, 4320, 1080, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 17280, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 1080, 1080, 1080, 1080]
Prompts retrieved: 1945080 . Total input tokens: 433756482 . Total output tokens: 389122472
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 3.9229347771033645,
    "estimated_duration": 3600.1207674118436,
    "input_throughput": 3673.2289982335483,
    "output_throughput": 3240.9035012422555,
    "total_throughput": 6914.132499475804,
    "itl": 263.43086766444884,
    "ttft": 2256025.6590084233,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2515,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.6971266759911074,
    "arrivals": 648144,
    "finished_requests": 53835,
    "scheduler_time": 53.49019082952841
}
#Debug simulation 
Total elapsed time: 3.9230222292244434. Arrivals time: 0.19598902110010386 Scheduler time: 3.6152195390313864 Scheduler overhead time: 0.021703616250306368 Adapter cache time: 0.05817848909646273 Engine time: 0.021935815457254648 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-16/adapters_256_slots_192_rate_1.6-0.4-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-16/adapters_256_slots_192_rate_1.6-0.4-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 1080, 17280, 17280, 1080, 17280, 4320, 17280, 1080, 4320, 1080, 17280, 4320, 4320, 4320, 4320, 17280, 1080, 1080, 1080, 4320, 17280, 1080, 17280, 17280, 4320, 4320, 4320, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 1080, 17280, 17280, 4320, 1080, 1080, 17280, 4320, 1080, 4320, 4320, 17280, 4320, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 4320, 1080, 4320, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 4320, 17280, 17280, 17280, 4320, 1080, 17280, 4320, 1080, 1080, 1080, 1080, 1080, 17280, 4320, 1080, 17280, 1080, 17280, 1080, 1080, 4320, 4320, 17280, 4320, 17280, 1080, 4320, 1080, 17280, 17280, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 1080, 4320, 17280, 17280, 1080, 17280, 4320, 1080, 4320, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 4320, 17280, 17280, 4320, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 17280, 1080, 17280, 1080, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 4320, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 1080, 17280, 17280, 4320, 1080, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 17280, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 1080, 1080, 1080, 1080]
Prompts retrieved: 1945080 . Total input tokens: 433756482 . Total output tokens: 389122472
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.178898133803159,
    "estimated_duration": 3600.218978326458,
    "input_throughput": 3666.8886196852095,
    "output_throughput": 3234.8121239596358,
    "total_throughput": 6901.700743644845,
    "itl": 260.83505018721803,
    "ttft": 2256973.9174975595,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2585,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.433698341313002,
    "arrivals": 648144,
    "finished_requests": 53740,
    "scheduler_time": 53.44696871811515
}
#Debug simulation 
Total elapsed time: 4.178964021615684. Arrivals time: 0.45612629782408476 Scheduler time: 3.6083511258475482 Scheduler overhead time: 0.02197602717205882 Adapter cache time: 0.060371559113264084 Engine time: 0.02206273376941681 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-32/adapters_256_slots_192_rate_1.6-0.4-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-32/adapters_256_slots_192_rate_1.6-0.4-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 1080, 17280, 17280, 1080, 17280, 4320, 17280, 1080, 4320, 1080, 17280, 4320, 4320, 4320, 4320, 17280, 1080, 1080, 1080, 4320, 17280, 1080, 17280, 17280, 4320, 4320, 4320, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 1080, 17280, 17280, 4320, 1080, 1080, 17280, 4320, 1080, 4320, 4320, 17280, 4320, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 4320, 1080, 4320, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 4320, 17280, 17280, 17280, 4320, 1080, 17280, 4320, 1080, 1080, 1080, 1080, 1080, 17280, 4320, 1080, 17280, 1080, 17280, 1080, 1080, 4320, 4320, 17280, 4320, 17280, 1080, 4320, 1080, 17280, 17280, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 1080, 4320, 17280, 17280, 1080, 17280, 4320, 1080, 4320, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 4320, 17280, 17280, 4320, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 17280, 1080, 17280, 1080, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 4320, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 1080, 17280, 17280, 4320, 1080, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 17280, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 1080, 1080, 1080, 1080]
Prompts retrieved: 1945080 . Total input tokens: 433756482 . Total output tokens: 389122472
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.8652500309981406,
    "estimated_duration": 3600.003860285046,
    "input_throughput": 3355.0611245854757,
    "output_throughput": 2980.5701372637973,
    "total_throughput": 6335.631261849273,
    "itl": 113.79393469660786,
    "ttft": 2314877.212207822,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2989,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.759094670731217,
    "arrivals": 648144,
    "finished_requests": 49184,
    "scheduler_time": 56.77863915395029
}
#Debug simulation 
Total elapsed time: 3.86533792829141. Arrivals time: 0.19578536367043853 Scheduler time: 3.39628582354635 Scheduler overhead time: 0.04347981233149767 Adapter cache time: 0.16474716132506728 Engine time: 0.044544795993715525 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-16-16/adapters_256_slots_192_rate_1.6-0.4-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-16-16/adapters_256_slots_192_rate_1.6-0.4-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 1080, 17280, 17280, 1080, 17280, 4320, 17280, 1080, 4320, 1080, 17280, 4320, 4320, 4320, 4320, 17280, 1080, 1080, 1080, 4320, 17280, 1080, 17280, 17280, 4320, 4320, 4320, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 1080, 17280, 17280, 4320, 1080, 1080, 17280, 4320, 1080, 4320, 4320, 17280, 4320, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 4320, 1080, 4320, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 4320, 17280, 17280, 17280, 4320, 1080, 17280, 4320, 1080, 1080, 1080, 1080, 1080, 17280, 4320, 1080, 17280, 1080, 17280, 1080, 1080, 4320, 4320, 17280, 4320, 17280, 1080, 4320, 1080, 17280, 17280, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 1080, 4320, 17280, 17280, 1080, 17280, 4320, 1080, 4320, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 4320, 17280, 17280, 4320, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 17280, 1080, 17280, 1080, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 4320, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 1080, 17280, 17280, 4320, 1080, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 17280, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 1080, 1080, 1080, 1080]
Prompts retrieved: 1945080 . Total input tokens: 433756482 . Total output tokens: 389122472
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 3.906528112012893,
    "estimated_duration": 3600.177902022556,
    "input_throughput": 3667.4579310601184,
    "output_throughput": 3235.5389975189673,
    "total_throughput": 6902.996928579086,
    "itl": 260.8155120852047,
    "ttft": 2256868.807548778,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2585,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.097015798918154,
    "arrivals": 648144,
    "finished_requests": 53747,
    "scheduler_time": 53.45129151434113
}
#Debug simulation 
Total elapsed time: 3.906833620276302. Arrivals time: 0.19547953782603145 Scheduler time: 3.5964360875077546 Scheduler overhead time: 0.021934885997325182 Adapter cache time: 0.060647903475910425 Engine time: 0.022056808229535818 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-16-32/adapters_256_slots_192_rate_1.6-0.4-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-16-32/adapters_256_slots_192_rate_1.6-0.4-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 1080, 17280, 17280, 1080, 17280, 4320, 17280, 1080, 4320, 1080, 17280, 4320, 4320, 4320, 4320, 17280, 1080, 1080, 1080, 4320, 17280, 1080, 17280, 17280, 4320, 4320, 4320, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 1080, 17280, 17280, 4320, 1080, 1080, 17280, 4320, 1080, 4320, 4320, 17280, 4320, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 4320, 1080, 4320, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 4320, 17280, 17280, 17280, 4320, 1080, 17280, 4320, 1080, 1080, 1080, 1080, 1080, 17280, 4320, 1080, 17280, 1080, 17280, 1080, 1080, 4320, 4320, 17280, 4320, 17280, 1080, 4320, 1080, 17280, 17280, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 1080, 4320, 17280, 17280, 1080, 17280, 4320, 1080, 4320, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 4320, 17280, 17280, 4320, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 17280, 1080, 17280, 1080, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 4320, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 1080, 17280, 17280, 4320, 1080, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 17280, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 1080, 1080, 1080, 1080]
Prompts retrieved: 1945080 . Total input tokens: 433756482 . Total output tokens: 389122472
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 3.8538771918974817,
    "estimated_duration": 3600.1201106354065,
    "input_throughput": 3354.9527873580423,
    "output_throughput": 2980.473892607485,
    "total_throughput": 6335.426679965527,
    "itl": 113.79773826157634,
    "ttft": 2314917.4985801745,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2989,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.875291169378453,
    "arrivals": 648144,
    "finished_requests": 49184,
    "scheduler_time": 56.778693005750256
}
#Debug simulation 
Total elapsed time: 3.8539637136273086. Arrivals time: 0.18648916948586702 Scheduler time: 3.394482599105686 Scheduler overhead time: 0.04367584362626076 Adapter cache time: 0.16403781389817595 Engine time: 0.04460107022896409 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_16-16-16/adapters_256_slots_192_rate_1.6-0.4-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_16-16-16/adapters_256_slots_192_rate_1.6-0.4-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 1080, 17280, 17280, 1080, 17280, 4320, 17280, 1080, 4320, 1080, 17280, 4320, 4320, 4320, 4320, 17280, 1080, 1080, 1080, 4320, 17280, 1080, 17280, 17280, 4320, 4320, 4320, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 1080, 17280, 17280, 4320, 1080, 1080, 17280, 4320, 1080, 4320, 4320, 17280, 4320, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 4320, 1080, 4320, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 4320, 17280, 17280, 17280, 4320, 1080, 17280, 4320, 1080, 1080, 1080, 1080, 1080, 17280, 4320, 1080, 17280, 1080, 17280, 1080, 1080, 4320, 4320, 17280, 4320, 17280, 1080, 4320, 1080, 17280, 17280, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 1080, 4320, 17280, 17280, 1080, 17280, 4320, 1080, 4320, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 4320, 17280, 17280, 4320, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 17280, 1080, 17280, 1080, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 4320, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 1080, 17280, 17280, 4320, 1080, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 17280, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 1080, 1080, 1080, 1080]
Prompts retrieved: 1945080 . Total input tokens: 433756482 . Total output tokens: 389122472
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 3.906305503565818,
    "estimated_duration": 3600.1062611141524,
    "input_throughput": 3668.00062060204,
    "output_throughput": 3235.823932706586,
    "total_throughput": 6903.824553308626,
    "itl": 260.78726777284453,
    "ttft": 2256849.0245465417,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2585,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.729280012321886,
    "arrivals": 648144,
    "finished_requests": 53752,
    "scheduler_time": 53.45561541118444
}
#Debug simulation 
Total elapsed time: 3.9063990488648415. Arrivals time: 0.19281596690416336 Scheduler time: 3.59928316809237 Scheduler overhead time: 0.022123944014310837 Adapter cache time: 0.0600141161121428 Engine time: 0.022085027303546667 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_16-16-32/adapters_256_slots_192_rate_1.6-0.4-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_16-16-32/adapters_256_slots_192_rate_1.6-0.4-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 1080, 17280, 17280, 1080, 17280, 4320, 17280, 1080, 4320, 1080, 17280, 4320, 4320, 4320, 4320, 17280, 1080, 1080, 1080, 4320, 17280, 1080, 17280, 17280, 4320, 4320, 4320, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 1080, 17280, 17280, 4320, 1080, 1080, 17280, 4320, 1080, 4320, 4320, 17280, 4320, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 4320, 1080, 4320, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 4320, 17280, 17280, 17280, 4320, 1080, 17280, 4320, 1080, 1080, 1080, 1080, 1080, 17280, 4320, 1080, 17280, 1080, 17280, 1080, 1080, 4320, 4320, 17280, 4320, 17280, 1080, 4320, 1080, 17280, 17280, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 1080, 4320, 17280, 17280, 1080, 17280, 4320, 1080, 4320, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 4320, 17280, 17280, 4320, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 17280, 1080, 17280, 1080, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 4320, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 1080, 17280, 17280, 4320, 1080, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 17280, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 1080, 1080, 1080, 1080]
Prompts retrieved: 1945080 . Total input tokens: 433756482 . Total output tokens: 389122472
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.863348691724241,
    "estimated_duration": 3600.123045012572,
    "input_throughput": 3354.8789441328167,
    "output_throughput": 2980.425631525194,
    "total_throughput": 6335.304575658011,
    "itl": 113.80288702820161,
    "ttft": 2314918.1216683965,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2989,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.00594935346341,
    "arrivals": 648144,
    "finished_requests": 49182,
    "scheduler_time": 56.776785797649616
}
#Debug simulation 
Total elapsed time: 3.863430507015437. Arrivals time: 0.19163357000797987 Scheduler time: 3.397924938239157 Scheduler overhead time: 0.043826965149492025 Adapter cache time: 0.16472106706351042 Engine time: 0.044620424043387175 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-8/adapters_256_slots_192_rate_1.6-0.4-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-8/adapters_256_slots_192_rate_1.6-0.4-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 540, 17280, 17280, 540, 17280, 4320, 17280, 540, 4320, 540, 17280, 4320, 4320, 4320, 4320, 17280, 540, 540, 540, 4320, 17280, 540, 17280, 17280, 4320, 4320, 4320, 540, 17280, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 17280, 4320, 540, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 540, 17280, 17280, 4320, 540, 540, 17280, 4320, 540, 4320, 4320, 17280, 4320, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 17280, 17280, 540, 17280, 540, 4320, 17280, 17280, 17280, 4320, 540, 17280, 4320, 540, 540, 540, 540, 540, 17280, 4320, 540, 17280, 540, 17280, 540, 540, 4320, 4320, 17280, 4320, 17280, 540, 4320, 540, 17280, 17280, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 540, 4320, 17280, 17280, 540, 17280, 4320, 540, 4320, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 4320, 17280, 17280, 4320, 540, 17280, 540, 4320, 4320, 540, 4320, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 17280, 540, 17280, 540, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 4320, 4320, 540, 4320, 17280, 4320, 4320, 17280, 540, 17280, 17280, 4320, 540, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 540, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 17280, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 540, 540, 540, 540]
Prompts retrieved: 1899180 . Total input tokens: 423567319 . Total output tokens: 379831664
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 3.9595396099612117,
    "estimated_duration": 3600.1671271789082,
    "input_throughput": 3813.083258375579,
    "output_throughput": 3359.0076718121886,
    "total_throughput": 7172.090930187768,
    "itl": 254.11708213109745,
    "ttft": 2233976.400999474,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1692,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.178345262734363,
    "arrivals": 632850,
    "finished_requests": 55533,
    "scheduler_time": 55.46106260790067
}
#Debug simulation 
Total elapsed time: 3.9596333582885563. Arrivals time: 0.19797035539522767 Scheduler time: 3.6532244295813143 Scheduler overhead time: 0.021789702121168375 Adapter cache time: 0.05444605881348252 Engine time: 0.022160256281495094 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-16/adapters_256_slots_192_rate_1.6-0.4-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-16/adapters_256_slots_192_rate_1.6-0.4-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 540, 17280, 17280, 540, 17280, 4320, 17280, 540, 4320, 540, 17280, 4320, 4320, 4320, 4320, 17280, 540, 540, 540, 4320, 17280, 540, 17280, 17280, 4320, 4320, 4320, 540, 17280, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 17280, 4320, 540, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 540, 17280, 17280, 4320, 540, 540, 17280, 4320, 540, 4320, 4320, 17280, 4320, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 17280, 17280, 540, 17280, 540, 4320, 17280, 17280, 17280, 4320, 540, 17280, 4320, 540, 540, 540, 540, 540, 17280, 4320, 540, 17280, 540, 17280, 540, 540, 4320, 4320, 17280, 4320, 17280, 540, 4320, 540, 17280, 17280, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 540, 4320, 17280, 17280, 540, 17280, 4320, 540, 4320, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 4320, 17280, 17280, 4320, 540, 17280, 540, 4320, 4320, 540, 4320, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 17280, 540, 17280, 540, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 4320, 4320, 540, 4320, 17280, 4320, 4320, 17280, 540, 17280, 17280, 4320, 540, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 540, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 17280, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 540, 540, 540, 540]
Prompts retrieved: 1899180 . Total input tokens: 423567319 . Total output tokens: 379831664
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.966525469906628,
    "estimated_duration": 3600.039129882535,
    "input_throughput": 3810.7330240178885,
    "output_throughput": 3357.007677967748,
    "total_throughput": 7167.740701985636,
    "itl": 251.0979463622467,
    "ttft": 2234419.782762927,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1687,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.499798627560823,
    "arrivals": 632850,
    "finished_requests": 55493,
    "scheduler_time": 55.490642175081945
}
#Debug simulation 
Total elapsed time: 3.9666348570026457. Arrivals time: 0.20152755687013268 Scheduler time: 3.6567863300442696 Scheduler overhead time: 0.02194915385916829 Adapter cache time: 0.05374019546434283 Engine time: 0.022464256267994642 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-32/adapters_256_slots_192_rate_1.6-0.4-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-32/adapters_256_slots_192_rate_1.6-0.4-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 540, 17280, 17280, 540, 17280, 4320, 17280, 540, 4320, 540, 17280, 4320, 4320, 4320, 4320, 17280, 540, 540, 540, 4320, 17280, 540, 17280, 17280, 4320, 4320, 4320, 540, 17280, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 17280, 4320, 540, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 540, 17280, 17280, 4320, 540, 540, 17280, 4320, 540, 4320, 4320, 17280, 4320, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 17280, 17280, 540, 17280, 540, 4320, 17280, 17280, 17280, 4320, 540, 17280, 4320, 540, 540, 540, 540, 540, 17280, 4320, 540, 17280, 540, 17280, 540, 540, 4320, 4320, 17280, 4320, 17280, 540, 4320, 540, 17280, 17280, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 540, 4320, 17280, 17280, 540, 17280, 4320, 540, 4320, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 4320, 17280, 17280, 4320, 540, 17280, 540, 4320, 4320, 540, 4320, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 17280, 540, 17280, 540, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 4320, 4320, 540, 4320, 17280, 4320, 4320, 17280, 540, 17280, 17280, 4320, 540, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 540, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 17280, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 540, 540, 540, 540]
Prompts retrieved: 1899180 . Total input tokens: 423567319 . Total output tokens: 379831664
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.905832476913929,
    "estimated_duration": 3600.1178633238087,
    "input_throughput": 3437.969941509872,
    "output_throughput": 3046.8949674532887,
    "total_throughput": 6484.864908963161,
    "itl": 109.96819169090655,
    "ttft": 2301371.4407452997,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1517,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.95190485564986,
    "arrivals": 632850,
    "finished_requests": 50076,
    "scheduler_time": 58.22728818929568
}
#Debug simulation 
Total elapsed time: 3.90591945592314. Arrivals time: 0.18854849180206656 Scheduler time: 3.4548703874461353 Scheduler overhead time: 0.04472900740802288 Adapter cache time: 0.15073172794654965 Engine time: 0.04579831939190626 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-16-16/adapters_256_slots_192_rate_1.6-0.4-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-16-16/adapters_256_slots_192_rate_1.6-0.4-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 540, 17280, 17280, 540, 17280, 4320, 17280, 540, 4320, 540, 17280, 4320, 4320, 4320, 4320, 17280, 540, 540, 540, 4320, 17280, 540, 17280, 17280, 4320, 4320, 4320, 540, 17280, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 17280, 4320, 540, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 540, 17280, 17280, 4320, 540, 540, 17280, 4320, 540, 4320, 4320, 17280, 4320, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 17280, 17280, 540, 17280, 540, 4320, 17280, 17280, 17280, 4320, 540, 17280, 4320, 540, 540, 540, 540, 540, 17280, 4320, 540, 17280, 540, 17280, 540, 540, 4320, 4320, 17280, 4320, 17280, 540, 4320, 540, 17280, 17280, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 540, 4320, 17280, 17280, 540, 17280, 4320, 540, 4320, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 4320, 17280, 17280, 4320, 540, 17280, 540, 4320, 4320, 540, 4320, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 17280, 540, 17280, 540, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 4320, 4320, 540, 4320, 17280, 4320, 4320, 17280, 540, 17280, 17280, 4320, 540, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 540, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 17280, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 540, 540, 540, 540]
Prompts retrieved: 1899180 . Total input tokens: 423567319 . Total output tokens: 379831664
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 3.964105805847794,
    "estimated_duration": 3600.1100327531262,
    "input_throughput": 3810.870466508545,
    "output_throughput": 3357.1971106553133,
    "total_throughput": 7168.067577163858,
    "itl": 251.08338166599864,
    "ttft": 2234356.7622111444,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1687,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.286511871334965,
    "arrivals": 632850,
    "finished_requests": 55497,
    "scheduler_time": 55.494955877398155
}
#Debug simulation 
Total elapsed time: 3.9642378869466484. Arrivals time: 0.2002431475557387 Scheduler time: 3.6551627768203616 Scheduler overhead time: 0.02205250784754753 Adapter cache time: 0.05416460335254669 Engine time: 0.022445788607001305 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-16-32/adapters_256_slots_192_rate_1.6-0.4-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-16-32/adapters_256_slots_192_rate_1.6-0.4-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 540, 17280, 17280, 540, 17280, 4320, 17280, 540, 4320, 540, 17280, 4320, 4320, 4320, 4320, 17280, 540, 540, 540, 4320, 17280, 540, 17280, 17280, 4320, 4320, 4320, 540, 17280, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 17280, 4320, 540, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 540, 17280, 17280, 4320, 540, 540, 17280, 4320, 540, 4320, 4320, 17280, 4320, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 17280, 17280, 540, 17280, 540, 4320, 17280, 17280, 17280, 4320, 540, 17280, 4320, 540, 540, 540, 540, 540, 17280, 4320, 540, 17280, 540, 17280, 540, 540, 4320, 4320, 17280, 4320, 17280, 540, 4320, 540, 17280, 17280, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 540, 4320, 17280, 17280, 540, 17280, 4320, 540, 4320, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 4320, 17280, 17280, 4320, 540, 17280, 540, 4320, 4320, 540, 4320, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 17280, 540, 17280, 540, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 4320, 4320, 540, 4320, 17280, 4320, 4320, 17280, 540, 17280, 17280, 4320, 540, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 540, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 17280, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 540, 540, 540, 540]
Prompts retrieved: 1899180 . Total input tokens: 423567319 . Total output tokens: 379831664
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 3.9021210712380707,
    "estimated_duration": 3600.0572023524605,
    "input_throughput": 3438.0278713105376,
    "output_throughput": 3046.9463076398283,
    "total_throughput": 6484.974178950366,
    "itl": 109.97004869340114,
    "ttft": 2301393.625162717,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1517,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.010757627692026,
    "arrivals": 632850,
    "finished_requests": 50076,
    "scheduler_time": 58.22536290356956
}
#Debug simulation 
Total elapsed time: 3.9022053591907024. Arrivals time: 0.18323554517701268 Scheduler time: 3.4561569495126605 Scheduler overhead time: 0.04474862990900874 Adapter cache time: 0.15109814750030637 Engine time: 0.04580161767080426 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_16-16-16/adapters_256_slots_192_rate_1.6-0.4-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_16-16-16/adapters_256_slots_192_rate_1.6-0.4-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 540, 17280, 17280, 540, 17280, 4320, 17280, 540, 4320, 540, 17280, 4320, 4320, 4320, 4320, 17280, 540, 540, 540, 4320, 17280, 540, 17280, 17280, 4320, 4320, 4320, 540, 17280, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 17280, 4320, 540, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 540, 17280, 17280, 4320, 540, 540, 17280, 4320, 540, 4320, 4320, 17280, 4320, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 17280, 17280, 540, 17280, 540, 4320, 17280, 17280, 17280, 4320, 540, 17280, 4320, 540, 540, 540, 540, 540, 17280, 4320, 540, 17280, 540, 17280, 540, 540, 4320, 4320, 17280, 4320, 17280, 540, 4320, 540, 17280, 17280, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 540, 4320, 17280, 17280, 540, 17280, 4320, 540, 4320, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 4320, 17280, 17280, 4320, 540, 17280, 540, 4320, 4320, 540, 4320, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 17280, 540, 17280, 540, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 4320, 4320, 540, 4320, 17280, 4320, 4320, 17280, 540, 17280, 17280, 4320, 540, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 540, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 17280, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 540, 540, 540, 540]
Prompts retrieved: 1899180 . Total input tokens: 423567319 . Total output tokens: 379831664
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 3.957807915750891,
    "estimated_duration": 3600.1505901248097,
    "input_throughput": 3811.272516665564,
    "output_throughput": 3357.352337747897,
    "total_throughput": 7168.624854413461,
    "itl": 251.0746008823149,
    "ttft": 2234352.4144725017,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1688,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.04720489779473,
    "arrivals": 632850,
    "finished_requests": 55501,
    "scheduler_time": 55.498969320400924
}
#Debug simulation 
Total elapsed time: 3.957906750962138. Arrivals time: 0.19663416361436248 Scheduler time: 3.653037182521075 Scheduler overhead time: 0.02193524967879057 Adapter cache time: 0.05367692233994603 Engine time: 0.02247537672519684 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_16-16-32/adapters_256_slots_192_rate_1.6-0.4-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_16-16-32/adapters_256_slots_192_rate_1.6-0.4-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 540, 17280, 17280, 540, 17280, 4320, 17280, 540, 4320, 540, 17280, 4320, 4320, 4320, 4320, 17280, 540, 540, 540, 4320, 17280, 540, 17280, 17280, 4320, 4320, 4320, 540, 17280, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 17280, 4320, 540, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 540, 17280, 17280, 4320, 540, 540, 17280, 4320, 540, 4320, 4320, 17280, 4320, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 17280, 17280, 540, 17280, 540, 4320, 17280, 17280, 17280, 4320, 540, 17280, 4320, 540, 540, 540, 540, 540, 17280, 4320, 540, 17280, 540, 17280, 540, 540, 4320, 4320, 17280, 4320, 17280, 540, 4320, 540, 17280, 17280, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 540, 4320, 17280, 17280, 540, 17280, 4320, 540, 4320, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 4320, 17280, 17280, 4320, 540, 17280, 540, 4320, 4320, 540, 4320, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 17280, 540, 17280, 540, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 4320, 4320, 540, 4320, 17280, 4320, 4320, 17280, 540, 17280, 17280, 4320, 540, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 540, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 17280, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 540, 540, 540, 540]
Prompts retrieved: 1899180 . Total input tokens: 423567319 . Total output tokens: 379831664
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.919208053033799,
    "estimated_duration": 3600.0035049277385,
    "input_throughput": 3437.9977639072977,
    "output_throughput": 3046.9517557372983,
    "total_throughput": 6484.949519644596,
    "itl": 109.97198390699928,
    "ttft": 2301438.829604355,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1517,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.07677836555983,
    "arrivals": 632850,
    "finished_requests": 50075,
    "scheduler_time": 58.22343286891986
}
#Debug simulation 
Total elapsed time: 3.919293339829892. Arrivals time: 0.18166836211457849 Scheduler time: 3.475099286530167 Scheduler overhead time: 0.044676297809928656 Adapter cache time: 0.1509529403410852 Engine time: 0.0457653715275228 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-8/adapters_256_slots_192_rate_1.6-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-8/adapters_256_slots_192_rate_1.6-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 270, 17280, 17280, 270, 17280, 4320, 17280, 270, 4320, 270, 17280, 4320, 4320, 4320, 4320, 17280, 270, 270, 270, 4320, 17280, 270, 17280, 17280, 4320, 4320, 4320, 270, 17280, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 17280, 4320, 270, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 270, 17280, 17280, 4320, 270, 270, 17280, 4320, 270, 4320, 4320, 17280, 4320, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 17280, 17280, 270, 17280, 270, 4320, 17280, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 270, 270, 270, 17280, 4320, 270, 17280, 270, 17280, 270, 270, 4320, 4320, 17280, 4320, 17280, 270, 4320, 270, 17280, 17280, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 270, 4320, 17280, 17280, 270, 17280, 4320, 270, 4320, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 4320, 17280, 17280, 4320, 270, 17280, 270, 4320, 4320, 270, 4320, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 17280, 270, 17280, 270, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 4320, 4320, 270, 4320, 17280, 4320, 4320, 17280, 270, 17280, 17280, 4320, 270, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 270, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 17280, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 270, 270, 270, 270]
Prompts retrieved: 1876230 . Total input tokens: 418371695 . Total output tokens: 375262201
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.064819076098502,
    "estimated_duration": 3600.273518042305,
    "input_throughput": 3942.8548772369127,
    "output_throughput": 3465.5491971578003,
    "total_throughput": 7408.404074394713,
    "itl": 245.908945091509,
    "ttft": 2224375.9933207785,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 851,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6044750700868278,
    "arrivals": 625482,
    "finished_requests": 57365,
    "scheduler_time": 57.1512035333371
}
#Debug simulation 
Total elapsed time: 4.064899971708655. Arrivals time: 0.19985722890123725 Scheduler time: 3.762556518893689 Scheduler overhead time: 0.022383250296115875 Adapter cache time: 0.04671435849741101 Engine time: 0.023041068110615015 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-16/adapters_256_slots_192_rate_1.6-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-16/adapters_256_slots_192_rate_1.6-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 270, 17280, 17280, 270, 17280, 4320, 17280, 270, 4320, 270, 17280, 4320, 4320, 4320, 4320, 17280, 270, 270, 270, 4320, 17280, 270, 17280, 17280, 4320, 4320, 4320, 270, 17280, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 17280, 4320, 270, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 270, 17280, 17280, 4320, 270, 270, 17280, 4320, 270, 4320, 4320, 17280, 4320, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 17280, 17280, 270, 17280, 270, 4320, 17280, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 270, 270, 270, 17280, 4320, 270, 17280, 270, 17280, 270, 270, 4320, 4320, 17280, 4320, 17280, 270, 4320, 270, 17280, 17280, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 270, 4320, 17280, 17280, 270, 17280, 4320, 270, 4320, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 4320, 17280, 17280, 4320, 270, 17280, 270, 4320, 4320, 270, 4320, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 17280, 270, 17280, 270, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 4320, 4320, 270, 4320, 17280, 4320, 4320, 17280, 270, 17280, 17280, 4320, 270, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 270, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 17280, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 270, 270, 270, 270]
Prompts retrieved: 1876230 . Total input tokens: 418371695 . Total output tokens: 375262201
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.056595750153065,
    "estimated_duration": 3600.1507867208866,
    "input_throughput": 3938.5883647709875,
    "output_throughput": 3462.230261569973,
    "total_throughput": 7400.818626340961,
    "itl": 242.9288087974292,
    "ttft": 2225200.1153843286,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 847,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.757300024924337,
    "arrivals": 625482,
    "finished_requests": 57299,
    "scheduler_time": 57.17776164473384
}
#Debug simulation 
Total elapsed time: 4.0567101701162755. Arrivals time: 0.19993213983252645 Scheduler time: 3.752833175472915 Scheduler overhead time: 0.022477262653410435 Adapter cache time: 0.047950700391083956 Engine time: 0.02307573240250349 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-32/adapters_256_slots_192_rate_1.6-0.4-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-32/adapters_256_slots_192_rate_1.6-0.4-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 270, 17280, 17280, 270, 17280, 4320, 17280, 270, 4320, 270, 17280, 4320, 4320, 4320, 4320, 17280, 270, 270, 270, 4320, 17280, 270, 17280, 17280, 4320, 4320, 4320, 270, 17280, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 17280, 4320, 270, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 270, 17280, 17280, 4320, 270, 270, 17280, 4320, 270, 4320, 4320, 17280, 4320, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 17280, 17280, 270, 17280, 270, 4320, 17280, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 270, 270, 270, 17280, 4320, 270, 17280, 270, 17280, 270, 270, 4320, 4320, 17280, 4320, 17280, 270, 4320, 270, 17280, 17280, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 270, 4320, 17280, 17280, 270, 17280, 4320, 270, 4320, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 4320, 17280, 17280, 4320, 270, 17280, 270, 4320, 4320, 270, 4320, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 17280, 270, 17280, 270, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 4320, 4320, 270, 4320, 17280, 4320, 4320, 17280, 270, 17280, 17280, 4320, 270, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 270, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 17280, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 270, 270, 270, 270]
Prompts retrieved: 1876230 . Total input tokens: 418371695 . Total output tokens: 375262201
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.001589528284967,
    "estimated_duration": 3600.0451044608717,
    "input_throughput": 3517.5548173851043,
    "output_throughput": 3112.780166591326,
    "total_throughput": 6630.3349839764305,
    "itl": 108.19670685882774,
    "ttft": 2295965.0403284975,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 754,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4620879692584237,
    "arrivals": 625482,
    "finished_requests": 51172,
    "scheduler_time": 59.365675142313435
}
#Debug simulation 
Total elapsed time: 4.001674338243902. Arrivals time: 0.2210967382416129 Scheduler time: 3.526852562557906 Scheduler overhead time: 0.0453245947137475 Adapter cache time: 0.14024352608248591 Engine time: 0.04675056738778949 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-16-16/adapters_256_slots_192_rate_1.6-0.4-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-16-16/adapters_256_slots_192_rate_1.6-0.4-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 270, 17280, 17280, 270, 17280, 4320, 17280, 270, 4320, 270, 17280, 4320, 4320, 4320, 4320, 17280, 270, 270, 270, 4320, 17280, 270, 17280, 17280, 4320, 4320, 4320, 270, 17280, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 17280, 4320, 270, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 270, 17280, 17280, 4320, 270, 270, 17280, 4320, 270, 4320, 4320, 17280, 4320, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 17280, 17280, 270, 17280, 270, 4320, 17280, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 270, 270, 270, 17280, 4320, 270, 17280, 270, 17280, 270, 270, 4320, 4320, 17280, 4320, 17280, 270, 4320, 270, 17280, 17280, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 270, 4320, 17280, 17280, 270, 17280, 4320, 270, 4320, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 4320, 17280, 17280, 4320, 270, 17280, 270, 4320, 4320, 270, 4320, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 17280, 270, 17280, 270, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 4320, 4320, 270, 4320, 17280, 4320, 4320, 17280, 270, 17280, 17280, 4320, 270, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 270, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 17280, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 270, 270, 270, 270]
Prompts retrieved: 1876230 . Total input tokens: 418371695 . Total output tokens: 375262201
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.089970517903566,
    "estimated_duration": 3600.0264372450774,
    "input_throughput": 3938.7535750573434,
    "output_throughput": 3462.402351005692,
    "total_throughput": 7401.155926063035,
    "itl": 242.95850878827122,
    "ttft": 2225271.837303685,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 848,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6552810783800442,
    "arrivals": 625482,
    "finished_requests": 57301,
    "scheduler_time": 57.17723308702737
}
#Debug simulation 
Total elapsed time: 4.090088521130383. Arrivals time: 0.20085991639643908 Scheduler time: 3.78422789555043 Scheduler overhead time: 0.022648945450782776 Adapter cache time: 0.048548674676567316 Engine time: 0.023243767209351063 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-16-32/adapters_256_slots_192_rate_1.6-0.4-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-16-32/adapters_256_slots_192_rate_1.6-0.4-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 270, 17280, 17280, 270, 17280, 4320, 17280, 270, 4320, 270, 17280, 4320, 4320, 4320, 4320, 17280, 270, 270, 270, 4320, 17280, 270, 17280, 17280, 4320, 4320, 4320, 270, 17280, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 17280, 4320, 270, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 270, 17280, 17280, 4320, 270, 270, 17280, 4320, 270, 4320, 4320, 17280, 4320, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 17280, 17280, 270, 17280, 270, 4320, 17280, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 270, 270, 270, 17280, 4320, 270, 17280, 270, 17280, 270, 270, 4320, 4320, 17280, 4320, 17280, 270, 4320, 270, 17280, 17280, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 270, 4320, 17280, 17280, 270, 17280, 4320, 270, 4320, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 4320, 17280, 17280, 4320, 270, 17280, 270, 4320, 4320, 270, 4320, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 17280, 270, 17280, 270, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 4320, 4320, 270, 4320, 17280, 4320, 4320, 17280, 270, 17280, 17280, 4320, 270, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 270, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 17280, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 270, 270, 270, 270]
Prompts retrieved: 1876230 . Total input tokens: 418371695 . Total output tokens: 375262201
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 3.9481379128992558,
    "estimated_duration": 3600.075080803052,
    "input_throughput": 3517.525528155164,
    "output_throughput": 3112.7542477531597,
    "total_throughput": 6630.279775908323,
    "itl": 108.19763318609857,
    "ttft": 2295977.643066143,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 754,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.492017370425168,
    "arrivals": 625482,
    "finished_requests": 51172,
    "scheduler_time": 59.36572208334972
}
#Debug simulation 
Total elapsed time: 3.948223046027124. Arrivals time: 0.18580080149695277 Scheduler time: 3.5108402324840426 Scheduler overhead time: 0.04505940666422248 Adapter cache time: 0.13878504000604153 Engine time: 0.046340926084667444 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_16-16-16/adapters_256_slots_192_rate_1.6-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_16-16-16/adapters_256_slots_192_rate_1.6-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 270, 17280, 17280, 270, 17280, 4320, 17280, 270, 4320, 270, 17280, 4320, 4320, 4320, 4320, 17280, 270, 270, 270, 4320, 17280, 270, 17280, 17280, 4320, 4320, 4320, 270, 17280, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 17280, 4320, 270, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 270, 17280, 17280, 4320, 270, 270, 17280, 4320, 270, 4320, 4320, 17280, 4320, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 17280, 17280, 270, 17280, 270, 4320, 17280, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 270, 270, 270, 17280, 4320, 270, 17280, 270, 17280, 270, 270, 4320, 4320, 17280, 4320, 17280, 270, 4320, 270, 17280, 17280, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 270, 4320, 17280, 17280, 270, 17280, 4320, 270, 4320, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 4320, 17280, 17280, 4320, 270, 17280, 270, 4320, 4320, 270, 4320, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 17280, 270, 17280, 270, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 4320, 4320, 270, 4320, 17280, 4320, 4320, 17280, 270, 17280, 17280, 4320, 270, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 270, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 17280, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 270, 270, 270, 270]
Prompts retrieved: 1876230 . Total input tokens: 418371695 . Total output tokens: 375262201
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.083703469019383,
    "estimated_duration": 3600.183466459411,
    "input_throughput": 3938.7951008912482,
    "output_throughput": 3462.3552149854117,
    "total_throughput": 7401.15031587666,
    "itl": 242.9523060849988,
    "ttft": 2225247.7005296242,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 848,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.535562650076992,
    "arrivals": 625482,
    "finished_requests": 57303,
    "scheduler_time": 57.18150208782829
}
#Debug simulation 
Total elapsed time: 4.083789519965649. Arrivals time: 0.19656322244554758 Scheduler time: 3.782786976546049 Scheduler overhead time: 0.022623895201832056 Adapter cache time: 0.04809542233124375 Engine time: 0.023253563791513443 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_16-16-32/adapters_256_slots_192_rate_1.6-0.4-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_16-16-32/adapters_256_slots_192_rate_1.6-0.4-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 270, 17280, 17280, 270, 17280, 4320, 17280, 270, 4320, 270, 17280, 4320, 4320, 4320, 4320, 17280, 270, 270, 270, 4320, 17280, 270, 17280, 17280, 4320, 4320, 4320, 270, 17280, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 17280, 4320, 270, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 270, 17280, 17280, 4320, 270, 270, 17280, 4320, 270, 4320, 4320, 17280, 4320, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 17280, 17280, 270, 17280, 270, 4320, 17280, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 270, 270, 270, 17280, 4320, 270, 17280, 270, 17280, 270, 270, 4320, 4320, 17280, 4320, 17280, 270, 4320, 270, 17280, 17280, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 270, 4320, 17280, 17280, 270, 17280, 4320, 270, 4320, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 4320, 17280, 17280, 4320, 270, 17280, 270, 4320, 4320, 270, 4320, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 17280, 270, 17280, 270, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 4320, 4320, 270, 4320, 17280, 4320, 4320, 17280, 270, 17280, 17280, 4320, 270, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 270, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 17280, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 270, 270, 270, 270]
Prompts retrieved: 1876230 . Total input tokens: 418371695 . Total output tokens: 375262201
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.9710120880044997,
    "estimated_duration": 3600.107571829784,
    "input_throughput": 3517.4937824326585,
    "output_throughput": 3112.7261550977446,
    "total_throughput": 6630.219937530403,
    "itl": 108.19861709146518,
    "ttft": 2295990.749403373,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 754,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5244618473202114,
    "arrivals": 625482,
    "finished_requests": 51172,
    "scheduler_time": 59.36576863321071
}
#Debug simulation 
Total elapsed time: 3.971093863248825. Arrivals time: 0.2120580547489226 Scheduler time: 3.506908259820193 Scheduler overhead time: 0.04523033369332552 Adapter cache time: 0.13882138347253203 Engine time: 0.046599982772022486 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-8/adapters_256_slots_192_rate_1.6-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-8/adapters_256_slots_192_rate_1.6-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 135, 17280, 17280, 135, 17280, 4320, 17280, 135, 4320, 135, 17280, 4320, 4320, 4320, 4320, 17280, 135, 135, 135, 4320, 17280, 135, 17280, 17280, 4320, 4320, 4320, 135, 17280, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 17280, 4320, 135, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 135, 17280, 17280, 4320, 135, 135, 17280, 4320, 135, 4320, 4320, 17280, 4320, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 17280, 17280, 135, 17280, 135, 4320, 17280, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 135, 135, 135, 17280, 4320, 135, 17280, 135, 17280, 135, 135, 4320, 4320, 17280, 4320, 17280, 135, 4320, 135, 17280, 17280, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 135, 4320, 17280, 17280, 135, 17280, 4320, 135, 4320, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 4320, 17280, 17280, 4320, 135, 17280, 135, 4320, 4320, 135, 4320, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 17280, 135, 17280, 135, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 4320, 4320, 135, 4320, 17280, 4320, 4320, 17280, 135, 17280, 17280, 4320, 135, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 135, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 17280, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 135, 135, 135, 135]
Prompts retrieved: 1864755 . Total input tokens: 415800092 . Total output tokens: 372975680
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.108936125878245,
    "estimated_duration": 3600.123388993491,
    "input_throughput": 4021.2874492747487,
    "output_throughput": 3528.843494320291,
    "total_throughput": 7550.13094359504,
    "itl": 241.7687635778188,
    "ttft": 2207614.9349646405,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 467,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4292477764166096,
    "arrivals": 621618,
    "finished_requests": 58585,
    "scheduler_time": 58.19456053617055
}
#Debug simulation 
Total elapsed time: 4.109014121815562. Arrivals time: 0.19229385862126946 Scheduler time: 3.82200839696452 Scheduler overhead time: 0.022780447732657194 Adapter cache time: 0.03803606145083904 Engine time: 0.023352353367954493 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-16/adapters_256_slots_192_rate_1.6-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-16/adapters_256_slots_192_rate_1.6-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 135, 17280, 17280, 135, 17280, 4320, 17280, 135, 4320, 135, 17280, 4320, 4320, 4320, 4320, 17280, 135, 135, 135, 4320, 17280, 135, 17280, 17280, 4320, 4320, 4320, 135, 17280, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 17280, 4320, 135, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 135, 17280, 17280, 4320, 135, 135, 17280, 4320, 135, 4320, 4320, 17280, 4320, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 17280, 17280, 135, 17280, 135, 4320, 17280, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 135, 135, 135, 17280, 4320, 135, 17280, 135, 17280, 135, 135, 4320, 4320, 17280, 4320, 17280, 135, 4320, 135, 17280, 17280, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 135, 4320, 17280, 17280, 135, 17280, 4320, 135, 4320, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 4320, 17280, 17280, 4320, 135, 17280, 135, 4320, 4320, 135, 4320, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 17280, 135, 17280, 135, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 4320, 4320, 135, 4320, 17280, 4320, 4320, 17280, 135, 17280, 17280, 4320, 135, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 135, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 17280, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 135, 135, 135, 135]
Prompts retrieved: 1864755 . Total input tokens: 415800092 . Total output tokens: 372975680
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.134817470796406,
    "estimated_duration": 3600.2238074459888,
    "input_throughput": 4016.7402843377117,
    "output_throughput": 3525.2783379052207,
    "total_throughput": 7542.018622242932,
    "itl": 239.46035884943632,
    "ttft": 2208706.767680356,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 467,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5226094411173885,
    "arrivals": 621618,
    "finished_requests": 58511,
    "scheduler_time": 58.182441453478205
}
#Debug simulation 
Total elapsed time: 4.134905323851854. Arrivals time: 0.19894016394391656 Scheduler time: 3.839976674411446 Scheduler overhead time: 0.023431916255503893 Adapter cache time: 0.03799252584576607 Engine time: 0.02391079207882285 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-32/adapters_256_slots_192_rate_1.6-0.4-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-32/adapters_256_slots_192_rate_1.6-0.4-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 135, 17280, 17280, 135, 17280, 4320, 17280, 135, 4320, 135, 17280, 4320, 4320, 4320, 4320, 17280, 135, 135, 135, 4320, 17280, 135, 17280, 17280, 4320, 4320, 4320, 135, 17280, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 17280, 4320, 135, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 135, 17280, 17280, 4320, 135, 135, 17280, 4320, 135, 4320, 4320, 17280, 4320, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 17280, 17280, 135, 17280, 135, 4320, 17280, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 135, 135, 135, 17280, 4320, 135, 17280, 135, 17280, 135, 135, 4320, 4320, 17280, 4320, 17280, 135, 4320, 135, 17280, 17280, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 135, 4320, 17280, 17280, 135, 17280, 4320, 135, 4320, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 4320, 17280, 17280, 4320, 135, 17280, 135, 4320, 4320, 135, 4320, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 17280, 135, 17280, 135, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 4320, 4320, 135, 4320, 17280, 4320, 4320, 17280, 135, 17280, 17280, 4320, 135, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 135, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 17280, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 135, 135, 135, 135]
Prompts retrieved: 1864755 . Total input tokens: 415800092 . Total output tokens: 372975680
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.988875214010477,
    "estimated_duration": 3600.0075975167947,
    "input_throughput": 3543.834465460592,
    "output_throughput": 3128.585619588392,
    "total_throughput": 6672.420085048984,
    "itl": 108.07860097023182,
    "ttft": 2285402.253302681,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 421,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3764252287894567,
    "arrivals": 621618,
    "finished_requests": 51635,
    "scheduler_time": 59.62474895189855
}
#Debug simulation 
Total elapsed time: 3.9889768781140447. Arrivals time: 0.21296320762485266 Scheduler time: 3.5322060519829392 Scheduler overhead time: 0.04538194090127945 Adapter cache time: 0.13026667665690184 Engine time: 0.04666458023712039 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-16/adapters_256_slots_192_rate_1.6-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-16/adapters_256_slots_192_rate_1.6-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 135, 17280, 17280, 135, 17280, 4320, 17280, 135, 4320, 135, 17280, 4320, 4320, 4320, 4320, 17280, 135, 135, 135, 4320, 17280, 135, 17280, 17280, 4320, 4320, 4320, 135, 17280, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 17280, 4320, 135, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 135, 17280, 17280, 4320, 135, 135, 17280, 4320, 135, 4320, 4320, 17280, 4320, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 17280, 17280, 135, 17280, 135, 4320, 17280, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 135, 135, 135, 17280, 4320, 135, 17280, 135, 17280, 135, 135, 4320, 4320, 17280, 4320, 17280, 135, 4320, 135, 17280, 17280, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 135, 4320, 17280, 17280, 135, 17280, 4320, 135, 4320, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 4320, 17280, 17280, 4320, 135, 17280, 135, 4320, 4320, 135, 4320, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 17280, 135, 17280, 135, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 4320, 4320, 135, 4320, 17280, 4320, 4320, 17280, 135, 17280, 17280, 4320, 135, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 135, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 17280, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 135, 135, 135, 135]
Prompts retrieved: 1864755 . Total input tokens: 415800092 . Total output tokens: 372975680
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.100337753072381,
    "estimated_duration": 3600.2606428406734,
    "input_throughput": 4016.616971539622,
    "output_throughput": 3524.969789405778,
    "total_throughput": 7541.586760945401,
    "itl": 239.28810021813513,
    "ttft": 2208748.065177078,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 467,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4596857620775654,
    "arrivals": 621618,
    "finished_requests": 58507,
    "scheduler_time": 58.18467106433453
}
#Debug simulation 
Total elapsed time: 4.100443324074149. Arrivals time: 0.19174794061109424 Scheduler time: 3.813178911805153 Scheduler overhead time: 0.022932579275220633 Adapter cache time: 0.03835123172029853 Engine time: 0.023596569430083036 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-32/adapters_256_slots_192_rate_1.6-0.4-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-32/adapters_256_slots_192_rate_1.6-0.4-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 135, 17280, 17280, 135, 17280, 4320, 17280, 135, 4320, 135, 17280, 4320, 4320, 4320, 4320, 17280, 135, 135, 135, 4320, 17280, 135, 17280, 17280, 4320, 4320, 4320, 135, 17280, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 17280, 4320, 135, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 135, 17280, 17280, 4320, 135, 135, 17280, 4320, 135, 4320, 4320, 17280, 4320, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 17280, 17280, 135, 17280, 135, 4320, 17280, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 135, 135, 135, 17280, 4320, 135, 17280, 135, 17280, 135, 135, 4320, 4320, 17280, 4320, 17280, 135, 4320, 135, 17280, 17280, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 135, 4320, 17280, 17280, 135, 17280, 4320, 135, 4320, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 4320, 17280, 17280, 4320, 135, 17280, 135, 4320, 4320, 135, 4320, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 17280, 135, 17280, 135, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 4320, 4320, 135, 4320, 17280, 4320, 4320, 17280, 135, 17280, 17280, 4320, 135, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 135, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 17280, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 135, 135, 135, 135]
Prompts retrieved: 1864755 . Total input tokens: 415800092 . Total output tokens: 372975680
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 3.968637510202825,
    "estimated_duration": 3600.0251223825726,
    "input_throughput": 3543.8172141300497,
    "output_throughput": 3128.5703896827126,
    "total_throughput": 6672.387603812762,
    "itl": 108.07914384418785,
    "ttft": 2285410.6542105502,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 421,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3939050051011193,
    "arrivals": 621618,
    "finished_requests": 51635,
    "scheduler_time": 59.62479404137174
}
#Debug simulation 
Total elapsed time: 3.9687326881103218. Arrivals time: 0.17977433279156685 Scheduler time: 3.544877843465656 Scheduler overhead time: 0.04545674566179514 Adapter cache time: 0.1303031900897622 Engine time: 0.04681108659133315 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-16/adapters_256_slots_192_rate_1.6-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-16/adapters_256_slots_192_rate_1.6-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 135, 17280, 17280, 135, 17280, 4320, 17280, 135, 4320, 135, 17280, 4320, 4320, 4320, 4320, 17280, 135, 135, 135, 4320, 17280, 135, 17280, 17280, 4320, 4320, 4320, 135, 17280, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 17280, 4320, 135, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 135, 17280, 17280, 4320, 135, 135, 17280, 4320, 135, 4320, 4320, 17280, 4320, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 17280, 17280, 135, 17280, 135, 4320, 17280, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 135, 135, 135, 17280, 4320, 135, 17280, 135, 17280, 135, 135, 4320, 4320, 17280, 4320, 17280, 135, 4320, 135, 17280, 17280, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 135, 4320, 17280, 17280, 135, 17280, 4320, 135, 4320, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 4320, 17280, 17280, 4320, 135, 17280, 135, 4320, 4320, 135, 4320, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 17280, 135, 17280, 135, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 4320, 4320, 135, 4320, 17280, 4320, 4320, 17280, 135, 17280, 17280, 4320, 135, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 135, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 17280, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 135, 135, 135, 135]
Prompts retrieved: 1864755 . Total input tokens: 415800092 . Total output tokens: 372975680
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.148951551876962,
    "estimated_duration": 3600.1265332494413,
    "input_throughput": 4016.8488152963573,
    "output_throughput": 3525.3735897289434,
    "total_throughput": 7542.222405025301,
    "itl": 239.44651573692727,
    "ttft": 2208667.5767138577,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 467,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3963534877193033,
    "arrivals": 621618,
    "finished_requests": 58511,
    "scheduler_time": 58.18250655082173
}
#Debug simulation 
Total elapsed time: 4.14903429010883. Arrivals time: 0.19315224699676037 Scheduler time: 3.8604240934364498 Scheduler overhead time: 0.02304220525547862 Adapter cache time: 0.03812008164823055 Engine time: 0.023636294528841972 
