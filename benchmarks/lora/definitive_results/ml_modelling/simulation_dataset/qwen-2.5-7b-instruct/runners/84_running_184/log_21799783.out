INFO 06-01 00:47:09 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:47:09 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-8/adapters_160_slots_96_rate_1.6-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-8/adapters_160_slots_96_rate_1.6-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 4320, 33, 33, 33, 17280, 33, 4320, 17280, 4320, 33, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 33, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 33, 4320, 4320, 4320, 17280, 33, 33, 17280, 33, 17280, 33, 33, 4320, 33, 4320, 17280, 33, 33, 4320, 33, 33, 33, 33, 33, 17280, 4320, 4320, 17280, 4320, 33, 17280, 17280, 17280, 4320, 4320, 33, 33, 33, 17280, 33, 4320, 4320, 33, 17280, 17280, 17280, 33, 33, 17280, 4320, 17280, 17280, 33, 17280, 33, 4320, 33, 33, 4320, 4320, 17280, 17280, 17280, 33, 17280, 4320, 4320, 33, 33, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 33, 4320, 4320, 17280, 4320, 17280, 33, 33, 33, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 33, 4320, 4320, 33, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 33, 17280, 33, 17280, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 17280, 4320, 33, 33]
Prompts retrieved: 1163829 . Total input tokens: 259366894 . Total output tokens: 232670004
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 6.2902547926642,
    "estimated_duration": 3600.094874680386,
    "input_throughput": 5362.738947737872,
    "output_throughput": 4747.595992596555,
    "total_throughput": 10110.334940334427,
    "itl": 181.5115453313802,
    "ttft": 1959187.9854955946,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 428,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.309888754403228,
    "arrivals": 388315,
    "finished_requests": 78054,
    "scheduler_time": 95.32230830736658
}
#Debug simulation 
Total elapsed time: 6.290416287723929. Arrivals time: 0.25842784298583865 Scheduler time: 5.940424141008407 Scheduler overhead time: 0.032398360315710306 Adapter cache time: 0.01157112279906869 Engine time: 0.03279159823432565 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-16/adapters_160_slots_96_rate_1.6-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-16/adapters_160_slots_96_rate_1.6-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 4320, 33, 33, 33, 17280, 33, 4320, 17280, 4320, 33, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 33, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 33, 4320, 4320, 4320, 17280, 33, 33, 17280, 33, 17280, 33, 33, 4320, 33, 4320, 17280, 33, 33, 4320, 33, 33, 33, 33, 33, 17280, 4320, 4320, 17280, 4320, 33, 17280, 17280, 17280, 4320, 4320, 33, 33, 33, 17280, 33, 4320, 4320, 33, 17280, 17280, 17280, 33, 33, 17280, 4320, 17280, 17280, 33, 17280, 33, 4320, 33, 33, 4320, 4320, 17280, 17280, 17280, 33, 17280, 4320, 4320, 33, 33, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 33, 4320, 4320, 17280, 4320, 17280, 33, 33, 33, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 33, 4320, 4320, 33, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 33, 17280, 33, 17280, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 17280, 4320, 33, 33]
Prompts retrieved: 1163829 . Total input tokens: 259366894 . Total output tokens: 232670004
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.235253984108567,
    "estimated_duration": 3600.139071574489,
    "input_throughput": 5362.673112390775,
    "output_throughput": 4747.537709015517,
    "total_throughput": 10110.210821406292,
    "itl": 181.51622989553343,
    "ttft": 1959205.6017986427,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 428,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3949654060183148,
    "arrivals": 388315,
    "finished_requests": 78054,
    "scheduler_time": 95.32203325714636
}
#Debug simulation 
Total elapsed time: 6.2353954440914094. Arrivals time: 0.2561026755720377 Scheduler time: 5.888758270535618 Scheduler overhead time: 0.03208466665819287 Adapter cache time: 0.01147695118561387 Engine time: 0.0321678533218801 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-32/adapters_160_slots_96_rate_1.6-0.4-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-32/adapters_160_slots_96_rate_1.6-0.4-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 4320, 33, 33, 33, 17280, 33, 4320, 17280, 4320, 33, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 33, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 33, 4320, 4320, 4320, 17280, 33, 33, 17280, 33, 17280, 33, 33, 4320, 33, 4320, 17280, 33, 33, 4320, 33, 33, 33, 33, 33, 17280, 4320, 4320, 17280, 4320, 33, 17280, 17280, 17280, 4320, 4320, 33, 33, 33, 17280, 33, 4320, 4320, 33, 17280, 17280, 17280, 33, 33, 17280, 4320, 17280, 17280, 33, 17280, 33, 4320, 33, 33, 4320, 4320, 17280, 17280, 17280, 33, 17280, 4320, 4320, 33, 33, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 33, 4320, 4320, 17280, 4320, 17280, 33, 33, 33, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 33, 4320, 4320, 33, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 33, 17280, 33, 17280, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 17280, 4320, 33, 33]
Prompts retrieved: 1163829 . Total input tokens: 259366894 . Total output tokens: 232670004
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.162721389904618,
    "estimated_duration": 3600.1934424928972,
    "input_throughput": 5347.004350596913,
    "output_throughput": 4734.267553189575,
    "total_throughput": 10081.271903786488,
    "itl": 179.46425689429063,
    "ttft": 1961453.2622680026,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 451,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4734640016593126,
    "arrivals": 388315,
    "finished_requests": 77827,
    "scheduler_time": 95.43257510060208
}
#Debug simulation 
Total elapsed time: 6.1628160970285535. Arrivals time: 0.2640413264743984 Scheduler time: 5.806028767023236 Scheduler overhead time: 0.03301543742418289 Adapter cache time: 0.012014367617666721 Engine time: 0.0327603854238987 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-16/adapters_160_slots_96_rate_1.6-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-16/adapters_160_slots_96_rate_1.6-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 4320, 33, 33, 33, 17280, 33, 4320, 17280, 4320, 33, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 33, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 33, 4320, 4320, 4320, 17280, 33, 33, 17280, 33, 17280, 33, 33, 4320, 33, 4320, 17280, 33, 33, 4320, 33, 33, 33, 33, 33, 17280, 4320, 4320, 17280, 4320, 33, 17280, 17280, 17280, 4320, 4320, 33, 33, 33, 17280, 33, 4320, 4320, 33, 17280, 17280, 17280, 33, 33, 17280, 4320, 17280, 17280, 33, 17280, 33, 4320, 33, 33, 4320, 4320, 17280, 17280, 17280, 33, 17280, 4320, 4320, 33, 33, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 33, 4320, 4320, 17280, 4320, 17280, 33, 33, 33, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 33, 4320, 4320, 33, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 33, 17280, 33, 17280, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 17280, 4320, 33, 33]
Prompts retrieved: 1163829 . Total input tokens: 259366894 . Total output tokens: 232670004
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 6.277072972152382,
    "estimated_duration": 3600.1659091595916,
    "input_throughput": 5362.84479303538,
    "output_throughput": 4747.651478092565,
    "total_throughput": 10110.496271127946,
    "itl": 181.51434356405,
    "ttft": 1959217.2368522228,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 424,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.325801860257051,
    "arrivals": 388315,
    "finished_requests": 78056,
    "scheduler_time": 95.3240442476303
}
#Debug simulation 
Total elapsed time: 6.277185317128897. Arrivals time: 0.27712169336155057 Scheduler time: 5.909041723702103 Scheduler overhead time: 0.03237850870937109 Adapter cache time: 0.011436175089329481 Engine time: 0.03242499195039272 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-32/adapters_160_slots_96_rate_1.6-0.4-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-32/adapters_160_slots_96_rate_1.6-0.4-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 4320, 33, 33, 33, 17280, 33, 4320, 17280, 4320, 33, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 33, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 33, 4320, 4320, 4320, 17280, 33, 33, 17280, 33, 17280, 33, 33, 4320, 33, 4320, 17280, 33, 33, 4320, 33, 33, 33, 33, 33, 17280, 4320, 4320, 17280, 4320, 33, 17280, 17280, 17280, 4320, 4320, 33, 33, 33, 17280, 33, 4320, 4320, 33, 17280, 17280, 17280, 33, 33, 17280, 4320, 17280, 17280, 33, 17280, 33, 4320, 33, 33, 4320, 4320, 17280, 17280, 17280, 33, 17280, 4320, 4320, 33, 33, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 33, 4320, 4320, 17280, 4320, 17280, 33, 33, 33, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 33, 4320, 4320, 33, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 33, 17280, 33, 17280, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 17280, 4320, 33, 33]
Prompts retrieved: 1163829 . Total input tokens: 259366894 . Total output tokens: 232670004
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 6.160308999940753,
    "estimated_duration": 3600.161861787126,
    "input_throughput": 5347.790110315436,
    "output_throughput": 4734.610735401395,
    "total_throughput": 10082.400845716831,
    "itl": 179.49065068317918,
    "ttft": 1961382.268520326,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 451,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4914467931166342,
    "arrivals": 388315,
    "finished_requests": 77836,
    "scheduler_time": 95.42947750290939
}
#Debug simulation 
Total elapsed time: 6.160429111216217. Arrivals time: 0.2651425781659782 Scheduler time: 5.803202501963824 Scheduler overhead time: 0.032618412747979164 Adapter cache time: 0.011924561578780413 Engine time: 0.03265538439154625 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-16/adapters_160_slots_96_rate_1.6-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-16/adapters_160_slots_96_rate_1.6-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 4320, 33, 33, 33, 17280, 33, 4320, 17280, 4320, 33, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 33, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 33, 4320, 4320, 4320, 17280, 33, 33, 17280, 33, 17280, 33, 33, 4320, 33, 4320, 17280, 33, 33, 4320, 33, 33, 33, 33, 33, 17280, 4320, 4320, 17280, 4320, 33, 17280, 17280, 17280, 4320, 4320, 33, 33, 33, 17280, 33, 4320, 4320, 33, 17280, 17280, 17280, 33, 33, 17280, 4320, 17280, 17280, 33, 17280, 33, 4320, 33, 33, 4320, 4320, 17280, 17280, 17280, 33, 17280, 4320, 4320, 33, 33, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 33, 4320, 4320, 17280, 4320, 17280, 33, 33, 33, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 33, 4320, 4320, 33, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 33, 17280, 33, 17280, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 17280, 4320, 33, 33]
Prompts retrieved: 1163829 . Total input tokens: 259366894 . Total output tokens: 232670004
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 6.250713009852916,
    "estimated_duration": 3600.059807639674,
    "input_throughput": 5362.791184476998,
    "output_throughput": 4747.642237423267,
    "total_throughput": 10110.433421900265,
    "itl": 181.5109771647858,
    "ttft": 1959175.0926443571,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 428,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2797415262181226,
    "arrivals": 388315,
    "finished_requests": 78054,
    "scheduler_time": 95.32208345199416
}
#Debug simulation 
Total elapsed time: 6.250808251090348. Arrivals time: 0.2654981301166117 Scheduler time: 5.893766152206808 Scheduler overhead time: 0.032564484514296055 Adapter cache time: 0.011618690565228462 Engine time: 0.03258443530648947 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-32/adapters_160_slots_96_rate_1.6-0.4-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-32/adapters_160_slots_96_rate_1.6-0.4-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 4320, 33, 33, 33, 17280, 33, 4320, 17280, 4320, 33, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 33, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 33, 4320, 4320, 4320, 17280, 33, 33, 17280, 33, 17280, 33, 33, 4320, 33, 4320, 17280, 33, 33, 4320, 33, 33, 33, 33, 33, 17280, 4320, 4320, 17280, 4320, 33, 17280, 17280, 17280, 4320, 4320, 33, 33, 33, 17280, 33, 4320, 4320, 33, 17280, 17280, 17280, 33, 33, 17280, 4320, 17280, 17280, 33, 17280, 33, 4320, 33, 33, 4320, 4320, 17280, 17280, 17280, 33, 17280, 4320, 4320, 33, 33, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 33, 4320, 4320, 17280, 4320, 17280, 33, 33, 33, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 33, 4320, 4320, 33, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 33, 17280, 33, 17280, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 17280, 4320, 33, 33]
Prompts retrieved: 1163829 . Total input tokens: 259366894 . Total output tokens: 232670004
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.535034026019275,
    "estimated_duration": 3600.0351289247383,
    "input_throughput": 5347.014212538931,
    "output_throughput": 4734.402412648324,
    "total_throughput": 10081.416625187256,
    "itl": 179.45469369557517,
    "ttft": 1961414.408012742,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 438,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.468257629796863,
    "arrivals": 388315,
    "finished_requests": 77825,
    "scheduler_time": 95.42881084496175
}
#Debug simulation 
Total elapsed time: 6.535131758078933. Arrivals time: 0.5438087652437389 Scheduler time: 5.898312032688409 Scheduler overhead time: 0.0329243722371757 Adapter cache time: 0.011905491352081299 Engine time: 0.03318531485274434 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-8/adapters_160_slots_96_rate_1.6-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-8/adapters_160_slots_96_rate_1.6-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [53 53 54]
Adapter prompts. [540, 17280, 540, 540, 1080, 540, 540, 540, 17280, 540, 1080, 17280, 1080, 540, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 540, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 540, 1080, 1080, 1080, 17280, 540, 540, 17280, 540, 17280, 540, 540, 1080, 540, 1080, 17280, 540, 540, 1080, 540, 540, 540, 540, 540, 17280, 1080, 1080, 17280, 1080, 540, 17280, 17280, 17280, 1080, 1080, 540, 540, 540, 17280, 540, 1080, 1080, 540, 17280, 17280, 17280, 540, 540, 17280, 1080, 17280, 17280, 540, 17280, 540, 1080, 540, 540, 1080, 1080, 17280, 17280, 17280, 540, 17280, 1080, 1080, 540, 540, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 540, 1080, 1080, 17280, 1080, 17280, 540, 540, 540, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 540, 1080, 1080, 540, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 540, 17280, 540, 17280, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 17280, 1080, 540, 540]
Prompts retrieved: 1018980 . Total input tokens: 227190681 . Total output tokens: 203611993
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 6.0155775072053075,
    "estimated_duration": 3600.1211817744756,
    "input_throughput": 5368.171798726595,
    "output_throughput": 4746.669386161371,
    "total_throughput": 10114.841184887966,
    "itl": 181.2649915159192,
    "ttft": 1916744.6361022752,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1631,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.991655510354459,
    "arrivals": 339810,
    "finished_requests": 78025,
    "scheduler_time": 94.97692653569473
}
#Debug simulation 
Total elapsed time: 6.015701683238149. Arrivals time: 0.24785727774724364 Scheduler time: 5.660154713317752 Scheduler overhead time: 0.032346026971936226 Adapter cache time: 0.02803163416683674 Engine time: 0.03246389841660857 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-16/adapters_160_slots_96_rate_1.6-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-16/adapters_160_slots_96_rate_1.6-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [53 53 54]
Adapter prompts. [540, 17280, 540, 540, 1080, 540, 540, 540, 17280, 540, 1080, 17280, 1080, 540, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 540, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 540, 1080, 1080, 1080, 17280, 540, 540, 17280, 540, 17280, 540, 540, 1080, 540, 1080, 17280, 540, 540, 1080, 540, 540, 540, 540, 540, 17280, 1080, 1080, 17280, 1080, 540, 17280, 17280, 17280, 1080, 1080, 540, 540, 540, 17280, 540, 1080, 1080, 540, 17280, 17280, 17280, 540, 540, 17280, 1080, 17280, 17280, 540, 17280, 540, 1080, 540, 540, 1080, 1080, 17280, 17280, 17280, 540, 17280, 1080, 1080, 540, 540, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 540, 1080, 1080, 17280, 1080, 17280, 540, 540, 540, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 540, 1080, 1080, 540, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 540, 17280, 540, 17280, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 17280, 1080, 540, 540]
Prompts retrieved: 1018980 . Total input tokens: 227190681 . Total output tokens: 203611993
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.952003861777484,
    "estimated_duration": 3600.088473262887,
    "input_throughput": 5367.713361356855,
    "output_throughput": 4746.4630735901965,
    "total_throughput": 10114.176434947052,
    "itl": 181.29046454861563,
    "ttft": 1916673.1663195307,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1691,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.507672875556034,
    "arrivals": 339810,
    "finished_requests": 78018,
    "scheduler_time": 94.96262643885875
}
#Debug simulation 
Total elapsed time: 5.952094703912735. Arrivals time: 0.25166591349989176 Scheduler time: 5.592674958519638 Scheduler overhead time: 0.03236866137012839 Adapter cache time: 0.02840748568996787 Engine time: 0.03229980496689677 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-32/adapters_160_slots_96_rate_1.6-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-32/adapters_160_slots_96_rate_1.6-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [53 53 54]
Adapter prompts. [540, 17280, 540, 540, 1080, 540, 540, 540, 17280, 540, 1080, 17280, 1080, 540, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 540, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 540, 1080, 1080, 1080, 17280, 540, 540, 17280, 540, 17280, 540, 540, 1080, 540, 1080, 17280, 540, 540, 1080, 540, 540, 540, 540, 540, 17280, 1080, 1080, 17280, 1080, 540, 17280, 17280, 17280, 1080, 1080, 540, 540, 540, 17280, 540, 1080, 1080, 540, 17280, 17280, 17280, 540, 540, 17280, 1080, 17280, 17280, 540, 17280, 540, 1080, 540, 540, 1080, 1080, 17280, 17280, 17280, 540, 17280, 1080, 1080, 540, 540, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 540, 1080, 1080, 17280, 1080, 17280, 540, 540, 540, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 540, 1080, 1080, 540, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 540, 17280, 540, 17280, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 17280, 1080, 540, 540]
Prompts retrieved: 1018980 . Total input tokens: 227190681 . Total output tokens: 203611993
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.197774309664965,
    "estimated_duration": 3600.103072225221,
    "input_throughput": 5351.318729908512,
    "output_throughput": 4732.193400637783,
    "total_throughput": 10083.512130546296,
    "itl": 179.13011712164024,
    "ttft": 1918793.5306493079,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1748,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.703521348927109,
    "arrivals": 339810,
    "finished_requests": 77783,
    "scheduler_time": 95.07906540460378
}
#Debug simulation 
Total elapsed time: 6.197874279692769. Arrivals time: 0.5113718979991972 Scheduler time: 5.5774459121748805 Scheduler overhead time: 0.03248395351693034 Adapter cache time: 0.0291246110573411 Engine time: 0.032531488221138716 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-16-16/adapters_160_slots_96_rate_1.6-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-16-16/adapters_160_slots_96_rate_1.6-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [53 53 54]
Adapter prompts. [540, 17280, 540, 540, 1080, 540, 540, 540, 17280, 540, 1080, 17280, 1080, 540, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 540, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 540, 1080, 1080, 1080, 17280, 540, 540, 17280, 540, 17280, 540, 540, 1080, 540, 1080, 17280, 540, 540, 1080, 540, 540, 540, 540, 540, 17280, 1080, 1080, 17280, 1080, 540, 17280, 17280, 17280, 1080, 1080, 540, 540, 540, 17280, 540, 1080, 1080, 540, 17280, 17280, 17280, 540, 540, 17280, 1080, 17280, 17280, 540, 17280, 540, 1080, 540, 540, 1080, 1080, 17280, 17280, 17280, 540, 17280, 1080, 1080, 540, 540, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 540, 1080, 1080, 17280, 1080, 17280, 540, 540, 540, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 540, 1080, 1080, 540, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 540, 17280, 540, 17280, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 17280, 1080, 540, 540]
Prompts retrieved: 1018980 . Total input tokens: 227190681 . Total output tokens: 203611993
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.9948345348238945,
    "estimated_duration": 3600.1109727236667,
    "input_throughput": 5368.3345170269695,
    "output_throughput": 4746.867285335684,
    "total_throughput": 10115.201802362653,
    "itl": 181.27968646814915,
    "ttft": 1916607.1186733053,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1692,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.299827741535716,
    "arrivals": 339810,
    "finished_requests": 78026,
    "scheduler_time": 94.96823400373806
}
#Debug simulation 
Total elapsed time: 5.994953909888864. Arrivals time: 0.25363130401819944 Scheduler time: 5.633204894140363 Scheduler overhead time: 0.03207339020445943 Adapter cache time: 0.0286413193680346 Engine time: 0.03262730408459902 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-16-32/adapters_160_slots_96_rate_1.6-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-16-32/adapters_160_slots_96_rate_1.6-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [53 53 54]
Adapter prompts. [540, 17280, 540, 540, 1080, 540, 540, 540, 17280, 540, 1080, 17280, 1080, 540, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 540, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 540, 1080, 1080, 1080, 17280, 540, 540, 17280, 540, 17280, 540, 540, 1080, 540, 1080, 17280, 540, 540, 1080, 540, 540, 540, 540, 540, 17280, 1080, 1080, 17280, 1080, 540, 17280, 17280, 17280, 1080, 1080, 540, 540, 540, 17280, 540, 1080, 1080, 540, 17280, 17280, 17280, 540, 540, 17280, 1080, 17280, 17280, 540, 17280, 540, 1080, 540, 540, 1080, 1080, 17280, 17280, 17280, 540, 17280, 1080, 1080, 540, 540, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 540, 1080, 1080, 17280, 1080, 17280, 540, 540, 540, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 540, 1080, 1080, 540, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 540, 17280, 540, 17280, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 17280, 1080, 540, 540]
Prompts retrieved: 1018980 . Total input tokens: 227190681 . Total output tokens: 203611993
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.940109407063574,
    "estimated_duration": 3600.1454002701016,
    "input_throughput": 5351.37914111874,
    "output_throughput": 4732.191927226558,
    "total_throughput": 10083.571068345298,
    "itl": 179.14313492763313,
    "ttft": 1918802.0205144621,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1749,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.775152119621554,
    "arrivals": 339810,
    "finished_requests": 77786,
    "scheduler_time": 95.07782018273397
}
#Debug simulation 
Total elapsed time: 5.940208943095058. Arrivals time: 0.2528001070022583 Scheduler time: 5.578651698306203 Scheduler overhead time: 0.032393963541835546 Adapter cache time: 0.028842152561992407 Engine time: 0.032586765475571156 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_16-16-16/adapters_160_slots_96_rate_1.6-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_16-16-16/adapters_160_slots_96_rate_1.6-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [53 53 54]
Adapter prompts. [540, 17280, 540, 540, 1080, 540, 540, 540, 17280, 540, 1080, 17280, 1080, 540, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 540, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 540, 1080, 1080, 1080, 17280, 540, 540, 17280, 540, 17280, 540, 540, 1080, 540, 1080, 17280, 540, 540, 1080, 540, 540, 540, 540, 540, 17280, 1080, 1080, 17280, 1080, 540, 17280, 17280, 17280, 1080, 1080, 540, 540, 540, 17280, 540, 1080, 1080, 540, 17280, 17280, 17280, 540, 540, 17280, 1080, 17280, 17280, 540, 17280, 540, 1080, 540, 540, 1080, 1080, 17280, 17280, 17280, 540, 17280, 1080, 1080, 540, 540, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 540, 1080, 1080, 17280, 1080, 17280, 540, 540, 540, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 540, 1080, 1080, 540, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 540, 17280, 540, 17280, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 17280, 1080, 540, 540]
Prompts retrieved: 1018980 . Total input tokens: 227190681 . Total output tokens: 203611993
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 6.310187740251422,
    "estimated_duration": 3600.1933300605206,
    "input_throughput": 5368.333927688018,
    "output_throughput": 4746.846469967966,
    "total_throughput": 10115.180397655984,
    "itl": 181.26042932373045,
    "ttft": 1916697.68954518,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1631,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.876772030985312,
    "arrivals": 339810,
    "finished_requests": 78029,
    "scheduler_time": 94.98185355485793
}
#Debug simulation 
Total elapsed time: 6.310283019207418. Arrivals time: 0.2604319783858955 Scheduler time: 5.941854908596724 Scheduler overhead time: 0.03232785826548934 Adapter cache time: 0.027881719637662172 Engine time: 0.03293157136067748 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_16-16-32/adapters_160_slots_96_rate_1.6-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_16-16-32/adapters_160_slots_96_rate_1.6-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [53 53 54]
Adapter prompts. [540, 17280, 540, 540, 1080, 540, 540, 540, 17280, 540, 1080, 17280, 1080, 540, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 540, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 540, 1080, 1080, 1080, 17280, 540, 540, 17280, 540, 17280, 540, 540, 1080, 540, 1080, 17280, 540, 540, 1080, 540, 540, 540, 540, 540, 17280, 1080, 1080, 17280, 1080, 540, 17280, 17280, 17280, 1080, 1080, 540, 540, 540, 17280, 540, 1080, 1080, 540, 17280, 17280, 17280, 540, 540, 17280, 1080, 17280, 17280, 540, 17280, 540, 1080, 540, 540, 1080, 1080, 17280, 17280, 17280, 540, 17280, 1080, 1080, 540, 540, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 540, 1080, 1080, 17280, 1080, 17280, 540, 540, 540, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 540, 1080, 1080, 540, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 540, 17280, 540, 17280, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 17280, 1080, 540, 540]
Prompts retrieved: 1018980 . Total input tokens: 227190681 . Total output tokens: 203611993
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.998522814363241,
    "estimated_duration": 3600.022097490161,
    "input_throughput": 5351.146320304677,
    "output_throughput": 4731.847899454889,
    "total_throughput": 10082.994219759566,
    "itl": 179.1287433494455,
    "ttft": 1918799.2738476167,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1743,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.830822808556137,
    "arrivals": 339810,
    "finished_requests": 77780,
    "scheduler_time": 95.07470519003655
}
#Debug simulation 
Total elapsed time: 5.998645656276494. Arrivals time: 0.2522718096151948 Scheduler time: 5.636560412589461 Scheduler overhead time: 0.032631258480250835 Adapter cache time: 0.0291422582231462 Engine time: 0.033036221750080585 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-8/adapters_160_slots_96_rate_1.6-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-8/adapters_160_slots_96_rate_1.6-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [53 53 54]
Adapter prompts. [270, 17280, 270, 270, 1080, 270, 270, 270, 17280, 270, 1080, 17280, 1080, 270, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 270, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 270, 1080, 1080, 1080, 17280, 270, 270, 17280, 270, 17280, 270, 270, 1080, 270, 1080, 17280, 270, 270, 1080, 270, 270, 270, 270, 270, 17280, 1080, 1080, 17280, 1080, 270, 17280, 17280, 17280, 1080, 1080, 270, 270, 270, 17280, 270, 1080, 1080, 270, 17280, 17280, 17280, 270, 270, 17280, 1080, 17280, 17280, 270, 17280, 270, 1080, 270, 270, 1080, 1080, 17280, 17280, 17280, 270, 17280, 1080, 1080, 270, 270, 270, 270, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 270, 1080, 1080, 17280, 1080, 17280, 270, 270, 270, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 270, 1080, 1080, 270, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 270, 17280, 270, 17280, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 17280, 1080, 270, 270]
Prompts retrieved: 1004670 . Total input tokens: 223978595 . Total output tokens: 200765999
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.807127886917442,
    "estimated_duration": 3600.0956281303897,
    "input_throughput": 5328.350127733118,
    "output_throughput": 4744.933125254558,
    "total_throughput": 10073.283252987676,
    "itl": 181.96858149806238,
    "ttft": 1914936.2942310327,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2045,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.258697436342663,
    "arrivals": 335110,
    "finished_requests": 77919,
    "scheduler_time": 94.91687459309207
}
#Debug simulation 
Total elapsed time: 5.807220679707825. Arrivals time: 0.24823690485209227 Scheduler time: 5.4476672862656415 Scheduler overhead time: 0.03199059842154384 Adapter cache time: 0.03225484350696206 Engine time: 0.03236038004979491 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-16/adapters_160_slots_96_rate_1.6-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-16/adapters_160_slots_96_rate_1.6-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [53 53 54]
Adapter prompts. [270, 17280, 270, 270, 1080, 270, 270, 270, 17280, 270, 1080, 17280, 1080, 270, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 270, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 270, 1080, 1080, 1080, 17280, 270, 270, 17280, 270, 17280, 270, 270, 1080, 270, 1080, 17280, 270, 270, 1080, 270, 270, 270, 270, 270, 17280, 1080, 1080, 17280, 1080, 270, 17280, 17280, 17280, 1080, 1080, 270, 270, 270, 17280, 270, 1080, 1080, 270, 17280, 17280, 17280, 270, 270, 17280, 1080, 17280, 17280, 270, 17280, 270, 1080, 270, 270, 1080, 1080, 17280, 17280, 17280, 270, 17280, 1080, 1080, 270, 270, 270, 270, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 270, 1080, 1080, 17280, 1080, 17280, 270, 270, 270, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 270, 1080, 1080, 270, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 270, 17280, 270, 17280, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 17280, 1080, 270, 270]
Prompts retrieved: 1004670 . Total input tokens: 223978595 . Total output tokens: 200765999
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.7424630667082965,
    "estimated_duration": 3600.094126655914,
    "input_throughput": 5327.9679156103575,
    "output_throughput": 4744.724831921761,
    "total_throughput": 10072.692747532119,
    "itl": 181.98730125617797,
    "ttft": 1915021.9707096529,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2041,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.650618973923609,
    "arrivals": 335110,
    "finished_requests": 77913,
    "scheduler_time": 94.90712591710073
}
#Debug simulation 
Total elapsed time: 5.742560958024114. Arrivals time: 0.24980052653700113 Scheduler time: 5.381099704653025 Scheduler overhead time: 0.0320508093573153 Adapter cache time: 0.032748634461313486 Engine time: 0.03214287059381604 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-32/adapters_160_slots_96_rate_1.6-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-32/adapters_160_slots_96_rate_1.6-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [53 53 54]
Adapter prompts. [270, 17280, 270, 270, 1080, 270, 270, 270, 17280, 270, 1080, 17280, 1080, 270, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 270, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 270, 1080, 1080, 1080, 17280, 270, 270, 17280, 270, 17280, 270, 270, 1080, 270, 1080, 17280, 270, 270, 1080, 270, 270, 270, 270, 270, 17280, 1080, 1080, 17280, 1080, 270, 17280, 17280, 17280, 1080, 1080, 270, 270, 270, 17280, 270, 1080, 1080, 270, 17280, 17280, 17280, 270, 270, 17280, 1080, 17280, 17280, 270, 17280, 270, 1080, 270, 270, 1080, 1080, 17280, 17280, 17280, 270, 17280, 1080, 1080, 270, 270, 270, 270, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 270, 1080, 1080, 17280, 1080, 17280, 270, 270, 270, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 270, 1080, 1080, 270, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 270, 17280, 270, 17280, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 17280, 1080, 270, 270]
Prompts retrieved: 1004670 . Total input tokens: 223978595 . Total output tokens: 200765999
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.9900010116398335,
    "estimated_duration": 3600.090038177391,
    "input_throughput": 5313.970983260544,
    "output_throughput": 4733.760216904962,
    "total_throughput": 10047.731200165506,
    "itl": 179.86900862740282,
    "ttft": 1916867.457436483,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2101,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.861183633692521,
    "arrivals": 335110,
    "finished_requests": 77696,
    "scheduler_time": 95.02190312861518
}
#Debug simulation 
Total elapsed time: 5.99010350368917. Arrivals time: 0.5014680861495435 Scheduler time: 5.375119349453598 Scheduler overhead time: 0.03232930228114128 Adapter cache time: 0.03358998941257596 Engine time: 0.03265820862725377 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-16-16/adapters_160_slots_96_rate_1.6-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-16-16/adapters_160_slots_96_rate_1.6-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [53 53 54]
Adapter prompts. [270, 17280, 270, 270, 1080, 270, 270, 270, 17280, 270, 1080, 17280, 1080, 270, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 270, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 270, 1080, 1080, 1080, 17280, 270, 270, 17280, 270, 17280, 270, 270, 1080, 270, 1080, 17280, 270, 270, 1080, 270, 270, 270, 270, 270, 17280, 1080, 1080, 17280, 1080, 270, 17280, 17280, 17280, 1080, 1080, 270, 270, 270, 17280, 270, 1080, 1080, 270, 17280, 17280, 17280, 270, 270, 17280, 1080, 17280, 17280, 270, 17280, 270, 1080, 270, 270, 1080, 1080, 17280, 17280, 17280, 270, 17280, 1080, 1080, 270, 270, 270, 270, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 270, 1080, 1080, 17280, 1080, 17280, 270, 270, 270, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 270, 1080, 1080, 270, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 270, 17280, 270, 17280, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 17280, 1080, 270, 270]
Prompts retrieved: 1004670 . Total input tokens: 223978595 . Total output tokens: 200765999
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.775930046103895,
    "estimated_duration": 3600.032585832846,
    "input_throughput": 5328.415658093898,
    "output_throughput": 4744.886773309092,
    "total_throughput": 10073.30243140299,
    "itl": 181.97382250969648,
    "ttft": 1914953.6803250923,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2044,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.396453739732765,
    "arrivals": 335110,
    "finished_requests": 77917,
    "scheduler_time": 94.91212710182107
}
#Debug simulation 
Total elapsed time: 5.776026850100607. Arrivals time: 0.2526013026945293 Scheduler time: 5.411993315443397 Scheduler overhead time: 0.03213027352467179 Adapter cache time: 0.03228101180866361 Engine time: 0.03225229540839791 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-16-32/adapters_160_slots_96_rate_1.6-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-16-32/adapters_160_slots_96_rate_1.6-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [53 53 54]
Adapter prompts. [270, 17280, 270, 270, 1080, 270, 270, 270, 17280, 270, 1080, 17280, 1080, 270, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 270, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 270, 1080, 1080, 1080, 17280, 270, 270, 17280, 270, 17280, 270, 270, 1080, 270, 1080, 17280, 270, 270, 1080, 270, 270, 270, 270, 270, 17280, 1080, 1080, 17280, 1080, 270, 17280, 17280, 17280, 1080, 1080, 270, 270, 270, 17280, 270, 1080, 1080, 270, 17280, 17280, 17280, 270, 270, 17280, 1080, 17280, 17280, 270, 17280, 270, 1080, 270, 270, 1080, 1080, 17280, 17280, 17280, 270, 17280, 1080, 1080, 270, 270, 270, 270, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 270, 1080, 1080, 17280, 1080, 17280, 270, 270, 270, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 270, 1080, 1080, 270, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 270, 17280, 270, 17280, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 17280, 1080, 270, 270]
Prompts retrieved: 1004670 . Total input tokens: 223978595 . Total output tokens: 200765999
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.752736394759268,
    "estimated_duration": 3600.154040106106,
    "input_throughput": 5313.5770822284585,
    "output_throughput": 4733.509402697043,
    "total_throughput": 10047.086484925501,
    "itl": 179.84020513407762,
    "ttft": 1916867.000482494,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2101,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.9454386705903906,
    "arrivals": 335110,
    "finished_requests": 77691,
    "scheduler_time": 95.02322704537308
}
#Debug simulation 
Total elapsed time: 5.752829109784216. Arrivals time: 0.25272152246907353 Scheduler time: 5.387464131694287 Scheduler overhead time: 0.03220906527712941 Adapter cache time: 0.03305660514160991 Engine time: 0.0325757316313684 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_16-16-16/adapters_160_slots_96_rate_1.6-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_16-16-16/adapters_160_slots_96_rate_1.6-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [53 53 54]
Adapter prompts. [270, 17280, 270, 270, 1080, 270, 270, 270, 17280, 270, 1080, 17280, 1080, 270, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 270, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 270, 1080, 1080, 1080, 17280, 270, 270, 17280, 270, 17280, 270, 270, 1080, 270, 1080, 17280, 270, 270, 1080, 270, 270, 270, 270, 270, 17280, 1080, 1080, 17280, 1080, 270, 17280, 17280, 17280, 1080, 1080, 270, 270, 270, 17280, 270, 1080, 1080, 270, 17280, 17280, 17280, 270, 270, 17280, 1080, 17280, 17280, 270, 17280, 270, 1080, 270, 270, 1080, 1080, 17280, 17280, 17280, 270, 17280, 1080, 1080, 270, 270, 270, 270, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 270, 1080, 1080, 17280, 1080, 17280, 270, 270, 270, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 270, 1080, 1080, 270, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 270, 17280, 270, 17280, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 17280, 1080, 270, 270]
Prompts retrieved: 1004670 . Total input tokens: 223978595 . Total output tokens: 200765999
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.751785647124052,
    "estimated_duration": 3600.0746512861174,
    "input_throughput": 5328.436451490528,
    "output_throughput": 4745.173824075328,
    "total_throughput": 10073.610275565856,
    "itl": 181.96011770306825,
    "ttft": 1914913.3895743203,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2048,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.123623003959475,
    "arrivals": 335110,
    "finished_requests": 77921,
    "scheduler_time": 94.92021215939192
}
#Debug simulation 
Total elapsed time: 5.751907335128635. Arrivals time: 0.253746354021132 Scheduler time: 5.386170245241374 Scheduler overhead time: 0.03197860810905695 Adapter cache time: 0.03295660391449928 Engine time: 0.03232446638867259 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_16-16-32/adapters_160_slots_96_rate_1.6-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_16-16-32/adapters_160_slots_96_rate_1.6-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [53 53 54]
Adapter prompts. [270, 17280, 270, 270, 1080, 270, 270, 270, 17280, 270, 1080, 17280, 1080, 270, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 270, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 270, 1080, 1080, 1080, 17280, 270, 270, 17280, 270, 17280, 270, 270, 1080, 270, 1080, 17280, 270, 270, 1080, 270, 270, 270, 270, 270, 17280, 1080, 1080, 17280, 1080, 270, 17280, 17280, 17280, 1080, 1080, 270, 270, 270, 17280, 270, 1080, 1080, 270, 17280, 17280, 17280, 270, 270, 17280, 1080, 17280, 17280, 270, 17280, 270, 1080, 270, 270, 1080, 1080, 17280, 17280, 17280, 270, 17280, 1080, 1080, 270, 270, 270, 270, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 270, 1080, 1080, 17280, 1080, 17280, 270, 270, 270, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 270, 1080, 1080, 270, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 270, 17280, 270, 17280, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 17280, 1080, 270, 270]
Prompts retrieved: 1004670 . Total input tokens: 223978595 . Total output tokens: 200765999
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.716039460152388,
    "estimated_duration": 3600.1246568264205,
    "input_throughput": 5313.620450260519,
    "output_throughput": 4733.548036367799,
    "total_throughput": 10047.168486628318,
    "itl": 179.8658779045908,
    "ttft": 1916854.375299796,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2099,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.028676835112034,
    "arrivals": 335110,
    "finished_requests": 77691,
    "scheduler_time": 95.01888318869399
}
#Debug simulation 
Total elapsed time: 5.716132497880608. Arrivals time: 0.24720828887075186 Scheduler time: 5.356143136508763 Scheduler overhead time: 0.032196384854614735 Adapter cache time: 0.033324743155390024 Engine time: 0.03244476206600666 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-8/adapters_160_slots_96_rate_1.6-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-8/adapters_160_slots_96_rate_1.6-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 1080, 135, 135, 135, 17280, 135, 1080, 17280, 1080, 135, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 135, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 135, 1080, 1080, 1080, 17280, 135, 135, 17280, 135, 17280, 135, 135, 1080, 135, 1080, 17280, 135, 135, 1080, 135, 135, 135, 135, 135, 17280, 1080, 1080, 17280, 1080, 135, 17280, 17280, 17280, 1080, 1080, 135, 135, 135, 17280, 135, 1080, 1080, 135, 17280, 17280, 17280, 135, 135, 17280, 1080, 17280, 17280, 135, 17280, 135, 1080, 135, 135, 1080, 1080, 17280, 17280, 17280, 135, 17280, 1080, 1080, 135, 135, 135, 135, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 135, 1080, 1080, 17280, 1080, 17280, 135, 135, 135, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 135, 1080, 1080, 135, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 135, 17280, 135, 17280, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 17280, 1080, 135, 135]
Prompts retrieved: 997515 . Total input tokens: 222378898 . Total output tokens: 199330563
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.668140958994627,
    "estimated_duration": 3600.171083481831,
    "input_throughput": 5438.8998594651985,
    "output_throughput": 4778.962888441529,
    "total_throughput": 10217.862747906727,
    "itl": 179.48732586230727,
    "ttft": 1907884.5973629027,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1979,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.056705245243094,
    "arrivals": 332795,
    "finished_requests": 78701,
    "scheduler_time": 95.70943952331496
}
#Debug simulation 
Total elapsed time: 5.6682337038218975. Arrivals time: 0.24860720755532384 Scheduler time: 5.3079424747265875 Scheduler overhead time: 0.031734046060591936 Adapter cache time: 0.032872804906219244 Engine time: 0.03248148038983345 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-16/adapters_160_slots_96_rate_1.6-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-16/adapters_160_slots_96_rate_1.6-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 1080, 135, 135, 135, 17280, 135, 1080, 17280, 1080, 135, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 135, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 135, 1080, 1080, 1080, 17280, 135, 135, 17280, 135, 17280, 135, 135, 1080, 135, 1080, 17280, 135, 135, 1080, 135, 135, 135, 135, 135, 17280, 1080, 1080, 17280, 1080, 135, 17280, 17280, 17280, 1080, 1080, 135, 135, 135, 17280, 135, 1080, 1080, 135, 17280, 17280, 17280, 135, 135, 17280, 1080, 17280, 17280, 135, 17280, 135, 1080, 135, 135, 1080, 1080, 17280, 17280, 17280, 135, 17280, 1080, 1080, 135, 135, 135, 135, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 135, 1080, 1080, 17280, 1080, 17280, 135, 135, 135, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 135, 1080, 1080, 135, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 135, 17280, 135, 17280, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 17280, 1080, 135, 135]
Prompts retrieved: 997515 . Total input tokens: 222378898 . Total output tokens: 199330563
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.725923386868089,
    "estimated_duration": 3600.162629516577,
    "input_throughput": 5437.90656552335,
    "output_throughput": 4778.111093917401,
    "total_throughput": 10216.017659440751,
    "itl": 179.50859096084065,
    "ttft": 1907998.7511479629,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1977,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.455578397183929,
    "arrivals": 332795,
    "finished_requests": 78690,
    "scheduler_time": 95.69896809668145
}
#Debug simulation 
Total elapsed time: 5.726019448135048. Arrivals time: 0.2521260380744934 Scheduler time: 5.36183791840449 Scheduler overhead time: 0.03194974269717932 Adapter cache time: 0.032884597312659025 Engine time: 0.03249903442338109 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-32/adapters_160_slots_96_rate_1.6-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-32/adapters_160_slots_96_rate_1.6-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 1080, 135, 135, 135, 17280, 135, 1080, 17280, 1080, 135, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 135, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 135, 1080, 1080, 1080, 17280, 135, 135, 17280, 135, 17280, 135, 135, 1080, 135, 1080, 17280, 135, 135, 1080, 135, 135, 135, 135, 135, 17280, 1080, 1080, 17280, 1080, 135, 17280, 17280, 17280, 1080, 1080, 135, 135, 135, 17280, 135, 1080, 1080, 135, 17280, 17280, 17280, 135, 135, 17280, 1080, 17280, 17280, 135, 17280, 135, 1080, 135, 135, 1080, 1080, 17280, 17280, 17280, 135, 17280, 1080, 1080, 135, 135, 135, 135, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 135, 1080, 1080, 17280, 1080, 17280, 135, 135, 135, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 135, 1080, 1080, 135, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 135, 17280, 135, 17280, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 17280, 1080, 135, 135]
Prompts retrieved: 997515 . Total input tokens: 222378898 . Total output tokens: 199330563
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.911402470897883,
    "estimated_duration": 3600.0948905157584,
    "input_throughput": 5430.218534378498,
    "output_throughput": 4771.968662620117,
    "total_throughput": 10202.187196998615,
    "itl": 177.64170390449,
    "ttft": 1909195.1564511803,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1995,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.52406899346034,
    "arrivals": 332795,
    "finished_requests": 78583,
    "scheduler_time": 95.89564255055683
}
#Debug simulation 
Total elapsed time: 5.911502765957266. Arrivals time: 0.5042517515830696 Scheduler time: 5.294827136211097 Scheduler overhead time: 0.032004355918616056 Adapter cache time: 0.0332671795040369 Engine time: 0.03242484387010336 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-16/adapters_160_slots_96_rate_1.6-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-16/adapters_160_slots_96_rate_1.6-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 1080, 135, 135, 135, 17280, 135, 1080, 17280, 1080, 135, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 135, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 135, 1080, 1080, 1080, 17280, 135, 135, 17280, 135, 17280, 135, 135, 1080, 135, 1080, 17280, 135, 135, 1080, 135, 135, 135, 135, 135, 17280, 1080, 1080, 17280, 1080, 135, 17280, 17280, 17280, 1080, 1080, 135, 135, 135, 17280, 135, 1080, 1080, 135, 17280, 17280, 17280, 135, 135, 17280, 1080, 17280, 17280, 135, 17280, 135, 1080, 135, 135, 1080, 1080, 17280, 17280, 17280, 135, 17280, 1080, 1080, 135, 135, 135, 135, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 135, 1080, 1080, 17280, 1080, 17280, 135, 135, 135, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 135, 1080, 1080, 135, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 135, 17280, 135, 17280, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 17280, 1080, 135, 135]
Prompts retrieved: 997515 . Total input tokens: 222378898 . Total output tokens: 199330563
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.681412637233734,
    "estimated_duration": 3600.1374480818563,
    "input_throughput": 5438.8215123376585,
    "output_throughput": 4778.558387865431,
    "total_throughput": 10217.379900203088,
    "itl": 179.4937347946848,
    "ttft": 1907897.1141339345,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1979,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.2057778284301035,
    "arrivals": 332795,
    "finished_requests": 78697,
    "scheduler_time": 95.70455934703989
}
#Debug simulation 
Total elapsed time: 5.6815074579790235. Arrivals time: 0.2541187913157046 Scheduler time: 5.316170089878142 Scheduler overhead time: 0.031663460191339254 Adapter cache time: 0.03241464635357261 Engine time: 0.032507304567843676 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-32/adapters_160_slots_96_rate_1.6-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-32/adapters_160_slots_96_rate_1.6-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 1080, 135, 135, 135, 17280, 135, 1080, 17280, 1080, 135, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 135, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 135, 1080, 1080, 1080, 17280, 135, 135, 17280, 135, 17280, 135, 135, 1080, 135, 1080, 17280, 135, 135, 1080, 135, 135, 135, 135, 135, 17280, 1080, 1080, 17280, 1080, 135, 17280, 17280, 17280, 1080, 1080, 135, 135, 135, 17280, 135, 1080, 1080, 135, 17280, 17280, 17280, 135, 135, 17280, 1080, 17280, 17280, 135, 17280, 135, 1080, 135, 135, 1080, 1080, 17280, 17280, 17280, 135, 17280, 1080, 1080, 135, 135, 135, 135, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 135, 1080, 1080, 17280, 1080, 17280, 135, 135, 135, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 135, 1080, 1080, 135, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 135, 17280, 135, 17280, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 17280, 1080, 135, 135]
Prompts retrieved: 997515 . Total input tokens: 222378898 . Total output tokens: 199330563
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.671285418793559,
    "estimated_duration": 3600.1881942535347,
    "input_throughput": 5430.077802933678,
    "output_throughput": 4771.8449906094465,
    "total_throughput": 10201.922793543124,
    "itl": 177.6452345076718,
    "ttft": 1909233.0260589493,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1996,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.606800399031371,
    "arrivals": 332795,
    "finished_requests": 78583,
    "scheduler_time": 95.89572862195371
}
#Debug simulation 
Total elapsed time: 5.671391264069825. Arrivals time: 0.2576297395862639 Scheduler time: 5.301365648396313 Scheduler overhead time: 0.03198713809251785 Adapter cache time: 0.03324229549616575 Engine time: 0.03239165060222149 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-16/adapters_160_slots_96_rate_1.6-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-16/adapters_160_slots_96_rate_1.6-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 1080, 135, 135, 135, 17280, 135, 1080, 17280, 1080, 135, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 135, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 135, 1080, 1080, 1080, 17280, 135, 135, 17280, 135, 17280, 135, 135, 1080, 135, 1080, 17280, 135, 135, 1080, 135, 135, 135, 135, 135, 17280, 1080, 1080, 17280, 1080, 135, 17280, 17280, 17280, 1080, 1080, 135, 135, 135, 17280, 135, 1080, 1080, 135, 17280, 17280, 17280, 135, 135, 17280, 1080, 17280, 17280, 135, 17280, 135, 1080, 135, 135, 1080, 1080, 17280, 17280, 17280, 135, 17280, 1080, 1080, 135, 135, 135, 135, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 135, 1080, 1080, 17280, 1080, 17280, 135, 135, 135, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 135, 1080, 1080, 135, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 135, 17280, 135, 17280, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 17280, 1080, 135, 135]
Prompts retrieved: 997515 . Total input tokens: 222378898 . Total output tokens: 199330563
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.93266040738672,
    "estimated_duration": 3600.040254535023,
    "input_throughput": 5439.005015383922,
    "output_throughput": 4779.002673185977,
    "total_throughput": 10218.007688569898,
    "itl": 179.48144258923503,
    "ttft": 1907849.0375892157,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1979,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.917309533611232,
    "arrivals": 332795,
    "finished_requests": 78700,
    "scheduler_time": 95.70920147049151
}
#Debug simulation 
Total elapsed time: 5.932756834197789. Arrivals time: 0.5068957176990807 Scheduler time: 5.314552757889032 Scheduler overhead time: 0.031828065402805805 Adapter cache time: 0.03262455575168133 Engine time: 0.03219427727162838 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-32/adapters_160_slots_96_rate_1.6-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-32/adapters_160_slots_96_rate_1.6-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 1080, 135, 135, 135, 17280, 135, 1080, 17280, 1080, 135, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 135, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 135, 1080, 1080, 1080, 17280, 135, 135, 17280, 135, 17280, 135, 135, 1080, 135, 1080, 17280, 135, 135, 1080, 135, 135, 135, 135, 135, 17280, 1080, 1080, 17280, 1080, 135, 17280, 17280, 17280, 1080, 1080, 135, 135, 135, 17280, 135, 1080, 1080, 135, 17280, 17280, 17280, 135, 135, 17280, 1080, 17280, 17280, 135, 17280, 135, 1080, 135, 135, 1080, 1080, 17280, 17280, 17280, 135, 17280, 1080, 1080, 135, 135, 135, 135, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 135, 1080, 1080, 17280, 1080, 17280, 135, 135, 135, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 135, 1080, 1080, 135, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 135, 17280, 135, 17280, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 17280, 1080, 135, 135]
Prompts retrieved: 997515 . Total input tokens: 222378898 . Total output tokens: 199330563
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.701725871302187,
    "estimated_duration": 3600.082356830678,
    "input_throughput": 5429.931057802022,
    "output_throughput": 4771.74222623151,
    "total_throughput": 10201.673284033532,
    "itl": 177.64946071938496,
    "ttft": 1909205.2216160041,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1996,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.696211341172252,
    "arrivals": 332795,
    "finished_requests": 78577,
    "scheduler_time": 95.8905746551119
}
#Debug simulation 
Total elapsed time: 5.701819345355034. Arrivals time: 0.2494292063638568 Scheduler time: 5.33865558821708 Scheduler overhead time: 0.03231259435415268 Adapter cache time: 0.03353476012125611 Engine time: 0.033012538217008114 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-8/adapters_160_slots_96_rate_1.6-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-8/adapters_160_slots_96_rate_1.6-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 1080, 66, 66, 66, 17280, 66, 1080, 17280, 1080, 66, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 66, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 66, 1080, 1080, 1080, 17280, 66, 66, 17280, 66, 17280, 66, 66, 1080, 66, 1080, 17280, 66, 66, 1080, 66, 66, 66, 66, 66, 17280, 1080, 1080, 17280, 1080, 66, 17280, 17280, 17280, 1080, 1080, 66, 66, 66, 17280, 66, 1080, 1080, 66, 17280, 17280, 17280, 66, 66, 17280, 1080, 17280, 17280, 66, 17280, 66, 1080, 66, 66, 1080, 1080, 17280, 17280, 17280, 66, 17280, 1080, 1080, 66, 66, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 66, 1080, 1080, 17280, 1080, 17280, 66, 66, 66, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 66, 1080, 1080, 66, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 66, 17280, 66, 17280, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 17280, 1080, 66, 66]
Prompts retrieved: 993858 . Total input tokens: 221564047 . Total output tokens: 198603084
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 6.0475378218106925,
    "estimated_duration": 3600.131657976496,
    "input_throughput": 5517.074064775681,
    "output_throughput": 4846.53886513889,
    "total_throughput": 10363.612929914572,
    "itl": 176.77075357906978,
    "ttft": 1887918.3267364688,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1617,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.948808681939399,
    "arrivals": 331579,
    "finished_requests": 80042,
    "scheduler_time": 97.03397298439229
}
#Debug simulation 
Total elapsed time: 6.047638647723943. Arrivals time: 0.5131827876903117 Scheduler time: 5.4258448872715235 Scheduler overhead time: 0.03158203652128577 Adapter cache time: 0.02996660117059946 Engine time: 0.03241383656859398 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-16/adapters_160_slots_96_rate_1.6-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-16/adapters_160_slots_96_rate_1.6-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 1080, 66, 66, 66, 17280, 66, 1080, 17280, 1080, 66, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 66, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 66, 1080, 1080, 1080, 17280, 66, 66, 17280, 66, 17280, 66, 66, 1080, 66, 1080, 17280, 66, 66, 1080, 66, 66, 66, 66, 66, 17280, 1080, 1080, 17280, 1080, 66, 17280, 17280, 17280, 1080, 1080, 66, 66, 66, 17280, 66, 1080, 1080, 66, 17280, 17280, 17280, 66, 66, 17280, 1080, 17280, 17280, 66, 17280, 66, 1080, 66, 66, 1080, 1080, 17280, 17280, 17280, 66, 17280, 1080, 1080, 66, 66, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 66, 1080, 1080, 17280, 1080, 17280, 66, 66, 66, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 66, 1080, 1080, 66, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 66, 17280, 66, 17280, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 17280, 1080, 66, 66]
Prompts retrieved: 993858 . Total input tokens: 221564047 . Total output tokens: 198603084
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.791427202988416,
    "estimated_duration": 3600.1752297378207,
    "input_throughput": 5516.278162228858,
    "output_throughput": 4846.104671763587,
    "total_throughput": 10362.382833992446,
    "itl": 176.785754582856,
    "ttft": 1888047.3727395767,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1618,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.274281177245903,
    "arrivals": 331579,
    "finished_requests": 80035,
    "scheduler_time": 97.02674845708313
}
#Debug simulation 
Total elapsed time: 5.791545075830072. Arrivals time: 0.24941771430894732 Scheduler time: 5.432377505116165 Scheduler overhead time: 0.03187311487272382 Adapter cache time: 0.03049164591357112 Engine time: 0.032600102946162224 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-32/adapters_160_slots_96_rate_1.6-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-32/adapters_160_slots_96_rate_1.6-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 1080, 66, 66, 66, 17280, 66, 1080, 17280, 1080, 66, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 66, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 66, 1080, 1080, 1080, 17280, 66, 66, 17280, 66, 17280, 66, 66, 1080, 66, 1080, 17280, 66, 66, 1080, 66, 66, 66, 66, 66, 17280, 1080, 1080, 17280, 1080, 66, 17280, 17280, 17280, 1080, 1080, 66, 66, 66, 17280, 66, 1080, 1080, 66, 17280, 17280, 17280, 66, 66, 17280, 1080, 17280, 17280, 66, 17280, 66, 1080, 66, 66, 1080, 1080, 17280, 17280, 17280, 66, 17280, 1080, 1080, 66, 66, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 66, 1080, 1080, 17280, 1080, 17280, 66, 66, 66, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 66, 1080, 1080, 66, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 66, 17280, 66, 17280, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 17280, 1080, 66, 66]
Prompts retrieved: 993858 . Total input tokens: 221564047 . Total output tokens: 198603084
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.70948995416984,
    "estimated_duration": 3600.0842124559736,
    "input_throughput": 5511.5591272415695,
    "output_throughput": 4842.622553017071,
    "total_throughput": 10354.181680258642,
    "itl": 175.19222482284738,
    "ttft": 1888673.3202161868,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1613,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.268027237243893,
    "arrivals": 331579,
    "finished_requests": 79963,
    "scheduler_time": 97.1981399243074
}
#Debug simulation 
Total elapsed time: 5.709584911819547. Arrivals time: 0.25154967652633786 Scheduler time: 5.34844933077693 Scheduler overhead time: 0.03159331111237407 Adapter cache time: 0.030541548505425453 Engine time: 0.032749470323324203 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-16/adapters_160_slots_96_rate_1.6-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-16/adapters_160_slots_96_rate_1.6-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 1080, 66, 66, 66, 17280, 66, 1080, 17280, 1080, 66, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 66, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 66, 1080, 1080, 1080, 17280, 66, 66, 17280, 66, 17280, 66, 66, 1080, 66, 1080, 17280, 66, 66, 1080, 66, 66, 66, 66, 66, 17280, 1080, 1080, 17280, 1080, 66, 17280, 17280, 17280, 1080, 1080, 66, 66, 66, 17280, 66, 1080, 1080, 66, 17280, 17280, 17280, 66, 66, 17280, 1080, 17280, 17280, 66, 17280, 66, 1080, 66, 66, 1080, 1080, 17280, 17280, 17280, 66, 17280, 1080, 1080, 66, 66, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 66, 1080, 1080, 17280, 1080, 17280, 66, 66, 66, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 66, 1080, 1080, 66, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 66, 17280, 66, 17280, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 17280, 1080, 66, 66]
Prompts retrieved: 993858 . Total input tokens: 221564047 . Total output tokens: 198603084
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.794491323176771,
    "estimated_duration": 3600.0693888497535,
    "input_throughput": 5516.943384901213,
    "output_throughput": 4846.485474429884,
    "total_throughput": 10363.428859331098,
    "itl": 176.7766371037385,
    "ttft": 1887959.9752680743,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1617,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.059230156680455,
    "arrivals": 331579,
    "finished_requests": 80039,
    "scheduler_time": 97.02901509436735
}
#Debug simulation 
Total elapsed time: 5.794597394298762. Arrivals time: 0.2832980351522565 Scheduler time: 5.402234831359237 Scheduler overhead time: 0.031699216924607754 Adapter cache time: 0.03029168490320444 Engine time: 0.032395892310887575 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-32/adapters_160_slots_96_rate_1.6-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-32/adapters_160_slots_96_rate_1.6-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 1080, 66, 66, 66, 17280, 66, 1080, 17280, 1080, 66, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 66, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 66, 1080, 1080, 1080, 17280, 66, 66, 17280, 66, 17280, 66, 66, 1080, 66, 1080, 17280, 66, 66, 1080, 66, 66, 66, 66, 66, 17280, 1080, 1080, 17280, 1080, 66, 17280, 17280, 17280, 1080, 1080, 66, 66, 66, 17280, 66, 1080, 1080, 66, 17280, 17280, 17280, 66, 66, 17280, 1080, 17280, 17280, 66, 17280, 66, 1080, 66, 66, 1080, 1080, 17280, 17280, 17280, 66, 17280, 1080, 1080, 66, 66, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 66, 1080, 1080, 17280, 1080, 17280, 66, 66, 66, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 66, 1080, 1080, 66, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 66, 17280, 66, 17280, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 17280, 1080, 66, 66]
Prompts retrieved: 993858 . Total input tokens: 221564047 . Total output tokens: 198603084
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.806656806729734,
    "estimated_duration": 3600.0252221936553,
    "input_throughput": 5511.574162780312,
    "output_throughput": 4842.461072919181,
    "total_throughput": 10354.035235699492,
    "itl": 175.20804373964472,
    "ttft": 1888688.2654503032,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1614,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.33549670860165,
    "arrivals": 331579,
    "finished_requests": 79961,
    "scheduler_time": 97.19259769083625
}
#Debug simulation 
Total elapsed time: 5.806772769894451. Arrivals time: 0.25373152643442154 Scheduler time: 5.442331505939364 Scheduler overhead time: 0.032366267405450344 Adapter cache time: 0.030329635366797447 Engine time: 0.03305514017120004 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-16/adapters_160_slots_96_rate_1.6-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-16/adapters_160_slots_96_rate_1.6-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 1080, 66, 66, 66, 17280, 66, 1080, 17280, 1080, 66, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 66, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 66, 1080, 1080, 1080, 17280, 66, 66, 17280, 66, 17280, 66, 66, 1080, 66, 1080, 17280, 66, 66, 1080, 66, 66, 66, 66, 66, 17280, 1080, 1080, 17280, 1080, 66, 17280, 17280, 17280, 1080, 1080, 66, 66, 66, 17280, 66, 1080, 1080, 66, 17280, 17280, 17280, 66, 66, 17280, 1080, 17280, 17280, 66, 17280, 66, 1080, 66, 66, 1080, 1080, 17280, 17280, 17280, 66, 17280, 1080, 1080, 66, 66, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 66, 1080, 1080, 17280, 1080, 17280, 66, 66, 66, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 66, 1080, 1080, 66, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 66, 17280, 66, 17280, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 17280, 1080, 66, 66]
Prompts retrieved: 993858 . Total input tokens: 221564047 . Total output tokens: 198603084
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.7748908386565745,
    "estimated_duration": 3600.14041421063,
    "input_throughput": 5517.405354967322,
    "output_throughput": 4846.565964796052,
    "total_throughput": 10363.971319763374,
    "itl": 176.7615354070307,
    "ttft": 1887902.480898896,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1619,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.840891427446487,
    "arrivals": 331579,
    "finished_requests": 80047,
    "scheduler_time": 97.03742466771445
}
#Debug simulation 
Total elapsed time: 5.774982892908156. Arrivals time: 0.2789203436113894 Scheduler time: 5.387069255579263 Scheduler overhead time: 0.031650470569729805 Adapter cache time: 0.030265177600085735 Engine time: 0.0324069089256227 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-32/adapters_160_slots_96_rate_1.6-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-32/adapters_160_slots_96_rate_1.6-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 1080, 66, 66, 66, 17280, 66, 1080, 17280, 1080, 66, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 66, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 66, 1080, 1080, 1080, 17280, 66, 66, 17280, 66, 17280, 66, 66, 1080, 66, 1080, 17280, 66, 66, 1080, 66, 66, 66, 66, 66, 17280, 1080, 1080, 17280, 1080, 66, 17280, 17280, 17280, 1080, 1080, 66, 66, 66, 17280, 66, 1080, 1080, 66, 17280, 17280, 17280, 66, 66, 17280, 1080, 17280, 17280, 66, 17280, 66, 1080, 66, 66, 1080, 1080, 17280, 17280, 17280, 66, 17280, 1080, 1080, 66, 66, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 66, 1080, 1080, 17280, 1080, 17280, 66, 66, 66, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 66, 1080, 1080, 66, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 66, 17280, 66, 17280, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 17280, 1080, 66, 66]
Prompts retrieved: 993858 . Total input tokens: 221564047 . Total output tokens: 198603084
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.713272113818675,
    "estimated_duration": 3600.023931472657,
    "input_throughput": 5511.57613885176,
    "output_throughput": 4842.462809092693,
    "total_throughput": 10354.038947944453,
    "itl": 175.19692013754621,
    "ttft": 1888691.3334702665,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1613,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.401829265989284,
    "arrivals": 331579,
    "finished_requests": 79961,
    "scheduler_time": 97.19300890192633
}
#Debug simulation 
Total elapsed time: 5.713364459574223. Arrivals time: 0.2746855979785323 Scheduler time: 5.328262515366077 Scheduler overhead time: 0.031909646932035685 Adapter cache time: 0.03090869588777423 Engine time: 0.03272203868255019 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-8/adapters_160_slots_96_rate_1.6-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-8/adapters_160_slots_96_rate_1.6-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 1080, 33, 33, 33, 17280, 33, 1080, 17280, 1080, 33, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 33, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 33, 1080, 1080, 1080, 17280, 33, 33, 17280, 33, 17280, 33, 33, 1080, 33, 1080, 17280, 33, 33, 1080, 33, 33, 33, 33, 33, 17280, 1080, 1080, 17280, 1080, 33, 17280, 17280, 17280, 1080, 1080, 33, 33, 33, 17280, 33, 1080, 1080, 33, 17280, 17280, 17280, 33, 33, 17280, 1080, 17280, 17280, 33, 17280, 33, 1080, 33, 33, 1080, 1080, 17280, 17280, 17280, 33, 17280, 1080, 1080, 33, 33, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 33, 1080, 1080, 17280, 1080, 17280, 33, 33, 33, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 33, 1080, 1080, 33, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 33, 17280, 33, 17280, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 17280, 1080, 33, 33]
Prompts retrieved: 992109 . Total input tokens: 221179572 . Total output tokens: 198253330
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.764708975795656,
    "estimated_duration": 3600.186963903227,
    "input_throughput": 5539.72646419929,
    "output_throughput": 4881.800077667418,
    "total_throughput": 10421.526541866708,
    "itl": 175.58646614401718,
    "ttft": 1887813.274120871,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1381,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.226533574371244,
    "arrivals": 330904,
    "finished_requests": 80216,
    "scheduler_time": 97.72558377130184
}
#Debug simulation 
Total elapsed time: 5.764804456848651. Arrivals time: 0.24957267800346017 Scheduler time: 5.407093498390168 Scheduler overhead time: 0.03172003198415041 Adapter cache time: 0.029141890816390514 Engine time: 0.03255161689594388 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-16/adapters_160_slots_96_rate_1.6-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-16/adapters_160_slots_96_rate_1.6-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 1080, 33, 33, 33, 17280, 33, 1080, 17280, 1080, 33, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 33, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 33, 1080, 1080, 1080, 17280, 33, 33, 17280, 33, 17280, 33, 33, 1080, 33, 1080, 17280, 33, 33, 1080, 33, 33, 33, 33, 33, 17280, 1080, 1080, 17280, 1080, 33, 17280, 17280, 17280, 1080, 1080, 33, 33, 33, 17280, 33, 1080, 1080, 33, 17280, 17280, 17280, 33, 33, 17280, 1080, 17280, 17280, 33, 17280, 33, 1080, 33, 33, 1080, 1080, 17280, 17280, 17280, 33, 17280, 1080, 1080, 33, 33, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 33, 1080, 1080, 17280, 1080, 17280, 33, 33, 33, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 33, 1080, 1080, 33, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 33, 17280, 33, 17280, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 17280, 1080, 33, 33]
Prompts retrieved: 992109 . Total input tokens: 221179572 . Total output tokens: 198253330
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.729350369889289,
    "estimated_duration": 3600.012119187404,
    "input_throughput": 5539.290518972254,
    "output_throughput": 4881.72217708169,
    "total_throughput": 10421.012696053944,
    "itl": 175.59984016920473,
    "ttft": 1887853.9051422507,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1384,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.5063739900593225,
    "arrivals": 330904,
    "finished_requests": 80208,
    "scheduler_time": 97.71459778934594
}
#Debug simulation 
Total elapsed time: 5.72944641392678. Arrivals time: 0.27483194088563323 Scheduler time: 5.346860354300588 Scheduler overhead time: 0.03158804448321462 Adapter cache time: 0.029075543396174908 Engine time: 0.03246625931933522 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-32/adapters_160_slots_96_rate_1.6-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-32/adapters_160_slots_96_rate_1.6-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 1080, 33, 33, 33, 17280, 33, 1080, 17280, 1080, 33, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 33, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 33, 1080, 1080, 1080, 17280, 33, 33, 17280, 33, 17280, 33, 33, 1080, 33, 1080, 17280, 33, 33, 1080, 33, 33, 33, 33, 33, 17280, 1080, 1080, 17280, 1080, 33, 17280, 17280, 17280, 1080, 1080, 33, 33, 33, 17280, 33, 1080, 1080, 33, 17280, 17280, 17280, 33, 33, 17280, 1080, 17280, 17280, 33, 17280, 33, 1080, 33, 33, 1080, 1080, 17280, 17280, 17280, 33, 17280, 1080, 1080, 33, 33, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 33, 1080, 1080, 17280, 1080, 17280, 33, 33, 33, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 33, 1080, 1080, 33, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 33, 17280, 33, 17280, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 17280, 1080, 33, 33]
Prompts retrieved: 992109 . Total input tokens: 221179572 . Total output tokens: 198253330
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.807664059102535,
    "estimated_duration": 3600.1710116651843,
    "input_throughput": 5532.1616488401005,
    "output_throughput": 4876.323358839563,
    "total_throughput": 10408.485007679665,
    "itl": 173.0684051418856,
    "ttft": 1888680.857915551,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1387,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.52690687328571,
    "arrivals": 330904,
    "finished_requests": 80110,
    "scheduler_time": 98.0123236321967
}
#Debug simulation 
Total elapsed time: 5.807782509829849. Arrivals time: 0.2804927979595959 Scheduler time: 5.417064726352692 Scheduler overhead time: 0.03219708660617471 Adapter cache time: 0.030179286375641823 Engine time: 0.03291682805866003 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-16/adapters_160_slots_96_rate_1.6-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-16/adapters_160_slots_96_rate_1.6-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 1080, 33, 33, 33, 17280, 33, 1080, 17280, 1080, 33, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 33, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 33, 1080, 1080, 1080, 17280, 33, 33, 17280, 33, 17280, 33, 33, 1080, 33, 1080, 17280, 33, 33, 1080, 33, 33, 33, 33, 33, 17280, 1080, 1080, 17280, 1080, 33, 17280, 17280, 17280, 1080, 1080, 33, 33, 33, 17280, 33, 1080, 1080, 33, 17280, 17280, 17280, 33, 33, 17280, 1080, 17280, 17280, 33, 17280, 33, 1080, 33, 33, 1080, 1080, 17280, 17280, 17280, 33, 17280, 1080, 1080, 33, 33, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 33, 1080, 1080, 17280, 1080, 17280, 33, 33, 33, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 33, 1080, 1080, 33, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 33, 17280, 33, 17280, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 17280, 1080, 33, 33]
Prompts retrieved: 992109 . Total input tokens: 221179572 . Total output tokens: 198253330
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.799812769051641,
    "estimated_duration": 3600.084323361151,
    "input_throughput": 5539.465248242025,
    "output_throughput": 4881.712877100564,
    "total_throughput": 10421.178125342589,
    "itl": 175.58743138358147,
    "ttft": 1887823.7440044198,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1380,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.317083420676582,
    "arrivals": 330904,
    "finished_requests": 80212,
    "scheduler_time": 97.72199449467995
}
#Debug simulation 
Total elapsed time: 5.7999063921161. Arrivals time: 0.2760998848825693 Scheduler time: 5.415488006547093 Scheduler overhead time: 0.03174686245620251 Adapter cache time: 0.028987953905016184 Engine time: 0.03285559080541134 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-32/adapters_160_slots_96_rate_1.6-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-32/adapters_160_slots_96_rate_1.6-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 1080, 33, 33, 33, 17280, 33, 1080, 17280, 1080, 33, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 33, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 33, 1080, 1080, 1080, 17280, 33, 33, 17280, 33, 17280, 33, 33, 1080, 33, 1080, 17280, 33, 33, 1080, 33, 33, 33, 33, 33, 17280, 1080, 1080, 17280, 1080, 33, 17280, 17280, 17280, 1080, 1080, 33, 33, 33, 17280, 33, 1080, 1080, 33, 17280, 17280, 17280, 33, 33, 17280, 1080, 17280, 17280, 33, 17280, 33, 1080, 33, 33, 1080, 1080, 17280, 17280, 17280, 33, 17280, 1080, 1080, 33, 33, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 33, 1080, 1080, 17280, 1080, 17280, 33, 33, 33, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 33, 1080, 1080, 33, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 33, 17280, 33, 17280, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 17280, 1080, 33, 33]
Prompts retrieved: 992109 . Total input tokens: 221179572 . Total output tokens: 198253330
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.783878110349178,
    "estimated_duration": 3600.0343411217577,
    "input_throughput": 5531.891396845553,
    "output_throughput": 4875.882376869339,
    "total_throughput": 10407.773773714891,
    "itl": 173.07042881680167,
    "ttft": 1888677.3188048785,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1387,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.581861277949031,
    "arrivals": 330904,
    "finished_requests": 80100,
    "scheduler_time": 98.0071380347277
}
#Debug simulation 
Total elapsed time: 5.783988056238741. Arrivals time: 0.2618882395327091 Scheduler time: 5.4121348122134805 Scheduler overhead time: 0.032105912920087576 Adapter cache time: 0.029908443801105022 Engine time: 0.03306105313822627 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-16/adapters_160_slots_96_rate_1.6-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-16/adapters_160_slots_96_rate_1.6-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 1080, 33, 33, 33, 17280, 33, 1080, 17280, 1080, 33, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 33, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 33, 1080, 1080, 1080, 17280, 33, 33, 17280, 33, 17280, 33, 33, 1080, 33, 1080, 17280, 33, 33, 1080, 33, 33, 33, 33, 33, 17280, 1080, 1080, 17280, 1080, 33, 17280, 17280, 17280, 1080, 1080, 33, 33, 33, 17280, 33, 1080, 1080, 33, 17280, 17280, 17280, 33, 33, 17280, 1080, 17280, 17280, 33, 17280, 33, 1080, 33, 33, 1080, 1080, 17280, 17280, 17280, 33, 17280, 1080, 1080, 33, 33, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 33, 1080, 1080, 17280, 1080, 17280, 33, 33, 33, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 33, 1080, 1080, 33, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 33, 17280, 33, 17280, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 17280, 1080, 33, 33]
Prompts retrieved: 992109 . Total input tokens: 221179572 . Total output tokens: 198253330
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.859977904241532,
    "estimated_duration": 3600.082201777203,
    "input_throughput": 5539.88766983001,
    "output_throughput": 4881.942137688911,
    "total_throughput": 10421.829807518921,
    "itl": 175.58210126152656,
    "ttft": 1887756.1255638776,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1382,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.132249507554697,
    "arrivals": 330904,
    "finished_requests": 80216,
    "scheduler_time": 97.7253528802353
}
#Debug simulation 
Total elapsed time: 5.860072009265423. Arrivals time: 0.25389645621180534 Scheduler time: 5.4972326080314815 Scheduler overhead time: 0.031954056583344936 Adapter cache time: 0.029212231282144785 Engine time: 0.032947763334959745 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-32/adapters_160_slots_96_rate_1.6-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-32/adapters_160_slots_96_rate_1.6-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 1080, 33, 33, 33, 17280, 33, 1080, 17280, 1080, 33, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 33, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 33, 1080, 1080, 1080, 17280, 33, 33, 17280, 33, 17280, 33, 33, 1080, 33, 1080, 17280, 33, 33, 1080, 33, 33, 33, 33, 33, 17280, 1080, 1080, 17280, 1080, 33, 17280, 17280, 17280, 1080, 1080, 33, 33, 33, 17280, 33, 1080, 1080, 33, 17280, 17280, 17280, 33, 33, 17280, 1080, 17280, 17280, 33, 17280, 33, 1080, 33, 33, 1080, 1080, 17280, 17280, 17280, 33, 17280, 1080, 1080, 33, 33, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 33, 1080, 1080, 17280, 1080, 17280, 33, 33, 33, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 33, 1080, 1080, 33, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 33, 17280, 33, 17280, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 17280, 1080, 33, 33]
Prompts retrieved: 992109 . Total input tokens: 221179572 . Total output tokens: 198253330
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.77404105104506,
    "estimated_duration": 3600.0970532907004,
    "input_throughput": 5531.795033635696,
    "output_throughput": 4875.7974410593215,
    "total_throughput": 10407.592474695017,
    "itl": 173.07300016994122,
    "ttft": 1888703.2449255104,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1386,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.637333283647893,
    "arrivals": 330904,
    "finished_requests": 80100,
    "scheduler_time": 98.0073919320788
}
#Debug simulation 
Total elapsed time: 5.774149448145181. Arrivals time: 0.267710137180984 Scheduler time: 5.396970607340336 Scheduler overhead time: 0.032006639055907726 Adapter cache time: 0.02957402216270566 Engine time: 0.032982100266963243 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-8/adapters_160_slots_96_rate_1.6-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-8/adapters_160_slots_96_rate_1.6-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [53 53 54]
Adapter prompts. [270, 17280, 270, 270, 540, 270, 270, 270, 17280, 270, 540, 17280, 540, 270, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 270, 17280, 540, 17280, 17280, 17280, 540, 17280, 270, 540, 540, 540, 17280, 270, 270, 17280, 270, 17280, 270, 270, 540, 270, 540, 17280, 270, 270, 540, 270, 270, 270, 270, 270, 17280, 540, 540, 17280, 540, 270, 17280, 17280, 17280, 540, 540, 270, 270, 270, 17280, 270, 540, 540, 270, 17280, 17280, 17280, 270, 270, 17280, 540, 17280, 17280, 270, 17280, 270, 540, 270, 270, 540, 540, 17280, 17280, 17280, 270, 17280, 540, 540, 270, 270, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 17280, 270, 540, 540, 17280, 540, 17280, 270, 270, 270, 540, 540, 540, 17280, 17280, 540, 17280, 270, 540, 540, 270, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 270, 17280, 270, 17280, 540, 270, 540, 270, 270, 540, 540, 540, 17280, 540, 270, 270]
Prompts retrieved: 976050 . Total input tokens: 217550544 . Total output tokens: 195044193
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 6.065096243750304,
    "estimated_duration": 3600.110078957373,
    "input_throughput": 5578.0511038750865,
    "output_throughput": 4931.301713180256,
    "total_throughput": 10509.352817055344,
    "itl": 174.52073144356996,
    "ttft": 1878066.0741156118,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2137,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.540262308784486,
    "arrivals": 325545,
    "finished_requests": 80993,
    "scheduler_time": 98.56282817736617
}
#Debug simulation 
Total elapsed time: 6.065162205602974. Arrivals time: 0.2619598042219877 Scheduler time: 5.6874948288314044 Scheduler overhead time: 0.03201480023562908 Adapter cache time: 0.035877407528460026 Engine time: 0.03288404829800129 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-16/adapters_160_slots_96_rate_1.6-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-16/adapters_160_slots_96_rate_1.6-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [53 53 54]
Adapter prompts. [270, 17280, 270, 270, 540, 270, 270, 270, 17280, 270, 540, 17280, 540, 270, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 270, 17280, 540, 17280, 17280, 17280, 540, 17280, 270, 540, 540, 540, 17280, 270, 270, 17280, 270, 17280, 270, 270, 540, 270, 540, 17280, 270, 270, 540, 270, 270, 270, 270, 270, 17280, 540, 540, 17280, 540, 270, 17280, 17280, 17280, 540, 540, 270, 270, 270, 17280, 270, 540, 540, 270, 17280, 17280, 17280, 270, 270, 17280, 540, 17280, 17280, 270, 17280, 270, 540, 270, 270, 540, 540, 17280, 17280, 17280, 270, 17280, 540, 540, 270, 270, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 17280, 270, 540, 540, 17280, 540, 17280, 270, 270, 270, 540, 540, 540, 17280, 17280, 540, 17280, 270, 540, 540, 270, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 270, 17280, 270, 17280, 540, 270, 540, 270, 270, 540, 540, 540, 17280, 540, 270, 270]
Prompts retrieved: 976050 . Total input tokens: 217550544 . Total output tokens: 195044193
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.85940847126767,
    "estimated_duration": 3600.013587530321,
    "input_throughput": 5577.401726912479,
    "output_throughput": 4931.020555446858,
    "total_throughput": 10508.422282359337,
    "itl": 174.54446077781773,
    "ttft": 1878096.5982630712,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2141,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.974548317838659,
    "arrivals": 325545,
    "finished_requests": 80979,
    "scheduler_time": 98.54960406950079
}
#Debug simulation 
Total elapsed time: 5.859531654976308. Arrivals time: 0.251455036457628 Scheduler time: 5.491836184635758 Scheduler overhead time: 0.03252784023061395 Adapter cache time: 0.035744150169193745 Engine time: 0.03305058320984244 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-32/adapters_160_slots_96_rate_1.6-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-32/adapters_160_slots_96_rate_1.6-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [53 53 54]
Adapter prompts. [270, 17280, 270, 270, 540, 270, 270, 270, 17280, 270, 540, 17280, 540, 270, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 270, 17280, 540, 17280, 17280, 17280, 540, 17280, 270, 540, 540, 540, 17280, 270, 270, 17280, 270, 17280, 270, 270, 540, 270, 540, 17280, 270, 270, 540, 270, 270, 270, 270, 270, 17280, 540, 540, 17280, 540, 270, 17280, 17280, 17280, 540, 540, 270, 270, 270, 17280, 270, 540, 540, 270, 17280, 17280, 17280, 270, 270, 17280, 540, 17280, 17280, 270, 17280, 270, 540, 270, 270, 540, 540, 17280, 17280, 17280, 270, 17280, 540, 540, 270, 270, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 17280, 270, 540, 540, 17280, 540, 17280, 270, 270, 270, 540, 540, 540, 17280, 17280, 540, 17280, 270, 540, 540, 270, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 270, 17280, 270, 17280, 540, 270, 540, 270, 270, 540, 540, 540, 17280, 540, 270, 270]
Prompts retrieved: 976050 . Total input tokens: 217550544 . Total output tokens: 195044193
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.8584292200393975,
    "estimated_duration": 3600.0021115314803,
    "input_throughput": 5572.9333979376925,
    "output_throughput": 4927.815720767216,
    "total_throughput": 10500.749118704907,
    "itl": 172.0341094092917,
    "ttft": 1878869.929686298,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2123,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.928478295858908,
    "arrivals": 325545,
    "finished_requests": 80918,
    "scheduler_time": 98.87660160465418
}
#Debug simulation 
Total elapsed time: 5.858538305852562. Arrivals time: 0.26020957017317414 Scheduler time: 5.481308779679239 Scheduler overhead time: 0.03261810727417469 Adapter cache time: 0.035831790417432785 Engine time: 0.033392990939319134 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-16-16/adapters_160_slots_96_rate_1.6-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-16-16/adapters_160_slots_96_rate_1.6-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [53 53 54]
Adapter prompts. [270, 17280, 270, 270, 540, 270, 270, 270, 17280, 270, 540, 17280, 540, 270, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 270, 17280, 540, 17280, 17280, 17280, 540, 17280, 270, 540, 540, 540, 17280, 270, 270, 17280, 270, 17280, 270, 270, 540, 270, 540, 17280, 270, 270, 540, 270, 270, 270, 270, 270, 17280, 540, 540, 17280, 540, 270, 17280, 17280, 17280, 540, 540, 270, 270, 270, 17280, 270, 540, 540, 270, 17280, 17280, 17280, 270, 270, 17280, 540, 17280, 17280, 270, 17280, 270, 540, 270, 270, 540, 540, 17280, 17280, 17280, 270, 17280, 540, 540, 270, 270, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 17280, 270, 540, 540, 17280, 540, 17280, 270, 270, 270, 540, 540, 540, 17280, 17280, 540, 17280, 270, 540, 540, 270, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 270, 17280, 270, 17280, 540, 270, 540, 270, 270, 540, 540, 540, 17280, 540, 270, 270]
Prompts retrieved: 976050 . Total input tokens: 217550544 . Total output tokens: 195044193
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.8165951250121,
    "estimated_duration": 3600.113528776004,
    "input_throughput": 5577.8957634225835,
    "output_throughput": 4931.222545650053,
    "total_throughput": 10509.118309072635,
    "itl": 174.53221325271127,
    "ttft": 1878066.8879451572,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2140,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.696573618233446,
    "arrivals": 325545,
    "finished_requests": 80987,
    "scheduler_time": 98.55901252362905
}
#Debug simulation 
Total elapsed time: 5.816686891019344. Arrivals time: 0.25223929109051824 Scheduler time: 5.449058189988136 Scheduler overhead time: 0.032061751931905746 Adapter cache time: 0.03573157172650099 Engine time: 0.032764457166194916 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-16-32/adapters_160_slots_96_rate_1.6-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-16-32/adapters_160_slots_96_rate_1.6-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [53 53 54]
Adapter prompts. [270, 17280, 270, 270, 540, 270, 270, 270, 17280, 270, 540, 17280, 540, 270, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 270, 17280, 540, 17280, 17280, 17280, 540, 17280, 270, 540, 540, 540, 17280, 270, 270, 17280, 270, 17280, 270, 270, 540, 270, 540, 17280, 270, 270, 540, 270, 270, 270, 270, 270, 17280, 540, 540, 17280, 540, 270, 17280, 17280, 17280, 540, 540, 270, 270, 270, 17280, 270, 540, 540, 270, 17280, 17280, 17280, 270, 270, 17280, 540, 17280, 17280, 270, 17280, 270, 540, 270, 270, 540, 540, 17280, 17280, 17280, 270, 17280, 540, 540, 270, 270, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 17280, 270, 540, 540, 17280, 540, 17280, 270, 270, 270, 540, 540, 540, 17280, 17280, 540, 17280, 270, 540, 540, 270, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 270, 17280, 270, 17280, 540, 270, 540, 270, 270, 540, 540, 540, 17280, 540, 270, 270]
Prompts retrieved: 976050 . Total input tokens: 217550544 . Total output tokens: 195044193
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.843922402244061,
    "estimated_duration": 3600.105606089278,
    "input_throughput": 5572.773189226959,
    "output_throughput": 4927.674057670426,
    "total_throughput": 10500.447246897385,
    "itl": 172.02832748469,
    "ttft": 1878917.343477433,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2122,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.0091867987623955,
    "arrivals": 325545,
    "finished_requests": 80918,
    "scheduler_time": 98.87812081881135
}
#Debug simulation 
Total elapsed time: 5.844039713963866. Arrivals time: 0.2572475206106901 Scheduler time: 5.4692782876081765 Scheduler overhead time: 0.03263648459687829 Adapter cache time: 0.03629664145410061 Engine time: 0.03339518187567592 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_16-16-16/adapters_160_slots_96_rate_1.6-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_16-16-16/adapters_160_slots_96_rate_1.6-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [53 53 54]
Adapter prompts. [270, 17280, 270, 270, 540, 270, 270, 270, 17280, 270, 540, 17280, 540, 270, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 270, 17280, 540, 17280, 17280, 17280, 540, 17280, 270, 540, 540, 540, 17280, 270, 270, 17280, 270, 17280, 270, 270, 540, 270, 540, 17280, 270, 270, 540, 270, 270, 270, 270, 270, 17280, 540, 540, 17280, 540, 270, 17280, 17280, 17280, 540, 540, 270, 270, 270, 17280, 270, 540, 540, 270, 17280, 17280, 17280, 270, 270, 17280, 540, 17280, 17280, 270, 17280, 270, 540, 270, 270, 540, 540, 17280, 17280, 17280, 270, 17280, 540, 540, 270, 270, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 17280, 270, 540, 540, 17280, 540, 17280, 270, 270, 270, 540, 540, 540, 17280, 17280, 540, 17280, 270, 540, 540, 270, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 270, 17280, 270, 17280, 540, 270, 540, 270, 270, 540, 540, 540, 17280, 540, 270, 270]
Prompts retrieved: 976050 . Total input tokens: 217550544 . Total output tokens: 195044193
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.815836973953992,
    "estimated_duration": 3600.1098736410077,
    "input_throughput": 5578.105309238819,
    "output_throughput": 4931.404213517717,
    "total_throughput": 10509.509522756536,
    "itl": 174.51301385564068,
    "ttft": 1878110.6049283836,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2136,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.386747429910857,
    "arrivals": 325545,
    "finished_requests": 80995,
    "scheduler_time": 98.56730764718931
}
#Debug simulation 
Total elapsed time: 5.815933059900999. Arrivals time: 0.25260757841169834 Scheduler time: 5.4474149090237916 Scheduler overhead time: 0.03196439705789089 Adapter cache time: 0.03616094449535012 Engine time: 0.03294769302010536 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_16-16-32/adapters_160_slots_96_rate_1.6-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_16-16-32/adapters_160_slots_96_rate_1.6-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [53 53 54]
Adapter prompts. [270, 17280, 270, 270, 540, 270, 270, 270, 17280, 270, 540, 17280, 540, 270, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 270, 17280, 540, 17280, 17280, 17280, 540, 17280, 270, 540, 540, 540, 17280, 270, 270, 17280, 270, 17280, 270, 270, 540, 270, 540, 17280, 270, 270, 540, 270, 270, 270, 270, 270, 17280, 540, 540, 17280, 540, 270, 17280, 17280, 17280, 540, 540, 270, 270, 270, 17280, 270, 540, 540, 270, 17280, 17280, 17280, 270, 270, 17280, 540, 17280, 17280, 270, 17280, 270, 540, 270, 270, 540, 540, 17280, 17280, 17280, 270, 17280, 540, 540, 270, 270, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 17280, 270, 540, 540, 17280, 540, 17280, 270, 270, 270, 540, 540, 540, 17280, 17280, 540, 17280, 270, 540, 540, 270, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 270, 17280, 270, 17280, 540, 270, 540, 270, 270, 540, 540, 540, 17280, 540, 270, 270]
Prompts retrieved: 976050 . Total input tokens: 217550544 . Total output tokens: 195044193
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.828306647948921,
    "estimated_duration": 3600.159646315505,
    "input_throughput": 5572.689539068787,
    "output_throughput": 4927.600090778118,
    "total_throughput": 10500.289629846906,
    "itl": 172.04862813216025,
    "ttft": 1878925.470136266,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2124,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.1061538101730255,
    "arrivals": 325545,
    "finished_requests": 80918,
    "scheduler_time": 98.87561964322734
}
#Debug simulation 
Total elapsed time: 5.828404919244349. Arrivals time: 0.2578687663190067 Scheduler time: 5.452882958110422 Scheduler overhead time: 0.03256731340661645 Adapter cache time: 0.036561738699674606 Engine time: 0.03347116615623236 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-8/adapters_160_slots_96_rate_1.6-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-8/adapters_160_slots_96_rate_1.6-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 540, 135, 135, 135, 17280, 135, 540, 17280, 540, 135, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 135, 17280, 540, 17280, 17280, 17280, 540, 17280, 135, 540, 540, 540, 17280, 135, 135, 17280, 135, 17280, 135, 135, 540, 135, 540, 17280, 135, 135, 540, 135, 135, 135, 135, 135, 17280, 540, 540, 17280, 540, 135, 17280, 17280, 17280, 540, 540, 135, 135, 135, 17280, 135, 540, 540, 135, 17280, 17280, 17280, 135, 135, 17280, 540, 17280, 17280, 135, 17280, 135, 540, 135, 135, 540, 540, 17280, 17280, 17280, 135, 17280, 540, 540, 135, 135, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 17280, 135, 540, 540, 17280, 540, 17280, 135, 135, 135, 540, 540, 540, 17280, 17280, 540, 17280, 135, 540, 540, 135, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 135, 17280, 135, 17280, 540, 135, 540, 135, 135, 540, 540, 540, 17280, 540, 135, 135]
Prompts retrieved: 968895 . Total input tokens: 215948582 . Total output tokens: 193639611
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.909772917162627,
    "estimated_duration": 3600.0785380672883,
    "input_throughput": 5727.311163347354,
    "output_throughput": 5056.210804159899,
    "total_throughput": 10783.521967507253,
    "itl": 169.96174521238297,
    "ttft": 1853074.7178438946,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1615,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.942687706451533,
    "arrivals": 323217,
    "finished_requests": 83423,
    "scheduler_time": 101.04511196278578
}
#Debug simulation 
Total elapsed time: 5.90987023897469. Arrivals time: 0.25996805215254426 Scheduler time: 5.536785027012229 Scheduler overhead time: 0.03276627976447344 Adapter cache time: 0.0316910850815475 Engine time: 0.03346354328095913 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-16/adapters_160_slots_96_rate_1.6-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-16/adapters_160_slots_96_rate_1.6-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 540, 135, 135, 135, 17280, 135, 540, 17280, 540, 135, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 135, 17280, 540, 17280, 17280, 17280, 540, 17280, 135, 540, 540, 540, 17280, 135, 135, 17280, 135, 17280, 135, 135, 540, 135, 540, 17280, 135, 135, 540, 135, 135, 135, 135, 135, 17280, 540, 540, 17280, 540, 135, 17280, 17280, 17280, 540, 540, 135, 135, 135, 17280, 135, 540, 540, 135, 17280, 17280, 17280, 135, 135, 17280, 540, 17280, 17280, 135, 17280, 135, 540, 135, 135, 540, 540, 17280, 17280, 17280, 135, 17280, 540, 540, 135, 135, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 17280, 135, 540, 540, 17280, 540, 17280, 135, 135, 135, 540, 540, 540, 17280, 17280, 540, 17280, 135, 540, 540, 135, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 135, 17280, 135, 17280, 540, 135, 540, 135, 135, 540, 540, 540, 17280, 540, 135, 135]
Prompts retrieved: 968895 . Total input tokens: 215948582 . Total output tokens: 193639611
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.016497788019478,
    "estimated_duration": 3600.1524671880566,
    "input_throughput": 5726.516637253044,
    "output_throughput": 5055.643661174213,
    "total_throughput": 10782.160298427256,
    "itl": 169.98208420211293,
    "ttft": 1853111.606758931,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1616,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.271978434522063,
    "arrivals": 323217,
    "finished_requests": 83412,
    "scheduler_time": 101.037355643593
}
#Debug simulation 
Total elapsed time: 6.016598066780716. Arrivals time: 0.2731521613895893 Scheduler time: 5.629144990351051 Scheduler overhead time: 0.032901858910918236 Adapter cache time: 0.032222367357462645 Engine time: 0.033875380642712116 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-32/adapters_160_slots_96_rate_1.6-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-32/adapters_160_slots_96_rate_1.6-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 540, 135, 135, 135, 17280, 135, 540, 17280, 540, 135, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 135, 17280, 540, 17280, 17280, 17280, 540, 17280, 135, 540, 540, 540, 17280, 135, 135, 17280, 135, 17280, 135, 135, 540, 135, 540, 17280, 135, 135, 540, 135, 135, 135, 135, 135, 17280, 540, 540, 17280, 540, 135, 17280, 17280, 17280, 540, 540, 135, 135, 135, 17280, 135, 540, 540, 135, 17280, 17280, 17280, 135, 135, 17280, 540, 17280, 17280, 135, 17280, 135, 540, 135, 135, 540, 540, 17280, 17280, 17280, 135, 17280, 540, 540, 135, 135, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 17280, 135, 540, 540, 17280, 540, 17280, 135, 135, 135, 540, 540, 540, 17280, 17280, 540, 17280, 135, 540, 540, 135, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 135, 17280, 135, 17280, 540, 135, 540, 135, 135, 540, 540, 540, 17280, 540, 135, 135]
Prompts retrieved: 968895 . Total input tokens: 215948582 . Total output tokens: 193639611
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.9553732317872345,
    "estimated_duration": 3600.120463258074,
    "input_throughput": 5721.986308579615,
    "output_throughput": 5051.54985384619,
    "total_throughput": 10773.536162425806,
    "itl": 168.1383828098654,
    "ttft": 1853635.7982748128,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1609,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.258213894311281,
    "arrivals": 323217,
    "finished_requests": 83346,
    "scheduler_time": 101.28236666011702
}
#Debug simulation 
Total elapsed time: 5.955495453905314. Arrivals time: 0.2600952936336398 Scheduler time: 5.580812726635486 Scheduler overhead time: 0.03317848592996597 Adapter cache time: 0.03198663052171469 Engine time: 0.034028925467282534 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-16/adapters_160_slots_96_rate_1.6-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-16/adapters_160_slots_96_rate_1.6-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 540, 135, 135, 135, 17280, 135, 540, 17280, 540, 135, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 135, 17280, 540, 17280, 17280, 17280, 540, 17280, 135, 540, 540, 540, 17280, 135, 135, 17280, 135, 17280, 135, 135, 540, 135, 540, 17280, 135, 135, 540, 135, 135, 135, 135, 135, 17280, 540, 540, 17280, 540, 135, 17280, 17280, 17280, 540, 540, 135, 135, 135, 17280, 135, 540, 540, 135, 17280, 17280, 17280, 135, 135, 17280, 540, 17280, 17280, 135, 17280, 135, 540, 135, 135, 540, 540, 17280, 17280, 17280, 135, 17280, 540, 540, 135, 135, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 17280, 135, 540, 540, 17280, 540, 17280, 135, 135, 135, 540, 540, 540, 17280, 17280, 540, 17280, 135, 540, 540, 135, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 135, 17280, 135, 17280, 540, 135, 540, 135, 135, 540, 540, 540, 17280, 540, 135, 135]
Prompts retrieved: 968895 . Total input tokens: 215948582 . Total output tokens: 193639611
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 6.0314067816361785,
    "estimated_duration": 3600.063690879939,
    "input_throughput": 5727.097843360794,
    "output_throughput": 5055.982216678795,
    "total_throughput": 10783.08006003959,
    "itl": 169.96951173737438,
    "ttft": 1853084.9008139067,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1612,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.043871309887505,
    "arrivals": 323217,
    "finished_requests": 83418,
    "scheduler_time": 101.04088546148408
}
#Debug simulation 
Total elapsed time: 6.031500004697591. Arrivals time: 0.2936714389361441 Scheduler time: 5.6236138148233294 Scheduler overhead time: 0.032986612524837255 Adapter cache time: 0.032204309944063425 Engine time: 0.0337141458876431 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-32/adapters_160_slots_96_rate_1.6-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-32/adapters_160_slots_96_rate_1.6-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 540, 135, 135, 135, 17280, 135, 540, 17280, 540, 135, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 135, 17280, 540, 17280, 17280, 17280, 540, 17280, 135, 540, 540, 540, 17280, 135, 135, 17280, 135, 17280, 135, 135, 540, 135, 540, 17280, 135, 135, 540, 135, 135, 135, 135, 135, 17280, 540, 540, 17280, 540, 135, 17280, 17280, 17280, 540, 540, 135, 135, 135, 17280, 135, 540, 540, 135, 17280, 17280, 17280, 135, 135, 17280, 540, 17280, 17280, 135, 17280, 135, 540, 135, 135, 540, 540, 17280, 17280, 17280, 135, 17280, 540, 540, 135, 135, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 17280, 135, 540, 540, 17280, 540, 17280, 135, 135, 135, 540, 540, 540, 17280, 17280, 540, 17280, 135, 540, 540, 135, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 135, 17280, 135, 17280, 540, 135, 540, 135, 135, 540, 540, 540, 17280, 540, 135, 135]
Prompts retrieved: 968895 . Total input tokens: 215948582 . Total output tokens: 193639611
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.97654419997707,
    "estimated_duration": 3600.0013641162286,
    "input_throughput": 5722.127831764601,
    "output_throughput": 5051.668919149013,
    "total_throughput": 10773.796750913614,
    "itl": 168.1409748363918,
    "ttft": 1853544.6784748635,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1609,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.324234632179077,
    "arrivals": 323217,
    "finished_requests": 83345,
    "scheduler_time": 101.27700342434339
}
#Debug simulation 
Total elapsed time: 5.976635423954576. Arrivals time: 0.2604096927680075 Scheduler time: 5.601844109594822 Scheduler overhead time: 0.033105815295130014 Adapter cache time: 0.031914311926811934 Engine time: 0.03378793364390731 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-16/adapters_160_slots_96_rate_1.6-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-16/adapters_160_slots_96_rate_1.6-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 540, 135, 135, 135, 17280, 135, 540, 17280, 540, 135, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 135, 17280, 540, 17280, 17280, 17280, 540, 17280, 135, 540, 540, 540, 17280, 135, 135, 17280, 135, 17280, 135, 135, 540, 135, 540, 17280, 135, 135, 540, 135, 135, 135, 135, 135, 17280, 540, 540, 17280, 540, 135, 17280, 17280, 17280, 540, 540, 135, 135, 135, 17280, 135, 540, 540, 135, 17280, 17280, 17280, 135, 135, 17280, 540, 17280, 17280, 135, 17280, 135, 540, 135, 135, 540, 540, 17280, 17280, 17280, 135, 17280, 540, 540, 135, 135, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 17280, 135, 540, 540, 17280, 540, 17280, 135, 135, 135, 540, 540, 540, 17280, 17280, 540, 17280, 135, 540, 540, 135, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 135, 17280, 135, 17280, 540, 135, 540, 135, 135, 540, 540, 540, 17280, 540, 135, 135]
Prompts retrieved: 968895 . Total input tokens: 215948582 . Total output tokens: 193639611
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.932580466847867,
    "estimated_duration": 3600.159640933018,
    "input_throughput": 5727.494349293951,
    "output_throughput": 5056.478271969688,
    "total_throughput": 10783.972621263638,
    "itl": 169.95737565881774,
    "ttft": 1853101.6725636837,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1615,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.828931226266879,
    "arrivals": 323217,
    "finished_requests": 83428,
    "scheduler_time": 101.05041273375576
}
#Debug simulation 
Total elapsed time: 5.932674001902342. Arrivals time: 0.25767618604004383 Scheduler time: 5.56145130796358 Scheduler overhead time: 0.03273505996912718 Adapter cache time: 0.031766876112669706 Engine time: 0.033932882361114025 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-32/adapters_160_slots_96_rate_1.6-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-32/adapters_160_slots_96_rate_1.6-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 540, 135, 135, 135, 17280, 135, 540, 17280, 540, 135, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 135, 17280, 540, 17280, 17280, 17280, 540, 17280, 135, 540, 540, 540, 17280, 135, 135, 17280, 135, 17280, 135, 135, 540, 135, 540, 17280, 135, 135, 540, 135, 135, 135, 135, 135, 17280, 540, 540, 17280, 540, 135, 17280, 17280, 17280, 540, 540, 135, 135, 135, 17280, 135, 540, 540, 135, 17280, 17280, 17280, 135, 135, 17280, 540, 17280, 17280, 135, 17280, 135, 540, 135, 135, 540, 540, 17280, 17280, 17280, 135, 17280, 540, 540, 135, 135, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 17280, 135, 540, 540, 17280, 540, 17280, 135, 135, 135, 540, 540, 540, 17280, 17280, 540, 17280, 135, 540, 540, 135, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 135, 17280, 135, 17280, 540, 135, 540, 135, 135, 540, 540, 540, 17280, 540, 135, 135]
Prompts retrieved: 968895 . Total input tokens: 215948582 . Total output tokens: 193639611
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.991948276758194,
    "estimated_duration": 3600.0655170921914,
    "input_throughput": 5722.025863751101,
    "output_throughput": 5051.578898677662,
    "total_throughput": 10773.604762428762,
    "itl": 168.14348591026294,
    "ttft": 1853569.071124079,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1609,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.392896199561578,
    "arrivals": 323217,
    "finished_requests": 83345,
    "scheduler_time": 101.27700607881742
}
#Debug simulation 
Total elapsed time: 5.9920466067269444. Arrivals time: 0.2610462000593543 Scheduler time: 5.616193911060691 Scheduler overhead time: 0.03320883912965655 Adapter cache time: 0.032260028179734945 Engine time: 0.03386848885565996 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-8/adapters_160_slots_96_rate_1.6-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-8/adapters_160_slots_96_rate_1.6-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 540, 66, 66, 66, 17280, 66, 540, 17280, 540, 66, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 66, 17280, 540, 17280, 17280, 17280, 540, 17280, 66, 540, 540, 540, 17280, 66, 66, 17280, 66, 17280, 66, 66, 540, 66, 540, 17280, 66, 66, 540, 66, 66, 66, 66, 66, 17280, 540, 540, 17280, 540, 66, 17280, 17280, 17280, 540, 540, 66, 66, 66, 17280, 66, 540, 540, 66, 17280, 17280, 17280, 66, 66, 17280, 540, 17280, 17280, 66, 17280, 66, 540, 66, 66, 540, 540, 17280, 17280, 17280, 66, 17280, 540, 540, 66, 66, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 17280, 66, 540, 540, 17280, 540, 17280, 66, 66, 66, 540, 540, 540, 17280, 17280, 540, 17280, 66, 540, 540, 66, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 66, 17280, 66, 17280, 540, 66, 540, 66, 66, 540, 540, 540, 17280, 540, 66, 66]
Prompts retrieved: 965238 . Total input tokens: 215125306 . Total output tokens: 192903108
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 6.103856520727277,
    "estimated_duration": 3600.106212689902,
    "input_throughput": 5840.45963029789,
    "output_throughput": 5164.344578075217,
    "total_throughput": 11004.804208373107,
    "itl": 166.72410441263375,
    "ttft": 1840187.146501691,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1187,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.632798952048269,
    "arrivals": 321998,
    "finished_requests": 84899,
    "scheduler_time": 103.09541767897544
}
#Debug simulation 
Total elapsed time: 6.103961086831987. Arrivals time: 0.2666006227955222 Scheduler time: 5.725449428893626 Scheduler overhead time: 0.03335239412263036 Adapter cache time: 0.02869959967210889 Engine time: 0.03431629529222846 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-16/adapters_160_slots_96_rate_1.6-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-16/adapters_160_slots_96_rate_1.6-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 540, 66, 66, 66, 17280, 66, 540, 17280, 540, 66, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 66, 17280, 540, 17280, 17280, 17280, 540, 17280, 66, 540, 540, 540, 17280, 66, 66, 17280, 66, 17280, 66, 66, 540, 66, 540, 17280, 66, 66, 540, 66, 66, 66, 66, 66, 17280, 540, 540, 17280, 540, 66, 17280, 17280, 17280, 540, 540, 66, 66, 66, 17280, 66, 540, 540, 66, 17280, 17280, 17280, 66, 66, 17280, 540, 17280, 17280, 66, 17280, 66, 540, 66, 66, 540, 540, 17280, 17280, 17280, 66, 17280, 540, 540, 66, 66, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 17280, 66, 540, 540, 17280, 540, 17280, 66, 66, 66, 540, 540, 540, 17280, 17280, 540, 17280, 66, 540, 540, 66, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 66, 17280, 66, 17280, 540, 66, 540, 66, 66, 540, 540, 540, 17280, 540, 66, 66]
Prompts retrieved: 965238 . Total input tokens: 215125306 . Total output tokens: 192903108
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.2925150860100985,
    "estimated_duration": 3600.0481833818703,
    "input_throughput": 5840.375719707342,
    "output_throughput": 5164.253102450191,
    "total_throughput": 11004.628822157534,
    "itl": 166.73544769693575,
    "ttft": 1840211.6179938433,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1190,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.879724366546148,
    "arrivals": 321998,
    "finished_requests": 84896,
    "scheduler_time": 103.08794535401566
}
#Debug simulation 
Total elapsed time: 6.292609238997102. Arrivals time: 0.2643207428045571 Scheduler time: 5.916787028312683 Scheduler overhead time: 0.03331422200426459 Adapter cache time: 0.02840039599686861 Engine time: 0.034261361695826054 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-32/adapters_160_slots_96_rate_1.6-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-32/adapters_160_slots_96_rate_1.6-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 540, 66, 66, 66, 17280, 66, 540, 17280, 540, 66, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 66, 17280, 540, 17280, 17280, 17280, 540, 17280, 66, 540, 540, 540, 17280, 66, 66, 17280, 66, 17280, 66, 66, 540, 66, 540, 17280, 66, 66, 540, 66, 66, 66, 66, 66, 17280, 540, 540, 17280, 540, 66, 17280, 17280, 17280, 540, 540, 66, 66, 66, 17280, 66, 540, 540, 66, 17280, 17280, 17280, 66, 66, 17280, 540, 17280, 17280, 66, 17280, 66, 540, 66, 66, 540, 540, 17280, 17280, 17280, 66, 17280, 540, 540, 66, 66, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 17280, 66, 540, 540, 17280, 540, 17280, 66, 66, 66, 540, 540, 540, 17280, 17280, 540, 17280, 66, 540, 540, 66, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 66, 17280, 66, 17280, 540, 66, 540, 66, 66, 540, 540, 540, 17280, 540, 66, 66]
Prompts retrieved: 965238 . Total input tokens: 215125306 . Total output tokens: 192903108
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.072026224806905,
    "estimated_duration": 3600.0558033310117,
    "input_throughput": 5833.556518920722,
    "output_throughput": 5158.4164286612595,
    "total_throughput": 10991.972947581982,
    "itl": 164.57403223241016,
    "ttft": 1841299.5751321693,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1179,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.8506872734426887,
    "arrivals": 321998,
    "finished_requests": 84801,
    "scheduler_time": 103.36264548205357
}
#Debug simulation 
Total elapsed time: 6.072122439742088. Arrivals time: 0.26287898095324636 Scheduler time: 5.696434927172959 Scheduler overhead time: 0.033830251544713974 Adapter cache time: 0.02874519396573305 Engine time: 0.03456862783059478 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-16/adapters_160_slots_96_rate_1.6-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-16/adapters_160_slots_96_rate_1.6-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 540, 66, 66, 66, 17280, 66, 540, 17280, 540, 66, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 66, 17280, 540, 17280, 17280, 17280, 540, 17280, 66, 540, 540, 540, 17280, 66, 66, 17280, 66, 17280, 66, 66, 540, 66, 540, 17280, 66, 66, 540, 66, 66, 66, 66, 66, 17280, 540, 540, 17280, 540, 66, 17280, 17280, 17280, 540, 540, 66, 66, 66, 17280, 66, 540, 540, 66, 17280, 17280, 17280, 66, 66, 17280, 540, 17280, 17280, 66, 17280, 66, 540, 66, 66, 540, 540, 17280, 17280, 17280, 66, 17280, 540, 540, 66, 66, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 17280, 66, 540, 540, 17280, 540, 17280, 66, 66, 66, 540, 540, 540, 17280, 17280, 540, 17280, 66, 540, 540, 66, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 66, 17280, 66, 17280, 540, 66, 540, 66, 66, 540, 540, 540, 17280, 540, 66, 66]
Prompts retrieved: 965238 . Total input tokens: 215125306 . Total output tokens: 192903108
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 6.0487770340405405,
    "estimated_duration": 3600.0247495817766,
    "input_throughput": 5840.58318000249,
    "output_throughput": 5164.350884576516,
    "total_throughput": 11004.934064579005,
    "itl": 166.7273909052501,
    "ttft": 1840170.0431055613,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1187,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7150793993356226,
    "arrivals": 321998,
    "finished_requests": 84898,
    "scheduler_time": 103.09110609935654
}
#Debug simulation 
Total elapsed time: 6.0488748350180686. Arrivals time: 0.2580052721314132 Scheduler time: 5.679590498097241 Scheduler overhead time: 0.03331988863646984 Adapter cache time: 0.02829416748136282 Engine time: 0.03415065025910735 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-32/adapters_160_slots_96_rate_1.6-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-32/adapters_160_slots_96_rate_1.6-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 540, 66, 66, 66, 17280, 66, 540, 17280, 540, 66, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 66, 17280, 540, 17280, 17280, 17280, 540, 17280, 66, 540, 540, 540, 17280, 66, 66, 17280, 66, 17280, 66, 66, 540, 66, 540, 17280, 66, 66, 540, 66, 66, 66, 66, 66, 17280, 540, 540, 17280, 540, 66, 17280, 17280, 17280, 540, 540, 66, 66, 66, 17280, 66, 540, 540, 66, 17280, 17280, 17280, 66, 66, 17280, 540, 17280, 17280, 66, 17280, 66, 540, 66, 66, 540, 540, 17280, 17280, 17280, 66, 17280, 540, 540, 66, 66, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 17280, 66, 540, 540, 17280, 540, 17280, 66, 66, 66, 540, 540, 540, 17280, 17280, 540, 17280, 66, 540, 540, 66, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 66, 17280, 66, 17280, 540, 66, 540, 66, 66, 540, 540, 540, 17280, 540, 66, 66]
Prompts retrieved: 965238 . Total input tokens: 215125306 . Total output tokens: 192903108
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 6.0398971904069185,
    "estimated_duration": 3600.10758660313,
    "input_throughput": 5833.472610138173,
    "output_throughput": 5158.342230967108,
    "total_throughput": 10991.81484110528,
    "itl": 164.5756228922378,
    "ttft": 1841322.9728933997,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1180,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.9013514634780586,
    "arrivals": 321998,
    "finished_requests": 84801,
    "scheduler_time": 103.36292086673632
}
#Debug simulation 
Total elapsed time: 6.039992327336222. Arrivals time: 0.26474814023822546 Scheduler time: 5.661913608666509 Scheduler overhead time: 0.03375612199306488 Adapter cache time: 0.029150118585675955 Engine time: 0.03474477492272854 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-16/adapters_160_slots_96_rate_1.6-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-16/adapters_160_slots_96_rate_1.6-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 540, 66, 66, 66, 17280, 66, 540, 17280, 540, 66, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 66, 17280, 540, 17280, 17280, 17280, 540, 17280, 66, 540, 540, 540, 17280, 66, 66, 17280, 66, 17280, 66, 66, 540, 66, 540, 17280, 66, 66, 540, 66, 66, 66, 66, 66, 17280, 540, 540, 17280, 540, 66, 17280, 17280, 17280, 540, 540, 66, 66, 66, 17280, 66, 540, 540, 66, 17280, 17280, 17280, 66, 66, 17280, 540, 17280, 17280, 66, 17280, 66, 540, 66, 66, 540, 540, 17280, 17280, 17280, 66, 17280, 540, 540, 66, 66, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 17280, 66, 540, 540, 17280, 540, 17280, 66, 66, 66, 540, 540, 540, 17280, 17280, 540, 17280, 66, 540, 540, 66, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 66, 17280, 66, 17280, 540, 66, 540, 66, 66, 540, 540, 540, 17280, 540, 66, 66]
Prompts retrieved: 965238 . Total input tokens: 215125306 . Total output tokens: 192903108
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 6.072640889789909,
    "estimated_duration": 3600.018052451161,
    "input_throughput": 5840.602656334943,
    "output_throughput": 5164.471046844071,
    "total_throughput": 11005.073703179014,
    "itl": 166.72042406888414,
    "ttft": 1840151.7367820945,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1187,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5491897000487933,
    "arrivals": 321998,
    "finished_requests": 84899,
    "scheduler_time": 103.09521642789298
}
#Debug simulation 
Total elapsed time: 6.072732486762106. Arrivals time: 0.26149429846554995 Scheduler time: 5.699374276213348 Scheduler overhead time: 0.033478382509201765 Adapter cache time: 0.028696355409920216 Engine time: 0.03424895694479346 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-32/adapters_160_slots_96_rate_1.6-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-32/adapters_160_slots_96_rate_1.6-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 540, 66, 66, 66, 17280, 66, 540, 17280, 540, 66, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 66, 17280, 540, 17280, 17280, 17280, 540, 17280, 66, 540, 540, 540, 17280, 66, 66, 17280, 66, 17280, 66, 66, 540, 66, 540, 17280, 66, 66, 540, 66, 66, 66, 66, 66, 17280, 540, 540, 17280, 540, 66, 17280, 17280, 17280, 540, 540, 66, 66, 66, 17280, 66, 540, 540, 66, 17280, 17280, 17280, 66, 66, 17280, 540, 17280, 17280, 66, 17280, 66, 540, 66, 66, 540, 540, 17280, 17280, 17280, 66, 17280, 540, 540, 66, 66, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 17280, 66, 540, 540, 17280, 540, 17280, 66, 66, 66, 540, 540, 540, 17280, 17280, 540, 17280, 66, 540, 540, 66, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 66, 17280, 66, 17280, 540, 66, 540, 66, 66, 540, 540, 540, 17280, 540, 66, 66]
Prompts retrieved: 965238 . Total input tokens: 215125306 . Total output tokens: 192903108
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.049125260207802,
    "estimated_duration": 3600.1590540456586,
    "input_throughput": 5833.389215512603,
    "output_throughput": 5158.268487924556,
    "total_throughput": 10991.657703437158,
    "itl": 164.5778291926908,
    "ttft": 1841344.5821521955,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1180,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.9520302394033076,
    "arrivals": 321998,
    "finished_requests": 84801,
    "scheduler_time": 103.36302205603656
}
#Debug simulation 
Total elapsed time: 6.049216411076486. Arrivals time: 0.2635364644229412 Scheduler time: 5.673403443302959 Scheduler overhead time: 0.03372403047978878 Adapter cache time: 0.02843860676512122 Engine time: 0.03452397044748068 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-8/adapters_160_slots_96_rate_1.6-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-8/adapters_160_slots_96_rate_1.6-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 540, 33, 33, 33, 17280, 33, 540, 17280, 540, 33, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 33, 17280, 540, 17280, 17280, 17280, 540, 17280, 33, 540, 540, 540, 17280, 33, 33, 17280, 33, 17280, 33, 33, 540, 33, 540, 17280, 33, 33, 540, 33, 33, 33, 33, 33, 17280, 540, 540, 17280, 540, 33, 17280, 17280, 17280, 540, 540, 33, 33, 33, 17280, 33, 540, 540, 33, 17280, 17280, 17280, 33, 33, 17280, 540, 17280, 17280, 33, 17280, 33, 540, 33, 33, 540, 540, 17280, 17280, 17280, 33, 17280, 540, 540, 33, 33, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 17280, 33, 540, 540, 17280, 540, 17280, 33, 33, 33, 540, 540, 540, 17280, 17280, 540, 17280, 33, 540, 540, 33, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 33, 17280, 33, 17280, 540, 33, 540, 33, 33, 540, 540, 540, 17280, 540, 33, 33]
Prompts retrieved: 963489 . Total input tokens: 214745861 . Total output tokens: 192549450
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 6.161888703238219,
    "estimated_duration": 3600.043163326074,
    "input_throughput": 5926.793938850179,
    "output_throughput": 5211.900843617895,
    "total_throughput": 11138.694782468074,
    "itl": 164.63670301802952,
    "ttft": 1833749.2711178458,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 923,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8248301876499937,
    "arrivals": 321377,
    "finished_requests": 85626,
    "scheduler_time": 104.23272515776868
}
#Debug simulation 
Total elapsed time: 6.161992580164224. Arrivals time: 0.2667441670782864 Scheduler time: 5.784732471685857 Scheduler overhead time: 0.033815443981438875 Adapter cache time: 0.026386833284050226 Engine time: 0.03464686404913664 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-16/adapters_160_slots_96_rate_1.6-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-16/adapters_160_slots_96_rate_1.6-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 540, 33, 33, 33, 17280, 33, 540, 17280, 540, 33, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 33, 17280, 540, 17280, 17280, 17280, 540, 17280, 33, 540, 540, 540, 17280, 33, 33, 17280, 33, 17280, 33, 33, 540, 33, 540, 17280, 33, 33, 540, 33, 33, 33, 33, 33, 17280, 540, 540, 17280, 540, 33, 17280, 17280, 17280, 540, 540, 33, 33, 33, 17280, 33, 540, 540, 33, 17280, 17280, 17280, 33, 33, 17280, 540, 17280, 17280, 33, 17280, 33, 540, 33, 33, 540, 540, 17280, 17280, 17280, 33, 17280, 540, 540, 33, 33, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 17280, 33, 540, 540, 17280, 540, 17280, 33, 33, 33, 540, 540, 540, 17280, 17280, 540, 17280, 33, 540, 540, 33, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 33, 17280, 33, 17280, 540, 33, 540, 33, 33, 540, 540, 540, 17280, 540, 33, 33]
Prompts retrieved: 963489 . Total input tokens: 214745861 . Total output tokens: 192549450
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.126028215046972,
    "estimated_duration": 3600.1128330128026,
    "input_throughput": 5926.547858263787,
    "output_throughput": 5211.758039344007,
    "total_throughput": 11138.305897607794,
    "itl": 164.64557230683255,
    "ttft": 1833793.3065847894,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 924,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.009189449509144,
    "arrivals": 321377,
    "finished_requests": 85624,
    "scheduler_time": 104.22971821276667
}
#Debug simulation 
Total elapsed time: 6.126143385190517. Arrivals time: 0.2876847074367106 Scheduler time: 5.728561450261623 Scheduler overhead time: 0.03355701407417655 Adapter cache time: 0.026272214483469725 Engine time: 0.0344675462692976 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-32/adapters_160_slots_96_rate_1.6-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-32/adapters_160_slots_96_rate_1.6-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 540, 33, 33, 33, 17280, 33, 540, 17280, 540, 33, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 33, 17280, 540, 17280, 17280, 17280, 540, 17280, 33, 540, 540, 540, 17280, 33, 33, 17280, 33, 17280, 33, 33, 540, 33, 540, 17280, 33, 33, 540, 33, 33, 33, 33, 33, 17280, 540, 540, 17280, 540, 33, 17280, 17280, 17280, 540, 540, 33, 33, 33, 17280, 33, 540, 540, 33, 17280, 17280, 17280, 33, 33, 17280, 540, 17280, 17280, 33, 17280, 33, 540, 33, 33, 540, 540, 17280, 17280, 17280, 33, 17280, 540, 540, 33, 33, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 17280, 33, 540, 540, 17280, 540, 17280, 33, 33, 33, 540, 540, 540, 17280, 17280, 540, 17280, 33, 540, 540, 33, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 33, 17280, 33, 17280, 540, 33, 540, 33, 33, 540, 540, 540, 17280, 540, 33, 33]
Prompts retrieved: 963489 . Total input tokens: 214745861 . Total output tokens: 192549450
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.071331254672259,
    "estimated_duration": 3600.1654486255734,
    "input_throughput": 5918.313006457603,
    "output_throughput": 5205.367438642131,
    "total_throughput": 11123.680445099733,
    "itl": 162.5318252703796,
    "ttft": 1835161.2757540008,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 921,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0050921089388174,
    "arrivals": 321377,
    "finished_requests": 85505,
    "scheduler_time": 104.50196373065756
}
#Debug simulation 
Total elapsed time: 6.071446821093559. Arrivals time: 0.2817087019793689 Scheduler time: 5.679006930440664 Scheduler overhead time: 0.0338955782353878 Adapter cache time: 0.026491887401789427 Engine time: 0.034549104049801826 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-16/adapters_160_slots_96_rate_1.6-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-16/adapters_160_slots_96_rate_1.6-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 540, 33, 33, 33, 17280, 33, 540, 17280, 540, 33, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 33, 17280, 540, 17280, 17280, 17280, 540, 17280, 33, 540, 540, 540, 17280, 33, 33, 17280, 33, 17280, 33, 33, 540, 33, 540, 17280, 33, 33, 540, 33, 33, 33, 33, 33, 17280, 540, 540, 17280, 540, 33, 17280, 17280, 17280, 540, 540, 33, 33, 33, 17280, 33, 540, 540, 33, 17280, 17280, 17280, 33, 33, 17280, 540, 17280, 17280, 33, 17280, 33, 540, 33, 33, 540, 540, 17280, 17280, 17280, 33, 17280, 540, 540, 33, 33, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 17280, 33, 540, 540, 17280, 540, 17280, 33, 33, 33, 540, 540, 540, 17280, 17280, 540, 17280, 33, 540, 540, 33, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 33, 17280, 33, 17280, 540, 33, 540, 33, 33, 540, 540, 540, 17280, 540, 33, 33]
Prompts retrieved: 963489 . Total input tokens: 214745861 . Total output tokens: 192549450
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 6.028756421990693,
    "estimated_duration": 3600.148956361271,
    "input_throughput": 5926.619775634329,
    "output_throughput": 5211.747688063479,
    "total_throughput": 11138.367463697808,
    "itl": 164.6409189146469,
    "ttft": 1833783.3343746527,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 924,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8890624258876496,
    "arrivals": 321377,
    "finished_requests": 85626,
    "scheduler_time": 104.2331903183329
}
#Debug simulation 
Total elapsed time: 6.028867649845779. Arrivals time: 0.24705948028713465 Scheduler time: 5.67335556820035 Scheduler overhead time: 0.03316361363977194 Adapter cache time: 0.025537014473229647 Engine time: 0.03426239127293229 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-32/adapters_160_slots_96_rate_1.6-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-32/adapters_160_slots_96_rate_1.6-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 540, 33, 33, 33, 17280, 33, 540, 17280, 540, 33, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 33, 17280, 540, 17280, 17280, 17280, 540, 17280, 33, 540, 540, 540, 17280, 33, 33, 17280, 33, 17280, 33, 33, 540, 33, 540, 17280, 33, 33, 540, 33, 33, 33, 33, 33, 17280, 540, 540, 17280, 540, 33, 17280, 17280, 17280, 540, 540, 33, 33, 33, 17280, 33, 540, 540, 33, 17280, 17280, 17280, 33, 33, 17280, 540, 17280, 17280, 33, 17280, 33, 540, 33, 33, 540, 540, 17280, 17280, 17280, 33, 17280, 540, 540, 33, 33, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 17280, 33, 540, 540, 17280, 540, 17280, 33, 33, 33, 540, 540, 540, 17280, 17280, 540, 17280, 33, 540, 540, 33, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 33, 17280, 33, 17280, 540, 33, 540, 33, 33, 540, 540, 540, 17280, 540, 33, 33]
Prompts retrieved: 963489 . Total input tokens: 214745861 . Total output tokens: 192549450
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 6.000669119879603,
    "estimated_duration": 3600.0362571825117,
    "input_throughput": 5918.188728653091,
    "output_throughput": 5205.439518174816,
    "total_throughput": 11123.628246827906,
    "itl": 162.5250039340149,
    "ttft": 1835167.2550994183,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 921,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.042275215853006,
    "arrivals": 321377,
    "finished_requests": 85502,
    "scheduler_time": 104.49939556874195
}
#Debug simulation 
Total elapsed time: 6.000779442023486. Arrivals time: 0.24528191657736897 Scheduler time: 5.645711641293019 Scheduler overhead time: 0.03364919265732169 Adapter cache time: 0.02584098046645522 Engine time: 0.03460833663120866 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-16/adapters_160_slots_96_rate_1.6-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-16/adapters_160_slots_96_rate_1.6-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 540, 33, 33, 33, 17280, 33, 540, 17280, 540, 33, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 33, 17280, 540, 17280, 17280, 17280, 540, 17280, 33, 540, 540, 540, 17280, 33, 33, 17280, 33, 17280, 33, 33, 540, 33, 540, 17280, 33, 33, 540, 33, 33, 33, 33, 33, 17280, 540, 540, 17280, 540, 33, 17280, 17280, 17280, 540, 540, 33, 33, 33, 17280, 33, 540, 540, 33, 17280, 17280, 17280, 33, 33, 17280, 540, 17280, 17280, 33, 17280, 33, 540, 33, 33, 540, 540, 17280, 17280, 17280, 33, 17280, 540, 540, 33, 33, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 17280, 33, 540, 540, 17280, 540, 17280, 33, 33, 33, 540, 540, 540, 17280, 17280, 540, 17280, 33, 540, 540, 33, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 33, 17280, 33, 17280, 540, 33, 540, 33, 33, 540, 540, 540, 17280, 540, 33, 33]
Prompts retrieved: 963489 . Total input tokens: 214745861 . Total output tokens: 192549450
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 6.06796465581283,
    "estimated_duration": 3600.1384770002305,
    "input_throughput": 5926.817575578117,
    "output_throughput": 5212.129511094581,
    "total_throughput": 11138.947086672697,
    "itl": 164.63464277284803,
    "ttft": 1833760.132766299,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 923,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.759816422194647,
    "arrivals": 321377,
    "finished_requests": 85629,
    "scheduler_time": 104.2372260469156
}
#Debug simulation 
Total elapsed time: 6.06805937923491. Arrivals time: 0.27385715395212173 Scheduler time: 5.685405221302062 Scheduler overhead time: 0.03343368973582983 Adapter cache time: 0.02559726918116212 Engine time: 0.034202033188194036 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-32/adapters_160_slots_96_rate_1.6-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-32/adapters_160_slots_96_rate_1.6-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 540, 33, 33, 33, 17280, 33, 540, 17280, 540, 33, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 33, 17280, 540, 17280, 17280, 17280, 540, 17280, 33, 540, 540, 540, 17280, 33, 33, 17280, 33, 17280, 33, 33, 540, 33, 540, 17280, 33, 33, 540, 33, 33, 33, 33, 33, 17280, 540, 540, 17280, 540, 33, 17280, 17280, 17280, 540, 540, 33, 33, 33, 17280, 33, 540, 540, 33, 17280, 17280, 17280, 33, 33, 17280, 540, 17280, 17280, 33, 17280, 33, 540, 33, 33, 540, 540, 17280, 17280, 17280, 33, 17280, 540, 540, 33, 33, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 17280, 33, 540, 540, 17280, 540, 17280, 33, 33, 33, 540, 540, 540, 17280, 17280, 540, 17280, 33, 540, 540, 33, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 33, 17280, 33, 17280, 540, 33, 540, 33, 33, 540, 540, 540, 17280, 540, 33, 33]
Prompts retrieved: 963489 . Total input tokens: 214745861 . Total output tokens: 192549450
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.062984105665237,
    "estimated_duration": 3600.0307942739378,
    "input_throughput": 5918.197709277368,
    "output_throughput": 5205.447417229518,
    "total_throughput": 11123.645126506886,
    "itl": 162.54127268860776,
    "ttft": 1835151.0151794283,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 921,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0804186270013765,
    "arrivals": 321377,
    "finished_requests": 85502,
    "scheduler_time": 104.49613641011629
}
#Debug simulation 
Total elapsed time: 6.063076763879508. Arrivals time: 0.2488046265207231 Scheduler time: 5.70411786949262 Scheduler overhead time: 0.03371829492971301 Adapter cache time: 0.026156458538025618 Engine time: 0.03455109894275665 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-8/adapters_160_slots_96_rate_1.6-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-8/adapters_160_slots_96_rate_1.6-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 270, 135, 135, 135, 17280, 135, 270, 17280, 270, 135, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 135, 17280, 270, 17280, 17280, 17280, 270, 17280, 135, 270, 270, 270, 17280, 135, 135, 17280, 135, 17280, 135, 135, 270, 135, 270, 17280, 135, 135, 270, 135, 135, 135, 135, 135, 17280, 270, 270, 17280, 270, 135, 17280, 17280, 17280, 270, 270, 135, 135, 135, 17280, 135, 270, 270, 135, 17280, 17280, 17280, 135, 135, 17280, 270, 17280, 17280, 135, 17280, 135, 270, 135, 135, 270, 270, 17280, 17280, 17280, 135, 17280, 270, 270, 135, 135, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 17280, 135, 270, 270, 17280, 270, 17280, 135, 135, 135, 270, 270, 270, 17280, 17280, 270, 17280, 135, 270, 270, 135, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 135, 17280, 135, 17280, 270, 135, 270, 135, 135, 270, 270, 270, 17280, 270, 135, 135]
Prompts retrieved: 954585 . Total input tokens: 212750706 . Total output tokens: 190774017
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 6.111153080593795,
    "estimated_duration": 3600.1271753297333,
    "input_throughput": 6019.307081288103,
    "output_throughput": 5314.165602565899,
    "total_throughput": 11333.472683854003,
    "itl": 161.9634416397073,
    "ttft": 1816518.7284290039,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1165,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.565468221681746,
    "arrivals": 318402,
    "finished_requests": 87144,
    "scheduler_time": 106.10000193541707
}
#Debug simulation 
Total elapsed time: 6.111247748602182. Arrivals time: 0.2640618998557329 Scheduler time: 5.7385664992034435 Scheduler overhead time: 0.03375014057382941 Adapter cache time: 0.024699326138943434 Engine time: 0.03447385551407933 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-16/adapters_160_slots_96_rate_1.6-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-16/adapters_160_slots_96_rate_1.6-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 270, 135, 135, 135, 17280, 135, 270, 17280, 270, 135, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 135, 17280, 270, 17280, 17280, 17280, 270, 17280, 135, 270, 270, 270, 17280, 135, 135, 17280, 135, 17280, 135, 135, 270, 135, 270, 17280, 135, 135, 270, 135, 135, 135, 135, 135, 17280, 270, 270, 17280, 270, 135, 17280, 17280, 17280, 270, 270, 135, 135, 135, 17280, 135, 270, 270, 135, 17280, 17280, 17280, 135, 135, 17280, 270, 17280, 17280, 135, 17280, 135, 270, 135, 135, 270, 270, 17280, 17280, 17280, 135, 17280, 270, 270, 135, 135, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 17280, 135, 270, 270, 17280, 270, 17280, 135, 135, 135, 270, 270, 270, 17280, 17280, 270, 17280, 135, 270, 270, 135, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 135, 17280, 135, 17280, 270, 135, 270, 135, 135, 270, 270, 270, 17280, 270, 135, 135]
Prompts retrieved: 954585 . Total input tokens: 212750706 . Total output tokens: 190774017
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.114218661095947,
    "estimated_duration": 3600.0295317823798,
    "input_throughput": 6019.202845058744,
    "output_throughput": 5314.2122394001735,
    "total_throughput": 11333.415084458918,
    "itl": 161.97301544916283,
    "ttft": 1816540.9278468662,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1165,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.799252774715429,
    "arrivals": 318402,
    "finished_requests": 87140,
    "scheduler_time": 106.09070886645353
}
#Debug simulation 
Total elapsed time: 6.114313752856106. Arrivals time: 0.25149729335680604 Scheduler time: 5.753262764308602 Scheduler overhead time: 0.03385906061157584 Adapter cache time: 0.024981242138892412 Engine time: 0.03491232171654701 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-32/adapters_160_slots_96_rate_1.6-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-32/adapters_160_slots_96_rate_1.6-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 270, 135, 135, 135, 17280, 135, 270, 17280, 270, 135, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 135, 17280, 270, 17280, 17280, 17280, 270, 17280, 135, 270, 270, 270, 17280, 135, 135, 17280, 135, 17280, 135, 135, 270, 135, 270, 17280, 135, 135, 270, 135, 135, 135, 135, 135, 17280, 270, 270, 17280, 270, 135, 17280, 17280, 17280, 270, 270, 135, 135, 135, 17280, 135, 270, 270, 135, 17280, 17280, 17280, 135, 135, 17280, 270, 17280, 17280, 135, 17280, 135, 270, 135, 135, 270, 270, 17280, 17280, 17280, 135, 17280, 270, 270, 135, 135, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 17280, 135, 270, 270, 17280, 270, 17280, 135, 135, 135, 270, 270, 270, 17280, 17280, 270, 17280, 135, 270, 270, 135, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 135, 17280, 135, 17280, 270, 135, 270, 135, 135, 270, 270, 270, 17280, 270, 135, 135]
Prompts retrieved: 954585 . Total input tokens: 212750706 . Total output tokens: 190774017
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.164903573226184,
    "estimated_duration": 3600.1393236895588,
    "input_throughput": 6012.40870251012,
    "output_throughput": 5306.762400634092,
    "total_throughput": 11319.171103144212,
    "itl": 159.9732206123657,
    "ttft": 1817818.158265509,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1164,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.803011005744282,
    "arrivals": 318402,
    "finished_requests": 87036,
    "scheduler_time": 106.34767871845683
}
#Debug simulation 
Total elapsed time: 6.164990690071136. Arrivals time: 0.25215944880619645 Scheduler time: 5.8020059913396835 Scheduler overhead time: 0.034388762433081865 Adapter cache time: 0.025155349634587765 Engine time: 0.035243016202002764 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-16/adapters_160_slots_96_rate_1.6-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-16/adapters_160_slots_96_rate_1.6-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 270, 135, 135, 135, 17280, 135, 270, 17280, 270, 135, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 135, 17280, 270, 17280, 17280, 17280, 270, 17280, 135, 270, 270, 270, 17280, 135, 135, 17280, 135, 17280, 135, 135, 270, 135, 270, 17280, 135, 135, 270, 135, 135, 135, 135, 135, 17280, 270, 270, 17280, 270, 135, 17280, 17280, 17280, 270, 270, 135, 135, 135, 17280, 135, 270, 270, 135, 17280, 17280, 17280, 135, 135, 17280, 270, 17280, 17280, 135, 17280, 135, 270, 135, 135, 270, 270, 17280, 17280, 17280, 135, 17280, 270, 270, 135, 135, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 17280, 135, 270, 270, 17280, 270, 17280, 135, 135, 135, 270, 270, 270, 17280, 17280, 270, 17280, 135, 270, 270, 135, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 135, 17280, 135, 17280, 270, 135, 270, 135, 135, 270, 270, 270, 17280, 270, 135, 135]
Prompts retrieved: 954585 . Total input tokens: 212750706 . Total output tokens: 190774017
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 6.119775003287941,
    "estimated_duration": 3600.0151222290338,
    "input_throughput": 6019.283604170755,
    "output_throughput": 5314.310732159986,
    "total_throughput": 11333.594336330741,
    "itl": 161.9661753892943,
    "ttft": 1816557.6953878235,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1165,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.6464381256186935,
    "arrivals": 318402,
    "finished_requests": 87141,
    "scheduler_time": 106.0950236242389
}
#Debug simulation 
Total elapsed time: 6.119868343230337. Arrivals time: 0.2652442934922874 Scheduler time: 5.745568489190191 Scheduler overhead time: 0.03375175874680281 Adapter cache time: 0.02504144050180912 Engine time: 0.03450694493949413 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-32/adapters_160_slots_96_rate_1.6-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-32/adapters_160_slots_96_rate_1.6-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 270, 135, 135, 135, 17280, 135, 270, 17280, 270, 135, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 135, 17280, 270, 17280, 17280, 17280, 270, 17280, 135, 270, 270, 270, 17280, 135, 135, 17280, 135, 17280, 135, 135, 270, 135, 270, 17280, 135, 135, 270, 135, 135, 135, 135, 135, 17280, 270, 270, 17280, 270, 135, 17280, 17280, 17280, 270, 270, 135, 135, 135, 17280, 135, 270, 270, 135, 17280, 17280, 17280, 135, 135, 17280, 270, 17280, 17280, 135, 17280, 135, 270, 135, 135, 270, 270, 17280, 17280, 17280, 135, 17280, 270, 270, 135, 135, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 17280, 135, 270, 270, 17280, 270, 17280, 135, 135, 135, 270, 270, 270, 17280, 17280, 270, 17280, 135, 270, 270, 135, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 135, 17280, 135, 17280, 270, 135, 270, 135, 135, 270, 270, 270, 17280, 270, 135, 135]
Prompts retrieved: 954585 . Total input tokens: 212750706 . Total output tokens: 190774017
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 6.151422468945384,
    "estimated_duration": 3600.0094467356994,
    "input_throughput": 6012.462000516827,
    "output_throughput": 5306.841074354159,
    "total_throughput": 11319.303074870986,
    "itl": 159.97537613315916,
    "ttft": 1817809.9990260215,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1164,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.849665660504251,
    "arrivals": 318402,
    "finished_requests": 87034,
    "scheduler_time": 106.34246063220675
}
#Debug simulation 
Total elapsed time: 6.151530874893069. Arrivals time: 0.251635835506022 Scheduler time: 5.7893787156790495 Scheduler overhead time: 0.03409908199682832 Adapter cache time: 0.025510100182145834 Engine time: 0.034960166085511446 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-16/adapters_160_slots_96_rate_1.6-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-16/adapters_160_slots_96_rate_1.6-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 270, 135, 135, 135, 17280, 135, 270, 17280, 270, 135, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 135, 17280, 270, 17280, 17280, 17280, 270, 17280, 135, 270, 270, 270, 17280, 135, 135, 17280, 135, 17280, 135, 135, 270, 135, 270, 17280, 135, 135, 270, 135, 135, 135, 135, 135, 17280, 270, 270, 17280, 270, 135, 17280, 17280, 17280, 270, 270, 135, 135, 135, 17280, 135, 270, 270, 135, 17280, 17280, 17280, 135, 135, 17280, 270, 17280, 17280, 135, 17280, 135, 270, 135, 135, 270, 270, 17280, 17280, 17280, 135, 17280, 270, 270, 135, 135, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 17280, 135, 270, 270, 17280, 270, 17280, 135, 135, 135, 270, 270, 270, 17280, 17280, 270, 17280, 135, 270, 270, 135, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 135, 17280, 135, 17280, 270, 135, 270, 135, 135, 270, 270, 270, 17280, 270, 135, 135]
Prompts retrieved: 954585 . Total input tokens: 212750706 . Total output tokens: 190774017
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 6.135186217259616,
    "estimated_duration": 3600.151041814164,
    "input_throughput": 6019.387450222045,
    "output_throughput": 5314.227869272707,
    "total_throughput": 11333.615319494753,
    "itl": 161.95849728964467,
    "ttft": 1816558.519865524,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1165,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.483408593560948,
    "arrivals": 318402,
    "finished_requests": 87145,
    "scheduler_time": 106.10355098766412
}
#Debug simulation 
Total elapsed time: 6.135278347879648. Arrivals time: 0.25621827971190214 Scheduler time: 5.7700031930580735 Scheduler overhead time: 0.033735270611941814 Adapter cache time: 0.02490293188020587 Engine time: 0.03461848432198167 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-32/adapters_160_slots_96_rate_1.6-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-32/adapters_160_slots_96_rate_1.6-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 270, 135, 135, 135, 17280, 135, 270, 17280, 270, 135, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 135, 17280, 270, 17280, 17280, 17280, 270, 17280, 135, 270, 270, 270, 17280, 135, 135, 17280, 135, 17280, 135, 135, 270, 135, 270, 17280, 135, 135, 270, 135, 135, 135, 135, 135, 17280, 270, 270, 17280, 270, 135, 17280, 17280, 17280, 270, 270, 135, 135, 135, 17280, 135, 270, 270, 135, 17280, 17280, 17280, 135, 135, 17280, 270, 17280, 17280, 135, 17280, 135, 270, 135, 135, 270, 270, 17280, 17280, 17280, 135, 17280, 270, 270, 135, 135, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 17280, 135, 270, 270, 17280, 270, 17280, 135, 135, 135, 270, 270, 270, 17280, 17280, 270, 17280, 135, 270, 270, 135, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 135, 17280, 135, 17280, 270, 135, 270, 135, 135, 270, 270, 270, 17280, 270, 135, 135]
Prompts retrieved: 954585 . Total input tokens: 212750706 . Total output tokens: 190774017
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.099819376133382,
    "estimated_duration": 3600.04574353891,
    "input_throughput": 6012.401380967635,
    "output_throughput": 5306.787569098985,
    "total_throughput": 11319.18895006662,
    "itl": 159.984280803261,
    "ttft": 1817820.2649497106,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1165,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.9035994489864096,
    "arrivals": 318402,
    "finished_requests": 87034,
    "scheduler_time": 106.34095050729142
}
#Debug simulation 
Total elapsed time: 6.09993787901476. Arrivals time: 0.2663972550071776 Scheduler time: 5.724045838229358 Scheduler overhead time: 0.03410295769572258 Adapter cache time: 0.024711517617106438 Engine time: 0.03480383846908808 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-8/adapters_160_slots_96_rate_1.6-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-8/adapters_160_slots_96_rate_1.6-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 270, 66, 66, 66, 17280, 66, 270, 17280, 270, 66, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 66, 17280, 270, 17280, 17280, 17280, 270, 17280, 66, 270, 270, 270, 17280, 66, 66, 17280, 66, 17280, 66, 66, 270, 66, 270, 17280, 66, 66, 270, 66, 66, 66, 66, 66, 17280, 270, 270, 17280, 270, 66, 17280, 17280, 17280, 270, 270, 66, 66, 66, 17280, 66, 270, 270, 66, 17280, 17280, 17280, 66, 66, 17280, 270, 17280, 17280, 66, 17280, 66, 270, 66, 66, 270, 270, 17280, 17280, 17280, 66, 17280, 270, 270, 66, 66, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 17280, 66, 270, 270, 17280, 270, 17280, 66, 66, 66, 270, 270, 270, 17280, 17280, 270, 17280, 66, 270, 270, 66, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 66, 17280, 66, 17280, 270, 66, 270, 66, 66, 270, 270, 270, 17280, 270, 66, 66]
Prompts retrieved: 950928 . Total input tokens: 211961236 . Total output tokens: 190027670
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 6.495449895970523,
    "estimated_duration": 3600.147007177329,
    "input_throughput": 6126.688425785597,
    "output_throughput": 5405.950357360329,
    "total_throughput": 11532.638783145925,
    "itl": 159.05912250836533,
    "ttft": 1792789.4628481884,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 903,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7636204327713365,
    "arrivals": 317160,
    "finished_requests": 89013,
    "scheduler_time": 107.93122411558156
}
#Debug simulation 
Total elapsed time: 6.495554124005139. Arrivals time: 0.26102745858952403 Scheduler time: 6.126526103820652 Scheduler overhead time: 0.034522578585892916 Adapter cache time: 0.022310364991426468 Engine time: 0.035101755522191525 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-16/adapters_160_slots_96_rate_1.6-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-16/adapters_160_slots_96_rate_1.6-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 270, 66, 66, 66, 17280, 66, 270, 17280, 270, 66, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 66, 17280, 270, 17280, 17280, 17280, 270, 17280, 66, 270, 270, 270, 17280, 66, 66, 17280, 66, 17280, 66, 66, 270, 66, 270, 17280, 66, 66, 270, 66, 66, 66, 66, 66, 17280, 270, 270, 17280, 270, 66, 17280, 17280, 17280, 270, 270, 66, 66, 66, 17280, 66, 270, 270, 66, 17280, 17280, 17280, 66, 66, 17280, 270, 17280, 17280, 66, 17280, 66, 270, 66, 66, 270, 270, 17280, 17280, 17280, 66, 17280, 270, 270, 66, 66, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 17280, 66, 270, 270, 17280, 270, 17280, 66, 66, 66, 270, 270, 270, 17280, 17280, 270, 17280, 66, 270, 270, 66, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 66, 17280, 66, 17280, 270, 66, 270, 66, 66, 270, 270, 270, 17280, 270, 66, 66]
Prompts retrieved: 950928 . Total input tokens: 211961236 . Total output tokens: 190027670
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.2743545970879495,
    "estimated_duration": 3600.0495925574155,
    "input_throughput": 6126.339771984198,
    "output_throughput": 5405.862474848565,
    "total_throughput": 11532.202246832763,
    "itl": 159.0687886957279,
    "ttft": 1792807.412049797,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 903,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.947624179271521,
    "arrivals": 317160,
    "finished_requests": 89007,
    "scheduler_time": 107.92259638347646
}
#Debug simulation 
Total elapsed time: 6.2744689378887415. Arrivals time: 0.2831931943073869 Scheduler time: 5.883565894793719 Scheduler overhead time: 0.03436046093702316 Adapter cache time: 0.022096920758485794 Engine time: 0.03520438587293029 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-32/adapters_160_slots_96_rate_1.6-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-32/adapters_160_slots_96_rate_1.6-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 270, 66, 66, 66, 17280, 66, 270, 17280, 270, 66, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 66, 17280, 270, 17280, 17280, 17280, 270, 17280, 66, 270, 270, 270, 17280, 66, 66, 17280, 66, 17280, 66, 66, 270, 66, 270, 17280, 66, 66, 270, 66, 66, 66, 66, 66, 17280, 270, 270, 17280, 270, 66, 17280, 17280, 17280, 270, 270, 66, 66, 66, 17280, 66, 270, 270, 66, 17280, 17280, 17280, 66, 66, 17280, 270, 17280, 17280, 66, 17280, 66, 270, 66, 66, 270, 270, 17280, 17280, 17280, 66, 17280, 270, 270, 66, 66, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 17280, 66, 270, 270, 17280, 270, 17280, 66, 66, 66, 270, 270, 270, 17280, 17280, 270, 17280, 66, 270, 270, 66, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 66, 17280, 66, 17280, 270, 66, 270, 66, 66, 270, 270, 270, 17280, 270, 66, 66]
Prompts retrieved: 950928 . Total input tokens: 211961236 . Total output tokens: 190027670
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.209278122056276,
    "estimated_duration": 3600.138663778163,
    "input_throughput": 6118.238228325433,
    "output_throughput": 5399.01593112573,
    "total_throughput": 11517.254159451164,
    "itl": 157.35162987989656,
    "ttft": 1793948.104809989,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 900,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.942864450588798,
    "arrivals": 317160,
    "finished_requests": 88884,
    "scheduler_time": 108.15389019426323
}
#Debug simulation 
Total elapsed time: 6.209368166979402. Arrivals time: 0.28010811982676387 Scheduler time: 5.821011452469975 Scheduler overhead time: 0.034469794016331434 Adapter cache time: 0.022223697043955326 Engine time: 0.03542834287509322 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-16/adapters_160_slots_96_rate_1.6-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-16/adapters_160_slots_96_rate_1.6-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 270, 66, 66, 66, 17280, 66, 270, 17280, 270, 66, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 66, 17280, 270, 17280, 17280, 17280, 270, 17280, 66, 270, 270, 270, 17280, 66, 66, 17280, 66, 17280, 66, 66, 270, 66, 270, 17280, 66, 66, 270, 66, 66, 66, 66, 66, 17280, 270, 270, 17280, 270, 66, 17280, 17280, 17280, 270, 270, 66, 66, 66, 17280, 66, 270, 270, 66, 17280, 17280, 17280, 66, 66, 17280, 270, 17280, 17280, 66, 17280, 66, 270, 66, 66, 270, 270, 17280, 17280, 17280, 66, 17280, 270, 270, 66, 66, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 17280, 66, 270, 270, 17280, 270, 17280, 66, 66, 66, 270, 270, 270, 17280, 17280, 270, 17280, 66, 270, 270, 66, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 66, 17280, 66, 17280, 270, 66, 270, 66, 66, 270, 270, 270, 17280, 270, 66, 66]
Prompts retrieved: 950928 . Total input tokens: 211961236 . Total output tokens: 190027670
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 6.237376919016242,
    "estimated_duration": 3600.069704389856,
    "input_throughput": 6126.7480385461595,
    "output_throughput": 5406.051715128797,
    "total_throughput": 11532.799753674955,
    "itl": 159.06250066381313,
    "ttft": 1792757.7925466343,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 903,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8250455837393837,
    "arrivals": 317160,
    "finished_requests": 89012,
    "scheduler_time": 107.92710576022225
}
#Debug simulation 
Total elapsed time: 6.237467668019235. Arrivals time: 0.29423159966245294 Scheduler time: 5.835866361856461 Scheduler overhead time: 0.03423395939171314 Adapter cache time: 0.02208932675421238 Engine time: 0.03506428422406316 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-32/adapters_160_slots_96_rate_1.6-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-32/adapters_160_slots_96_rate_1.6-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 270, 66, 66, 66, 17280, 66, 270, 17280, 270, 66, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 66, 17280, 270, 17280, 17280, 17280, 270, 17280, 66, 270, 270, 270, 17280, 66, 66, 17280, 66, 17280, 66, 66, 270, 66, 270, 17280, 66, 66, 270, 66, 66, 66, 66, 66, 17280, 270, 270, 17280, 270, 66, 17280, 17280, 17280, 270, 270, 66, 66, 66, 17280, 66, 270, 270, 66, 17280, 17280, 17280, 66, 66, 17280, 270, 17280, 17280, 66, 17280, 66, 270, 66, 66, 270, 270, 17280, 17280, 17280, 66, 17280, 270, 270, 66, 66, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 17280, 66, 270, 270, 17280, 270, 17280, 66, 66, 66, 270, 270, 270, 17280, 17280, 270, 17280, 66, 270, 270, 66, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 66, 17280, 66, 17280, 270, 66, 270, 66, 66, 270, 270, 270, 17280, 270, 66, 66]
Prompts retrieved: 950928 . Total input tokens: 211961236 . Total output tokens: 190027670
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 6.265681469812989,
    "estimated_duration": 3600.000534440243,
    "input_throughput": 6118.14464728258,
    "output_throughput": 5398.97836515797,
    "total_throughput": 11517.12301244055,
    "itl": 157.3533123861281,
    "ttft": 1793957.5116514703,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 900,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9800875713676236,
    "arrivals": 317160,
    "finished_requests": 88881,
    "scheduler_time": 108.14864909651452
}
#Debug simulation 
Total elapsed time: 6.265770799014717. Arrivals time: 0.272163525223732 Scheduler time: 5.884741379413754 Scheduler overhead time: 0.03473237343132496 Adapter cache time: 0.02236057072877884 Engine time: 0.03559233248233795 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-16/adapters_160_slots_96_rate_1.6-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-16/adapters_160_slots_96_rate_1.6-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 270, 66, 66, 66, 17280, 66, 270, 17280, 270, 66, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 66, 17280, 270, 17280, 17280, 17280, 270, 17280, 66, 270, 270, 270, 17280, 66, 66, 17280, 66, 17280, 66, 66, 270, 66, 270, 17280, 66, 66, 270, 66, 66, 66, 66, 66, 17280, 270, 270, 17280, 270, 66, 17280, 17280, 17280, 270, 270, 66, 66, 66, 17280, 66, 270, 270, 66, 17280, 17280, 17280, 66, 66, 17280, 270, 17280, 17280, 66, 17280, 66, 270, 66, 66, 270, 270, 17280, 17280, 17280, 66, 17280, 270, 270, 66, 66, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 17280, 66, 270, 270, 17280, 270, 17280, 66, 66, 66, 270, 270, 270, 17280, 17280, 270, 17280, 66, 270, 270, 66, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 66, 17280, 66, 17280, 270, 66, 270, 66, 66, 270, 270, 270, 17280, 270, 66, 66]
Prompts retrieved: 950928 . Total input tokens: 211961236 . Total output tokens: 190027670
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 6.2573028658516705,
    "estimated_duration": 3600.0615296629057,
    "input_throughput": 6126.833893882175,
    "output_throughput": 5406.07871272199,
    "total_throughput": 11532.912606604164,
    "itl": 159.05626555910789,
    "ttft": 1792760.8162381256,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 903,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7000154162966057,
    "arrivals": 317160,
    "finished_requests": 89013,
    "scheduler_time": 107.92992638014738
}
#Debug simulation 
Total elapsed time: 6.257391034625471. Arrivals time: 0.2584244851022959 Scheduler time: 5.890956704039127 Scheduler overhead time: 0.03427853249013424 Adapter cache time: 0.022587298415601254 Engine time: 0.03521851310506463 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-32/adapters_160_slots_96_rate_1.6-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-32/adapters_160_slots_96_rate_1.6-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 270, 66, 66, 66, 17280, 66, 270, 17280, 270, 66, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 66, 17280, 270, 17280, 17280, 17280, 270, 17280, 66, 270, 270, 270, 17280, 66, 66, 17280, 66, 17280, 66, 66, 270, 66, 270, 17280, 66, 66, 270, 66, 66, 66, 66, 66, 17280, 270, 270, 17280, 270, 66, 17280, 17280, 17280, 270, 270, 66, 66, 66, 17280, 66, 270, 270, 66, 17280, 17280, 17280, 66, 66, 17280, 270, 17280, 17280, 66, 17280, 66, 270, 66, 66, 270, 270, 17280, 17280, 17280, 66, 17280, 270, 270, 66, 66, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 17280, 66, 270, 270, 17280, 270, 17280, 66, 66, 66, 270, 270, 270, 17280, 17280, 270, 17280, 66, 270, 270, 66, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 66, 17280, 66, 17280, 270, 66, 270, 66, 66, 270, 270, 270, 17280, 270, 66, 66]
Prompts retrieved: 950928 . Total input tokens: 211961236 . Total output tokens: 190027670
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.244769351556897,
    "estimated_duration": 3600.0181757083174,
    "input_throughput": 6118.114666370103,
    "output_throughput": 5398.951908395804,
    "total_throughput": 11517.066574765908,
    "itl": 157.36041794744793,
    "ttft": 1793966.5297631975,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 900,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0188197375834287,
    "arrivals": 317160,
    "finished_requests": 88881,
    "scheduler_time": 108.14730892590984
}
#Debug simulation 
Total elapsed time: 6.24486053083092. Arrivals time: 0.2508097467944026 Scheduler time: 5.885400734376162 Scheduler overhead time: 0.03471692372113466 Adapter cache time: 0.02239014534279704 Engine time: 0.03540654806420207 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-8/adapters_160_slots_96_rate_1.6-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-8/adapters_160_slots_96_rate_1.6-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 270, 33, 33, 33, 17280, 33, 270, 17280, 270, 33, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 33, 17280, 270, 17280, 17280, 17280, 270, 17280, 33, 270, 270, 270, 17280, 33, 33, 17280, 33, 17280, 33, 33, 270, 33, 270, 17280, 33, 33, 270, 33, 33, 33, 33, 33, 17280, 270, 270, 17280, 270, 33, 17280, 17280, 17280, 270, 270, 33, 33, 33, 17280, 33, 270, 270, 33, 17280, 17280, 17280, 33, 33, 17280, 270, 17280, 17280, 33, 17280, 33, 270, 33, 33, 270, 270, 17280, 17280, 17280, 33, 17280, 270, 270, 33, 33, 33, 33, 17280, 270, 17280, 270, 17280, 17280, 17280, 33, 270, 270, 17280, 270, 17280, 33, 33, 33, 270, 270, 270, 17280, 17280, 270, 17280, 33, 270, 270, 33, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 33, 17280, 33, 17280, 270, 33, 270, 33, 33, 270, 270, 270, 17280, 270, 33, 33]
Prompts retrieved: 949179 . Total input tokens: 211564065 . Total output tokens: 189683248
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 6.283789988141507,
    "estimated_duration": 3600.1436422367815,
    "input_throughput": 6174.320585216815,
    "output_throughput": 5476.930911498104,
    "total_throughput": 11651.251496714918,
    "itl": 157.45354884880234,
    "ttft": 1789948.4854455872,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 682,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0872526413621744,
    "arrivals": 316555,
    "finished_requests": 89953,
    "scheduler_time": 109.18799831932158
}
#Debug simulation 
Total elapsed time: 6.283875796943903. Arrivals time: 0.2446455443277955 Scheduler time: 5.932176782749593 Scheduler overhead time: 0.034640459809452295 Adapter cache time: 0.020439709071069956 Engine time: 0.03576906584203243 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-16/adapters_160_slots_96_rate_1.6-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-16/adapters_160_slots_96_rate_1.6-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 270, 33, 33, 33, 17280, 33, 270, 17280, 270, 33, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 33, 17280, 270, 17280, 17280, 17280, 270, 17280, 33, 270, 270, 270, 17280, 33, 33, 17280, 33, 17280, 33, 33, 270, 33, 270, 17280, 33, 33, 270, 33, 33, 33, 33, 33, 17280, 270, 270, 17280, 270, 33, 17280, 17280, 17280, 270, 270, 33, 33, 33, 17280, 33, 270, 270, 33, 17280, 17280, 17280, 33, 33, 17280, 270, 17280, 17280, 33, 17280, 33, 270, 33, 33, 270, 270, 17280, 17280, 17280, 33, 17280, 270, 270, 33, 33, 33, 33, 17280, 270, 17280, 270, 17280, 17280, 17280, 33, 270, 270, 17280, 270, 17280, 33, 33, 33, 270, 270, 270, 17280, 17280, 270, 17280, 33, 270, 270, 33, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 33, 17280, 33, 17280, 270, 33, 270, 33, 33, 270, 270, 270, 17280, 270, 33, 33]
Prompts retrieved: 949179 . Total input tokens: 211564065 . Total output tokens: 189683248
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.303891560062766,
    "estimated_duration": 3600.055654934381,
    "input_throughput": 6174.120661033264,
    "output_throughput": 5476.753942116314,
    "total_throughput": 11650.874603149578,
    "itl": 157.45974092957348,
    "ttft": 1789905.1633957005,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 682,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.225942361650528,
    "arrivals": 316555,
    "finished_requests": 89948,
    "scheduler_time": 109.18129871979286
}
#Debug simulation 
Total elapsed time: 6.3039743499830365. Arrivals time: 0.2717716502957046 Scheduler time: 5.925215173047036 Scheduler overhead time: 0.03460137406364083 Adapter cache time: 0.020618331152945757 Engine time: 0.03555260086432099 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-32/adapters_160_slots_96_rate_1.6-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-32/adapters_160_slots_96_rate_1.6-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 270, 33, 33, 33, 17280, 33, 270, 17280, 270, 33, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 33, 17280, 270, 17280, 17280, 17280, 270, 17280, 33, 270, 270, 270, 17280, 33, 33, 17280, 33, 17280, 33, 33, 270, 33, 270, 17280, 33, 33, 270, 33, 33, 33, 33, 33, 17280, 270, 270, 17280, 270, 33, 17280, 17280, 17280, 270, 270, 33, 33, 33, 17280, 33, 270, 270, 33, 17280, 17280, 17280, 33, 33, 17280, 270, 17280, 17280, 33, 17280, 33, 270, 33, 33, 270, 270, 17280, 17280, 17280, 33, 17280, 270, 270, 33, 33, 33, 33, 17280, 270, 17280, 270, 17280, 17280, 17280, 33, 270, 270, 17280, 270, 17280, 33, 33, 33, 270, 270, 270, 17280, 17280, 270, 17280, 33, 270, 270, 33, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 33, 17280, 33, 17280, 270, 33, 270, 33, 33, 270, 270, 270, 17280, 270, 33, 33]
Prompts retrieved: 949179 . Total input tokens: 211564065 . Total output tokens: 189683248
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.325493305921555,
    "estimated_duration": 3600.093351410912,
    "input_throughput": 6164.022105510989,
    "output_throughput": 5470.477034236248,
    "total_throughput": 11634.499139747237,
    "itl": 155.76647522727052,
    "ttft": 1791326.650868851,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 684,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2365634925477242,
    "arrivals": 316555,
    "finished_requests": 89834,
    "scheduler_time": 109.38086135906897
}
#Debug simulation 
Total elapsed time: 6.325581685174257. Arrivals time: 0.28316602017730474 Scheduler time: 5.934482297394425 Scheduler overhead time: 0.03506381483748555 Adapter cache time: 0.02055245777592063 Engine time: 0.03597358101978898 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-16/adapters_160_slots_96_rate_1.6-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-16/adapters_160_slots_96_rate_1.6-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 270, 33, 33, 33, 17280, 33, 270, 17280, 270, 33, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 33, 17280, 270, 17280, 17280, 17280, 270, 17280, 33, 270, 270, 270, 17280, 33, 33, 17280, 33, 17280, 33, 33, 270, 33, 270, 17280, 33, 33, 270, 33, 33, 33, 33, 33, 17280, 270, 270, 17280, 270, 33, 17280, 17280, 17280, 270, 270, 33, 33, 33, 17280, 33, 270, 270, 33, 17280, 17280, 17280, 33, 33, 17280, 270, 17280, 17280, 33, 17280, 33, 270, 33, 33, 270, 270, 17280, 17280, 17280, 33, 17280, 270, 270, 33, 33, 33, 33, 17280, 270, 17280, 270, 17280, 17280, 17280, 33, 270, 270, 17280, 270, 17280, 33, 33, 33, 270, 270, 270, 17280, 17280, 270, 17280, 33, 270, 270, 33, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 33, 17280, 33, 17280, 270, 33, 270, 33, 33, 270, 270, 270, 17280, 270, 33, 33]
Prompts retrieved: 949179 . Total input tokens: 211564065 . Total output tokens: 189683248
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 6.347628511954099,
    "estimated_duration": 3600.0401707066735,
    "input_throughput": 6174.253326633524,
    "output_throughput": 5476.871386168349,
    "total_throughput": 11651.124712801873,
    "itl": 157.45521090534905,
    "ttft": 1789885.585782915,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 681,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1302011740696463,
    "arrivals": 316555,
    "finished_requests": 89950,
    "scheduler_time": 109.18377625838693
}
#Debug simulation 
Total elapsed time: 6.34772779000923. Arrivals time: 0.2647739020176232 Scheduler time: 5.975659402552992 Scheduler overhead time: 0.034806717187166214 Adapter cache time: 0.020778900012373924 Engine time: 0.035456374287605286 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-32/adapters_160_slots_96_rate_1.6-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-32/adapters_160_slots_96_rate_1.6-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 270, 33, 33, 33, 17280, 33, 270, 17280, 270, 33, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 33, 17280, 270, 17280, 17280, 17280, 270, 17280, 33, 270, 270, 270, 17280, 33, 33, 17280, 33, 17280, 33, 33, 270, 33, 270, 17280, 33, 33, 270, 33, 33, 33, 33, 33, 17280, 270, 270, 17280, 270, 33, 17280, 17280, 17280, 270, 270, 33, 33, 33, 17280, 33, 270, 270, 33, 17280, 17280, 17280, 33, 33, 17280, 270, 17280, 17280, 33, 17280, 33, 270, 33, 33, 270, 270, 17280, 17280, 17280, 33, 17280, 270, 270, 33, 33, 33, 33, 17280, 270, 17280, 270, 17280, 17280, 17280, 33, 270, 270, 17280, 270, 17280, 33, 33, 33, 270, 270, 270, 17280, 17280, 270, 17280, 33, 270, 270, 33, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 33, 17280, 33, 17280, 270, 33, 270, 33, 33, 270, 270, 270, 17280, 270, 33, 33]
Prompts retrieved: 949179 . Total input tokens: 211564065 . Total output tokens: 189683248
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 6.520055212080479,
    "estimated_duration": 3600.1403906165306,
    "input_throughput": 6163.785183999405,
    "output_throughput": 5470.440555966015,
    "total_throughput": 11634.225739965419,
    "itl": 155.76684471024734,
    "ttft": 1791337.3482684838,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 684,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2651096020638963,
    "arrivals": 316555,
    "finished_requests": 89835,
    "scheduler_time": 109.38113852164103
}
#Debug simulation 
Total elapsed time: 6.520147774834186. Arrivals time: 0.2663615201599896 Scheduler time: 6.1454742276109755 Scheduler overhead time: 0.03497355245053768 Adapter cache time: 0.020671991631388664 Engine time: 0.036448771599680185 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-16/adapters_160_slots_96_rate_1.6-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-16/adapters_160_slots_96_rate_1.6-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 270, 33, 33, 33, 17280, 33, 270, 17280, 270, 33, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 33, 17280, 270, 17280, 17280, 17280, 270, 17280, 33, 270, 270, 270, 17280, 33, 33, 17280, 33, 17280, 33, 33, 270, 33, 270, 17280, 33, 33, 270, 33, 33, 33, 33, 33, 17280, 270, 270, 17280, 270, 33, 17280, 17280, 17280, 270, 270, 33, 33, 33, 17280, 33, 270, 270, 33, 17280, 17280, 17280, 33, 33, 17280, 270, 17280, 17280, 33, 17280, 33, 270, 33, 33, 270, 270, 17280, 17280, 17280, 33, 17280, 270, 270, 33, 33, 33, 33, 17280, 270, 17280, 270, 17280, 17280, 17280, 33, 270, 270, 17280, 270, 17280, 33, 33, 33, 270, 270, 270, 17280, 17280, 270, 17280, 33, 270, 270, 33, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 33, 17280, 33, 17280, 270, 33, 270, 33, 33, 270, 270, 270, 17280, 270, 33, 33]
Prompts retrieved: 949179 . Total input tokens: 211564065 . Total output tokens: 189683248
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 6.333712498191744,
    "estimated_duration": 3600.0993901070715,
    "input_throughput": 6174.396479464668,
    "output_throughput": 5476.998233488651,
    "total_throughput": 11651.394712953319,
    "itl": 157.4524990442996,
    "ttft": 1789932.0210771577,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 682,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0392143011232484,
    "arrivals": 316555,
    "finished_requests": 89953,
    "scheduler_time": 109.1874919158029
}
#Debug simulation 
Total elapsed time: 6.33382273837924. Arrivals time: 0.28536259895190597 Scheduler time: 5.94145040679723 Scheduler overhead time: 0.03456610441207886 Adapter cache time: 0.020617370028048754 Engine time: 0.035642750561237335 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-32/adapters_160_slots_96_rate_1.6-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-32/adapters_160_slots_96_rate_1.6-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 270, 33, 33, 33, 17280, 33, 270, 17280, 270, 33, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 33, 17280, 270, 17280, 17280, 17280, 270, 17280, 33, 270, 270, 270, 17280, 33, 33, 17280, 33, 17280, 33, 33, 270, 33, 270, 17280, 33, 33, 270, 33, 33, 33, 33, 33, 17280, 270, 270, 17280, 270, 33, 17280, 17280, 17280, 270, 270, 33, 33, 33, 17280, 33, 270, 270, 33, 17280, 17280, 17280, 33, 33, 17280, 270, 17280, 17280, 33, 17280, 33, 270, 33, 33, 270, 270, 17280, 17280, 17280, 33, 17280, 270, 270, 33, 33, 33, 33, 17280, 270, 17280, 270, 17280, 17280, 17280, 33, 270, 270, 17280, 270, 17280, 33, 33, 33, 270, 270, 270, 17280, 17280, 270, 17280, 33, 270, 270, 33, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 33, 17280, 33, 17280, 270, 33, 270, 33, 33, 270, 270, 270, 17280, 270, 33, 33]
Prompts retrieved: 949179 . Total input tokens: 211564065 . Total output tokens: 189683248
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.332543599884957,
    "estimated_duration": 3600.1608439616407,
    "input_throughput": 6163.906548014343,
    "output_throughput": 5470.374478693663,
    "total_throughput": 11634.281026708006,
    "itl": 155.76063172888735,
    "ttft": 1791360.3575719146,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 684,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.294284480512147,
    "arrivals": 316555,
    "finished_requests": 89834,
    "scheduler_time": 109.38245496818769
}
#Debug simulation 
Total elapsed time: 6.332633377052844. Arrivals time: 0.2850345983169973 Scheduler time: 5.939576166216284 Scheduler overhead time: 0.03500791359692812 Adapter cache time: 0.020608645398169756 Engine time: 0.03602948319166899 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-8/adapters_160_slots_96_rate_1.6-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-8/adapters_160_slots_96_rate_1.6-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 135, 66, 66, 66, 17280, 66, 135, 17280, 135, 66, 135, 135, 135, 135, 17280, 17280, 17280, 135, 135, 135, 17280, 17280, 66, 17280, 135, 17280, 17280, 17280, 135, 17280, 66, 135, 135, 135, 17280, 66, 66, 17280, 66, 17280, 66, 66, 135, 66, 135, 17280, 66, 66, 135, 66, 66, 66, 66, 66, 17280, 135, 135, 17280, 135, 66, 17280, 17280, 17280, 135, 135, 66, 66, 66, 17280, 66, 135, 135, 66, 17280, 17280, 17280, 66, 66, 17280, 135, 17280, 17280, 66, 17280, 66, 135, 66, 66, 135, 135, 17280, 17280, 17280, 66, 17280, 135, 135, 66, 66, 66, 66, 17280, 135, 17280, 135, 17280, 17280, 17280, 66, 135, 135, 17280, 135, 17280, 66, 66, 66, 135, 135, 135, 17280, 17280, 135, 17280, 66, 135, 135, 66, 17280, 17280, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 135, 17280, 66, 17280, 66, 17280, 135, 66, 135, 66, 66, 135, 135, 135, 17280, 135, 66, 66]
Prompts retrieved: 943773 . Total input tokens: 210368094 . Total output tokens: 188601248
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 6.511481372173876,
    "estimated_duration": 3600.0937399941326,
    "input_throughput": 6377.597267797093,
    "output_throughput": 5621.1000216991515,
    "total_throughput": 11998.697289496246,
    "itl": 153.08265982036178,
    "ttft": 1759893.235678968,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 660,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0199219109956514,
    "arrivals": 314729,
    "finished_requests": 92532,
    "scheduler_time": 112.11272331586098
}
#Debug simulation 
Total elapsed time: 6.511593474075198. Arrivals time: 0.26452740328386426 Scheduler time: 6.14080930640921 Scheduler overhead time: 0.035547290463000536 Adapter cache time: 0.017574374098330736 Engine time: 0.03649478266015649 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-16/adapters_160_slots_96_rate_1.6-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-16/adapters_160_slots_96_rate_1.6-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 135, 66, 66, 66, 17280, 66, 135, 17280, 135, 66, 135, 135, 135, 135, 17280, 17280, 17280, 135, 135, 135, 17280, 17280, 66, 17280, 135, 17280, 17280, 17280, 135, 17280, 66, 135, 135, 135, 17280, 66, 66, 17280, 66, 17280, 66, 66, 135, 66, 135, 17280, 66, 66, 135, 66, 66, 66, 66, 66, 17280, 135, 135, 17280, 135, 66, 17280, 17280, 17280, 135, 135, 66, 66, 66, 17280, 66, 135, 135, 66, 17280, 17280, 17280, 66, 66, 17280, 135, 17280, 17280, 66, 17280, 66, 135, 66, 66, 135, 135, 17280, 17280, 17280, 66, 17280, 135, 135, 66, 66, 66, 66, 17280, 135, 17280, 135, 17280, 17280, 17280, 66, 135, 135, 17280, 135, 17280, 66, 66, 66, 135, 135, 135, 17280, 17280, 135, 17280, 66, 135, 135, 66, 17280, 17280, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 135, 17280, 66, 17280, 66, 17280, 135, 66, 135, 66, 66, 135, 135, 135, 17280, 135, 66, 66]
Prompts retrieved: 943773 . Total input tokens: 210368094 . Total output tokens: 188601248
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.458468022290617,
    "estimated_duration": 3600.1433086593543,
    "input_throughput": 6377.454459875351,
    "output_throughput": 5621.004017069469,
    "total_throughput": 11998.45847694482,
    "itl": 153.088447529909,
    "ttft": 1759859.0737863556,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 660,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.15811827857048,
    "arrivals": 314729,
    "finished_requests": 92531,
    "scheduler_time": 112.11083930817813
}
#Debug simulation 
Total elapsed time: 6.4585582301951945. Arrivals time: 0.2658749483525753 Scheduler time: 6.0863461988046765 Scheduler overhead time: 0.0356283076107502 Adapter cache time: 0.017732069361954927 Engine time: 0.03637017775326967 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-32/adapters_160_slots_96_rate_1.6-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-32/adapters_160_slots_96_rate_1.6-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 135, 66, 66, 66, 17280, 66, 135, 17280, 135, 66, 135, 135, 135, 135, 17280, 17280, 17280, 135, 135, 135, 17280, 17280, 66, 17280, 135, 17280, 17280, 17280, 135, 17280, 66, 135, 135, 135, 17280, 66, 66, 17280, 66, 17280, 66, 66, 135, 66, 135, 17280, 66, 66, 135, 66, 66, 66, 66, 66, 17280, 135, 135, 17280, 135, 66, 17280, 17280, 17280, 135, 135, 66, 66, 66, 17280, 66, 135, 135, 66, 17280, 17280, 17280, 66, 66, 17280, 135, 17280, 17280, 66, 17280, 66, 135, 66, 66, 135, 135, 17280, 17280, 17280, 66, 17280, 135, 135, 66, 66, 66, 66, 17280, 135, 17280, 135, 17280, 17280, 17280, 66, 135, 135, 17280, 135, 17280, 66, 66, 66, 135, 135, 135, 17280, 17280, 135, 17280, 66, 135, 135, 66, 17280, 17280, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 135, 17280, 66, 17280, 66, 17280, 135, 66, 135, 66, 66, 135, 135, 135, 17280, 135, 66, 66]
Prompts retrieved: 943773 . Total input tokens: 210368094 . Total output tokens: 188601248
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.456273433752358,
    "estimated_duration": 3600.0816089661926,
    "input_throughput": 6365.3684802385815,
    "output_throughput": 5611.073357251134,
    "total_throughput": 11976.441837489716,
    "itl": 151.2825306804153,
    "ttft": 1761651.0407374958,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 662,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1675825929082984,
    "arrivals": 314729,
    "finished_requests": 92354,
    "scheduler_time": 112.3152814901498
}
#Debug simulation 
Total elapsed time: 6.4563650619238615. Arrivals time: 0.2638827823102474 Scheduler time: 6.084811764303595 Scheduler overhead time: 0.036129130981862545 Adapter cache time: 0.017902427818626165 Engine time: 0.036789736710488796 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-16/adapters_160_slots_96_rate_1.6-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-16/adapters_160_slots_96_rate_1.6-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 135, 66, 66, 66, 17280, 66, 135, 17280, 135, 66, 135, 135, 135, 135, 17280, 17280, 17280, 135, 135, 135, 17280, 17280, 66, 17280, 135, 17280, 17280, 17280, 135, 17280, 66, 135, 135, 135, 17280, 66, 66, 17280, 66, 17280, 66, 66, 135, 66, 135, 17280, 66, 66, 135, 66, 66, 66, 66, 66, 17280, 135, 135, 17280, 135, 66, 17280, 17280, 17280, 135, 135, 66, 66, 66, 17280, 66, 135, 135, 66, 17280, 17280, 17280, 66, 66, 17280, 135, 17280, 17280, 66, 17280, 66, 135, 66, 66, 135, 135, 17280, 17280, 17280, 66, 17280, 135, 135, 66, 66, 66, 66, 17280, 135, 17280, 135, 17280, 17280, 17280, 66, 135, 135, 17280, 135, 17280, 66, 66, 66, 135, 135, 135, 17280, 17280, 135, 17280, 66, 135, 135, 66, 17280, 17280, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 135, 17280, 66, 17280, 66, 17280, 135, 66, 135, 66, 66, 135, 135, 135, 17280, 135, 66, 66]
Prompts retrieved: 943773 . Total input tokens: 210368094 . Total output tokens: 188601248
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 6.477890269830823,
    "estimated_duration": 3600.05663452486,
    "input_throughput": 6377.6080020002955,
    "output_throughput": 5621.139347067752,
    "total_throughput": 11998.747349068048,
    "itl": 153.08591594586906,
    "ttft": 1759828.1758601512,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 660,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0665929272398214,
    "arrivals": 314729,
    "finished_requests": 92531,
    "scheduler_time": 112.11034642929545
}
#Debug simulation 
Total elapsed time: 6.477981704752892. Arrivals time: 0.2643207861110568 Scheduler time: 6.1069676307961345 Scheduler overhead time: 0.035626808647066355 Adapter cache time: 0.017709430307149887 Engine time: 0.036739726550877094 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-32/adapters_160_slots_96_rate_1.6-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-32/adapters_160_slots_96_rate_1.6-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 135, 66, 66, 66, 17280, 66, 135, 17280, 135, 66, 135, 135, 135, 135, 17280, 17280, 17280, 135, 135, 135, 17280, 17280, 66, 17280, 135, 17280, 17280, 17280, 135, 17280, 66, 135, 135, 135, 17280, 66, 66, 17280, 66, 17280, 66, 66, 135, 66, 135, 17280, 66, 66, 135, 66, 66, 66, 66, 66, 17280, 135, 135, 17280, 135, 66, 17280, 17280, 17280, 135, 135, 66, 66, 66, 17280, 66, 135, 135, 66, 17280, 17280, 17280, 66, 66, 17280, 135, 17280, 17280, 66, 17280, 66, 135, 66, 66, 135, 135, 17280, 17280, 17280, 66, 17280, 135, 135, 66, 66, 66, 66, 17280, 135, 17280, 135, 17280, 17280, 17280, 66, 135, 135, 17280, 135, 17280, 66, 66, 66, 135, 135, 135, 17280, 17280, 135, 17280, 66, 135, 135, 66, 17280, 17280, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 135, 17280, 66, 17280, 66, 17280, 135, 66, 135, 66, 66, 135, 135, 135, 17280, 135, 66, 66]
Prompts retrieved: 943773 . Total input tokens: 210368094 . Total output tokens: 188601248
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 6.47977511677891,
    "estimated_duration": 3600.1099331603855,
    "input_throughput": 6365.318400119838,
    "output_throughput": 5611.0292116182645,
    "total_throughput": 11976.347611738101,
    "itl": 151.28308349248604,
    "ttft": 1761662.6524761142,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 662,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.195877194851642,
    "arrivals": 314729,
    "finished_requests": 92354,
    "scheduler_time": 112.31536935119773
}
#Debug simulation 
Total elapsed time: 6.479863711167127. Arrivals time: 0.26416254369542 Scheduler time: 6.107474319636822 Scheduler overhead time: 0.03631602227687836 Adapter cache time: 0.01810242421925068 Engine time: 0.03701141802594066 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-16/adapters_160_slots_96_rate_1.6-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-16/adapters_160_slots_96_rate_1.6-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 135, 66, 66, 66, 17280, 66, 135, 17280, 135, 66, 135, 135, 135, 135, 17280, 17280, 17280, 135, 135, 135, 17280, 17280, 66, 17280, 135, 17280, 17280, 17280, 135, 17280, 66, 135, 135, 135, 17280, 66, 66, 17280, 66, 17280, 66, 66, 135, 66, 135, 17280, 66, 66, 135, 66, 66, 66, 66, 66, 17280, 135, 135, 17280, 135, 66, 17280, 17280, 17280, 135, 135, 66, 66, 66, 17280, 66, 135, 135, 66, 17280, 17280, 17280, 66, 66, 17280, 135, 17280, 17280, 66, 17280, 66, 135, 66, 66, 135, 135, 17280, 17280, 17280, 66, 17280, 135, 135, 66, 66, 66, 66, 17280, 135, 17280, 135, 17280, 17280, 17280, 66, 135, 135, 17280, 135, 17280, 66, 66, 66, 135, 135, 135, 17280, 17280, 135, 17280, 66, 135, 135, 66, 17280, 17280, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 135, 17280, 66, 17280, 66, 17280, 135, 66, 135, 66, 66, 135, 135, 135, 17280, 135, 66, 66]
Prompts retrieved: 943773 . Total input tokens: 210368094 . Total output tokens: 188601248
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 6.712727077770978,
    "estimated_duration": 3600.044095080079,
    "input_throughput": 6377.685215405475,
    "output_throughput": 5621.177537146212,
    "total_throughput": 11998.862752551686,
    "itl": 153.0812176615854,
    "ttft": 1759858.0770051724,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 660,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9734331946354027,
    "arrivals": 314729,
    "finished_requests": 92532,
    "scheduler_time": 112.11248701588194
}
#Debug simulation 
Total elapsed time: 6.712791915051639. Arrivals time: 0.47422472201287746 Scheduler time: 6.132023907266557 Scheduler overhead time: 0.03571924939751625 Adapter cache time: 0.017643031664192677 Engine time: 0.03648588573560119 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-32/adapters_160_slots_96_rate_1.6-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-32/adapters_160_slots_96_rate_1.6-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 135, 66, 66, 66, 17280, 66, 135, 17280, 135, 66, 135, 135, 135, 135, 17280, 17280, 17280, 135, 135, 135, 17280, 17280, 66, 17280, 135, 17280, 17280, 17280, 135, 17280, 66, 135, 135, 135, 17280, 66, 66, 17280, 66, 17280, 66, 66, 135, 66, 135, 17280, 66, 66, 135, 66, 66, 66, 66, 66, 17280, 135, 135, 17280, 135, 66, 17280, 17280, 17280, 135, 135, 66, 66, 66, 17280, 66, 135, 135, 66, 17280, 17280, 17280, 66, 66, 17280, 135, 17280, 17280, 66, 17280, 66, 135, 66, 66, 135, 135, 17280, 17280, 17280, 66, 17280, 135, 135, 66, 66, 66, 66, 17280, 135, 17280, 135, 17280, 17280, 17280, 66, 135, 135, 17280, 135, 17280, 66, 66, 66, 135, 135, 135, 17280, 17280, 135, 17280, 66, 135, 135, 66, 17280, 17280, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 135, 17280, 66, 17280, 66, 17280, 135, 66, 135, 66, 66, 135, 135, 135, 17280, 135, 66, 66]
Prompts retrieved: 943773 . Total input tokens: 210368094 . Total output tokens: 188601248
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.454065112397075,
    "estimated_duration": 3600.1385013025974,
    "input_throughput": 6365.267889473868,
    "output_throughput": 5610.984686475575,
    "total_throughput": 11976.252575949444,
    "itl": 151.2841350334009,
    "ttft": 1761674.2269277896,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 662,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2245490581542273,
    "arrivals": 314729,
    "finished_requests": 92354,
    "scheduler_time": 112.31542651081169
}
#Debug simulation 
Total elapsed time: 6.454150214325637. Arrivals time: 0.2642275718972087 Scheduler time: 6.082013969775289 Scheduler overhead time: 0.03602928062900901 Adapter cache time: 0.018149282317608595 Engine time: 0.03687745286151767 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-8/adapters_160_slots_96_rate_1.6-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-8/adapters_160_slots_96_rate_1.6-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 135, 33, 33, 33, 17280, 33, 135, 17280, 135, 33, 135, 135, 135, 135, 17280, 17280, 17280, 135, 135, 135, 17280, 17280, 33, 17280, 135, 17280, 17280, 17280, 135, 17280, 33, 135, 135, 135, 17280, 33, 33, 17280, 33, 17280, 33, 33, 135, 33, 135, 17280, 33, 33, 135, 33, 33, 33, 33, 33, 17280, 135, 135, 17280, 135, 33, 17280, 17280, 17280, 135, 135, 33, 33, 33, 17280, 33, 135, 135, 33, 17280, 17280, 17280, 33, 33, 17280, 135, 17280, 17280, 33, 17280, 33, 135, 33, 33, 135, 135, 17280, 17280, 17280, 33, 17280, 135, 135, 33, 33, 33, 33, 17280, 135, 17280, 135, 17280, 17280, 17280, 33, 135, 135, 17280, 135, 17280, 33, 33, 33, 135, 135, 135, 17280, 17280, 135, 17280, 33, 135, 135, 33, 17280, 17280, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 135, 17280, 33, 17280, 33, 17280, 135, 33, 135, 33, 33, 135, 135, 135, 17280, 135, 33, 33]
Prompts retrieved: 942024 . Total input tokens: 209985148 . Total output tokens: 188245389
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 6.520923427771777,
    "estimated_duration": 3600.016036386352,
    "input_throughput": 6371.38856276428,
    "output_throughput": 5662.460887385974,
    "total_throughput": 12033.849450150254,
    "itl": 152.57445779424268,
    "ttft": 1754610.6276402064,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 511,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5639092371496555,
    "arrivals": 314142,
    "finished_requests": 93203,
    "scheduler_time": 112.77566742490107
}
#Debug simulation 
Total elapsed time: 6.521028688177466. Arrivals time: 0.26770838955417275 Scheduler time: 6.148673603311181 Scheduler overhead time: 0.03556846966966987 Adapter cache time: 0.015788812655955553 Engine time: 0.03663778956979513 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-16/adapters_160_slots_96_rate_1.6-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-16/adapters_160_slots_96_rate_1.6-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 135, 33, 33, 33, 17280, 33, 135, 17280, 135, 33, 135, 135, 135, 135, 17280, 17280, 17280, 135, 135, 135, 17280, 17280, 33, 17280, 135, 17280, 17280, 17280, 135, 17280, 33, 135, 135, 135, 17280, 33, 33, 17280, 33, 17280, 33, 33, 135, 33, 135, 17280, 33, 33, 135, 33, 33, 33, 33, 33, 17280, 135, 135, 17280, 135, 33, 17280, 17280, 17280, 135, 135, 33, 33, 33, 17280, 33, 135, 135, 33, 17280, 17280, 17280, 33, 33, 17280, 135, 17280, 17280, 33, 17280, 33, 135, 33, 33, 135, 135, 17280, 17280, 17280, 33, 17280, 135, 135, 33, 33, 33, 33, 17280, 135, 17280, 135, 17280, 17280, 17280, 33, 135, 135, 17280, 135, 17280, 33, 33, 33, 135, 135, 135, 17280, 17280, 135, 17280, 33, 135, 135, 33, 17280, 17280, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 135, 17280, 33, 17280, 33, 17280, 135, 33, 135, 33, 33, 135, 135, 135, 17280, 135, 33, 33]
Prompts retrieved: 942024 . Total input tokens: 209985148 . Total output tokens: 188245389
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.488224341068417,
    "estimated_duration": 3600.000776543386,
    "input_throughput": 6370.627514703149,
    "output_throughput": 5661.9012786911135,
    "total_throughput": 12032.528793394264,
    "itl": 152.5773717459437,
    "ttft": 1754691.2583984772,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 511,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6696982761938188,
    "arrivals": 314142,
    "finished_requests": 93195,
    "scheduler_time": 112.77143575418327
}
#Debug simulation 
Total elapsed time: 6.488329772371799. Arrivals time: 0.29161682538688183 Scheduler time: 6.092024568933994 Scheduler overhead time: 0.035684125032275915 Adapter cache time: 0.01602495275437832 Engine time: 0.0363638736307621 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-32/adapters_160_slots_96_rate_1.6-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-32/adapters_160_slots_96_rate_1.6-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 135, 33, 33, 33, 17280, 33, 135, 17280, 135, 33, 135, 135, 135, 135, 17280, 17280, 17280, 135, 135, 135, 17280, 17280, 33, 17280, 135, 17280, 17280, 17280, 135, 17280, 33, 135, 135, 135, 17280, 33, 33, 17280, 33, 17280, 33, 33, 135, 33, 135, 17280, 33, 33, 135, 33, 33, 33, 33, 33, 17280, 135, 135, 17280, 135, 33, 17280, 17280, 17280, 135, 135, 33, 33, 33, 17280, 33, 135, 135, 33, 17280, 17280, 17280, 33, 33, 17280, 135, 17280, 17280, 33, 17280, 33, 135, 33, 33, 135, 135, 17280, 17280, 17280, 33, 17280, 135, 135, 33, 33, 33, 33, 17280, 135, 17280, 135, 17280, 17280, 17280, 33, 135, 135, 17280, 135, 17280, 33, 33, 33, 135, 135, 135, 17280, 17280, 135, 17280, 33, 135, 135, 33, 17280, 17280, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 135, 17280, 33, 17280, 33, 17280, 135, 33, 135, 33, 33, 135, 135, 135, 17280, 135, 33, 33]
Prompts retrieved: 942024 . Total input tokens: 209985148 . Total output tokens: 188245389
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.644990228116512,
    "estimated_duration": 3600.091976259535,
    "input_throughput": 6359.960287400549,
    "output_throughput": 5651.337280870982,
    "total_throughput": 12011.29756827153,
    "itl": 150.93883667220885,
    "ttft": 1756253.9925725101,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 511,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6719257648289305,
    "arrivals": 314142,
    "finished_requests": 93031,
    "scheduler_time": 112.94930819550974
}
#Debug simulation 
Total elapsed time: 6.64509752811864. Arrivals time: 0.4726086622104049 Scheduler time: 6.066654944326729 Scheduler overhead time: 0.03601977974176407 Adapter cache time: 0.01620198879390955 Engine time: 0.03687166515737772 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-16/adapters_160_slots_96_rate_1.6-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-16/adapters_160_slots_96_rate_1.6-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 135, 33, 33, 33, 17280, 33, 135, 17280, 135, 33, 135, 135, 135, 135, 17280, 17280, 17280, 135, 135, 135, 17280, 17280, 33, 17280, 135, 17280, 17280, 17280, 135, 17280, 33, 135, 135, 135, 17280, 33, 33, 17280, 33, 17280, 33, 33, 135, 33, 135, 17280, 33, 33, 135, 33, 33, 33, 33, 33, 17280, 135, 135, 17280, 135, 33, 17280, 17280, 17280, 135, 135, 33, 33, 33, 17280, 33, 135, 135, 33, 17280, 17280, 17280, 33, 33, 17280, 135, 17280, 17280, 33, 17280, 33, 135, 33, 33, 135, 135, 17280, 17280, 17280, 33, 17280, 135, 135, 33, 33, 33, 33, 17280, 135, 17280, 135, 17280, 17280, 17280, 33, 135, 135, 17280, 135, 17280, 33, 33, 33, 135, 135, 135, 17280, 17280, 135, 17280, 33, 135, 135, 33, 17280, 17280, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 135, 17280, 33, 17280, 33, 17280, 135, 33, 135, 33, 33, 135, 135, 135, 17280, 135, 33, 33]
Prompts retrieved: 942024 . Total input tokens: 209985148 . Total output tokens: 188245389
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 6.542068921029568,
    "estimated_duration": 3600.0553978520775,
    "input_throughput": 6371.318900727222,
    "output_throughput": 5662.3989764608605,
    "total_throughput": 12033.717877188083,
    "itl": 152.5757420224297,
    "ttft": 1754625.1358940385,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 511,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5994198814220666,
    "arrivals": 314142,
    "finished_requests": 93203,
    "scheduler_time": 112.77583863692537
}
#Debug simulation 
Total elapsed time: 6.542183464858681. Arrivals time: 0.26831872295588255 Scheduler time: 6.168394600972533 Scheduler overhead time: 0.03575275093317032 Adapter cache time: 0.016161371022462845 Engine time: 0.03679073043167591 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-32/adapters_160_slots_96_rate_1.6-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-32/adapters_160_slots_96_rate_1.6-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 135, 33, 33, 33, 17280, 33, 135, 17280, 135, 33, 135, 135, 135, 135, 17280, 17280, 17280, 135, 135, 135, 17280, 17280, 33, 17280, 135, 17280, 17280, 17280, 135, 17280, 33, 135, 135, 135, 17280, 33, 33, 17280, 33, 17280, 33, 33, 135, 33, 135, 17280, 33, 33, 135, 33, 33, 33, 33, 33, 17280, 135, 135, 17280, 135, 33, 17280, 17280, 17280, 135, 135, 33, 33, 33, 17280, 33, 135, 135, 33, 17280, 17280, 17280, 33, 33, 17280, 135, 17280, 17280, 33, 17280, 33, 135, 33, 33, 135, 135, 17280, 17280, 17280, 33, 17280, 135, 135, 33, 33, 33, 33, 17280, 135, 17280, 135, 17280, 17280, 17280, 33, 135, 135, 17280, 135, 17280, 33, 33, 33, 135, 135, 135, 17280, 17280, 135, 17280, 33, 135, 135, 33, 17280, 17280, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 135, 17280, 33, 17280, 33, 17280, 135, 33, 135, 33, 33, 135, 135, 135, 17280, 135, 33, 33]
Prompts retrieved: 942024 . Total input tokens: 209985148 . Total output tokens: 188245389
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 6.531639289110899,
    "estimated_duration": 3600.136542969919,
    "input_throughput": 6359.881556356656,
    "output_throughput": 5651.267321993347,
    "total_throughput": 12011.148878350003,
    "itl": 150.9326069121384,
    "ttft": 1756280.1267716645,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 511,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6935554160922806,
    "arrivals": 314142,
    "finished_requests": 93031,
    "scheduler_time": 112.95085240841425
}
#Debug simulation 
Total elapsed time: 6.531727087218314. Arrivals time: 0.26770547591149807 Scheduler time: 6.15746369259432 Scheduler overhead time: 0.03626261139288545 Adapter cache time: 0.016209354624152184 Engine time: 0.03721494087949395 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-16/adapters_160_slots_96_rate_1.6-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-16/adapters_160_slots_96_rate_1.6-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 135, 33, 33, 33, 17280, 33, 135, 17280, 135, 33, 135, 135, 135, 135, 17280, 17280, 17280, 135, 135, 135, 17280, 17280, 33, 17280, 135, 17280, 17280, 17280, 135, 17280, 33, 135, 135, 135, 17280, 33, 33, 17280, 33, 17280, 33, 33, 135, 33, 135, 17280, 33, 33, 135, 33, 33, 33, 33, 33, 17280, 135, 135, 17280, 135, 33, 17280, 17280, 17280, 135, 135, 33, 33, 33, 17280, 33, 135, 135, 33, 17280, 17280, 17280, 33, 33, 17280, 135, 17280, 17280, 33, 17280, 33, 135, 33, 33, 135, 135, 17280, 17280, 17280, 33, 17280, 135, 135, 33, 33, 33, 33, 17280, 135, 17280, 135, 17280, 17280, 17280, 33, 135, 135, 17280, 135, 17280, 33, 33, 33, 135, 135, 135, 17280, 17280, 135, 17280, 33, 135, 135, 33, 17280, 17280, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 135, 17280, 33, 17280, 33, 17280, 135, 33, 135, 33, 33, 135, 135, 135, 17280, 135, 33, 33]
Prompts retrieved: 942024 . Total input tokens: 209985148 . Total output tokens: 188245389
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 6.529822777956724,
    "estimated_duration": 3600.14637335938,
    "input_throughput": 6371.494273049718,
    "output_throughput": 5662.525043662996,
    "total_throughput": 12034.019316712713,
    "itl": 152.57424392945993,
    "ttft": 1754649.2729303238,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 511,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5279157006949944,
    "arrivals": 314142,
    "finished_requests": 93207,
    "scheduler_time": 112.77989492631403
}
#Debug simulation 
Total elapsed time: 6.529910054989159. Arrivals time: 0.2911451826803386 Scheduler time: 6.133509430103004 Scheduler overhead time: 0.035733853466808796 Adapter cache time: 0.016100121196359396 Engine time: 0.03675854252651334 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-32/adapters_160_slots_96_rate_1.6-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-32/adapters_160_slots_96_rate_1.6-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 135, 33, 33, 33, 17280, 33, 135, 17280, 135, 33, 135, 135, 135, 135, 17280, 17280, 17280, 135, 135, 135, 17280, 17280, 33, 17280, 135, 17280, 17280, 17280, 135, 17280, 33, 135, 135, 135, 17280, 33, 33, 17280, 33, 17280, 33, 33, 135, 33, 135, 17280, 33, 33, 135, 33, 33, 33, 33, 33, 17280, 135, 135, 17280, 135, 33, 17280, 17280, 17280, 135, 135, 33, 33, 33, 17280, 33, 135, 135, 33, 17280, 17280, 17280, 33, 33, 17280, 135, 17280, 17280, 33, 17280, 33, 135, 33, 33, 135, 135, 17280, 17280, 17280, 33, 17280, 135, 135, 33, 33, 33, 33, 17280, 135, 17280, 135, 17280, 17280, 17280, 33, 135, 135, 17280, 135, 17280, 33, 33, 33, 135, 135, 135, 17280, 17280, 135, 17280, 33, 135, 135, 33, 17280, 17280, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 135, 17280, 33, 17280, 33, 17280, 135, 33, 135, 33, 33, 135, 135, 135, 17280, 135, 33, 33]
Prompts retrieved: 942024 . Total input tokens: 209985148 . Total output tokens: 188245389
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.610181333962828,
    "estimated_duration": 3600.1645383883706,
    "input_throughput": 6359.8321009655,
    "output_throughput": 5651.223376892568,
    "total_throughput": 12011.055477858068,
    "itl": 150.93276235700378,
    "ttft": 1756294.5028588707,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 511,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7154365749284604,
    "arrivals": 314142,
    "finished_requests": 93031,
    "scheduler_time": 112.95102472196977
}
#Debug simulation 
Total elapsed time: 6.610266651026905. Arrivals time: 0.27725930185988545 Scheduler time: 6.226774349343032 Scheduler overhead time: 0.03615864459425211 Adapter cache time: 0.01617631781846285 Engine time: 0.036987271159887314 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-8/adapters_160_slots_96_rate_1.6-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-8/adapters_160_slots_96_rate_1.6-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 66, 33, 33, 33, 17280, 33, 66, 17280, 66, 33, 66, 66, 66, 66, 17280, 17280, 17280, 66, 66, 66, 17280, 17280, 33, 17280, 66, 17280, 17280, 17280, 66, 17280, 33, 66, 66, 66, 17280, 33, 33, 17280, 33, 17280, 33, 33, 66, 33, 66, 17280, 33, 33, 66, 33, 33, 33, 33, 33, 17280, 66, 66, 17280, 66, 33, 17280, 17280, 17280, 66, 66, 33, 33, 33, 17280, 33, 66, 66, 33, 17280, 17280, 17280, 33, 33, 17280, 66, 17280, 17280, 33, 17280, 33, 66, 33, 33, 66, 66, 17280, 17280, 17280, 33, 17280, 66, 66, 33, 33, 33, 33, 17280, 66, 17280, 66, 17280, 17280, 17280, 33, 66, 66, 17280, 66, 17280, 33, 33, 33, 66, 66, 66, 17280, 17280, 66, 17280, 33, 66, 66, 33, 17280, 17280, 17280, 17280, 17280, 17280, 66, 66, 66, 66, 66, 17280, 33, 17280, 33, 17280, 66, 33, 66, 33, 33, 66, 66, 66, 17280, 66, 33, 33]
Prompts retrieved: 938367 . Total input tokens: 209161351 . Total output tokens: 187500351
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 6.655267351772636,
    "estimated_duration": 3600.143308071607,
    "input_throughput": 6541.058503755433,
    "output_throughput": 5781.520405961018,
    "total_throughput": 12322.57890971645,
    "itl": 148.92595424145378,
    "ttft": 1737545.7829461938,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 379,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.159924854950518,
    "arrivals": 312976,
    "finished_requests": 95291,
    "scheduler_time": 115.1444829026516
}
#Debug simulation 
Total elapsed time: 6.655357129871845. Arrivals time: 0.30793410167098045 Scheduler time: 6.2436436247080564 Scheduler overhead time: 0.03648112062364817 Adapter cache time: 0.013148378115147352 Engine time: 0.03710738802328706 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-16/adapters_160_slots_96_rate_1.6-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-16/adapters_160_slots_96_rate_1.6-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 66, 33, 33, 33, 17280, 33, 66, 17280, 66, 33, 66, 66, 66, 66, 17280, 17280, 17280, 66, 66, 66, 17280, 17280, 33, 17280, 66, 17280, 17280, 17280, 66, 17280, 33, 66, 66, 66, 17280, 33, 33, 17280, 33, 17280, 33, 33, 66, 33, 66, 17280, 33, 33, 66, 33, 33, 33, 33, 33, 17280, 66, 66, 17280, 66, 33, 17280, 17280, 17280, 66, 66, 33, 33, 33, 17280, 33, 66, 66, 33, 17280, 17280, 17280, 33, 33, 17280, 66, 17280, 17280, 33, 17280, 33, 66, 33, 33, 66, 66, 17280, 17280, 17280, 33, 17280, 66, 66, 33, 33, 33, 33, 17280, 66, 17280, 66, 17280, 17280, 17280, 33, 66, 66, 17280, 66, 17280, 33, 33, 33, 66, 66, 66, 17280, 17280, 66, 17280, 33, 66, 66, 33, 17280, 17280, 17280, 17280, 17280, 17280, 66, 66, 66, 66, 66, 17280, 33, 17280, 33, 17280, 66, 33, 66, 33, 33, 66, 66, 66, 17280, 66, 33, 33]
Prompts retrieved: 938367 . Total input tokens: 209161351 . Total output tokens: 187500351
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.678081412333995,
    "estimated_duration": 3600.0913583988104,
    "input_throughput": 6541.034839314033,
    "output_throughput": 5781.466337359067,
    "total_throughput": 12322.5011766731,
    "itl": 148.9280279954854,
    "ttft": 1737578.6689157092,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 379,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2386466539255405,
    "arrivals": 312976,
    "finished_requests": 95289,
    "scheduler_time": 115.14110979632706
}
#Debug simulation 
Total elapsed time: 6.678163411095738. Arrivals time: 0.29737754352390766 Scheduler time: 6.276633783709258 Scheduler overhead time: 0.03655571490526199 Adapter cache time: 0.013299616519361734 Engine time: 0.03726427210494876 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-32/adapters_160_slots_96_rate_1.6-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-32/adapters_160_slots_96_rate_1.6-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 66, 33, 33, 33, 17280, 33, 66, 17280, 66, 33, 66, 66, 66, 66, 17280, 17280, 17280, 66, 66, 66, 17280, 17280, 33, 17280, 66, 17280, 17280, 17280, 66, 17280, 33, 66, 66, 66, 17280, 33, 33, 17280, 33, 17280, 33, 33, 66, 33, 66, 17280, 33, 33, 66, 33, 33, 33, 33, 33, 17280, 66, 66, 17280, 66, 33, 17280, 17280, 17280, 66, 66, 33, 33, 33, 17280, 33, 66, 66, 33, 17280, 17280, 17280, 33, 33, 17280, 66, 17280, 17280, 33, 17280, 33, 66, 33, 33, 66, 66, 17280, 17280, 17280, 33, 17280, 66, 66, 33, 33, 33, 33, 17280, 66, 17280, 66, 17280, 17280, 17280, 33, 66, 66, 17280, 66, 17280, 33, 33, 33, 66, 66, 66, 17280, 17280, 66, 17280, 33, 66, 66, 33, 17280, 17280, 17280, 17280, 17280, 17280, 66, 66, 66, 66, 66, 17280, 33, 17280, 33, 17280, 66, 33, 66, 33, 33, 66, 66, 66, 17280, 66, 33, 33]
Prompts retrieved: 938367 . Total input tokens: 209161351 . Total output tokens: 187500351
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.665841148700565,
    "estimated_duration": 3600.1099072102606,
    "input_throughput": 6527.257668699717,
    "output_throughput": 5769.26803217926,
    "total_throughput": 12296.525700878978,
    "itl": 147.338865118449,
    "ttft": 1739182.746282195,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 379,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.240503497272737,
    "arrivals": 312976,
    "finished_requests": 95090,
    "scheduler_time": 115.31239947750457
}
#Debug simulation 
Total elapsed time: 6.6659231865778565. Arrivals time: 0.2921022856608033 Scheduler time: 6.268680017907172 Scheduler overhead time: 0.03689832426607609 Adapter cache time: 0.013196582440286875 Engine time: 0.037850355729460716 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-16/adapters_160_slots_96_rate_1.6-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-16/adapters_160_slots_96_rate_1.6-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 66, 33, 33, 33, 17280, 33, 66, 17280, 66, 33, 66, 66, 66, 66, 17280, 17280, 17280, 66, 66, 66, 17280, 17280, 33, 17280, 66, 17280, 17280, 17280, 66, 17280, 33, 66, 66, 66, 17280, 33, 33, 17280, 33, 17280, 33, 33, 66, 33, 66, 17280, 33, 33, 66, 33, 33, 33, 33, 33, 17280, 66, 66, 17280, 66, 33, 17280, 17280, 17280, 66, 66, 33, 33, 33, 17280, 33, 66, 66, 33, 17280, 17280, 17280, 33, 33, 17280, 66, 17280, 17280, 33, 17280, 33, 66, 33, 33, 66, 66, 17280, 17280, 17280, 33, 17280, 66, 66, 33, 33, 33, 33, 17280, 66, 17280, 66, 17280, 17280, 17280, 33, 66, 66, 17280, 66, 17280, 33, 33, 33, 66, 66, 66, 17280, 17280, 66, 17280, 33, 66, 66, 33, 17280, 17280, 17280, 17280, 17280, 17280, 66, 66, 66, 66, 66, 17280, 33, 17280, 33, 17280, 66, 33, 66, 33, 33, 66, 66, 66, 17280, 66, 33, 33]
Prompts retrieved: 938367 . Total input tokens: 209161351 . Total output tokens: 187500351
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 6.649028630927205,
    "estimated_duration": 3600.0300152924456,
    "input_throughput": 6541.146295994721,
    "output_throughput": 5781.564851288943,
    "total_throughput": 12322.711147283664,
    "itl": 148.92661236396864,
    "ttft": 1737558.0830664034,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 379,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1887980250758126,
    "arrivals": 312976,
    "finished_requests": 95289,
    "scheduler_time": 115.14014742436021
}
#Debug simulation 
Total elapsed time: 6.649120907764882. Arrivals time: 0.29842065926641226 Scheduler time: 6.246573145501316 Scheduler overhead time: 0.036594025790691376 Adapter cache time: 0.01325566926971078 Engine time: 0.03726250771433115 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-32/adapters_160_slots_96_rate_1.6-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-32/adapters_160_slots_96_rate_1.6-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 66, 33, 33, 33, 17280, 33, 66, 17280, 66, 33, 66, 66, 66, 66, 17280, 17280, 17280, 66, 66, 66, 17280, 17280, 33, 17280, 66, 17280, 17280, 17280, 66, 17280, 33, 66, 66, 66, 17280, 33, 33, 17280, 33, 17280, 33, 33, 66, 33, 66, 17280, 33, 33, 66, 33, 33, 33, 33, 33, 17280, 66, 66, 17280, 66, 33, 17280, 17280, 17280, 66, 66, 33, 33, 33, 17280, 33, 66, 66, 33, 17280, 17280, 17280, 33, 33, 17280, 66, 17280, 17280, 33, 17280, 33, 66, 33, 33, 66, 66, 17280, 17280, 17280, 33, 17280, 66, 66, 33, 33, 33, 33, 17280, 66, 17280, 66, 17280, 17280, 17280, 33, 66, 66, 17280, 66, 17280, 33, 33, 33, 66, 66, 66, 17280, 17280, 66, 17280, 33, 66, 66, 33, 17280, 17280, 17280, 17280, 17280, 17280, 66, 66, 66, 66, 66, 17280, 33, 17280, 33, 17280, 66, 33, 66, 33, 33, 66, 66, 66, 17280, 66, 33, 33]
Prompts retrieved: 938367 . Total input tokens: 209161351 . Total output tokens: 187500351
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 6.655231734737754,
    "estimated_duration": 3600.1259523626572,
    "input_throughput": 6527.228577816394,
    "output_throughput": 5769.242319527531,
    "total_throughput": 12296.470897343926,
    "itl": 147.33916477324883,
    "ttft": 1739190.3708352114,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 379,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.255845459215348,
    "arrivals": 312976,
    "finished_requests": 95090,
    "scheduler_time": 115.31246956750897
}
#Debug simulation 
Total elapsed time: 6.655324070714414. Arrivals time: 0.27037489600479603 Scheduler time: 6.279641317203641 Scheduler overhead time: 0.036922835279256105 Adapter cache time: 0.013187302742153406 Engine time: 0.037908272352069616 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-16/adapters_160_slots_96_rate_1.6-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-16/adapters_160_slots_96_rate_1.6-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 66, 33, 33, 33, 17280, 33, 66, 17280, 66, 33, 66, 66, 66, 66, 17280, 17280, 17280, 66, 66, 66, 17280, 17280, 33, 17280, 66, 17280, 17280, 17280, 66, 17280, 33, 66, 66, 66, 17280, 33, 33, 17280, 33, 17280, 33, 33, 66, 33, 66, 17280, 33, 33, 66, 33, 33, 33, 33, 33, 17280, 66, 66, 17280, 66, 33, 17280, 17280, 17280, 66, 66, 33, 33, 33, 17280, 33, 66, 66, 33, 17280, 17280, 17280, 33, 33, 17280, 66, 17280, 17280, 33, 17280, 33, 66, 33, 33, 66, 66, 17280, 17280, 17280, 33, 17280, 66, 66, 33, 33, 33, 33, 17280, 66, 17280, 66, 17280, 17280, 17280, 33, 66, 66, 17280, 66, 17280, 33, 33, 33, 66, 66, 66, 17280, 17280, 66, 17280, 33, 66, 66, 33, 17280, 17280, 17280, 17280, 17280, 17280, 66, 66, 66, 66, 66, 17280, 33, 17280, 33, 17280, 66, 33, 66, 33, 33, 66, 66, 66, 17280, 66, 33, 33]
Prompts retrieved: 938367 . Total input tokens: 209161351 . Total output tokens: 187500351
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 6.638809365220368,
    "estimated_duration": 3600.058529154744,
    "input_throughput": 6541.191430442933,
    "output_throughput": 5781.609613132301,
    "total_throughput": 12322.801043575233,
    "itl": 148.9240783579547,
    "ttft": 1737523.3850204088,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 379,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1332290617679213,
    "arrivals": 312976,
    "finished_requests": 95290,
    "scheduler_time": 115.14296091445651
}
#Debug simulation 
Total elapsed time: 6.638910964131355. Arrivals time: 0.2728315033018589 Scheduler time: 6.261945892591029 Scheduler overhead time: 0.036514404229819775 Adapter cache time: 0.01323393639177084 Engine time: 0.03742517298087478 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-32/adapters_160_slots_96_rate_1.6-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-32/adapters_160_slots_96_rate_1.6-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 66, 33, 33, 33, 17280, 33, 66, 17280, 66, 33, 66, 66, 66, 66, 17280, 17280, 17280, 66, 66, 66, 17280, 17280, 33, 17280, 66, 17280, 17280, 17280, 66, 17280, 33, 66, 66, 66, 17280, 33, 33, 17280, 33, 17280, 33, 33, 66, 33, 66, 17280, 33, 33, 66, 33, 33, 33, 33, 33, 17280, 66, 66, 17280, 66, 33, 17280, 17280, 17280, 66, 66, 33, 33, 33, 17280, 33, 66, 66, 33, 17280, 17280, 17280, 33, 33, 17280, 66, 17280, 17280, 33, 17280, 33, 66, 33, 33, 66, 66, 17280, 17280, 17280, 33, 17280, 66, 66, 33, 33, 33, 33, 17280, 66, 17280, 66, 17280, 17280, 17280, 33, 66, 66, 17280, 66, 17280, 33, 33, 33, 66, 66, 66, 17280, 17280, 66, 17280, 33, 66, 66, 33, 17280, 17280, 17280, 17280, 17280, 17280, 66, 66, 66, 66, 66, 17280, 33, 17280, 33, 17280, 66, 33, 66, 33, 33, 66, 66, 66, 17280, 66, 33, 33]
Prompts retrieved: 938367 . Total input tokens: 209161351 . Total output tokens: 187500351
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.703671731986105,
    "estimated_duration": 3600.1431919458314,
    "input_throughput": 6527.197321642969,
    "output_throughput": 5769.21469303394,
    "total_throughput": 12296.41201467691,
    "itl": 147.33969517980037,
    "ttft": 1739198.3479613578,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 379,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2729479741677667,
    "arrivals": 312976,
    "finished_requests": 95090,
    "scheduler_time": 115.31251734968397
}
#Debug simulation 
Total elapsed time: 6.703765759244561. Arrivals time: 0.2629175325855613 Scheduler time: 6.335440918803215 Scheduler overhead time: 0.037067677825689316 Adapter cache time: 0.013210319448262453 Engine time: 0.0378728280775249 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-8/adapters_160_slots_96_rate_0.8-0.4-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-8/adapters_160_slots_96_rate_0.8-0.4-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [53 53 54]
Adapter prompts. [1080, 8640, 1080, 1080, 4320, 1080, 1080, 1080, 8640, 1080, 4320, 8640, 4320, 1080, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 1080, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 1080, 4320, 4320, 4320, 8640, 1080, 1080, 8640, 1080, 8640, 1080, 1080, 4320, 1080, 4320, 8640, 1080, 1080, 4320, 1080, 1080, 1080, 1080, 1080, 8640, 4320, 4320, 8640, 4320, 1080, 8640, 8640, 8640, 4320, 4320, 1080, 1080, 1080, 8640, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 1080, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 1080, 4320, 1080, 1080, 4320, 4320, 8640, 8640, 8640, 1080, 8640, 4320, 4320, 1080, 1080, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 1080, 4320, 4320, 8640, 4320, 8640, 1080, 1080, 1080, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 1080, 8640, 1080, 8640, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 8640, 4320, 1080, 1080]
Prompts retrieved: 752760 . Total input tokens: 167901726 . Total output tokens: 150505799
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 22.321322043891996,
    "estimated_duration": 3600.06472173836,
    "input_throughput": 5392.838323924717,
    "output_throughput": 4769.2212021425485,
    "total_throughput": 10162.059526067265,
    "itl": 180.16133242082626,
    "ttft": 1806009.446743234,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 406,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2425580240367051,
    "arrivals": 250580,
    "finished_requests": 78748,
    "scheduler_time": 94.69988159197601
}
#Debug simulation 
Total elapsed time: 22.32141754589975. Arrivals time: 0.3043686109595001 Scheduler time: 21.90654366929084 Scheduler overhead time: 0.04159553861245513 Adapter cache time: 0.012065391521900892 Engine time: 0.04070792067795992 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-16/adapters_160_slots_96_rate_0.8-0.4-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-16/adapters_160_slots_96_rate_0.8-0.4-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [53 53 54]
Adapter prompts. [1080, 8640, 1080, 1080, 4320, 1080, 1080, 1080, 8640, 1080, 4320, 8640, 4320, 1080, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 1080, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 1080, 4320, 4320, 4320, 8640, 1080, 1080, 8640, 1080, 8640, 1080, 1080, 4320, 1080, 4320, 8640, 1080, 1080, 4320, 1080, 1080, 1080, 1080, 1080, 8640, 4320, 4320, 8640, 4320, 1080, 8640, 8640, 8640, 4320, 4320, 1080, 1080, 1080, 8640, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 1080, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 1080, 4320, 1080, 1080, 4320, 4320, 8640, 8640, 8640, 1080, 8640, 4320, 4320, 1080, 1080, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 1080, 4320, 4320, 8640, 4320, 8640, 1080, 1080, 1080, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 1080, 8640, 1080, 8640, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 8640, 4320, 1080, 1080]
Prompts retrieved: 752760 . Total input tokens: 167901726 . Total output tokens: 150505799
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 22.800455682445318,
    "estimated_duration": 3600.166646498337,
    "input_throughput": 5395.594956387243,
    "output_throughput": 4773.655690831904,
    "total_throughput": 10169.250647219147,
    "itl": 179.90146951155674,
    "ttft": 1804816.7706199784,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 424,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3862739673862297,
    "arrivals": 250580,
    "finished_requests": 78816,
    "scheduler_time": 94.8417943397236
}
#Debug simulation 
Total elapsed time: 22.800607113167644. Arrivals time: 0.3144611162133515 Scheduler time: 22.3755718562752 Scheduler overhead time: 0.041356710251420736 Adapter cache time: 0.012335825711488724 Engine time: 0.040656866040080786 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-32/adapters_160_slots_96_rate_0.8-0.4-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-32/adapters_160_slots_96_rate_0.8-0.4-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [53 53 54]
Adapter prompts. [1080, 8640, 1080, 1080, 4320, 1080, 1080, 1080, 8640, 1080, 4320, 8640, 4320, 1080, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 1080, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 1080, 4320, 4320, 4320, 8640, 1080, 1080, 8640, 1080, 8640, 1080, 1080, 4320, 1080, 4320, 8640, 1080, 1080, 4320, 1080, 1080, 1080, 1080, 1080, 8640, 4320, 4320, 8640, 4320, 1080, 8640, 8640, 8640, 4320, 4320, 1080, 1080, 1080, 8640, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 1080, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 1080, 4320, 1080, 1080, 4320, 4320, 8640, 8640, 8640, 1080, 8640, 4320, 4320, 1080, 1080, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 1080, 4320, 4320, 8640, 4320, 8640, 1080, 1080, 1080, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 1080, 8640, 1080, 8640, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 8640, 4320, 1080, 1080]
Prompts retrieved: 752760 . Total input tokens: 167901726 . Total output tokens: 150505799
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 20.832294318825006,
    "estimated_duration": 3600.1937527530154,
    "input_throughput": 5380.445423301885,
    "output_throughput": 4758.736661575263,
    "total_throughput": 10139.182084877148,
    "itl": 177.9918654917485,
    "ttft": 1805779.1417140344,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 353,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.15563879979775,
    "arrivals": 250580,
    "finished_requests": 78558,
    "scheduler_time": 94.85554860256676
}
#Debug simulation 
Total elapsed time: 20.832388968206942. Arrivals time: 0.3095032083801925 Scheduler time: 20.41246356535703 Scheduler overhead time: 0.041723907459527254 Adapter cache time: 0.011332359164953232 Engine time: 0.04105692449957132 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-16-16/adapters_160_slots_96_rate_0.8-0.4-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-16-16/adapters_160_slots_96_rate_0.8-0.4-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [53 53 54]
Adapter prompts. [1080, 8640, 1080, 1080, 4320, 1080, 1080, 1080, 8640, 1080, 4320, 8640, 4320, 1080, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 1080, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 1080, 4320, 4320, 4320, 8640, 1080, 1080, 8640, 1080, 8640, 1080, 1080, 4320, 1080, 4320, 8640, 1080, 1080, 4320, 1080, 1080, 1080, 1080, 1080, 8640, 4320, 4320, 8640, 4320, 1080, 8640, 8640, 8640, 4320, 4320, 1080, 1080, 1080, 8640, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 1080, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 1080, 4320, 1080, 1080, 4320, 4320, 8640, 8640, 8640, 1080, 8640, 4320, 4320, 1080, 1080, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 1080, 4320, 4320, 8640, 4320, 8640, 1080, 1080, 1080, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 1080, 8640, 1080, 8640, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 8640, 4320, 1080, 1080]
Prompts retrieved: 752760 . Total input tokens: 167901726 . Total output tokens: 150505799
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 22.576534312218428,
    "estimated_duration": 3600.197209498462,
    "input_throughput": 5393.253999745453,
    "output_throughput": 4769.515946153431,
    "total_throughput": 10162.769945898885,
    "itl": 180.1436017197165,
    "ttft": 1806143.7402137856,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 402,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2616551350429657,
    "arrivals": 250580,
    "finished_requests": 78755,
    "scheduler_time": 94.71403137484343
}
#Debug simulation 
Total elapsed time: 22.576647136826068. Arrivals time: 0.3348225150257349 Scheduler time: 22.128876134287566 Scheduler overhead time: 0.04249985795468092 Adapter cache time: 0.012355008162558079 Engine time: 0.04148509353399277 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-16-32/adapters_160_slots_96_rate_0.8-0.4-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-16-32/adapters_160_slots_96_rate_0.8-0.4-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [53 53 54]
Adapter prompts. [1080, 8640, 1080, 1080, 4320, 1080, 1080, 1080, 8640, 1080, 4320, 8640, 4320, 1080, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 1080, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 1080, 4320, 4320, 4320, 8640, 1080, 1080, 8640, 1080, 8640, 1080, 1080, 4320, 1080, 4320, 8640, 1080, 1080, 4320, 1080, 1080, 1080, 1080, 1080, 8640, 4320, 4320, 8640, 4320, 1080, 8640, 8640, 8640, 4320, 4320, 1080, 1080, 1080, 8640, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 1080, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 1080, 4320, 1080, 1080, 4320, 4320, 8640, 8640, 8640, 1080, 8640, 4320, 4320, 1080, 1080, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 1080, 4320, 4320, 8640, 4320, 8640, 1080, 1080, 1080, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 1080, 8640, 1080, 8640, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 8640, 4320, 1080, 1080]
Prompts retrieved: 752760 . Total input tokens: 167901726 . Total output tokens: 150505799
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 21.707388726994395,
    "estimated_duration": 3600.168017114425,
    "input_throughput": 5386.571378838968,
    "output_throughput": 4768.511891219982,
    "total_throughput": 10155.08327005895,
    "itl": 177.75662755463654,
    "ttft": 1806228.1278463076,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 380,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2585917444340933,
    "arrivals": 250580,
    "finished_requests": 78644,
    "scheduler_time": 95.02670079590004
}
#Debug simulation 
Total elapsed time: 21.707479037810117. Arrivals time: 0.3099192576482892 Scheduler time: 21.28695636196062 Scheduler overhead time: 0.04190148925408721 Adapter cache time: 0.011495369486510754 Engine time: 0.04083599429577589 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_16-16-16/adapters_160_slots_96_rate_0.8-0.4-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_16-16-16/adapters_160_slots_96_rate_0.8-0.4-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [53 53 54]
Adapter prompts. [1080, 8640, 1080, 1080, 4320, 1080, 1080, 1080, 8640, 1080, 4320, 8640, 4320, 1080, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 1080, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 1080, 4320, 4320, 4320, 8640, 1080, 1080, 8640, 1080, 8640, 1080, 1080, 4320, 1080, 4320, 8640, 1080, 1080, 4320, 1080, 1080, 1080, 1080, 1080, 8640, 4320, 4320, 8640, 4320, 1080, 8640, 8640, 8640, 4320, 4320, 1080, 1080, 1080, 8640, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 1080, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 1080, 4320, 1080, 1080, 4320, 4320, 8640, 8640, 8640, 1080, 8640, 4320, 4320, 1080, 1080, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 1080, 4320, 4320, 8640, 4320, 8640, 1080, 1080, 1080, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 1080, 8640, 1080, 8640, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 8640, 4320, 1080, 1080]
Prompts retrieved: 752760 . Total input tokens: 167901726 . Total output tokens: 150505799
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 22.265976613853127,
    "estimated_duration": 3600.114750175652,
    "input_throughput": 5401.996144442654,
    "output_throughput": 4779.213495669971,
    "total_throughput": 10181.209640112625,
    "itl": 179.88949469830854,
    "ttft": 1804505.3816452755,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 418,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.249841023269102,
    "arrivals": 250580,
    "finished_requests": 78867,
    "scheduler_time": 94.86332775437482
}
#Debug simulation 
Total elapsed time: 22.26610257383436. Arrivals time: 0.30972123099491 Scheduler time: 21.84737914055586 Scheduler overhead time: 0.04073592182248831 Adapter cache time: 0.012045777402818203 Engine time: 0.039913186337798834 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_16-16-32/adapters_160_slots_96_rate_0.8-0.4-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_16-16-32/adapters_160_slots_96_rate_0.8-0.4-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [53 53 54]
Adapter prompts. [1080, 8640, 1080, 1080, 4320, 1080, 1080, 1080, 8640, 1080, 4320, 8640, 4320, 1080, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 1080, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 1080, 4320, 4320, 4320, 8640, 1080, 1080, 8640, 1080, 8640, 1080, 1080, 4320, 1080, 4320, 8640, 1080, 1080, 4320, 1080, 1080, 1080, 1080, 1080, 8640, 4320, 4320, 8640, 4320, 1080, 8640, 8640, 8640, 4320, 4320, 1080, 1080, 1080, 8640, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 1080, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 1080, 4320, 1080, 1080, 4320, 4320, 8640, 8640, 8640, 1080, 8640, 4320, 4320, 1080, 1080, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 1080, 4320, 4320, 8640, 4320, 8640, 1080, 1080, 1080, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 1080, 8640, 1080, 8640, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 8640, 4320, 1080, 1080]
Prompts retrieved: 752760 . Total input tokens: 167901726 . Total output tokens: 150505799
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 22.012444669846445,
    "estimated_duration": 3600.0512092008908,
    "input_throughput": 5389.2708388186,
    "output_throughput": 4767.35801872375,
    "total_throughput": 10156.62885754235,
    "itl": 177.6170000968551,
    "ttft": 1806181.6675345844,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 347,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1658323441073333,
    "arrivals": 250580,
    "finished_requests": 78630,
    "scheduler_time": 95.03245561877942
}
#Debug simulation 
Total elapsed time: 22.01258405391127. Arrivals time: 0.3168166405521333 Scheduler time: 21.583713282831013 Scheduler overhead time: 0.042178075294941664 Adapter cache time: 0.010924119036644697 Engine time: 0.04251110693439841 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-8/adapters_160_slots_96_rate_0.8-0.4-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-8/adapters_160_slots_96_rate_0.8-0.4-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [53 53 54]
Adapter prompts. [540, 8640, 540, 540, 4320, 540, 540, 540, 8640, 540, 4320, 8640, 4320, 540, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 540, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 540, 4320, 4320, 4320, 8640, 540, 540, 8640, 540, 8640, 540, 540, 4320, 540, 4320, 8640, 540, 540, 4320, 540, 540, 540, 540, 540, 8640, 4320, 4320, 8640, 4320, 540, 8640, 8640, 8640, 4320, 4320, 540, 540, 540, 8640, 540, 4320, 4320, 540, 8640, 8640, 8640, 540, 540, 8640, 4320, 8640, 8640, 540, 8640, 540, 4320, 540, 540, 4320, 4320, 8640, 8640, 8640, 540, 8640, 4320, 4320, 540, 540, 540, 540, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 540, 4320, 4320, 8640, 4320, 8640, 540, 540, 540, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 540, 4320, 4320, 540, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 540, 8640, 540, 8640, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 8640, 4320, 540, 540]
Prompts retrieved: 724140 . Total input tokens: 161448183 . Total output tokens: 144817153
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 18.365139856934547,
    "estimated_duration": 3600.0912208337563,
    "input_throughput": 5419.724613389455,
    "output_throughput": 4772.67656457348,
    "total_throughput": 10192.401177962935,
    "itl": 179.54360369457874,
    "ttft": 1783576.146756503,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 322,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9854770535463454,
    "arrivals": 240851,
    "finished_requests": 78645,
    "scheduler_time": 94.6811503062093
}
#Debug simulation 
Total elapsed time: 18.365234332624823. Arrivals time: 0.30498150968924165 Scheduler time: 17.956809094641358 Scheduler overhead time: 0.03850853815674782 Adapter cache time: 0.010690332390367985 Engine time: 0.03857907513156533 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-16/adapters_160_slots_96_rate_0.8-0.4-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-16/adapters_160_slots_96_rate_0.8-0.4-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [53 53 54]
Adapter prompts. [540, 8640, 540, 540, 4320, 540, 540, 540, 8640, 540, 4320, 8640, 4320, 540, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 540, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 540, 4320, 4320, 4320, 8640, 540, 540, 8640, 540, 8640, 540, 540, 4320, 540, 4320, 8640, 540, 540, 4320, 540, 540, 540, 540, 540, 8640, 4320, 4320, 8640, 4320, 540, 8640, 8640, 8640, 4320, 4320, 540, 540, 540, 8640, 540, 4320, 4320, 540, 8640, 8640, 8640, 540, 540, 8640, 4320, 8640, 8640, 540, 8640, 540, 4320, 540, 540, 4320, 4320, 8640, 8640, 8640, 540, 8640, 4320, 4320, 540, 540, 540, 540, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 540, 4320, 4320, 8640, 4320, 8640, 540, 540, 540, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 540, 4320, 4320, 540, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 540, 8640, 540, 8640, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 8640, 4320, 540, 540]
Prompts retrieved: 724140 . Total input tokens: 161448183 . Total output tokens: 144817153
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 18.50911521119997,
    "estimated_duration": 3600.004231650272,
    "input_throughput": 5413.966969440334,
    "output_throughput": 4773.146889364352,
    "total_throughput": 10187.113858804687,
    "itl": 179.68550438718447,
    "ttft": 1783849.8831063341,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 326,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0638301755581105,
    "arrivals": 240851,
    "finished_requests": 78597,
    "scheduler_time": 94.66195298048972
}
#Debug simulation 
Total elapsed time: 18.50924146315083. Arrivals time: 0.3111076131463051 Scheduler time: 18.092780768405646 Scheduler overhead time: 0.03926674509420991 Adapter cache time: 0.01069218060001731 Engine time: 0.0393808470107615 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-32/adapters_160_slots_96_rate_0.8-0.4-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-32/adapters_160_slots_96_rate_0.8-0.4-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [53 53 54]
Adapter prompts. [540, 8640, 540, 540, 4320, 540, 540, 540, 8640, 540, 4320, 8640, 4320, 540, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 540, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 540, 4320, 4320, 4320, 8640, 540, 540, 8640, 540, 8640, 540, 540, 4320, 540, 4320, 8640, 540, 540, 4320, 540, 540, 540, 540, 540, 8640, 4320, 4320, 8640, 4320, 540, 8640, 8640, 8640, 4320, 4320, 540, 540, 540, 8640, 540, 4320, 4320, 540, 8640, 8640, 8640, 540, 540, 8640, 4320, 8640, 8640, 540, 8640, 540, 4320, 540, 540, 4320, 4320, 8640, 8640, 8640, 540, 8640, 4320, 4320, 540, 540, 540, 540, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 540, 4320, 4320, 8640, 4320, 8640, 540, 540, 540, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 540, 4320, 4320, 540, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 540, 8640, 540, 8640, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 8640, 4320, 540, 540]
Prompts retrieved: 724140 . Total input tokens: 161448183 . Total output tokens: 144817153
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 16.213922010734677,
    "estimated_duration": 3600.0867305424717,
    "input_throughput": 5374.316634056365,
    "output_throughput": 4740.231076996459,
    "total_throughput": 10114.547711052823,
    "itl": 178.07705516975258,
    "ttft": 1786389.7399829146,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 340,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1110143423453034,
    "arrivals": 240851,
    "finished_requests": 78043,
    "scheduler_time": 94.38496491592795
}
#Debug simulation 
Total elapsed time: 16.214056854136288. Arrivals time: 0.2962462743744254 Scheduler time: 15.813946326263249 Scheduler overhead time: 0.03903876431286335 Adapter cache time: 0.010685826651751995 Engine time: 0.03829716145992279 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-16-16/adapters_160_slots_96_rate_0.8-0.4-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-16-16/adapters_160_slots_96_rate_0.8-0.4-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [53 53 54]
Adapter prompts. [540, 8640, 540, 540, 4320, 540, 540, 540, 8640, 540, 4320, 8640, 4320, 540, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 540, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 540, 4320, 4320, 4320, 8640, 540, 540, 8640, 540, 8640, 540, 540, 4320, 540, 4320, 8640, 540, 540, 4320, 540, 540, 540, 540, 540, 8640, 4320, 4320, 8640, 4320, 540, 8640, 8640, 8640, 4320, 4320, 540, 540, 540, 8640, 540, 4320, 4320, 540, 8640, 8640, 8640, 540, 540, 8640, 4320, 8640, 8640, 540, 8640, 540, 4320, 540, 540, 4320, 4320, 8640, 8640, 8640, 540, 8640, 4320, 4320, 540, 540, 540, 540, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 540, 4320, 4320, 8640, 4320, 8640, 540, 540, 540, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 540, 4320, 4320, 540, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 540, 8640, 540, 8640, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 8640, 4320, 540, 540]
Prompts retrieved: 724140 . Total input tokens: 161448183 . Total output tokens: 144817153
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 17.878376157954335,
    "estimated_duration": 3600.018536422661,
    "input_throughput": 5419.1193191427365,
    "output_throughput": 4772.4179267900545,
    "total_throughput": 10191.53724593279,
    "itl": 179.5413882428771,
    "ttft": 1784832.1246986124,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 330,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0320706776645994,
    "arrivals": 240851,
    "finished_requests": 78648,
    "scheduler_time": 94.67665845145157
}
#Debug simulation 
Total elapsed time: 17.87847075331956. Arrivals time: 0.29453359032049775 Scheduler time: 17.479886590968817 Scheduler overhead time: 0.03853600472211838 Adapter cache time: 0.010549668222665787 Engine time: 0.03919320087879896 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-16-32/adapters_160_slots_96_rate_0.8-0.4-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-16-32/adapters_160_slots_96_rate_0.8-0.4-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [53 53 54]
Adapter prompts. [540, 8640, 540, 540, 4320, 540, 540, 540, 8640, 540, 4320, 8640, 4320, 540, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 540, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 540, 4320, 4320, 4320, 8640, 540, 540, 8640, 540, 8640, 540, 540, 4320, 540, 4320, 8640, 540, 540, 4320, 540, 540, 540, 540, 540, 8640, 4320, 4320, 8640, 4320, 540, 8640, 8640, 8640, 4320, 4320, 540, 540, 540, 8640, 540, 4320, 4320, 540, 8640, 8640, 8640, 540, 540, 8640, 4320, 8640, 8640, 540, 8640, 540, 4320, 540, 540, 4320, 4320, 8640, 8640, 8640, 540, 8640, 4320, 4320, 540, 540, 540, 540, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 540, 4320, 4320, 8640, 4320, 8640, 540, 540, 540, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 540, 4320, 4320, 540, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 540, 8640, 540, 8640, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 8640, 4320, 540, 540]
Prompts retrieved: 724140 . Total input tokens: 161448183 . Total output tokens: 144817153
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 16.671924961730838,
    "estimated_duration": 3600.13367138903,
    "input_throughput": 5374.70459882518,
    "output_throughput": 4738.601551263495,
    "total_throughput": 10113.306150088676,
    "itl": 178.34155023051449,
    "ttft": 1786843.320141446,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 346,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.143657113146042,
    "arrivals": 240851,
    "finished_requests": 78024,
    "scheduler_time": 94.3426960474198
}
#Debug simulation 
Total elapsed time: 16.672031772788614. Arrivals time: 0.2973654782399535 Scheduler time: 16.270484924316406 Scheduler overhead time: 0.03890406899154186 Adapter cache time: 0.010789747349917889 Engine time: 0.03865464497357607 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_16-16-16/adapters_160_slots_96_rate_0.8-0.4-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_16-16-16/adapters_160_slots_96_rate_0.8-0.4-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [53 53 54]
Adapter prompts. [540, 8640, 540, 540, 4320, 540, 540, 540, 8640, 540, 4320, 8640, 4320, 540, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 540, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 540, 4320, 4320, 4320, 8640, 540, 540, 8640, 540, 8640, 540, 540, 4320, 540, 4320, 8640, 540, 540, 4320, 540, 540, 540, 540, 540, 8640, 4320, 4320, 8640, 4320, 540, 8640, 8640, 8640, 4320, 4320, 540, 540, 540, 8640, 540, 4320, 4320, 540, 8640, 8640, 8640, 540, 540, 8640, 4320, 8640, 8640, 540, 8640, 540, 4320, 540, 540, 4320, 4320, 8640, 8640, 8640, 540, 8640, 4320, 4320, 540, 540, 540, 540, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 540, 4320, 4320, 8640, 4320, 8640, 540, 540, 540, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 540, 4320, 4320, 540, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 540, 8640, 540, 8640, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 8640, 4320, 540, 540]
Prompts retrieved: 724140 . Total input tokens: 161448183 . Total output tokens: 144817153
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 18.020714351907372,
    "estimated_duration": 3600.140575249467,
    "input_throughput": 5409.465156412821,
    "output_throughput": 4772.1086554542435,
    "total_throughput": 10181.573811867063,
    "itl": 179.70023177303145,
    "ttft": 1787942.7961677082,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 450,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3455226327059682,
    "arrivals": 240851,
    "finished_requests": 78579,
    "scheduler_time": 94.64879993633092
}
#Debug simulation 
Total elapsed time: 18.0208599739708. Arrivals time: 0.30024378513917327 Scheduler time: 17.615374316927046 Scheduler overhead time: 0.038821445778012276 Adapter cache time: 0.012530631851404905 Engine time: 0.038242042530328035 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_16-16-32/adapters_160_slots_96_rate_0.8-0.4-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_16-16-32/adapters_160_slots_96_rate_0.8-0.4-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [53 53 54]
Adapter prompts. [540, 8640, 540, 540, 4320, 540, 540, 540, 8640, 540, 4320, 8640, 4320, 540, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 540, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 540, 4320, 4320, 4320, 8640, 540, 540, 8640, 540, 8640, 540, 540, 4320, 540, 4320, 8640, 540, 540, 4320, 540, 540, 540, 540, 540, 8640, 4320, 4320, 8640, 4320, 540, 8640, 8640, 8640, 4320, 4320, 540, 540, 540, 8640, 540, 4320, 4320, 540, 8640, 8640, 8640, 540, 540, 8640, 4320, 8640, 8640, 540, 8640, 540, 4320, 540, 540, 4320, 4320, 8640, 8640, 8640, 540, 8640, 4320, 4320, 540, 540, 540, 540, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 540, 4320, 4320, 8640, 4320, 8640, 540, 540, 540, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 540, 4320, 4320, 540, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 540, 8640, 540, 8640, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 8640, 4320, 540, 540]
Prompts retrieved: 724140 . Total input tokens: 161448183 . Total output tokens: 144817153
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 16.59881469188258,
    "estimated_duration": 3600.1748965269608,
    "input_throughput": 5374.643053776734,
    "output_throughput": 4738.54729014892,
    "total_throughput": 10113.190343925655,
    "itl": 178.34193798208372,
    "ttft": 1786858.6416901909,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 346,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1586218137294093,
    "arrivals": 240851,
    "finished_requests": 78024,
    "scheduler_time": 94.34320808355726
}
#Debug simulation 
Total elapsed time: 16.598923683632165. Arrivals time: 0.2893739202991128 Scheduler time: 16.20667822100222 Scheduler overhead time: 0.03831387357786298 Adapter cache time: 0.010733623523265123 Engine time: 0.03797423467040062 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-8/adapters_160_slots_96_rate_0.8-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-8/adapters_160_slots_96_rate_0.8-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [53 53 54]
Adapter prompts. [270, 8640, 270, 270, 4320, 270, 270, 270, 8640, 270, 4320, 8640, 4320, 270, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 270, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 270, 4320, 4320, 4320, 8640, 270, 270, 8640, 270, 8640, 270, 270, 4320, 270, 4320, 8640, 270, 270, 4320, 270, 270, 270, 270, 270, 8640, 4320, 4320, 8640, 4320, 270, 8640, 8640, 8640, 4320, 4320, 270, 270, 270, 8640, 270, 4320, 4320, 270, 8640, 8640, 8640, 270, 270, 8640, 4320, 8640, 8640, 270, 8640, 270, 4320, 270, 270, 4320, 4320, 8640, 8640, 8640, 270, 8640, 4320, 4320, 270, 270, 270, 270, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 270, 4320, 4320, 8640, 4320, 8640, 270, 270, 270, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 270, 4320, 4320, 270, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 270, 8640, 270, 8640, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 8640, 4320, 270, 270]
Prompts retrieved: 709830 . Total input tokens: 158254628 . Total output tokens: 141942651
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 18.77460052492097,
    "estimated_duration": 3600.0129509288718,
    "input_throughput": 5408.459154286163,
    "output_throughput": 4761.959535611323,
    "total_throughput": 10170.418689897486,
    "itl": 179.82764077732287,
    "ttft": 1780776.3950536991,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 321,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9824165658024127,
    "arrivals": 236027,
    "finished_requests": 78785,
    "scheduler_time": 94.4344605159439
}
#Debug simulation 
Total elapsed time: 18.774686270859092. Arrivals time: 0.2925419402308762 Scheduler time: 18.380006551742554 Scheduler overhead time: 0.03821602929383516 Adapter cache time: 0.010105608496814966 Engine time: 0.038207927253097296 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-16/adapters_160_slots_96_rate_0.8-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-16/adapters_160_slots_96_rate_0.8-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [53 53 54]
Adapter prompts. [270, 8640, 270, 270, 4320, 270, 270, 270, 8640, 270, 4320, 8640, 4320, 270, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 270, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 270, 4320, 4320, 4320, 8640, 270, 270, 8640, 270, 8640, 270, 270, 4320, 270, 4320, 8640, 270, 270, 4320, 270, 270, 270, 270, 270, 8640, 4320, 4320, 8640, 4320, 270, 8640, 8640, 8640, 4320, 4320, 270, 270, 270, 8640, 270, 4320, 4320, 270, 8640, 8640, 8640, 270, 270, 8640, 4320, 8640, 8640, 270, 8640, 270, 4320, 270, 270, 4320, 4320, 8640, 8640, 8640, 270, 8640, 4320, 4320, 270, 270, 270, 270, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 270, 4320, 4320, 8640, 4320, 8640, 270, 270, 270, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 270, 4320, 4320, 270, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 270, 8640, 270, 8640, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 8640, 4320, 270, 270]
Prompts retrieved: 709830 . Total input tokens: 158254628 . Total output tokens: 141942651
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 18.78554796706885,
    "estimated_duration": 3600.0289957231635,
    "input_throughput": 5408.435049587376,
    "output_throughput": 4761.938312265271,
    "total_throughput": 10170.373361852648,
    "itl": 179.83110999763082,
    "ttft": 1780782.875936978,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0454812784702574,
    "arrivals": 236027,
    "finished_requests": 78785,
    "scheduler_time": 94.43376111853804
}
#Debug simulation 
Total elapsed time: 18.785681087058038. Arrivals time: 0.2964210552163422 Scheduler time: 18.384202191140503 Scheduler overhead time: 0.039609163999557495 Adapter cache time: 0.010417678859084845 Engine time: 0.03898386284708977 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-32/adapters_160_slots_96_rate_0.8-0.4-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-32/adapters_160_slots_96_rate_0.8-0.4-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [53 53 54]
Adapter prompts. [270, 8640, 270, 270, 4320, 270, 270, 270, 8640, 270, 4320, 8640, 4320, 270, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 270, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 270, 4320, 4320, 4320, 8640, 270, 270, 8640, 270, 8640, 270, 270, 4320, 270, 4320, 8640, 270, 270, 4320, 270, 270, 270, 270, 270, 8640, 4320, 4320, 8640, 4320, 270, 8640, 8640, 8640, 4320, 4320, 270, 270, 270, 8640, 270, 4320, 4320, 270, 8640, 8640, 8640, 270, 270, 8640, 4320, 8640, 8640, 270, 8640, 270, 4320, 270, 270, 4320, 4320, 8640, 8640, 8640, 270, 8640, 4320, 4320, 270, 270, 270, 270, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 270, 4320, 4320, 8640, 4320, 8640, 270, 270, 270, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 270, 4320, 4320, 270, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 270, 8640, 270, 8640, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 8640, 4320, 270, 270]
Prompts retrieved: 709830 . Total input tokens: 158254628 . Total output tokens: 141942651
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 19.49978233408183,
    "estimated_duration": 3600.143644223788,
    "input_throughput": 5403.094965727109,
    "output_throughput": 4761.401958919852,
    "total_throughput": 10164.49692464696,
    "itl": 177.71114803680527,
    "ttft": 1783407.8473331325,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0471087379194852,
    "arrivals": 236027,
    "finished_requests": 78750,
    "scheduler_time": 94.73538446702345
}
#Debug simulation 
Total elapsed time: 19.499885936733335. Arrivals time: 0.30029262509196997 Scheduler time: 19.09404691355303 Scheduler overhead time: 0.039430458564311266 Adapter cache time: 0.01038903882727027 Engine time: 0.03970955405384302 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-16-16/adapters_160_slots_96_rate_0.8-0.4-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-16-16/adapters_160_slots_96_rate_0.8-0.4-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [53 53 54]
Adapter prompts. [270, 8640, 270, 270, 4320, 270, 270, 270, 8640, 270, 4320, 8640, 4320, 270, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 270, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 270, 4320, 4320, 4320, 8640, 270, 270, 8640, 270, 8640, 270, 270, 4320, 270, 4320, 8640, 270, 270, 4320, 270, 270, 270, 270, 270, 8640, 4320, 4320, 8640, 4320, 270, 8640, 8640, 8640, 4320, 4320, 270, 270, 270, 8640, 270, 4320, 4320, 270, 8640, 8640, 8640, 270, 270, 8640, 4320, 8640, 8640, 270, 8640, 270, 4320, 270, 270, 4320, 4320, 8640, 8640, 8640, 270, 8640, 4320, 4320, 270, 270, 270, 270, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 270, 4320, 4320, 8640, 4320, 8640, 270, 270, 270, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 270, 4320, 4320, 270, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 270, 8640, 270, 8640, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 8640, 4320, 270, 270]
Prompts retrieved: 709830 . Total input tokens: 158254628 . Total output tokens: 141942651
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 18.822854240890592,
    "estimated_duration": 3600.1199416049603,
    "input_throughput": 5407.898713319129,
    "output_throughput": 4761.613579006981,
    "total_throughput": 10169.51229232611,
    "itl": 179.8376760577601,
    "ttft": 1780815.126986114,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 318,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9974158600810952,
    "arrivals": 236027,
    "finished_requests": 78782,
    "scheduler_time": 94.43266695722963
}
#Debug simulation 
Total elapsed time: 18.822948039043695. Arrivals time: 0.2982466728426516 Scheduler time: 18.42110686004162 Scheduler overhead time: 0.039633148815482855 Adapter cache time: 0.010289852507412434 Engine time: 0.037795488722622395 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-16-32/adapters_160_slots_96_rate_0.8-0.4-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-16-32/adapters_160_slots_96_rate_0.8-0.4-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [53 53 54]
Adapter prompts. [270, 8640, 270, 270, 4320, 270, 270, 270, 8640, 270, 4320, 8640, 4320, 270, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 270, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 270, 4320, 4320, 4320, 8640, 270, 270, 8640, 270, 8640, 270, 270, 4320, 270, 4320, 8640, 270, 270, 4320, 270, 270, 270, 270, 270, 8640, 4320, 4320, 8640, 4320, 270, 8640, 8640, 8640, 4320, 4320, 270, 270, 270, 8640, 270, 4320, 4320, 270, 8640, 8640, 8640, 270, 270, 8640, 4320, 8640, 8640, 270, 8640, 270, 4320, 270, 270, 4320, 4320, 8640, 8640, 8640, 270, 8640, 4320, 4320, 270, 270, 270, 270, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 270, 4320, 4320, 8640, 4320, 8640, 270, 270, 270, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 270, 4320, 4320, 270, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 270, 8640, 270, 8640, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 8640, 4320, 270, 270]
Prompts retrieved: 709830 . Total input tokens: 158254628 . Total output tokens: 141942651
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 19.526251350995153,
    "estimated_duration": 3600.129020597205,
    "input_throughput": 5403.116912952534,
    "output_throughput": 4761.421299605661,
    "total_throughput": 10164.538212558195,
    "itl": 177.72955508870982,
    "ttft": 1783471.1796439998,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 321,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0629791429825182,
    "arrivals": 236027,
    "finished_requests": 78750,
    "scheduler_time": 94.73307669438024
}
#Debug simulation 
Total elapsed time: 19.526379263028502. Arrivals time: 0.29736420325934887 Scheduler time: 19.122758209705353 Scheduler overhead time: 0.04014594154432416 Adapter cache time: 0.010467133950442076 Engine time: 0.03957743151113391 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_16-16-16/adapters_160_slots_96_rate_0.8-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_16-16-16/adapters_160_slots_96_rate_0.8-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [53 53 54]
Adapter prompts. [270, 8640, 270, 270, 4320, 270, 270, 270, 8640, 270, 4320, 8640, 4320, 270, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 270, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 270, 4320, 4320, 4320, 8640, 270, 270, 8640, 270, 8640, 270, 270, 4320, 270, 4320, 8640, 270, 270, 4320, 270, 270, 270, 270, 270, 8640, 4320, 4320, 8640, 4320, 270, 8640, 8640, 8640, 4320, 4320, 270, 270, 270, 8640, 270, 4320, 4320, 270, 8640, 8640, 8640, 270, 270, 8640, 4320, 8640, 8640, 270, 8640, 270, 4320, 270, 270, 4320, 4320, 8640, 8640, 8640, 270, 8640, 4320, 4320, 270, 270, 270, 270, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 270, 4320, 4320, 8640, 4320, 8640, 270, 270, 270, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 270, 4320, 4320, 270, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 270, 8640, 270, 8640, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 8640, 4320, 270, 270]
Prompts retrieved: 709830 . Total input tokens: 158254628 . Total output tokens: 141942651
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 18.830249638762325,
    "estimated_duration": 3600.1688799744484,
    "input_throughput": 5408.3896198053335,
    "output_throughput": 4762.071050434078,
    "total_throughput": 10170.460670239412,
    "itl": 179.82738183915384,
    "ttft": 1780784.8767814892,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9568160943686975,
    "arrivals": 236027,
    "finished_requests": 78788,
    "scheduler_time": 94.43927537776892
}
#Debug simulation 
Total elapsed time: 18.83035713294521. Arrivals time: 0.2905686958692968 Scheduler time: 18.43417256884277 Scheduler overhead time: 0.0400980357080698 Adapter cache time: 0.010161833837628365 Engine time: 0.03947825636714697 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_16-16-32/adapters_160_slots_96_rate_0.8-0.4-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_16-16-32/adapters_160_slots_96_rate_0.8-0.4-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [53 53 54]
Adapter prompts. [270, 8640, 270, 270, 4320, 270, 270, 270, 8640, 270, 4320, 8640, 4320, 270, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 270, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 270, 4320, 4320, 4320, 8640, 270, 270, 8640, 270, 8640, 270, 270, 4320, 270, 4320, 8640, 270, 270, 4320, 270, 270, 270, 270, 270, 8640, 4320, 4320, 8640, 4320, 270, 8640, 8640, 8640, 4320, 4320, 270, 270, 270, 8640, 270, 4320, 4320, 270, 8640, 8640, 8640, 270, 270, 8640, 4320, 8640, 8640, 270, 8640, 270, 4320, 270, 270, 4320, 4320, 8640, 8640, 8640, 270, 8640, 4320, 4320, 270, 270, 270, 270, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 270, 4320, 4320, 8640, 4320, 8640, 270, 270, 270, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 270, 4320, 4320, 270, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 270, 8640, 270, 8640, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 8640, 4320, 270, 270]
Prompts retrieved: 709830 . Total input tokens: 158254628 . Total output tokens: 141942651
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 19.505379223730415,
    "estimated_duration": 3600.179109579197,
    "input_throughput": 5402.70203453113,
    "output_throughput": 4761.408662805005,
    "total_throughput": 10164.110697336137,
    "itl": 177.71643483455222,
    "ttft": 1783282.9765402193,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 321,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0774408284202264,
    "arrivals": 236027,
    "finished_requests": 78741,
    "scheduler_time": 94.73634355846264
}
#Debug simulation 
Total elapsed time: 19.505466856993735. Arrivals time: 0.296399166341871 Scheduler time: 19.102729118429124 Scheduler overhead time: 0.03996498743072152 Adapter cache time: 0.010065989103168249 Engine time: 0.040243135299533606 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-8/adapters_160_slots_96_rate_0.8-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-8/adapters_160_slots_96_rate_0.8-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 4320, 135, 135, 135, 8640, 135, 4320, 8640, 4320, 135, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 135, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 135, 4320, 4320, 4320, 8640, 135, 135, 8640, 135, 8640, 135, 135, 4320, 135, 4320, 8640, 135, 135, 4320, 135, 135, 135, 135, 135, 8640, 4320, 4320, 8640, 4320, 135, 8640, 8640, 8640, 4320, 4320, 135, 135, 135, 8640, 135, 4320, 4320, 135, 8640, 8640, 8640, 135, 135, 8640, 4320, 8640, 8640, 135, 8640, 135, 4320, 135, 135, 4320, 4320, 8640, 8640, 8640, 135, 8640, 4320, 4320, 135, 135, 135, 135, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 135, 4320, 4320, 8640, 4320, 8640, 135, 135, 135, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 135, 4320, 4320, 135, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 135, 8640, 135, 8640, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 8640, 4320, 135, 135]
Prompts retrieved: 702675 . Total input tokens: 156663449 . Total output tokens: 140515378
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 15.986855090595782,
    "estimated_duration": 3600.052918230198,
    "input_throughput": 5407.474679447257,
    "output_throughput": 4778.502536139664,
    "total_throughput": 10185.977215586921,
    "itl": 179.89250369978225,
    "ttft": 1773232.5331948528,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 298,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9120253476919594,
    "arrivals": 233648,
    "finished_requests": 78367,
    "scheduler_time": 94.58232593375817
}
#Debug simulation 
Total elapsed time: 15.986954990774393. Arrivals time: 0.2926691686734557 Scheduler time: 15.594872293062508 Scheduler overhead time: 0.037078418768942356 Adapter cache time: 0.009587062522768974 Engine time: 0.03735546721145511 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-16/adapters_160_slots_96_rate_0.8-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-16/adapters_160_slots_96_rate_0.8-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 4320, 135, 135, 135, 8640, 135, 4320, 8640, 4320, 135, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 135, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 135, 4320, 4320, 4320, 8640, 135, 135, 8640, 135, 8640, 135, 135, 4320, 135, 4320, 8640, 135, 135, 4320, 135, 135, 135, 135, 135, 8640, 4320, 4320, 8640, 4320, 135, 8640, 8640, 8640, 4320, 4320, 135, 135, 135, 8640, 135, 4320, 4320, 135, 8640, 8640, 8640, 135, 135, 8640, 4320, 8640, 8640, 135, 8640, 135, 4320, 135, 135, 4320, 4320, 8640, 8640, 8640, 135, 8640, 4320, 4320, 135, 135, 135, 135, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 135, 4320, 4320, 8640, 4320, 8640, 135, 135, 135, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 135, 4320, 4320, 135, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 135, 8640, 135, 8640, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 8640, 4320, 135, 135]
Prompts retrieved: 702675 . Total input tokens: 156663449 . Total output tokens: 140515378
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 18.693245977163315,
    "estimated_duration": 3600.1140191899344,
    "input_throughput": 5416.384563394364,
    "output_throughput": 4783.897095535677,
    "total_throughput": 10200.28165893004,
    "itl": 179.5802328545915,
    "ttft": 1775925.681846555,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 313,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0229165451321809,
    "arrivals": 233648,
    "finished_requests": 78478,
    "scheduler_time": 94.74003798925133
}
#Debug simulation 
Total elapsed time: 18.69333899533376. Arrivals time: 0.31142598390579224 Scheduler time: 18.2768452973105 Scheduler overhead time: 0.03977483930066228 Adapter cache time: 0.010176589712500572 Engine time: 0.0392231666482985 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-32/adapters_160_slots_96_rate_0.8-0.4-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-32/adapters_160_slots_96_rate_0.8-0.4-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 4320, 135, 135, 135, 8640, 135, 4320, 8640, 4320, 135, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 135, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 135, 4320, 4320, 4320, 8640, 135, 135, 8640, 135, 8640, 135, 135, 4320, 135, 4320, 8640, 135, 135, 4320, 135, 135, 135, 135, 135, 8640, 4320, 4320, 8640, 4320, 135, 8640, 8640, 8640, 4320, 4320, 135, 135, 135, 8640, 135, 4320, 4320, 135, 8640, 8640, 8640, 135, 135, 8640, 4320, 8640, 8640, 135, 8640, 135, 4320, 135, 135, 4320, 4320, 8640, 8640, 8640, 135, 8640, 4320, 4320, 135, 135, 135, 135, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 135, 4320, 4320, 8640, 4320, 8640, 135, 135, 135, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 135, 4320, 4320, 135, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 135, 8640, 135, 8640, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 8640, 4320, 135, 135]
Prompts retrieved: 702675 . Total input tokens: 156663449 . Total output tokens: 140515378
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 14.683905343990773,
    "estimated_duration": 3600.036884465854,
    "input_throughput": 5370.512475421106,
    "output_throughput": 4751.677149146234,
    "total_throughput": 10122.18962456734,
    "itl": 177.57127382439324,
    "ttft": 1775105.7653957095,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 311,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0180308308079893,
    "arrivals": 233648,
    "finished_requests": 77855,
    "scheduler_time": 94.52951539298859
}
#Debug simulation 
Total elapsed time: 14.683998077176511. Arrivals time: 0.3080061813816428 Scheduler time: 14.275480363052338 Scheduler overhead time: 0.03794262744486332 Adapter cache time: 0.009742643684148788 Engine time: 0.037094120401889086 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-16/adapters_160_slots_96_rate_0.8-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-16/adapters_160_slots_96_rate_0.8-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 4320, 135, 135, 135, 8640, 135, 4320, 8640, 4320, 135, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 135, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 135, 4320, 4320, 4320, 8640, 135, 135, 8640, 135, 8640, 135, 135, 4320, 135, 4320, 8640, 135, 135, 4320, 135, 135, 135, 135, 135, 8640, 4320, 4320, 8640, 4320, 135, 8640, 8640, 8640, 4320, 4320, 135, 135, 135, 8640, 135, 4320, 4320, 135, 8640, 8640, 8640, 135, 135, 8640, 4320, 8640, 8640, 135, 8640, 135, 4320, 135, 135, 4320, 4320, 8640, 8640, 8640, 135, 8640, 4320, 4320, 135, 135, 135, 135, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 135, 4320, 4320, 8640, 4320, 8640, 135, 135, 135, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 135, 4320, 4320, 135, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 135, 8640, 135, 8640, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 8640, 4320, 135, 135]
Prompts retrieved: 702675 . Total input tokens: 156663449 . Total output tokens: 140515378
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 15.887788632884622,
    "estimated_duration": 3600.0881739653023,
    "input_throughput": 5407.42172394015,
    "output_throughput": 4778.455740169269,
    "total_throughput": 10185.877464109419,
    "itl": 179.89151572619184,
    "ttft": 1773271.3660102403,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 299,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9365189512935499,
    "arrivals": 233648,
    "finished_requests": 78367,
    "scheduler_time": 94.58331128723424
}
#Debug simulation 
Total elapsed time: 15.887895666994154. Arrivals time: 0.2846330157481134 Scheduler time: 15.504554143641144 Scheduler overhead time: 0.03689051605761051 Adapter cache time: 0.009572166949510574 Engine time: 0.03682979242876172 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-32/adapters_160_slots_96_rate_0.8-0.4-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-32/adapters_160_slots_96_rate_0.8-0.4-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 4320, 135, 135, 135, 8640, 135, 4320, 8640, 4320, 135, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 135, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 135, 4320, 4320, 4320, 8640, 135, 135, 8640, 135, 8640, 135, 135, 4320, 135, 4320, 8640, 135, 135, 4320, 135, 135, 135, 135, 135, 8640, 4320, 4320, 8640, 4320, 135, 8640, 8640, 8640, 4320, 4320, 135, 135, 135, 8640, 135, 4320, 4320, 135, 8640, 8640, 8640, 135, 135, 8640, 4320, 8640, 8640, 135, 8640, 135, 4320, 135, 135, 4320, 4320, 8640, 8640, 8640, 135, 8640, 4320, 4320, 135, 135, 135, 135, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 135, 4320, 4320, 8640, 4320, 8640, 135, 135, 135, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 135, 4320, 4320, 135, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 135, 8640, 135, 8640, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 8640, 4320, 135, 135]
Prompts retrieved: 702675 . Total input tokens: 156663449 . Total output tokens: 140515378
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 14.669133980292827,
    "estimated_duration": 3600.140924482382,
    "input_throughput": 5371.5730594019515,
    "output_throughput": 4750.350155378672,
    "total_throughput": 10121.923214780623,
    "itl": 177.5154206163142,
    "ttft": 1775657.3930007447,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 312,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0342784972302668,
    "arrivals": 233648,
    "finished_requests": 77840,
    "scheduler_time": 94.54018456157273
}
#Debug simulation 
Total elapsed time: 14.669225680176169. Arrivals time: 0.3057727203704417 Scheduler time: 14.262989988550544 Scheduler overhead time: 0.03745009610429406 Adapter cache time: 0.00990361999720335 Engine time: 0.03725501801818609 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-16/adapters_160_slots_96_rate_0.8-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-16/adapters_160_slots_96_rate_0.8-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 4320, 135, 135, 135, 8640, 135, 4320, 8640, 4320, 135, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 135, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 135, 4320, 4320, 4320, 8640, 135, 135, 8640, 135, 8640, 135, 135, 4320, 135, 4320, 8640, 135, 135, 4320, 135, 135, 135, 135, 135, 8640, 4320, 4320, 8640, 4320, 135, 8640, 8640, 8640, 4320, 4320, 135, 135, 135, 8640, 135, 4320, 4320, 135, 8640, 8640, 8640, 135, 135, 8640, 4320, 8640, 8640, 135, 8640, 135, 4320, 135, 135, 4320, 4320, 8640, 8640, 8640, 135, 8640, 4320, 4320, 135, 135, 135, 135, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 135, 4320, 4320, 8640, 4320, 8640, 135, 135, 135, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 135, 4320, 4320, 135, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 135, 8640, 135, 8640, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 8640, 4320, 135, 135]
Prompts retrieved: 702675 . Total input tokens: 156663449 . Total output tokens: 140515378
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 18.42618119297549,
    "estimated_duration": 3600.189251221991,
    "input_throughput": 5417.624363324709,
    "output_throughput": 4785.742303450261,
    "total_throughput": 10203.36666677497,
    "itl": 179.5226913560867,
    "ttft": 1775878.2286108339,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 314,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9388757925992844,
    "arrivals": 233648,
    "finished_requests": 78509,
    "scheduler_time": 94.77333645960884
}
#Debug simulation 
Total elapsed time: 18.42628003563732. Arrivals time: 0.3152818982489407 Scheduler time: 18.007132267579436 Scheduler overhead time: 0.03921117167919874 Adapter cache time: 0.010101202875375748 Engine time: 0.03870265418663621 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-32/adapters_160_slots_96_rate_0.8-0.4-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-32/adapters_160_slots_96_rate_0.8-0.4-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 4320, 135, 135, 135, 8640, 135, 4320, 8640, 4320, 135, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 135, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 135, 4320, 4320, 4320, 8640, 135, 135, 8640, 135, 8640, 135, 135, 4320, 135, 4320, 8640, 135, 135, 4320, 135, 135, 135, 135, 135, 8640, 4320, 4320, 8640, 4320, 135, 8640, 8640, 8640, 4320, 4320, 135, 135, 135, 8640, 135, 4320, 4320, 135, 8640, 8640, 8640, 135, 135, 8640, 4320, 8640, 8640, 135, 8640, 135, 4320, 135, 135, 4320, 4320, 8640, 8640, 8640, 135, 8640, 4320, 4320, 135, 135, 135, 135, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 135, 4320, 4320, 8640, 4320, 8640, 135, 135, 135, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 135, 4320, 4320, 135, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 135, 8640, 135, 8640, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 8640, 4320, 135, 135]
Prompts retrieved: 702675 . Total input tokens: 156663449 . Total output tokens: 140515378
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 14.63477905280888,
    "estimated_duration": 3600.125577381603,
    "input_throughput": 5372.472871923336,
    "output_throughput": 4753.248360976867,
    "total_throughput": 10125.721232900203,
    "itl": 177.6806261320407,
    "ttft": 1774892.5420291512,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 309,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0381405945494822,
    "arrivals": 233648,
    "finished_requests": 77879,
    "scheduler_time": 94.53926192706719
}
#Debug simulation 
Total elapsed time: 14.634906415827572. Arrivals time: 0.3096358650363982 Scheduler time: 14.225874302443117 Scheduler overhead time: 0.037283191457390785 Adapter cache time: 0.009870046749711037 Engine time: 0.036500709131360054 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-8/adapters_160_slots_96_rate_0.8-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-8/adapters_160_slots_96_rate_0.8-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 4320, 66, 66, 66, 8640, 66, 4320, 8640, 4320, 66, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 66, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 66, 4320, 4320, 4320, 8640, 66, 66, 8640, 66, 8640, 66, 66, 4320, 66, 4320, 8640, 66, 66, 4320, 66, 66, 66, 66, 66, 8640, 4320, 4320, 8640, 4320, 66, 8640, 8640, 8640, 4320, 4320, 66, 66, 66, 8640, 66, 4320, 4320, 66, 8640, 8640, 8640, 66, 66, 8640, 4320, 8640, 8640, 66, 8640, 66, 4320, 66, 66, 4320, 4320, 8640, 8640, 8640, 66, 8640, 4320, 4320, 66, 66, 66, 66, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 66, 4320, 4320, 8640, 4320, 8640, 66, 66, 66, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 66, 4320, 4320, 66, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 66, 8640, 66, 8640, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 8640, 4320, 66, 66]
Prompts retrieved: 699018 . Total input tokens: 155862900 . Total output tokens: 139789936
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 12.659972181078047,
    "estimated_duration": 3600.0770277802253,
    "input_throughput": 5374.811386169387,
    "output_throughput": 4749.521431918602,
    "total_throughput": 10124.332818087989,
    "itl": 180.93646694821942,
    "ttft": 1774586.0400192721,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 300,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9181463231798249,
    "arrivals": 232444,
    "finished_requests": 78173,
    "scheduler_time": 94.04137107469205
}
#Debug simulation 
Total elapsed time: 12.660079260822386. Arrivals time: 0.27098382404074073 Scheduler time: 12.294599713291973 Scheduler overhead time: 0.03525955928489566 Adapter cache time: 0.009251052048057318 Engine time: 0.03479347191751003 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-16/adapters_160_slots_96_rate_0.8-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-16/adapters_160_slots_96_rate_0.8-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 4320, 66, 66, 66, 8640, 66, 4320, 8640, 4320, 66, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 66, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 66, 4320, 4320, 4320, 8640, 66, 66, 8640, 66, 8640, 66, 66, 4320, 66, 4320, 8640, 66, 66, 4320, 66, 66, 66, 66, 66, 8640, 4320, 4320, 8640, 4320, 66, 8640, 8640, 8640, 4320, 4320, 66, 66, 66, 8640, 66, 4320, 4320, 66, 8640, 8640, 8640, 66, 66, 8640, 4320, 8640, 8640, 66, 8640, 66, 4320, 66, 66, 4320, 4320, 8640, 8640, 8640, 66, 8640, 4320, 4320, 66, 66, 66, 66, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 66, 4320, 4320, 8640, 4320, 8640, 66, 66, 66, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 66, 4320, 4320, 66, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 66, 8640, 66, 8640, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 8640, 4320, 66, 66]
Prompts retrieved: 699018 . Total input tokens: 155862900 . Total output tokens: 139789936
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 12.750330422073603,
    "estimated_duration": 3600.162296467827,
    "input_throughput": 5374.684085488122,
    "output_throughput": 4749.408941029056,
    "total_throughput": 10124.09302651718,
    "itl": 180.94371403478814,
    "ttft": 1774607.673017148,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 303,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9901558749540764,
    "arrivals": 232444,
    "finished_requests": 78173,
    "scheduler_time": 94.0410024229598
}
#Debug simulation 
Total elapsed time: 12.750422195065767. Arrivals time: 0.2719035670161247 Scheduler time: 12.383183853700757 Scheduler overhead time: 0.03567615384235978 Adapter cache time: 0.009348359890282154 Engine time: 0.03503461042419076 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-32/adapters_160_slots_96_rate_0.8-0.4-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-32/adapters_160_slots_96_rate_0.8-0.4-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 4320, 66, 66, 66, 8640, 66, 4320, 8640, 4320, 66, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 66, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 66, 4320, 4320, 4320, 8640, 66, 66, 8640, 66, 8640, 66, 66, 4320, 66, 4320, 8640, 66, 66, 4320, 66, 66, 66, 66, 66, 8640, 4320, 4320, 8640, 4320, 66, 8640, 8640, 8640, 4320, 4320, 66, 66, 66, 8640, 66, 4320, 4320, 66, 8640, 8640, 8640, 66, 66, 8640, 4320, 8640, 8640, 66, 8640, 66, 4320, 66, 66, 4320, 4320, 8640, 8640, 8640, 66, 8640, 4320, 4320, 66, 66, 66, 66, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 66, 4320, 4320, 8640, 4320, 8640, 66, 66, 66, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 66, 4320, 4320, 66, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 66, 8640, 66, 8640, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 8640, 4320, 66, 66]
Prompts retrieved: 699018 . Total input tokens: 155862900 . Total output tokens: 139789936
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 12.90592702711001,
    "estimated_duration": 3600.079346025808,
    "input_throughput": 5357.50302872956,
    "output_throughput": 4735.74451041496,
    "total_throughput": 10093.24753914452,
    "itl": 178.8361875240191,
    "ttft": 1778488.169015517,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 239,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7823723464645482,
    "arrivals": 232444,
    "finished_requests": 77939,
    "scheduler_time": 94.10998818709885
}
#Debug simulation 
Total elapsed time: 12.906021110713482. Arrivals time: 0.2727747275494039 Scheduler time: 12.537676135078073 Scheduler overhead time: 0.03568424331024289 Adapter cache time: 0.008679807651787996 Engine time: 0.03566630557179451 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-16/adapters_160_slots_96_rate_0.8-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-16/adapters_160_slots_96_rate_0.8-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 4320, 66, 66, 66, 8640, 66, 4320, 8640, 4320, 66, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 66, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 66, 4320, 4320, 4320, 8640, 66, 66, 8640, 66, 8640, 66, 66, 4320, 66, 4320, 8640, 66, 66, 4320, 66, 66, 66, 66, 66, 8640, 4320, 4320, 8640, 4320, 66, 8640, 8640, 8640, 4320, 4320, 66, 66, 66, 8640, 66, 4320, 4320, 66, 8640, 8640, 8640, 66, 66, 8640, 4320, 8640, 8640, 66, 8640, 66, 4320, 66, 66, 4320, 4320, 8640, 8640, 8640, 66, 8640, 4320, 4320, 66, 66, 66, 66, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 66, 4320, 4320, 8640, 4320, 8640, 66, 66, 66, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 66, 4320, 4320, 66, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 66, 8640, 66, 8640, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 8640, 4320, 66, 66]
Prompts retrieved: 699018 . Total input tokens: 155862900 . Total output tokens: 139789936
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 12.775574500206858,
    "estimated_duration": 3600.1763284498334,
    "input_throughput": 5374.723689806526,
    "output_throughput": 4749.540422472191,
    "total_throughput": 10124.264112278715,
    "itl": 180.9402455518009,
    "ttft": 1774593.2477704983,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 301,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9424990518833544,
    "arrivals": 232444,
    "finished_requests": 78174,
    "scheduler_time": 94.0423592776941
}
#Debug simulation 
Total elapsed time: 12.775670603848994. Arrivals time: 0.27649121452122927 Scheduler time: 12.403985838405788 Scheduler overhead time: 0.0355945797637105 Adapter cache time: 0.00934896431863308 Engine time: 0.03500815946608782 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-32/adapters_160_slots_96_rate_0.8-0.4-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-32/adapters_160_slots_96_rate_0.8-0.4-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 4320, 66, 66, 66, 8640, 66, 4320, 8640, 4320, 66, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 66, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 66, 4320, 4320, 4320, 8640, 66, 66, 8640, 66, 8640, 66, 66, 4320, 66, 4320, 8640, 66, 66, 4320, 66, 66, 66, 66, 66, 8640, 4320, 4320, 8640, 4320, 66, 8640, 8640, 8640, 4320, 4320, 66, 66, 66, 8640, 66, 4320, 4320, 66, 8640, 8640, 8640, 66, 66, 8640, 4320, 8640, 8640, 66, 8640, 66, 4320, 66, 66, 4320, 4320, 8640, 8640, 8640, 66, 8640, 4320, 4320, 66, 66, 66, 66, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 66, 4320, 4320, 8640, 4320, 8640, 66, 66, 66, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 66, 4320, 4320, 66, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 66, 8640, 66, 8640, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 8640, 4320, 66, 66]
Prompts retrieved: 699018 . Total input tokens: 155862900 . Total output tokens: 139789936
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 12.915274215862155,
    "estimated_duration": 3600.095761627827,
    "input_throughput": 5357.478599757844,
    "output_throughput": 4735.722916517938,
    "total_throughput": 10093.201516275782,
    "itl": 178.83605476187213,
    "ttft": 1778498.7013094993,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 239,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.792306895591322,
    "arrivals": 232444,
    "finished_requests": 77939,
    "scheduler_time": 94.11014766122705
}
#Debug simulation 
Total elapsed time: 12.915389135945588. Arrivals time: 0.2729722075164318 Scheduler time: 12.546884180046618 Scheduler overhead time: 0.035860291216522455 Adapter cache time: 0.008912482298910618 Engine time: 0.03540495131164789 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-16/adapters_160_slots_96_rate_0.8-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-16/adapters_160_slots_96_rate_0.8-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 4320, 66, 66, 66, 8640, 66, 4320, 8640, 4320, 66, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 66, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 66, 4320, 4320, 4320, 8640, 66, 66, 8640, 66, 8640, 66, 66, 4320, 66, 4320, 8640, 66, 66, 4320, 66, 66, 66, 66, 66, 8640, 4320, 4320, 8640, 4320, 66, 8640, 8640, 8640, 4320, 4320, 66, 66, 66, 8640, 66, 4320, 4320, 66, 8640, 8640, 8640, 66, 66, 8640, 4320, 8640, 8640, 66, 8640, 66, 4320, 66, 66, 4320, 4320, 8640, 8640, 8640, 66, 8640, 4320, 4320, 66, 66, 66, 66, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 66, 4320, 4320, 8640, 4320, 8640, 66, 66, 66, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 66, 4320, 4320, 66, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 66, 8640, 66, 8640, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 8640, 4320, 66, 66]
Prompts retrieved: 699018 . Total input tokens: 155862900 . Total output tokens: 139789936
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 12.683994764927775,
    "estimated_duration": 3600.050583929965,
    "input_throughput": 5374.8508663667235,
    "output_throughput": 4749.556319104387,
    "total_throughput": 10124.40718547111,
    "itl": 180.9361455089664,
    "ttft": 1774576.5824740892,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 300,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8970150884706539,
    "arrivals": 232444,
    "finished_requests": 78173,
    "scheduler_time": 94.0411074282701
}
#Debug simulation 
Total elapsed time: 12.684102575294673. Arrivals time: 0.2690497529692948 Scheduler time: 12.320746193639934 Scheduler overhead time: 0.03479299833998084 Adapter cache time: 0.009126810822635889 Engine time: 0.035114377271384 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-32/adapters_160_slots_96_rate_0.8-0.4-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-32/adapters_160_slots_96_rate_0.8-0.4-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 4320, 66, 66, 66, 8640, 66, 4320, 8640, 4320, 66, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 66, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 66, 4320, 4320, 4320, 8640, 66, 66, 8640, 66, 8640, 66, 66, 4320, 66, 4320, 8640, 66, 66, 4320, 66, 66, 66, 66, 66, 8640, 4320, 4320, 8640, 4320, 66, 8640, 8640, 8640, 4320, 4320, 66, 66, 66, 8640, 66, 4320, 4320, 66, 8640, 8640, 8640, 66, 66, 8640, 4320, 8640, 8640, 66, 8640, 66, 4320, 66, 66, 4320, 4320, 8640, 8640, 8640, 66, 8640, 4320, 4320, 66, 66, 66, 66, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 66, 4320, 4320, 8640, 4320, 8640, 66, 66, 66, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 66, 4320, 4320, 66, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 66, 8640, 66, 8640, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 8640, 4320, 66, 66]
Prompts retrieved: 699018 . Total input tokens: 155862900 . Total output tokens: 139789936
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 12.964932013303041,
    "estimated_duration": 3600.106474511986,
    "input_throughput": 5357.462657438352,
    "output_throughput": 4735.708824365005,
    "total_throughput": 10093.171481803356,
    "itl": 178.8358627197337,
    "ttft": 1778503.8080870432,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 239,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8028702136501702,
    "arrivals": 232444,
    "finished_requests": 77939,
    "scheduler_time": 94.11021795088992
}
#Debug simulation 
Total elapsed time: 12.965021105948836. Arrivals time: 0.2754863384179771 Scheduler time: 12.593143476638943 Scheduler overhead time: 0.0363259045407176 Adapter cache time: 0.00904052471742034 Engine time: 0.03567129746079445 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-8/adapters_160_slots_96_rate_0.8-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-8/adapters_160_slots_96_rate_0.8-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 4320, 33, 33, 33, 8640, 33, 4320, 8640, 4320, 33, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 33, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 33, 4320, 4320, 4320, 8640, 33, 33, 8640, 33, 8640, 33, 33, 4320, 33, 4320, 8640, 33, 33, 4320, 33, 33, 33, 33, 33, 8640, 4320, 4320, 8640, 4320, 33, 8640, 8640, 8640, 4320, 4320, 33, 33, 33, 8640, 33, 4320, 4320, 33, 8640, 8640, 8640, 33, 33, 8640, 4320, 8640, 8640, 33, 8640, 33, 4320, 33, 33, 4320, 4320, 8640, 8640, 8640, 33, 8640, 4320, 4320, 33, 33, 33, 33, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 33, 4320, 4320, 8640, 4320, 8640, 33, 33, 33, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 33, 4320, 4320, 33, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 33, 8640, 33, 8640, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 8640, 4320, 33, 33]
Prompts retrieved: 697269 . Total input tokens: 155478076 . Total output tokens: 139435224
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 10.584735576063395,
    "estimated_duration": 3600.04342111496,
    "input_throughput": 5400.073200777988,
    "output_throughput": 4744.719994157689,
    "total_throughput": 10144.793194935677,
    "itl": 180.55062689695396,
    "ttft": 1775366.7565014695,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 225,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6886097423848687,
    "arrivals": 231825,
    "finished_requests": 78072,
    "scheduler_time": 94.02301713941401
}
#Debug simulation 
Total elapsed time: 10.584804215002805. Arrivals time: 0.266874794382602 Scheduler time: 10.228147157933563 Scheduler overhead time: 0.03321932116523385 Adapter cache time: 0.008271868340671062 Engine time: 0.03344250191003084 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-16/adapters_160_slots_96_rate_0.8-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-16/adapters_160_slots_96_rate_0.8-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 4320, 33, 33, 33, 8640, 33, 4320, 8640, 4320, 33, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 33, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 33, 4320, 4320, 4320, 8640, 33, 33, 8640, 33, 8640, 33, 33, 4320, 33, 4320, 8640, 33, 33, 4320, 33, 33, 33, 33, 33, 8640, 4320, 4320, 8640, 4320, 33, 8640, 8640, 8640, 4320, 4320, 33, 33, 33, 8640, 33, 4320, 4320, 33, 8640, 8640, 8640, 33, 33, 8640, 4320, 8640, 8640, 33, 8640, 33, 4320, 33, 33, 4320, 4320, 8640, 8640, 8640, 33, 8640, 4320, 4320, 33, 33, 33, 33, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 33, 4320, 4320, 8640, 4320, 8640, 33, 33, 33, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 33, 4320, 4320, 33, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 33, 8640, 33, 8640, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 8640, 4320, 33, 33]
Prompts retrieved: 697269 . Total input tokens: 155478076 . Total output tokens: 139435224
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 10.966715902090073,
    "estimated_duration": 3600.1018610263673,
    "input_throughput": 5405.749545778606,
    "output_throughput": 4744.237707521606,
    "total_throughput": 10149.987253300213,
    "itl": 180.46016140395196,
    "ttft": 1774903.308008933,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 212,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.691094007100912,
    "arrivals": 231825,
    "finished_requests": 78105,
    "scheduler_time": 94.03146064174122
}
#Debug simulation 
Total elapsed time: 10.96682391827926. Arrivals time: 0.2717795460484922 Scheduler time: 10.604062780737877 Scheduler overhead time: 0.03388459514826536 Adapter cache time: 0.008228153921663761 Engine time: 0.0338684618473053 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-32/adapters_160_slots_96_rate_0.8-0.4-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-32/adapters_160_slots_96_rate_0.8-0.4-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 4320, 33, 33, 33, 8640, 33, 4320, 8640, 4320, 33, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 33, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 33, 4320, 4320, 4320, 8640, 33, 33, 8640, 33, 8640, 33, 33, 4320, 33, 4320, 8640, 33, 33, 4320, 33, 33, 33, 33, 33, 8640, 4320, 4320, 8640, 4320, 33, 8640, 8640, 8640, 4320, 4320, 33, 33, 33, 8640, 33, 4320, 4320, 33, 8640, 8640, 8640, 33, 33, 8640, 4320, 8640, 8640, 33, 8640, 33, 4320, 33, 33, 4320, 4320, 8640, 8640, 8640, 33, 8640, 4320, 4320, 33, 33, 33, 33, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 33, 4320, 4320, 8640, 4320, 8640, 33, 33, 33, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 33, 4320, 4320, 33, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 33, 8640, 33, 8640, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 8640, 4320, 33, 33]
Prompts retrieved: 697269 . Total input tokens: 155478076 . Total output tokens: 139435224
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 10.674014508724213,
    "estimated_duration": 3600.0155935846115,
    "input_throughput": 5393.894136070946,
    "output_throughput": 4732.315612843357,
    "total_throughput": 10126.209748914302,
    "itl": 178.56214278546085,
    "ttft": 1777490.053780544,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 198,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6474706488288966,
    "arrivals": 231825,
    "finished_requests": 77919,
    "scheduler_time": 94.10319746955162
}
#Debug simulation 
Total elapsed time: 10.674144513905048. Arrivals time: 0.2642722371965647 Scheduler time: 10.318893179763108 Scheduler overhead time: 0.034145683981478214 Adapter cache time: 0.007935476955026388 Engine time: 0.03373236348852515 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-16/adapters_160_slots_96_rate_0.8-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-16/adapters_160_slots_96_rate_0.8-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 4320, 33, 33, 33, 8640, 33, 4320, 8640, 4320, 33, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 33, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 33, 4320, 4320, 4320, 8640, 33, 33, 8640, 33, 8640, 33, 33, 4320, 33, 4320, 8640, 33, 33, 4320, 33, 33, 33, 33, 33, 8640, 4320, 4320, 8640, 4320, 33, 8640, 8640, 8640, 4320, 4320, 33, 33, 33, 8640, 33, 4320, 4320, 33, 8640, 8640, 8640, 33, 33, 8640, 4320, 8640, 8640, 33, 8640, 33, 4320, 33, 33, 4320, 4320, 8640, 8640, 8640, 33, 8640, 4320, 4320, 33, 33, 33, 33, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 33, 4320, 4320, 8640, 4320, 8640, 33, 33, 33, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 33, 4320, 4320, 33, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 33, 8640, 33, 8640, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 8640, 4320, 33, 33]
Prompts retrieved: 697269 . Total input tokens: 155478076 . Total output tokens: 139435224
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 10.631957565899938,
    "estimated_duration": 3600.083211905201,
    "input_throughput": 5400.013515163137,
    "output_throughput": 4744.667551992626,
    "total_throughput": 10144.681067155763,
    "itl": 180.5517284463137,
    "ttft": 1775374.020654168,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 225,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7046317511913383,
    "arrivals": 231825,
    "finished_requests": 78072,
    "scheduler_time": 94.02380495773212
}
#Debug simulation 
Total elapsed time: 10.632058918010443. Arrivals time: 0.4518488021567464 Scheduler time: 10.09002019977197 Scheduler overhead time: 0.03355010086670518 Adapter cache time: 0.008388183545321226 Engine time: 0.03325516916811466 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-32/adapters_160_slots_96_rate_0.8-0.4-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-32/adapters_160_slots_96_rate_0.8-0.4-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 4320, 33, 33, 33, 8640, 33, 4320, 8640, 4320, 33, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 33, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 33, 4320, 4320, 4320, 8640, 33, 33, 8640, 33, 8640, 33, 33, 4320, 33, 4320, 8640, 33, 33, 4320, 33, 33, 33, 33, 33, 8640, 4320, 4320, 8640, 4320, 33, 8640, 8640, 8640, 4320, 4320, 33, 33, 33, 8640, 33, 4320, 4320, 33, 8640, 8640, 8640, 33, 33, 8640, 4320, 8640, 8640, 33, 8640, 33, 4320, 33, 33, 4320, 4320, 8640, 8640, 8640, 33, 8640, 4320, 4320, 33, 33, 33, 33, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 33, 4320, 4320, 8640, 4320, 8640, 33, 33, 33, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 33, 4320, 4320, 33, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 33, 8640, 33, 8640, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 8640, 4320, 33, 33]
Prompts retrieved: 697269 . Total input tokens: 155478076 . Total output tokens: 139435224
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 10.692679525818676,
    "estimated_duration": 3600.177185884826,
    "input_throughput": 5393.881466761018,
    "output_throughput": 4732.294028970894,
    "total_throughput": 10126.175495731912,
    "itl": 178.5494237667511,
    "ttft": 1777512.6132355344,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 198,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6562734138779366,
    "arrivals": 231825,
    "finished_requests": 77922,
    "scheduler_time": 94.10821550829264
}
#Debug simulation 
Total elapsed time: 10.692794432863593. Arrivals time: 0.2616746798157692 Scheduler time: 10.340345996432006 Scheduler overhead time: 0.03381897555664182 Adapter cache time: 0.008048849180340767 Engine time: 0.03370976587757468 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-16/adapters_160_slots_96_rate_0.8-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-16/adapters_160_slots_96_rate_0.8-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 4320, 33, 33, 33, 8640, 33, 4320, 8640, 4320, 33, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 33, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 33, 4320, 4320, 4320, 8640, 33, 33, 8640, 33, 8640, 33, 33, 4320, 33, 4320, 8640, 33, 33, 4320, 33, 33, 33, 33, 33, 8640, 4320, 4320, 8640, 4320, 33, 8640, 8640, 8640, 4320, 4320, 33, 33, 33, 8640, 33, 4320, 4320, 33, 8640, 8640, 8640, 33, 33, 8640, 4320, 8640, 8640, 33, 8640, 33, 4320, 33, 33, 4320, 4320, 8640, 8640, 8640, 33, 8640, 4320, 4320, 33, 33, 33, 33, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 33, 4320, 4320, 8640, 4320, 8640, 33, 33, 33, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 33, 4320, 4320, 33, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 33, 8640, 33, 8640, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 8640, 4320, 33, 33]
Prompts retrieved: 697269 . Total input tokens: 155478076 . Total output tokens: 139435224
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 11.035181964747608,
    "estimated_duration": 3600.07844259693,
    "input_throughput": 5405.7847100580275,
    "output_throughput": 4744.268568681372,
    "total_throughput": 10150.053278739399,
    "itl": 180.45787553448602,
    "ttft": 1774889.8974750598,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 212,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6338906625192621,
    "arrivals": 231825,
    "finished_requests": 78105,
    "scheduler_time": 94.03152393822658
}
#Debug simulation 
Total elapsed time: 11.035271421074867. Arrivals time: 0.2697647721506655 Scheduler time: 10.674283986445516 Scheduler overhead time: 0.033975486643612385 Adapter cache time: 0.008171048946678638 Engine time: 0.0340335420332849 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-32/adapters_160_slots_96_rate_0.8-0.4-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-32/adapters_160_slots_96_rate_0.8-0.4-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 4320, 33, 33, 33, 8640, 33, 4320, 8640, 4320, 33, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 33, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 33, 4320, 4320, 4320, 8640, 33, 33, 8640, 33, 8640, 33, 33, 4320, 33, 4320, 8640, 33, 33, 4320, 33, 33, 33, 33, 33, 8640, 4320, 4320, 8640, 4320, 33, 8640, 8640, 8640, 4320, 4320, 33, 33, 33, 8640, 33, 4320, 4320, 33, 8640, 8640, 8640, 33, 33, 8640, 4320, 8640, 8640, 33, 8640, 33, 4320, 33, 33, 4320, 4320, 8640, 8640, 8640, 33, 8640, 4320, 4320, 33, 33, 33, 33, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 33, 4320, 4320, 8640, 4320, 8640, 33, 33, 33, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 33, 4320, 4320, 33, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 33, 8640, 33, 8640, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 8640, 4320, 33, 33]
Prompts retrieved: 697269 . Total input tokens: 155478076 . Total output tokens: 139435224
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 10.892809794284403,
    "estimated_duration": 3600.1462503467123,
    "input_throughput": 5393.9278156074515,
    "output_throughput": 4732.334692891779,
    "total_throughput": 10126.26250849923,
    "itl": 178.55626074099217,
    "ttft": 1777490.2478713028,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 198,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6641959024220723,
    "arrivals": 231825,
    "finished_requests": 77922,
    "scheduler_time": 94.10713268547956
}
#Debug simulation 
Total elapsed time: 10.892875005025417. Arrivals time: 0.4537006984464824 Scheduler time: 10.348604665137827 Scheduler overhead time: 0.03395534818992019 Adapter cache time: 0.007784166838973761 Engine time: 0.03379494743421674 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-8/adapters_160_slots_96_rate_0.8-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-8/adapters_160_slots_96_rate_0.8-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [53 53 54]
Adapter prompts. [540, 8640, 540, 540, 1080, 540, 540, 540, 8640, 540, 1080, 8640, 1080, 540, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 540, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 540, 1080, 1080, 1080, 8640, 540, 540, 8640, 540, 8640, 540, 540, 1080, 540, 1080, 8640, 540, 540, 1080, 540, 540, 540, 540, 540, 8640, 1080, 1080, 8640, 1080, 540, 8640, 8640, 8640, 1080, 1080, 540, 540, 540, 8640, 540, 1080, 1080, 540, 8640, 8640, 8640, 540, 540, 8640, 1080, 8640, 8640, 540, 8640, 540, 1080, 540, 540, 1080, 1080, 8640, 8640, 8640, 540, 8640, 1080, 1080, 540, 540, 540, 540, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 540, 1080, 1080, 8640, 1080, 8640, 540, 540, 540, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 540, 1080, 1080, 540, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 540, 8640, 540, 8640, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 8640, 1080, 540, 540]
Prompts retrieved: 552420 . Total input tokens: 123244485 . Total output tokens: 110517912
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 7.13172437204048,
    "estimated_duration": 3600.0274200520207,
    "input_throughput": 5376.824601997141,
    "output_throughput": 4746.18607203639,
    "total_throughput": 10123.01067403353,
    "itl": 180.68925783738834,
    "ttft": 1658075.3534164892,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 948,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9013423812483152,
    "arrivals": 183717,
    "finished_requests": 78094,
    "scheduler_time": 92.75755470697818
}
#Debug simulation 
Total elapsed time: 7.131813337095082. Arrivals time: 0.2467372128739953 Scheduler time: 6.78690785728395 Scheduler overhead time: 0.03220627177506685 Adapter cache time: 0.01897052163258195 Engine time: 0.03212173189967871 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-16/adapters_160_slots_96_rate_0.8-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-16/adapters_160_slots_96_rate_0.8-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [53 53 54]
Adapter prompts. [540, 8640, 540, 540, 1080, 540, 540, 540, 8640, 540, 1080, 8640, 1080, 540, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 540, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 540, 1080, 1080, 1080, 8640, 540, 540, 8640, 540, 8640, 540, 540, 1080, 540, 1080, 8640, 540, 540, 1080, 540, 540, 540, 540, 540, 8640, 1080, 1080, 8640, 1080, 540, 8640, 8640, 8640, 1080, 1080, 540, 540, 540, 8640, 540, 1080, 1080, 540, 8640, 8640, 8640, 540, 540, 8640, 1080, 8640, 8640, 540, 8640, 540, 1080, 540, 540, 1080, 1080, 8640, 8640, 8640, 540, 8640, 1080, 1080, 540, 540, 540, 540, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 540, 1080, 1080, 8640, 1080, 8640, 540, 540, 540, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 540, 1080, 1080, 540, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 540, 8640, 540, 8640, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 8640, 1080, 540, 540]
Prompts retrieved: 552420 . Total input tokens: 123244485 . Total output tokens: 110517912
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 7.104109083302319,
    "estimated_duration": 3600.085377330991,
    "input_throughput": 5375.9927811347,
    "output_throughput": 4745.641341613448,
    "total_throughput": 10121.634122748148,
    "itl": 180.69852297323277,
    "ttft": 1658204.6922652735,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 947,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0812293688394155,
    "arrivals": 183717,
    "finished_requests": 78088,
    "scheduler_time": 92.75548595050809
}
#Debug simulation 
Total elapsed time: 7.104198500979692. Arrivals time: 0.2477858648635447 Scheduler time: 6.757675534114242 Scheduler overhead time: 0.032523948699235916 Adapter cache time: 0.01897900691255927 Engine time: 0.032439551781862974 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-32/adapters_160_slots_96_rate_0.8-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-32/adapters_160_slots_96_rate_0.8-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [53 53 54]
Adapter prompts. [540, 8640, 540, 540, 1080, 540, 540, 540, 8640, 540, 1080, 8640, 1080, 540, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 540, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 540, 1080, 1080, 1080, 8640, 540, 540, 8640, 540, 8640, 540, 540, 1080, 540, 1080, 8640, 540, 540, 1080, 540, 540, 540, 540, 540, 8640, 1080, 1080, 8640, 1080, 540, 8640, 8640, 8640, 1080, 1080, 540, 540, 540, 8640, 540, 1080, 1080, 540, 8640, 8640, 8640, 540, 540, 8640, 1080, 8640, 8640, 540, 8640, 540, 1080, 540, 540, 1080, 1080, 8640, 8640, 8640, 540, 8640, 1080, 1080, 540, 540, 540, 540, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 540, 1080, 1080, 8640, 1080, 8640, 540, 540, 540, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 540, 1080, 1080, 540, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 540, 8640, 540, 8640, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 8640, 1080, 540, 540]
Prompts retrieved: 552420 . Total input tokens: 123244485 . Total output tokens: 110517912
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.98945616511628,
    "estimated_duration": 3600.1457648384276,
    "input_throughput": 5361.10737195837,
    "output_throughput": 4731.402868840358,
    "total_throughput": 10092.510240798729,
    "itl": 178.4621598908265,
    "ttft": 1662125.866634918,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 968,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.157243177182943,
    "arrivals": 183717,
    "finished_requests": 77866,
    "scheduler_time": 92.84001271116986
}
#Debug simulation 
Total elapsed time: 6.989544681273401. Arrivals time: 0.2428920459933579 Scheduler time: 6.6469800169579685 Scheduler overhead time: 0.03284785570576787 Adapter cache time: 0.019519248511642218 Engine time: 0.03242157818749547 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-16-16/adapters_160_slots_96_rate_0.8-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-16-16/adapters_160_slots_96_rate_0.8-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [53 53 54]
Adapter prompts. [540, 8640, 540, 540, 1080, 540, 540, 540, 8640, 540, 1080, 8640, 1080, 540, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 540, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 540, 1080, 1080, 1080, 8640, 540, 540, 8640, 540, 8640, 540, 540, 1080, 540, 1080, 8640, 540, 540, 1080, 540, 540, 540, 540, 540, 8640, 1080, 1080, 8640, 1080, 540, 8640, 8640, 8640, 1080, 1080, 540, 540, 540, 8640, 540, 1080, 1080, 540, 8640, 8640, 8640, 540, 540, 8640, 1080, 8640, 8640, 540, 8640, 540, 1080, 540, 540, 1080, 1080, 8640, 8640, 8640, 540, 8640, 1080, 1080, 540, 540, 540, 540, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 540, 1080, 1080, 8640, 1080, 8640, 540, 540, 540, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 540, 1080, 1080, 540, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 540, 8640, 540, 8640, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 8640, 1080, 540, 540]
Prompts retrieved: 552420 . Total input tokens: 123244485 . Total output tokens: 110517912
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 7.09376229904592,
    "estimated_duration": 3600.095060208544,
    "input_throughput": 5376.7235798708925,
    "output_throughput": 4746.096898621958,
    "total_throughput": 10122.82047849285,
    "itl": 180.69135792054166,
    "ttft": 1658102.0944871984,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 948,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9645009908312634,
    "arrivals": 183717,
    "finished_requests": 78094,
    "scheduler_time": 92.7578909652588
}
#Debug simulation 
Total elapsed time: 7.093850163277239. Arrivals time: 0.2441615629941225 Scheduler time: 6.7511610998772085 Scheduler overhead time: 0.03226983267813921 Adapter cache time: 0.019002307672053576 Engine time: 0.03239198727533221 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-16-32/adapters_160_slots_96_rate_0.8-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-16-32/adapters_160_slots_96_rate_0.8-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [53 53 54]
Adapter prompts. [540, 8640, 540, 540, 1080, 540, 540, 540, 8640, 540, 1080, 8640, 1080, 540, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 540, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 540, 1080, 1080, 1080, 8640, 540, 540, 8640, 540, 8640, 540, 540, 1080, 540, 1080, 8640, 540, 540, 1080, 540, 540, 540, 540, 540, 8640, 1080, 1080, 8640, 1080, 540, 8640, 8640, 8640, 1080, 1080, 540, 540, 540, 8640, 540, 1080, 1080, 540, 8640, 8640, 8640, 540, 540, 8640, 1080, 8640, 8640, 540, 8640, 540, 1080, 540, 540, 1080, 1080, 8640, 8640, 8640, 540, 8640, 1080, 1080, 540, 540, 540, 540, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 540, 1080, 1080, 8640, 1080, 8640, 540, 540, 540, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 540, 1080, 1080, 540, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 540, 8640, 540, 8640, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 8640, 1080, 540, 540]
Prompts retrieved: 552420 . Total input tokens: 123244485 . Total output tokens: 110517912
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 7.093748539220542,
    "estimated_duration": 3600.127197312037,
    "input_throughput": 5360.113113338824,
    "output_throughput": 4732.062526212854,
    "total_throughput": 10092.175639551679,
    "itl": 178.46846176219915,
    "ttft": 1661909.4494519054,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 966,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1890080291964122,
    "arrivals": 183717,
    "finished_requests": 77853,
    "scheduler_time": 92.84011294712614
}
#Debug simulation 
Total elapsed time: 7.093840191140771. Arrivals time: 0.25156043842434883 Scheduler time: 6.741496893577278 Scheduler overhead time: 0.03308971365913749 Adapter cache time: 0.019616606179624796 Engine time: 0.03293077973648906 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_16-16-16/adapters_160_slots_96_rate_0.8-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_16-16-16/adapters_160_slots_96_rate_0.8-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [53 53 54]
Adapter prompts. [540, 8640, 540, 540, 1080, 540, 540, 540, 8640, 540, 1080, 8640, 1080, 540, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 540, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 540, 1080, 1080, 1080, 8640, 540, 540, 8640, 540, 8640, 540, 540, 1080, 540, 1080, 8640, 540, 540, 1080, 540, 540, 540, 540, 540, 8640, 1080, 1080, 8640, 1080, 540, 8640, 8640, 8640, 1080, 1080, 540, 540, 540, 8640, 540, 1080, 1080, 540, 8640, 8640, 8640, 540, 540, 8640, 1080, 8640, 8640, 540, 8640, 540, 1080, 540, 540, 1080, 1080, 8640, 8640, 8640, 540, 8640, 1080, 1080, 540, 540, 540, 540, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 540, 1080, 1080, 8640, 1080, 8640, 540, 540, 540, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 540, 1080, 1080, 540, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 540, 8640, 540, 8640, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 8640, 1080, 540, 540]
Prompts retrieved: 552420 . Total input tokens: 123244485 . Total output tokens: 110517912
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 7.058079218957573,
    "estimated_duration": 3600.08535004929,
    "input_throughput": 5376.4275337902745,
    "output_throughput": 4745.569712608644,
    "total_throughput": 10121.997246398918,
    "itl": 180.6757407534564,
    "ttft": 1658281.4515201943,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 949,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.837557729862101,
    "arrivals": 183717,
    "finished_requests": 78090,
    "scheduler_time": 92.76083685009932
}
#Debug simulation 
Total elapsed time: 7.058166978880763. Arrivals time: 0.2432640721090138 Scheduler time: 6.716471574734896 Scheduler overhead time: 0.032621889375150204 Adapter cache time: 0.01898637879639864 Engine time: 0.03203830122947693 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_16-16-32/adapters_160_slots_96_rate_0.8-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_16-16-32/adapters_160_slots_96_rate_0.8-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [53 53 54]
Adapter prompts. [540, 8640, 540, 540, 1080, 540, 540, 540, 8640, 540, 1080, 8640, 1080, 540, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 540, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 540, 1080, 1080, 1080, 8640, 540, 540, 8640, 540, 8640, 540, 540, 1080, 540, 1080, 8640, 540, 540, 1080, 540, 540, 540, 540, 540, 8640, 1080, 1080, 8640, 1080, 540, 8640, 8640, 8640, 1080, 1080, 540, 540, 540, 8640, 540, 1080, 1080, 540, 8640, 8640, 8640, 540, 540, 8640, 1080, 8640, 8640, 540, 8640, 540, 1080, 540, 540, 1080, 1080, 8640, 8640, 8640, 540, 8640, 1080, 1080, 540, 540, 540, 540, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 540, 1080, 1080, 8640, 1080, 8640, 540, 540, 540, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 540, 1080, 1080, 540, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 540, 8640, 540, 8640, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 8640, 1080, 540, 540]
Prompts retrieved: 552420 . Total input tokens: 123244485 . Total output tokens: 110517912
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 7.0367679400369525,
    "estimated_duration": 3600.0791572290877,
    "input_throughput": 5361.796826394525,
    "output_throughput": 4731.665959564909,
    "total_throughput": 10093.462785959435,
    "itl": 178.49234344407768,
    "ttft": 1662053.5832701677,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 955,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.192695292197202,
    "arrivals": 183717,
    "finished_requests": 77870,
    "scheduler_time": 92.83661741980673
}
#Debug simulation 
Total elapsed time: 7.036859415937215. Arrivals time: 0.24341112468391657 Scheduler time: 6.6942392103374 Scheduler overhead time: 0.032651237677782774 Adapter cache time: 0.01916808495298028 Engine time: 0.03245694236829877 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-8/adapters_160_slots_96_rate_0.8-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-8/adapters_160_slots_96_rate_0.8-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [53 53 54]
Adapter prompts. [270, 8640, 270, 270, 1080, 270, 270, 270, 8640, 270, 1080, 8640, 1080, 270, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 270, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 270, 1080, 1080, 1080, 8640, 270, 270, 8640, 270, 8640, 270, 270, 1080, 270, 1080, 8640, 270, 270, 1080, 270, 270, 270, 270, 270, 8640, 1080, 1080, 8640, 1080, 270, 8640, 8640, 8640, 1080, 1080, 270, 270, 270, 8640, 270, 1080, 1080, 270, 8640, 8640, 8640, 270, 270, 8640, 1080, 8640, 8640, 270, 8640, 270, 1080, 270, 270, 1080, 1080, 8640, 8640, 8640, 270, 8640, 1080, 1080, 270, 270, 270, 270, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 270, 1080, 1080, 8640, 1080, 8640, 270, 270, 270, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 270, 1080, 1080, 270, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 270, 8640, 270, 8640, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 8640, 1080, 270, 270]
Prompts retrieved: 538110 . Total input tokens: 120059615 . Total output tokens: 107649944
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 6.5624722968786955,
    "estimated_duration": 3600.0217057576415,
    "input_throughput": 5335.129776935021,
    "output_throughput": 4746.411382095798,
    "total_throughput": 10081.54115903082,
    "itl": 181.75737387442496,
    "ttft": 1639318.1858253602,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1036,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.170665302714407,
    "arrivals": 179046,
    "finished_requests": 77858,
    "scheduler_time": 92.43101857447569
}
#Debug simulation 
Total elapsed time: 6.562560656107962. Arrivals time: 0.23894050205126405 Scheduler time: 6.224084968212992 Scheduler overhead time: 0.032418421003967524 Adapter cache time: 0.02011170517653227 Engine time: 0.03225954528898001 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-16/adapters_160_slots_96_rate_0.8-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-16/adapters_160_slots_96_rate_0.8-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [53 53 54]
Adapter prompts. [270, 8640, 270, 270, 1080, 270, 270, 270, 8640, 270, 1080, 8640, 1080, 270, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 270, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 270, 1080, 1080, 1080, 8640, 270, 270, 8640, 270, 8640, 270, 270, 1080, 270, 1080, 8640, 270, 270, 1080, 270, 270, 270, 270, 270, 8640, 1080, 1080, 8640, 1080, 270, 8640, 8640, 8640, 1080, 1080, 270, 270, 270, 8640, 270, 1080, 1080, 270, 8640, 8640, 8640, 270, 270, 8640, 1080, 8640, 8640, 270, 8640, 270, 1080, 270, 270, 1080, 1080, 8640, 8640, 8640, 270, 8640, 1080, 1080, 270, 270, 270, 270, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 270, 1080, 1080, 8640, 1080, 8640, 270, 270, 270, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 270, 1080, 1080, 270, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 270, 8640, 270, 8640, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 8640, 1080, 270, 270]
Prompts retrieved: 538110 . Total input tokens: 120059615 . Total output tokens: 107649944
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.61089929798618,
    "estimated_duration": 3600.0327965228566,
    "input_throughput": 5335.263894971034,
    "output_throughput": 4747.367584125144,
    "total_throughput": 10082.631479096179,
    "itl": 181.77760394911658,
    "ttft": 1639262.7222463987,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1043,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3956500834855277,
    "arrivals": 179046,
    "finished_requests": 77865,
    "scheduler_time": 92.4261913115306
}
#Debug simulation 
Total elapsed time: 6.610986804123968. Arrivals time: 0.24310302594676614 Scheduler time: 6.268361320253462 Scheduler overhead time: 0.03242534678429365 Adapter cache time: 0.020291533786803484 Engine time: 0.032044473104178905 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-32/adapters_160_slots_96_rate_0.8-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-32/adapters_160_slots_96_rate_0.8-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [53 53 54]
Adapter prompts. [270, 8640, 270, 270, 1080, 270, 270, 270, 8640, 270, 1080, 8640, 1080, 270, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 270, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 270, 1080, 1080, 1080, 8640, 270, 270, 8640, 270, 8640, 270, 270, 1080, 270, 1080, 8640, 270, 270, 1080, 270, 270, 270, 270, 270, 8640, 1080, 1080, 8640, 1080, 270, 8640, 8640, 8640, 1080, 1080, 270, 270, 270, 8640, 270, 1080, 1080, 270, 8640, 8640, 8640, 270, 270, 8640, 1080, 8640, 8640, 270, 8640, 270, 1080, 270, 270, 1080, 1080, 8640, 8640, 8640, 270, 8640, 1080, 1080, 270, 270, 270, 270, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 270, 1080, 1080, 8640, 1080, 8640, 270, 270, 270, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 270, 1080, 1080, 270, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 270, 8640, 270, 8640, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 8640, 1080, 270, 270]
Prompts retrieved: 538110 . Total input tokens: 120059615 . Total output tokens: 107649944
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.511424261145294,
    "estimated_duration": 3600.0242586697027,
    "input_throughput": 5323.379406082579,
    "output_throughput": 4735.668921936612,
    "total_throughput": 10059.048328019191,
    "itl": 179.640874480021,
    "ttft": 1641436.876741012,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1080,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5240853453240857,
    "arrivals": 179046,
    "finished_requests": 77674,
    "scheduler_time": 92.53276724140565
}
#Debug simulation 
Total elapsed time: 6.511515158228576. Arrivals time: 0.2432807134464383 Scheduler time: 6.167733134701848 Scheduler overhead time: 0.032644009217619896 Adapter cache time: 0.020623442716896534 Engine time: 0.03234929172322154 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-16-16/adapters_160_slots_96_rate_0.8-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-16-16/adapters_160_slots_96_rate_0.8-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [53 53 54]
Adapter prompts. [270, 8640, 270, 270, 1080, 270, 270, 270, 8640, 270, 1080, 8640, 1080, 270, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 270, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 270, 1080, 1080, 1080, 8640, 270, 270, 8640, 270, 8640, 270, 270, 1080, 270, 1080, 8640, 270, 270, 1080, 270, 270, 270, 270, 270, 8640, 1080, 1080, 8640, 1080, 270, 8640, 8640, 8640, 1080, 1080, 270, 270, 270, 8640, 270, 1080, 1080, 270, 8640, 8640, 8640, 270, 270, 8640, 1080, 8640, 8640, 270, 8640, 270, 1080, 270, 270, 1080, 1080, 8640, 8640, 8640, 270, 8640, 1080, 1080, 270, 270, 270, 270, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 270, 1080, 1080, 8640, 1080, 8640, 270, 270, 270, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 270, 1080, 1080, 270, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 270, 8640, 270, 8640, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 8640, 1080, 270, 270]
Prompts retrieved: 538110 . Total input tokens: 120059615 . Total output tokens: 107649944
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 6.567472190596163,
    "estimated_duration": 3600.1906867650882,
    "input_throughput": 5334.319671066105,
    "output_throughput": 4745.98638978005,
    "total_throughput": 10080.306060846155,
    "itl": 181.77395829090042,
    "ttft": 1639537.4281599468,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1039,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2496706178574475,
    "arrivals": 179046,
    "finished_requests": 77846,
    "scheduler_time": 92.43313520161352
}
#Debug simulation 
Total elapsed time: 6.567563880700618. Arrivals time: 0.242255927529186 Scheduler time: 6.2249784879386425 Scheduler overhead time: 0.03234914690256119 Adapter cache time: 0.020999294705688953 Engine time: 0.03226792858913541 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-16-32/adapters_160_slots_96_rate_0.8-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-16-32/adapters_160_slots_96_rate_0.8-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [53 53 54]
Adapter prompts. [270, 8640, 270, 270, 1080, 270, 270, 270, 8640, 270, 1080, 8640, 1080, 270, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 270, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 270, 1080, 1080, 1080, 8640, 270, 270, 8640, 270, 8640, 270, 270, 1080, 270, 1080, 8640, 270, 270, 1080, 270, 270, 270, 270, 270, 8640, 1080, 1080, 8640, 1080, 270, 8640, 8640, 8640, 1080, 1080, 270, 270, 270, 8640, 270, 1080, 1080, 270, 8640, 8640, 8640, 270, 270, 8640, 1080, 8640, 8640, 270, 8640, 270, 1080, 270, 270, 1080, 1080, 8640, 8640, 8640, 270, 8640, 1080, 1080, 270, 270, 270, 270, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 270, 1080, 1080, 8640, 1080, 8640, 270, 270, 270, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 270, 1080, 1080, 270, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 270, 8640, 270, 8640, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 8640, 1080, 270, 270]
Prompts retrieved: 538110 . Total input tokens: 120059615 . Total output tokens: 107649944
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 6.4840556108392775,
    "estimated_duration": 3600.1698197032097,
    "input_throughput": 5321.79479288548,
    "output_throughput": 4734.459720959813,
    "total_throughput": 10056.254513845293,
    "itl": 179.5847074591648,
    "ttft": 1641477.7663032003,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1082,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5734774116054187,
    "arrivals": 179046,
    "finished_requests": 77669,
    "scheduler_time": 92.53908372430261
}
#Debug simulation 
Total elapsed time: 6.484144560992718. Arrivals time: 0.24354243790730834 Scheduler time: 6.139863763935864 Scheduler overhead time: 0.032636307179927826 Adapter cache time: 0.021021421533077955 Engine time: 0.032253338024020195 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_16-16-16/adapters_160_slots_96_rate_0.8-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_16-16-16/adapters_160_slots_96_rate_0.8-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [53 53 54]
Adapter prompts. [270, 8640, 270, 270, 1080, 270, 270, 270, 8640, 270, 1080, 8640, 1080, 270, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 270, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 270, 1080, 1080, 1080, 8640, 270, 270, 8640, 270, 8640, 270, 270, 1080, 270, 1080, 8640, 270, 270, 1080, 270, 270, 270, 270, 270, 8640, 1080, 1080, 8640, 1080, 270, 8640, 8640, 8640, 1080, 1080, 270, 270, 270, 8640, 270, 1080, 1080, 270, 8640, 8640, 8640, 270, 270, 8640, 1080, 8640, 8640, 270, 8640, 270, 1080, 270, 270, 1080, 1080, 8640, 8640, 8640, 270, 8640, 1080, 1080, 270, 270, 270, 270, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 270, 1080, 1080, 8640, 1080, 8640, 270, 270, 270, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 270, 1080, 1080, 270, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 270, 8640, 270, 8640, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 8640, 1080, 270, 270]
Prompts retrieved: 538110 . Total input tokens: 120059615 . Total output tokens: 107649944
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 6.590913854073733,
    "estimated_duration": 3600.1513517224307,
    "input_throughput": 5335.192919267269,
    "output_throughput": 4746.582110172769,
    "total_throughput": 10081.775029440038,
    "itl": 181.75548771815974,
    "ttft": 1639281.0632200032,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1037,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.100682155813483,
    "arrivals": 179046,
    "finished_requests": 77862,
    "scheduler_time": 92.4361086139287
}
#Debug simulation 
Total elapsed time: 6.591008306946605. Arrivals time: 0.2411927510984242 Scheduler time: 6.249919452704489 Scheduler overhead time: 0.032598404213786125 Adapter cache time: 0.020308736711740494 Engine time: 0.0322361676953733 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_16-16-32/adapters_160_slots_96_rate_0.8-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_16-16-32/adapters_160_slots_96_rate_0.8-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [53 53 54]
Adapter prompts. [270, 8640, 270, 270, 1080, 270, 270, 270, 8640, 270, 1080, 8640, 1080, 270, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 270, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 270, 1080, 1080, 1080, 8640, 270, 270, 8640, 270, 8640, 270, 270, 1080, 270, 1080, 8640, 270, 270, 1080, 270, 270, 270, 270, 270, 8640, 1080, 1080, 8640, 1080, 270, 8640, 8640, 8640, 1080, 1080, 270, 270, 270, 8640, 270, 1080, 1080, 270, 8640, 8640, 8640, 270, 270, 8640, 1080, 8640, 8640, 270, 8640, 270, 1080, 270, 270, 1080, 1080, 8640, 8640, 8640, 270, 8640, 1080, 1080, 270, 270, 270, 270, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 270, 1080, 1080, 8640, 1080, 8640, 270, 270, 270, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 270, 1080, 1080, 270, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 270, 8640, 270, 8640, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 8640, 1080, 270, 270]
Prompts retrieved: 538110 . Total input tokens: 120059615 . Total output tokens: 107649944
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.478881943970919,
    "estimated_duration": 3600.1408668676895,
    "input_throughput": 5322.502843248945,
    "output_throughput": 4735.25526650636,
    "total_throughput": 10057.758109755305,
    "itl": 179.66540182684776,
    "ttft": 1641480.3966736898,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1080,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.6120272558928015,
    "arrivals": 179046,
    "finished_requests": 77674,
    "scheduler_time": 92.53289213943992
}
#Debug simulation 
Total elapsed time: 6.478982849046588. Arrivals time: 0.23971189139410853 Scheduler time: 6.139021047856659 Scheduler overhead time: 0.03269387874752283 Adapter cache time: 0.02049476094543934 Engine time: 0.03217427944764495 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-8/adapters_160_slots_96_rate_0.8-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-8/adapters_160_slots_96_rate_0.8-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 1080, 135, 135, 135, 8640, 135, 1080, 8640, 1080, 135, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 135, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 135, 1080, 1080, 1080, 8640, 135, 135, 8640, 135, 8640, 135, 135, 1080, 135, 1080, 8640, 135, 135, 1080, 135, 135, 135, 135, 135, 8640, 1080, 1080, 8640, 1080, 135, 8640, 8640, 8640, 1080, 1080, 135, 135, 135, 8640, 135, 1080, 1080, 135, 8640, 8640, 8640, 135, 135, 8640, 1080, 8640, 8640, 135, 8640, 135, 1080, 135, 135, 1080, 1080, 8640, 8640, 8640, 135, 8640, 1080, 1080, 135, 135, 135, 135, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 135, 1080, 1080, 8640, 1080, 8640, 135, 135, 135, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 135, 1080, 1080, 135, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 135, 8640, 135, 8640, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 8640, 1080, 135, 135]
Prompts retrieved: 530955 . Total input tokens: 118470383 . Total output tokens: 106229005
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 6.106968787964433,
    "estimated_duration": 3600.06523328333,
    "input_throughput": 5369.602423112156,
    "output_throughput": 4744.511527759791,
    "total_throughput": 10114.113950871948,
    "itl": 181.08893138914567,
    "ttft": 1629374.9197845708,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1187,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.632798952048269,
    "arrivals": 176720,
    "finished_requests": 78113,
    "scheduler_time": 92.38572488615317
}
#Debug simulation 
Total elapsed time: 6.107075133826584. Arrivals time: 0.24086393043398857 Scheduler time: 5.7657565786503255 Scheduler overhead time: 0.0320731932297349 Adapter cache time: 0.021858411375433207 Engine time: 0.031841129064559937 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-16/adapters_160_slots_96_rate_0.8-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-16/adapters_160_slots_96_rate_0.8-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 1080, 135, 135, 135, 8640, 135, 1080, 8640, 1080, 135, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 135, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 135, 1080, 1080, 1080, 8640, 135, 135, 8640, 135, 8640, 135, 135, 1080, 135, 1080, 8640, 135, 135, 1080, 135, 135, 135, 135, 135, 8640, 1080, 1080, 8640, 1080, 135, 8640, 8640, 8640, 1080, 1080, 135, 135, 135, 8640, 135, 1080, 1080, 135, 8640, 8640, 8640, 135, 135, 8640, 1080, 8640, 8640, 135, 8640, 135, 1080, 135, 135, 1080, 1080, 8640, 8640, 8640, 135, 8640, 1080, 1080, 135, 135, 135, 135, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 135, 1080, 1080, 8640, 1080, 8640, 135, 135, 135, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 135, 1080, 1080, 135, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 135, 8640, 135, 8640, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 8640, 1080, 135, 135]
Prompts retrieved: 530955 . Total input tokens: 118470383 . Total output tokens: 106229005
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.107461167033762,
    "estimated_duration": 3600.177991062732,
    "input_throughput": 5368.704838477863,
    "output_throughput": 4743.770180917817,
    "total_throughput": 10112.47501939568,
    "itl": 181.0976833172582,
    "ttft": 1629603.1162223956,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1164,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.788499413370157,
    "arrivals": 176720,
    "finished_requests": 78102,
    "scheduler_time": 92.38538998721994
}
#Debug simulation 
Total elapsed time: 6.107551995199174. Arrivals time: 0.2372779818251729 Scheduler time: 5.769853997044265 Scheduler overhead time: 0.03210948873311281 Adapter cache time: 0.021424847189337015 Engine time: 0.03219396993517876 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-32/adapters_160_slots_96_rate_0.8-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-32/adapters_160_slots_96_rate_0.8-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 1080, 135, 135, 135, 8640, 135, 1080, 8640, 1080, 135, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 135, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 135, 1080, 1080, 1080, 8640, 135, 135, 8640, 135, 8640, 135, 135, 1080, 135, 1080, 8640, 135, 135, 1080, 135, 135, 135, 135, 135, 8640, 1080, 1080, 8640, 1080, 135, 8640, 8640, 8640, 1080, 1080, 135, 135, 135, 8640, 135, 1080, 1080, 135, 8640, 8640, 8640, 135, 135, 8640, 1080, 8640, 8640, 135, 8640, 135, 1080, 135, 135, 1080, 1080, 8640, 8640, 8640, 135, 8640, 1080, 1080, 135, 135, 135, 135, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 135, 1080, 1080, 8640, 1080, 8640, 135, 135, 135, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 135, 1080, 1080, 135, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 135, 8640, 135, 8640, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 8640, 1080, 135, 135]
Prompts retrieved: 530955 . Total input tokens: 118470383 . Total output tokens: 106229005
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.058936662040651,
    "estimated_duration": 3600.0979240688544,
    "input_throughput": 5356.52401871477,
    "output_throughput": 4731.778512498649,
    "total_throughput": 10088.30253121342,
    "itl": 178.91010255842616,
    "ttft": 1631919.2829514858,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1220,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.9791812686807813,
    "arrivals": 176720,
    "finished_requests": 77900,
    "scheduler_time": 92.48865775417758
}
#Debug simulation 
Total elapsed time: 6.059030099306256. Arrivals time: 0.2376552945934236 Scheduler time: 5.719122998416424 Scheduler overhead time: 0.032433181535452604 Adapter cache time: 0.022437666077166796 Engine time: 0.03238421073183417 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-16/adapters_160_slots_96_rate_0.8-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-16/adapters_160_slots_96_rate_0.8-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 1080, 135, 135, 135, 8640, 135, 1080, 8640, 1080, 135, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 135, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 135, 1080, 1080, 1080, 8640, 135, 135, 8640, 135, 8640, 135, 135, 1080, 135, 1080, 8640, 135, 135, 1080, 135, 135, 135, 135, 135, 8640, 1080, 1080, 8640, 1080, 135, 8640, 8640, 8640, 1080, 1080, 135, 135, 135, 8640, 135, 1080, 1080, 135, 8640, 8640, 8640, 135, 135, 8640, 1080, 8640, 8640, 135, 8640, 135, 1080, 135, 135, 1080, 1080, 8640, 8640, 8640, 135, 8640, 1080, 1080, 135, 135, 135, 135, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 135, 1080, 1080, 8640, 1080, 8640, 135, 135, 135, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 135, 1080, 1080, 135, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 135, 8640, 135, 8640, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 8640, 1080, 135, 135]
Prompts retrieved: 530955 . Total input tokens: 118470383 . Total output tokens: 106229005
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 6.0495703858323395,
    "estimated_duration": 3600.078308529701,
    "input_throughput": 5369.473201235651,
    "output_throughput": 4744.849566057453,
    "total_throughput": 10114.322767293103,
    "itl": 181.09750260039493,
    "ttft": 1629370.5655890298,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1172,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.664508310453924,
    "arrivals": 176720,
    "finished_requests": 78113,
    "scheduler_time": 92.38545163386702
}
#Debug simulation 
Total elapsed time: 6.049659324809909. Arrivals time: 0.23883399832993746 Scheduler time: 5.710816764738411 Scheduler overhead time: 0.03220567340031266 Adapter cache time: 0.021246476098895073 Engine time: 0.03185436688363552 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-32/adapters_160_slots_96_rate_0.8-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-32/adapters_160_slots_96_rate_0.8-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 1080, 135, 135, 135, 8640, 135, 1080, 8640, 1080, 135, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 135, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 135, 1080, 1080, 1080, 8640, 135, 135, 8640, 135, 8640, 135, 135, 1080, 135, 1080, 8640, 135, 135, 1080, 135, 135, 135, 135, 135, 8640, 1080, 1080, 8640, 1080, 135, 8640, 8640, 8640, 1080, 1080, 135, 135, 135, 8640, 135, 1080, 1080, 135, 8640, 8640, 8640, 135, 135, 8640, 1080, 8640, 8640, 135, 8640, 135, 1080, 135, 135, 1080, 1080, 8640, 8640, 8640, 135, 8640, 1080, 1080, 135, 135, 135, 135, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 135, 1080, 1080, 8640, 1080, 8640, 135, 135, 135, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 135, 1080, 1080, 135, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 135, 8640, 135, 8640, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 8640, 1080, 135, 135]
Prompts retrieved: 530955 . Total input tokens: 118470383 . Total output tokens: 106229005
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 6.044370366726071,
    "estimated_duration": 3600.040535091076,
    "input_throughput": 5356.549408828295,
    "output_throughput": 4731.764777078836,
    "total_throughput": 10088.314185907131,
    "itl": 178.89686183415523,
    "ttft": 1631960.5275254888,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1222,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.0338549939915485,
    "arrivals": 176720,
    "finished_requests": 77897,
    "scheduler_time": 92.48634593456899
}
#Debug simulation 
Total elapsed time: 6.044457426760346. Arrivals time: 0.24082141555845737 Scheduler time: 5.701281446963549 Scheduler overhead time: 0.03259878512471914 Adapter cache time: 0.022509964648634195 Engine time: 0.03238319419324398 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-16/adapters_160_slots_96_rate_0.8-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-16/adapters_160_slots_96_rate_0.8-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 1080, 135, 135, 135, 8640, 135, 1080, 8640, 1080, 135, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 135, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 135, 1080, 1080, 1080, 8640, 135, 135, 8640, 135, 8640, 135, 135, 1080, 135, 1080, 8640, 135, 135, 1080, 135, 135, 135, 135, 135, 8640, 1080, 1080, 8640, 1080, 135, 8640, 8640, 8640, 1080, 1080, 135, 135, 135, 8640, 135, 1080, 1080, 135, 8640, 8640, 8640, 135, 135, 8640, 1080, 8640, 8640, 135, 8640, 135, 1080, 135, 135, 1080, 1080, 8640, 8640, 8640, 135, 8640, 1080, 1080, 135, 135, 135, 135, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 135, 1080, 1080, 8640, 1080, 8640, 135, 135, 135, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 135, 1080, 1080, 135, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 135, 8640, 135, 8640, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 8640, 1080, 135, 135]
Prompts retrieved: 530955 . Total input tokens: 118470383 . Total output tokens: 106229005
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 6.0742639768868685,
    "estimated_duration": 3600.1402915382173,
    "input_throughput": 5369.459641735407,
    "output_throughput": 4744.899258551203,
    "total_throughput": 10114.35890028661,
    "itl": 181.08523580779186,
    "ttft": 1629341.4922355586,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1168,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.492378744445654,
    "arrivals": 176720,
    "finished_requests": 78114,
    "scheduler_time": 92.3910679520709
}
#Debug simulation 
Total elapsed time: 6.074354238808155. Arrivals time: 0.23845066642388701 Scheduler time: 5.735660398378968 Scheduler overhead time: 0.032129097264260054 Adapter cache time: 0.021356526762247086 Engine time: 0.032094537280499935 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-32/adapters_160_slots_96_rate_0.8-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-32/adapters_160_slots_96_rate_0.8-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 1080, 135, 135, 135, 8640, 135, 1080, 8640, 1080, 135, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 135, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 135, 1080, 1080, 1080, 8640, 135, 135, 8640, 135, 8640, 135, 135, 1080, 135, 1080, 8640, 135, 135, 1080, 135, 135, 135, 135, 135, 8640, 1080, 1080, 8640, 1080, 135, 8640, 8640, 8640, 1080, 1080, 135, 135, 135, 8640, 135, 1080, 1080, 135, 8640, 8640, 8640, 135, 135, 8640, 1080, 8640, 8640, 135, 8640, 135, 1080, 135, 135, 1080, 1080, 8640, 8640, 8640, 135, 8640, 1080, 1080, 135, 135, 135, 135, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 135, 1080, 1080, 8640, 1080, 8640, 135, 135, 135, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 135, 1080, 1080, 135, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 135, 8640, 135, 8640, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 8640, 1080, 135, 135]
Prompts retrieved: 530955 . Total input tokens: 118470383 . Total output tokens: 106229005
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.047515894751996,
    "estimated_duration": 3600.0927546400862,
    "input_throughput": 5356.471711776178,
    "output_throughput": 4731.696142563139,
    "total_throughput": 10088.167854339317,
    "itl": 178.89895324181617,
    "ttft": 1631980.8694715465,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1222,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.085414046421699,
    "arrivals": 176720,
    "finished_requests": 77897,
    "scheduler_time": 92.48653087392003
}
#Debug simulation 
Total elapsed time: 6.047620134893805. Arrivals time: 0.24012780794873834 Scheduler time: 5.705721591133624 Scheduler overhead time: 0.0325526213273406 Adapter cache time: 0.022128665819764137 Engine time: 0.03221737081184983 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-8/adapters_160_slots_96_rate_0.8-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-8/adapters_160_slots_96_rate_0.8-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 1080, 66, 66, 66, 8640, 66, 1080, 8640, 1080, 66, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 66, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 66, 1080, 1080, 1080, 8640, 66, 66, 8640, 66, 8640, 66, 66, 1080, 66, 1080, 8640, 66, 66, 1080, 66, 66, 66, 66, 66, 8640, 1080, 1080, 8640, 1080, 66, 8640, 8640, 8640, 1080, 1080, 66, 66, 66, 8640, 66, 1080, 1080, 66, 8640, 8640, 8640, 66, 66, 8640, 1080, 8640, 8640, 66, 8640, 66, 1080, 66, 66, 1080, 1080, 8640, 8640, 8640, 66, 8640, 1080, 1080, 66, 66, 66, 66, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 66, 1080, 1080, 8640, 1080, 8640, 66, 66, 66, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 66, 1080, 1080, 66, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 66, 8640, 66, 8640, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 8640, 1080, 66, 66]
Prompts retrieved: 527298 . Total input tokens: 117664903 . Total output tokens: 105498308
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.942722885869443,
    "estimated_duration": 3600.043315018747,
    "input_throughput": 5381.250253067891,
    "output_throughput": 4740.764626025375,
    "total_throughput": 10122.014879093265,
    "itl": 180.5049699180545,
    "ttft": 1629183.212440552,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1032,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1584233517386755,
    "arrivals": 175562,
    "finished_requests": 78248,
    "scheduler_time": 92.42793515321219
}
#Debug simulation 
Total elapsed time: 5.942833105102181. Arrivals time: 0.24408657243475318 Scheduler time: 5.599538179114461 Scheduler overhead time: 0.03224639734253287 Adapter cache time: 0.019777373876422644 Engine time: 0.03235614113509655 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-16/adapters_160_slots_96_rate_0.8-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-16/adapters_160_slots_96_rate_0.8-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 1080, 66, 66, 66, 8640, 66, 1080, 8640, 1080, 66, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 66, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 66, 1080, 1080, 1080, 8640, 66, 66, 8640, 66, 8640, 66, 66, 1080, 66, 1080, 8640, 66, 66, 1080, 66, 66, 66, 66, 66, 8640, 1080, 1080, 8640, 1080, 66, 8640, 8640, 8640, 1080, 1080, 66, 66, 66, 8640, 66, 1080, 1080, 66, 8640, 8640, 8640, 66, 66, 8640, 1080, 8640, 8640, 66, 8640, 66, 1080, 66, 66, 1080, 1080, 8640, 8640, 8640, 66, 8640, 1080, 1080, 66, 66, 66, 66, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 66, 1080, 1080, 8640, 1080, 8640, 66, 66, 66, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 66, 1080, 1080, 66, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 66, 8640, 66, 8640, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 8640, 1080, 66, 66]
Prompts retrieved: 527298 . Total input tokens: 117664903 . Total output tokens: 105498308
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.929104979149997,
    "estimated_duration": 3600.1629925408806,
    "input_throughput": 5381.215250570357,
    "output_throughput": 4740.706750044789,
    "total_throughput": 10121.922000615146,
    "itl": 180.51351447990064,
    "ttft": 1629181.3433880832,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1037,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3777097817161152,
    "arrivals": 175562,
    "finished_requests": 78249,
    "scheduler_time": 92.42630512046675
}
#Debug simulation 
Total elapsed time: 5.9291956489905715. Arrivals time: 0.23558129649609327 Scheduler time: 5.594839001074433 Scheduler overhead time: 0.032000831328332424 Adapter cache time: 0.019888699986040592 Engine time: 0.03213266050443053 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-32/adapters_160_slots_96_rate_0.8-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-32/adapters_160_slots_96_rate_0.8-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 1080, 66, 66, 66, 8640, 66, 1080, 8640, 1080, 66, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 66, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 66, 1080, 1080, 1080, 8640, 66, 66, 8640, 66, 8640, 66, 66, 1080, 66, 1080, 8640, 66, 66, 1080, 66, 66, 66, 66, 66, 8640, 1080, 1080, 8640, 1080, 66, 8640, 8640, 8640, 1080, 1080, 66, 66, 66, 8640, 66, 1080, 1080, 66, 8640, 8640, 8640, 66, 66, 8640, 1080, 8640, 8640, 66, 8640, 66, 1080, 66, 66, 1080, 1080, 8640, 8640, 8640, 66, 8640, 1080, 1080, 66, 66, 66, 66, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 66, 1080, 1080, 8640, 1080, 8640, 66, 66, 66, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 66, 1080, 1080, 66, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 66, 8640, 66, 8640, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 8640, 1080, 66, 66]
Prompts retrieved: 527298 . Total input tokens: 117664903 . Total output tokens: 105498308
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.894732139073312,
    "estimated_duration": 3600.015109758273,
    "input_throughput": 5369.980516914572,
    "output_throughput": 4730.2943128878815,
    "total_throughput": 10100.274829802453,
    "itl": 178.61878036779004,
    "ttft": 1632040.972933039,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1060,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.459167998414446,
    "arrivals": 175562,
    "finished_requests": 78074,
    "scheduler_time": 92.48761803499666
}
#Debug simulation 
Total elapsed time: 5.8948040790855885. Arrivals time: 0.2252333746291697 Scheduler time: 5.569650972262025 Scheduler overhead time: 0.03244992019608617 Adapter cache time: 0.020228507462888956 Engine time: 0.03234288841485977 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-16/adapters_160_slots_96_rate_0.8-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-16/adapters_160_slots_96_rate_0.8-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 1080, 66, 66, 66, 8640, 66, 1080, 8640, 1080, 66, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 66, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 66, 1080, 1080, 1080, 8640, 66, 66, 8640, 66, 8640, 66, 66, 1080, 66, 1080, 8640, 66, 66, 1080, 66, 66, 66, 66, 66, 8640, 1080, 1080, 8640, 1080, 66, 8640, 8640, 8640, 1080, 1080, 66, 66, 66, 8640, 66, 1080, 1080, 66, 8640, 8640, 8640, 66, 66, 8640, 1080, 8640, 8640, 66, 8640, 66, 1080, 66, 66, 1080, 1080, 8640, 8640, 8640, 66, 8640, 1080, 1080, 66, 66, 66, 66, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 66, 1080, 1080, 8640, 1080, 8640, 66, 66, 66, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 66, 1080, 1080, 66, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 66, 8640, 66, 8640, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 8640, 1080, 66, 66]
Prompts retrieved: 527298 . Total input tokens: 117664903 . Total output tokens: 105498308
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.898540463298559,
    "estimated_duration": 3600.129106255171,
    "input_throughput": 5381.122017635468,
    "output_throughput": 4740.651653393878,
    "total_throughput": 10121.773671029347,
    "itl": 180.50733700622916,
    "ttft": 1629207.3659230908,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1032,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2238371219718482,
    "arrivals": 175562,
    "finished_requests": 78248,
    "scheduler_time": 92.4287705839131
}
#Debug simulation 
Total elapsed time: 5.89862773520872. Arrivals time: 0.22685127845034003 Scheduler time: 5.573339004535228 Scheduler overhead time: 0.03201487800106406 Adapter cache time: 0.019702814053744078 Engine time: 0.03200191678479314 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-32/adapters_160_slots_96_rate_0.8-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-32/adapters_160_slots_96_rate_0.8-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 1080, 66, 66, 66, 8640, 66, 1080, 8640, 1080, 66, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 66, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 66, 1080, 1080, 1080, 8640, 66, 66, 8640, 66, 8640, 66, 66, 1080, 66, 1080, 8640, 66, 66, 1080, 66, 66, 66, 66, 66, 8640, 1080, 1080, 8640, 1080, 66, 8640, 8640, 8640, 1080, 1080, 66, 66, 66, 8640, 66, 1080, 1080, 66, 8640, 8640, 8640, 66, 66, 8640, 1080, 8640, 8640, 66, 8640, 66, 1080, 66, 66, 1080, 1080, 8640, 8640, 8640, 66, 8640, 1080, 1080, 66, 66, 66, 66, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 66, 1080, 1080, 8640, 1080, 8640, 66, 66, 66, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 66, 1080, 1080, 66, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 66, 8640, 66, 8640, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 8640, 1080, 66, 66]
Prompts retrieved: 527298 . Total input tokens: 117664903 . Total output tokens: 105498308
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.830386966001242,
    "estimated_duration": 3600.1851986307547,
    "input_throughput": 5369.701260744152,
    "output_throughput": 4730.070277072587,
    "total_throughput": 10099.77153781674,
    "itl": 178.59971509554742,
    "ttft": 1632011.8694004058,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1066,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5218259103037433,
    "arrivals": 175562,
    "finished_requests": 78073,
    "scheduler_time": 92.49166057881051
}
#Debug simulation 
Total elapsed time: 5.830478162039071. Arrivals time: 0.22544618276879191 Scheduler time: 5.504956048447639 Scheduler overhead time: 0.03235981799662113 Adapter cache time: 0.020381140056997538 Engine time: 0.03246431378647685 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-16/adapters_160_slots_96_rate_0.8-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-16/adapters_160_slots_96_rate_0.8-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 1080, 66, 66, 66, 8640, 66, 1080, 8640, 1080, 66, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 66, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 66, 1080, 1080, 1080, 8640, 66, 66, 8640, 66, 8640, 66, 66, 1080, 66, 1080, 8640, 66, 66, 1080, 66, 66, 66, 66, 66, 8640, 1080, 1080, 8640, 1080, 66, 8640, 8640, 8640, 1080, 1080, 66, 66, 66, 8640, 66, 1080, 1080, 66, 8640, 8640, 8640, 66, 66, 8640, 1080, 8640, 8640, 66, 8640, 66, 1080, 66, 66, 1080, 1080, 8640, 8640, 8640, 66, 8640, 1080, 1080, 66, 66, 66, 66, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 66, 1080, 1080, 8640, 1080, 8640, 66, 66, 66, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 66, 1080, 1080, 66, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 66, 8640, 66, 8640, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 8640, 1080, 66, 66]
Prompts retrieved: 527298 . Total input tokens: 117664903 . Total output tokens: 105498308
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.896022774279118,
    "estimated_duration": 3600.1901500208883,
    "input_throughput": 5381.303818046275,
    "output_throughput": 4740.9879169579335,
    "total_throughput": 10122.291735004208,
    "itl": 180.50240694413455,
    "ttft": 1629113.986192452,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1030,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0797518037491685,
    "arrivals": 175562,
    "finished_requests": 78253,
    "scheduler_time": 92.43355068094422
}
#Debug simulation 
Total elapsed time: 5.896098492201418. Arrivals time: 0.2253017444163561 Scheduler time: 5.571799589321017 Scheduler overhead time: 0.03231019852682948 Adapter cache time: 0.019976697396486998 Engine time: 0.03199026174843311 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-32/adapters_160_slots_96_rate_0.8-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-32/adapters_160_slots_96_rate_0.8-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 1080, 66, 66, 66, 8640, 66, 1080, 8640, 1080, 66, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 66, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 66, 1080, 1080, 1080, 8640, 66, 66, 8640, 66, 8640, 66, 66, 1080, 66, 1080, 8640, 66, 66, 1080, 66, 66, 66, 66, 66, 8640, 1080, 1080, 8640, 1080, 66, 8640, 8640, 8640, 1080, 1080, 66, 66, 66, 8640, 66, 1080, 1080, 66, 8640, 8640, 8640, 66, 66, 8640, 1080, 8640, 8640, 66, 8640, 66, 1080, 66, 66, 1080, 1080, 8640, 8640, 8640, 66, 8640, 1080, 1080, 66, 66, 66, 66, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 66, 1080, 1080, 8640, 1080, 8640, 66, 66, 66, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 66, 1080, 1080, 66, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 66, 8640, 66, 8640, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 8640, 1080, 66, 66]
Prompts retrieved: 527298 . Total input tokens: 117664903 . Total output tokens: 105498308
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.90309774922207,
    "estimated_duration": 3600.0996628843427,
    "input_throughput": 5369.888283734735,
    "output_throughput": 4730.060996799429,
    "total_throughput": 10099.949280534163,
    "itl": 178.61313995320012,
    "ttft": 1632224.182729672,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1056,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5329637868702863,
    "arrivals": 175562,
    "finished_requests": 78074,
    "scheduler_time": 92.4882834937294
}
#Debug simulation 
Total elapsed time: 5.903174008242786. Arrivals time: 0.22544896975159645 Scheduler time: 5.577288741711527 Scheduler overhead time: 0.03253952832892537 Adapter cache time: 0.02034765388816595 Engine time: 0.03259903844445944 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-8/adapters_160_slots_96_rate_0.8-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-8/adapters_160_slots_96_rate_0.8-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 1080, 33, 33, 33, 8640, 33, 1080, 8640, 1080, 33, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 33, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 33, 1080, 1080, 1080, 8640, 33, 33, 8640, 33, 8640, 33, 33, 1080, 33, 1080, 8640, 33, 33, 1080, 33, 33, 33, 33, 33, 8640, 1080, 1080, 8640, 1080, 33, 8640, 8640, 8640, 1080, 1080, 33, 33, 33, 8640, 33, 1080, 1080, 33, 8640, 8640, 8640, 33, 33, 8640, 1080, 8640, 8640, 33, 8640, 33, 1080, 33, 33, 1080, 1080, 8640, 8640, 8640, 33, 8640, 1080, 1080, 33, 33, 33, 33, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 33, 1080, 1080, 8640, 1080, 8640, 33, 33, 33, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 33, 1080, 1080, 33, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 33, 8640, 33, 8640, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 8640, 1080, 33, 33]
Prompts retrieved: 525549 . Total input tokens: 117286699 . Total output tokens: 105141760
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.756236820947379,
    "estimated_duration": 3600.1456470483804,
    "input_throughput": 5398.038553227133,
    "output_throughput": 4744.950253333581,
    "total_throughput": 10142.988806560714,
    "itl": 180.4556231987916,
    "ttft": 1622373.3651848517,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1031,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1553628639947426,
    "arrivals": 174997,
    "finished_requests": 78045,
    "scheduler_time": 92.33779903726177
}
#Debug simulation 
Total elapsed time: 5.756310128141195. Arrivals time: 0.22461614618077874 Scheduler time: 5.433027438819408 Scheduler overhead time: 0.03218009229749441 Adapter cache time: 0.019583724439144135 Engine time: 0.03216582955792546 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-16/adapters_160_slots_96_rate_0.8-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-16/adapters_160_slots_96_rate_0.8-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 1080, 33, 33, 33, 8640, 33, 1080, 8640, 1080, 33, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 33, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 33, 1080, 1080, 1080, 8640, 33, 33, 8640, 33, 8640, 33, 33, 1080, 33, 1080, 8640, 33, 33, 1080, 33, 33, 33, 33, 33, 8640, 1080, 1080, 8640, 1080, 33, 8640, 8640, 8640, 1080, 1080, 33, 33, 33, 8640, 33, 1080, 1080, 33, 8640, 8640, 8640, 33, 33, 8640, 1080, 8640, 8640, 33, 8640, 33, 1080, 33, 33, 1080, 1080, 8640, 8640, 8640, 33, 8640, 1080, 1080, 33, 33, 33, 33, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 33, 1080, 1080, 8640, 1080, 8640, 33, 33, 33, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 33, 1080, 1080, 33, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 33, 8640, 33, 8640, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 8640, 1080, 33, 33]
Prompts retrieved: 525549 . Total input tokens: 117286699 . Total output tokens: 105141760
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.733113053720444,
    "estimated_duration": 3600.0314694145522,
    "input_throughput": 5397.806981715116,
    "output_throughput": 4744.751857065795,
    "total_throughput": 10142.558838780911,
    "itl": 180.46290136214557,
    "ttft": 1622433.5454412915,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1025,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.347958107953898,
    "arrivals": 174997,
    "finished_requests": 78040,
    "scheduler_time": 92.33053005347902
}
#Debug simulation 
Total elapsed time: 5.733201337978244. Arrivals time: 0.22407951718196273 Scheduler time: 5.41070024156943 Scheduler overhead time: 0.03212753031402826 Adapter cache time: 0.019445805344730616 Engine time: 0.03219917323440313 
