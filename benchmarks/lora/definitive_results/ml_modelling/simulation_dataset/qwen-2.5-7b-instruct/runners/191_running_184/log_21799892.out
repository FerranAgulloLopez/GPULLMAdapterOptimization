INFO 06-01 00:47:16 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:47:16 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-8/adapters_320_slots_192_rate_3.2-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-8/adapters_320_slots_192_rate_3.2-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [270, 34560, 34560, 33, 34560, 34560, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 34560, 34560, 270, 33, 33, 270, 34560, 34560, 270, 270, 33, 33, 270, 34560, 34560, 33, 34560, 270, 33, 270, 34560, 33, 270, 34560, 34560, 270, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 270, 270, 270, 33, 270, 33, 34560, 33, 34560, 270, 34560, 34560, 33, 34560, 33, 34560, 270, 33, 33, 270, 270, 34560, 270, 34560, 34560, 34560, 33, 270, 270, 33, 34560, 270, 34560, 34560, 270, 33, 270, 270, 270, 33, 34560, 270, 34560, 33, 34560, 33, 33, 270, 34560, 34560, 270, 33, 270, 33, 270, 34560, 34560, 270, 33, 270, 33, 34560, 33, 33, 33, 33, 34560, 270, 270, 34560, 270, 270, 33, 270, 34560, 270, 33, 33, 270, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 270, 34560, 270, 270, 270, 33, 34560, 33, 34560, 270, 33, 270, 33, 33, 270, 33, 270, 34560, 34560, 34560, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 33, 33, 34560, 270, 34560, 270, 34560, 270, 33, 270, 33, 33, 33, 34560, 34560, 270, 270, 33, 33, 270, 33, 34560, 33, 33, 270, 33, 34560, 270, 33, 34560, 33, 33, 34560, 270, 34560, 270, 33, 270, 34560, 270, 270, 34560, 270, 33, 270, 33, 34560, 270, 270, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 270, 33, 270, 33, 270, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 270, 270, 34560, 33, 34560, 33, 33, 33, 34560, 270, 34560, 34560, 33, 270, 270, 270, 33, 270, 33, 270, 270, 34560, 33, 33, 270, 33, 270, 270, 33, 34560, 34560, 34560, 33, 270, 270, 270, 270, 33, 270, 33, 34560, 33, 33, 34560, 270, 34560, 270, 270, 270, 270, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3730308 . Total input tokens: 830506775 . Total output tokens: 745982208
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.158466549008153,
    "estimated_duration": 3600.078939008749,
    "input_throughput": 4937.833670084644,
    "output_throughput": 4343.980580688593,
    "total_throughput": 9281.814250773237,
    "itl": 197.451555530928,
    "ttft": 2179496.930157745,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 398,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2180741220852422,
    "arrivals": 1242821,
    "finished_requests": 71835,
    "scheduler_time": 88.25731540392903
}
#Debug simulation 
Total elapsed time: 5.15861348103499. Arrivals time: 0.251739228668157 Scheduler time: 4.816839383624028 Scheduler overhead time: 0.028294967371039093 Adapter cache time: 0.019193043757695705 Engine time: 0.02927589335013181 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-16/adapters_320_slots_192_rate_3.2-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-16/adapters_320_slots_192_rate_3.2-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [270, 34560, 34560, 33, 34560, 34560, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 34560, 34560, 270, 33, 33, 270, 34560, 34560, 270, 270, 33, 33, 270, 34560, 34560, 33, 34560, 270, 33, 270, 34560, 33, 270, 34560, 34560, 270, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 270, 270, 270, 33, 270, 33, 34560, 33, 34560, 270, 34560, 34560, 33, 34560, 33, 34560, 270, 33, 33, 270, 270, 34560, 270, 34560, 34560, 34560, 33, 270, 270, 33, 34560, 270, 34560, 34560, 270, 33, 270, 270, 270, 33, 34560, 270, 34560, 33, 34560, 33, 33, 270, 34560, 34560, 270, 33, 270, 33, 270, 34560, 34560, 270, 33, 270, 33, 34560, 33, 33, 33, 33, 34560, 270, 270, 34560, 270, 270, 33, 270, 34560, 270, 33, 33, 270, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 270, 34560, 270, 270, 270, 33, 34560, 33, 34560, 270, 33, 270, 33, 33, 270, 33, 270, 34560, 34560, 34560, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 33, 33, 34560, 270, 34560, 270, 34560, 270, 33, 270, 33, 33, 33, 34560, 34560, 270, 270, 33, 33, 270, 33, 34560, 33, 33, 270, 33, 34560, 270, 33, 34560, 33, 33, 34560, 270, 34560, 270, 33, 270, 34560, 270, 270, 34560, 270, 33, 270, 33, 34560, 270, 270, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 270, 33, 270, 33, 270, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 270, 270, 34560, 33, 34560, 33, 33, 33, 34560, 270, 34560, 34560, 33, 270, 270, 270, 33, 270, 33, 270, 270, 34560, 33, 33, 270, 33, 270, 270, 33, 34560, 34560, 34560, 33, 270, 270, 270, 270, 33, 270, 33, 34560, 33, 33, 34560, 270, 34560, 270, 270, 270, 270, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3730308 . Total input tokens: 830506775 . Total output tokens: 745982208
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.125047323992476,
    "estimated_duration": 3600.136356860912,
    "input_throughput": 4930.086596907672,
    "output_throughput": 4337.242663112624,
    "total_throughput": 9267.329260020295,
    "itl": 195.59812953880595,
    "ttft": 2180103.8469835133,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 398,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.297909181439323,
    "arrivals": 1242821,
    "finished_requests": 71713,
    "scheduler_time": 88.38196812633255
}
#Debug simulation 
Total elapsed time: 5.125146884995047. Arrivals time: 0.2436309044715017 Scheduler time: 4.790477778471541 Scheduler overhead time: 0.028722476155962795 Adapter cache time: 0.019227152632083744 Engine time: 0.029687106085475534 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-32/adapters_320_slots_192_rate_3.2-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-32/adapters_320_slots_192_rate_3.2-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [270, 34560, 34560, 33, 34560, 34560, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 34560, 34560, 270, 33, 33, 270, 34560, 34560, 270, 270, 33, 33, 270, 34560, 34560, 33, 34560, 270, 33, 270, 34560, 33, 270, 34560, 34560, 270, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 270, 270, 270, 33, 270, 33, 34560, 33, 34560, 270, 34560, 34560, 33, 34560, 33, 34560, 270, 33, 33, 270, 270, 34560, 270, 34560, 34560, 34560, 33, 270, 270, 33, 34560, 270, 34560, 34560, 270, 33, 270, 270, 270, 33, 34560, 270, 34560, 33, 34560, 33, 33, 270, 34560, 34560, 270, 33, 270, 33, 270, 34560, 34560, 270, 33, 270, 33, 34560, 33, 33, 33, 33, 34560, 270, 270, 34560, 270, 270, 33, 270, 34560, 270, 33, 33, 270, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 270, 34560, 270, 270, 270, 33, 34560, 33, 34560, 270, 33, 270, 33, 33, 270, 33, 270, 34560, 34560, 34560, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 33, 33, 34560, 270, 34560, 270, 34560, 270, 33, 270, 33, 33, 33, 34560, 34560, 270, 270, 33, 33, 270, 33, 34560, 33, 33, 270, 33, 34560, 270, 33, 34560, 33, 33, 34560, 270, 34560, 270, 33, 270, 34560, 270, 270, 34560, 270, 33, 270, 33, 34560, 270, 270, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 270, 33, 270, 33, 270, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 270, 270, 34560, 33, 34560, 33, 33, 33, 34560, 270, 34560, 34560, 33, 270, 270, 270, 33, 270, 33, 270, 270, 34560, 33, 33, 270, 33, 270, 270, 33, 34560, 34560, 34560, 33, 270, 270, 270, 270, 33, 270, 33, 34560, 33, 33, 34560, 270, 34560, 270, 270, 270, 270, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3730308 . Total input tokens: 830506775 . Total output tokens: 745982208
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.423975203011651,
    "estimated_duration": 3600.016683838566,
    "input_throughput": 3971.588260739613,
    "output_throughput": 3506.6365266228554,
    "total_throughput": 7478.224787362468,
    "itl": 96.69854329173398,
    "ttft": 2287215.8420286565,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 327,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0694251123443304,
    "arrivals": 1242821,
    "finished_requests": 57769,
    "scheduler_time": 101.29307801067715
}
#Debug simulation 
Total elapsed time: 4.424083259014878. Arrivals time: 0.22722172911744565 Scheduler time: 4.009944387536962 Scheduler overhead time: 0.051605007553007454 Adapter cache time: 0.05759910709457472 Engine time: 0.052915504202246666 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-16/adapters_320_slots_192_rate_3.2-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-16/adapters_320_slots_192_rate_3.2-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [270, 34560, 34560, 33, 34560, 34560, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 34560, 34560, 270, 33, 33, 270, 34560, 34560, 270, 270, 33, 33, 270, 34560, 34560, 33, 34560, 270, 33, 270, 34560, 33, 270, 34560, 34560, 270, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 270, 270, 270, 33, 270, 33, 34560, 33, 34560, 270, 34560, 34560, 33, 34560, 33, 34560, 270, 33, 33, 270, 270, 34560, 270, 34560, 34560, 34560, 33, 270, 270, 33, 34560, 270, 34560, 34560, 270, 33, 270, 270, 270, 33, 34560, 270, 34560, 33, 34560, 33, 33, 270, 34560, 34560, 270, 33, 270, 33, 270, 34560, 34560, 270, 33, 270, 33, 34560, 33, 33, 33, 33, 34560, 270, 270, 34560, 270, 270, 33, 270, 34560, 270, 33, 33, 270, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 270, 34560, 270, 270, 270, 33, 34560, 33, 34560, 270, 33, 270, 33, 33, 270, 33, 270, 34560, 34560, 34560, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 33, 33, 34560, 270, 34560, 270, 34560, 270, 33, 270, 33, 33, 33, 34560, 34560, 270, 270, 33, 33, 270, 33, 34560, 33, 33, 270, 33, 34560, 270, 33, 34560, 33, 33, 34560, 270, 34560, 270, 33, 270, 34560, 270, 270, 34560, 270, 33, 270, 33, 34560, 270, 270, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 270, 33, 270, 33, 270, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 270, 270, 34560, 33, 34560, 33, 33, 33, 34560, 270, 34560, 34560, 33, 270, 270, 270, 33, 270, 33, 270, 270, 34560, 33, 33, 270, 33, 270, 270, 33, 34560, 34560, 34560, 33, 270, 270, 270, 270, 33, 270, 33, 34560, 33, 33, 34560, 270, 34560, 270, 270, 270, 270, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3730308 . Total input tokens: 830506775 . Total output tokens: 745982208
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 5.1260554129839875,
    "estimated_duration": 3600.084313338545,
    "input_throughput": 4930.157867202962,
    "output_throughput": 4337.305363140151,
    "total_throughput": 9267.463230343112,
    "itl": 195.5958340440795,
    "ttft": 2180078.9907207163,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 398,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.246017575997393,
    "arrivals": 1242821,
    "finished_requests": 71713,
    "scheduler_time": 88.38181620939778
}
#Debug simulation 
Total elapsed time: 5.126152570010163. Arrivals time: 0.24790287745418027 Scheduler time: 4.787621732917614 Scheduler overhead time: 0.028870697366073728 Adapter cache time: 0.01899750204756856 Engine time: 0.029361592198256403 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-32/adapters_320_slots_192_rate_3.2-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-32/adapters_320_slots_192_rate_3.2-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [270, 34560, 34560, 33, 34560, 34560, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 34560, 34560, 270, 33, 33, 270, 34560, 34560, 270, 270, 33, 33, 270, 34560, 34560, 33, 34560, 270, 33, 270, 34560, 33, 270, 34560, 34560, 270, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 270, 270, 270, 33, 270, 33, 34560, 33, 34560, 270, 34560, 34560, 33, 34560, 33, 34560, 270, 33, 33, 270, 270, 34560, 270, 34560, 34560, 34560, 33, 270, 270, 33, 34560, 270, 34560, 34560, 270, 33, 270, 270, 270, 33, 34560, 270, 34560, 33, 34560, 33, 33, 270, 34560, 34560, 270, 33, 270, 33, 270, 34560, 34560, 270, 33, 270, 33, 34560, 33, 33, 33, 33, 34560, 270, 270, 34560, 270, 270, 33, 270, 34560, 270, 33, 33, 270, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 270, 34560, 270, 270, 270, 33, 34560, 33, 34560, 270, 33, 270, 33, 33, 270, 33, 270, 34560, 34560, 34560, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 33, 33, 34560, 270, 34560, 270, 34560, 270, 33, 270, 33, 33, 33, 34560, 34560, 270, 270, 33, 33, 270, 33, 34560, 33, 33, 270, 33, 34560, 270, 33, 34560, 33, 33, 34560, 270, 34560, 270, 33, 270, 34560, 270, 270, 34560, 270, 33, 270, 33, 34560, 270, 270, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 270, 33, 270, 33, 270, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 270, 270, 34560, 33, 34560, 33, 33, 33, 34560, 270, 34560, 34560, 33, 270, 270, 270, 33, 270, 33, 270, 270, 34560, 33, 33, 270, 33, 270, 270, 33, 34560, 34560, 34560, 33, 270, 270, 270, 270, 33, 270, 33, 34560, 33, 33, 34560, 270, 34560, 270, 270, 270, 270, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3730308 . Total input tokens: 830506775 . Total output tokens: 745982208
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.406928878976032,
    "estimated_duration": 3600.030091057748,
    "input_throughput": 3971.5734697648254,
    "output_throughput": 3506.623467219652,
    "total_throughput": 7478.196936984477,
    "itl": 96.69889841466401,
    "ttft": 2287222.3878341024,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 327,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0827550137043052,
    "arrivals": 1242821,
    "finished_requests": 57769,
    "scheduler_time": 101.29315532850602
}
#Debug simulation 
Total elapsed time: 4.407023446983658. Arrivals time: 0.2134292145492509 Scheduler time: 4.005817597382702 Scheduler overhead time: 0.05167854542378336 Adapter cache time: 0.05823951418278739 Engine time: 0.05300241016084328 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-16/adapters_320_slots_192_rate_3.2-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-16/adapters_320_slots_192_rate_3.2-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [270, 34560, 34560, 33, 34560, 34560, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 34560, 34560, 270, 33, 33, 270, 34560, 34560, 270, 270, 33, 33, 270, 34560, 34560, 33, 34560, 270, 33, 270, 34560, 33, 270, 34560, 34560, 270, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 270, 270, 270, 33, 270, 33, 34560, 33, 34560, 270, 34560, 34560, 33, 34560, 33, 34560, 270, 33, 33, 270, 270, 34560, 270, 34560, 34560, 34560, 33, 270, 270, 33, 34560, 270, 34560, 34560, 270, 33, 270, 270, 270, 33, 34560, 270, 34560, 33, 34560, 33, 33, 270, 34560, 34560, 270, 33, 270, 33, 270, 34560, 34560, 270, 33, 270, 33, 34560, 33, 33, 33, 33, 34560, 270, 270, 34560, 270, 270, 33, 270, 34560, 270, 33, 33, 270, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 270, 34560, 270, 270, 270, 33, 34560, 33, 34560, 270, 33, 270, 33, 33, 270, 33, 270, 34560, 34560, 34560, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 33, 33, 34560, 270, 34560, 270, 34560, 270, 33, 270, 33, 33, 33, 34560, 34560, 270, 270, 33, 33, 270, 33, 34560, 33, 33, 270, 33, 34560, 270, 33, 34560, 33, 33, 34560, 270, 34560, 270, 33, 270, 34560, 270, 270, 34560, 270, 33, 270, 33, 34560, 270, 270, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 270, 33, 270, 33, 270, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 270, 270, 34560, 33, 34560, 33, 33, 33, 34560, 270, 34560, 34560, 33, 270, 270, 270, 33, 270, 33, 270, 270, 34560, 33, 33, 270, 33, 270, 270, 33, 34560, 34560, 34560, 33, 270, 270, 270, 270, 33, 270, 33, 34560, 33, 33, 34560, 270, 34560, 270, 270, 270, 270, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3730308 . Total input tokens: 830506775 . Total output tokens: 745982208
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.104759375040885,
    "estimated_duration": 3600.204736065914,
    "input_throughput": 4930.102119524304,
    "output_throughput": 4337.281389464322,
    "total_throughput": 9267.383508988625,
    "itl": 195.61659902714413,
    "ttft": 2180109.455131481,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 398,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1900400173710606,
    "arrivals": 1242821,
    "finished_requests": 71714,
    "scheduler_time": 88.38461565276275
}
#Debug simulation 
Total elapsed time: 5.104856203019153. Arrivals time: 0.25088420807151124 Scheduler time: 4.763301448256243 Scheduler overhead time: 0.028707340301480144 Adapter cache time: 0.019319887622259557 Engine time: 0.029362474335357547 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-32/adapters_320_slots_192_rate_3.2-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-32/adapters_320_slots_192_rate_3.2-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [270, 34560, 34560, 33, 34560, 34560, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 34560, 34560, 270, 33, 33, 270, 34560, 34560, 270, 270, 33, 33, 270, 34560, 34560, 33, 34560, 270, 33, 270, 34560, 33, 270, 34560, 34560, 270, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 270, 270, 270, 33, 270, 33, 34560, 33, 34560, 270, 34560, 34560, 33, 34560, 33, 34560, 270, 33, 33, 270, 270, 34560, 270, 34560, 34560, 34560, 33, 270, 270, 33, 34560, 270, 34560, 34560, 270, 33, 270, 270, 270, 33, 34560, 270, 34560, 33, 34560, 33, 33, 270, 34560, 34560, 270, 33, 270, 33, 270, 34560, 34560, 270, 33, 270, 33, 34560, 33, 33, 33, 33, 34560, 270, 270, 34560, 270, 270, 33, 270, 34560, 270, 33, 33, 270, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 270, 34560, 270, 270, 270, 33, 34560, 33, 34560, 270, 33, 270, 33, 33, 270, 33, 270, 34560, 34560, 34560, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 33, 33, 34560, 270, 34560, 270, 34560, 270, 33, 270, 33, 33, 33, 34560, 34560, 270, 270, 33, 33, 270, 33, 34560, 33, 33, 270, 33, 34560, 270, 33, 34560, 33, 33, 34560, 270, 34560, 270, 33, 270, 34560, 270, 270, 34560, 270, 33, 270, 33, 34560, 270, 270, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 270, 33, 270, 33, 270, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 270, 270, 34560, 33, 34560, 33, 33, 33, 34560, 270, 34560, 34560, 33, 270, 270, 270, 33, 270, 33, 270, 270, 34560, 33, 33, 270, 33, 270, 270, 33, 34560, 34560, 34560, 33, 270, 270, 270, 270, 33, 270, 33, 34560, 33, 33, 34560, 270, 34560, 270, 270, 270, 270, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3730308 . Total input tokens: 830506775 . Total output tokens: 745982208
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.808628999977373,
    "estimated_duration": 3600.044521348971,
    "input_throughput": 3971.557550250096,
    "output_throughput": 3506.6094113940803,
    "total_throughput": 7478.166961644177,
    "itl": 96.69927555510768,
    "ttft": 2287229.534059995,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 327,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0970909453555986,
    "arrivals": 1242821,
    "finished_requests": 57769,
    "scheduler_time": 101.29324968808619
}
#Debug simulation 
Total elapsed time: 4.8087310179835185. Arrivals time: 0.6002329141483642 Scheduler time: 4.020624313969165 Scheduler overhead time: 0.05147788586327806 Adapter cache time: 0.05831059598131105 Engine time: 0.05328143970109522 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-8/adapters_320_slots_192_rate_3.2-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-8/adapters_320_slots_192_rate_3.2-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [106 107 107]
Adapter prompts. [135, 34560, 34560, 66, 34560, 34560, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 34560, 34560, 135, 66, 66, 135, 34560, 34560, 135, 135, 66, 66, 135, 34560, 34560, 66, 34560, 135, 66, 135, 34560, 66, 135, 34560, 34560, 135, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 135, 135, 135, 66, 135, 66, 34560, 66, 34560, 135, 34560, 34560, 66, 34560, 66, 34560, 135, 66, 66, 135, 135, 34560, 135, 34560, 34560, 34560, 66, 135, 135, 66, 34560, 135, 34560, 34560, 135, 66, 135, 135, 135, 66, 34560, 135, 34560, 66, 34560, 66, 66, 135, 34560, 34560, 135, 66, 135, 66, 135, 34560, 34560, 135, 66, 135, 66, 34560, 66, 66, 66, 66, 34560, 135, 135, 34560, 135, 135, 66, 135, 34560, 135, 66, 66, 135, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 135, 34560, 135, 135, 135, 66, 34560, 66, 34560, 135, 66, 135, 66, 66, 135, 66, 135, 34560, 34560, 34560, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 66, 66, 34560, 135, 34560, 135, 34560, 135, 66, 135, 66, 66, 66, 34560, 34560, 135, 135, 66, 66, 135, 66, 34560, 66, 66, 135, 66, 34560, 135, 66, 34560, 66, 66, 34560, 135, 34560, 135, 66, 135, 34560, 135, 135, 34560, 135, 66, 135, 66, 34560, 135, 135, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 135, 66, 135, 66, 135, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 135, 135, 34560, 66, 34560, 66, 66, 66, 34560, 135, 34560, 34560, 66, 135, 135, 135, 66, 135, 66, 135, 135, 34560, 66, 66, 135, 66, 135, 135, 66, 34560, 34560, 34560, 66, 135, 135, 135, 135, 66, 135, 66, 34560, 66, 66, 34560, 135, 34560, 135, 135, 135, 135, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3719361 . Total input tokens: 828083487 . Total output tokens: 743797253
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.1564119620015845,
    "estimated_duration": 3600.194119064573,
    "input_throughput": 4958.152091153904,
    "output_throughput": 4387.661464239139,
    "total_throughput": 9345.813555393042,
    "itl": 196.10219233033843,
    "ttft": 2172129.0319285034,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 391,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1966507078777122,
    "arrivals": 1239193,
    "finished_requests": 72518,
    "scheduler_time": 89.07494077652885
}
#Debug simulation 
Total elapsed time: 5.156538270995952. Arrivals time: 0.2524205739609897 Scheduler time: 4.815538915747311 Scheduler overhead time: 0.028590722824446857 Adapter cache time: 0.01680626440793276 Engine time: 0.029831784951966256 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-16/adapters_320_slots_192_rate_3.2-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-16/adapters_320_slots_192_rate_3.2-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [106 107 107]
Adapter prompts. [135, 34560, 34560, 66, 34560, 34560, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 34560, 34560, 135, 66, 66, 135, 34560, 34560, 135, 135, 66, 66, 135, 34560, 34560, 66, 34560, 135, 66, 135, 34560, 66, 135, 34560, 34560, 135, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 135, 135, 135, 66, 135, 66, 34560, 66, 34560, 135, 34560, 34560, 66, 34560, 66, 34560, 135, 66, 66, 135, 135, 34560, 135, 34560, 34560, 34560, 66, 135, 135, 66, 34560, 135, 34560, 34560, 135, 66, 135, 135, 135, 66, 34560, 135, 34560, 66, 34560, 66, 66, 135, 34560, 34560, 135, 66, 135, 66, 135, 34560, 34560, 135, 66, 135, 66, 34560, 66, 66, 66, 66, 34560, 135, 135, 34560, 135, 135, 66, 135, 34560, 135, 66, 66, 135, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 135, 34560, 135, 135, 135, 66, 34560, 66, 34560, 135, 66, 135, 66, 66, 135, 66, 135, 34560, 34560, 34560, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 66, 66, 34560, 135, 34560, 135, 34560, 135, 66, 135, 66, 66, 66, 34560, 34560, 135, 135, 66, 66, 135, 66, 34560, 66, 66, 135, 66, 34560, 135, 66, 34560, 66, 66, 34560, 135, 34560, 135, 66, 135, 34560, 135, 135, 34560, 135, 66, 135, 66, 34560, 135, 135, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 135, 66, 135, 66, 135, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 135, 135, 34560, 66, 34560, 66, 66, 66, 34560, 135, 34560, 34560, 66, 135, 135, 135, 66, 135, 66, 135, 135, 34560, 66, 66, 135, 66, 135, 135, 66, 34560, 34560, 34560, 66, 135, 135, 135, 135, 66, 135, 66, 34560, 66, 66, 34560, 135, 34560, 135, 135, 135, 135, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3719361 . Total input tokens: 828083487 . Total output tokens: 743797253
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.328441489022225,
    "estimated_duration": 3600.1807049548343,
    "input_throughput": 4949.632660237135,
    "output_throughput": 4380.406788552533,
    "total_throughput": 9330.039448789668,
    "itl": 194.05786714230118,
    "ttft": 2172625.5923210424,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 391,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2798389966040924,
    "arrivals": 1239193,
    "finished_requests": 72374,
    "scheduler_time": 89.20278311964609
}
#Debug simulation 
Total elapsed time: 5.328536921995692. Arrivals time: 0.256715600611642 Scheduler time: 4.983075477764942 Scheduler overhead time: 0.028875140706077218 Adapter cache time: 0.01655966619728133 Engine time: 0.029703277396038175 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-32/adapters_320_slots_192_rate_3.2-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-32/adapters_320_slots_192_rate_3.2-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [106 107 107]
Adapter prompts. [135, 34560, 34560, 66, 34560, 34560, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 34560, 34560, 135, 66, 66, 135, 34560, 34560, 135, 135, 66, 66, 135, 34560, 34560, 66, 34560, 135, 66, 135, 34560, 66, 135, 34560, 34560, 135, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 135, 135, 135, 66, 135, 66, 34560, 66, 34560, 135, 34560, 34560, 66, 34560, 66, 34560, 135, 66, 66, 135, 135, 34560, 135, 34560, 34560, 34560, 66, 135, 135, 66, 34560, 135, 34560, 34560, 135, 66, 135, 135, 135, 66, 34560, 135, 34560, 66, 34560, 66, 66, 135, 34560, 34560, 135, 66, 135, 66, 135, 34560, 34560, 135, 66, 135, 66, 34560, 66, 66, 66, 66, 34560, 135, 135, 34560, 135, 135, 66, 135, 34560, 135, 66, 66, 135, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 135, 34560, 135, 135, 135, 66, 34560, 66, 34560, 135, 66, 135, 66, 66, 135, 66, 135, 34560, 34560, 34560, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 66, 66, 34560, 135, 34560, 135, 34560, 135, 66, 135, 66, 66, 66, 34560, 34560, 135, 135, 66, 66, 135, 66, 34560, 66, 66, 135, 66, 34560, 135, 66, 34560, 66, 66, 34560, 135, 34560, 135, 66, 135, 34560, 135, 135, 34560, 135, 66, 135, 66, 34560, 135, 135, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 135, 66, 135, 66, 135, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 135, 135, 34560, 66, 34560, 66, 66, 66, 34560, 135, 34560, 34560, 66, 135, 135, 135, 66, 135, 66, 135, 135, 34560, 66, 66, 135, 66, 135, 135, 66, 34560, 34560, 34560, 66, 135, 135, 135, 135, 66, 135, 66, 34560, 66, 66, 34560, 135, 34560, 135, 135, 135, 135, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3719361 . Total input tokens: 828083487 . Total output tokens: 743797253
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.44942910404643,
    "estimated_duration": 3600.059607863698,
    "input_throughput": 3972.934772734885,
    "output_throughput": 3526.39049983215,
    "total_throughput": 7499.3252725670345,
    "itl": 96.49237599785457,
    "ttft": 2280853.438545662,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 326,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0657070985063968,
    "arrivals": 1239193,
    "finished_requests": 58121,
    "scheduler_time": 101.61138037202363
}
#Debug simulation 
Total elapsed time: 4.449525262054522. Arrivals time: 0.21688784705474973 Scheduler time: 4.047202290617861 Scheduler overhead time: 0.05178264359710738 Adapter cache time: 0.055478618189226836 Engine time: 0.05335712217492983 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-16/adapters_320_slots_192_rate_3.2-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-16/adapters_320_slots_192_rate_3.2-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [106 107 107]
Adapter prompts. [135, 34560, 34560, 66, 34560, 34560, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 34560, 34560, 135, 66, 66, 135, 34560, 34560, 135, 135, 66, 66, 135, 34560, 34560, 66, 34560, 135, 66, 135, 34560, 66, 135, 34560, 34560, 135, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 135, 135, 135, 66, 135, 66, 34560, 66, 34560, 135, 34560, 34560, 66, 34560, 66, 34560, 135, 66, 66, 135, 135, 34560, 135, 34560, 34560, 34560, 66, 135, 135, 66, 34560, 135, 34560, 34560, 135, 66, 135, 135, 135, 66, 34560, 135, 34560, 66, 34560, 66, 66, 135, 34560, 34560, 135, 66, 135, 66, 135, 34560, 34560, 135, 66, 135, 66, 34560, 66, 66, 66, 66, 34560, 135, 135, 34560, 135, 135, 66, 135, 34560, 135, 66, 66, 135, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 135, 34560, 135, 135, 135, 66, 34560, 66, 34560, 135, 66, 135, 66, 66, 135, 66, 135, 34560, 34560, 34560, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 66, 66, 34560, 135, 34560, 135, 34560, 135, 66, 135, 66, 66, 66, 34560, 34560, 135, 135, 66, 66, 135, 66, 34560, 66, 66, 135, 66, 34560, 135, 66, 34560, 66, 66, 34560, 135, 34560, 135, 66, 135, 34560, 135, 135, 34560, 135, 66, 135, 66, 34560, 135, 135, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 135, 66, 135, 66, 135, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 135, 135, 34560, 66, 34560, 66, 66, 66, 34560, 135, 34560, 34560, 66, 135, 135, 135, 66, 135, 66, 135, 135, 34560, 66, 66, 135, 66, 135, 135, 66, 34560, 34560, 34560, 66, 135, 135, 135, 135, 66, 135, 66, 34560, 66, 66, 34560, 135, 34560, 135, 135, 135, 135, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3719361 . Total input tokens: 828083487 . Total output tokens: 743797253
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 5.148211430001538,
    "estimated_duration": 3600.122539398966,
    "input_throughput": 4949.712629219267,
    "output_throughput": 4380.477560809031,
    "total_throughput": 9330.190190028297,
    "itl": 194.0551903921661,
    "ttft": 2172598.5014362,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 391,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2218184613855556,
    "arrivals": 1239193,
    "finished_requests": 72374,
    "scheduler_time": 89.20263809898421
}
#Debug simulation 
Total elapsed time: 5.148304839036427. Arrivals time: 0.25083070842083544 Scheduler time: 4.8089795804116875 Scheduler overhead time: 0.028765014722011983 Adapter cache time: 0.016443643544334918 Engine time: 0.0298006787779741 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-32/adapters_320_slots_192_rate_3.2-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-32/adapters_320_slots_192_rate_3.2-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [106 107 107]
Adapter prompts. [135, 34560, 34560, 66, 34560, 34560, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 34560, 34560, 135, 66, 66, 135, 34560, 34560, 135, 135, 66, 66, 135, 34560, 34560, 66, 34560, 135, 66, 135, 34560, 66, 135, 34560, 34560, 135, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 135, 135, 135, 66, 135, 66, 34560, 66, 34560, 135, 34560, 34560, 66, 34560, 66, 34560, 135, 66, 66, 135, 135, 34560, 135, 34560, 34560, 34560, 66, 135, 135, 66, 34560, 135, 34560, 34560, 135, 66, 135, 135, 135, 66, 34560, 135, 34560, 66, 34560, 66, 66, 135, 34560, 34560, 135, 66, 135, 66, 135, 34560, 34560, 135, 66, 135, 66, 34560, 66, 66, 66, 66, 34560, 135, 135, 34560, 135, 135, 66, 135, 34560, 135, 66, 66, 135, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 135, 34560, 135, 135, 135, 66, 34560, 66, 34560, 135, 66, 135, 66, 66, 135, 66, 135, 34560, 34560, 34560, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 66, 66, 34560, 135, 34560, 135, 34560, 135, 66, 135, 66, 66, 66, 34560, 34560, 135, 135, 66, 66, 135, 66, 34560, 66, 66, 135, 66, 34560, 135, 66, 34560, 66, 66, 34560, 135, 34560, 135, 66, 135, 34560, 135, 135, 34560, 135, 66, 135, 66, 34560, 135, 135, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 135, 66, 135, 66, 135, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 135, 135, 34560, 66, 34560, 66, 66, 66, 34560, 135, 34560, 34560, 66, 135, 135, 135, 66, 135, 66, 135, 135, 34560, 66, 66, 135, 66, 135, 135, 66, 34560, 34560, 34560, 66, 135, 135, 135, 135, 66, 135, 66, 34560, 66, 66, 34560, 135, 34560, 135, 135, 135, 135, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3719361 . Total input tokens: 828083487 . Total output tokens: 743797253
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.439869786030613,
    "estimated_duration": 3600.0738891925266,
    "input_throughput": 3972.919012283947,
    "output_throughput": 3526.3765108019643,
    "total_throughput": 7499.295523085912,
    "itl": 96.4927672628927,
    "ttft": 2280860.4359020456,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 326,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0799172763712757,
    "arrivals": 1239193,
    "finished_requests": 58121,
    "scheduler_time": 101.61145152299308
}
#Debug simulation 
Total elapsed time: 4.4399921059957705. Arrivals time: 0.2139346344047226 Scheduler time: 4.03991073241923 Scheduler overhead time: 0.052202187885995954 Adapter cache time: 0.05528907134430483 Engine time: 0.05357183754676953 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-16/adapters_320_slots_192_rate_3.2-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-16/adapters_320_slots_192_rate_3.2-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [106 107 107]
Adapter prompts. [135, 34560, 34560, 66, 34560, 34560, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 34560, 34560, 135, 66, 66, 135, 34560, 34560, 135, 135, 66, 66, 135, 34560, 34560, 66, 34560, 135, 66, 135, 34560, 66, 135, 34560, 34560, 135, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 135, 135, 135, 66, 135, 66, 34560, 66, 34560, 135, 34560, 34560, 66, 34560, 66, 34560, 135, 66, 66, 135, 135, 34560, 135, 34560, 34560, 34560, 66, 135, 135, 66, 34560, 135, 34560, 34560, 135, 66, 135, 135, 135, 66, 34560, 135, 34560, 66, 34560, 66, 66, 135, 34560, 34560, 135, 66, 135, 66, 135, 34560, 34560, 135, 66, 135, 66, 34560, 66, 66, 66, 66, 34560, 135, 135, 34560, 135, 135, 66, 135, 34560, 135, 66, 66, 135, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 135, 34560, 135, 135, 135, 66, 34560, 66, 34560, 135, 66, 135, 66, 66, 135, 66, 135, 34560, 34560, 34560, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 66, 66, 34560, 135, 34560, 135, 34560, 135, 66, 135, 66, 66, 66, 34560, 34560, 135, 135, 66, 66, 135, 66, 34560, 66, 66, 135, 66, 34560, 135, 66, 34560, 66, 66, 34560, 135, 34560, 135, 66, 135, 34560, 135, 135, 34560, 135, 66, 135, 66, 34560, 135, 135, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 135, 66, 135, 66, 135, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 135, 135, 34560, 66, 34560, 66, 66, 66, 34560, 135, 34560, 34560, 66, 135, 135, 135, 66, 135, 66, 135, 135, 34560, 66, 66, 135, 66, 135, 135, 66, 34560, 34560, 34560, 66, 135, 135, 135, 135, 66, 135, 66, 34560, 66, 66, 34560, 135, 34560, 135, 135, 135, 135, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3719361 . Total input tokens: 828083487 . Total output tokens: 743797253
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.17947518103756,
    "estimated_duration": 3600.0696550131806,
    "input_throughput": 4949.785339621369,
    "output_throughput": 4380.54190924877,
    "total_throughput": 9330.327248870139,
    "itl": 194.05284747878858,
    "ttft": 2172573.283522754,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 391,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.169109665306746,
    "arrivals": 1239193,
    "finished_requests": 72374,
    "scheduler_time": 89.2024625092665
}
#Debug simulation 
Total elapsed time: 5.179574249021243. Arrivals time: 0.2546381446882151 Scheduler time: 4.836731283634435 Scheduler overhead time: 0.02884651010390371 Adapter cache time: 0.01627477683359757 Engine time: 0.029636901104822755 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-32/adapters_320_slots_192_rate_3.2-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-32/adapters_320_slots_192_rate_3.2-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [106 107 107]
Adapter prompts. [135, 34560, 34560, 66, 34560, 34560, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 34560, 34560, 135, 66, 66, 135, 34560, 34560, 135, 135, 66, 66, 135, 34560, 34560, 66, 34560, 135, 66, 135, 34560, 66, 135, 34560, 34560, 135, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 135, 135, 135, 66, 135, 66, 34560, 66, 34560, 135, 34560, 34560, 66, 34560, 66, 34560, 135, 66, 66, 135, 135, 34560, 135, 34560, 34560, 34560, 66, 135, 135, 66, 34560, 135, 34560, 34560, 135, 66, 135, 135, 135, 66, 34560, 135, 34560, 66, 34560, 66, 66, 135, 34560, 34560, 135, 66, 135, 66, 135, 34560, 34560, 135, 66, 135, 66, 34560, 66, 66, 66, 66, 34560, 135, 135, 34560, 135, 135, 66, 135, 34560, 135, 66, 66, 135, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 135, 34560, 135, 135, 135, 66, 34560, 66, 34560, 135, 66, 135, 66, 66, 135, 66, 135, 34560, 34560, 34560, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 66, 66, 34560, 135, 34560, 135, 34560, 135, 66, 135, 66, 66, 66, 34560, 34560, 135, 135, 66, 66, 135, 66, 34560, 66, 66, 135, 66, 34560, 135, 66, 34560, 66, 66, 34560, 135, 34560, 135, 66, 135, 34560, 135, 135, 34560, 135, 66, 135, 66, 34560, 135, 135, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 135, 66, 135, 66, 135, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 135, 135, 34560, 66, 34560, 66, 66, 66, 34560, 135, 34560, 34560, 66, 135, 135, 135, 66, 135, 66, 135, 135, 34560, 66, 66, 135, 66, 135, 135, 66, 34560, 34560, 34560, 66, 135, 135, 135, 135, 66, 135, 66, 34560, 66, 66, 34560, 135, 34560, 135, 135, 135, 135, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3719361 . Total input tokens: 828083487 . Total output tokens: 743797253
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.430213605053723,
    "estimated_duration": 3600.08718053816,
    "input_throughput": 3972.904344461442,
    "output_throughput": 3526.3634915925154,
    "total_throughput": 7499.267836053958,
    "itl": 96.49313042032036,
    "ttft": 2280867.085334426,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 326,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0931214239448355,
    "arrivals": 1239193,
    "finished_requests": 58121,
    "scheduler_time": 101.61153872105909
}
#Debug simulation 
Total elapsed time: 4.430334010045044. Arrivals time: 0.21901569253532216 Scheduler time: 4.0256796414614655 Scheduler overhead time: 0.05218017095467076 Adapter cache time: 0.05537499685306102 Engine time: 0.053268297750037163 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-8/adapters_320_slots_192_rate_3.2-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-8/adapters_320_slots_192_rate_3.2-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [135, 34560, 34560, 33, 34560, 34560, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 34560, 34560, 135, 33, 33, 135, 34560, 34560, 135, 135, 33, 33, 135, 34560, 34560, 33, 34560, 135, 33, 135, 34560, 33, 135, 34560, 34560, 135, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 135, 135, 135, 33, 135, 33, 34560, 33, 34560, 135, 34560, 34560, 33, 34560, 33, 34560, 135, 33, 33, 135, 135, 34560, 135, 34560, 34560, 34560, 33, 135, 135, 33, 34560, 135, 34560, 34560, 135, 33, 135, 135, 135, 33, 34560, 135, 34560, 33, 34560, 33, 33, 135, 34560, 34560, 135, 33, 135, 33, 135, 34560, 34560, 135, 33, 135, 33, 34560, 33, 33, 33, 33, 34560, 135, 135, 34560, 135, 135, 33, 135, 34560, 135, 33, 33, 135, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 135, 34560, 135, 135, 135, 33, 34560, 33, 34560, 135, 33, 135, 33, 33, 135, 33, 135, 34560, 34560, 34560, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 33, 33, 34560, 135, 34560, 135, 34560, 135, 33, 135, 33, 33, 33, 34560, 34560, 135, 135, 33, 33, 135, 33, 34560, 33, 33, 135, 33, 34560, 135, 33, 34560, 33, 33, 34560, 135, 34560, 135, 33, 135, 34560, 135, 135, 34560, 135, 33, 135, 33, 34560, 135, 135, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 135, 33, 135, 33, 135, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 135, 135, 34560, 33, 34560, 33, 33, 33, 34560, 135, 34560, 34560, 33, 135, 135, 135, 33, 135, 33, 135, 135, 34560, 33, 33, 135, 33, 135, 135, 33, 34560, 34560, 34560, 33, 135, 135, 135, 135, 33, 135, 33, 34560, 33, 33, 34560, 135, 34560, 135, 135, 135, 135, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3715863 . Total input tokens: 827311191 . Total output tokens: 743093542
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.264251170039643,
    "estimated_duration": 3600.2100730568823,
    "input_throughput": 5005.963717194247,
    "output_throughput": 4410.042935777638,
    "total_throughput": 9416.006652971884,
    "itl": 194.70203825648625,
    "ttft": 2171522.0598098664,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 330,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0099609554978077,
    "arrivals": 1238058,
    "finished_requests": 72549,
    "scheduler_time": 89.54550132616139
}
#Debug simulation 
Total elapsed time: 5.264343834016472. Arrivals time: 0.25875866902060807 Scheduler time: 4.919330620497931 Scheduler overhead time: 0.028856094810180366 Adapter cache time: 0.014179674733895808 Engine time: 0.029689875664189458 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-16/adapters_320_slots_192_rate_3.2-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-16/adapters_320_slots_192_rate_3.2-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [135, 34560, 34560, 33, 34560, 34560, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 34560, 34560, 135, 33, 33, 135, 34560, 34560, 135, 135, 33, 33, 135, 34560, 34560, 33, 34560, 135, 33, 135, 34560, 33, 135, 34560, 34560, 135, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 135, 135, 135, 33, 135, 33, 34560, 33, 34560, 135, 34560, 34560, 33, 34560, 33, 34560, 135, 33, 33, 135, 135, 34560, 135, 34560, 34560, 34560, 33, 135, 135, 33, 34560, 135, 34560, 34560, 135, 33, 135, 135, 135, 33, 34560, 135, 34560, 33, 34560, 33, 33, 135, 34560, 34560, 135, 33, 135, 33, 135, 34560, 34560, 135, 33, 135, 33, 34560, 33, 33, 33, 33, 34560, 135, 135, 34560, 135, 135, 33, 135, 34560, 135, 33, 33, 135, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 135, 34560, 135, 135, 135, 33, 34560, 33, 34560, 135, 33, 135, 33, 33, 135, 33, 135, 34560, 34560, 34560, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 33, 33, 34560, 135, 34560, 135, 34560, 135, 33, 135, 33, 33, 33, 34560, 34560, 135, 135, 33, 33, 135, 33, 34560, 33, 33, 135, 33, 34560, 135, 33, 34560, 33, 33, 34560, 135, 34560, 135, 33, 135, 34560, 135, 135, 34560, 135, 33, 135, 33, 34560, 135, 135, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 135, 33, 135, 33, 135, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 135, 135, 34560, 33, 34560, 33, 33, 33, 34560, 135, 34560, 34560, 33, 135, 135, 135, 33, 135, 33, 135, 135, 34560, 33, 33, 135, 33, 135, 135, 33, 34560, 34560, 34560, 33, 135, 135, 135, 135, 33, 135, 33, 34560, 33, 33, 34560, 135, 34560, 135, 135, 135, 135, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3715863 . Total input tokens: 827311191 . Total output tokens: 743093542
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.1998763919691555,
    "estimated_duration": 3600.1369132803625,
    "input_throughput": 4995.407239557801,
    "output_throughput": 4402.360071789231,
    "total_throughput": 9397.767311347034,
    "itl": 192.7174825019127,
    "ttft": 2172322.5621013865,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 330,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0766075673746,
    "arrivals": 1238058,
    "finished_requests": 72395,
    "scheduler_time": 89.66776448535752
}
#Debug simulation 
Total elapsed time: 5.200016867020167. Arrivals time: 0.25365014508133754 Scheduler time: 4.859436521190219 Scheduler overhead time: 0.02911233325721696 Adapter cache time: 0.014338799926918 Engine time: 0.029900130990426987 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-32/adapters_320_slots_192_rate_3.2-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-32/adapters_320_slots_192_rate_3.2-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [135, 34560, 34560, 33, 34560, 34560, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 34560, 34560, 135, 33, 33, 135, 34560, 34560, 135, 135, 33, 33, 135, 34560, 34560, 33, 34560, 135, 33, 135, 34560, 33, 135, 34560, 34560, 135, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 135, 135, 135, 33, 135, 33, 34560, 33, 34560, 135, 34560, 34560, 33, 34560, 33, 34560, 135, 33, 33, 135, 135, 34560, 135, 34560, 34560, 34560, 33, 135, 135, 33, 34560, 135, 34560, 34560, 135, 33, 135, 135, 135, 33, 34560, 135, 34560, 33, 34560, 33, 33, 135, 34560, 34560, 135, 33, 135, 33, 135, 34560, 34560, 135, 33, 135, 33, 34560, 33, 33, 33, 33, 34560, 135, 135, 34560, 135, 135, 33, 135, 34560, 135, 33, 33, 135, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 135, 34560, 135, 135, 135, 33, 34560, 33, 34560, 135, 33, 135, 33, 33, 135, 33, 135, 34560, 34560, 34560, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 33, 33, 34560, 135, 34560, 135, 34560, 135, 33, 135, 33, 33, 33, 34560, 34560, 135, 135, 33, 33, 135, 33, 34560, 33, 33, 135, 33, 34560, 135, 33, 34560, 33, 33, 34560, 135, 34560, 135, 33, 135, 34560, 135, 135, 34560, 135, 33, 135, 33, 34560, 135, 135, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 135, 33, 135, 33, 135, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 135, 135, 34560, 33, 34560, 33, 33, 33, 34560, 135, 34560, 34560, 33, 135, 135, 135, 33, 135, 33, 135, 135, 34560, 33, 33, 135, 33, 135, 135, 33, 34560, 34560, 34560, 33, 135, 135, 135, 135, 33, 135, 33, 34560, 33, 33, 34560, 135, 34560, 135, 135, 135, 135, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3715863 . Total input tokens: 827311191 . Total output tokens: 743093542
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.852404597972054,
    "estimated_duration": 3600.0449474154325,
    "input_throughput": 3996.424547512672,
    "output_throughput": 3524.9884891327733,
    "total_throughput": 7521.413036645446,
    "itl": 95.80246468632191,
    "ttft": 2286840.82670688,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 285,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9321543908491778,
    "arrivals": 1238058,
    "finished_requests": 57867,
    "scheduler_time": 101.98505169410106
}
#Debug simulation 
Total elapsed time: 4.852468567958567. Arrivals time: 0.5994654495152645 Scheduler time: 4.066319435019977 Scheduler overhead time: 0.05195629416266456 Adapter cache time: 0.05628033331595361 Engine time: 0.053512124868575484 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-16/adapters_320_slots_192_rate_3.2-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-16/adapters_320_slots_192_rate_3.2-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [135, 34560, 34560, 33, 34560, 34560, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 34560, 34560, 135, 33, 33, 135, 34560, 34560, 135, 135, 33, 33, 135, 34560, 34560, 33, 34560, 135, 33, 135, 34560, 33, 135, 34560, 34560, 135, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 135, 135, 135, 33, 135, 33, 34560, 33, 34560, 135, 34560, 34560, 33, 34560, 33, 34560, 135, 33, 33, 135, 135, 34560, 135, 34560, 34560, 34560, 33, 135, 135, 33, 34560, 135, 34560, 34560, 135, 33, 135, 135, 135, 33, 34560, 135, 34560, 33, 34560, 33, 33, 135, 34560, 34560, 135, 33, 135, 33, 135, 34560, 34560, 135, 33, 135, 33, 34560, 33, 33, 33, 33, 34560, 135, 135, 34560, 135, 135, 33, 135, 34560, 135, 33, 33, 135, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 135, 34560, 135, 135, 135, 33, 34560, 33, 34560, 135, 33, 135, 33, 33, 135, 33, 135, 34560, 34560, 34560, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 33, 33, 34560, 135, 34560, 135, 34560, 135, 33, 135, 33, 33, 33, 34560, 34560, 135, 135, 33, 33, 135, 33, 34560, 33, 33, 135, 33, 34560, 135, 33, 34560, 33, 33, 34560, 135, 34560, 135, 33, 135, 34560, 135, 135, 34560, 135, 33, 135, 33, 34560, 135, 135, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 135, 33, 135, 33, 135, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 135, 135, 34560, 33, 34560, 33, 33, 33, 34560, 135, 34560, 34560, 33, 135, 135, 135, 33, 135, 33, 135, 135, 34560, 33, 33, 135, 33, 135, 135, 33, 34560, 34560, 34560, 33, 135, 135, 135, 135, 33, 135, 33, 34560, 33, 33, 34560, 135, 34560, 135, 135, 135, 135, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3715863 . Total input tokens: 827311191 . Total output tokens: 743093542
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 5.4603343330090865,
    "estimated_duration": 3600.089784108259,
    "input_throughput": 4995.472634984482,
    "output_throughput": 4402.417703570083,
    "total_throughput": 9397.890338554565,
    "itl": 192.7155224062397,
    "ttft": 2172299.725643887,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 330,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0296191057539574,
    "arrivals": 1238058,
    "finished_requests": 72395,
    "scheduler_time": 89.66762377486621
}
#Debug simulation 
Total elapsed time: 5.460440487018786. Arrivals time: 0.27726132760290056 Scheduler time: 5.0952735801110975 Scheduler overhead time: 0.029234470042865723 Adapter cache time: 0.014896168024279177 Engine time: 0.030006184882950038 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-32/adapters_320_slots_192_rate_3.2-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-32/adapters_320_slots_192_rate_3.2-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [135, 34560, 34560, 33, 34560, 34560, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 34560, 34560, 135, 33, 33, 135, 34560, 34560, 135, 135, 33, 33, 135, 34560, 34560, 33, 34560, 135, 33, 135, 34560, 33, 135, 34560, 34560, 135, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 135, 135, 135, 33, 135, 33, 34560, 33, 34560, 135, 34560, 34560, 33, 34560, 33, 34560, 135, 33, 33, 135, 135, 34560, 135, 34560, 34560, 34560, 33, 135, 135, 33, 34560, 135, 34560, 34560, 135, 33, 135, 135, 135, 33, 34560, 135, 34560, 33, 34560, 33, 33, 135, 34560, 34560, 135, 33, 135, 33, 135, 34560, 34560, 135, 33, 135, 33, 34560, 33, 33, 33, 33, 34560, 135, 135, 34560, 135, 135, 33, 135, 34560, 135, 33, 33, 135, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 135, 34560, 135, 135, 135, 33, 34560, 33, 34560, 135, 33, 135, 33, 33, 135, 33, 135, 34560, 34560, 34560, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 33, 33, 34560, 135, 34560, 135, 34560, 135, 33, 135, 33, 33, 33, 34560, 34560, 135, 135, 33, 33, 135, 33, 34560, 33, 33, 135, 33, 34560, 135, 33, 34560, 33, 33, 34560, 135, 34560, 135, 33, 135, 34560, 135, 135, 34560, 135, 33, 135, 33, 34560, 135, 135, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 135, 33, 135, 33, 135, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 135, 135, 34560, 33, 34560, 33, 33, 33, 34560, 135, 34560, 34560, 33, 135, 135, 135, 33, 135, 33, 135, 135, 34560, 33, 33, 135, 33, 135, 135, 33, 34560, 34560, 34560, 33, 135, 135, 135, 135, 33, 135, 33, 34560, 33, 33, 34560, 135, 34560, 135, 135, 135, 135, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3715863 . Total input tokens: 827311191 . Total output tokens: 743093542
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.481646732019726,
    "estimated_duration": 3600.0574699153162,
    "input_throughput": 3996.4106462829413,
    "output_throughput": 3524.976227754083,
    "total_throughput": 7521.386874037024,
    "itl": 95.80276586157495,
    "ttft": 2286846.8097928176,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 285,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9446040157042492,
    "arrivals": 1238058,
    "finished_requests": 57867,
    "scheduler_time": 101.98512456913873
}
#Debug simulation 
Total elapsed time: 4.48175178602105. Arrivals time: 0.21856096136616543 Scheduler time: 4.075571100751404 Scheduler overhead time: 0.05227133026346564 Adapter cache time: 0.056320378032978624 Engine time: 0.05385854479391128 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-16/adapters_320_slots_192_rate_3.2-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-16/adapters_320_slots_192_rate_3.2-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [135, 34560, 34560, 33, 34560, 34560, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 34560, 34560, 135, 33, 33, 135, 34560, 34560, 135, 135, 33, 33, 135, 34560, 34560, 33, 34560, 135, 33, 135, 34560, 33, 135, 34560, 34560, 135, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 135, 135, 135, 33, 135, 33, 34560, 33, 34560, 135, 34560, 34560, 33, 34560, 33, 34560, 135, 33, 33, 135, 135, 34560, 135, 34560, 34560, 34560, 33, 135, 135, 33, 34560, 135, 34560, 34560, 135, 33, 135, 135, 135, 33, 34560, 135, 34560, 33, 34560, 33, 33, 135, 34560, 34560, 135, 33, 135, 33, 135, 34560, 34560, 135, 33, 135, 33, 34560, 33, 33, 33, 33, 34560, 135, 135, 34560, 135, 135, 33, 135, 34560, 135, 33, 33, 135, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 135, 34560, 135, 135, 135, 33, 34560, 33, 34560, 135, 33, 135, 33, 33, 135, 33, 135, 34560, 34560, 34560, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 33, 33, 34560, 135, 34560, 135, 34560, 135, 33, 135, 33, 33, 33, 34560, 34560, 135, 135, 33, 33, 135, 33, 34560, 33, 33, 135, 33, 34560, 135, 33, 34560, 33, 33, 34560, 135, 34560, 135, 33, 135, 34560, 135, 135, 34560, 135, 33, 135, 33, 34560, 135, 135, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 135, 33, 135, 33, 135, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 135, 135, 34560, 33, 34560, 33, 33, 33, 34560, 135, 34560, 34560, 33, 135, 135, 135, 33, 135, 33, 135, 135, 34560, 33, 33, 135, 33, 135, 135, 33, 34560, 34560, 34560, 33, 135, 135, 135, 135, 33, 135, 33, 34560, 33, 33, 34560, 135, 34560, 135, 135, 135, 135, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3715863 . Total input tokens: 827311191 . Total output tokens: 743093542
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.61127219494665,
    "estimated_duration": 3600.046712309593,
    "input_throughput": 4995.532401984405,
    "output_throughput": 4402.4703751224615,
    "total_throughput": 9398.002777106865,
    "itl": 192.7137415087227,
    "ttft": 2172278.099530068,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 330,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9867165973177193,
    "arrivals": 1238058,
    "finished_requests": 72395,
    "scheduler_time": 89.66745448462856
}
#Debug simulation 
Total elapsed time: 5.611342770978808. Arrivals time: 0.6464324126136489 Scheduler time: 4.87822240171954 Scheduler overhead time: 0.029093105345964432 Adapter cache time: 0.0143617078429088 Engine time: 0.029627539624925703 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-32/adapters_320_slots_192_rate_3.2-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-32/adapters_320_slots_192_rate_3.2-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [135, 34560, 34560, 33, 34560, 34560, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 34560, 34560, 135, 33, 33, 135, 34560, 34560, 135, 135, 33, 33, 135, 34560, 34560, 33, 34560, 135, 33, 135, 34560, 33, 135, 34560, 34560, 135, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 135, 135, 135, 33, 135, 33, 34560, 33, 34560, 135, 34560, 34560, 33, 34560, 33, 34560, 135, 33, 33, 135, 135, 34560, 135, 34560, 34560, 34560, 33, 135, 135, 33, 34560, 135, 34560, 34560, 135, 33, 135, 135, 135, 33, 34560, 135, 34560, 33, 34560, 33, 33, 135, 34560, 34560, 135, 33, 135, 33, 135, 34560, 34560, 135, 33, 135, 33, 34560, 33, 33, 33, 33, 34560, 135, 135, 34560, 135, 135, 33, 135, 34560, 135, 33, 33, 135, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 135, 34560, 135, 135, 135, 33, 34560, 33, 34560, 135, 33, 135, 33, 33, 135, 33, 135, 34560, 34560, 34560, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 33, 33, 34560, 135, 34560, 135, 34560, 135, 33, 135, 33, 33, 33, 34560, 34560, 135, 135, 33, 33, 135, 33, 34560, 33, 33, 135, 33, 34560, 135, 33, 34560, 33, 33, 34560, 135, 34560, 135, 33, 135, 34560, 135, 135, 34560, 135, 33, 135, 33, 34560, 135, 135, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 135, 33, 135, 33, 135, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 135, 135, 34560, 33, 34560, 33, 33, 33, 34560, 135, 34560, 34560, 33, 135, 135, 135, 33, 135, 33, 135, 135, 34560, 33, 33, 135, 33, 135, 135, 33, 34560, 34560, 34560, 33, 135, 135, 135, 135, 33, 135, 33, 34560, 33, 33, 34560, 135, 34560, 135, 135, 135, 135, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3715863 . Total input tokens: 827311191 . Total output tokens: 743093542
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.470628030016087,
    "estimated_duration": 3600.069247507481,
    "input_throughput": 3996.3975720636754,
    "output_throughput": 3524.9646958280155,
    "total_throughput": 7521.362267891691,
    "itl": 95.80307789221523,
    "ttft": 2286852.5619176095,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 285,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9562991178408315,
    "arrivals": 1238058,
    "finished_requests": 57867,
    "scheduler_time": 101.98520705917228
}
#Debug simulation 
Total elapsed time: 4.4707260460127145. Arrivals time: 0.2152519014198333 Scheduler time: 4.06721321697114 Scheduler overhead time: 0.052163071813993156 Adapter cache time: 0.0566118867136538 Engine time: 0.054430266725830734 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-8/adapters_320_slots_192_rate_3.2-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-8/adapters_320_slots_192_rate_3.2-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [66, 34560, 34560, 33, 34560, 34560, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 34560, 34560, 66, 33, 33, 66, 34560, 34560, 66, 66, 33, 33, 66, 34560, 34560, 33, 34560, 66, 33, 66, 34560, 33, 66, 34560, 34560, 66, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 66, 66, 66, 33, 66, 33, 34560, 33, 34560, 66, 34560, 34560, 33, 34560, 33, 34560, 66, 33, 33, 66, 66, 34560, 66, 34560, 34560, 34560, 33, 66, 66, 33, 34560, 66, 34560, 34560, 66, 33, 66, 66, 66, 33, 34560, 66, 34560, 33, 34560, 33, 33, 66, 34560, 34560, 66, 33, 66, 33, 66, 34560, 34560, 66, 33, 66, 33, 34560, 33, 33, 33, 33, 34560, 66, 66, 34560, 66, 66, 33, 66, 34560, 66, 33, 33, 66, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 66, 34560, 66, 66, 66, 33, 34560, 33, 34560, 66, 33, 66, 33, 33, 66, 33, 66, 34560, 34560, 34560, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 33, 33, 34560, 66, 34560, 66, 34560, 66, 33, 66, 33, 33, 33, 34560, 34560, 66, 66, 33, 33, 66, 33, 34560, 33, 33, 66, 33, 34560, 66, 33, 34560, 33, 33, 34560, 66, 34560, 66, 33, 66, 34560, 66, 66, 34560, 66, 33, 66, 33, 34560, 66, 66, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 66, 33, 66, 33, 66, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 66, 66, 34560, 33, 34560, 33, 33, 33, 34560, 66, 34560, 34560, 33, 66, 66, 66, 33, 66, 33, 66, 66, 34560, 33, 33, 66, 33, 66, 66, 33, 34560, 34560, 34560, 33, 66, 66, 66, 66, 33, 66, 33, 34560, 33, 33, 34560, 66, 34560, 66, 66, 66, 66, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3708480 . Total input tokens: 825698762 . Total output tokens: 741622434
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.340603606950026,
    "estimated_duration": 3600.113280326298,
    "input_throughput": 5050.803567589944,
    "output_throughput": 4448.5280748022615,
    "total_throughput": 9499.331642392204,
    "itl": 192.8178191921605,
    "ttft": 2166027.287681511,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 266,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8140897398861114,
    "arrivals": 1235689,
    "finished_requests": 73527,
    "scheduler_time": 90.33762422986237
}
#Debug simulation 
Total elapsed time: 5.340711058001034. Arrivals time: 0.2788127255626023 Scheduler time: 4.977589199086651 Scheduler overhead time: 0.029277896333951503 Adapter cache time: 0.011231136217247695 Engine time: 0.030150760838296264 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-16/adapters_320_slots_192_rate_3.2-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-16/adapters_320_slots_192_rate_3.2-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [66, 34560, 34560, 33, 34560, 34560, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 34560, 34560, 66, 33, 33, 66, 34560, 34560, 66, 66, 33, 33, 66, 34560, 34560, 33, 34560, 66, 33, 66, 34560, 33, 66, 34560, 34560, 66, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 66, 66, 66, 33, 66, 33, 34560, 33, 34560, 66, 34560, 34560, 33, 34560, 33, 34560, 66, 33, 33, 66, 66, 34560, 66, 34560, 34560, 34560, 33, 66, 66, 33, 34560, 66, 34560, 34560, 66, 33, 66, 66, 66, 33, 34560, 66, 34560, 33, 34560, 33, 33, 66, 34560, 34560, 66, 33, 66, 33, 66, 34560, 34560, 66, 33, 66, 33, 34560, 33, 33, 33, 33, 34560, 66, 66, 34560, 66, 66, 33, 66, 34560, 66, 33, 33, 66, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 66, 34560, 66, 66, 66, 33, 34560, 33, 34560, 66, 33, 66, 33, 33, 66, 33, 66, 34560, 34560, 34560, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 33, 33, 34560, 66, 34560, 66, 34560, 66, 33, 66, 33, 33, 33, 34560, 34560, 66, 66, 33, 33, 66, 33, 34560, 33, 33, 66, 33, 34560, 66, 33, 34560, 33, 33, 34560, 66, 34560, 66, 33, 66, 34560, 66, 66, 34560, 66, 33, 66, 33, 34560, 66, 66, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 66, 33, 66, 33, 66, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 66, 66, 34560, 33, 34560, 33, 33, 33, 34560, 66, 34560, 34560, 33, 66, 66, 66, 33, 66, 33, 66, 66, 34560, 33, 33, 66, 33, 66, 66, 33, 34560, 34560, 34560, 33, 66, 66, 66, 66, 33, 66, 33, 34560, 33, 33, 34560, 66, 34560, 66, 66, 66, 66, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3708480 . Total input tokens: 825698762 . Total output tokens: 741622434
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.349460805999115,
    "estimated_duration": 3600.153137779452,
    "input_throughput": 5042.008021690994,
    "output_throughput": 4439.945576831521,
    "total_throughput": 9481.953598522516,
    "itl": 190.7649900536308,
    "ttft": 2167352.553652266,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 266,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8648145825788419,
    "arrivals": 1235689,
    "finished_requests": 73376,
    "scheduler_time": 90.45943567929257
}
#Debug simulation 
Total elapsed time: 5.349583002040163. Arrivals time: 0.33951411937596276 Scheduler time: 4.924947303603403 Scheduler overhead time: 0.029383688466623425 Adapter cache time: 0.011659874813631177 Engine time: 0.03021468222141266 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-32/adapters_320_slots_192_rate_3.2-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-32/adapters_320_slots_192_rate_3.2-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [66, 34560, 34560, 33, 34560, 34560, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 34560, 34560, 66, 33, 33, 66, 34560, 34560, 66, 66, 33, 33, 66, 34560, 34560, 33, 34560, 66, 33, 66, 34560, 33, 66, 34560, 34560, 66, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 66, 66, 66, 33, 66, 33, 34560, 33, 34560, 66, 34560, 34560, 33, 34560, 33, 34560, 66, 33, 33, 66, 66, 34560, 66, 34560, 34560, 34560, 33, 66, 66, 33, 34560, 66, 34560, 34560, 66, 33, 66, 66, 66, 33, 34560, 66, 34560, 33, 34560, 33, 33, 66, 34560, 34560, 66, 33, 66, 33, 66, 34560, 34560, 66, 33, 66, 33, 34560, 33, 33, 33, 33, 34560, 66, 66, 34560, 66, 66, 33, 66, 34560, 66, 33, 33, 66, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 66, 34560, 66, 66, 66, 33, 34560, 33, 34560, 66, 33, 66, 33, 33, 66, 33, 66, 34560, 34560, 34560, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 33, 33, 34560, 66, 34560, 66, 34560, 66, 33, 66, 33, 33, 33, 34560, 34560, 66, 66, 33, 33, 66, 33, 34560, 33, 33, 66, 33, 34560, 66, 33, 34560, 33, 33, 34560, 66, 34560, 66, 33, 66, 34560, 66, 66, 34560, 66, 33, 66, 33, 34560, 66, 66, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 66, 33, 66, 33, 66, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 66, 66, 34560, 33, 34560, 33, 33, 33, 34560, 66, 34560, 34560, 33, 66, 66, 66, 33, 66, 33, 66, 66, 34560, 33, 33, 66, 33, 66, 66, 33, 34560, 34560, 34560, 33, 66, 66, 66, 66, 33, 66, 33, 34560, 33, 33, 34560, 66, 34560, 66, 66, 66, 66, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3708480 . Total input tokens: 825698762 . Total output tokens: 741622434
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.863070057996083,
    "estimated_duration": 3600.0680630665765,
    "input_throughput": 4003.64263883459,
    "output_throughput": 3537.5308957775346,
    "total_throughput": 7541.173534612125,
    "itl": 95.53391931668462,
    "ttft": 2279609.5267802267,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 231,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.753302730750296,
    "arrivals": 1235689,
    "finished_requests": 58246,
    "scheduler_time": 102.31291875347684
}
#Debug simulation 
Total elapsed time: 4.863137532025576. Arrivals time: 0.5997531705070287 Scheduler time: 4.080311831494328 Scheduler overhead time: 0.05238447291776538 Adapter cache time: 0.05128791386960074 Engine time: 0.05423741036793217 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-16/adapters_320_slots_192_rate_3.2-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-16/adapters_320_slots_192_rate_3.2-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [66, 34560, 34560, 33, 34560, 34560, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 34560, 34560, 66, 33, 33, 66, 34560, 34560, 66, 66, 33, 33, 66, 34560, 34560, 33, 34560, 66, 33, 66, 34560, 33, 66, 34560, 34560, 66, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 66, 66, 66, 33, 66, 33, 34560, 33, 34560, 66, 34560, 34560, 33, 34560, 33, 34560, 66, 33, 33, 66, 66, 34560, 66, 34560, 34560, 34560, 33, 66, 66, 33, 34560, 66, 34560, 34560, 66, 33, 66, 66, 66, 33, 34560, 66, 34560, 33, 34560, 33, 33, 66, 34560, 34560, 66, 33, 66, 33, 66, 34560, 34560, 66, 33, 66, 33, 34560, 33, 33, 33, 33, 34560, 66, 66, 34560, 66, 66, 33, 66, 34560, 66, 33, 33, 66, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 66, 34560, 66, 66, 66, 33, 34560, 33, 34560, 66, 33, 66, 33, 33, 66, 33, 66, 34560, 34560, 34560, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 33, 33, 34560, 66, 34560, 66, 34560, 66, 33, 66, 33, 33, 33, 34560, 34560, 66, 66, 33, 33, 66, 33, 34560, 33, 33, 66, 33, 34560, 66, 33, 34560, 33, 33, 34560, 66, 34560, 66, 33, 66, 34560, 66, 66, 34560, 66, 33, 66, 33, 34560, 66, 66, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 66, 33, 66, 33, 66, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 66, 66, 34560, 33, 34560, 33, 33, 33, 34560, 66, 34560, 34560, 33, 66, 66, 66, 33, 66, 33, 66, 66, 34560, 33, 33, 66, 33, 66, 66, 33, 34560, 34560, 34560, 33, 66, 66, 66, 66, 33, 66, 33, 34560, 33, 33, 34560, 66, 34560, 66, 66, 66, 66, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3708480 . Total input tokens: 825698762 . Total output tokens: 741622434
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 5.356384152022656,
    "estimated_duration": 3600.1194886057865,
    "input_throughput": 5042.055147738916,
    "output_throughput": 4439.987075592952,
    "total_throughput": 9482.042223331868,
    "itl": 190.76367591996103,
    "ttft": 2167334.7950965003,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 266,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8313097664667318,
    "arrivals": 1235689,
    "finished_requests": 73376,
    "scheduler_time": 90.45929132173386
}
#Debug simulation 
Total elapsed time: 5.356478617992252. Arrivals time: 0.33550903503783047 Scheduler time: 4.935757921019103 Scheduler overhead time: 0.029471573361661285 Adapter cache time: 0.011821612773928791 Engine time: 0.030250634183175862 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-32/adapters_320_slots_192_rate_3.2-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-32/adapters_320_slots_192_rate_3.2-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [66, 34560, 34560, 33, 34560, 34560, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 34560, 34560, 66, 33, 33, 66, 34560, 34560, 66, 66, 33, 33, 66, 34560, 34560, 33, 34560, 66, 33, 66, 34560, 33, 66, 34560, 34560, 66, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 66, 66, 66, 33, 66, 33, 34560, 33, 34560, 66, 34560, 34560, 33, 34560, 33, 34560, 66, 33, 33, 66, 66, 34560, 66, 34560, 34560, 34560, 33, 66, 66, 33, 34560, 66, 34560, 34560, 66, 33, 66, 66, 66, 33, 34560, 66, 34560, 33, 34560, 33, 33, 66, 34560, 34560, 66, 33, 66, 33, 66, 34560, 34560, 66, 33, 66, 33, 34560, 33, 33, 33, 33, 34560, 66, 66, 34560, 66, 66, 33, 66, 34560, 66, 33, 33, 66, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 66, 34560, 66, 66, 66, 33, 34560, 33, 34560, 66, 33, 66, 33, 33, 66, 33, 66, 34560, 34560, 34560, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 33, 33, 34560, 66, 34560, 66, 34560, 66, 33, 66, 33, 33, 33, 34560, 34560, 66, 66, 33, 33, 66, 33, 34560, 33, 33, 66, 33, 34560, 66, 33, 34560, 33, 33, 34560, 66, 34560, 66, 33, 66, 34560, 66, 66, 34560, 66, 33, 66, 33, 34560, 66, 66, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 66, 33, 66, 33, 66, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 66, 66, 34560, 33, 34560, 33, 33, 33, 34560, 66, 34560, 34560, 33, 66, 66, 66, 33, 66, 33, 66, 66, 34560, 33, 33, 66, 33, 66, 66, 33, 34560, 34560, 34560, 33, 66, 66, 66, 66, 33, 66, 33, 34560, 33, 33, 34560, 66, 34560, 66, 66, 66, 66, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3708480 . Total input tokens: 825698762 . Total output tokens: 741622434
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.613160894019529,
    "estimated_duration": 3600.0770646593783,
    "input_throughput": 4003.6326281708984,
    "output_throughput": 3537.5220505744805,
    "total_throughput": 7541.154678745379,
    "itl": 95.53417253223283,
    "ttft": 2279614.277291393,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 231,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.762231249585751,
    "arrivals": 1235689,
    "finished_requests": 58246,
    "scheduler_time": 102.31299182744546
}
#Debug simulation 
Total elapsed time: 4.613255187985487. Arrivals time: 0.21745464077685028 Scheduler time: 4.212389469088521 Scheduler overhead time: 0.052669616823550314 Adapter cache time: 0.051446459954604506 Engine time: 0.05413496872643009 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-16/adapters_320_slots_192_rate_3.2-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-16/adapters_320_slots_192_rate_3.2-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [66, 34560, 34560, 33, 34560, 34560, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 34560, 34560, 66, 33, 33, 66, 34560, 34560, 66, 66, 33, 33, 66, 34560, 34560, 33, 34560, 66, 33, 66, 34560, 33, 66, 34560, 34560, 66, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 66, 66, 66, 33, 66, 33, 34560, 33, 34560, 66, 34560, 34560, 33, 34560, 33, 34560, 66, 33, 33, 66, 66, 34560, 66, 34560, 34560, 34560, 33, 66, 66, 33, 34560, 66, 34560, 34560, 66, 33, 66, 66, 66, 33, 34560, 66, 34560, 33, 34560, 33, 33, 66, 34560, 34560, 66, 33, 66, 33, 66, 34560, 34560, 66, 33, 66, 33, 34560, 33, 33, 33, 33, 34560, 66, 66, 34560, 66, 66, 33, 66, 34560, 66, 33, 33, 66, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 66, 34560, 66, 66, 66, 33, 34560, 33, 34560, 66, 33, 66, 33, 33, 66, 33, 66, 34560, 34560, 34560, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 33, 33, 34560, 66, 34560, 66, 34560, 66, 33, 66, 33, 33, 33, 34560, 34560, 66, 66, 33, 33, 66, 33, 34560, 33, 33, 66, 33, 34560, 66, 33, 34560, 33, 33, 34560, 66, 34560, 66, 33, 66, 34560, 66, 66, 34560, 66, 33, 66, 33, 34560, 66, 66, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 66, 33, 66, 33, 66, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 66, 66, 34560, 33, 34560, 33, 33, 33, 34560, 66, 34560, 34560, 33, 66, 66, 66, 33, 66, 33, 66, 66, 34560, 33, 33, 66, 33, 66, 66, 33, 34560, 34560, 34560, 33, 66, 66, 66, 66, 33, 66, 33, 34560, 33, 33, 34560, 66, 34560, 66, 66, 66, 66, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3708480 . Total input tokens: 825698762 . Total output tokens: 741622434
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.276367463986389,
    "estimated_duration": 3600.0833745318378,
    "input_throughput": 5042.105726887651,
    "output_throughput": 4440.0316151229845,
    "total_throughput": 9482.137342010636,
    "itl": 190.7622502469386,
    "ttft": 2167316.4233529773,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 266,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7953533784439798,
    "arrivals": 1235689,
    "finished_requests": 73376,
    "scheduler_time": 90.45913363580156
}
#Debug simulation 
Total elapsed time: 5.276538219011854. Arrivals time: 0.2545808328432031 Scheduler time: 4.936878411390353 Scheduler overhead time: 0.029502245073672384 Adapter cache time: 0.01142862404230982 Engine time: 0.030250905838329345 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-32/adapters_320_slots_192_rate_3.2-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-32/adapters_320_slots_192_rate_3.2-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [66, 34560, 34560, 33, 34560, 34560, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 34560, 34560, 66, 33, 33, 66, 34560, 34560, 66, 66, 33, 33, 66, 34560, 34560, 33, 34560, 66, 33, 66, 34560, 33, 66, 34560, 34560, 66, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 66, 66, 66, 33, 66, 33, 34560, 33, 34560, 66, 34560, 34560, 33, 34560, 33, 34560, 66, 33, 33, 66, 66, 34560, 66, 34560, 34560, 34560, 33, 66, 66, 33, 34560, 66, 34560, 34560, 66, 33, 66, 66, 66, 33, 34560, 66, 34560, 33, 34560, 33, 33, 66, 34560, 34560, 66, 33, 66, 33, 66, 34560, 34560, 66, 33, 66, 33, 34560, 33, 33, 33, 33, 34560, 66, 66, 34560, 66, 66, 33, 66, 34560, 66, 33, 33, 66, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 66, 34560, 66, 66, 66, 33, 34560, 33, 34560, 66, 33, 66, 33, 33, 66, 33, 66, 34560, 34560, 34560, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 33, 33, 34560, 66, 34560, 66, 34560, 66, 33, 66, 33, 33, 33, 34560, 34560, 66, 66, 33, 33, 66, 33, 34560, 33, 33, 66, 33, 34560, 66, 33, 34560, 33, 33, 34560, 66, 34560, 66, 33, 66, 34560, 66, 66, 34560, 66, 33, 66, 33, 34560, 66, 66, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 66, 33, 66, 33, 66, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 66, 66, 34560, 33, 34560, 33, 33, 33, 34560, 66, 34560, 34560, 33, 66, 66, 66, 33, 66, 33, 66, 66, 34560, 33, 33, 66, 33, 66, 66, 33, 34560, 34560, 34560, 33, 66, 66, 66, 66, 33, 66, 33, 34560, 33, 33, 34560, 66, 34560, 66, 66, 66, 66, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3708480 . Total input tokens: 825698762 . Total output tokens: 741622434
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.463227553991601,
    "estimated_duration": 3600.086949352096,
    "input_throughput": 4003.621635470211,
    "output_throughput": 3537.512337665058,
    "total_throughput": 7541.133973135269,
    "itl": 95.53443607931396,
    "ttft": 2279619.1608659234,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 231,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.77204004492611,
    "arrivals": 1235689,
    "finished_requests": 58246,
    "scheduler_time": 102.31306772483084
}
#Debug simulation 
Total elapsed time: 4.4633212690241635. Arrivals time: 0.21769835706800222 Scheduler time: 4.063421526458114 Scheduler overhead time: 0.05243915563914925 Adapter cache time: 0.05089807556942105 Engine time: 0.05384078767383471 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-8/adapters_320_slots_192_rate_1.6-0.8-0.4_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-8/adapters_320_slots_192_rate_1.6-0.8-0.4_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 4320, 17280, 17280, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 8640, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 17280, 17280, 8640, 4320, 4320, 8640, 17280, 17280, 8640, 8640, 4320, 4320, 8640, 17280, 17280, 4320, 17280, 8640, 4320, 8640, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 4320, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 4320, 17280, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 4320, 8640, 8640, 4320, 17280, 8640, 17280, 17280, 8640, 4320, 8640, 8640, 8640, 4320, 17280, 8640, 17280, 4320, 17280, 4320, 4320, 8640, 17280, 17280, 8640, 4320, 8640, 4320, 8640, 17280, 17280, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 8640, 8640, 17280, 8640, 8640, 4320, 8640, 17280, 8640, 4320, 4320, 8640, 17280, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 8640, 17280, 8640, 8640, 8640, 4320, 17280, 4320, 17280, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 4320, 4320, 17280, 8640, 17280, 8640, 17280, 8640, 4320, 8640, 4320, 4320, 4320, 17280, 17280, 8640, 8640, 4320, 4320, 8640, 4320, 17280, 4320, 4320, 8640, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 8640, 4320, 8640, 4320, 17280, 8640, 8640, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 8640, 4320, 8640, 4320, 8640, 17280, 17280, 17280, 4320, 17280, 17280, 17280, 17280, 4320, 8640, 8640, 17280, 4320, 17280, 4320, 4320, 4320, 17280, 8640, 17280, 17280, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 17280, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 17280, 17280, 17280, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 4320, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 4320]
Prompts retrieved: 3231360 . Total input tokens: 719366854 . Total output tokens: 646131383
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 7.2374709360301495,
    "estimated_duration": 3600.2464704159243,
    "input_throughput": 3688.654126634224,
    "output_throughput": 3226.876575107888,
    "total_throughput": 6915.530701742113,
    "itl": 263.7522174210564,
    "ttft": 2299382.0999951866,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1373,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.202049672419781,
    "arrivals": 1075699,
    "finished_requests": 53506,
    "scheduler_time": 65.80218848846266
}
#Debug simulation 
Total elapsed time: 7.237580507004168. Arrivals time: 0.24882443103706464 Scheduler time: 6.89234191714786 Scheduler overhead time: 0.02403915667673573 Adapter cache time: 0.037879319745115936 Engine time: 0.023948876187205315 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-16/adapters_320_slots_192_rate_1.6-0.8-0.4_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-16/adapters_320_slots_192_rate_1.6-0.8-0.4_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 4320, 17280, 17280, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 8640, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 17280, 17280, 8640, 4320, 4320, 8640, 17280, 17280, 8640, 8640, 4320, 4320, 8640, 17280, 17280, 4320, 17280, 8640, 4320, 8640, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 4320, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 4320, 17280, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 4320, 8640, 8640, 4320, 17280, 8640, 17280, 17280, 8640, 4320, 8640, 8640, 8640, 4320, 17280, 8640, 17280, 4320, 17280, 4320, 4320, 8640, 17280, 17280, 8640, 4320, 8640, 4320, 8640, 17280, 17280, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 8640, 8640, 17280, 8640, 8640, 4320, 8640, 17280, 8640, 4320, 4320, 8640, 17280, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 8640, 17280, 8640, 8640, 8640, 4320, 17280, 4320, 17280, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 4320, 4320, 17280, 8640, 17280, 8640, 17280, 8640, 4320, 8640, 4320, 4320, 4320, 17280, 17280, 8640, 8640, 4320, 4320, 8640, 4320, 17280, 4320, 4320, 8640, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 8640, 4320, 8640, 4320, 17280, 8640, 8640, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 8640, 4320, 8640, 4320, 8640, 17280, 17280, 17280, 4320, 17280, 17280, 17280, 17280, 4320, 8640, 8640, 17280, 4320, 17280, 4320, 4320, 4320, 17280, 8640, 17280, 17280, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 17280, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 17280, 17280, 17280, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 4320, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 4320]
Prompts retrieved: 3231360 . Total input tokens: 719366854 . Total output tokens: 646131383
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 7.051413231994957,
    "estimated_duration": 3600.0801214926255,
    "input_throughput": 3680.426144101066,
    "output_throughput": 3219.756952296414,
    "total_throughput": 6900.18309639748,
    "itl": 261.6107857199725,
    "ttft": 2300549.058441016,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1396,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.560641382927961,
    "arrivals": 1075699,
    "finished_requests": 53415,
    "scheduler_time": 65.85532696939245
}
#Debug simulation 
Total elapsed time: 7.051509623997845. Arrivals time: 0.23635047813877463 Scheduler time: 6.71661797753768 Scheduler overhead time: 0.02397830074187368 Adapter cache time: 0.03993497003102675 Engine time: 0.024041198659688234 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-32/adapters_320_slots_192_rate_1.6-0.8-0.4_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-32/adapters_320_slots_192_rate_1.6-0.8-0.4_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 4320, 17280, 17280, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 8640, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 17280, 17280, 8640, 4320, 4320, 8640, 17280, 17280, 8640, 8640, 4320, 4320, 8640, 17280, 17280, 4320, 17280, 8640, 4320, 8640, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 4320, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 4320, 17280, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 4320, 8640, 8640, 4320, 17280, 8640, 17280, 17280, 8640, 4320, 8640, 8640, 8640, 4320, 17280, 8640, 17280, 4320, 17280, 4320, 4320, 8640, 17280, 17280, 8640, 4320, 8640, 4320, 8640, 17280, 17280, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 8640, 8640, 17280, 8640, 8640, 4320, 8640, 17280, 8640, 4320, 4320, 8640, 17280, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 8640, 17280, 8640, 8640, 8640, 4320, 17280, 4320, 17280, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 4320, 4320, 17280, 8640, 17280, 8640, 17280, 8640, 4320, 8640, 4320, 4320, 4320, 17280, 17280, 8640, 8640, 4320, 4320, 8640, 4320, 17280, 4320, 4320, 8640, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 8640, 4320, 8640, 4320, 17280, 8640, 8640, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 8640, 4320, 8640, 4320, 8640, 17280, 17280, 17280, 4320, 17280, 17280, 17280, 17280, 4320, 8640, 8640, 17280, 4320, 17280, 4320, 4320, 4320, 17280, 8640, 17280, 17280, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 17280, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 17280, 17280, 17280, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 4320, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 4320]
Prompts retrieved: 3231360 . Total input tokens: 719366854 . Total output tokens: 646131383
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.679683163005393,
    "estimated_duration": 3600.0271061086596,
    "input_throughput": 2846.1077369706736,
    "output_throughput": 2506.7583476488458,
    "total_throughput": 5352.86608461952,
    "itl": 134.83581349274309,
    "ttft": 2431310.0607588696,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9616,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 31.42924543218828,
    "arrivals": 1075699,
    "finished_requests": 41202,
    "scheduler_time": 72.50878086326284
}
#Debug simulation 
Total elapsed time: 3.6798078599967994. Arrivals time: 0.260038792679552 Scheduler time: 3.1018015522276983 Scheduler overhead time: 0.03896513133076951 Adapter cache time: 0.2212106265942566 Engine time: 0.03921392816118896 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-16-16/adapters_320_slots_192_rate_1.6-0.8-0.4_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-16-16/adapters_320_slots_192_rate_1.6-0.8-0.4_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 4320, 17280, 17280, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 8640, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 17280, 17280, 8640, 4320, 4320, 8640, 17280, 17280, 8640, 8640, 4320, 4320, 8640, 17280, 17280, 4320, 17280, 8640, 4320, 8640, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 4320, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 4320, 17280, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 4320, 8640, 8640, 4320, 17280, 8640, 17280, 17280, 8640, 4320, 8640, 8640, 8640, 4320, 17280, 8640, 17280, 4320, 17280, 4320, 4320, 8640, 17280, 17280, 8640, 4320, 8640, 4320, 8640, 17280, 17280, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 8640, 8640, 17280, 8640, 8640, 4320, 8640, 17280, 8640, 4320, 4320, 8640, 17280, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 8640, 17280, 8640, 8640, 8640, 4320, 17280, 4320, 17280, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 4320, 4320, 17280, 8640, 17280, 8640, 17280, 8640, 4320, 8640, 4320, 4320, 4320, 17280, 17280, 8640, 8640, 4320, 4320, 8640, 4320, 17280, 4320, 4320, 8640, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 8640, 4320, 8640, 4320, 17280, 8640, 8640, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 8640, 4320, 8640, 4320, 8640, 17280, 17280, 17280, 4320, 17280, 17280, 17280, 17280, 4320, 8640, 8640, 17280, 4320, 17280, 4320, 4320, 4320, 17280, 8640, 17280, 17280, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 17280, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 17280, 17280, 17280, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 4320, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 4320]
Prompts retrieved: 3231360 . Total input tokens: 719366854 . Total output tokens: 646131383
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 7.041748265037313,
    "estimated_duration": 3600.1714854247175,
    "input_throughput": 3680.5468999587965,
    "output_throughput": 3219.941618595547,
    "total_throughput": 6900.4885185543435,
    "itl": 261.59779891334415,
    "ttft": 2300527.1979224645,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1396,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.363698439439687,
    "arrivals": 1075699,
    "finished_requests": 53420,
    "scheduler_time": 65.86039479755698
}
#Debug simulation 
Total elapsed time: 7.041845851985272. Arrivals time: 0.23465998604660854 Scheduler time: 6.707901254645549 Scheduler overhead time: 0.023944516375195235 Adapter cache time: 0.04040892457123846 Engine time: 0.024292983231134713 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-16-32/adapters_320_slots_192_rate_1.6-0.8-0.4_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-16-32/adapters_320_slots_192_rate_1.6-0.8-0.4_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 4320, 17280, 17280, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 8640, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 17280, 17280, 8640, 4320, 4320, 8640, 17280, 17280, 8640, 8640, 4320, 4320, 8640, 17280, 17280, 4320, 17280, 8640, 4320, 8640, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 4320, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 4320, 17280, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 4320, 8640, 8640, 4320, 17280, 8640, 17280, 17280, 8640, 4320, 8640, 8640, 8640, 4320, 17280, 8640, 17280, 4320, 17280, 4320, 4320, 8640, 17280, 17280, 8640, 4320, 8640, 4320, 8640, 17280, 17280, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 8640, 8640, 17280, 8640, 8640, 4320, 8640, 17280, 8640, 4320, 4320, 8640, 17280, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 8640, 17280, 8640, 8640, 8640, 4320, 17280, 4320, 17280, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 4320, 4320, 17280, 8640, 17280, 8640, 17280, 8640, 4320, 8640, 4320, 4320, 4320, 17280, 17280, 8640, 8640, 4320, 4320, 8640, 4320, 17280, 4320, 4320, 8640, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 8640, 4320, 8640, 4320, 17280, 8640, 8640, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 8640, 4320, 8640, 4320, 8640, 17280, 17280, 17280, 4320, 17280, 17280, 17280, 17280, 4320, 8640, 8640, 17280, 4320, 17280, 4320, 4320, 4320, 17280, 8640, 17280, 17280, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 17280, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 17280, 17280, 17280, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 4320, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 4320]
Prompts retrieved: 3231360 . Total input tokens: 719366854 . Total output tokens: 646131383
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 3.6049532550387084,
    "estimated_duration": 3600.0080050867628,
    "input_throughput": 2845.9672827180493,
    "output_throughput": 2506.503593117018,
    "total_throughput": 5352.470875835068,
    "itl": 134.85167439314995,
    "ttft": 2431398.3798638578,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9615,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 31.834312964118364,
    "arrivals": 1075699,
    "finished_requests": 41196,
    "scheduler_time": 72.50017590132306
}
#Debug simulation 
Total elapsed time: 3.6051309410249814. Arrivals time: 0.18620737636229023 Scheduler time: 3.100687817961443 Scheduler overhead time: 0.03897021507145837 Adapter cache time: 0.22120121662737802 Engine time: 0.039458460931200534 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_16-16-16/adapters_320_slots_192_rate_1.6-0.8-0.4_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_16-16-16/adapters_320_slots_192_rate_1.6-0.8-0.4_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 4320, 17280, 17280, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 8640, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 17280, 17280, 8640, 4320, 4320, 8640, 17280, 17280, 8640, 8640, 4320, 4320, 8640, 17280, 17280, 4320, 17280, 8640, 4320, 8640, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 4320, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 4320, 17280, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 4320, 8640, 8640, 4320, 17280, 8640, 17280, 17280, 8640, 4320, 8640, 8640, 8640, 4320, 17280, 8640, 17280, 4320, 17280, 4320, 4320, 8640, 17280, 17280, 8640, 4320, 8640, 4320, 8640, 17280, 17280, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 8640, 8640, 17280, 8640, 8640, 4320, 8640, 17280, 8640, 4320, 4320, 8640, 17280, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 8640, 17280, 8640, 8640, 8640, 4320, 17280, 4320, 17280, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 4320, 4320, 17280, 8640, 17280, 8640, 17280, 8640, 4320, 8640, 4320, 4320, 4320, 17280, 17280, 8640, 8640, 4320, 4320, 8640, 4320, 17280, 4320, 4320, 8640, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 8640, 4320, 8640, 4320, 17280, 8640, 8640, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 8640, 4320, 8640, 4320, 8640, 17280, 17280, 17280, 4320, 17280, 17280, 17280, 17280, 4320, 8640, 8640, 17280, 4320, 17280, 4320, 4320, 4320, 17280, 8640, 17280, 17280, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 17280, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 17280, 17280, 17280, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 4320, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 4320]
Prompts retrieved: 3231360 . Total input tokens: 719366854 . Total output tokens: 646131383
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 7.0760358379920945,
    "estimated_duration": 3600.2699228377896,
    "input_throughput": 3680.7873531756472,
    "output_throughput": 3220.119115641746,
    "total_throughput": 6900.906468817393,
    "itl": 261.58493879949367,
    "ttft": 2300540.3807316534,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1396,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.174110211683326,
    "arrivals": 1075699,
    "finished_requests": 53424,
    "scheduler_time": 65.86542516051402
}
#Debug simulation 
Total elapsed time: 7.076134722970892. Arrivals time: 0.23608573619276285 Scheduler time: 6.7410649747471325 Scheduler overhead time: 0.024061038566287607 Adapter cache time: 0.03999291465152055 Engine time: 0.02432434307411313 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_16-16-32/adapters_320_slots_192_rate_1.6-0.8-0.4_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_16-16-32/adapters_320_slots_192_rate_1.6-0.8-0.4_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 4320, 17280, 17280, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 8640, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 17280, 17280, 8640, 4320, 4320, 8640, 17280, 17280, 8640, 8640, 4320, 4320, 8640, 17280, 17280, 4320, 17280, 8640, 4320, 8640, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 4320, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 4320, 17280, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 4320, 8640, 8640, 4320, 17280, 8640, 17280, 17280, 8640, 4320, 8640, 8640, 8640, 4320, 17280, 8640, 17280, 4320, 17280, 4320, 4320, 8640, 17280, 17280, 8640, 4320, 8640, 4320, 8640, 17280, 17280, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 8640, 8640, 17280, 8640, 8640, 4320, 8640, 17280, 8640, 4320, 4320, 8640, 17280, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 8640, 17280, 8640, 8640, 8640, 4320, 17280, 4320, 17280, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 4320, 4320, 17280, 8640, 17280, 8640, 17280, 8640, 4320, 8640, 4320, 4320, 4320, 17280, 17280, 8640, 8640, 4320, 4320, 8640, 4320, 17280, 4320, 4320, 8640, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 8640, 4320, 8640, 4320, 17280, 8640, 8640, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 8640, 4320, 8640, 4320, 8640, 17280, 17280, 17280, 4320, 17280, 17280, 17280, 17280, 4320, 8640, 8640, 17280, 4320, 17280, 4320, 4320, 4320, 17280, 8640, 17280, 17280, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 17280, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 17280, 17280, 17280, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 4320, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 4320]
Prompts retrieved: 3231360 . Total input tokens: 719366854 . Total output tokens: 646131383
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.6316641200101003,
    "estimated_duration": 3600.1183484373705,
    "input_throughput": 2845.733392194406,
    "output_throughput": 2506.4048252515317,
    "total_throughput": 5352.138217445938,
    "itl": 134.867825185567,
    "ttft": 2431543.478239602,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9614,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 32.22869142420325,
    "arrivals": 1075699,
    "finished_requests": 41194,
    "scheduler_time": 72.49448329072663
}
#Debug simulation 
Total elapsed time: 3.6318154959590174. Arrivals time: 0.19765146443387493 Scheduler time: 3.1160815682378598 Scheduler overhead time: 0.03907424857607111 Adapter cache time: 0.22088062326656654 Engine time: 0.03950356150744483 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-8/adapters_320_slots_192_rate_1.6-0.8-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-8/adapters_320_slots_192_rate_1.6-0.8-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 1080, 17280, 17280, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 8640, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 17280, 17280, 8640, 1080, 1080, 8640, 17280, 17280, 8640, 8640, 1080, 1080, 8640, 17280, 17280, 1080, 17280, 8640, 1080, 8640, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 1080, 17280, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 1080, 8640, 8640, 1080, 17280, 8640, 17280, 17280, 8640, 1080, 8640, 8640, 8640, 1080, 17280, 8640, 17280, 1080, 17280, 1080, 1080, 8640, 17280, 17280, 8640, 1080, 8640, 1080, 8640, 17280, 17280, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 8640, 8640, 17280, 8640, 8640, 1080, 8640, 17280, 8640, 1080, 1080, 8640, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 8640, 17280, 8640, 8640, 8640, 1080, 17280, 1080, 17280, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 1080, 1080, 17280, 8640, 17280, 8640, 17280, 8640, 1080, 8640, 1080, 1080, 1080, 17280, 17280, 8640, 8640, 1080, 1080, 8640, 1080, 17280, 1080, 1080, 8640, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 8640, 1080, 8640, 1080, 17280, 8640, 8640, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 8640, 1080, 8640, 1080, 8640, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 8640, 8640, 17280, 1080, 17280, 1080, 1080, 1080, 17280, 8640, 17280, 17280, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 17280, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 17280, 17280, 17280, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 2887920 . Total input tokens: 643016451 . Total output tokens: 577573617
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.7514023759868,
    "estimated_duration": 3600.1435710320484,
    "input_throughput": 3661.8225745427208,
    "output_throughput": 3229.298990614201,
    "total_throughput": 6891.121565156922,
    "itl": 264.71700798090063,
    "ttft": 2294463.2880525165,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1358,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.156142356260788,
    "arrivals": 961706,
    "finished_requests": 53232,
    "scheduler_time": 65.74310922916177
}
#Debug simulation 
Total elapsed time: 5.751495931006502. Arrivals time: 0.22818837338127196 Scheduler time: 5.429139921208844 Scheduler overhead time: 0.02319431764772162 Adapter cache time: 0.03691630234243348 Engine time: 0.023599689884576946 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-16/adapters_320_slots_192_rate_1.6-0.8-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-16/adapters_320_slots_192_rate_1.6-0.8-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 1080, 17280, 17280, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 8640, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 17280, 17280, 8640, 1080, 1080, 8640, 17280, 17280, 8640, 8640, 1080, 1080, 8640, 17280, 17280, 1080, 17280, 8640, 1080, 8640, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 1080, 17280, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 1080, 8640, 8640, 1080, 17280, 8640, 17280, 17280, 8640, 1080, 8640, 8640, 8640, 1080, 17280, 8640, 17280, 1080, 17280, 1080, 1080, 8640, 17280, 17280, 8640, 1080, 8640, 1080, 8640, 17280, 17280, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 8640, 8640, 17280, 8640, 8640, 1080, 8640, 17280, 8640, 1080, 1080, 8640, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 8640, 17280, 8640, 8640, 8640, 1080, 17280, 1080, 17280, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 1080, 1080, 17280, 8640, 17280, 8640, 17280, 8640, 1080, 8640, 1080, 1080, 1080, 17280, 17280, 8640, 8640, 1080, 1080, 8640, 1080, 17280, 1080, 1080, 8640, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 8640, 1080, 8640, 1080, 17280, 8640, 8640, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 8640, 1080, 8640, 1080, 8640, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 8640, 8640, 17280, 1080, 17280, 1080, 1080, 1080, 17280, 8640, 17280, 17280, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 17280, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 17280, 17280, 17280, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 2887920 . Total input tokens: 643016451 . Total output tokens: 577573617
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.710045965970494,
    "estimated_duration": 3600.0100786164353,
    "input_throughput": 3651.9728314351664,
    "output_throughput": 3220.0979294078015,
    "total_throughput": 6872.070760842968,
    "itl": 261.45023447180137,
    "ttft": 2296682.0518065486,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1363,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.446851696413907,
    "arrivals": 961706,
    "finished_requests": 53075,
    "scheduler_time": 65.82823133817874
}
#Debug simulation 
Total elapsed time: 5.710202200978529. Arrivals time: 0.28972024942049757 Scheduler time: 5.325165458489209 Scheduler overhead time: 0.023280863009858876 Adapter cache time: 0.03784457175061107 Engine time: 0.023660968232434243 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-32/adapters_320_slots_192_rate_1.6-0.8-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-32/adapters_320_slots_192_rate_1.6-0.8-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 1080, 17280, 17280, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 8640, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 17280, 17280, 8640, 1080, 1080, 8640, 17280, 17280, 8640, 8640, 1080, 1080, 8640, 17280, 17280, 1080, 17280, 8640, 1080, 8640, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 1080, 17280, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 1080, 8640, 8640, 1080, 17280, 8640, 17280, 17280, 8640, 1080, 8640, 8640, 8640, 1080, 17280, 8640, 17280, 1080, 17280, 1080, 1080, 8640, 17280, 17280, 8640, 1080, 8640, 1080, 8640, 17280, 17280, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 8640, 8640, 17280, 8640, 8640, 1080, 8640, 17280, 8640, 1080, 1080, 8640, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 8640, 17280, 8640, 8640, 8640, 1080, 17280, 1080, 17280, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 1080, 1080, 17280, 8640, 17280, 8640, 17280, 8640, 1080, 8640, 1080, 1080, 1080, 17280, 17280, 8640, 8640, 1080, 1080, 8640, 1080, 17280, 1080, 1080, 8640, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 8640, 1080, 8640, 1080, 17280, 8640, 8640, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 8640, 1080, 8640, 1080, 8640, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 8640, 8640, 17280, 1080, 17280, 1080, 1080, 1080, 17280, 8640, 17280, 17280, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 17280, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 17280, 17280, 17280, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 2887920 . Total input tokens: 643016451 . Total output tokens: 577573617
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.597206749022007,
    "estimated_duration": 3600.056366529967,
    "input_throughput": 2909.2733373214583,
    "output_throughput": 2590.9683211406896,
    "total_throughput": 5500.241658462148,
    "itl": 130.84554493754072,
    "ttft": 2418333.345798221,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7439,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.325287951175316,
    "arrivals": 961706,
    "finished_requests": 42380,
    "scheduler_time": 74.80349411662277
}
#Debug simulation 
Total elapsed time: 3.5973309169639833. Arrivals time: 0.18718926183646545 Scheduler time: 3.1025692000985146 Scheduler overhead time: 0.03944758785655722 Adapter cache time: 0.20901729335309938 Engine time: 0.040240427653770894 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-16-16/adapters_320_slots_192_rate_1.6-0.8-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-16-16/adapters_320_slots_192_rate_1.6-0.8-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 1080, 17280, 17280, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 8640, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 17280, 17280, 8640, 1080, 1080, 8640, 17280, 17280, 8640, 8640, 1080, 1080, 8640, 17280, 17280, 1080, 17280, 8640, 1080, 8640, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 1080, 17280, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 1080, 8640, 8640, 1080, 17280, 8640, 17280, 17280, 8640, 1080, 8640, 8640, 8640, 1080, 17280, 8640, 17280, 1080, 17280, 1080, 1080, 8640, 17280, 17280, 8640, 1080, 8640, 1080, 8640, 17280, 17280, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 8640, 8640, 17280, 8640, 8640, 1080, 8640, 17280, 8640, 1080, 1080, 8640, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 8640, 17280, 8640, 8640, 8640, 1080, 17280, 1080, 17280, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 1080, 1080, 17280, 8640, 17280, 8640, 17280, 8640, 1080, 8640, 1080, 1080, 1080, 17280, 17280, 8640, 8640, 1080, 1080, 8640, 1080, 17280, 1080, 1080, 8640, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 8640, 1080, 8640, 1080, 17280, 8640, 8640, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 8640, 1080, 8640, 1080, 8640, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 8640, 8640, 17280, 1080, 17280, 1080, 1080, 1080, 17280, 8640, 17280, 17280, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 17280, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 17280, 17280, 17280, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 2887920 . Total input tokens: 643016451 . Total output tokens: 577573617
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 5.671858063957188,
    "estimated_duration": 3600.108203347483,
    "input_throughput": 3652.0407880448856,
    "output_throughput": 3220.3104310087306,
    "total_throughput": 6872.351219053617,
    "itl": 261.44011860952253,
    "ttft": 2296626.7017074698,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1363,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.251951729517832,
    "arrivals": 961706,
    "finished_requests": 53080,
    "scheduler_time": 65.83338536745065
}
#Debug simulation 
Total elapsed time: 5.672003261977807. Arrivals time: 0.2298729273607023 Scheduler time: 5.346916574053466 Scheduler overhead time: 0.023265252297278494 Adapter cache time: 0.03780495934188366 Engine time: 0.023593895020894706 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-16-32/adapters_320_slots_192_rate_1.6-0.8-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-16-32/adapters_320_slots_192_rate_1.6-0.8-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 1080, 17280, 17280, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 8640, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 17280, 17280, 8640, 1080, 1080, 8640, 17280, 17280, 8640, 8640, 1080, 1080, 8640, 17280, 17280, 1080, 17280, 8640, 1080, 8640, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 1080, 17280, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 1080, 8640, 8640, 1080, 17280, 8640, 17280, 17280, 8640, 1080, 8640, 8640, 8640, 1080, 17280, 8640, 17280, 1080, 17280, 1080, 1080, 8640, 17280, 17280, 8640, 1080, 8640, 1080, 8640, 17280, 17280, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 8640, 8640, 17280, 8640, 8640, 1080, 8640, 17280, 8640, 1080, 1080, 8640, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 8640, 17280, 8640, 8640, 8640, 1080, 17280, 1080, 17280, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 1080, 1080, 17280, 8640, 17280, 8640, 17280, 8640, 1080, 8640, 1080, 1080, 1080, 17280, 17280, 8640, 8640, 1080, 1080, 8640, 1080, 17280, 1080, 1080, 8640, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 8640, 1080, 8640, 1080, 17280, 8640, 8640, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 8640, 1080, 8640, 1080, 8640, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 8640, 8640, 17280, 1080, 17280, 1080, 1080, 1080, 17280, 8640, 17280, 17280, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 17280, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 17280, 17280, 17280, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 2887920 . Total input tokens: 643016451 . Total output tokens: 577573617
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 3.5972436179872602,
    "estimated_duration": 3600.0822813005275,
    "input_throughput": 2909.0446222292194,
    "output_throughput": 2590.866616701468,
    "total_throughput": 5499.911238930687,
    "itl": 130.85731376447416,
    "ttft": 2418333.6235231734,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7439,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.64495407624081,
    "arrivals": 961706,
    "finished_requests": 42378,
    "scheduler_time": 74.797539190054
}
#Debug simulation 
Total elapsed time: 3.5973455639905296. Arrivals time: 0.19513340992853045 Scheduler time: 3.093963330902625 Scheduler overhead time: 0.03953519382048398 Adapter cache time: 0.20933839300414547 Engine time: 0.04041746672010049 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_16-16-16/adapters_320_slots_192_rate_1.6-0.8-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_16-16-16/adapters_320_slots_192_rate_1.6-0.8-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 1080, 17280, 17280, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 8640, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 17280, 17280, 8640, 1080, 1080, 8640, 17280, 17280, 8640, 8640, 1080, 1080, 8640, 17280, 17280, 1080, 17280, 8640, 1080, 8640, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 1080, 17280, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 1080, 8640, 8640, 1080, 17280, 8640, 17280, 17280, 8640, 1080, 8640, 8640, 8640, 1080, 17280, 8640, 17280, 1080, 17280, 1080, 1080, 8640, 17280, 17280, 8640, 1080, 8640, 1080, 8640, 17280, 17280, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 8640, 8640, 17280, 8640, 8640, 1080, 8640, 17280, 8640, 1080, 1080, 8640, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 8640, 17280, 8640, 8640, 8640, 1080, 17280, 1080, 17280, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 1080, 1080, 17280, 8640, 17280, 8640, 17280, 8640, 1080, 8640, 1080, 1080, 1080, 17280, 17280, 8640, 8640, 1080, 1080, 8640, 1080, 17280, 1080, 1080, 8640, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 8640, 1080, 8640, 1080, 17280, 8640, 8640, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 8640, 1080, 8640, 1080, 8640, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 8640, 8640, 17280, 1080, 17280, 1080, 1080, 1080, 17280, 8640, 17280, 17280, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 17280, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 17280, 17280, 17280, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 2887920 . Total input tokens: 643016451 . Total output tokens: 577573617
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.657663736026734,
    "estimated_duration": 3600.2244908589096,
    "input_throughput": 3652.182255130181,
    "output_throughput": 3220.4336228027655,
    "total_throughput": 6872.615877932946,
    "itl": 261.4282372233747,
    "ttft": 2296626.621638189,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1363,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.0754385519515575,
    "arrivals": 961706,
    "finished_requests": 53085,
    "scheduler_time": 65.83855915731809
}
#Debug simulation 
Total elapsed time: 5.6578012870159. Arrivals time: 0.2241305440547876 Scheduler time: 5.338469967013225 Scheduler overhead time: 0.02321581426076591 Adapter cache time: 0.0377974808216095 Engine time: 0.02358195057604462 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_16-16-32/adapters_320_slots_192_rate_1.6-0.8-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_16-16-32/adapters_320_slots_192_rate_1.6-0.8-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 1080, 17280, 17280, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 8640, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 17280, 17280, 8640, 1080, 1080, 8640, 17280, 17280, 8640, 8640, 1080, 1080, 8640, 17280, 17280, 1080, 17280, 8640, 1080, 8640, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 1080, 17280, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 1080, 8640, 8640, 1080, 17280, 8640, 17280, 17280, 8640, 1080, 8640, 8640, 8640, 1080, 17280, 8640, 17280, 1080, 17280, 1080, 1080, 8640, 17280, 17280, 8640, 1080, 8640, 1080, 8640, 17280, 17280, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 8640, 8640, 17280, 8640, 8640, 1080, 8640, 17280, 8640, 1080, 1080, 8640, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 8640, 17280, 8640, 8640, 8640, 1080, 17280, 1080, 17280, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 1080, 1080, 17280, 8640, 17280, 8640, 17280, 8640, 1080, 8640, 1080, 1080, 1080, 17280, 17280, 8640, 8640, 1080, 1080, 8640, 1080, 17280, 1080, 1080, 8640, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 8640, 1080, 8640, 1080, 17280, 8640, 8640, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 8640, 1080, 8640, 1080, 8640, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 8640, 8640, 17280, 1080, 17280, 1080, 1080, 1080, 17280, 8640, 17280, 17280, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 17280, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 17280, 17280, 17280, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 2887920 . Total input tokens: 643016451 . Total output tokens: 577573617
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.6768003439647146,
    "estimated_duration": 3600.092496894752,
    "input_throughput": 2908.633322347142,
    "output_throughput": 2590.6306596412596,
    "total_throughput": 5499.263981988402,
    "itl": 130.8738351233365,
    "ttft": 2418256.3492949056,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7438,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.94992159418561,
    "arrivals": 961706,
    "finished_requests": 42372,
    "scheduler_time": 74.79156761959581
}
#Debug simulation 
Total elapsed time: 3.6768926849472336. Arrivals time: 0.1871326618711464 Scheduler time: 3.177533552458044 Scheduler overhead time: 0.0398706296691671 Adapter cache time: 0.21252093673683703 Engine time: 0.040782872936688364 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-8/adapters_320_slots_192_rate_1.6-0.8-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-8/adapters_320_slots_192_rate_1.6-0.8-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 540, 17280, 17280, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 8640, 8640, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 17280, 17280, 8640, 540, 540, 8640, 17280, 17280, 8640, 8640, 540, 540, 8640, 17280, 17280, 540, 17280, 8640, 540, 8640, 17280, 540, 8640, 17280, 17280, 8640, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 8640, 8640, 8640, 540, 8640, 540, 17280, 540, 17280, 8640, 17280, 17280, 540, 17280, 540, 17280, 8640, 540, 540, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 540, 8640, 8640, 540, 17280, 8640, 17280, 17280, 8640, 540, 8640, 8640, 8640, 540, 17280, 8640, 17280, 540, 17280, 540, 540, 8640, 17280, 17280, 8640, 540, 8640, 540, 8640, 17280, 17280, 8640, 540, 8640, 540, 17280, 540, 540, 540, 540, 17280, 8640, 8640, 17280, 8640, 8640, 540, 8640, 17280, 8640, 540, 540, 8640, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 8640, 17280, 8640, 8640, 8640, 540, 17280, 540, 17280, 8640, 540, 8640, 540, 540, 8640, 540, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 540, 540, 17280, 8640, 17280, 8640, 17280, 8640, 540, 8640, 540, 540, 540, 17280, 17280, 8640, 8640, 540, 540, 8640, 540, 17280, 540, 540, 8640, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 8640, 17280, 8640, 540, 8640, 540, 17280, 8640, 8640, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 8640, 540, 8640, 540, 8640, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 8640, 8640, 17280, 540, 17280, 540, 540, 540, 17280, 8640, 17280, 17280, 540, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 17280, 540, 540, 8640, 540, 8640, 8640, 540, 17280, 17280, 17280, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 17280, 540, 540, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2830680 . Total input tokens: 630386708 . Total output tokens: 566081381
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.297040531004313,
    "estimated_duration": 3600.065195492714,
    "input_throughput": 3677.028687306391,
    "output_throughput": 3229.473181362426,
    "total_throughput": 6906.501868668817,
    "itl": 263.647375741242,
    "ttft": 2286956.2985378033,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1194,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.654222366255799,
    "arrivals": 942321,
    "finished_requests": 53684,
    "scheduler_time": 65.76984071491648
}
#Debug simulation 
Total elapsed time: 5.297188986034598. Arrivals time: 0.23874610272469 Scheduler time: 4.969610000203829 Scheduler overhead time: 0.023061265179421753 Adapter cache time: 0.03217235510237515 Engine time: 0.023126747051719576 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-16/adapters_320_slots_192_rate_1.6-0.8-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-16/adapters_320_slots_192_rate_1.6-0.8-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 540, 17280, 17280, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 8640, 8640, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 17280, 17280, 8640, 540, 540, 8640, 17280, 17280, 8640, 8640, 540, 540, 8640, 17280, 17280, 540, 17280, 8640, 540, 8640, 17280, 540, 8640, 17280, 17280, 8640, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 8640, 8640, 8640, 540, 8640, 540, 17280, 540, 17280, 8640, 17280, 17280, 540, 17280, 540, 17280, 8640, 540, 540, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 540, 8640, 8640, 540, 17280, 8640, 17280, 17280, 8640, 540, 8640, 8640, 8640, 540, 17280, 8640, 17280, 540, 17280, 540, 540, 8640, 17280, 17280, 8640, 540, 8640, 540, 8640, 17280, 17280, 8640, 540, 8640, 540, 17280, 540, 540, 540, 540, 17280, 8640, 8640, 17280, 8640, 8640, 540, 8640, 17280, 8640, 540, 540, 8640, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 8640, 17280, 8640, 8640, 8640, 540, 17280, 540, 17280, 8640, 540, 8640, 540, 540, 8640, 540, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 540, 540, 17280, 8640, 17280, 8640, 17280, 8640, 540, 8640, 540, 540, 540, 17280, 17280, 8640, 8640, 540, 540, 8640, 540, 17280, 540, 540, 8640, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 8640, 17280, 8640, 540, 8640, 540, 17280, 8640, 8640, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 8640, 540, 8640, 540, 8640, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 8640, 8640, 17280, 540, 17280, 540, 540, 540, 17280, 8640, 17280, 17280, 540, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 17280, 540, 540, 8640, 540, 8640, 8640, 540, 17280, 17280, 17280, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 17280, 540, 540, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2830680 . Total input tokens: 630386708 . Total output tokens: 566081381
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.196171745017637,
    "estimated_duration": 3600.2098079852085,
    "input_throughput": 3667.1393346901973,
    "output_throughput": 3220.138163694384,
    "total_throughput": 6887.277498384581,
    "itl": 260.9878585487878,
    "ttft": 2288478.4783785567,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1191,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.8937464904389425,
    "arrivals": 942321,
    "finished_requests": 53533,
    "scheduler_time": 65.84524503691648
}
#Debug simulation 
Total elapsed time: 5.196265259990469. Arrivals time: 0.22280393302207813 Scheduler time: 4.883129244321026 Scheduler overhead time: 0.023085481312591583 Adapter cache time: 0.0333049877663143 Engine time: 0.02347864571493119 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-32/adapters_320_slots_192_rate_1.6-0.8-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-32/adapters_320_slots_192_rate_1.6-0.8-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 540, 17280, 17280, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 8640, 8640, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 17280, 17280, 8640, 540, 540, 8640, 17280, 17280, 8640, 8640, 540, 540, 8640, 17280, 17280, 540, 17280, 8640, 540, 8640, 17280, 540, 8640, 17280, 17280, 8640, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 8640, 8640, 8640, 540, 8640, 540, 17280, 540, 17280, 8640, 17280, 17280, 540, 17280, 540, 17280, 8640, 540, 540, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 540, 8640, 8640, 540, 17280, 8640, 17280, 17280, 8640, 540, 8640, 8640, 8640, 540, 17280, 8640, 17280, 540, 17280, 540, 540, 8640, 17280, 17280, 8640, 540, 8640, 540, 8640, 17280, 17280, 8640, 540, 8640, 540, 17280, 540, 540, 540, 540, 17280, 8640, 8640, 17280, 8640, 8640, 540, 8640, 17280, 8640, 540, 540, 8640, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 8640, 17280, 8640, 8640, 8640, 540, 17280, 540, 17280, 8640, 540, 8640, 540, 540, 8640, 540, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 540, 540, 17280, 8640, 17280, 8640, 17280, 8640, 540, 8640, 540, 540, 540, 17280, 17280, 8640, 8640, 540, 540, 8640, 540, 17280, 540, 540, 8640, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 8640, 17280, 8640, 540, 8640, 540, 17280, 8640, 8640, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 8640, 540, 8640, 540, 8640, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 8640, 8640, 17280, 540, 17280, 540, 540, 540, 17280, 8640, 17280, 17280, 540, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 17280, 540, 540, 8640, 540, 8640, 8640, 540, 17280, 17280, 17280, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 17280, 540, 540, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2830680 . Total input tokens: 630386708 . Total output tokens: 566081381
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.65247307397658,
    "estimated_duration": 3600.0618767666197,
    "input_throughput": 2994.3929768457233,
    "output_throughput": 2639.1649158356754,
    "total_throughput": 5633.557892681399,
    "itl": 127.79155173535642,
    "ttft": 2400468.2634464637,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6013,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.69148750509995,
    "arrivals": 942321,
    "finished_requests": 43622,
    "scheduler_time": 76.2905025438444
}
#Debug simulation 
Total elapsed time: 3.6526062209741212. Arrivals time: 0.19376323849428445 Scheduler time: 3.1583705419907346 Scheduler overhead time: 0.04024973860941827 Adapter cache time: 0.1990507929585874 Engine time: 0.04174885438987985 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-16-16/adapters_320_slots_192_rate_1.6-0.8-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-16-16/adapters_320_slots_192_rate_1.6-0.8-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 540, 17280, 17280, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 8640, 8640, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 17280, 17280, 8640, 540, 540, 8640, 17280, 17280, 8640, 8640, 540, 540, 8640, 17280, 17280, 540, 17280, 8640, 540, 8640, 17280, 540, 8640, 17280, 17280, 8640, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 8640, 8640, 8640, 540, 8640, 540, 17280, 540, 17280, 8640, 17280, 17280, 540, 17280, 540, 17280, 8640, 540, 540, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 540, 8640, 8640, 540, 17280, 8640, 17280, 17280, 8640, 540, 8640, 8640, 8640, 540, 17280, 8640, 17280, 540, 17280, 540, 540, 8640, 17280, 17280, 8640, 540, 8640, 540, 8640, 17280, 17280, 8640, 540, 8640, 540, 17280, 540, 540, 540, 540, 17280, 8640, 8640, 17280, 8640, 8640, 540, 8640, 17280, 8640, 540, 540, 8640, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 8640, 17280, 8640, 8640, 8640, 540, 17280, 540, 17280, 8640, 540, 8640, 540, 540, 8640, 540, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 540, 540, 17280, 8640, 17280, 8640, 17280, 8640, 540, 8640, 540, 540, 540, 17280, 17280, 8640, 8640, 540, 540, 8640, 540, 17280, 540, 540, 8640, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 8640, 17280, 8640, 540, 8640, 540, 17280, 8640, 8640, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 8640, 540, 8640, 540, 8640, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 8640, 8640, 17280, 540, 17280, 540, 540, 540, 17280, 8640, 17280, 17280, 540, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 17280, 540, 540, 8640, 540, 8640, 8640, 540, 17280, 17280, 17280, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 17280, 540, 540, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2830680 . Total input tokens: 630386708 . Total output tokens: 566081381
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 5.298268412996549,
    "estimated_duration": 3600.1953110138525,
    "input_throughput": 3668.059052129905,
    "output_throughput": 3221.7263226015493,
    "total_throughput": 6889.785374731454,
    "itl": 261.3738715162014,
    "ttft": 2288333.418965157,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1203,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7547482976852455,
    "arrivals": 942321,
    "finished_requests": 53557,
    "scheduler_time": 65.83535060108464
}
#Debug simulation 
Total elapsed time: 5.298392634023912. Arrivals time: 0.22192822821671143 Scheduler time: 4.985888433875516 Scheduler overhead time: 0.023192392371129245 Adapter cache time: 0.033303657663054764 Engine time: 0.023543236835394055 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-16-32/adapters_320_slots_192_rate_1.6-0.8-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-16-32/adapters_320_slots_192_rate_1.6-0.8-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 540, 17280, 17280, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 8640, 8640, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 17280, 17280, 8640, 540, 540, 8640, 17280, 17280, 8640, 8640, 540, 540, 8640, 17280, 17280, 540, 17280, 8640, 540, 8640, 17280, 540, 8640, 17280, 17280, 8640, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 8640, 8640, 8640, 540, 8640, 540, 17280, 540, 17280, 8640, 17280, 17280, 540, 17280, 540, 17280, 8640, 540, 540, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 540, 8640, 8640, 540, 17280, 8640, 17280, 17280, 8640, 540, 8640, 8640, 8640, 540, 17280, 8640, 17280, 540, 17280, 540, 540, 8640, 17280, 17280, 8640, 540, 8640, 540, 8640, 17280, 17280, 8640, 540, 8640, 540, 17280, 540, 540, 540, 540, 17280, 8640, 8640, 17280, 8640, 8640, 540, 8640, 17280, 8640, 540, 540, 8640, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 8640, 17280, 8640, 8640, 8640, 540, 17280, 540, 17280, 8640, 540, 8640, 540, 540, 8640, 540, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 540, 540, 17280, 8640, 17280, 8640, 17280, 8640, 540, 8640, 540, 540, 540, 17280, 17280, 8640, 8640, 540, 540, 8640, 540, 17280, 540, 540, 8640, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 8640, 17280, 8640, 540, 8640, 540, 17280, 8640, 8640, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 8640, 540, 8640, 540, 8640, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 8640, 8640, 17280, 540, 17280, 540, 540, 540, 17280, 8640, 17280, 17280, 540, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 17280, 540, 540, 8640, 540, 8640, 8640, 540, 17280, 17280, 17280, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 17280, 540, 540, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2830680 . Total input tokens: 630386708 . Total output tokens: 566081381
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 3.6289831079775468,
    "estimated_duration": 3600.030815676926,
    "input_throughput": 2994.2318696439065,
    "output_throughput": 2639.1193538196176,
    "total_throughput": 5633.351223463524,
    "itl": 127.80091544102096,
    "ttft": 2400437.2008409477,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6011,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.94717412466076,
    "arrivals": 942321,
    "finished_requests": 43620,
    "scheduler_time": 76.28448044638023
}
#Debug simulation 
Total elapsed time: 3.6291495179757476. Arrivals time: 0.18901156930951402 Scheduler time: 3.138581202714704 Scheduler overhead time: 0.04030410636914894 Adapter cache time: 0.20045166101772338 Engine time: 0.04151527985231951 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_16-16-16/adapters_320_slots_192_rate_1.6-0.8-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_16-16-16/adapters_320_slots_192_rate_1.6-0.8-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 540, 17280, 17280, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 8640, 8640, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 17280, 17280, 8640, 540, 540, 8640, 17280, 17280, 8640, 8640, 540, 540, 8640, 17280, 17280, 540, 17280, 8640, 540, 8640, 17280, 540, 8640, 17280, 17280, 8640, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 8640, 8640, 8640, 540, 8640, 540, 17280, 540, 17280, 8640, 17280, 17280, 540, 17280, 540, 17280, 8640, 540, 540, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 540, 8640, 8640, 540, 17280, 8640, 17280, 17280, 8640, 540, 8640, 8640, 8640, 540, 17280, 8640, 17280, 540, 17280, 540, 540, 8640, 17280, 17280, 8640, 540, 8640, 540, 8640, 17280, 17280, 8640, 540, 8640, 540, 17280, 540, 540, 540, 540, 17280, 8640, 8640, 17280, 8640, 8640, 540, 8640, 17280, 8640, 540, 540, 8640, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 8640, 17280, 8640, 8640, 8640, 540, 17280, 540, 17280, 8640, 540, 8640, 540, 540, 8640, 540, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 540, 540, 17280, 8640, 17280, 8640, 17280, 8640, 540, 8640, 540, 540, 540, 17280, 17280, 8640, 8640, 540, 540, 8640, 540, 17280, 540, 540, 8640, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 8640, 17280, 8640, 540, 8640, 540, 17280, 8640, 8640, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 8640, 540, 8640, 540, 8640, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 8640, 8640, 17280, 540, 17280, 540, 540, 540, 17280, 8640, 17280, 17280, 540, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 17280, 540, 540, 8640, 540, 8640, 8640, 540, 17280, 17280, 17280, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 17280, 540, 540, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2830680 . Total input tokens: 630386708 . Total output tokens: 566081381
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.227065020008013,
    "estimated_duration": 3600.0373609359335,
    "input_throughput": 3668.219986630025,
    "output_throughput": 3221.8676744467302,
    "total_throughput": 6890.0876610767555,
    "itl": 261.3637238748643,
    "ttft": 2288270.8845930705,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1203,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5970305047672264,
    "arrivals": 942321,
    "finished_requests": 53557,
    "scheduler_time": 65.83511831604645
}
#Debug simulation 
Total elapsed time: 5.2271705160383135. Arrivals time: 0.23286390339490026 Scheduler time: 4.903748397424351 Scheduler overhead time: 0.023157761606853455 Adapter cache time: 0.03330184909282252 Engine time: 0.023543424846138805 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_16-16-32/adapters_320_slots_192_rate_1.6-0.8-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_16-16-32/adapters_320_slots_192_rate_1.6-0.8-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 540, 17280, 17280, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 8640, 8640, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 17280, 17280, 8640, 540, 540, 8640, 17280, 17280, 8640, 8640, 540, 540, 8640, 17280, 17280, 540, 17280, 8640, 540, 8640, 17280, 540, 8640, 17280, 17280, 8640, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 8640, 8640, 8640, 540, 8640, 540, 17280, 540, 17280, 8640, 17280, 17280, 540, 17280, 540, 17280, 8640, 540, 540, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 540, 8640, 8640, 540, 17280, 8640, 17280, 17280, 8640, 540, 8640, 8640, 8640, 540, 17280, 8640, 17280, 540, 17280, 540, 540, 8640, 17280, 17280, 8640, 540, 8640, 540, 8640, 17280, 17280, 8640, 540, 8640, 540, 17280, 540, 540, 540, 540, 17280, 8640, 8640, 17280, 8640, 8640, 540, 8640, 17280, 8640, 540, 540, 8640, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 8640, 17280, 8640, 8640, 8640, 540, 17280, 540, 17280, 8640, 540, 8640, 540, 540, 8640, 540, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 540, 540, 17280, 8640, 17280, 8640, 17280, 8640, 540, 8640, 540, 540, 540, 17280, 17280, 8640, 8640, 540, 540, 8640, 540, 17280, 540, 540, 8640, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 8640, 17280, 8640, 540, 8640, 540, 17280, 8640, 8640, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 8640, 540, 8640, 540, 8640, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 8640, 8640, 17280, 540, 17280, 540, 540, 540, 17280, 8640, 17280, 17280, 540, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 17280, 540, 540, 8640, 540, 8640, 8640, 540, 17280, 17280, 17280, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 17280, 540, 540, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2830680 . Total input tokens: 630386708 . Total output tokens: 566081381
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.615395790024195,
    "estimated_duration": 3600.00287051541,
    "input_throughput": 2993.7142795825075,
    "output_throughput": 2638.9565068985225,
    "total_throughput": 5632.67078648103,
    "itl": 127.81054758677097,
    "ttft": 2400431.9583004396,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6011,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.203083080014558,
    "arrivals": 942321,
    "finished_requests": 43614,
    "scheduler_time": 76.27848407659127
}
#Debug simulation 
Total elapsed time: 3.6155363030266017. Arrivals time: 0.18750846560578793 Scheduler time: 3.1257051681168377 Scheduler overhead time: 0.040268415526952595 Adapter cache time: 0.20161711383843794 Engine time: 0.041167388088069856 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-8/adapters_320_slots_192_rate_1.6-0.8-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-8/adapters_320_slots_192_rate_1.6-0.8-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 270, 17280, 17280, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 8640, 8640, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 17280, 17280, 8640, 270, 270, 8640, 17280, 17280, 8640, 8640, 270, 270, 8640, 17280, 17280, 270, 17280, 8640, 270, 8640, 17280, 270, 8640, 17280, 17280, 8640, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 8640, 8640, 8640, 270, 8640, 270, 17280, 270, 17280, 8640, 17280, 17280, 270, 17280, 270, 17280, 8640, 270, 270, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 270, 8640, 8640, 270, 17280, 8640, 17280, 17280, 8640, 270, 8640, 8640, 8640, 270, 17280, 8640, 17280, 270, 17280, 270, 270, 8640, 17280, 17280, 8640, 270, 8640, 270, 8640, 17280, 17280, 8640, 270, 8640, 270, 17280, 270, 270, 270, 270, 17280, 8640, 8640, 17280, 8640, 8640, 270, 8640, 17280, 8640, 270, 270, 8640, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 8640, 17280, 8640, 8640, 8640, 270, 17280, 270, 17280, 8640, 270, 8640, 270, 270, 8640, 270, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 270, 270, 17280, 8640, 17280, 8640, 17280, 8640, 270, 8640, 270, 270, 270, 17280, 17280, 8640, 8640, 270, 270, 8640, 270, 17280, 270, 270, 8640, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 8640, 17280, 8640, 270, 8640, 270, 17280, 8640, 8640, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 8640, 270, 8640, 270, 8640, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 8640, 8640, 17280, 270, 17280, 270, 270, 270, 17280, 8640, 17280, 17280, 270, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 17280, 270, 270, 8640, 270, 8640, 8640, 270, 17280, 17280, 17280, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 17280, 270, 270, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2802060 . Total input tokens: 624030052 . Total output tokens: 560316778
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.788334881013725,
    "estimated_duration": 3600.011547664501,
    "input_throughput": 3680.4787497406096,
    "output_throughput": 3230.792692191644,
    "total_throughput": 6911.271441932254,
    "itl": 264.10350094592445,
    "ttft": 2286948.5718556885,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1103,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3757179815579086,
    "arrivals": 932854,
    "finished_requests": 53492,
    "scheduler_time": 65.76405139141464
}
#Debug simulation 
Total elapsed time: 4.788433692010585. Arrivals time: 0.21930851961951703 Scheduler time: 4.4831221549538895 Scheduler overhead time: 0.022580134856980294 Adapter cache time: 0.03016972285695374 Engine time: 0.022923866577912122 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-16/adapters_320_slots_192_rate_1.6-0.8-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-16/adapters_320_slots_192_rate_1.6-0.8-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 270, 17280, 17280, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 8640, 8640, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 17280, 17280, 8640, 270, 270, 8640, 17280, 17280, 8640, 8640, 270, 270, 8640, 17280, 17280, 270, 17280, 8640, 270, 8640, 17280, 270, 8640, 17280, 17280, 8640, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 8640, 8640, 8640, 270, 8640, 270, 17280, 270, 17280, 8640, 17280, 17280, 270, 17280, 270, 17280, 8640, 270, 270, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 270, 8640, 8640, 270, 17280, 8640, 17280, 17280, 8640, 270, 8640, 8640, 8640, 270, 17280, 8640, 17280, 270, 17280, 270, 270, 8640, 17280, 17280, 8640, 270, 8640, 270, 8640, 17280, 17280, 8640, 270, 8640, 270, 17280, 270, 270, 270, 270, 17280, 8640, 8640, 17280, 8640, 8640, 270, 8640, 17280, 8640, 270, 270, 8640, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 8640, 17280, 8640, 8640, 8640, 270, 17280, 270, 17280, 8640, 270, 8640, 270, 270, 8640, 270, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 270, 270, 17280, 8640, 17280, 8640, 17280, 8640, 270, 8640, 270, 270, 270, 17280, 17280, 8640, 8640, 270, 270, 8640, 270, 17280, 270, 270, 8640, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 8640, 17280, 8640, 270, 8640, 270, 17280, 8640, 8640, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 8640, 270, 8640, 270, 8640, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 8640, 8640, 17280, 270, 17280, 270, 270, 270, 17280, 8640, 17280, 17280, 270, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 17280, 270, 270, 8640, 270, 8640, 8640, 270, 17280, 17280, 17280, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 17280, 270, 270, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2802060 . Total input tokens: 624030052 . Total output tokens: 560316778
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.763324671017472,
    "estimated_duration": 3600.05645981396,
    "input_throughput": 3670.939649841753,
    "output_throughput": 3221.1233711038126,
    "total_throughput": 6892.063020945566,
    "itl": 261.46511925034747,
    "ttft": 2288665.849570918,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1142,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.727621450703597,
    "arrivals": 932854,
    "finished_requests": 53346,
    "scheduler_time": 65.83386346672454
}
#Debug simulation 
Total elapsed time: 4.7635036099818535. Arrivals time: 0.22143430903088301 Scheduler time: 4.453664280474186 Scheduler overhead time: 0.023135976458434016 Adapter cache time: 0.031472857226617634 Engine time: 0.023198966053314507 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-32/adapters_320_slots_192_rate_1.6-0.8-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-32/adapters_320_slots_192_rate_1.6-0.8-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 270, 17280, 17280, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 8640, 8640, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 17280, 17280, 8640, 270, 270, 8640, 17280, 17280, 8640, 8640, 270, 270, 8640, 17280, 17280, 270, 17280, 8640, 270, 8640, 17280, 270, 8640, 17280, 17280, 8640, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 8640, 8640, 8640, 270, 8640, 270, 17280, 270, 17280, 8640, 17280, 17280, 270, 17280, 270, 17280, 8640, 270, 270, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 270, 8640, 8640, 270, 17280, 8640, 17280, 17280, 8640, 270, 8640, 8640, 8640, 270, 17280, 8640, 17280, 270, 17280, 270, 270, 8640, 17280, 17280, 8640, 270, 8640, 270, 8640, 17280, 17280, 8640, 270, 8640, 270, 17280, 270, 270, 270, 270, 17280, 8640, 8640, 17280, 8640, 8640, 270, 8640, 17280, 8640, 270, 270, 8640, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 8640, 17280, 8640, 8640, 8640, 270, 17280, 270, 17280, 8640, 270, 8640, 270, 270, 8640, 270, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 270, 270, 17280, 8640, 17280, 8640, 17280, 8640, 270, 8640, 270, 270, 270, 17280, 17280, 8640, 8640, 270, 270, 8640, 270, 17280, 270, 270, 8640, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 8640, 17280, 8640, 270, 8640, 270, 17280, 8640, 8640, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 8640, 270, 8640, 270, 8640, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 8640, 8640, 17280, 270, 17280, 270, 270, 270, 17280, 8640, 17280, 17280, 270, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 17280, 270, 270, 8640, 270, 8640, 8640, 270, 17280, 17280, 17280, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 17280, 270, 270, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2802060 . Total input tokens: 624030052 . Total output tokens: 560316778
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.981557337974664,
    "estimated_duration": 3600.0908581751064,
    "input_throughput": 3017.677172044191,
    "output_throughput": 2661.8694853878296,
    "total_throughput": 5679.546657432021,
    "itl": 126.18532449722298,
    "ttft": 2393542.1862092214,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4979,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.27772624729062,
    "arrivals": 932854,
    "finished_requests": 43787,
    "scheduler_time": 77.18418334147238
}
#Debug simulation 
Total elapsed time: 3.981618711957708. Arrivals time: 0.5342361954972148 Scheduler time: 3.152381268911995 Scheduler overhead time: 0.040643323212862015 Adapter cache time: 0.19309762079501525 Engine time: 0.04186031688004732 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-16-16/adapters_320_slots_192_rate_1.6-0.8-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-16-16/adapters_320_slots_192_rate_1.6-0.8-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 270, 17280, 17280, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 8640, 8640, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 17280, 17280, 8640, 270, 270, 8640, 17280, 17280, 8640, 8640, 270, 270, 8640, 17280, 17280, 270, 17280, 8640, 270, 8640, 17280, 270, 8640, 17280, 17280, 8640, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 8640, 8640, 8640, 270, 8640, 270, 17280, 270, 17280, 8640, 17280, 17280, 270, 17280, 270, 17280, 8640, 270, 270, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 270, 8640, 8640, 270, 17280, 8640, 17280, 17280, 8640, 270, 8640, 8640, 8640, 270, 17280, 8640, 17280, 270, 17280, 270, 270, 8640, 17280, 17280, 8640, 270, 8640, 270, 8640, 17280, 17280, 8640, 270, 8640, 270, 17280, 270, 270, 270, 270, 17280, 8640, 8640, 17280, 8640, 8640, 270, 8640, 17280, 8640, 270, 270, 8640, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 8640, 17280, 8640, 8640, 8640, 270, 17280, 270, 17280, 8640, 270, 8640, 270, 270, 8640, 270, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 270, 270, 17280, 8640, 17280, 8640, 17280, 8640, 270, 8640, 270, 270, 270, 17280, 17280, 8640, 8640, 270, 270, 8640, 270, 17280, 270, 270, 8640, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 8640, 17280, 8640, 270, 8640, 270, 17280, 8640, 8640, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 8640, 270, 8640, 270, 8640, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 8640, 8640, 17280, 270, 17280, 270, 270, 270, 17280, 8640, 17280, 17280, 270, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 17280, 270, 270, 8640, 270, 8640, 8640, 270, 17280, 17280, 17280, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 17280, 270, 270, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2802060 . Total input tokens: 624030052 . Total output tokens: 560316778
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 5.13971640903037,
    "estimated_duration": 3600.190626194887,
    "input_throughput": 3671.059222208129,
    "output_throughput": 3221.2391520660058,
    "total_throughput": 6892.298374274135,
    "itl": 261.4515987710311,
    "ttft": 2288690.8248916054,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1142,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.570720848422457,
    "arrivals": 932854,
    "finished_requests": 53350,
    "scheduler_time": 65.83900993759043
}
#Debug simulation 
Total elapsed time: 5.139854326029308. Arrivals time: 0.5711537459865212 Scheduler time: 4.479500277317129 Scheduler overhead time: 0.023028375930152833 Adapter cache time: 0.03235619806218892 Engine time: 0.023287200136110187 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-16-32/adapters_320_slots_192_rate_1.6-0.8-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-16-32/adapters_320_slots_192_rate_1.6-0.8-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 270, 17280, 17280, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 8640, 8640, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 17280, 17280, 8640, 270, 270, 8640, 17280, 17280, 8640, 8640, 270, 270, 8640, 17280, 17280, 270, 17280, 8640, 270, 8640, 17280, 270, 8640, 17280, 17280, 8640, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 8640, 8640, 8640, 270, 8640, 270, 17280, 270, 17280, 8640, 17280, 17280, 270, 17280, 270, 17280, 8640, 270, 270, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 270, 8640, 8640, 270, 17280, 8640, 17280, 17280, 8640, 270, 8640, 8640, 8640, 270, 17280, 8640, 17280, 270, 17280, 270, 270, 8640, 17280, 17280, 8640, 270, 8640, 270, 8640, 17280, 17280, 8640, 270, 8640, 270, 17280, 270, 270, 270, 270, 17280, 8640, 8640, 17280, 8640, 8640, 270, 8640, 17280, 8640, 270, 270, 8640, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 8640, 17280, 8640, 8640, 8640, 270, 17280, 270, 17280, 8640, 270, 8640, 270, 270, 8640, 270, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 270, 270, 17280, 8640, 17280, 8640, 17280, 8640, 270, 8640, 270, 270, 270, 17280, 17280, 8640, 8640, 270, 270, 8640, 270, 17280, 270, 270, 8640, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 8640, 17280, 8640, 270, 8640, 270, 17280, 8640, 8640, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 8640, 270, 8640, 270, 8640, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 8640, 8640, 17280, 270, 17280, 270, 270, 270, 17280, 8640, 17280, 17280, 270, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 17280, 270, 270, 8640, 270, 8640, 8640, 270, 17280, 17280, 17280, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 17280, 270, 270, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2802060 . Total input tokens: 624030052 . Total output tokens: 560316778
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 3.9756207640166394,
    "estimated_duration": 3600.0238748608513,
    "input_throughput": 3017.4616551452386,
    "output_throughput": 2661.634848288433,
    "total_throughput": 5679.096503433672,
    "itl": 126.19187851285899,
    "ttft": 2393621.8629495623,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4979,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.4902501463319,
    "arrivals": 932854,
    "finished_requests": 43783,
    "scheduler_time": 77.17831017249227
}
#Debug simulation 
Total elapsed time: 3.9756832950515673. Arrivals time: 0.5321165064815432 Scheduler time: 3.1475505891721696 Scheduler overhead time: 0.04077057901304215 Adapter cache time: 0.19301683135563508 Engine time: 0.04280130675761029 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_16-16-16/adapters_320_slots_192_rate_1.6-0.8-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_16-16-16/adapters_320_slots_192_rate_1.6-0.8-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 270, 17280, 17280, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 8640, 8640, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 17280, 17280, 8640, 270, 270, 8640, 17280, 17280, 8640, 8640, 270, 270, 8640, 17280, 17280, 270, 17280, 8640, 270, 8640, 17280, 270, 8640, 17280, 17280, 8640, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 8640, 8640, 8640, 270, 8640, 270, 17280, 270, 17280, 8640, 17280, 17280, 270, 17280, 270, 17280, 8640, 270, 270, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 270, 8640, 8640, 270, 17280, 8640, 17280, 17280, 8640, 270, 8640, 8640, 8640, 270, 17280, 8640, 17280, 270, 17280, 270, 270, 8640, 17280, 17280, 8640, 270, 8640, 270, 8640, 17280, 17280, 8640, 270, 8640, 270, 17280, 270, 270, 270, 270, 17280, 8640, 8640, 17280, 8640, 8640, 270, 8640, 17280, 8640, 270, 270, 8640, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 8640, 17280, 8640, 8640, 8640, 270, 17280, 270, 17280, 8640, 270, 8640, 270, 270, 8640, 270, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 270, 270, 17280, 8640, 17280, 8640, 17280, 8640, 270, 8640, 270, 270, 270, 17280, 17280, 8640, 8640, 270, 270, 8640, 270, 17280, 270, 270, 8640, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 8640, 17280, 8640, 270, 8640, 270, 17280, 8640, 8640, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 8640, 270, 8640, 270, 8640, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 8640, 8640, 17280, 270, 17280, 270, 270, 270, 17280, 8640, 17280, 17280, 270, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 17280, 270, 270, 8640, 270, 8640, 8640, 270, 17280, 17280, 17280, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 17280, 270, 270, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2802060 . Total input tokens: 624030052 . Total output tokens: 560316778
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.121538430976216,
    "estimated_duration": 3600.2356039822857,
    "input_throughput": 3670.1492495058983,
    "output_throughput": 3220.829488818381,
    "total_throughput": 6890.978738324279,
    "itl": 261.19548908525104,
    "ttft": 2288595.016796756,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1151,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.441547889432319,
    "arrivals": 932854,
    "finished_requests": 53338,
    "scheduler_time": 65.84960291363278
}
#Debug simulation 
Total elapsed time: 5.121667044004425. Arrivals time: 0.23136653314577416 Scheduler time: 4.80162875802489 Scheduler overhead time: 0.022982715629041195 Adapter cache time: 0.03182607574854046 Engine time: 0.023328169248998165 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_16-16-32/adapters_320_slots_192_rate_1.6-0.8-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_16-16-32/adapters_320_slots_192_rate_1.6-0.8-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 270, 17280, 17280, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 8640, 8640, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 17280, 17280, 8640, 270, 270, 8640, 17280, 17280, 8640, 8640, 270, 270, 8640, 17280, 17280, 270, 17280, 8640, 270, 8640, 17280, 270, 8640, 17280, 17280, 8640, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 8640, 8640, 8640, 270, 8640, 270, 17280, 270, 17280, 8640, 17280, 17280, 270, 17280, 270, 17280, 8640, 270, 270, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 270, 8640, 8640, 270, 17280, 8640, 17280, 17280, 8640, 270, 8640, 8640, 8640, 270, 17280, 8640, 17280, 270, 17280, 270, 270, 8640, 17280, 17280, 8640, 270, 8640, 270, 8640, 17280, 17280, 8640, 270, 8640, 270, 17280, 270, 270, 270, 270, 17280, 8640, 8640, 17280, 8640, 8640, 270, 8640, 17280, 8640, 270, 270, 8640, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 8640, 17280, 8640, 8640, 8640, 270, 17280, 270, 17280, 8640, 270, 8640, 270, 270, 8640, 270, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 270, 270, 17280, 8640, 17280, 8640, 17280, 8640, 270, 8640, 270, 270, 270, 17280, 17280, 8640, 8640, 270, 270, 8640, 270, 17280, 270, 270, 8640, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 8640, 17280, 8640, 270, 8640, 270, 17280, 8640, 8640, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 8640, 270, 8640, 270, 8640, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 8640, 8640, 17280, 270, 17280, 270, 270, 270, 17280, 8640, 17280, 17280, 270, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 17280, 270, 270, 8640, 270, 8640, 8640, 270, 17280, 17280, 17280, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 17280, 270, 270, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2802060 . Total input tokens: 624030052 . Total output tokens: 560316778
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.006178853975143,
    "estimated_duration": 3600.0905652205556,
    "input_throughput": 3017.3327040550466,
    "output_throughput": 2661.4922114919054,
    "total_throughput": 5678.824915546952,
    "itl": 126.19913570983805,
    "ttft": 2393690.9962958293,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4979,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.696863617411555,
    "arrivals": 932854,
    "finished_requests": 43782,
    "scheduler_time": 77.17544536891965
}
#Debug simulation 
Total elapsed time: 4.006241273949854. Arrivals time: 0.5339551439974457 Scheduler time: 3.177094926359132 Scheduler overhead time: 0.04092529613990337 Adapter cache time: 0.19239526422461495 Engine time: 0.04237217374611646 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-8/adapters_320_slots_192_rate_1.6-0.8-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-8/adapters_320_slots_192_rate_1.6-0.8-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 135, 17280, 17280, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 8640, 8640, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 17280, 17280, 8640, 135, 135, 8640, 17280, 17280, 8640, 8640, 135, 135, 8640, 17280, 17280, 135, 17280, 8640, 135, 8640, 17280, 135, 8640, 17280, 17280, 8640, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 8640, 8640, 8640, 135, 8640, 135, 17280, 135, 17280, 8640, 17280, 17280, 135, 17280, 135, 17280, 8640, 135, 135, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 135, 8640, 8640, 135, 17280, 8640, 17280, 17280, 8640, 135, 8640, 8640, 8640, 135, 17280, 8640, 17280, 135, 17280, 135, 135, 8640, 17280, 17280, 8640, 135, 8640, 135, 8640, 17280, 17280, 8640, 135, 8640, 135, 17280, 135, 135, 135, 135, 17280, 8640, 8640, 17280, 8640, 8640, 135, 8640, 17280, 8640, 135, 135, 8640, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 8640, 17280, 8640, 8640, 8640, 135, 17280, 135, 17280, 8640, 135, 8640, 135, 135, 8640, 135, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 135, 135, 17280, 8640, 17280, 8640, 17280, 8640, 135, 8640, 135, 135, 135, 17280, 17280, 8640, 8640, 135, 135, 8640, 135, 17280, 135, 135, 8640, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 8640, 17280, 8640, 135, 8640, 135, 17280, 8640, 8640, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 8640, 135, 8640, 135, 8640, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 8640, 8640, 17280, 135, 17280, 135, 135, 135, 17280, 8640, 17280, 17280, 135, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 17280, 135, 135, 8640, 135, 8640, 8640, 135, 17280, 17280, 17280, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2787750 . Total input tokens: 620823562 . Total output tokens: 557458365
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.553795193962287,
    "estimated_duration": 3600.1695501979375,
    "input_throughput": 3666.6817537174675,
    "output_throughput": 3231.3714223154825,
    "total_throughput": 6898.05317603295,
    "itl": 264.3975283987137,
    "ttft": 2290578.172956773,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1012,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0972135968600183,
    "arrivals": 928080,
    "finished_requests": 53460,
    "scheduler_time": 65.75748600214519
}
#Debug simulation 
Total elapsed time: 4.553929059999064. Arrivals time: 0.276602384110447 Scheduler time: 4.19238404231146 Scheduler overhead time: 0.022683777729980648 Adapter cache time: 0.029046972456853837 Engine time: 0.022903337667230517 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-16/adapters_320_slots_192_rate_1.6-0.8-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-16/adapters_320_slots_192_rate_1.6-0.8-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 135, 17280, 17280, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 8640, 8640, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 17280, 17280, 8640, 135, 135, 8640, 17280, 17280, 8640, 8640, 135, 135, 8640, 17280, 17280, 135, 17280, 8640, 135, 8640, 17280, 135, 8640, 17280, 17280, 8640, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 8640, 8640, 8640, 135, 8640, 135, 17280, 135, 17280, 8640, 17280, 17280, 135, 17280, 135, 17280, 8640, 135, 135, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 135, 8640, 8640, 135, 17280, 8640, 17280, 17280, 8640, 135, 8640, 8640, 8640, 135, 17280, 8640, 17280, 135, 17280, 135, 135, 8640, 17280, 17280, 8640, 135, 8640, 135, 8640, 17280, 17280, 8640, 135, 8640, 135, 17280, 135, 135, 135, 135, 17280, 8640, 8640, 17280, 8640, 8640, 135, 8640, 17280, 8640, 135, 135, 8640, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 8640, 17280, 8640, 8640, 8640, 135, 17280, 135, 17280, 8640, 135, 8640, 135, 135, 8640, 135, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 135, 135, 17280, 8640, 17280, 8640, 17280, 8640, 135, 8640, 135, 135, 135, 17280, 17280, 8640, 8640, 135, 135, 8640, 135, 17280, 135, 135, 8640, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 8640, 17280, 8640, 135, 8640, 135, 17280, 8640, 8640, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 8640, 135, 8640, 135, 8640, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 8640, 8640, 17280, 135, 17280, 135, 135, 135, 17280, 8640, 17280, 17280, 135, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 17280, 135, 135, 8640, 135, 8640, 8640, 135, 17280, 17280, 17280, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2787750 . Total input tokens: 620823562 . Total output tokens: 557458365
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.468558181019034,
    "estimated_duration": 3600.025741971646,
    "input_throughput": 3657.0610722326587,
    "output_throughput": 3224.3705550957206,
    "total_throughput": 6881.431627328379,
    "itl": 261.5279383326829,
    "ttft": 2292472.8585104155,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1031,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.372844530136799,
    "arrivals": 928080,
    "finished_requests": 53330,
    "scheduler_time": 65.83200236402264
}
#Debug simulation 
Total elapsed time: 4.468679593002889. Arrivals time: 0.2191638692165725 Scheduler time: 4.164888977422379 Scheduler overhead time: 0.0228656860999763 Adapter cache time: 0.02807026158552617 Engine time: 0.023198796319775283 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-32/adapters_320_slots_192_rate_1.6-0.8-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-32/adapters_320_slots_192_rate_1.6-0.8-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 135, 17280, 17280, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 8640, 8640, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 17280, 17280, 8640, 135, 135, 8640, 17280, 17280, 8640, 8640, 135, 135, 8640, 17280, 17280, 135, 17280, 8640, 135, 8640, 17280, 135, 8640, 17280, 17280, 8640, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 8640, 8640, 8640, 135, 8640, 135, 17280, 135, 17280, 8640, 17280, 17280, 135, 17280, 135, 17280, 8640, 135, 135, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 135, 8640, 8640, 135, 17280, 8640, 17280, 17280, 8640, 135, 8640, 8640, 8640, 135, 17280, 8640, 17280, 135, 17280, 135, 135, 8640, 17280, 17280, 8640, 135, 8640, 135, 8640, 17280, 17280, 8640, 135, 8640, 135, 17280, 135, 135, 135, 135, 17280, 8640, 8640, 17280, 8640, 8640, 135, 8640, 17280, 8640, 135, 135, 8640, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 8640, 17280, 8640, 8640, 8640, 135, 17280, 135, 17280, 8640, 135, 8640, 135, 135, 8640, 135, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 135, 135, 17280, 8640, 17280, 8640, 17280, 8640, 135, 8640, 135, 135, 135, 17280, 17280, 8640, 8640, 135, 135, 8640, 135, 17280, 135, 135, 8640, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 8640, 17280, 8640, 135, 8640, 135, 17280, 8640, 8640, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 8640, 135, 8640, 135, 8640, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 8640, 8640, 17280, 135, 17280, 135, 135, 135, 17280, 8640, 17280, 17280, 135, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 17280, 135, 135, 8640, 135, 8640, 8640, 135, 17280, 17280, 17280, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2787750 . Total input tokens: 620823562 . Total output tokens: 557458365
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.650392854004167,
    "estimated_duration": 3600.0311824301093,
    "input_throughput": 3020.1838398134714,
    "output_throughput": 2683.0781486397645,
    "total_throughput": 5703.261988453236,
    "itl": 125.55454887370995,
    "ttft": 2396163.879552812,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4205,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.781410453132263,
    "arrivals": 928080,
    "finished_requests": 43999,
    "scheduler_time": 77.65747095923943
}
#Debug simulation 
Total elapsed time: 3.650535720982589. Arrivals time: 0.20090786716900766 Scheduler time: 3.164169957395643 Scheduler overhead time: 0.040763106604572386 Adapter cache time: 0.18307540763635188 Engine time: 0.04209072596859187 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-16/adapters_320_slots_192_rate_1.6-0.8-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-16/adapters_320_slots_192_rate_1.6-0.8-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 135, 17280, 17280, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 8640, 8640, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 17280, 17280, 8640, 135, 135, 8640, 17280, 17280, 8640, 8640, 135, 135, 8640, 17280, 17280, 135, 17280, 8640, 135, 8640, 17280, 135, 8640, 17280, 17280, 8640, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 8640, 8640, 8640, 135, 8640, 135, 17280, 135, 17280, 8640, 17280, 17280, 135, 17280, 135, 17280, 8640, 135, 135, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 135, 8640, 8640, 135, 17280, 8640, 17280, 17280, 8640, 135, 8640, 8640, 8640, 135, 17280, 8640, 17280, 135, 17280, 135, 135, 8640, 17280, 17280, 8640, 135, 8640, 135, 8640, 17280, 17280, 8640, 135, 8640, 135, 17280, 135, 135, 135, 135, 17280, 8640, 8640, 17280, 8640, 8640, 135, 8640, 17280, 8640, 135, 135, 8640, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 8640, 17280, 8640, 8640, 8640, 135, 17280, 135, 17280, 8640, 135, 8640, 135, 135, 8640, 135, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 135, 135, 17280, 8640, 17280, 8640, 17280, 8640, 135, 8640, 135, 135, 135, 17280, 17280, 8640, 8640, 135, 135, 8640, 135, 17280, 135, 135, 8640, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 8640, 17280, 8640, 135, 8640, 135, 17280, 8640, 8640, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 8640, 135, 8640, 135, 8640, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 8640, 8640, 17280, 135, 17280, 135, 135, 135, 17280, 8640, 17280, 17280, 135, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 17280, 135, 135, 8640, 135, 8640, 8640, 135, 17280, 17280, 17280, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2787750 . Total input tokens: 620823562 . Total output tokens: 557458365
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.448082955961581,
    "estimated_duration": 3600.116716563549,
    "input_throughput": 3658.401667758127,
    "output_throughput": 3224.9087777026966,
    "total_throughput": 6883.310445460824,
    "itl": 261.74670378380097,
    "ttft": 2292412.6794549664,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1030,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.223985951158651,
    "arrivals": 928080,
    "finished_requests": 53346,
    "scheduler_time": 65.82959931559033
}
#Debug simulation 
Total elapsed time: 4.4481840310036205. Arrivals time: 0.2179375893319957 Scheduler time: 4.145118704647757 Scheduler overhead time: 0.022769555856939405 Adapter cache time: 0.02876312955049798 Engine time: 0.023232461302541196 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-32/adapters_320_slots_192_rate_1.6-0.8-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-32/adapters_320_slots_192_rate_1.6-0.8-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 135, 17280, 17280, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 8640, 8640, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 17280, 17280, 8640, 135, 135, 8640, 17280, 17280, 8640, 8640, 135, 135, 8640, 17280, 17280, 135, 17280, 8640, 135, 8640, 17280, 135, 8640, 17280, 17280, 8640, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 8640, 8640, 8640, 135, 8640, 135, 17280, 135, 17280, 8640, 17280, 17280, 135, 17280, 135, 17280, 8640, 135, 135, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 135, 8640, 8640, 135, 17280, 8640, 17280, 17280, 8640, 135, 8640, 8640, 8640, 135, 17280, 8640, 17280, 135, 17280, 135, 135, 8640, 17280, 17280, 8640, 135, 8640, 135, 8640, 17280, 17280, 8640, 135, 8640, 135, 17280, 135, 135, 135, 135, 17280, 8640, 8640, 17280, 8640, 8640, 135, 8640, 17280, 8640, 135, 135, 8640, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 8640, 17280, 8640, 8640, 8640, 135, 17280, 135, 17280, 8640, 135, 8640, 135, 135, 8640, 135, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 135, 135, 17280, 8640, 17280, 8640, 17280, 8640, 135, 8640, 135, 135, 135, 17280, 17280, 8640, 8640, 135, 135, 8640, 135, 17280, 135, 135, 8640, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 8640, 17280, 8640, 135, 8640, 135, 17280, 8640, 8640, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 8640, 135, 8640, 135, 8640, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 8640, 8640, 17280, 135, 17280, 135, 135, 135, 17280, 8640, 17280, 17280, 135, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 17280, 135, 135, 8640, 135, 8640, 8640, 135, 17280, 17280, 17280, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2787750 . Total input tokens: 620823562 . Total output tokens: 557458365
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 3.630626078986097,
    "estimated_duration": 3600.080839748428,
    "input_throughput": 3019.9677407132167,
    "output_throughput": 2682.860588395824,
    "total_throughput": 5702.828329109041,
    "itl": 125.56224499156136,
    "ttft": 2396080.0880976887,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4205,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.971550178191588,
    "arrivals": 928080,
    "finished_requests": 43996,
    "scheduler_time": 77.65452711583109
}
#Debug simulation 
Total elapsed time: 3.6307482410338707. Arrivals time: 0.18521899881307036 Scheduler time: 3.158371208817698 Scheduler overhead time: 0.04076329618692398 Adapter cache time: 0.1848986481782049 Engine time: 0.04188869835343212 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-16/adapters_320_slots_192_rate_1.6-0.8-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-16/adapters_320_slots_192_rate_1.6-0.8-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 135, 17280, 17280, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 8640, 8640, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 17280, 17280, 8640, 135, 135, 8640, 17280, 17280, 8640, 8640, 135, 135, 8640, 17280, 17280, 135, 17280, 8640, 135, 8640, 17280, 135, 8640, 17280, 17280, 8640, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 8640, 8640, 8640, 135, 8640, 135, 17280, 135, 17280, 8640, 17280, 17280, 135, 17280, 135, 17280, 8640, 135, 135, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 135, 8640, 8640, 135, 17280, 8640, 17280, 17280, 8640, 135, 8640, 8640, 8640, 135, 17280, 8640, 17280, 135, 17280, 135, 135, 8640, 17280, 17280, 8640, 135, 8640, 135, 8640, 17280, 17280, 8640, 135, 8640, 135, 17280, 135, 135, 135, 135, 17280, 8640, 8640, 17280, 8640, 8640, 135, 8640, 17280, 8640, 135, 135, 8640, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 8640, 17280, 8640, 8640, 8640, 135, 17280, 135, 17280, 8640, 135, 8640, 135, 135, 8640, 135, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 135, 135, 17280, 8640, 17280, 8640, 17280, 8640, 135, 8640, 135, 135, 135, 17280, 17280, 8640, 8640, 135, 135, 8640, 135, 17280, 135, 135, 8640, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 8640, 17280, 8640, 135, 8640, 135, 17280, 8640, 8640, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 8640, 135, 8640, 135, 8640, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 8640, 8640, 17280, 135, 17280, 135, 135, 135, 17280, 8640, 17280, 17280, 135, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 17280, 135, 135, 8640, 135, 8640, 8640, 135, 17280, 17280, 17280, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2787750 . Total input tokens: 620823562 . Total output tokens: 557458365
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.522211037983652,
    "estimated_duration": 3600.2568348054783,
    "input_throughput": 3658.6223162358588,
    "output_throughput": 3225.4001680486804,
    "total_throughput": 6884.022484284539,
    "itl": 261.7397067138966,
    "ttft": 2292417.605067499,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1030,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0797518037491685,
    "arrivals": 928080,
    "finished_requests": 53351,
    "scheduler_time": 65.8346129701665
}
#Debug simulation 
Total elapsed time: 4.522319048002828. Arrivals time: 0.22686590248486027 Scheduler time: 4.210134125780314 Scheduler overhead time: 0.022905670979525894 Adapter cache time: 0.02877179317874834 Engine time: 0.0231609926559031 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-32/adapters_320_slots_192_rate_1.6-0.8-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-32/adapters_320_slots_192_rate_1.6-0.8-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 135, 17280, 17280, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 8640, 8640, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 17280, 17280, 8640, 135, 135, 8640, 17280, 17280, 8640, 8640, 135, 135, 8640, 17280, 17280, 135, 17280, 8640, 135, 8640, 17280, 135, 8640, 17280, 17280, 8640, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 8640, 8640, 8640, 135, 8640, 135, 17280, 135, 17280, 8640, 17280, 17280, 135, 17280, 135, 17280, 8640, 135, 135, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 135, 8640, 8640, 135, 17280, 8640, 17280, 17280, 8640, 135, 8640, 8640, 8640, 135, 17280, 8640, 17280, 135, 17280, 135, 135, 8640, 17280, 17280, 8640, 135, 8640, 135, 8640, 17280, 17280, 8640, 135, 8640, 135, 17280, 135, 135, 135, 135, 17280, 8640, 8640, 17280, 8640, 8640, 135, 8640, 17280, 8640, 135, 135, 8640, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 8640, 17280, 8640, 8640, 8640, 135, 17280, 135, 17280, 8640, 135, 8640, 135, 135, 8640, 135, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 135, 135, 17280, 8640, 17280, 8640, 17280, 8640, 135, 8640, 135, 135, 135, 17280, 17280, 8640, 8640, 135, 135, 8640, 135, 17280, 135, 135, 8640, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 8640, 17280, 8640, 135, 8640, 135, 17280, 8640, 8640, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 8640, 135, 8640, 135, 8640, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 8640, 8640, 17280, 135, 17280, 135, 135, 135, 17280, 8640, 17280, 17280, 135, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 17280, 135, 135, 8640, 135, 8640, 8640, 135, 17280, 17280, 17280, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2787750 . Total input tokens: 620823562 . Total output tokens: 557458365
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.7119609150104225,
    "estimated_duration": 3600.108714658027,
    "input_throughput": 3019.916858547626,
    "output_throughput": 2682.8392600131406,
    "total_throughput": 5702.7561185607665,
    "itl": 125.56993940457514,
    "ttft": 2395967.4239154025,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4203,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.141095454058618,
    "arrivals": 928080,
    "finished_requests": 43995,
    "scheduler_time": 77.65157325992874
}
#Debug simulation 
Total elapsed time: 3.712130160012748. Arrivals time: 0.25098127755336463 Scheduler time: 3.1733007464790717 Scheduler overhead time: 0.04083323694067076 Adapter cache time: 0.18561506894184276 Engine time: 0.04177437798352912 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-8/adapters_320_slots_192_rate_1.6-0.8-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-8/adapters_320_slots_192_rate_1.6-0.8-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 66, 17280, 17280, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 8640, 8640, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 17280, 8640, 66, 66, 8640, 17280, 17280, 8640, 8640, 66, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 8640, 17280, 17280, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 66, 17280, 8640, 66, 66, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 66, 8640, 8640, 66, 17280, 8640, 17280, 17280, 8640, 66, 8640, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 66, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 17280, 66, 66, 66, 66, 17280, 8640, 8640, 17280, 8640, 8640, 66, 8640, 17280, 8640, 66, 66, 8640, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 8640, 17280, 8640, 8640, 8640, 66, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 66, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 66, 66, 17280, 8640, 17280, 8640, 17280, 8640, 66, 8640, 66, 66, 66, 17280, 17280, 8640, 8640, 66, 66, 8640, 66, 17280, 66, 66, 8640, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 66, 8640, 66, 17280, 8640, 8640, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 8640, 8640, 17280, 66, 17280, 66, 66, 66, 17280, 8640, 17280, 17280, 66, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 17280, 66, 66, 8640, 66, 8640, 8640, 66, 17280, 17280, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2780436 . Total input tokens: 619158227 . Total output tokens: 555999522
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.4381209400016814,
    "estimated_duration": 3600.1180229726288,
    "input_throughput": 3678.4105175156037,
    "output_throughput": 3228.8721996957647,
    "total_throughput": 6907.282717211368,
    "itl": 264.13391394775783,
    "ttft": 2285744.079573722,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 856,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.619777508806492,
    "arrivals": 925677,
    "finished_requests": 53576,
    "scheduler_time": 65.77209246235147
}
#Debug simulation 
Total elapsed time: 4.438214552006684. Arrivals time: 0.21511485532391816 Scheduler time: 4.142542437708471 Scheduler overhead time: 0.022687248478177935 Adapter cache time: 0.02450027089798823 Engine time: 0.023043950204737484 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-16/adapters_320_slots_192_rate_1.6-0.8-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-16/adapters_320_slots_192_rate_1.6-0.8-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 66, 17280, 17280, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 8640, 8640, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 17280, 8640, 66, 66, 8640, 17280, 17280, 8640, 8640, 66, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 8640, 17280, 17280, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 66, 17280, 8640, 66, 66, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 66, 8640, 8640, 66, 17280, 8640, 17280, 17280, 8640, 66, 8640, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 66, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 17280, 66, 66, 66, 66, 17280, 8640, 8640, 17280, 8640, 8640, 66, 8640, 17280, 8640, 66, 66, 8640, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 8640, 17280, 8640, 8640, 8640, 66, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 66, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 66, 66, 17280, 8640, 17280, 8640, 17280, 8640, 66, 8640, 66, 66, 66, 17280, 17280, 8640, 8640, 66, 66, 8640, 66, 17280, 66, 66, 8640, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 66, 8640, 66, 17280, 8640, 8640, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 8640, 8640, 17280, 66, 17280, 66, 66, 66, 17280, 8640, 17280, 17280, 66, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 17280, 66, 66, 8640, 66, 8640, 8640, 66, 17280, 17280, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2780436 . Total input tokens: 619158227 . Total output tokens: 555999522
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.419235615001526,
    "estimated_duration": 3600.1780007846237,
    "input_throughput": 3668.93497963747,
    "output_throughput": 3220.8321359312954,
    "total_throughput": 6889.767115568765,
    "itl": 261.3091849699192,
    "ttft": 2286809.334324494,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 876,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.855860747711272,
    "arrivals": 925677,
    "finished_requests": 53439,
    "scheduler_time": 65.85024436188328
}
#Debug simulation 
Total elapsed time: 4.419340973021463. Arrivals time: 0.22648850036785007 Scheduler time: 4.111446777416859 Scheduler overhead time: 0.02287839778000489 Adapter cache time: 0.024932685948442668 Engine time: 0.023109736444894224 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-32/adapters_320_slots_192_rate_1.6-0.8-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-32/adapters_320_slots_192_rate_1.6-0.8-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 66, 17280, 17280, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 8640, 8640, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 17280, 8640, 66, 66, 8640, 17280, 17280, 8640, 8640, 66, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 8640, 17280, 17280, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 66, 17280, 8640, 66, 66, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 66, 8640, 8640, 66, 17280, 8640, 17280, 17280, 8640, 66, 8640, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 66, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 17280, 66, 66, 66, 66, 17280, 8640, 8640, 17280, 8640, 8640, 66, 8640, 17280, 8640, 66, 66, 8640, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 8640, 17280, 8640, 8640, 8640, 66, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 66, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 66, 66, 17280, 8640, 17280, 8640, 17280, 8640, 66, 8640, 66, 66, 66, 17280, 17280, 8640, 8640, 66, 66, 8640, 66, 17280, 66, 66, 8640, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 66, 8640, 66, 17280, 8640, 8640, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 8640, 8640, 17280, 66, 17280, 66, 66, 66, 17280, 8640, 17280, 17280, 66, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 17280, 66, 66, 8640, 66, 8640, 8640, 66, 17280, 17280, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2780436 . Total input tokens: 619158227 . Total output tokens: 555999522
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.6475992019986734,
    "estimated_duration": 3600.08935444971,
    "input_throughput": 3035.7846497592177,
    "output_throughput": 2690.8732106958387,
    "total_throughput": 5726.657860455056,
    "itl": 125.61647545223009,
    "ttft": 2388483.3708720114,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4028,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.175258117987768,
    "arrivals": 925677,
    "finished_requests": 44325,
    "scheduler_time": 77.79174504893628
}
#Debug simulation 
Total elapsed time: 3.6477191250305623. Arrivals time: 0.18724413856398314 Scheduler time: 3.1724924830487 Scheduler overhead time: 0.040922210086137056 Adapter cache time: 0.18542539706686512 Engine time: 0.04199615615652874 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-16/adapters_320_slots_192_rate_1.6-0.8-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-16/adapters_320_slots_192_rate_1.6-0.8-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 66, 17280, 17280, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 8640, 8640, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 17280, 8640, 66, 66, 8640, 17280, 17280, 8640, 8640, 66, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 8640, 17280, 17280, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 66, 17280, 8640, 66, 66, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 66, 8640, 8640, 66, 17280, 8640, 17280, 17280, 8640, 66, 8640, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 66, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 17280, 66, 66, 66, 66, 17280, 8640, 8640, 17280, 8640, 8640, 66, 8640, 17280, 8640, 66, 66, 8640, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 8640, 17280, 8640, 8640, 8640, 66, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 66, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 66, 66, 17280, 8640, 17280, 8640, 17280, 8640, 66, 8640, 66, 66, 66, 17280, 17280, 8640, 8640, 66, 66, 8640, 66, 17280, 66, 66, 8640, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 66, 8640, 66, 17280, 8640, 8640, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 8640, 8640, 17280, 66, 17280, 66, 66, 66, 17280, 8640, 17280, 17280, 66, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 17280, 66, 66, 8640, 66, 8640, 8640, 66, 17280, 17280, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2780436 . Total input tokens: 619158227 . Total output tokens: 555999522
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.368545258999802,
    "estimated_duration": 3600.0881377516557,
    "input_throughput": 3669.6787674344832,
    "output_throughput": 3221.762233644544,
    "total_throughput": 6891.441001079027,
    "itl": 261.4637982559545,
    "ttft": 2286820.1916191913,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 874,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.725667670315569,
    "arrivals": 925677,
    "finished_requests": 53453,
    "scheduler_time": 65.84594069741372
}
#Debug simulation 
Total elapsed time: 4.368640807981137. Arrivals time: 0.21794818743364885 Scheduler time: 4.069641858921386 Scheduler overhead time: 0.022721183893736452 Adapter cache time: 0.02480676188133657 Engine time: 0.02313204138772562 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-32/adapters_320_slots_192_rate_1.6-0.8-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-32/adapters_320_slots_192_rate_1.6-0.8-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 66, 17280, 17280, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 8640, 8640, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 17280, 8640, 66, 66, 8640, 17280, 17280, 8640, 8640, 66, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 8640, 17280, 17280, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 66, 17280, 8640, 66, 66, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 66, 8640, 8640, 66, 17280, 8640, 17280, 17280, 8640, 66, 8640, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 66, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 17280, 66, 66, 66, 66, 17280, 8640, 8640, 17280, 8640, 8640, 66, 8640, 17280, 8640, 66, 66, 8640, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 8640, 17280, 8640, 8640, 8640, 66, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 66, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 66, 66, 17280, 8640, 17280, 8640, 17280, 8640, 66, 8640, 66, 66, 66, 17280, 17280, 8640, 8640, 66, 66, 8640, 66, 17280, 66, 66, 8640, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 66, 8640, 66, 17280, 8640, 8640, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 8640, 8640, 17280, 66, 17280, 66, 66, 66, 17280, 8640, 17280, 17280, 66, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 17280, 66, 66, 8640, 66, 8640, 8640, 66, 17280, 17280, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2780436 . Total input tokens: 619158227 . Total output tokens: 555999522
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 3.7185551639995538,
    "estimated_duration": 3600.0043076956417,
    "input_throughput": 3035.8563673485437,
    "output_throughput": 2690.9367800731557,
    "total_throughput": 5726.793147421699,
    "itl": 125.62287660604693,
    "ttft": 2388523.4793445505,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4028,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.350684650036532,
    "arrivals": 925677,
    "finished_requests": 44325,
    "scheduler_time": 77.7859894443881
}
#Debug simulation 
Total elapsed time: 3.718656986951828. Arrivals time: 0.24561215238645673 Scheduler time: 3.1823185632238165 Scheduler overhead time: 0.04093353764619678 Adapter cache time: 0.1880668864469044 Engine time: 0.042120857746340334 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-16/adapters_320_slots_192_rate_1.6-0.8-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-16/adapters_320_slots_192_rate_1.6-0.8-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 66, 17280, 17280, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 8640, 8640, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 17280, 8640, 66, 66, 8640, 17280, 17280, 8640, 8640, 66, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 8640, 17280, 17280, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 66, 17280, 8640, 66, 66, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 66, 8640, 8640, 66, 17280, 8640, 17280, 17280, 8640, 66, 8640, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 66, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 17280, 66, 66, 66, 66, 17280, 8640, 8640, 17280, 8640, 8640, 66, 8640, 17280, 8640, 66, 66, 8640, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 8640, 17280, 8640, 8640, 8640, 66, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 66, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 66, 66, 17280, 8640, 17280, 8640, 17280, 8640, 66, 8640, 66, 66, 66, 17280, 17280, 8640, 8640, 66, 66, 8640, 66, 17280, 66, 66, 8640, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 66, 8640, 66, 17280, 8640, 8640, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 8640, 8640, 17280, 66, 17280, 66, 66, 66, 17280, 8640, 17280, 17280, 66, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 17280, 66, 66, 8640, 66, 8640, 8640, 66, 17280, 17280, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2780436 . Total input tokens: 619158227 . Total output tokens: 555999522
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.37019072601106,
    "estimated_duration": 3600.2700499435314,
    "input_throughput": 3669.9513693999806,
    "output_throughput": 3221.9197002130263,
    "total_throughput": 6891.871069613007,
    "itl": 261.4568757022338,
    "ttft": 2286823.216919426,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 874,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6133039577444457,
    "arrivals": 925677,
    "finished_requests": 53458,
    "scheduler_time": 65.85112708551372
}
#Debug simulation 
Total elapsed time: 4.370287680008914. Arrivals time: 0.21616405225358903 Scheduler time: 4.072906376968604 Scheduler overhead time: 0.02280401298776269 Adapter cache time: 0.02511538367252797 Engine time: 0.022901395859662443 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-32/adapters_320_slots_192_rate_1.6-0.8-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-32/adapters_320_slots_192_rate_1.6-0.8-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 66, 17280, 17280, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 8640, 8640, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 17280, 8640, 66, 66, 8640, 17280, 17280, 8640, 8640, 66, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 8640, 17280, 17280, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 66, 17280, 8640, 66, 66, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 66, 8640, 8640, 66, 17280, 8640, 17280, 17280, 8640, 66, 8640, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 66, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 17280, 66, 66, 66, 66, 17280, 8640, 8640, 17280, 8640, 8640, 66, 8640, 17280, 8640, 66, 66, 8640, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 8640, 17280, 8640, 8640, 8640, 66, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 66, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 66, 66, 17280, 8640, 17280, 8640, 17280, 8640, 66, 8640, 66, 66, 66, 17280, 17280, 8640, 8640, 66, 66, 8640, 66, 17280, 66, 66, 8640, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 66, 8640, 66, 17280, 8640, 8640, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 8640, 8640, 17280, 66, 17280, 66, 66, 66, 17280, 8640, 17280, 17280, 66, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 17280, 66, 66, 8640, 66, 8640, 8640, 66, 17280, 17280, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2780436 . Total input tokens: 619158227 . Total output tokens: 555999522
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.017852517019492,
    "estimated_duration": 3600.040367648377,
    "input_throughput": 3035.484017957919,
    "output_throughput": 2690.7451058188044,
    "total_throughput": 5726.229123776724,
    "itl": 125.62862751888414,
    "ttft": 2388535.4037717404,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4028,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.516805401890595,
    "arrivals": 925677,
    "finished_requests": 44322,
    "scheduler_time": 77.78317662616341
}
#Debug simulation 
Total elapsed time: 4.017959130986128. Arrivals time: 0.5351512339548208 Scheduler time: 3.1912113996222615 Scheduler overhead time: 0.04218427598243579 Adapter cache time: 0.18677288840990514 Engine time: 0.042840253037866205 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-8/adapters_320_slots_192_rate_1.6-0.8-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-8/adapters_320_slots_192_rate_1.6-0.8-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 33, 17280, 17280, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 8640, 8640, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 17280, 17280, 8640, 33, 33, 8640, 17280, 17280, 8640, 8640, 33, 33, 8640, 17280, 17280, 33, 17280, 8640, 33, 8640, 17280, 33, 8640, 17280, 17280, 8640, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 8640, 8640, 8640, 33, 8640, 33, 17280, 33, 17280, 8640, 17280, 17280, 33, 17280, 33, 17280, 8640, 33, 33, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 33, 8640, 8640, 33, 17280, 8640, 17280, 17280, 8640, 33, 8640, 8640, 8640, 33, 17280, 8640, 17280, 33, 17280, 33, 33, 8640, 17280, 17280, 8640, 33, 8640, 33, 8640, 17280, 17280, 8640, 33, 8640, 33, 17280, 33, 33, 33, 33, 17280, 8640, 8640, 17280, 8640, 8640, 33, 8640, 17280, 8640, 33, 33, 8640, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 8640, 17280, 8640, 8640, 8640, 33, 17280, 33, 17280, 8640, 33, 8640, 33, 33, 8640, 33, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 33, 33, 17280, 8640, 17280, 8640, 17280, 8640, 33, 8640, 33, 33, 33, 17280, 17280, 8640, 8640, 33, 33, 8640, 33, 17280, 33, 33, 8640, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 8640, 17280, 8640, 33, 8640, 33, 17280, 8640, 8640, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 8640, 33, 8640, 33, 8640, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 8640, 8640, 17280, 33, 17280, 33, 33, 33, 17280, 8640, 17280, 17280, 33, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 17280, 33, 33, 8640, 33, 8640, 8640, 33, 17280, 17280, 17280, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2776938 . Total input tokens: 618377608 . Total output tokens: 555301754
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.819940196990501,
    "estimated_duration": 3600.0697880788284,
    "input_throughput": 3669.375811475449,
    "output_throughput": 3230.715704043826,
    "total_throughput": 6900.091515519275,
    "itl": 264.5926789312524,
    "ttft": 2291145.8432174274,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 787,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4086038544751247,
    "arrivals": 924451,
    "finished_requests": 53273,
    "scheduler_time": 65.76956834065815
}
#Debug simulation 
Total elapsed time: 4.820007592032198. Arrivals time: 0.5616904530324973 Scheduler time: 4.179319977702107 Scheduler overhead time: 0.02263109339401126 Adapter cache time: 0.02329494891455397 Engine time: 0.022788627597037703 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-16/adapters_320_slots_192_rate_1.6-0.8-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-16/adapters_320_slots_192_rate_1.6-0.8-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 33, 17280, 17280, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 8640, 8640, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 17280, 17280, 8640, 33, 33, 8640, 17280, 17280, 8640, 8640, 33, 33, 8640, 17280, 17280, 33, 17280, 8640, 33, 8640, 17280, 33, 8640, 17280, 17280, 8640, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 8640, 8640, 8640, 33, 8640, 33, 17280, 33, 17280, 8640, 17280, 17280, 33, 17280, 33, 17280, 8640, 33, 33, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 33, 8640, 8640, 33, 17280, 8640, 17280, 17280, 8640, 33, 8640, 8640, 8640, 33, 17280, 8640, 17280, 33, 17280, 33, 33, 8640, 17280, 17280, 8640, 33, 8640, 33, 8640, 17280, 17280, 8640, 33, 8640, 33, 17280, 33, 33, 33, 33, 17280, 8640, 8640, 17280, 8640, 8640, 33, 8640, 17280, 8640, 33, 33, 8640, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 8640, 17280, 8640, 8640, 8640, 33, 17280, 33, 17280, 8640, 33, 8640, 33, 33, 8640, 33, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 33, 33, 17280, 8640, 17280, 8640, 17280, 8640, 33, 8640, 33, 33, 33, 17280, 17280, 8640, 8640, 33, 33, 8640, 33, 17280, 33, 33, 8640, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 8640, 17280, 8640, 33, 8640, 33, 17280, 8640, 8640, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 8640, 33, 8640, 33, 8640, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 8640, 8640, 17280, 33, 17280, 33, 33, 33, 17280, 8640, 17280, 17280, 33, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 17280, 33, 33, 8640, 33, 8640, 8640, 33, 17280, 17280, 17280, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2776938 . Total input tokens: 618377608 . Total output tokens: 555301754
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.712069472006988,
    "estimated_duration": 3600.198365611082,
    "input_throughput": 3658.739231099065,
    "output_throughput": 3222.313278849262,
    "total_throughput": 6881.052509948327,
    "itl": 261.73554685291634,
    "ttft": 2292624.773313013,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 809,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6400007558520935,
    "arrivals": 924451,
    "finished_requests": 53126,
    "scheduler_time": 65.85048270493797
}
#Debug simulation 
Total elapsed time: 4.712133272958454. Arrivals time: 0.5578393843024969 Scheduler time: 4.074798668734729 Scheduler overhead time: 0.02269256761064753 Adapter cache time: 0.02360611892072484 Engine time: 0.022843827377073467 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-32/adapters_320_slots_192_rate_1.6-0.8-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-32/adapters_320_slots_192_rate_1.6-0.8-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 33, 17280, 17280, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 8640, 8640, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 17280, 17280, 8640, 33, 33, 8640, 17280, 17280, 8640, 8640, 33, 33, 8640, 17280, 17280, 33, 17280, 8640, 33, 8640, 17280, 33, 8640, 17280, 17280, 8640, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 8640, 8640, 8640, 33, 8640, 33, 17280, 33, 17280, 8640, 17280, 17280, 33, 17280, 33, 17280, 8640, 33, 33, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 33, 8640, 8640, 33, 17280, 8640, 17280, 17280, 8640, 33, 8640, 8640, 8640, 33, 17280, 8640, 17280, 33, 17280, 33, 33, 8640, 17280, 17280, 8640, 33, 8640, 33, 8640, 17280, 17280, 8640, 33, 8640, 33, 17280, 33, 33, 33, 33, 17280, 8640, 8640, 17280, 8640, 8640, 33, 8640, 17280, 8640, 33, 33, 8640, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 8640, 17280, 8640, 8640, 8640, 33, 17280, 33, 17280, 8640, 33, 8640, 33, 33, 8640, 33, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 33, 33, 17280, 8640, 17280, 8640, 17280, 8640, 33, 8640, 33, 33, 33, 17280, 17280, 8640, 8640, 33, 33, 8640, 33, 17280, 33, 33, 8640, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 8640, 17280, 8640, 33, 8640, 33, 17280, 8640, 8640, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 8640, 33, 8640, 33, 8640, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 8640, 8640, 17280, 33, 17280, 33, 33, 33, 17280, 8640, 17280, 17280, 33, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 17280, 33, 33, 8640, 33, 8640, 8640, 33, 17280, 17280, 17280, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2776938 . Total input tokens: 618377608 . Total output tokens: 555301754
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.110270332021173,
    "estimated_duration": 3600.114597932921,
    "input_throughput": 3038.577718131801,
    "output_throughput": 2692.9598312138623,
    "total_throughput": 5731.537549345663,
    "itl": 124.95753712703423,
    "ttft": 2397375.991847525,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3856,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.606581711731023,
    "arrivals": 924451,
    "finished_requests": 44140,
    "scheduler_time": 78.00731873936941
}
#Debug simulation 
Total elapsed time: 4.110335437988397. Arrivals time: 0.5338295960100368 Scheduler time: 3.285301643598359 Scheduler overhead time: 0.04210677125956863 Adapter cache time: 0.1869510353426449 Engine time: 0.042485248181037605 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-16/adapters_320_slots_192_rate_1.6-0.8-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-16/adapters_320_slots_192_rate_1.6-0.8-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 33, 17280, 17280, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 8640, 8640, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 17280, 17280, 8640, 33, 33, 8640, 17280, 17280, 8640, 8640, 33, 33, 8640, 17280, 17280, 33, 17280, 8640, 33, 8640, 17280, 33, 8640, 17280, 17280, 8640, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 8640, 8640, 8640, 33, 8640, 33, 17280, 33, 17280, 8640, 17280, 17280, 33, 17280, 33, 17280, 8640, 33, 33, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 33, 8640, 8640, 33, 17280, 8640, 17280, 17280, 8640, 33, 8640, 8640, 8640, 33, 17280, 8640, 17280, 33, 17280, 33, 33, 8640, 17280, 17280, 8640, 33, 8640, 33, 8640, 17280, 17280, 8640, 33, 8640, 33, 17280, 33, 33, 33, 33, 17280, 8640, 8640, 17280, 8640, 8640, 33, 8640, 17280, 8640, 33, 33, 8640, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 8640, 17280, 8640, 8640, 8640, 33, 17280, 33, 17280, 8640, 33, 8640, 33, 33, 8640, 33, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 33, 33, 17280, 8640, 17280, 8640, 17280, 8640, 33, 8640, 33, 33, 33, 17280, 17280, 8640, 8640, 33, 33, 8640, 33, 17280, 33, 33, 8640, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 8640, 17280, 8640, 33, 8640, 33, 17280, 8640, 8640, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 8640, 33, 8640, 33, 8640, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 8640, 8640, 17280, 33, 17280, 33, 33, 33, 17280, 8640, 17280, 17280, 33, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 17280, 33, 33, 8640, 33, 8640, 8640, 33, 17280, 17280, 17280, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2776938 . Total input tokens: 618377608 . Total output tokens: 555301754
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.6959760949830525,
    "estimated_duration": 3600.081292106748,
    "input_throughput": 3658.858212141012,
    "output_throughput": 3222.4180674573536,
    "total_throughput": 6881.276279598365,
    "itl": 261.7284019164519,
    "ttft": 2292577.972669944,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 809,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.523142494778124,
    "arrivals": 924451,
    "finished_requests": 53126,
    "scheduler_time": 65.85026746165109
}
#Debug simulation 
Total elapsed time: 4.696061561990064. Arrivals time: 0.5495950591866858 Scheduler time: 4.066656400915235 Scheduler overhead time: 0.022837822616565973 Adapter cache time: 0.02364468644373119 Engine time: 0.0229595277342014 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-32/adapters_320_slots_192_rate_1.6-0.8-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-32/adapters_320_slots_192_rate_1.6-0.8-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 33, 17280, 17280, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 8640, 8640, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 17280, 17280, 8640, 33, 33, 8640, 17280, 17280, 8640, 8640, 33, 33, 8640, 17280, 17280, 33, 17280, 8640, 33, 8640, 17280, 33, 8640, 17280, 17280, 8640, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 8640, 8640, 8640, 33, 8640, 33, 17280, 33, 17280, 8640, 17280, 17280, 33, 17280, 33, 17280, 8640, 33, 33, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 33, 8640, 8640, 33, 17280, 8640, 17280, 17280, 8640, 33, 8640, 8640, 8640, 33, 17280, 8640, 17280, 33, 17280, 33, 33, 8640, 17280, 17280, 8640, 33, 8640, 33, 8640, 17280, 17280, 8640, 33, 8640, 33, 17280, 33, 33, 33, 33, 17280, 8640, 8640, 17280, 8640, 8640, 33, 8640, 17280, 8640, 33, 33, 8640, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 8640, 17280, 8640, 8640, 8640, 33, 17280, 33, 17280, 8640, 33, 8640, 33, 33, 8640, 33, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 33, 33, 17280, 8640, 17280, 8640, 17280, 8640, 33, 8640, 33, 33, 33, 17280, 17280, 8640, 8640, 33, 33, 8640, 33, 17280, 33, 33, 8640, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 8640, 17280, 8640, 33, 8640, 33, 17280, 8640, 8640, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 8640, 33, 8640, 33, 8640, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 8640, 8640, 17280, 33, 17280, 33, 33, 33, 17280, 8640, 17280, 17280, 33, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 17280, 33, 33, 8640, 33, 8640, 8640, 33, 17280, 17280, 17280, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2776938 . Total input tokens: 618377608 . Total output tokens: 555301754
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 3.9717026129947044,
    "estimated_duration": 3600.001767937023,
    "input_throughput": 3038.4796189331632,
    "output_throughput": 2692.9603441710296,
    "total_throughput": 5731.439963104192,
    "itl": 124.96438025129667,
    "ttft": 2397353.861612346,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3856,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.777355353682399,
    "arrivals": 924451,
    "finished_requests": 44137,
    "scheduler_time": 78.00130791405275
}
#Debug simulation 
Total elapsed time: 3.9717654660344124. Arrivals time: 0.5139539364608936 Scheduler time: 3.170093431894202 Scheduler overhead time: 0.041200304171070457 Adapter cache time: 0.18512085900874808 Engine time: 0.041867738764267415 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-16/adapters_320_slots_192_rate_1.6-0.8-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-16/adapters_320_slots_192_rate_1.6-0.8-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 33, 17280, 17280, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 8640, 8640, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 17280, 17280, 8640, 33, 33, 8640, 17280, 17280, 8640, 8640, 33, 33, 8640, 17280, 17280, 33, 17280, 8640, 33, 8640, 17280, 33, 8640, 17280, 17280, 8640, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 8640, 8640, 8640, 33, 8640, 33, 17280, 33, 17280, 8640, 17280, 17280, 33, 17280, 33, 17280, 8640, 33, 33, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 33, 8640, 8640, 33, 17280, 8640, 17280, 17280, 8640, 33, 8640, 8640, 8640, 33, 17280, 8640, 17280, 33, 17280, 33, 33, 8640, 17280, 17280, 8640, 33, 8640, 33, 8640, 17280, 17280, 8640, 33, 8640, 33, 17280, 33, 33, 33, 33, 17280, 8640, 8640, 17280, 8640, 8640, 33, 8640, 17280, 8640, 33, 33, 8640, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 8640, 17280, 8640, 8640, 8640, 33, 17280, 33, 17280, 8640, 33, 8640, 33, 33, 8640, 33, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 33, 33, 17280, 8640, 17280, 8640, 17280, 8640, 33, 8640, 33, 33, 33, 17280, 17280, 8640, 8640, 33, 33, 8640, 33, 17280, 33, 33, 8640, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 8640, 17280, 8640, 33, 8640, 33, 17280, 8640, 8640, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 8640, 33, 8640, 33, 8640, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 8640, 8640, 17280, 33, 17280, 33, 33, 33, 17280, 8640, 17280, 17280, 33, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 17280, 33, 33, 8640, 33, 8640, 8640, 33, 17280, 17280, 17280, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2776938 . Total input tokens: 618377608 . Total output tokens: 555301754
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.714612622978166,
    "estimated_duration": 3600.2669223766898,
    "input_throughput": 3658.736222619938,
    "output_throughput": 3222.519399295281,
    "total_throughput": 6881.255621915219,
    "itl": 261.72351570036307,
    "ttft": 2292571.994290938,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 809,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.418950688575811,
    "arrivals": 924451,
    "finished_requests": 53129,
    "scheduler_time": 65.85538787316895
}
#Debug simulation 
Total elapsed time: 4.71468468697276. Arrivals time: 0.5654661824228242 Scheduler time: 4.070119941316079 Scheduler overhead time: 0.022665764612611383 Adapter cache time: 0.02318426239071414 Engine time: 0.02290051558520645 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-32/adapters_320_slots_192_rate_1.6-0.8-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-32/adapters_320_slots_192_rate_1.6-0.8-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 33, 17280, 17280, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 8640, 8640, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 17280, 17280, 8640, 33, 33, 8640, 17280, 17280, 8640, 8640, 33, 33, 8640, 17280, 17280, 33, 17280, 8640, 33, 8640, 17280, 33, 8640, 17280, 17280, 8640, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 8640, 8640, 8640, 33, 8640, 33, 17280, 33, 17280, 8640, 17280, 17280, 33, 17280, 33, 17280, 8640, 33, 33, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 33, 8640, 8640, 33, 17280, 8640, 17280, 17280, 8640, 33, 8640, 8640, 8640, 33, 17280, 8640, 17280, 33, 17280, 33, 33, 8640, 17280, 17280, 8640, 33, 8640, 33, 8640, 17280, 17280, 8640, 33, 8640, 33, 17280, 33, 33, 33, 33, 17280, 8640, 8640, 17280, 8640, 8640, 33, 8640, 17280, 8640, 33, 33, 8640, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 8640, 17280, 8640, 8640, 8640, 33, 17280, 33, 17280, 8640, 33, 8640, 33, 33, 8640, 33, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 33, 33, 17280, 8640, 17280, 8640, 17280, 8640, 33, 8640, 33, 33, 33, 17280, 17280, 8640, 8640, 33, 33, 8640, 33, 17280, 33, 33, 8640, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 8640, 17280, 8640, 33, 8640, 33, 17280, 8640, 8640, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 8640, 33, 8640, 33, 8640, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 8640, 8640, 17280, 33, 17280, 33, 33, 33, 17280, 8640, 17280, 17280, 33, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 17280, 33, 33, 8640, 33, 8640, 8640, 33, 17280, 17280, 17280, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2776938 . Total input tokens: 618377608 . Total output tokens: 555301754
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.9709939070162363,
    "estimated_duration": 3600.0132517736974,
    "input_throughput": 3038.469926356708,
    "output_throughput": 2692.951753781328,
    "total_throughput": 5731.421680138036,
    "itl": 124.9700656963581,
    "ttft": 2397455.806522485,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3856,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.931277988254203,
    "arrivals": 924451,
    "finished_requests": 44137,
    "scheduler_time": 77.9983527318228
}
#Debug simulation 
Total elapsed time: 3.971055033034645. Arrivals time: 0.18843233480583876 Scheduler time: 3.4968011513119563 Scheduler overhead time: 0.040604629437439144 Adapter cache time: 0.1840071459300816 Engine time: 0.041711053636390716 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-8/adapters_320_slots_192_rate_1.6-0.4-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-8/adapters_320_slots_192_rate_1.6-0.4-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 1080, 17280, 17280, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 17280, 17280, 4320, 1080, 1080, 4320, 17280, 17280, 4320, 4320, 1080, 1080, 4320, 17280, 17280, 1080, 17280, 4320, 1080, 4320, 17280, 1080, 4320, 17280, 17280, 4320, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 1080, 17280, 4320, 1080, 1080, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 1080, 4320, 4320, 1080, 17280, 4320, 17280, 17280, 4320, 1080, 4320, 4320, 4320, 1080, 17280, 4320, 17280, 1080, 17280, 1080, 1080, 4320, 17280, 17280, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 4320, 4320, 17280, 4320, 4320, 1080, 4320, 17280, 4320, 1080, 1080, 4320, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 4320, 17280, 4320, 4320, 4320, 1080, 17280, 1080, 17280, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 4320, 1080, 4320, 1080, 1080, 1080, 17280, 17280, 4320, 4320, 1080, 1080, 4320, 1080, 17280, 1080, 1080, 4320, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 4320, 1080, 4320, 1080, 17280, 4320, 4320, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 4320, 4320, 17280, 1080, 17280, 1080, 1080, 1080, 17280, 4320, 17280, 17280, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 17280, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 17280, 17280, 17280, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 2425680 . Total input tokens: 540332341 . Total output tokens: 485051984
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.912830736022443,
    "estimated_duration": 3600.129081818052,
    "input_throughput": 3664.5316598863983,
    "output_throughput": 3226.90457369193,
    "total_throughput": 6891.436233578328,
    "itl": 264.72054062991504,
    "ttft": 2277118.8356700665,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1802,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.514998914566978,
    "arrivals": 807771,
    "finished_requests": 53288,
    "scheduler_time": 65.66386066381274
}
#Debug simulation 
Total elapsed time: 4.912940755020827. Arrivals time: 0.21508641680702567 Scheduler time: 4.596666991710663 Scheduler overhead time: 0.022876459115650505 Adapter cache time: 0.04534025926841423 Engine time: 0.022663526178803295 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-16/adapters_320_slots_192_rate_1.6-0.4-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-16/adapters_320_slots_192_rate_1.6-0.4-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 1080, 17280, 17280, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 17280, 17280, 4320, 1080, 1080, 4320, 17280, 17280, 4320, 4320, 1080, 1080, 4320, 17280, 17280, 1080, 17280, 4320, 1080, 4320, 17280, 1080, 4320, 17280, 17280, 4320, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 1080, 17280, 4320, 1080, 1080, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 1080, 4320, 4320, 1080, 17280, 4320, 17280, 17280, 4320, 1080, 4320, 4320, 4320, 1080, 17280, 4320, 17280, 1080, 17280, 1080, 1080, 4320, 17280, 17280, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 4320, 4320, 17280, 4320, 4320, 1080, 4320, 17280, 4320, 1080, 1080, 4320, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 4320, 17280, 4320, 4320, 4320, 1080, 17280, 1080, 17280, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 4320, 1080, 4320, 1080, 1080, 1080, 17280, 17280, 4320, 4320, 1080, 1080, 4320, 1080, 17280, 1080, 1080, 4320, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 4320, 1080, 4320, 1080, 17280, 4320, 4320, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 4320, 4320, 17280, 1080, 17280, 1080, 1080, 1080, 17280, 4320, 17280, 17280, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 17280, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 17280, 17280, 17280, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 2425680 . Total input tokens: 540332341 . Total output tokens: 485051984
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.842327954014763,
    "estimated_duration": 3600.116815943809,
    "input_throughput": 3656.487462212799,
    "output_throughput": 3219.364424140647,
    "total_throughput": 6875.851886353446,
    "itl": 261.4289726636343,
    "ttft": 2278909.1866008295,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1837,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.995703228735188,
    "arrivals": 807771,
    "finished_requests": 53146,
    "scheduler_time": 65.74854303951419
}
#Debug simulation 
Total elapsed time: 4.8424168360070325. Arrivals time: 0.24730143800843507 Scheduler time: 4.495693316566758 Scheduler overhead time: 0.02259515633340925 Adapter cache time: 0.044328185147605836 Engine time: 0.0222309137461707 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-32/adapters_320_slots_192_rate_1.6-0.4-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-32/adapters_320_slots_192_rate_1.6-0.4-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 1080, 17280, 17280, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 17280, 17280, 4320, 1080, 1080, 4320, 17280, 17280, 4320, 4320, 1080, 1080, 4320, 17280, 17280, 1080, 17280, 4320, 1080, 4320, 17280, 1080, 4320, 17280, 17280, 4320, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 1080, 17280, 4320, 1080, 1080, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 1080, 4320, 4320, 1080, 17280, 4320, 17280, 17280, 4320, 1080, 4320, 4320, 4320, 1080, 17280, 4320, 17280, 1080, 17280, 1080, 1080, 4320, 17280, 17280, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 4320, 4320, 17280, 4320, 4320, 1080, 4320, 17280, 4320, 1080, 1080, 4320, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 4320, 17280, 4320, 4320, 4320, 1080, 17280, 1080, 17280, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 4320, 1080, 4320, 1080, 1080, 1080, 17280, 17280, 4320, 4320, 1080, 1080, 4320, 1080, 17280, 1080, 1080, 4320, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 4320, 1080, 4320, 1080, 17280, 4320, 4320, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 4320, 4320, 17280, 1080, 17280, 1080, 1080, 1080, 17280, 4320, 17280, 17280, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 17280, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 17280, 17280, 17280, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 2425680 . Total input tokens: 540332341 . Total output tokens: 485051984
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.6519726699916646,
    "estimated_duration": 3600.1055181318975,
    "input_throughput": 3060.976114310732,
    "output_throughput": 2710.2136175894525,
    "total_throughput": 5771.189731900185,
    "itl": 123.77306978361456,
    "ttft": 2376015.742624007,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6109,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.971187157276365,
    "arrivals": 807771,
    "finished_requests": 44518,
    "scheduler_time": 78.52130115140457
}
#Debug simulation 
Total elapsed time: 3.652064209978562. Arrivals time: 0.1738098282366991 Scheduler time: 3.1811862299218774 Scheduler overhead time: 0.04096813243813813 Adapter cache time: 0.19467130937846377 Engine time: 0.04174909653374925 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-16-16/adapters_320_slots_192_rate_1.6-0.4-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-16-16/adapters_320_slots_192_rate_1.6-0.4-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 1080, 17280, 17280, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 17280, 17280, 4320, 1080, 1080, 4320, 17280, 17280, 4320, 4320, 1080, 1080, 4320, 17280, 17280, 1080, 17280, 4320, 1080, 4320, 17280, 1080, 4320, 17280, 17280, 4320, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 1080, 17280, 4320, 1080, 1080, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 1080, 4320, 4320, 1080, 17280, 4320, 17280, 17280, 4320, 1080, 4320, 4320, 4320, 1080, 17280, 4320, 17280, 1080, 17280, 1080, 1080, 4320, 17280, 17280, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 4320, 4320, 17280, 4320, 4320, 1080, 4320, 17280, 4320, 1080, 1080, 4320, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 4320, 17280, 4320, 4320, 4320, 1080, 17280, 1080, 17280, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 4320, 1080, 4320, 1080, 1080, 1080, 17280, 17280, 4320, 4320, 1080, 1080, 4320, 1080, 17280, 1080, 1080, 4320, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 4320, 1080, 4320, 1080, 17280, 4320, 4320, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 4320, 4320, 17280, 1080, 17280, 1080, 1080, 1080, 17280, 4320, 17280, 17280, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 17280, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 17280, 17280, 17280, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 2425680 . Total input tokens: 540332341 . Total output tokens: 485051984
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.804724881018046,
    "estimated_duration": 3600.1539988901022,
    "input_throughput": 3656.679409841507,
    "output_throughput": 3219.4283921113474,
    "total_throughput": 6876.107801952854,
    "itl": 261.406198963574,
    "ttft": 2278917.178772301,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1837,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.739105368754669,
    "arrivals": 807771,
    "finished_requests": 53151,
    "scheduler_time": 65.75372186848065
}
#Debug simulation 
Total elapsed time: 4.804817188996822. Arrivals time: 0.19810905522899702 Scheduler time: 4.50652125175111 Scheduler overhead time: 0.02303356019547209 Adapter cache time: 0.044162857986520976 Engine time: 0.02263559674611315 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-16-32/adapters_320_slots_192_rate_1.6-0.4-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-16-32/adapters_320_slots_192_rate_1.6-0.4-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 1080, 17280, 17280, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 17280, 17280, 4320, 1080, 1080, 4320, 17280, 17280, 4320, 4320, 1080, 1080, 4320, 17280, 17280, 1080, 17280, 4320, 1080, 4320, 17280, 1080, 4320, 17280, 17280, 4320, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 1080, 17280, 4320, 1080, 1080, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 1080, 4320, 4320, 1080, 17280, 4320, 17280, 17280, 4320, 1080, 4320, 4320, 4320, 1080, 17280, 4320, 17280, 1080, 17280, 1080, 1080, 4320, 17280, 17280, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 4320, 4320, 17280, 4320, 4320, 1080, 4320, 17280, 4320, 1080, 1080, 4320, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 4320, 17280, 4320, 4320, 4320, 1080, 17280, 1080, 17280, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 4320, 1080, 4320, 1080, 1080, 1080, 17280, 17280, 4320, 4320, 1080, 1080, 4320, 1080, 17280, 1080, 1080, 4320, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 4320, 1080, 4320, 1080, 17280, 4320, 4320, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 4320, 4320, 17280, 1080, 17280, 1080, 1080, 1080, 17280, 4320, 17280, 17280, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 17280, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 17280, 17280, 17280, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 2425680 . Total input tokens: 540332341 . Total output tokens: 485051984
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 3.6798988099908456,
    "estimated_duration": 3600.1142384909467,
    "input_throughput": 3060.6839866889154,
    "output_throughput": 2709.667347692009,
    "total_throughput": 5770.3513343809245,
    "itl": 123.78147680664632,
    "ttft": 2376096.0120910103,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6108,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.233987142908227,
    "arrivals": 807771,
    "finished_requests": 44514,
    "scheduler_time": 78.5154997283679
}
#Debug simulation 
Total elapsed time: 3.6799866360379383. Arrivals time: 0.1774510177783668 Scheduler time: 3.2061480836127885 Scheduler overhead time: 0.040940341947134584 Adapter cache time: 0.19390654156450182 Engine time: 0.04193047882290557 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_16-16-16/adapters_320_slots_192_rate_1.6-0.4-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_16-16-16/adapters_320_slots_192_rate_1.6-0.4-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 1080, 17280, 17280, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 17280, 17280, 4320, 1080, 1080, 4320, 17280, 17280, 4320, 4320, 1080, 1080, 4320, 17280, 17280, 1080, 17280, 4320, 1080, 4320, 17280, 1080, 4320, 17280, 17280, 4320, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 1080, 17280, 4320, 1080, 1080, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 1080, 4320, 4320, 1080, 17280, 4320, 17280, 17280, 4320, 1080, 4320, 4320, 4320, 1080, 17280, 4320, 17280, 1080, 17280, 1080, 1080, 4320, 17280, 17280, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 4320, 4320, 17280, 4320, 4320, 1080, 4320, 17280, 4320, 1080, 1080, 4320, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 4320, 17280, 4320, 4320, 4320, 1080, 17280, 1080, 17280, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 4320, 1080, 4320, 1080, 1080, 1080, 17280, 17280, 4320, 4320, 1080, 1080, 4320, 1080, 17280, 1080, 1080, 4320, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 4320, 1080, 4320, 1080, 17280, 4320, 4320, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 4320, 4320, 17280, 1080, 17280, 1080, 1080, 1080, 17280, 4320, 17280, 17280, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 17280, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 17280, 17280, 17280, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 2425680 . Total input tokens: 540332341 . Total output tokens: 485051984
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.810474046971649,
    "estimated_duration": 3600.2004073078765,
    "input_throughput": 3656.992808865625,
    "output_throughput": 3219.975748146913,
    "total_throughput": 6876.968557012538,
    "itl": 261.39354228396104,
    "ttft": 2278863.136287925,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1837,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.492722391735138,
    "arrivals": 807771,
    "finished_requests": 53158,
    "scheduler_time": 65.75886349784469
}
#Debug simulation 
Total elapsed time: 4.810572116984986. Arrivals time: 0.1978156331460923 Scheduler time: 4.513831891003065 Scheduler overhead time: 0.02270944108022377 Adapter cache time: 0.04338180914055556 Engine time: 0.022431292047258466 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_16-16-32/adapters_320_slots_192_rate_1.6-0.4-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_16-16-32/adapters_320_slots_192_rate_1.6-0.4-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 1080, 17280, 17280, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 17280, 17280, 4320, 1080, 1080, 4320, 17280, 17280, 4320, 4320, 1080, 1080, 4320, 17280, 17280, 1080, 17280, 4320, 1080, 4320, 17280, 1080, 4320, 17280, 17280, 4320, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 1080, 17280, 4320, 1080, 1080, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 1080, 4320, 4320, 1080, 17280, 4320, 17280, 17280, 4320, 1080, 4320, 4320, 4320, 1080, 17280, 4320, 17280, 1080, 17280, 1080, 1080, 4320, 17280, 17280, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 4320, 4320, 17280, 4320, 4320, 1080, 4320, 17280, 4320, 1080, 1080, 4320, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 4320, 17280, 4320, 4320, 4320, 1080, 17280, 1080, 17280, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 4320, 1080, 4320, 1080, 1080, 1080, 17280, 17280, 4320, 4320, 1080, 1080, 4320, 1080, 17280, 1080, 1080, 4320, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 4320, 1080, 4320, 1080, 17280, 4320, 4320, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 4320, 4320, 17280, 1080, 17280, 1080, 1080, 1080, 17280, 4320, 17280, 17280, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 17280, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 17280, 17280, 17280, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 2425680 . Total input tokens: 540332341 . Total output tokens: 485051984
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.709951839991845,
    "estimated_duration": 3600.108752581257,
    "input_throughput": 3060.368382510779,
    "output_throughput": 2709.4898155524083,
    "total_throughput": 5769.858198063187,
    "itl": 123.79264450733211,
    "ttft": 2376115.809396487,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6108,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.48209936350428,
    "arrivals": 807771,
    "finished_requests": 44510,
    "scheduler_time": 78.50970294705338
}
#Debug simulation 
Total elapsed time: 3.7100753519916907. Arrivals time: 0.22270550770917907 Scheduler time: 3.1897660386166535 Scheduler overhead time: 0.041095654654782265 Adapter cache time: 0.19522679125657305 Engine time: 0.04168515023775399 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-8/adapters_320_slots_192_rate_1.6-0.4-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-8/adapters_320_slots_192_rate_1.6-0.4-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 540, 17280, 17280, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 17280, 17280, 4320, 540, 540, 4320, 17280, 17280, 4320, 4320, 540, 540, 4320, 17280, 17280, 540, 17280, 4320, 540, 4320, 17280, 540, 4320, 17280, 17280, 4320, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 17280, 540, 17280, 4320, 17280, 17280, 540, 17280, 540, 17280, 4320, 540, 540, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 540, 4320, 4320, 540, 17280, 4320, 17280, 17280, 4320, 540, 4320, 4320, 4320, 540, 17280, 4320, 17280, 540, 17280, 540, 540, 4320, 17280, 17280, 4320, 540, 4320, 540, 4320, 17280, 17280, 4320, 540, 4320, 540, 17280, 540, 540, 540, 540, 17280, 4320, 4320, 17280, 4320, 4320, 540, 4320, 17280, 4320, 540, 540, 4320, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 4320, 17280, 4320, 4320, 4320, 540, 17280, 540, 17280, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 540, 540, 17280, 4320, 17280, 4320, 17280, 4320, 540, 4320, 540, 540, 540, 17280, 17280, 4320, 4320, 540, 540, 4320, 540, 17280, 540, 540, 4320, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 4320, 17280, 4320, 540, 4320, 540, 17280, 4320, 4320, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 4320, 540, 4320, 540, 4320, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 4320, 4320, 17280, 540, 17280, 540, 540, 540, 17280, 4320, 17280, 17280, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 17280, 540, 540, 4320, 540, 4320, 4320, 540, 17280, 17280, 17280, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2368440 . Total input tokens: 527524345 . Total output tokens: 473668431
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.421974262979347,
    "estimated_duration": 3600.2235150771976,
    "input_throughput": 3714.6651989781353,
    "output_throughput": 3226.0774786231445,
    "total_throughput": 6940.74267760128,
    "itl": 262.62839458822356,
    "ttft": 2274722.295706928,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1884,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.7659589095694725,
    "arrivals": 788657,
    "finished_requests": 53911,
    "scheduler_time": 65.6975338291942
}
#Debug simulation 
Total elapsed time: 4.422072582994588. Arrivals time: 0.24391657579690218 Scheduler time: 4.07827011536574 Scheduler overhead time: 0.02241832099389285 Adapter cache time: 0.045095376088283956 Engine time: 0.022132030106149614 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-16/adapters_320_slots_192_rate_1.6-0.4-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-16/adapters_320_slots_192_rate_1.6-0.4-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 540, 17280, 17280, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 17280, 17280, 4320, 540, 540, 4320, 17280, 17280, 4320, 4320, 540, 540, 4320, 17280, 17280, 540, 17280, 4320, 540, 4320, 17280, 540, 4320, 17280, 17280, 4320, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 17280, 540, 17280, 4320, 17280, 17280, 540, 17280, 540, 17280, 4320, 540, 540, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 540, 4320, 4320, 540, 17280, 4320, 17280, 17280, 4320, 540, 4320, 4320, 4320, 540, 17280, 4320, 17280, 540, 17280, 540, 540, 4320, 17280, 17280, 4320, 540, 4320, 540, 4320, 17280, 17280, 4320, 540, 4320, 540, 17280, 540, 540, 540, 540, 17280, 4320, 4320, 17280, 4320, 4320, 540, 4320, 17280, 4320, 540, 540, 4320, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 4320, 17280, 4320, 4320, 4320, 540, 17280, 540, 17280, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 540, 540, 17280, 4320, 17280, 4320, 17280, 4320, 540, 4320, 540, 540, 540, 17280, 17280, 4320, 4320, 540, 540, 4320, 540, 17280, 540, 540, 4320, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 4320, 17280, 4320, 540, 4320, 540, 17280, 4320, 4320, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 4320, 540, 4320, 540, 4320, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 4320, 4320, 17280, 540, 17280, 540, 540, 540, 17280, 4320, 17280, 17280, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 17280, 540, 540, 4320, 540, 4320, 4320, 540, 17280, 17280, 17280, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2368440 . Total input tokens: 527524345 . Total output tokens: 473668431
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.399769483017735,
    "estimated_duration": 3600.09752728002,
    "input_throughput": 3706.4768103883957,
    "output_throughput": 3219.7011086967755,
    "total_throughput": 6926.177919085171,
    "itl": 260.568047285879,
    "ttft": 2276653.2400784437,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1904,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.216466364415631,
    "arrivals": 788657,
    "finished_requests": 53799,
    "scheduler_time": 65.74660591090203
}
#Debug simulation 
Total elapsed time: 4.399862580001354. Arrivals time: 0.24447732738917693 Scheduler time: 4.054499891761225 Scheduler overhead time: 0.022568455256987363 Adapter cache time: 0.04553015262354165 Engine time: 0.022381686605513096 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-32/adapters_320_slots_192_rate_1.6-0.4-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-32/adapters_320_slots_192_rate_1.6-0.4-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 540, 17280, 17280, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 17280, 17280, 4320, 540, 540, 4320, 17280, 17280, 4320, 4320, 540, 540, 4320, 17280, 17280, 540, 17280, 4320, 540, 4320, 17280, 540, 4320, 17280, 17280, 4320, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 17280, 540, 17280, 4320, 17280, 17280, 540, 17280, 540, 17280, 4320, 540, 540, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 540, 4320, 4320, 540, 17280, 4320, 17280, 17280, 4320, 540, 4320, 4320, 4320, 540, 17280, 4320, 17280, 540, 17280, 540, 540, 4320, 17280, 17280, 4320, 540, 4320, 540, 4320, 17280, 17280, 4320, 540, 4320, 540, 17280, 540, 540, 540, 540, 17280, 4320, 4320, 17280, 4320, 4320, 540, 4320, 17280, 4320, 540, 540, 4320, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 4320, 17280, 4320, 4320, 4320, 540, 17280, 540, 17280, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 540, 540, 17280, 4320, 17280, 4320, 17280, 4320, 540, 4320, 540, 540, 540, 17280, 17280, 4320, 4320, 540, 540, 4320, 540, 17280, 540, 540, 4320, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 4320, 17280, 4320, 540, 4320, 540, 17280, 4320, 4320, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 4320, 540, 4320, 540, 4320, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 4320, 4320, 17280, 540, 17280, 540, 540, 540, 17280, 4320, 17280, 17280, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 17280, 540, 540, 4320, 540, 4320, 4320, 540, 17280, 17280, 17280, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2368440 . Total input tokens: 527524345 . Total output tokens: 473668431
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.74874044500757,
    "estimated_duration": 3600.0136597501264,
    "input_throughput": 3170.9996347048163,
    "output_throughput": 2782.621386135325,
    "total_throughput": 5953.621020840141,
    "itl": 121.25234333864728,
    "ttft": 2361765.563947453,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4394,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.364054960421075,
    "arrivals": 788657,
    "finished_requests": 46072,
    "scheduler_time": 80.21829395646446
}
#Debug simulation 
Total elapsed time: 3.748821845976636. Arrivals time: 0.22783659968990833 Scheduler time: 3.2356920105521567 Scheduler overhead time: 0.0414885304053314 Adapter cache time: 0.18176449032034725 Engine time: 0.042162409343291074 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-16-16/adapters_320_slots_192_rate_1.6-0.4-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-16-16/adapters_320_slots_192_rate_1.6-0.4-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 540, 17280, 17280, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 17280, 17280, 4320, 540, 540, 4320, 17280, 17280, 4320, 4320, 540, 540, 4320, 17280, 17280, 540, 17280, 4320, 540, 4320, 17280, 540, 4320, 17280, 17280, 4320, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 17280, 540, 17280, 4320, 17280, 17280, 540, 17280, 540, 17280, 4320, 540, 540, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 540, 4320, 4320, 540, 17280, 4320, 17280, 17280, 4320, 540, 4320, 4320, 4320, 540, 17280, 4320, 17280, 540, 17280, 540, 540, 4320, 17280, 17280, 4320, 540, 4320, 540, 4320, 17280, 17280, 4320, 540, 4320, 540, 17280, 540, 540, 540, 540, 17280, 4320, 4320, 17280, 4320, 4320, 540, 4320, 17280, 4320, 540, 540, 4320, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 4320, 17280, 4320, 4320, 4320, 540, 17280, 540, 17280, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 540, 540, 17280, 4320, 17280, 4320, 17280, 4320, 540, 4320, 540, 540, 540, 17280, 17280, 4320, 4320, 540, 540, 4320, 540, 17280, 540, 540, 4320, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 4320, 17280, 4320, 540, 4320, 540, 17280, 4320, 4320, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 4320, 540, 4320, 540, 4320, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 4320, 4320, 17280, 540, 17280, 540, 540, 540, 17280, 4320, 17280, 17280, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 17280, 540, 540, 4320, 540, 4320, 4320, 540, 17280, 17280, 17280, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2368440 . Total input tokens: 527524345 . Total output tokens: 473668431
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.443494329985697,
    "estimated_duration": 3600.145313495327,
    "input_throughput": 3706.4701110757874,
    "output_throughput": 3219.5875418002192,
    "total_throughput": 6926.057652876007,
    "itl": 260.42808552163115,
    "ttft": 2276724.3420571457,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1901,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.938640493997207,
    "arrivals": 788657,
    "finished_requests": 53800,
    "scheduler_time": 65.75604465535086
}
#Debug simulation 
Total elapsed time: 4.44358319696039. Arrivals time: 0.24749708181479946 Scheduler time: 4.093861968605779 Scheduler overhead time: 0.02271963079692796 Adapter cache time: 0.04670578596414998 Engine time: 0.022419409768190235 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-16-32/adapters_320_slots_192_rate_1.6-0.4-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-16-32/adapters_320_slots_192_rate_1.6-0.4-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 540, 17280, 17280, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 17280, 17280, 4320, 540, 540, 4320, 17280, 17280, 4320, 4320, 540, 540, 4320, 17280, 17280, 540, 17280, 4320, 540, 4320, 17280, 540, 4320, 17280, 17280, 4320, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 17280, 540, 17280, 4320, 17280, 17280, 540, 17280, 540, 17280, 4320, 540, 540, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 540, 4320, 4320, 540, 17280, 4320, 17280, 17280, 4320, 540, 4320, 4320, 4320, 540, 17280, 4320, 17280, 540, 17280, 540, 540, 4320, 17280, 17280, 4320, 540, 4320, 540, 4320, 17280, 17280, 4320, 540, 4320, 540, 17280, 540, 540, 540, 540, 17280, 4320, 4320, 17280, 4320, 4320, 540, 4320, 17280, 4320, 540, 540, 4320, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 4320, 17280, 4320, 4320, 4320, 540, 17280, 540, 17280, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 540, 540, 17280, 4320, 17280, 4320, 17280, 4320, 540, 4320, 540, 540, 540, 17280, 17280, 4320, 4320, 540, 540, 4320, 540, 17280, 540, 540, 4320, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 4320, 17280, 4320, 540, 4320, 540, 17280, 4320, 4320, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 4320, 540, 4320, 540, 4320, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 4320, 4320, 17280, 540, 17280, 540, 540, 540, 17280, 4320, 17280, 17280, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 17280, 540, 540, 4320, 540, 4320, 4320, 540, 17280, 17280, 17280, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2368440 . Total input tokens: 527524345 . Total output tokens: 473668431
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 3.752888768038247,
    "estimated_duration": 3600.069701353526,
    "input_throughput": 3170.8441632972217,
    "output_throughput": 2782.3672403437063,
    "total_throughput": 5953.2114036409275,
    "itl": 121.2583601708176,
    "ttft": 2361800.537800723,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4394,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.555074961985332,
    "arrivals": 788657,
    "finished_requests": 46070,
    "scheduler_time": 80.21539652918626
}
#Debug simulation 
Total elapsed time: 3.752973014023155. Arrivals time: 0.22585644840728492 Scheduler time: 3.2414826172753237 Scheduler overhead time: 0.04155981488293037 Adapter cache time: 0.1821659097331576 Engine time: 0.04212308395653963 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_16-16-16/adapters_320_slots_192_rate_1.6-0.4-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_16-16-16/adapters_320_slots_192_rate_1.6-0.4-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 540, 17280, 17280, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 17280, 17280, 4320, 540, 540, 4320, 17280, 17280, 4320, 4320, 540, 540, 4320, 17280, 17280, 540, 17280, 4320, 540, 4320, 17280, 540, 4320, 17280, 17280, 4320, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 17280, 540, 17280, 4320, 17280, 17280, 540, 17280, 540, 17280, 4320, 540, 540, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 540, 4320, 4320, 540, 17280, 4320, 17280, 17280, 4320, 540, 4320, 4320, 4320, 540, 17280, 4320, 17280, 540, 17280, 540, 540, 4320, 17280, 17280, 4320, 540, 4320, 540, 4320, 17280, 17280, 4320, 540, 4320, 540, 17280, 540, 540, 540, 540, 17280, 4320, 4320, 17280, 4320, 4320, 540, 4320, 17280, 4320, 540, 540, 4320, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 4320, 17280, 4320, 4320, 4320, 540, 17280, 540, 17280, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 540, 540, 17280, 4320, 17280, 4320, 17280, 4320, 540, 4320, 540, 540, 540, 17280, 17280, 4320, 4320, 540, 540, 4320, 540, 17280, 540, 540, 4320, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 4320, 17280, 4320, 540, 4320, 540, 17280, 4320, 4320, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 4320, 540, 4320, 540, 4320, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 4320, 4320, 17280, 540, 17280, 540, 540, 540, 17280, 4320, 17280, 17280, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 17280, 540, 540, 4320, 540, 4320, 4320, 540, 17280, 17280, 17280, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2368440 . Total input tokens: 527524345 . Total output tokens: 473668431
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.453865600982681,
    "estimated_duration": 3600.092241236862,
    "input_throughput": 3707.621390115878,
    "output_throughput": 3220.5422036677132,
    "total_throughput": 6928.163593783591,
    "itl": 260.6764216803823,
    "ttft": 2276429.857288202,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1923,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.749866717096716,
    "arrivals": 788657,
    "finished_requests": 53817,
    "scheduler_time": 65.75110744903691
}
#Debug simulation 
Total elapsed time: 4.453953542979434. Arrivals time: 0.258845356060192 Scheduler time: 4.092605735582765 Scheduler overhead time: 0.022619762341491878 Adapter cache time: 0.047075236623641104 Engine time: 0.02251865534344688 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_16-16-32/adapters_320_slots_192_rate_1.6-0.4-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_16-16-32/adapters_320_slots_192_rate_1.6-0.4-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 540, 17280, 17280, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 17280, 17280, 4320, 540, 540, 4320, 17280, 17280, 4320, 4320, 540, 540, 4320, 17280, 17280, 540, 17280, 4320, 540, 4320, 17280, 540, 4320, 17280, 17280, 4320, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 17280, 540, 17280, 4320, 17280, 17280, 540, 17280, 540, 17280, 4320, 540, 540, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 540, 4320, 4320, 540, 17280, 4320, 17280, 17280, 4320, 540, 4320, 4320, 4320, 540, 17280, 4320, 17280, 540, 17280, 540, 540, 4320, 17280, 17280, 4320, 540, 4320, 540, 4320, 17280, 17280, 4320, 540, 4320, 540, 17280, 540, 540, 540, 540, 17280, 4320, 4320, 17280, 4320, 4320, 540, 4320, 17280, 4320, 540, 540, 4320, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 4320, 17280, 4320, 4320, 4320, 540, 17280, 540, 17280, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 540, 540, 17280, 4320, 17280, 4320, 17280, 4320, 540, 4320, 540, 540, 540, 17280, 17280, 4320, 4320, 540, 540, 4320, 540, 17280, 540, 540, 4320, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 4320, 17280, 4320, 540, 4320, 540, 17280, 4320, 4320, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 4320, 540, 4320, 540, 4320, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 4320, 4320, 17280, 540, 17280, 540, 540, 540, 17280, 4320, 17280, 17280, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 17280, 540, 540, 4320, 540, 4320, 4320, 540, 17280, 17280, 17280, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2368440 . Total input tokens: 527524345 . Total output tokens: 473668431
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.759947117010597,
    "estimated_duration": 3600.1122214616744,
    "input_throughput": 3170.8067131766556,
    "output_throughput": 2782.334378435885,
    "total_throughput": 5953.141091612541,
    "itl": 121.26469666960212,
    "ttft": 2361859.7153226235,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4394,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.733519584908082,
    "arrivals": 788657,
    "finished_requests": 46070,
    "scheduler_time": 80.21248471281193
}
#Debug simulation 
Total elapsed time: 3.760032414982561. Arrivals time: 0.2261337304371409 Scheduler time: 3.246816913539078 Scheduler overhead time: 0.04184440994868055 Adapter cache time: 0.18332668917719275 Engine time: 0.04200677771586925 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-8/adapters_320_slots_192_rate_1.6-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-8/adapters_320_slots_192_rate_1.6-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 270, 17280, 17280, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 17280, 17280, 4320, 270, 270, 4320, 17280, 17280, 4320, 4320, 270, 270, 4320, 17280, 17280, 270, 17280, 4320, 270, 4320, 17280, 270, 4320, 17280, 17280, 4320, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 17280, 270, 17280, 4320, 17280, 17280, 270, 17280, 270, 17280, 4320, 270, 270, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 270, 4320, 4320, 270, 17280, 4320, 17280, 17280, 4320, 270, 4320, 4320, 4320, 270, 17280, 4320, 17280, 270, 17280, 270, 270, 4320, 17280, 17280, 4320, 270, 4320, 270, 4320, 17280, 17280, 4320, 270, 4320, 270, 17280, 270, 270, 270, 270, 17280, 4320, 4320, 17280, 4320, 4320, 270, 4320, 17280, 4320, 270, 270, 4320, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 4320, 17280, 4320, 4320, 4320, 270, 17280, 270, 17280, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 270, 270, 17280, 4320, 17280, 4320, 17280, 4320, 270, 4320, 270, 270, 270, 17280, 17280, 4320, 4320, 270, 270, 4320, 270, 17280, 270, 270, 4320, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 4320, 17280, 4320, 270, 4320, 270, 17280, 4320, 4320, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 4320, 270, 4320, 270, 4320, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 4320, 4320, 17280, 270, 17280, 270, 270, 270, 17280, 4320, 17280, 17280, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 17280, 270, 270, 4320, 270, 4320, 4320, 270, 17280, 17280, 17280, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2339820 . Total input tokens: 521146796 . Total output tokens: 467944613
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.216978347976692,
    "estimated_duration": 3600.1135626791965,
    "input_throughput": 3667.2359830157006,
    "output_throughput": 3230.150604289769,
    "total_throughput": 6897.38658730547,
    "itl": 264.73631126806674,
    "ttft": 2278871.542471952,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1789,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.475212573895851,
    "arrivals": 779141,
    "finished_requests": 53471,
    "scheduler_time": 65.64584816038729
}
#Debug simulation 
Total elapsed time: 4.217069803969935. Arrivals time: 0.19969535834388807 Scheduler time: 3.9197571811964735 Scheduler overhead time: 0.022172650729771703 Adapter cache time: 0.043293269991409034 Engine time: 0.0219634230597876 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-16/adapters_320_slots_192_rate_1.6-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-16/adapters_320_slots_192_rate_1.6-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 270, 17280, 17280, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 17280, 17280, 4320, 270, 270, 4320, 17280, 17280, 4320, 4320, 270, 270, 4320, 17280, 17280, 270, 17280, 4320, 270, 4320, 17280, 270, 4320, 17280, 17280, 4320, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 17280, 270, 17280, 4320, 17280, 17280, 270, 17280, 270, 17280, 4320, 270, 270, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 270, 4320, 4320, 270, 17280, 4320, 17280, 17280, 4320, 270, 4320, 4320, 4320, 270, 17280, 4320, 17280, 270, 17280, 270, 270, 4320, 17280, 17280, 4320, 270, 4320, 270, 4320, 17280, 17280, 4320, 270, 4320, 270, 17280, 270, 270, 270, 270, 17280, 4320, 4320, 17280, 4320, 4320, 270, 4320, 17280, 4320, 270, 270, 4320, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 4320, 17280, 4320, 4320, 4320, 270, 17280, 270, 17280, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 270, 270, 17280, 4320, 17280, 4320, 17280, 4320, 270, 4320, 270, 270, 270, 17280, 17280, 4320, 4320, 270, 270, 4320, 270, 17280, 270, 270, 4320, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 4320, 17280, 4320, 270, 4320, 270, 17280, 4320, 4320, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 4320, 270, 4320, 270, 4320, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 4320, 4320, 17280, 270, 17280, 270, 270, 270, 17280, 4320, 17280, 17280, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 17280, 270, 270, 4320, 270, 4320, 4320, 270, 17280, 17280, 17280, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2339820 . Total input tokens: 521146796 . Total output tokens: 467944613
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.166155699989758,
    "estimated_duration": 3600.1207302206467,
    "input_throughput": 3658.076766551342,
    "output_throughput": 3222.6152591524174,
    "total_throughput": 6880.69202570376,
    "itl": 262.0432621348495,
    "ttft": 2280608.574862775,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1834,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.984690101258287,
    "arrivals": 779141,
    "finished_requests": 53332,
    "scheduler_time": 65.71360729079773
}
#Debug simulation 
Total elapsed time: 4.1662566109444015. Arrivals time: 0.1957001999253407 Scheduler time: 3.870809289684985 Scheduler overhead time: 0.02240369498031214 Adapter cache time: 0.04484776098979637 Engine time: 0.022197783342562616 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-32/adapters_320_slots_192_rate_1.6-0.4-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-32/adapters_320_slots_192_rate_1.6-0.4-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 270, 17280, 17280, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 17280, 17280, 4320, 270, 270, 4320, 17280, 17280, 4320, 4320, 270, 270, 4320, 17280, 17280, 270, 17280, 4320, 270, 4320, 17280, 270, 4320, 17280, 17280, 4320, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 17280, 270, 17280, 4320, 17280, 17280, 270, 17280, 270, 17280, 4320, 270, 270, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 270, 4320, 4320, 270, 17280, 4320, 17280, 17280, 4320, 270, 4320, 4320, 4320, 270, 17280, 4320, 17280, 270, 17280, 270, 270, 4320, 17280, 17280, 4320, 270, 4320, 270, 4320, 17280, 17280, 4320, 270, 4320, 270, 17280, 270, 270, 270, 270, 17280, 4320, 4320, 17280, 4320, 4320, 270, 4320, 17280, 4320, 270, 270, 4320, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 4320, 17280, 4320, 4320, 4320, 270, 17280, 270, 17280, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 270, 270, 17280, 4320, 17280, 4320, 17280, 4320, 270, 4320, 270, 270, 270, 17280, 17280, 4320, 4320, 270, 270, 4320, 270, 17280, 270, 270, 4320, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 4320, 17280, 4320, 270, 4320, 270, 17280, 4320, 4320, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 4320, 270, 4320, 270, 4320, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 4320, 4320, 17280, 270, 17280, 270, 270, 270, 17280, 4320, 17280, 17280, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 17280, 270, 270, 4320, 270, 4320, 4320, 270, 17280, 17280, 17280, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2339820 . Total input tokens: 521146796 . Total output tokens: 467944613
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.7727968640392646,
    "estimated_duration": 3600.0079530054036,
    "input_throughput": 3175.3690961867833,
    "output_throughput": 2823.430707011203,
    "total_throughput": 5998.799803197986,
    "itl": 119.91179250018124,
    "ttft": 2359257.98917431,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3461,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.318056407868244,
    "arrivals": 779141,
    "finished_requests": 46315,
    "scheduler_time": 81.37389141996036
}
#Debug simulation 
Total elapsed time: 3.7728809650288895. Arrivals time: 0.1783002812298946 Scheduler time: 3.314249796792865 Scheduler overhead time: 0.04249272291781381 Adapter cache time: 0.17427548445994034 Engine time: 0.04322205617791042 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-16-16/adapters_320_slots_192_rate_1.6-0.4-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-16-16/adapters_320_slots_192_rate_1.6-0.4-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 270, 17280, 17280, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 17280, 17280, 4320, 270, 270, 4320, 17280, 17280, 4320, 4320, 270, 270, 4320, 17280, 17280, 270, 17280, 4320, 270, 4320, 17280, 270, 4320, 17280, 17280, 4320, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 17280, 270, 17280, 4320, 17280, 17280, 270, 17280, 270, 17280, 4320, 270, 270, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 270, 4320, 4320, 270, 17280, 4320, 17280, 17280, 4320, 270, 4320, 4320, 4320, 270, 17280, 4320, 17280, 270, 17280, 270, 270, 4320, 17280, 17280, 4320, 270, 4320, 270, 4320, 17280, 17280, 4320, 270, 4320, 270, 17280, 270, 270, 270, 270, 17280, 4320, 4320, 17280, 4320, 4320, 270, 4320, 17280, 4320, 270, 270, 4320, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 4320, 17280, 4320, 4320, 4320, 270, 17280, 270, 17280, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 270, 270, 17280, 4320, 17280, 4320, 17280, 4320, 270, 4320, 270, 270, 270, 17280, 17280, 4320, 4320, 270, 270, 4320, 270, 17280, 270, 270, 4320, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 4320, 17280, 4320, 270, 4320, 270, 17280, 4320, 4320, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 4320, 270, 4320, 270, 4320, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 4320, 4320, 17280, 270, 17280, 270, 270, 270, 17280, 4320, 17280, 17280, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 17280, 270, 270, 4320, 270, 4320, 4320, 270, 17280, 17280, 17280, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2339820 . Total input tokens: 521146796 . Total output tokens: 467944613
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.590148068964481,
    "estimated_duration": 3600.1576096233507,
    "input_throughput": 3658.254839953487,
    "output_throughput": 3222.9372316880085,
    "total_throughput": 6881.192071641496,
    "itl": 262.02401213571227,
    "ttft": 2280653.9690710013,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1834,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.732995385099045,
    "arrivals": 779141,
    "finished_requests": 53339,
    "scheduler_time": 65.71869859269297
}
#Debug simulation 
Total elapsed time: 4.590233672002796. Arrivals time: 0.24176189536228776 Scheduler time: 4.2486556835938245 Scheduler overhead time: 0.022544868348632008 Adapter cache time: 0.044764719787053764 Engine time: 0.022190456045791507 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-16-32/adapters_320_slots_192_rate_1.6-0.4-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-16-32/adapters_320_slots_192_rate_1.6-0.4-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 270, 17280, 17280, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 17280, 17280, 4320, 270, 270, 4320, 17280, 17280, 4320, 4320, 270, 270, 4320, 17280, 17280, 270, 17280, 4320, 270, 4320, 17280, 270, 4320, 17280, 17280, 4320, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 17280, 270, 17280, 4320, 17280, 17280, 270, 17280, 270, 17280, 4320, 270, 270, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 270, 4320, 4320, 270, 17280, 4320, 17280, 17280, 4320, 270, 4320, 4320, 4320, 270, 17280, 4320, 17280, 270, 17280, 270, 270, 4320, 17280, 17280, 4320, 270, 4320, 270, 4320, 17280, 17280, 4320, 270, 4320, 270, 17280, 270, 270, 270, 270, 17280, 4320, 4320, 17280, 4320, 4320, 270, 4320, 17280, 4320, 270, 270, 4320, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 4320, 17280, 4320, 4320, 4320, 270, 17280, 270, 17280, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 270, 270, 17280, 4320, 17280, 4320, 17280, 4320, 270, 4320, 270, 270, 270, 17280, 17280, 4320, 4320, 270, 270, 4320, 270, 17280, 270, 270, 4320, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 4320, 17280, 4320, 270, 4320, 270, 17280, 4320, 4320, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 4320, 270, 4320, 270, 4320, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 4320, 4320, 17280, 270, 17280, 270, 270, 270, 17280, 4320, 17280, 17280, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 17280, 270, 270, 4320, 270, 4320, 4320, 270, 17280, 17280, 17280, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2339820 . Total input tokens: 521146796 . Total output tokens: 467944613
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 3.7620883799972944,
    "estimated_duration": 3600.0226049997113,
    "input_throughput": 3175.2403399147315,
    "output_throughput": 2823.3203274568923,
    "total_throughput": 5998.560667371624,
    "itl": 119.91762465227708,
    "ttft": 2359179.270421671,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3461,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.470344243216594,
    "arrivals": 779141,
    "finished_requests": 46312,
    "scheduler_time": 81.37092947444192
}
#Debug simulation 
Total elapsed time: 3.762172525981441. Arrivals time: 0.18003929842961952 Scheduler time: 3.299978875205852 Scheduler overhead time: 0.04231862677261233 Adapter cache time: 0.17641121352789924 Engine time: 0.04317575506865978 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_16-16-16/adapters_320_slots_192_rate_1.6-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_16-16-16/adapters_320_slots_192_rate_1.6-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 270, 17280, 17280, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 17280, 17280, 4320, 270, 270, 4320, 17280, 17280, 4320, 4320, 270, 270, 4320, 17280, 17280, 270, 17280, 4320, 270, 4320, 17280, 270, 4320, 17280, 17280, 4320, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 17280, 270, 17280, 4320, 17280, 17280, 270, 17280, 270, 17280, 4320, 270, 270, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 270, 4320, 4320, 270, 17280, 4320, 17280, 17280, 4320, 270, 4320, 4320, 4320, 270, 17280, 4320, 17280, 270, 17280, 270, 270, 4320, 17280, 17280, 4320, 270, 4320, 270, 4320, 17280, 17280, 4320, 270, 4320, 270, 17280, 270, 270, 270, 270, 17280, 4320, 4320, 17280, 4320, 4320, 270, 4320, 17280, 4320, 270, 270, 4320, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 4320, 17280, 4320, 4320, 4320, 270, 17280, 270, 17280, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 270, 270, 17280, 4320, 17280, 4320, 17280, 4320, 270, 4320, 270, 270, 270, 17280, 17280, 4320, 4320, 270, 270, 4320, 270, 17280, 270, 270, 4320, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 4320, 17280, 4320, 270, 4320, 270, 17280, 4320, 4320, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 4320, 270, 4320, 270, 4320, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 4320, 4320, 17280, 270, 17280, 270, 270, 270, 17280, 4320, 17280, 17280, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 17280, 270, 270, 4320, 270, 4320, 4320, 270, 17280, 17280, 17280, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2339820 . Total input tokens: 521146796 . Total output tokens: 467944613
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.157074153015856,
    "estimated_duration": 3600.1962107485347,
    "input_throughput": 3658.5297658711393,
    "output_throughput": 3223.399037350571,
    "total_throughput": 6881.92880322171,
    "itl": 262.0101220896323,
    "ttft": 2280585.9532215586,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1834,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.483752240850432,
    "arrivals": 779141,
    "finished_requests": 53345,
    "scheduler_time": 65.72379135377896
}
#Debug simulation 
Total elapsed time: 4.157159792026505. Arrivals time: 0.1951261047506705 Scheduler time: 3.862272353610024 Scheduler overhead time: 0.022452269739005715 Adapter cache time: 0.04495078983018175 Engine time: 0.022073138155974448 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_16-16-32/adapters_320_slots_192_rate_1.6-0.4-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_16-16-32/adapters_320_slots_192_rate_1.6-0.4-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 270, 17280, 17280, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 17280, 17280, 4320, 270, 270, 4320, 17280, 17280, 4320, 4320, 270, 270, 4320, 17280, 17280, 270, 17280, 4320, 270, 4320, 17280, 270, 4320, 17280, 17280, 4320, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 17280, 270, 17280, 4320, 17280, 17280, 270, 17280, 270, 17280, 4320, 270, 270, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 270, 4320, 4320, 270, 17280, 4320, 17280, 17280, 4320, 270, 4320, 4320, 4320, 270, 17280, 4320, 17280, 270, 17280, 270, 270, 4320, 17280, 17280, 4320, 270, 4320, 270, 4320, 17280, 17280, 4320, 270, 4320, 270, 17280, 270, 270, 270, 270, 17280, 4320, 4320, 17280, 4320, 4320, 270, 4320, 17280, 4320, 270, 270, 4320, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 4320, 17280, 4320, 4320, 4320, 270, 17280, 270, 17280, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 270, 270, 17280, 4320, 17280, 4320, 17280, 4320, 270, 4320, 270, 270, 270, 17280, 17280, 4320, 4320, 270, 270, 4320, 270, 17280, 270, 270, 4320, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 4320, 17280, 4320, 270, 4320, 270, 17280, 4320, 4320, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 4320, 270, 4320, 270, 4320, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 4320, 4320, 17280, 270, 17280, 270, 270, 270, 17280, 4320, 17280, 17280, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 17280, 270, 270, 4320, 270, 4320, 4320, 270, 17280, 17280, 17280, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2339820 . Total input tokens: 521146796 . Total output tokens: 467944613
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.7586494049755856,
    "estimated_duration": 3600.021229516042,
    "input_throughput": 3175.2123866049174,
    "output_throughput": 2823.2161290244167,
    "total_throughput": 5998.428515629334,
    "itl": 119.92300308779619,
    "ttft": 2359149.0670770393,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3460,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.607053194939398,
    "arrivals": 779141,
    "finished_requests": 46309,
    "scheduler_time": 81.36795910775582
}
#Debug simulation 
Total elapsed time: 3.758730427012779. Arrivals time: 0.17989019327796996 Scheduler time: 3.2989840746158734 Scheduler overhead time: 0.042395645985379815 Adapter cache time: 0.17410442174877971 Engine time: 0.04310236650053412 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-8/adapters_320_slots_192_rate_1.6-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-8/adapters_320_slots_192_rate_1.6-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 135, 17280, 17280, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 17280, 17280, 4320, 135, 135, 4320, 17280, 17280, 4320, 4320, 135, 135, 4320, 17280, 17280, 135, 17280, 4320, 135, 4320, 17280, 135, 4320, 17280, 17280, 4320, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 17280, 135, 17280, 4320, 17280, 17280, 135, 17280, 135, 17280, 4320, 135, 135, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 135, 4320, 4320, 135, 17280, 4320, 17280, 17280, 4320, 135, 4320, 4320, 4320, 135, 17280, 4320, 17280, 135, 17280, 135, 135, 4320, 17280, 17280, 4320, 135, 4320, 135, 4320, 17280, 17280, 4320, 135, 4320, 135, 17280, 135, 135, 135, 135, 17280, 4320, 4320, 17280, 4320, 4320, 135, 4320, 17280, 4320, 135, 135, 4320, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 4320, 17280, 4320, 4320, 4320, 135, 17280, 135, 17280, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 135, 135, 17280, 4320, 17280, 4320, 17280, 4320, 135, 4320, 135, 135, 135, 17280, 17280, 4320, 4320, 135, 135, 4320, 135, 17280, 135, 135, 4320, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 4320, 17280, 4320, 135, 4320, 135, 17280, 4320, 4320, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 4320, 135, 4320, 135, 4320, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 4320, 4320, 17280, 135, 17280, 135, 135, 135, 17280, 4320, 17280, 17280, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 17280, 135, 135, 4320, 135, 4320, 4320, 135, 17280, 17280, 17280, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2325510 . Total input tokens: 517947587 . Total output tokens: 465135213
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.103953662968706,
    "estimated_duration": 3600.0504757172803,
    "input_throughput": 3693.50765765325,
    "output_throughput": 3228.9777819528817,
    "total_throughput": 6922.485439606132,
    "itl": 263.5126554852781,
    "ttft": 2271395.9647837514,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1700,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.202829164685826,
    "arrivals": 774377,
    "finished_requests": 53573,
    "scheduler_time": 65.68152188976627
}
#Debug simulation 
Total elapsed time: 4.104032367002219. Arrivals time: 0.19784608960617334 Scheduler time: 3.809649234637618 Scheduler overhead time: 0.022236130840610713 Adapter cache time: 0.04205611551878974 Engine time: 0.022039923060219735 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-16/adapters_320_slots_192_rate_1.6-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-16/adapters_320_slots_192_rate_1.6-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 135, 17280, 17280, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 17280, 17280, 4320, 135, 135, 4320, 17280, 17280, 4320, 4320, 135, 135, 4320, 17280, 17280, 135, 17280, 4320, 135, 4320, 17280, 135, 4320, 17280, 17280, 4320, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 17280, 135, 17280, 4320, 17280, 17280, 135, 17280, 135, 17280, 4320, 135, 135, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 135, 4320, 4320, 135, 17280, 4320, 17280, 17280, 4320, 135, 4320, 4320, 4320, 135, 17280, 4320, 17280, 135, 17280, 135, 135, 4320, 17280, 17280, 4320, 135, 4320, 135, 4320, 17280, 17280, 4320, 135, 4320, 135, 17280, 135, 135, 135, 135, 17280, 4320, 4320, 17280, 4320, 4320, 135, 4320, 17280, 4320, 135, 135, 4320, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 4320, 17280, 4320, 4320, 4320, 135, 17280, 135, 17280, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 135, 135, 17280, 4320, 17280, 4320, 17280, 4320, 135, 4320, 135, 135, 135, 17280, 17280, 4320, 4320, 135, 135, 4320, 135, 17280, 135, 135, 4320, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 4320, 17280, 4320, 135, 4320, 135, 17280, 4320, 4320, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 4320, 135, 4320, 135, 4320, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 4320, 4320, 17280, 135, 17280, 135, 135, 135, 17280, 4320, 17280, 17280, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 17280, 135, 135, 4320, 135, 4320, 4320, 135, 17280, 17280, 17280, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2325510 . Total input tokens: 517947587 . Total output tokens: 465135213
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.089238797954749,
    "estimated_duration": 3600.1019724516123,
    "input_throughput": 3685.488939349296,
    "output_throughput": 3221.761519188716,
    "total_throughput": 6907.250458538012,
    "itl": 260.4437751559514,
    "ttft": 2272683.836371704,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1709,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.588052476562884,
    "arrivals": 774377,
    "finished_requests": 53440,
    "scheduler_time": 65.76379568812023
}
#Debug simulation 
Total elapsed time: 4.08933565497864. Arrivals time: 0.1990686112549156 Scheduler time: 3.7927846201928332 Scheduler overhead time: 0.02250458556227386 Adapter cache time: 0.04230542480945587 Engine time: 0.02234071504790336 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-32/adapters_320_slots_192_rate_1.6-0.4-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-32/adapters_320_slots_192_rate_1.6-0.4-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 135, 17280, 17280, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 17280, 17280, 4320, 135, 135, 4320, 17280, 17280, 4320, 4320, 135, 135, 4320, 17280, 17280, 135, 17280, 4320, 135, 4320, 17280, 135, 4320, 17280, 17280, 4320, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 17280, 135, 17280, 4320, 17280, 17280, 135, 17280, 135, 17280, 4320, 135, 135, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 135, 4320, 4320, 135, 17280, 4320, 17280, 17280, 4320, 135, 4320, 4320, 4320, 135, 17280, 4320, 17280, 135, 17280, 135, 135, 4320, 17280, 17280, 4320, 135, 4320, 135, 4320, 17280, 17280, 4320, 135, 4320, 135, 17280, 135, 135, 135, 135, 17280, 4320, 4320, 17280, 4320, 4320, 135, 4320, 17280, 4320, 135, 135, 4320, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 4320, 17280, 4320, 4320, 4320, 135, 17280, 135, 17280, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 135, 135, 17280, 4320, 17280, 4320, 17280, 4320, 135, 4320, 135, 135, 135, 17280, 17280, 4320, 4320, 135, 135, 4320, 135, 17280, 135, 135, 4320, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 4320, 17280, 4320, 135, 4320, 135, 17280, 4320, 4320, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 4320, 135, 4320, 135, 4320, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 4320, 4320, 17280, 135, 17280, 135, 135, 135, 17280, 4320, 17280, 17280, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 17280, 135, 135, 4320, 135, 4320, 4320, 135, 17280, 17280, 17280, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2325510 . Total input tokens: 517947587 . Total output tokens: 465135213
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.7650939419982024,
    "estimated_duration": 3600.079861536651,
    "input_throughput": 3220.1793976458366,
    "output_throughput": 2841.6514059311376,
    "total_throughput": 6061.830803576974,
    "itl": 119.13765658920371,
    "ttft": 2352468.851055306,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2862,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.37223052944962,
    "arrivals": 774377,
    "finished_requests": 46854,
    "scheduler_time": 81.83686534805385
}
#Debug simulation 
Total elapsed time: 3.765192660037428. Arrivals time: 0.17925363400718197 Scheduler time: 3.3096796110621653 Scheduler overhead time: 0.04254976875381544 Adapter cache time: 0.1701772945234552 Engine time: 0.04317778203403577 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-16/adapters_320_slots_192_rate_1.6-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-16/adapters_320_slots_192_rate_1.6-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 135, 17280, 17280, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 17280, 17280, 4320, 135, 135, 4320, 17280, 17280, 4320, 4320, 135, 135, 4320, 17280, 17280, 135, 17280, 4320, 135, 4320, 17280, 135, 4320, 17280, 17280, 4320, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 17280, 135, 17280, 4320, 17280, 17280, 135, 17280, 135, 17280, 4320, 135, 135, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 135, 4320, 4320, 135, 17280, 4320, 17280, 17280, 4320, 135, 4320, 4320, 4320, 135, 17280, 4320, 17280, 135, 17280, 135, 135, 4320, 17280, 17280, 4320, 135, 4320, 135, 4320, 17280, 17280, 4320, 135, 4320, 135, 17280, 135, 135, 135, 135, 17280, 4320, 4320, 17280, 4320, 4320, 135, 4320, 17280, 4320, 135, 135, 4320, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 4320, 17280, 4320, 4320, 4320, 135, 17280, 135, 17280, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 135, 135, 17280, 4320, 17280, 4320, 17280, 4320, 135, 4320, 135, 135, 135, 17280, 17280, 4320, 4320, 135, 135, 4320, 135, 17280, 135, 135, 4320, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 4320, 17280, 4320, 135, 4320, 135, 17280, 4320, 4320, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 4320, 135, 4320, 135, 4320, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 4320, 4320, 17280, 135, 17280, 135, 135, 135, 17280, 4320, 17280, 17280, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 17280, 135, 135, 4320, 135, 4320, 4320, 135, 17280, 17280, 17280, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2325510 . Total input tokens: 517947587 . Total output tokens: 465135213
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.043898408999667,
    "estimated_duration": 3600.1283677485217,
    "input_throughput": 3687.399626892221,
    "output_throughput": 3223.2328446824354,
    "total_throughput": 6910.632471574657,
    "itl": 261.0818383671331,
    "ttft": 2272347.9314453686,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1744,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.445504069228046,
    "arrivals": 774377,
    "finished_requests": 53471,
    "scheduler_time": 65.74797403280948
}
#Debug simulation 
Total elapsed time: 4.043983240029775. Arrivals time: 0.1961744306026958 Scheduler time: 3.7493846527067944 Scheduler overhead time: 0.02241445065010339 Adapter cache time: 0.04350981774041429 Engine time: 0.02219205175060779 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-32/adapters_320_slots_192_rate_1.6-0.4-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-32/adapters_320_slots_192_rate_1.6-0.4-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 135, 17280, 17280, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 17280, 17280, 4320, 135, 135, 4320, 17280, 17280, 4320, 4320, 135, 135, 4320, 17280, 17280, 135, 17280, 4320, 135, 4320, 17280, 135, 4320, 17280, 17280, 4320, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 17280, 135, 17280, 4320, 17280, 17280, 135, 17280, 135, 17280, 4320, 135, 135, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 135, 4320, 4320, 135, 17280, 4320, 17280, 17280, 4320, 135, 4320, 4320, 4320, 135, 17280, 4320, 17280, 135, 17280, 135, 135, 4320, 17280, 17280, 4320, 135, 4320, 135, 4320, 17280, 17280, 4320, 135, 4320, 135, 17280, 135, 135, 135, 135, 17280, 4320, 4320, 17280, 4320, 4320, 135, 4320, 17280, 4320, 135, 135, 4320, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 4320, 17280, 4320, 4320, 4320, 135, 17280, 135, 17280, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 135, 135, 17280, 4320, 17280, 4320, 17280, 4320, 135, 4320, 135, 135, 135, 17280, 17280, 4320, 4320, 135, 135, 4320, 135, 17280, 135, 135, 4320, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 4320, 17280, 4320, 135, 4320, 135, 17280, 4320, 4320, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 4320, 135, 4320, 135, 4320, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 4320, 4320, 17280, 135, 17280, 135, 135, 135, 17280, 4320, 17280, 17280, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 17280, 135, 135, 4320, 135, 4320, 4320, 135, 17280, 17280, 17280, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2325510 . Total input tokens: 517947587 . Total output tokens: 465135213
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 3.7562016749870963,
    "estimated_duration": 3600.078279759135,
    "input_throughput": 3219.758043921069,
    "output_throughput": 2841.499324477027,
    "total_throughput": 6061.257368398096,
    "itl": 119.14252200697713,
    "ttft": 2352492.206640409,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2862,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.50402049761227,
    "arrivals": 774377,
    "finished_requests": 46850,
    "scheduler_time": 81.83394086689411
}
#Debug simulation 
Total elapsed time: 3.7562838020385243. Arrivals time: 0.1787029702682048 Scheduler time: 3.3027563539799303 Scheduler overhead time: 0.04246199666522443 Adapter cache time: 0.16896780155366287 Engine time: 0.04310875036753714 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-16/adapters_320_slots_192_rate_1.6-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-16/adapters_320_slots_192_rate_1.6-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 135, 17280, 17280, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 17280, 17280, 4320, 135, 135, 4320, 17280, 17280, 4320, 4320, 135, 135, 4320, 17280, 17280, 135, 17280, 4320, 135, 4320, 17280, 135, 4320, 17280, 17280, 4320, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 17280, 135, 17280, 4320, 17280, 17280, 135, 17280, 135, 17280, 4320, 135, 135, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 135, 4320, 4320, 135, 17280, 4320, 17280, 17280, 4320, 135, 4320, 4320, 4320, 135, 17280, 4320, 17280, 135, 17280, 135, 135, 4320, 17280, 17280, 4320, 135, 4320, 135, 4320, 17280, 17280, 4320, 135, 4320, 135, 17280, 135, 135, 135, 135, 17280, 4320, 4320, 17280, 4320, 4320, 135, 4320, 17280, 4320, 135, 135, 4320, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 4320, 17280, 4320, 4320, 4320, 135, 17280, 135, 17280, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 135, 135, 17280, 4320, 17280, 4320, 17280, 4320, 135, 4320, 135, 135, 135, 17280, 17280, 4320, 4320, 135, 135, 4320, 135, 17280, 135, 135, 4320, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 4320, 17280, 4320, 135, 4320, 135, 17280, 4320, 4320, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 4320, 135, 4320, 135, 4320, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 4320, 4320, 17280, 135, 17280, 135, 135, 135, 17280, 4320, 17280, 17280, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 17280, 135, 135, 4320, 135, 4320, 4320, 135, 17280, 17280, 17280, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2325510 . Total input tokens: 517947587 . Total output tokens: 465135213
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.079713036015164,
    "estimated_duration": 3600.185330000941,
    "input_throughput": 3687.548774050621,
    "output_throughput": 3223.2199001813515,
    "total_throughput": 6910.768674231972,
    "itl": 261.0623674083018,
    "ttft": 2272388.171828703,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1744,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.214647714309246,
    "arrivals": 774377,
    "finished_requests": 53474,
    "scheduler_time": 65.75304113180304
}
#Debug simulation 
Total elapsed time: 4.079796386999078. Arrivals time: 0.19555164850316942 Scheduler time: 3.786285732057877 Scheduler overhead time: 0.02247352944687009 Adapter cache time: 0.042951048526447266 Engine time: 0.02227829140610993 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-32/adapters_320_slots_192_rate_1.6-0.4-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-32/adapters_320_slots_192_rate_1.6-0.4-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 135, 17280, 17280, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 17280, 17280, 4320, 135, 135, 4320, 17280, 17280, 4320, 4320, 135, 135, 4320, 17280, 17280, 135, 17280, 4320, 135, 4320, 17280, 135, 4320, 17280, 17280, 4320, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 17280, 135, 17280, 4320, 17280, 17280, 135, 17280, 135, 17280, 4320, 135, 135, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 135, 4320, 4320, 135, 17280, 4320, 17280, 17280, 4320, 135, 4320, 4320, 4320, 135, 17280, 4320, 17280, 135, 17280, 135, 135, 4320, 17280, 17280, 4320, 135, 4320, 135, 4320, 17280, 17280, 4320, 135, 4320, 135, 17280, 135, 135, 135, 135, 17280, 4320, 4320, 17280, 4320, 4320, 135, 4320, 17280, 4320, 135, 135, 4320, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 4320, 17280, 4320, 4320, 4320, 135, 17280, 135, 17280, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 135, 135, 17280, 4320, 17280, 4320, 17280, 4320, 135, 4320, 135, 135, 135, 17280, 17280, 4320, 4320, 135, 135, 4320, 135, 17280, 135, 135, 4320, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 4320, 17280, 4320, 135, 4320, 135, 17280, 4320, 4320, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 4320, 135, 4320, 135, 4320, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 4320, 4320, 17280, 135, 17280, 135, 135, 135, 17280, 4320, 17280, 17280, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 17280, 135, 135, 4320, 135, 4320, 4320, 135, 17280, 17280, 17280, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2325510 . Total input tokens: 517947587 . Total output tokens: 465135213
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.783923283976037,
    "estimated_duration": 3600.059633225585,
    "input_throughput": 3219.774442906754,
    "output_throughput": 2841.3612667951693,
    "total_throughput": 6061.135709701923,
    "itl": 119.14629987474558,
    "ttft": 2352535.572496707,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2862,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.618959458395352,
    "arrivals": 774377,
    "finished_requests": 46849,
    "scheduler_time": 81.83101864040638
}
#Debug simulation 
Total elapsed time: 3.784005869005341. Arrivals time: 0.17988026834791526 Scheduler time: 3.327783431392163 Scheduler overhead time: 0.04263531119795516 Adapter cache time: 0.1702079486567527 Engine time: 0.04315760458121076 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-8/adapters_320_slots_192_rate_1.6-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-8/adapters_320_slots_192_rate_1.6-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 66, 17280, 17280, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 17280, 17280, 4320, 66, 66, 4320, 17280, 17280, 4320, 4320, 66, 66, 4320, 17280, 17280, 66, 17280, 4320, 66, 4320, 17280, 66, 4320, 17280, 17280, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 17280, 4320, 17280, 17280, 66, 17280, 66, 17280, 4320, 66, 66, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 66, 4320, 4320, 66, 17280, 4320, 17280, 17280, 4320, 66, 4320, 4320, 4320, 66, 17280, 4320, 17280, 66, 17280, 66, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 17280, 66, 66, 66, 66, 17280, 4320, 4320, 17280, 4320, 4320, 66, 4320, 17280, 4320, 66, 66, 4320, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 4320, 17280, 4320, 4320, 4320, 66, 17280, 66, 17280, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 66, 66, 17280, 4320, 17280, 4320, 17280, 4320, 66, 4320, 66, 66, 66, 17280, 17280, 4320, 4320, 66, 66, 4320, 66, 17280, 66, 66, 4320, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 4320, 17280, 4320, 66, 4320, 66, 17280, 4320, 4320, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 4320, 4320, 17280, 66, 17280, 66, 66, 66, 17280, 4320, 17280, 17280, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 17280, 66, 66, 4320, 66, 4320, 4320, 66, 17280, 17280, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2318196 . Total input tokens: 516259933 . Total output tokens: 463669613
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.085293051961344,
    "estimated_duration": 3600.2601166152817,
    "input_throughput": 3665.148231679853,
    "output_throughput": 3231.3520754542637,
    "total_throughput": 6896.500307134116,
    "itl": 264.89553734881184,
    "ttft": 2278801.45154222,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1660,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.080409654928512,
    "arrivals": 771975,
    "finished_requests": 53468,
    "scheduler_time": 65.65930375752407
}
#Debug simulation 
Total elapsed time: 4.085380123986397. Arrivals time: 0.1961019038571976 Scheduler time: 3.793161019915715 Scheduler overhead time: 0.0222499500378035 Adapter cache time: 0.041871395078487694 Engine time: 0.02183297195006162 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-16/adapters_320_slots_192_rate_1.6-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-16/adapters_320_slots_192_rate_1.6-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 66, 17280, 17280, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 17280, 17280, 4320, 66, 66, 4320, 17280, 17280, 4320, 4320, 66, 66, 4320, 17280, 17280, 66, 17280, 4320, 66, 4320, 17280, 66, 4320, 17280, 17280, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 17280, 4320, 17280, 17280, 66, 17280, 66, 17280, 4320, 66, 66, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 66, 4320, 4320, 66, 17280, 4320, 17280, 17280, 4320, 66, 4320, 4320, 4320, 66, 17280, 4320, 17280, 66, 17280, 66, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 17280, 66, 66, 66, 66, 17280, 4320, 4320, 17280, 4320, 4320, 66, 4320, 17280, 4320, 66, 66, 4320, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 4320, 17280, 4320, 4320, 4320, 66, 17280, 66, 17280, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 66, 66, 17280, 4320, 17280, 4320, 17280, 4320, 66, 4320, 66, 66, 66, 17280, 17280, 4320, 4320, 66, 66, 4320, 66, 17280, 66, 66, 4320, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 4320, 17280, 4320, 66, 4320, 66, 17280, 4320, 4320, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 4320, 4320, 17280, 66, 17280, 66, 66, 66, 17280, 4320, 17280, 17280, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 17280, 66, 66, 4320, 66, 4320, 4320, 66, 17280, 17280, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2318196 . Total input tokens: 516259933 . Total output tokens: 463669613
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.027481723984238,
    "estimated_duration": 3600.1652885908634,
    "input_throughput": 3655.032462454089,
    "output_throughput": 3222.876193148752,
    "total_throughput": 6877.9086556028415,
    "itl": 262.1307467081115,
    "ttft": 2281296.155009352,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1724,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.637806374807695,
    "arrivals": 771975,
    "finished_requests": 53319,
    "scheduler_time": 65.72585428161271
}
#Debug simulation 
Total elapsed time: 4.027566601987928. Arrivals time: 0.23906424752203748 Scheduler time: 3.6909430114901625 Scheduler overhead time: 0.022237650118768215 Adapter cache time: 0.04310954868560657 Engine time: 0.022030761057976633 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-32/adapters_320_slots_192_rate_1.6-0.4-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-32/adapters_320_slots_192_rate_1.6-0.4-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 66, 17280, 17280, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 17280, 17280, 4320, 66, 66, 4320, 17280, 17280, 4320, 4320, 66, 66, 4320, 17280, 17280, 66, 17280, 4320, 66, 4320, 17280, 66, 4320, 17280, 17280, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 17280, 4320, 17280, 17280, 66, 17280, 66, 17280, 4320, 66, 66, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 66, 4320, 4320, 66, 17280, 4320, 17280, 17280, 4320, 66, 4320, 4320, 4320, 66, 17280, 4320, 17280, 66, 17280, 66, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 17280, 66, 66, 66, 66, 17280, 4320, 4320, 17280, 4320, 4320, 66, 4320, 17280, 4320, 66, 66, 4320, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 4320, 17280, 4320, 4320, 4320, 66, 17280, 66, 17280, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 66, 66, 17280, 4320, 17280, 4320, 17280, 4320, 66, 4320, 66, 66, 66, 17280, 17280, 4320, 4320, 66, 66, 4320, 66, 17280, 66, 66, 4320, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 4320, 17280, 4320, 66, 4320, 66, 17280, 4320, 4320, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 4320, 4320, 17280, 66, 17280, 66, 66, 66, 17280, 4320, 17280, 17280, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 17280, 66, 66, 4320, 66, 4320, 4320, 66, 17280, 17280, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2318196 . Total input tokens: 516259933 . Total output tokens: 463669613
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.04028916801326,
    "estimated_duration": 3600.1224075007663,
    "input_throughput": 3206.8101284407626,
    "output_throughput": 2849.330616822316,
    "total_throughput": 6056.140745263079,
    "itl": 118.3388735854815,
    "ttft": 2357523.850943294,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2520,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.247709704525697,
    "arrivals": 771975,
    "finished_requests": 46735,
    "scheduler_time": 82.24408201663071
}
#Debug simulation 
Total elapsed time: 4.04037724097725. Arrivals time: 0.4561013825586997 Scheduler time: 3.3106333313626237 Scheduler overhead time: 0.04260502476245165 Adapter cache time: 0.16681186360074207 Engine time: 0.0438349568285048 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-16/adapters_320_slots_192_rate_1.6-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-16/adapters_320_slots_192_rate_1.6-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 66, 17280, 17280, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 17280, 17280, 4320, 66, 66, 4320, 17280, 17280, 4320, 4320, 66, 66, 4320, 17280, 17280, 66, 17280, 4320, 66, 4320, 17280, 66, 4320, 17280, 17280, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 17280, 4320, 17280, 17280, 66, 17280, 66, 17280, 4320, 66, 66, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 66, 4320, 4320, 66, 17280, 4320, 17280, 17280, 4320, 66, 4320, 4320, 4320, 66, 17280, 4320, 17280, 66, 17280, 66, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 17280, 66, 66, 66, 66, 17280, 4320, 4320, 17280, 4320, 4320, 66, 4320, 17280, 4320, 66, 66, 4320, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 4320, 17280, 4320, 4320, 4320, 66, 17280, 66, 17280, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 66, 66, 17280, 4320, 17280, 4320, 17280, 4320, 66, 4320, 66, 66, 66, 17280, 17280, 4320, 4320, 66, 66, 4320, 66, 17280, 66, 66, 4320, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 4320, 17280, 4320, 66, 4320, 66, 17280, 4320, 4320, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 4320, 4320, 17280, 66, 17280, 66, 66, 66, 17280, 4320, 17280, 17280, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 17280, 66, 66, 4320, 66, 4320, 4320, 66, 17280, 17280, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2318196 . Total input tokens: 516259933 . Total output tokens: 463669613
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.065107963979244,
    "estimated_duration": 3600.1940811075515,
    "input_throughput": 3655.485149831523,
    "output_throughput": 3223.214287500335,
    "total_throughput": 6878.6994373318585,
    "itl": 262.1150931010372,
    "ttft": 2281233.935059977,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1724,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.378756942916524,
    "arrivals": 771975,
    "finished_requests": 53324,
    "scheduler_time": 65.73094472183763
}
#Debug simulation 
Total elapsed time: 4.065191812987905. Arrivals time: 0.2424809469957836 Scheduler time: 3.724377077072859 Scheduler overhead time: 0.02228357846615836 Adapter cache time: 0.043800378509331495 Engine time: 0.022053366410546005 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-32/adapters_320_slots_192_rate_1.6-0.4-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-32/adapters_320_slots_192_rate_1.6-0.4-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 66, 17280, 17280, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 17280, 17280, 4320, 66, 66, 4320, 17280, 17280, 4320, 4320, 66, 66, 4320, 17280, 17280, 66, 17280, 4320, 66, 4320, 17280, 66, 4320, 17280, 17280, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 17280, 4320, 17280, 17280, 66, 17280, 66, 17280, 4320, 66, 66, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 66, 4320, 4320, 66, 17280, 4320, 17280, 17280, 4320, 66, 4320, 4320, 4320, 66, 17280, 4320, 17280, 66, 17280, 66, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 17280, 66, 66, 66, 66, 17280, 4320, 4320, 17280, 4320, 4320, 66, 4320, 17280, 4320, 66, 66, 4320, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 4320, 17280, 4320, 4320, 4320, 66, 17280, 66, 17280, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 66, 66, 17280, 4320, 17280, 4320, 17280, 4320, 66, 4320, 66, 66, 66, 17280, 17280, 4320, 4320, 66, 66, 4320, 66, 17280, 66, 66, 4320, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 4320, 17280, 4320, 66, 4320, 66, 17280, 4320, 4320, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 4320, 4320, 17280, 66, 17280, 66, 66, 66, 17280, 4320, 17280, 17280, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 17280, 66, 66, 4320, 66, 4320, 4320, 66, 17280, 17280, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2318196 . Total input tokens: 516259933 . Total output tokens: 463669613
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 3.817596215987578,
    "estimated_duration": 3600.109529448558,
    "input_throughput": 3206.821599610714,
    "output_throughput": 2849.340809242336,
    "total_throughput": 6056.16240885305,
    "itl": 118.34276615953408,
    "ttft": 2357509.998376959,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2520,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.361768388803808,
    "arrivals": 771975,
    "finished_requests": 46735,
    "scheduler_time": 82.241246918746
}
#Debug simulation 
Total elapsed time: 3.817678346997127. Arrivals time: 0.23376677185297012 Scheduler time: 3.3098058998584747 Scheduler overhead time: 0.04272309527732432 Adapter cache time: 0.16737368644680828 Engine time: 0.04358860629145056 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-16/adapters_320_slots_192_rate_1.6-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-16/adapters_320_slots_192_rate_1.6-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 66, 17280, 17280, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 17280, 17280, 4320, 66, 66, 4320, 17280, 17280, 4320, 4320, 66, 66, 4320, 17280, 17280, 66, 17280, 4320, 66, 4320, 17280, 66, 4320, 17280, 17280, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 17280, 4320, 17280, 17280, 66, 17280, 66, 17280, 4320, 66, 66, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 66, 4320, 4320, 66, 17280, 4320, 17280, 17280, 4320, 66, 4320, 4320, 4320, 66, 17280, 4320, 17280, 66, 17280, 66, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 17280, 66, 66, 66, 66, 17280, 4320, 4320, 17280, 4320, 4320, 66, 4320, 17280, 4320, 66, 66, 4320, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 4320, 17280, 4320, 4320, 4320, 66, 17280, 66, 17280, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 66, 66, 17280, 4320, 17280, 4320, 17280, 4320, 66, 4320, 66, 66, 66, 17280, 17280, 4320, 4320, 66, 66, 4320, 66, 17280, 66, 66, 4320, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 4320, 17280, 4320, 66, 4320, 66, 17280, 4320, 4320, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 4320, 4320, 17280, 66, 17280, 66, 66, 66, 17280, 4320, 17280, 17280, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 17280, 66, 66, 4320, 66, 4320, 4320, 66, 17280, 17280, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2318196 . Total input tokens: 516259933 . Total output tokens: 463669613
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.39818442100659,
    "estimated_duration": 3600.02586204756,
    "input_throughput": 3655.6559603476917,
    "output_throughput": 3223.364899217687,
    "total_throughput": 6879.0208595653785,
    "itl": 262.07228867976926,
    "ttft": 2281171.5201271805,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1722,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.1488666078214,
    "arrivals": 771975,
    "finished_requests": 53324,
    "scheduler_time": 65.73270007479297
}
#Debug simulation 
Total elapsed time: 4.398245770018548. Arrivals time: 0.4697278525563888 Scheduler time: 3.8304783128551207 Scheduler overhead time: 0.022337578528095037 Adapter cache time: 0.043196246901061386 Engine time: 0.022229387192055583 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-32/adapters_320_slots_192_rate_1.6-0.4-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-32/adapters_320_slots_192_rate_1.6-0.4-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 66, 17280, 17280, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 17280, 17280, 4320, 66, 66, 4320, 17280, 17280, 4320, 4320, 66, 66, 4320, 17280, 17280, 66, 17280, 4320, 66, 4320, 17280, 66, 4320, 17280, 17280, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 17280, 4320, 17280, 17280, 66, 17280, 66, 17280, 4320, 66, 66, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 66, 4320, 4320, 66, 17280, 4320, 17280, 17280, 4320, 66, 4320, 4320, 4320, 66, 17280, 4320, 17280, 66, 17280, 66, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 17280, 66, 66, 66, 66, 17280, 4320, 4320, 17280, 4320, 4320, 66, 4320, 17280, 4320, 66, 66, 4320, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 4320, 17280, 4320, 4320, 4320, 66, 17280, 66, 17280, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 66, 66, 17280, 4320, 17280, 4320, 17280, 4320, 66, 4320, 66, 66, 66, 17280, 17280, 4320, 4320, 66, 66, 4320, 66, 17280, 66, 66, 4320, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 4320, 17280, 4320, 66, 4320, 66, 17280, 4320, 4320, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 4320, 4320, 17280, 66, 17280, 66, 66, 66, 17280, 4320, 17280, 17280, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 17280, 66, 66, 4320, 66, 4320, 4320, 66, 17280, 17280, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2318196 . Total input tokens: 516259933 . Total output tokens: 463669613
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.848599140997976,
    "estimated_duration": 3600.0829106258975,
    "input_throughput": 3206.6669814537563,
    "output_throughput": 2849.324100209852,
    "total_throughput": 6055.991081663608,
    "itl": 118.34716834088061,
    "ttft": 2357533.767547954,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2520,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.463251694440464,
    "arrivals": 771975,
    "finished_requests": 46733,
    "scheduler_time": 82.23840797498421
}
#Debug simulation 
Total elapsed time: 3.8487086680252105. Arrivals time: 0.2274528464768082 Scheduler time: 3.3465242343372665 Scheduler overhead time: 0.0429784101434052 Adapter cache time: 0.1672578168218024 Engine time: 0.043958870286587626 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-8/adapters_320_slots_192_rate_1.6-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-8/adapters_320_slots_192_rate_1.6-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 33, 17280, 17280, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 17280, 17280, 4320, 33, 33, 4320, 17280, 17280, 4320, 4320, 33, 33, 4320, 17280, 17280, 33, 17280, 4320, 33, 4320, 17280, 33, 4320, 17280, 17280, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 17280, 4320, 17280, 17280, 33, 17280, 33, 17280, 4320, 33, 33, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 33, 4320, 4320, 33, 17280, 4320, 17280, 17280, 4320, 33, 4320, 4320, 4320, 33, 17280, 4320, 17280, 33, 17280, 33, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 17280, 33, 33, 33, 33, 17280, 4320, 4320, 17280, 4320, 4320, 33, 4320, 17280, 4320, 33, 33, 4320, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 4320, 17280, 4320, 4320, 4320, 33, 17280, 33, 17280, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 33, 33, 17280, 4320, 17280, 4320, 17280, 4320, 33, 4320, 33, 33, 33, 17280, 17280, 4320, 4320, 33, 33, 4320, 33, 17280, 33, 33, 4320, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 4320, 17280, 4320, 33, 4320, 33, 17280, 4320, 4320, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 4320, 4320, 17280, 33, 17280, 33, 33, 33, 17280, 4320, 17280, 17280, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 17280, 33, 33, 4320, 33, 4320, 4320, 33, 17280, 17280, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2314698 . Total input tokens: 515493855 . Total output tokens: 462974761
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.0224756200332195,
    "estimated_duration": 3600.0666114297683,
    "input_throughput": 3659.8072819456315,
    "output_throughput": 3227.852218930171,
    "total_throughput": 6887.659500875802,
    "itl": 264.3149227957767,
    "ttft": 2270416.8708053473,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1731,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.297704284747745,
    "arrivals": 770785,
    "finished_requests": 53490,
    "scheduler_time": 65.67366381089175
}
#Debug simulation 
Total elapsed time: 4.022570857021492. Arrivals time: 0.27432799409143627 Scheduler time: 3.6509843142703176 Scheduler overhead time: 0.021887920680455863 Adapter cache time: 0.04329603782389313 Engine time: 0.021994590293616056 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-16/adapters_320_slots_192_rate_1.6-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-16/adapters_320_slots_192_rate_1.6-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 33, 17280, 17280, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 17280, 17280, 4320, 33, 33, 4320, 17280, 17280, 4320, 4320, 33, 33, 4320, 17280, 17280, 33, 17280, 4320, 33, 4320, 17280, 33, 4320, 17280, 17280, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 17280, 4320, 17280, 17280, 33, 17280, 33, 17280, 4320, 33, 33, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 33, 4320, 4320, 33, 17280, 4320, 17280, 17280, 4320, 33, 4320, 4320, 4320, 33, 17280, 4320, 17280, 33, 17280, 33, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 17280, 33, 33, 33, 33, 17280, 4320, 4320, 17280, 4320, 4320, 33, 4320, 17280, 4320, 33, 33, 4320, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 4320, 17280, 4320, 4320, 4320, 33, 17280, 33, 17280, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 33, 33, 17280, 4320, 17280, 4320, 17280, 4320, 33, 4320, 33, 33, 33, 17280, 17280, 4320, 4320, 33, 33, 4320, 33, 17280, 33, 33, 4320, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 4320, 17280, 4320, 33, 4320, 33, 17280, 4320, 4320, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 4320, 4320, 17280, 33, 17280, 33, 33, 33, 17280, 4320, 17280, 17280, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 17280, 33, 33, 4320, 33, 4320, 4320, 33, 17280, 17280, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2314698 . Total input tokens: 515493855 . Total output tokens: 462974761
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.048753481998574,
    "estimated_duration": 3600.2474606511146,
    "input_throughput": 3651.7650921757145,
    "output_throughput": 3220.83221410088,
    "total_throughput": 6872.597306276594,
    "itl": 261.8425539078909,
    "ttft": 2270953.439897416,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1796,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.871068190052005,
    "arrivals": 770785,
    "finished_requests": 53378,
    "scheduler_time": 65.74528392763982
}
#Debug simulation 
Total elapsed time: 4.048840463976376. Arrivals time: 0.2730932508711703 Scheduler time: 3.6753819823497906 Scheduler overhead time: 0.022328389750327915 Adapter cache time: 0.04564691864652559 Engine time: 0.022139433422125876 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-32/adapters_320_slots_192_rate_1.6-0.4-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-32/adapters_320_slots_192_rate_1.6-0.4-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 33, 17280, 17280, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 17280, 17280, 4320, 33, 33, 4320, 17280, 17280, 4320, 4320, 33, 33, 4320, 17280, 17280, 33, 17280, 4320, 33, 4320, 17280, 33, 4320, 17280, 17280, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 17280, 4320, 17280, 17280, 33, 17280, 33, 17280, 4320, 33, 33, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 33, 4320, 4320, 33, 17280, 4320, 17280, 17280, 4320, 33, 4320, 4320, 4320, 33, 17280, 4320, 17280, 33, 17280, 33, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 17280, 33, 33, 33, 33, 17280, 4320, 4320, 17280, 4320, 4320, 33, 4320, 17280, 4320, 33, 33, 4320, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 4320, 17280, 4320, 4320, 4320, 33, 17280, 33, 17280, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 33, 33, 17280, 4320, 17280, 4320, 17280, 4320, 33, 4320, 33, 33, 33, 17280, 17280, 4320, 4320, 33, 33, 4320, 33, 17280, 33, 33, 4320, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 4320, 17280, 4320, 33, 4320, 33, 17280, 4320, 4320, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 4320, 4320, 17280, 33, 17280, 33, 33, 33, 17280, 4320, 17280, 17280, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 17280, 33, 33, 4320, 33, 4320, 4320, 33, 17280, 17280, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2314698 . Total input tokens: 515493855 . Total output tokens: 462974761
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.8605392340105027,
    "estimated_duration": 3600.0973705271545,
    "input_throughput": 3247.997150223691,
    "output_throughput": 2873.6192206060136,
    "total_throughput": 6121.6163708297045,
    "itl": 117.54869246648411,
    "ttft": 2345282.9533672817,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2245,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.345653254669138,
    "arrivals": 770785,
    "finished_requests": 47398,
    "scheduler_time": 82.81801668288108
}
#Debug simulation 
Total elapsed time: 3.8606216750340536. Arrivals time: 0.25983896863181144 Scheduler time: 3.332043099217117 Scheduler overhead time: 0.042953976429998875 Adapter cache time: 0.1618571284925565 Engine time: 0.043418543122243136 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-16/adapters_320_slots_192_rate_1.6-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-16/adapters_320_slots_192_rate_1.6-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 33, 17280, 17280, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 17280, 17280, 4320, 33, 33, 4320, 17280, 17280, 4320, 4320, 33, 33, 4320, 17280, 17280, 33, 17280, 4320, 33, 4320, 17280, 33, 4320, 17280, 17280, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 17280, 4320, 17280, 17280, 33, 17280, 33, 17280, 4320, 33, 33, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 33, 4320, 4320, 33, 17280, 4320, 17280, 17280, 4320, 33, 4320, 4320, 4320, 33, 17280, 4320, 17280, 33, 17280, 33, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 17280, 33, 33, 33, 33, 17280, 4320, 4320, 17280, 4320, 4320, 33, 4320, 17280, 4320, 33, 33, 4320, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 4320, 17280, 4320, 4320, 4320, 33, 17280, 33, 17280, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 33, 33, 17280, 4320, 17280, 4320, 17280, 4320, 33, 4320, 33, 33, 33, 17280, 17280, 4320, 4320, 33, 33, 4320, 33, 17280, 33, 33, 4320, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 4320, 17280, 4320, 33, 4320, 33, 17280, 4320, 4320, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 4320, 4320, 17280, 33, 17280, 33, 33, 33, 17280, 4320, 17280, 17280, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 17280, 33, 33, 4320, 33, 4320, 4320, 33, 17280, 17280, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2314698 . Total input tokens: 515493855 . Total output tokens: 462974761
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.088480597943999,
    "estimated_duration": 3600.120937899923,
    "input_throughput": 3651.8270432518075,
    "output_throughput": 3220.9673508257974,
    "total_throughput": 6872.794394077605,
    "itl": 261.66322891360693,
    "ttft": 2271042.3203430176,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1795,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.613114661050346,
    "arrivals": 770785,
    "finished_requests": 53374,
    "scheduler_time": 65.75124051104547
}
#Debug simulation 
Total elapsed time: 4.088567829981912. Arrivals time: 0.3188173582893796 Scheduler time: 3.6703638919861987 Scheduler overhead time: 0.02216568891890347 Adapter cache time: 0.04508431482827291 Engine time: 0.021924541739281267 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-32/adapters_320_slots_192_rate_1.6-0.4-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-32/adapters_320_slots_192_rate_1.6-0.4-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 33, 17280, 17280, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 17280, 17280, 4320, 33, 33, 4320, 17280, 17280, 4320, 4320, 33, 33, 4320, 17280, 17280, 33, 17280, 4320, 33, 4320, 17280, 33, 4320, 17280, 17280, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 17280, 4320, 17280, 17280, 33, 17280, 33, 17280, 4320, 33, 33, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 33, 4320, 4320, 33, 17280, 4320, 17280, 17280, 4320, 33, 4320, 4320, 4320, 33, 17280, 4320, 17280, 33, 17280, 33, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 17280, 33, 33, 33, 33, 17280, 4320, 4320, 17280, 4320, 4320, 33, 4320, 17280, 4320, 33, 33, 4320, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 4320, 17280, 4320, 4320, 4320, 33, 17280, 33, 17280, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 33, 33, 17280, 4320, 17280, 4320, 17280, 4320, 33, 4320, 33, 33, 33, 17280, 17280, 4320, 4320, 33, 33, 4320, 33, 17280, 33, 33, 4320, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 4320, 17280, 4320, 33, 4320, 33, 17280, 4320, 4320, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 4320, 4320, 17280, 33, 17280, 33, 33, 33, 17280, 4320, 17280, 17280, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 17280, 33, 33, 4320, 33, 4320, 4320, 33, 17280, 17280, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2314698 . Total input tokens: 515493855 . Total output tokens: 462974761
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 3.882259197998792,
    "estimated_duration": 3600.058621222564,
    "input_throughput": 3247.8312800443564,
    "output_throughput": 2873.5395971099256,
    "total_throughput": 6121.3708771542815,
    "itl": 117.55230596255512,
    "ttft": 2345256.1831115615,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2245,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.442483670208448,
    "arrivals": 770785,
    "finished_requests": 47395,
    "scheduler_time": 82.81504426057518
}
#Debug simulation 
Total elapsed time: 3.882342762022745. Arrivals time: 0.2581349825486541 Scheduler time: 3.3546720711747184 Scheduler overhead time: 0.043087348458357155 Adapter cache time: 0.1619728832738474 Engine time: 0.043837855104357004 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-16/adapters_320_slots_192_rate_1.6-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-16/adapters_320_slots_192_rate_1.6-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 33, 17280, 17280, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 17280, 17280, 4320, 33, 33, 4320, 17280, 17280, 4320, 4320, 33, 33, 4320, 17280, 17280, 33, 17280, 4320, 33, 4320, 17280, 33, 4320, 17280, 17280, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 17280, 4320, 17280, 17280, 33, 17280, 33, 17280, 4320, 33, 33, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 33, 4320, 4320, 33, 17280, 4320, 17280, 17280, 4320, 33, 4320, 4320, 4320, 33, 17280, 4320, 17280, 33, 17280, 33, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 17280, 33, 33, 33, 33, 17280, 4320, 4320, 17280, 4320, 4320, 33, 4320, 17280, 4320, 33, 33, 4320, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 4320, 17280, 4320, 4320, 4320, 33, 17280, 33, 17280, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 33, 33, 17280, 4320, 17280, 4320, 17280, 4320, 33, 4320, 33, 33, 33, 17280, 17280, 4320, 4320, 33, 33, 4320, 33, 17280, 33, 33, 4320, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 4320, 17280, 4320, 33, 4320, 33, 17280, 4320, 4320, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 4320, 4320, 17280, 33, 17280, 33, 33, 33, 17280, 4320, 17280, 17280, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 17280, 33, 33, 4320, 33, 4320, 4320, 33, 17280, 17280, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2314698 . Total input tokens: 515493855 . Total output tokens: 462974761
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.024029469001107,
    "estimated_duration": 3600.1648009120877,
    "input_throughput": 3652.0442054955415,
    "output_throughput": 3221.201706394658,
    "total_throughput": 6873.2459118902,
    "itl": 261.64441954690506,
    "ttft": 2271042.5489993007,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1795,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.367140279349251,
    "arrivals": 770785,
    "finished_requests": 53381,
    "scheduler_time": 65.7563762402464
}
#Debug simulation 
Total elapsed time: 4.024133366998285. Arrivals time: 0.2738713431172073 Scheduler time: 3.6508631204487756 Scheduler overhead time: 0.022194279939867556 Adapter cache time: 0.045071394357364625 Engine time: 0.02196668164106086 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-32/adapters_320_slots_192_rate_1.6-0.4-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-32/adapters_320_slots_192_rate_1.6-0.4-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 33, 17280, 17280, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 17280, 17280, 4320, 33, 33, 4320, 17280, 17280, 4320, 4320, 33, 33, 4320, 17280, 17280, 33, 17280, 4320, 33, 4320, 17280, 33, 4320, 17280, 17280, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 17280, 4320, 17280, 17280, 33, 17280, 33, 17280, 4320, 33, 33, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 33, 4320, 4320, 33, 17280, 4320, 17280, 17280, 4320, 33, 4320, 4320, 4320, 33, 17280, 4320, 17280, 33, 17280, 33, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 17280, 33, 33, 33, 33, 17280, 4320, 4320, 17280, 4320, 4320, 33, 4320, 17280, 4320, 33, 33, 4320, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 4320, 17280, 4320, 4320, 4320, 33, 17280, 33, 17280, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 33, 33, 17280, 4320, 17280, 4320, 17280, 4320, 33, 4320, 33, 33, 33, 17280, 17280, 4320, 4320, 33, 33, 4320, 33, 17280, 33, 33, 4320, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 4320, 17280, 4320, 33, 4320, 33, 17280, 4320, 4320, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 4320, 4320, 17280, 33, 17280, 33, 33, 33, 17280, 4320, 17280, 17280, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 17280, 33, 33, 4320, 33, 4320, 4320, 33, 17280, 17280, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2314698 . Total input tokens: 515493855 . Total output tokens: 462974761
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.8926543170236982,
    "estimated_duration": 3600.017471853761,
    "input_throughput": 3247.6403493618745,
    "output_throughput": 2873.383832404967,
    "total_throughput": 6121.024181766841,
    "itl": 117.55486418834339,
    "ttft": 2345277.910380278,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2245,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.536924763805882,
    "arrivals": 770785,
    "finished_requests": 47393,
    "scheduler_time": 82.81206109599803
}
#Debug simulation 
Total elapsed time: 3.892761410039384. Arrivals time: 0.18208432151004672 Scheduler time: 3.4420280978665687 Scheduler overhead time: 0.042989791254512966 Adapter cache time: 0.16135579423280433 Engine time: 0.04364283330505714 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-8/adapters_320_slots_192_rate_1.6-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-8/adapters_320_slots_192_rate_1.6-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 540, 17280, 17280, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 17280, 17280, 1080, 540, 540, 1080, 17280, 17280, 1080, 1080, 540, 540, 1080, 17280, 17280, 540, 17280, 1080, 540, 1080, 17280, 540, 1080, 17280, 17280, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 17280, 1080, 17280, 17280, 540, 17280, 540, 17280, 1080, 540, 540, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 540, 1080, 1080, 540, 17280, 1080, 17280, 17280, 1080, 540, 1080, 1080, 1080, 540, 17280, 1080, 17280, 540, 17280, 540, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 17280, 540, 540, 540, 540, 17280, 1080, 1080, 17280, 1080, 1080, 540, 1080, 17280, 1080, 540, 540, 1080, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 1080, 17280, 1080, 1080, 1080, 540, 17280, 540, 17280, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 540, 540, 17280, 1080, 17280, 1080, 17280, 1080, 540, 1080, 540, 540, 540, 17280, 17280, 1080, 1080, 540, 540, 1080, 540, 17280, 540, 540, 1080, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 1080, 17280, 1080, 540, 1080, 540, 17280, 1080, 1080, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 1080, 1080, 17280, 540, 17280, 540, 540, 540, 17280, 1080, 17280, 17280, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 17280, 540, 540, 1080, 540, 1080, 1080, 540, 17280, 17280, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2021760 . Total input tokens: 450245744 . Total output tokens: 404618148
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.197268531017471,
    "estimated_duration": 3600.106330584965,
    "input_throughput": 3903.751364398296,
    "output_throughput": 3431.62642032093,
    "total_throughput": 7335.377784719226,
    "itl": 248.9848976993966,
    "ttft": 2235897.5333100823,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2963,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.068225185272718,
    "arrivals": 673640,
    "finished_requests": 56736,
    "scheduler_time": 69.64481945617003
}
#Debug simulation 
Total elapsed time: 4.197374414012302. Arrivals time: 0.23962182726245373 Scheduler time: 3.8310996940126643 Scheduler overhead time: 0.022716377046890557 Adapter cache time: 0.07044148247223347 Engine time: 0.022902831435203552 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-16/adapters_320_slots_192_rate_1.6-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-16/adapters_320_slots_192_rate_1.6-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 540, 17280, 17280, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 17280, 17280, 1080, 540, 540, 1080, 17280, 17280, 1080, 1080, 540, 540, 1080, 17280, 17280, 540, 17280, 1080, 540, 1080, 17280, 540, 1080, 17280, 17280, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 17280, 1080, 17280, 17280, 540, 17280, 540, 17280, 1080, 540, 540, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 540, 1080, 1080, 540, 17280, 1080, 17280, 17280, 1080, 540, 1080, 1080, 1080, 540, 17280, 1080, 17280, 540, 17280, 540, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 17280, 540, 540, 540, 540, 17280, 1080, 1080, 17280, 1080, 1080, 540, 1080, 17280, 1080, 540, 540, 1080, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 1080, 17280, 1080, 1080, 1080, 540, 17280, 540, 17280, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 540, 540, 17280, 1080, 17280, 1080, 17280, 1080, 540, 1080, 540, 540, 540, 17280, 17280, 1080, 1080, 540, 540, 1080, 540, 17280, 540, 540, 1080, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 1080, 17280, 1080, 540, 1080, 540, 17280, 1080, 1080, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 1080, 1080, 17280, 540, 17280, 540, 540, 540, 17280, 1080, 17280, 17280, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 17280, 540, 540, 1080, 540, 1080, 1080, 540, 17280, 17280, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2021760 . Total input tokens: 450245744 . Total output tokens: 404618148
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.172781669010874,
    "estimated_duration": 3600.1710219566307,
    "input_throughput": 3903.0912460272766,
    "output_throughput": 3431.4558738062137,
    "total_throughput": 7334.547119833491,
    "itl": 246.3848677652247,
    "ttft": 2236372.801742551,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2972,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.70974904310652,
    "arrivals": 673640,
    "finished_requests": 56729,
    "scheduler_time": 69.84306776581741
}
#Debug simulation 
Total elapsed time: 4.1728673949837685. Arrivals time: 0.20035836950410157 Scheduler time: 3.844256960961502 Scheduler overhead time: 0.023049768700730056 Adapter cache time: 0.07139248470775783 Engine time: 0.023093818686902523 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-32/adapters_320_slots_192_rate_1.6-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-32/adapters_320_slots_192_rate_1.6-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 540, 17280, 17280, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 17280, 17280, 1080, 540, 540, 1080, 17280, 17280, 1080, 1080, 540, 540, 1080, 17280, 17280, 540, 17280, 1080, 540, 1080, 17280, 540, 1080, 17280, 17280, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 17280, 1080, 17280, 17280, 540, 17280, 540, 17280, 1080, 540, 540, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 540, 1080, 1080, 540, 17280, 1080, 17280, 17280, 1080, 540, 1080, 1080, 1080, 540, 17280, 1080, 17280, 540, 17280, 540, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 17280, 540, 540, 540, 540, 17280, 1080, 1080, 17280, 1080, 1080, 540, 1080, 17280, 1080, 540, 540, 1080, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 1080, 17280, 1080, 1080, 1080, 540, 17280, 540, 17280, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 540, 540, 17280, 1080, 17280, 1080, 17280, 1080, 540, 1080, 540, 540, 540, 17280, 17280, 1080, 1080, 540, 540, 1080, 540, 17280, 540, 540, 1080, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 1080, 17280, 1080, 540, 1080, 540, 17280, 1080, 1080, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 1080, 1080, 17280, 540, 17280, 540, 540, 540, 17280, 1080, 17280, 17280, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 17280, 540, 540, 1080, 540, 1080, 1080, 540, 17280, 17280, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2021760 . Total input tokens: 450245744 . Total output tokens: 404618148
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.078908871975727,
    "estimated_duration": 3600.0427045066176,
    "input_throughput": 3536.5197151862276,
    "output_throughput": 3131.2745223517886,
    "total_throughput": 6667.794237538016,
    "itl": 108.36381876782866,
    "ttft": 2300735.001432345,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2706,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.856297394707626,
    "arrivals": 673640,
    "finished_requests": 51471,
    "scheduler_time": 89.88997894143158
}
#Debug simulation 
Total elapsed time: 4.078993042989168. Arrivals time: 0.19111512508243322 Scheduler time: 3.637779071170371 Scheduler overhead time: 0.04666061792522669 Adapter cache time: 0.13350703491596505 Engine time: 0.04741358128376305 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-16-16/adapters_320_slots_192_rate_1.6-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-16-16/adapters_320_slots_192_rate_1.6-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 540, 17280, 17280, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 17280, 17280, 1080, 540, 540, 1080, 17280, 17280, 1080, 1080, 540, 540, 1080, 17280, 17280, 540, 17280, 1080, 540, 1080, 17280, 540, 1080, 17280, 17280, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 17280, 1080, 17280, 17280, 540, 17280, 540, 17280, 1080, 540, 540, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 540, 1080, 1080, 540, 17280, 1080, 17280, 17280, 1080, 540, 1080, 1080, 1080, 540, 17280, 1080, 17280, 540, 17280, 540, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 17280, 540, 540, 540, 540, 17280, 1080, 1080, 17280, 1080, 1080, 540, 1080, 17280, 1080, 540, 540, 1080, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 1080, 17280, 1080, 1080, 1080, 540, 17280, 540, 17280, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 540, 540, 17280, 1080, 17280, 1080, 17280, 1080, 540, 1080, 540, 540, 540, 17280, 17280, 1080, 1080, 540, 540, 1080, 540, 17280, 540, 540, 1080, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 1080, 17280, 1080, 540, 1080, 540, 17280, 1080, 1080, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 1080, 1080, 17280, 540, 17280, 540, 540, 540, 17280, 1080, 17280, 17280, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 17280, 540, 540, 1080, 540, 1080, 1080, 540, 17280, 17280, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2021760 . Total input tokens: 450245744 . Total output tokens: 404618148
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.1674253039527684,
    "estimated_duration": 3600.0349647645453,
    "input_throughput": 3903.5445870785056,
    "output_throughput": 3431.9822226526835,
    "total_throughput": 7335.526809731189,
    "itl": 246.3796987421119,
    "ttft": 2236239.1638812968,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2970,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.28577593175227,
    "arrivals": 673640,
    "finished_requests": 56733,
    "scheduler_time": 69.84688558831058
}
#Debug simulation 
Total elapsed time: 4.167510122002568. Arrivals time: 0.1994231216958724 Scheduler time: 3.8397868988104165 Scheduler overhead time: 0.022958217072300613 Adapter cache time: 0.07150698499754071 Engine time: 0.023134512943215668 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-16-32/adapters_320_slots_192_rate_1.6-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-16-32/adapters_320_slots_192_rate_1.6-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 540, 17280, 17280, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 17280, 17280, 1080, 540, 540, 1080, 17280, 17280, 1080, 1080, 540, 540, 1080, 17280, 17280, 540, 17280, 1080, 540, 1080, 17280, 540, 1080, 17280, 17280, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 17280, 1080, 17280, 17280, 540, 17280, 540, 17280, 1080, 540, 540, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 540, 1080, 1080, 540, 17280, 1080, 17280, 17280, 1080, 540, 1080, 1080, 1080, 540, 17280, 1080, 17280, 540, 17280, 540, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 17280, 540, 540, 540, 540, 17280, 1080, 1080, 17280, 1080, 1080, 540, 1080, 17280, 1080, 540, 540, 1080, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 1080, 17280, 1080, 1080, 1080, 540, 17280, 540, 17280, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 540, 540, 17280, 1080, 17280, 1080, 17280, 1080, 540, 1080, 540, 540, 540, 17280, 17280, 1080, 1080, 540, 540, 1080, 540, 17280, 540, 540, 1080, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 1080, 17280, 1080, 540, 1080, 540, 17280, 1080, 1080, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 1080, 1080, 17280, 540, 17280, 540, 540, 540, 17280, 1080, 17280, 17280, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 17280, 540, 540, 1080, 540, 1080, 1080, 540, 17280, 17280, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2021760 . Total input tokens: 450245744 . Total output tokens: 404618148
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.100086218037177,
    "estimated_duration": 3600.0406925737825,
    "input_throughput": 3536.521691619481,
    "output_throughput": 3131.2762723081264,
    "total_throughput": 6667.797963927607,
    "itl": 108.36755083537744,
    "ttft": 2300792.2487929994,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2706,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.974505953937468,
    "arrivals": 673640,
    "finished_requests": 51471,
    "scheduler_time": 89.88708741540776
}
#Debug simulation 
Total elapsed time: 4.100170637015253. Arrivals time: 0.23332042095717043 Scheduler time: 3.6180647523724474 Scheduler overhead time: 0.046327677730005234 Adapter cache time: 0.13317393307806924 Engine time: 0.047081122756935656 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_16-16-16/adapters_320_slots_192_rate_1.6-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_16-16-16/adapters_320_slots_192_rate_1.6-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 540, 17280, 17280, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 17280, 17280, 1080, 540, 540, 1080, 17280, 17280, 1080, 1080, 540, 540, 1080, 17280, 17280, 540, 17280, 1080, 540, 1080, 17280, 540, 1080, 17280, 17280, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 17280, 1080, 17280, 17280, 540, 17280, 540, 17280, 1080, 540, 540, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 540, 1080, 1080, 540, 17280, 1080, 17280, 17280, 1080, 540, 1080, 1080, 1080, 540, 17280, 1080, 17280, 540, 17280, 540, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 17280, 540, 540, 540, 540, 17280, 1080, 1080, 17280, 1080, 1080, 540, 1080, 17280, 1080, 540, 540, 1080, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 1080, 17280, 1080, 1080, 1080, 540, 17280, 540, 17280, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 540, 540, 17280, 1080, 17280, 1080, 17280, 1080, 540, 1080, 540, 540, 540, 17280, 17280, 1080, 1080, 540, 540, 1080, 540, 17280, 540, 540, 1080, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 1080, 17280, 1080, 540, 1080, 540, 17280, 1080, 1080, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 1080, 1080, 17280, 540, 17280, 540, 540, 540, 17280, 1080, 17280, 17280, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 17280, 540, 540, 1080, 540, 1080, 1080, 540, 17280, 17280, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2021760 . Total input tokens: 450245744 . Total output tokens: 404618148
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.188486629049294,
    "estimated_duration": 3600.2336366223044,
    "input_throughput": 3904.163012372462,
    "output_throughput": 3432.3447440465047,
    "total_throughput": 7336.507756418967,
    "itl": 246.32125563520128,
    "ttft": 2236237.391691973,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2973,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.889419526744152,
    "arrivals": 673640,
    "finished_requests": 56743,
    "scheduler_time": 69.8609737364149
}
#Debug simulation 
Total elapsed time: 4.188581631053239. Arrivals time: 0.1995200586388819 Scheduler time: 3.860851484176237 Scheduler overhead time: 0.023248214973136783 Adapter cache time: 0.07100585708394647 Engine time: 0.023210802115499973 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_16-16-32/adapters_320_slots_192_rate_1.6-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_16-16-32/adapters_320_slots_192_rate_1.6-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 540, 17280, 17280, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 17280, 17280, 1080, 540, 540, 1080, 17280, 17280, 1080, 1080, 540, 540, 1080, 17280, 17280, 540, 17280, 1080, 540, 1080, 17280, 540, 1080, 17280, 17280, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 17280, 1080, 17280, 17280, 540, 17280, 540, 17280, 1080, 540, 540, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 540, 1080, 1080, 540, 17280, 1080, 17280, 17280, 1080, 540, 1080, 1080, 1080, 540, 17280, 1080, 17280, 540, 17280, 540, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 17280, 540, 540, 540, 540, 17280, 1080, 1080, 17280, 1080, 1080, 540, 1080, 17280, 1080, 540, 540, 1080, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 1080, 17280, 1080, 1080, 1080, 540, 17280, 540, 17280, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 540, 540, 17280, 1080, 17280, 1080, 17280, 1080, 540, 1080, 540, 540, 540, 17280, 17280, 1080, 1080, 540, 540, 1080, 540, 17280, 540, 540, 1080, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 1080, 17280, 1080, 540, 1080, 540, 17280, 1080, 1080, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 1080, 1080, 17280, 540, 17280, 540, 540, 540, 17280, 1080, 17280, 17280, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 17280, 540, 540, 1080, 540, 1080, 1080, 540, 17280, 17280, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2021760 . Total input tokens: 450245744 . Total output tokens: 404618148
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.0412350060069,
    "estimated_duration": 3600.033576905128,
    "input_throughput": 3536.437015941618,
    "output_throughput": 3130.981630924117,
    "total_throughput": 6667.418646865734,
    "itl": 108.37039245400219,
    "ttft": 2300827.122464711,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2706,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.08768436171071,
    "arrivals": 673640,
    "finished_requests": 51468,
    "scheduler_time": 89.88421206885862
}
#Debug simulation 
Total elapsed time: 4.041322856966872. Arrivals time: 0.18715533218346536 Scheduler time: 3.6051682179095224 Scheduler overhead time: 0.046452971058897674 Adapter cache time: 0.13330179447075352 Engine time: 0.047010726120788604 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-8/adapters_320_slots_192_rate_1.6-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-8/adapters_320_slots_192_rate_1.6-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 270, 17280, 17280, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 17280, 17280, 1080, 270, 270, 1080, 17280, 17280, 1080, 1080, 270, 270, 1080, 17280, 17280, 270, 17280, 1080, 270, 1080, 17280, 270, 1080, 17280, 17280, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 17280, 1080, 17280, 17280, 270, 17280, 270, 17280, 1080, 270, 270, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 270, 1080, 1080, 270, 17280, 1080, 17280, 17280, 1080, 270, 1080, 1080, 1080, 270, 17280, 1080, 17280, 270, 17280, 270, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 17280, 270, 270, 270, 270, 17280, 1080, 1080, 17280, 1080, 1080, 270, 1080, 17280, 1080, 270, 270, 1080, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 1080, 17280, 1080, 1080, 1080, 270, 17280, 270, 17280, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 270, 270, 17280, 1080, 17280, 1080, 17280, 1080, 270, 1080, 270, 270, 270, 17280, 17280, 1080, 1080, 270, 270, 1080, 270, 17280, 270, 270, 1080, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 1080, 17280, 1080, 270, 1080, 270, 17280, 1080, 1080, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 1080, 1080, 17280, 270, 17280, 270, 270, 270, 17280, 1080, 17280, 17280, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 17280, 270, 270, 1080, 270, 1080, 1080, 270, 17280, 17280, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1993140 . Total input tokens: 443958301 . Total output tokens: 398929590
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.364910685049836,
    "estimated_duration": 3600.0380972210087,
    "input_throughput": 4048.313547362243,
    "output_throughput": 3576.3268755235067,
    "total_throughput": 7624.640422885749,
    "itl": 239.45202132009751,
    "ttft": 2211528.259246212,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2219,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.791222303786981,
    "arrivals": 664253,
    "finished_requests": 59413,
    "scheduler_time": 72.54565654693191
}
#Debug simulation 
Total elapsed time: 4.365012568014208. Arrivals time: 0.20632734143873677 Scheduler time: 4.038034361205064 Scheduler overhead time: 0.02375412918627262 Adapter cache time: 0.062248847854789346 Engine time: 0.023646491405088454 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-16/adapters_320_slots_192_rate_1.6-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-16/adapters_320_slots_192_rate_1.6-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 270, 17280, 17280, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 17280, 17280, 1080, 270, 270, 1080, 17280, 17280, 1080, 1080, 270, 270, 1080, 17280, 17280, 270, 17280, 1080, 270, 1080, 17280, 270, 1080, 17280, 17280, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 17280, 1080, 17280, 17280, 270, 17280, 270, 17280, 1080, 270, 270, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 270, 1080, 1080, 270, 17280, 1080, 17280, 17280, 1080, 270, 1080, 1080, 1080, 270, 17280, 1080, 17280, 270, 17280, 270, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 17280, 270, 270, 270, 270, 17280, 1080, 1080, 17280, 1080, 1080, 270, 1080, 17280, 1080, 270, 270, 1080, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 1080, 17280, 1080, 1080, 1080, 270, 17280, 270, 17280, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 270, 270, 17280, 1080, 17280, 1080, 17280, 1080, 270, 1080, 270, 270, 270, 17280, 17280, 1080, 1080, 270, 270, 1080, 270, 17280, 270, 270, 1080, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 1080, 17280, 1080, 270, 1080, 270, 17280, 1080, 1080, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 1080, 1080, 17280, 270, 17280, 270, 270, 270, 17280, 1080, 17280, 17280, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 17280, 270, 270, 1080, 270, 1080, 1080, 270, 17280, 17280, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1993140 . Total input tokens: 443958301 . Total output tokens: 398929590
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.309379533980973,
    "estimated_duration": 3600.0993962040243,
    "input_throughput": 4047.9421249774077,
    "output_throughput": 3576.4693090352425,
    "total_throughput": 7624.41143401265,
    "itl": 237.06181934903879,
    "ttft": 2212124.735890986,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2220,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.2520304182983795,
    "arrivals": 664253,
    "finished_requests": 59402,
    "scheduler_time": 72.73155300773973
}
#Debug simulation 
Total elapsed time: 4.309462739969604. Arrivals time: 0.20682171796215698 Scheduler time: 3.980887606041506 Scheduler overhead time: 0.02393797697732225 Adapter cache time: 0.0627197713474743 Engine time: 0.02398642897605896 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-32/adapters_320_slots_192_rate_1.6-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-32/adapters_320_slots_192_rate_1.6-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 270, 17280, 17280, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 17280, 17280, 1080, 270, 270, 1080, 17280, 17280, 1080, 1080, 270, 270, 1080, 17280, 17280, 270, 17280, 1080, 270, 1080, 17280, 270, 1080, 17280, 17280, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 17280, 1080, 17280, 17280, 270, 17280, 270, 17280, 1080, 270, 270, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 270, 1080, 1080, 270, 17280, 1080, 17280, 17280, 1080, 270, 1080, 1080, 1080, 270, 17280, 1080, 17280, 270, 17280, 270, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 17280, 270, 270, 270, 270, 17280, 1080, 1080, 17280, 1080, 1080, 270, 1080, 17280, 1080, 270, 270, 1080, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 1080, 17280, 1080, 1080, 1080, 270, 17280, 270, 17280, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 270, 270, 17280, 1080, 17280, 1080, 17280, 1080, 270, 1080, 270, 270, 270, 17280, 17280, 1080, 1080, 270, 270, 1080, 270, 17280, 270, 270, 1080, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 1080, 17280, 1080, 270, 1080, 270, 17280, 1080, 1080, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 1080, 1080, 17280, 270, 17280, 270, 270, 270, 17280, 1080, 17280, 17280, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 17280, 270, 270, 1080, 270, 1080, 1080, 270, 17280, 17280, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1993140 . Total input tokens: 443958301 . Total output tokens: 398929590
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.158019731985405,
    "estimated_duration": 3600.092057790859,
    "input_throughput": 3605.4411364038638,
    "output_throughput": 3206.175790705445,
    "total_throughput": 6811.616927109309,
    "itl": 106.09228949130629,
    "ttft": 2281937.8228473426,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1987,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.500395337659818,
    "arrivals": 664253,
    "finished_requests": 52909,
    "scheduler_time": 91.93759243483534
}
#Debug simulation 
Total elapsed time: 4.15810188598698. Arrivals time: 0.23259164713090286 Scheduler time: 3.6898737614392303 Scheduler overhead time: 0.04729508829768747 Adapter cache time: 0.11736559821292758 Engine time: 0.048211444984190166 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-16-16/adapters_320_slots_192_rate_1.6-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-16-16/adapters_320_slots_192_rate_1.6-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 270, 17280, 17280, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 17280, 17280, 1080, 270, 270, 1080, 17280, 17280, 1080, 1080, 270, 270, 1080, 17280, 17280, 270, 17280, 1080, 270, 1080, 17280, 270, 1080, 17280, 17280, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 17280, 1080, 17280, 17280, 270, 17280, 270, 17280, 1080, 270, 270, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 270, 1080, 1080, 270, 17280, 1080, 17280, 17280, 1080, 270, 1080, 1080, 1080, 270, 17280, 1080, 17280, 270, 17280, 270, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 17280, 270, 270, 270, 270, 17280, 1080, 1080, 17280, 1080, 1080, 270, 1080, 17280, 1080, 270, 270, 1080, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 1080, 17280, 1080, 1080, 1080, 270, 17280, 270, 17280, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 270, 270, 17280, 1080, 17280, 1080, 17280, 1080, 270, 1080, 270, 270, 270, 17280, 17280, 1080, 1080, 270, 270, 1080, 270, 17280, 270, 270, 1080, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 1080, 17280, 1080, 270, 1080, 270, 17280, 1080, 1080, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 1080, 1080, 17280, 270, 17280, 270, 270, 270, 17280, 1080, 17280, 17280, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 17280, 270, 270, 1080, 270, 1080, 1080, 270, 17280, 17280, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1993140 . Total input tokens: 443958301 . Total output tokens: 398929590
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.3218718789867125,
    "estimated_duration": 3600.032371024506,
    "input_throughput": 4048.1369326833747,
    "output_throughput": 3576.6172836761834,
    "total_throughput": 7624.754216359558,
    "itl": 237.02547720461934,
    "ttft": 2212059.9912924995,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2223,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.939844648889027,
    "arrivals": 664253,
    "finished_requests": 59404,
    "scheduler_time": 72.73709799908276
}
#Debug simulation 
Total elapsed time: 4.321957245992962. Arrivals time: 0.20686812745407224 Scheduler time: 3.9934743746416643 Scheduler overhead time: 0.023959835525602102 Adapter cache time: 0.06246312893927097 Engine time: 0.024075100722257048 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-16-32/adapters_320_slots_192_rate_1.6-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-16-32/adapters_320_slots_192_rate_1.6-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 270, 17280, 17280, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 17280, 17280, 1080, 270, 270, 1080, 17280, 17280, 1080, 1080, 270, 270, 1080, 17280, 17280, 270, 17280, 1080, 270, 1080, 17280, 270, 1080, 17280, 17280, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 17280, 1080, 17280, 17280, 270, 17280, 270, 17280, 1080, 270, 270, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 270, 1080, 1080, 270, 17280, 1080, 17280, 17280, 1080, 270, 1080, 1080, 1080, 270, 17280, 1080, 17280, 270, 17280, 270, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 17280, 270, 270, 270, 270, 17280, 1080, 1080, 17280, 1080, 1080, 270, 1080, 17280, 1080, 270, 270, 1080, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 1080, 17280, 1080, 1080, 1080, 270, 17280, 270, 17280, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 270, 270, 17280, 1080, 17280, 1080, 17280, 1080, 270, 1080, 270, 270, 270, 17280, 17280, 1080, 1080, 270, 270, 1080, 270, 17280, 270, 270, 1080, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 1080, 17280, 1080, 270, 1080, 270, 17280, 1080, 1080, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 1080, 1080, 17280, 270, 17280, 270, 270, 270, 17280, 1080, 17280, 17280, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 17280, 270, 270, 1080, 270, 1080, 1080, 270, 17280, 17280, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1993140 . Total input tokens: 443958301 . Total output tokens: 398929590
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.159930669004098,
    "estimated_duration": 3600.065178770673,
    "input_throughput": 3604.992230843919,
    "output_throughput": 3205.8589016827327,
    "total_throughput": 6810.851132526652,
    "itl": 106.10024707322954,
    "ttft": 2281963.8015361913,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1984,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.578366429041948,
    "arrivals": 664253,
    "finished_requests": 52903,
    "scheduler_time": 91.93272748244632
}
#Debug simulation 
Total elapsed time: 4.160011485975701. Arrivals time: 0.23012445465428755 Scheduler time: 3.6915395514224656 Scheduler overhead time: 0.047358385170809925 Adapter cache time: 0.12025802134303376 Engine time: 0.048103571170940995 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_16-16-16/adapters_320_slots_192_rate_1.6-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_16-16-16/adapters_320_slots_192_rate_1.6-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 270, 17280, 17280, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 17280, 17280, 1080, 270, 270, 1080, 17280, 17280, 1080, 1080, 270, 270, 1080, 17280, 17280, 270, 17280, 1080, 270, 1080, 17280, 270, 1080, 17280, 17280, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 17280, 1080, 17280, 17280, 270, 17280, 270, 17280, 1080, 270, 270, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 270, 1080, 1080, 270, 17280, 1080, 17280, 17280, 1080, 270, 1080, 1080, 1080, 270, 17280, 1080, 17280, 270, 17280, 270, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 17280, 270, 270, 270, 270, 17280, 1080, 1080, 17280, 1080, 1080, 270, 1080, 17280, 1080, 270, 270, 1080, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 1080, 17280, 1080, 1080, 1080, 270, 17280, 270, 17280, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 270, 270, 17280, 1080, 17280, 1080, 17280, 1080, 270, 1080, 270, 270, 270, 17280, 17280, 1080, 1080, 270, 270, 1080, 270, 17280, 270, 270, 1080, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 1080, 17280, 1080, 270, 1080, 270, 17280, 1080, 1080, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 1080, 1080, 17280, 270, 17280, 270, 270, 270, 17280, 1080, 17280, 17280, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 17280, 270, 270, 1080, 270, 1080, 1080, 270, 17280, 17280, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1993140 . Total input tokens: 443958301 . Total output tokens: 398929590
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.355893064988777,
    "estimated_duration": 3600.0447834506645,
    "input_throughput": 4048.9149098941357,
    "output_throughput": 3577.3585537610275,
    "total_throughput": 7626.273463655163,
    "itl": 237.02035422369002,
    "ttft": 2211998.0545712616,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2221,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.640901704977533,
    "arrivals": 664253,
    "finished_requests": 59413,
    "scheduler_time": 72.74248528537247
}
#Debug simulation 
Total elapsed time: 4.355981194006745. Arrivals time: 0.2091918573132716 Scheduler time: 4.024676620145328 Scheduler overhead time: 0.02407669834792614 Adapter cache time: 0.06255863461410627 Engine time: 0.024192735785618424 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_16-16-32/adapters_320_slots_192_rate_1.6-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_16-16-32/adapters_320_slots_192_rate_1.6-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 270, 17280, 17280, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 17280, 17280, 1080, 270, 270, 1080, 17280, 17280, 1080, 1080, 270, 270, 1080, 17280, 17280, 270, 17280, 1080, 270, 1080, 17280, 270, 1080, 17280, 17280, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 17280, 1080, 17280, 17280, 270, 17280, 270, 17280, 1080, 270, 270, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 270, 1080, 1080, 270, 17280, 1080, 17280, 17280, 1080, 270, 1080, 1080, 1080, 270, 17280, 1080, 17280, 270, 17280, 270, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 17280, 270, 270, 270, 270, 17280, 1080, 1080, 17280, 1080, 1080, 270, 1080, 17280, 1080, 270, 270, 1080, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 1080, 17280, 1080, 1080, 1080, 270, 17280, 270, 17280, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 270, 270, 17280, 1080, 17280, 1080, 17280, 1080, 270, 1080, 270, 270, 270, 17280, 17280, 1080, 1080, 270, 270, 1080, 270, 17280, 270, 270, 1080, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 1080, 17280, 1080, 270, 1080, 270, 17280, 1080, 1080, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 1080, 1080, 17280, 270, 17280, 270, 270, 270, 17280, 1080, 17280, 17280, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 17280, 270, 270, 1080, 270, 1080, 1080, 270, 17280, 17280, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1993140 . Total input tokens: 443958301 . Total output tokens: 398929590
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.182226839009672,
    "estimated_duration": 3600.0140573235376,
    "input_throughput": 3604.9789787900413,
    "output_throughput": 3205.817481885126,
    "total_throughput": 6810.7964606751675,
    "itl": 106.10714263648732,
    "ttft": 2281902.970077968,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1984,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.658763112425605,
    "arrivals": 664253,
    "finished_requests": 52902,
    "scheduler_time": 91.92832326116813
}
#Debug simulation 
Total elapsed time: 4.182309928000905. Arrivals time: 0.2315410624141805 Scheduler time: 3.712861236941535 Scheduler overhead time: 0.047478078689891845 Adapter cache time: 0.11942990677198395 Engine time: 0.04826754459645599 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-8/adapters_320_slots_192_rate_1.6-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-8/adapters_320_slots_192_rate_1.6-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 135, 17280, 17280, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 17280, 17280, 1080, 135, 135, 1080, 17280, 17280, 1080, 1080, 135, 135, 1080, 17280, 17280, 135, 17280, 1080, 135, 1080, 17280, 135, 1080, 17280, 17280, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 17280, 1080, 17280, 17280, 135, 17280, 135, 17280, 1080, 135, 135, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 135, 1080, 1080, 135, 17280, 1080, 17280, 17280, 1080, 135, 1080, 1080, 1080, 135, 17280, 1080, 17280, 135, 17280, 135, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 17280, 135, 135, 135, 135, 17280, 1080, 1080, 17280, 1080, 1080, 135, 1080, 17280, 1080, 135, 135, 1080, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 1080, 17280, 1080, 1080, 1080, 135, 17280, 135, 17280, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 135, 135, 17280, 1080, 17280, 1080, 17280, 1080, 135, 1080, 135, 135, 135, 17280, 17280, 1080, 1080, 135, 135, 1080, 135, 17280, 135, 135, 1080, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 1080, 17280, 1080, 135, 1080, 135, 17280, 1080, 1080, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 1080, 1080, 17280, 135, 17280, 135, 135, 135, 17280, 1080, 17280, 17280, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 17280, 135, 135, 1080, 135, 1080, 1080, 135, 17280, 17280, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1978830 . Total input tokens: 440734472 . Total output tokens: 396088724
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.404390999989118,
    "estimated_duration": 3600.1761166733295,
    "input_throughput": 4150.496952301138,
    "output_throughput": 3666.306472861276,
    "total_throughput": 7816.803425162414,
    "itl": 234.17788386882842,
    "ttft": 2201918.1915614605,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1658,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.074288679440646,
    "arrivals": 659440,
    "finished_requests": 60410,
    "scheduler_time": 74.31587050675982
}
#Debug simulation 
Total elapsed time: 4.404478648968507. Arrivals time: 0.20821028150385246 Scheduler time: 4.081486151844729 Scheduler overhead time: 0.024308068677783012 Adapter cache time: 0.05472458485746756 Engine time: 0.02450185886118561 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-16/adapters_320_slots_192_rate_1.6-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-16/adapters_320_slots_192_rate_1.6-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 135, 17280, 17280, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 17280, 17280, 1080, 135, 135, 1080, 17280, 17280, 1080, 1080, 135, 135, 1080, 17280, 17280, 135, 17280, 1080, 135, 1080, 17280, 135, 1080, 17280, 17280, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 17280, 1080, 17280, 17280, 135, 17280, 135, 17280, 1080, 135, 135, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 135, 1080, 1080, 135, 17280, 1080, 17280, 17280, 1080, 135, 1080, 1080, 1080, 135, 17280, 1080, 17280, 135, 17280, 135, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 17280, 135, 135, 135, 135, 17280, 1080, 1080, 17280, 1080, 1080, 135, 1080, 17280, 1080, 135, 135, 1080, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 1080, 17280, 1080, 1080, 1080, 135, 17280, 135, 17280, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 135, 135, 17280, 1080, 17280, 1080, 17280, 1080, 135, 1080, 135, 135, 135, 17280, 17280, 1080, 1080, 135, 135, 1080, 135, 17280, 135, 135, 1080, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 1080, 17280, 1080, 135, 1080, 135, 17280, 1080, 1080, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 1080, 1080, 17280, 135, 17280, 135, 135, 135, 17280, 1080, 17280, 17280, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 17280, 135, 135, 1080, 135, 1080, 1080, 135, 17280, 17280, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1978830 . Total input tokens: 440734472 . Total output tokens: 396088724
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.396407576976344,
    "estimated_duration": 3600.006930323134,
    "input_throughput": 4148.743402185451,
    "output_throughput": 3664.497667735289,
    "total_throughput": 7813.241069920739,
    "itl": 231.27537507508012,
    "ttft": 2202186.7884189608,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1657,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.399065045115884,
    "arrivals": 659440,
    "finished_requests": 60372,
    "scheduler_time": 74.54013085696239
}
#Debug simulation 
Total elapsed time: 4.396508531994186. Arrivals time: 0.20635820628376678 Scheduler time: 4.074310621712357 Scheduler overhead time: 0.024424446804914623 Adapter cache time: 0.05554784130072221 Engine time: 0.024470843258313835 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-32/adapters_320_slots_192_rate_1.6-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-32/adapters_320_slots_192_rate_1.6-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 135, 17280, 17280, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 17280, 17280, 1080, 135, 135, 1080, 17280, 17280, 1080, 1080, 135, 135, 1080, 17280, 17280, 135, 17280, 1080, 135, 1080, 17280, 135, 1080, 17280, 17280, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 17280, 1080, 17280, 17280, 135, 17280, 135, 17280, 1080, 135, 135, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 135, 1080, 1080, 135, 17280, 1080, 17280, 17280, 1080, 135, 1080, 1080, 1080, 135, 17280, 1080, 17280, 135, 17280, 135, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 17280, 135, 135, 135, 135, 17280, 1080, 1080, 17280, 1080, 1080, 135, 1080, 17280, 1080, 135, 135, 1080, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 1080, 17280, 1080, 1080, 1080, 135, 17280, 135, 17280, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 135, 135, 17280, 1080, 17280, 1080, 17280, 1080, 135, 1080, 135, 135, 135, 17280, 17280, 1080, 1080, 135, 135, 1080, 135, 17280, 135, 135, 1080, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 1080, 17280, 1080, 135, 1080, 135, 17280, 1080, 1080, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 1080, 1080, 17280, 135, 17280, 135, 135, 135, 17280, 1080, 17280, 17280, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 17280, 135, 135, 1080, 135, 1080, 1080, 135, 17280, 17280, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1978830 . Total input tokens: 440734472 . Total output tokens: 396088724
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.8310295289848,
    "estimated_duration": 3600.056514895414,
    "input_throughput": 3645.110276937202,
    "output_throughput": 3239.4933112150898,
    "total_throughput": 6884.603588152292,
    "itl": 104.71141870981454,
    "ttft": 2282121.5494855754,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1486,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.8538460488989355,
    "arrivals": 659440,
    "finished_requests": 53119,
    "scheduler_time": 93.05198949138436
}
#Debug simulation 
Total elapsed time: 4.83112644701032. Arrivals time: 0.2320174400229007 Scheduler time: 4.3667878931737505 Scheduler overhead time: 0.048433246673084795 Adapter cache time: 0.1114138457342051 Engine time: 0.04906250012572855 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-16/adapters_320_slots_192_rate_1.6-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-16/adapters_320_slots_192_rate_1.6-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 135, 17280, 17280, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 17280, 17280, 1080, 135, 135, 1080, 17280, 17280, 1080, 1080, 135, 135, 1080, 17280, 17280, 135, 17280, 1080, 135, 1080, 17280, 135, 1080, 17280, 17280, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 17280, 1080, 17280, 17280, 135, 17280, 135, 17280, 1080, 135, 135, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 135, 1080, 1080, 135, 17280, 1080, 17280, 17280, 1080, 135, 1080, 1080, 1080, 135, 17280, 1080, 17280, 135, 17280, 135, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 17280, 135, 135, 135, 135, 17280, 1080, 1080, 17280, 1080, 1080, 135, 1080, 17280, 1080, 135, 135, 1080, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 1080, 17280, 1080, 1080, 1080, 135, 17280, 135, 17280, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 135, 135, 17280, 1080, 17280, 1080, 17280, 1080, 135, 1080, 135, 135, 135, 17280, 17280, 1080, 1080, 135, 135, 1080, 135, 17280, 135, 135, 1080, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 1080, 17280, 1080, 135, 1080, 135, 17280, 1080, 1080, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 1080, 1080, 17280, 135, 17280, 135, 135, 135, 17280, 1080, 17280, 17280, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 17280, 135, 135, 1080, 135, 1080, 1080, 135, 17280, 17280, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1978830 . Total input tokens: 440734472 . Total output tokens: 396088724
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.381661154970061,
    "estimated_duration": 3600.0337203689282,
    "input_throughput": 4148.951693282844,
    "output_throughput": 3665.048170339877,
    "total_throughput": 7813.99986362272,
    "itl": 231.26185563818098,
    "ttft": 2202150.525405602,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1657,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.171477452744608,
    "arrivals": 659440,
    "finished_requests": 60379,
    "scheduler_time": 74.54530889117511
}
#Debug simulation 
Total elapsed time: 4.381746546947397. Arrivals time: 0.20756974932737648 Scheduler time: 4.058319279691204 Scheduler overhead time: 0.024373834137804806 Adapter cache time: 0.05565787706291303 Engine time: 0.02452115248888731 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-32/adapters_320_slots_192_rate_1.6-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-32/adapters_320_slots_192_rate_1.6-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 135, 17280, 17280, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 17280, 17280, 1080, 135, 135, 1080, 17280, 17280, 1080, 1080, 135, 135, 1080, 17280, 17280, 135, 17280, 1080, 135, 1080, 17280, 135, 1080, 17280, 17280, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 17280, 1080, 17280, 17280, 135, 17280, 135, 17280, 1080, 135, 135, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 135, 1080, 1080, 135, 17280, 1080, 17280, 17280, 1080, 135, 1080, 1080, 1080, 135, 17280, 1080, 17280, 135, 17280, 135, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 17280, 135, 135, 135, 135, 17280, 1080, 1080, 17280, 1080, 1080, 135, 1080, 17280, 1080, 135, 135, 1080, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 1080, 17280, 1080, 1080, 1080, 135, 17280, 135, 17280, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 135, 135, 17280, 1080, 17280, 1080, 17280, 1080, 135, 1080, 135, 135, 135, 17280, 17280, 1080, 1080, 135, 135, 1080, 135, 17280, 135, 135, 1080, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 1080, 17280, 1080, 135, 1080, 135, 17280, 1080, 1080, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 1080, 1080, 17280, 135, 17280, 135, 135, 135, 17280, 1080, 17280, 17280, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 17280, 135, 135, 1080, 135, 1080, 1080, 135, 17280, 17280, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1978830 . Total input tokens: 440734472 . Total output tokens: 396088724
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.156721281004138,
    "estimated_duration": 3600.0078711728042,
    "input_throughput": 3645.1417523498253,
    "output_throughput": 3239.4895837271356,
    "total_throughput": 6884.631336076961,
    "itl": 104.71308972158175,
    "ttft": 2282147.9880094244,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1486,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.915591158028653,
    "arrivals": 659440,
    "finished_requests": 53118,
    "scheduler_time": 93.04916374264798
}
#Debug simulation 
Total elapsed time: 4.156802926037926. Arrivals time: 0.19390945695340633 Scheduler time: 3.731773959589191 Scheduler overhead time: 0.04790214292006567 Adapter cache time: 0.11130151053657755 Engine time: 0.048872645827941597 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-16/adapters_320_slots_192_rate_1.6-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-16/adapters_320_slots_192_rate_1.6-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 135, 17280, 17280, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 17280, 17280, 1080, 135, 135, 1080, 17280, 17280, 1080, 1080, 135, 135, 1080, 17280, 17280, 135, 17280, 1080, 135, 1080, 17280, 135, 1080, 17280, 17280, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 17280, 1080, 17280, 17280, 135, 17280, 135, 17280, 1080, 135, 135, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 135, 1080, 1080, 135, 17280, 1080, 17280, 17280, 1080, 135, 1080, 1080, 1080, 135, 17280, 1080, 17280, 135, 17280, 135, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 17280, 135, 135, 135, 135, 17280, 1080, 1080, 17280, 1080, 1080, 135, 1080, 17280, 1080, 135, 135, 1080, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 1080, 17280, 1080, 1080, 1080, 135, 17280, 135, 17280, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 135, 135, 17280, 1080, 17280, 1080, 17280, 1080, 135, 1080, 135, 135, 135, 17280, 17280, 1080, 1080, 135, 135, 1080, 135, 17280, 135, 135, 1080, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 1080, 17280, 1080, 135, 1080, 135, 17280, 1080, 1080, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 1080, 1080, 17280, 135, 17280, 135, 135, 135, 17280, 1080, 17280, 17280, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 17280, 135, 135, 1080, 135, 1080, 1080, 135, 17280, 17280, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1978830 . Total input tokens: 440734472 . Total output tokens: 396088724
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.543211158015765,
    "estimated_duration": 3600.070259158612,
    "input_throughput": 4149.055414127102,
    "output_throughput": 3665.3965200901443,
    "total_throughput": 7814.451934217247,
    "itl": 231.24979975360807,
    "ttft": 2202167.256609279,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1657,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.954513338652766,
    "arrivals": 659440,
    "finished_requests": 60382,
    "scheduler_time": 74.55045987126378
}
#Debug simulation 
Total elapsed time: 4.543291655019857. Arrivals time: 0.2486557083320804 Scheduler time: 4.178237069398165 Scheduler overhead time: 0.02477827074471861 Adapter cache time: 0.055601742467842996 Engine time: 0.024639287788886577 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-32/adapters_320_slots_192_rate_1.6-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-32/adapters_320_slots_192_rate_1.6-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 135, 17280, 17280, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 17280, 17280, 1080, 135, 135, 1080, 17280, 17280, 1080, 1080, 135, 135, 1080, 17280, 17280, 135, 17280, 1080, 135, 1080, 17280, 135, 1080, 17280, 17280, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 17280, 1080, 17280, 17280, 135, 17280, 135, 17280, 1080, 135, 135, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 135, 1080, 1080, 135, 17280, 1080, 17280, 17280, 1080, 135, 1080, 1080, 1080, 135, 17280, 1080, 17280, 135, 17280, 135, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 17280, 135, 135, 135, 135, 17280, 1080, 1080, 17280, 1080, 1080, 135, 1080, 17280, 1080, 135, 135, 1080, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 1080, 17280, 1080, 1080, 1080, 135, 17280, 135, 17280, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 135, 135, 17280, 1080, 17280, 1080, 17280, 1080, 135, 1080, 135, 135, 135, 17280, 17280, 1080, 1080, 135, 135, 1080, 135, 17280, 135, 135, 1080, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 1080, 17280, 1080, 135, 1080, 135, 17280, 1080, 1080, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 1080, 1080, 17280, 135, 17280, 135, 135, 135, 17280, 1080, 17280, 17280, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 17280, 135, 135, 1080, 135, 1080, 1080, 135, 17280, 17280, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1978830 . Total input tokens: 440734472 . Total output tokens: 396088724
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.1492537570302375,
    "estimated_duration": 3600.0697230414867,
    "input_throughput": 3645.0791261102413,
    "output_throughput": 3239.433926892756,
    "total_throughput": 6884.513053002997,
    "itl": 104.71494806132934,
    "ttft": 2282170.457813981,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1486,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.9773362671583525,
    "arrivals": 659440,
    "finished_requests": 53118,
    "scheduler_time": 93.04927050225731
}
#Debug simulation 
Total elapsed time: 4.1493384829955176. Arrivals time: 0.19197373586939648 Scheduler time: 3.7260210048989393 Scheduler overhead time: 0.04779330635210499 Adapter cache time: 0.11191020952537656 Engine time: 0.048671282769646496 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-8/adapters_320_slots_192_rate_1.6-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-8/adapters_320_slots_192_rate_1.6-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 66, 17280, 17280, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 17280, 17280, 1080, 66, 66, 1080, 17280, 17280, 1080, 1080, 66, 66, 1080, 17280, 17280, 66, 17280, 1080, 66, 1080, 17280, 66, 1080, 17280, 17280, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 17280, 1080, 17280, 17280, 66, 17280, 66, 17280, 1080, 66, 66, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 66, 1080, 1080, 66, 17280, 1080, 17280, 17280, 1080, 66, 1080, 1080, 1080, 66, 17280, 1080, 17280, 66, 17280, 66, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 17280, 66, 66, 66, 66, 17280, 1080, 1080, 17280, 1080, 1080, 66, 1080, 17280, 1080, 66, 66, 1080, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 1080, 17280, 1080, 1080, 1080, 66, 17280, 66, 17280, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 66, 66, 17280, 1080, 17280, 1080, 17280, 1080, 66, 1080, 66, 66, 66, 17280, 17280, 1080, 1080, 66, 66, 1080, 66, 17280, 66, 66, 1080, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 1080, 17280, 1080, 66, 1080, 66, 17280, 1080, 1080, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 1080, 1080, 17280, 66, 17280, 66, 66, 66, 17280, 1080, 17280, 17280, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 17280, 66, 66, 1080, 66, 1080, 1080, 66, 17280, 17280, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1971516 . Total input tokens: 439087091 . Total output tokens: 394634127
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.459927135962062,
    "estimated_duration": 3600.121806853963,
    "input_throughput": 4175.0762353052005,
    "output_throughput": 3671.329946347049,
    "total_throughput": 7846.40618165225,
    "itl": 232.83522796652252,
    "ttft": 2191969.3541038516,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1377,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.214291623395512,
    "arrivals": 657053,
    "finished_requests": 60699,
    "scheduler_time": 74.44331092737218
}
#Debug simulation 
Total elapsed time: 4.460014177951962. Arrivals time: 0.21128025196958333 Scheduler time: 4.135036309540737 Scheduler overhead time: 0.02435207727830857 Adapter cache time: 0.053568352945148945 Engine time: 0.02451654727337882 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-16/adapters_320_slots_192_rate_1.6-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-16/adapters_320_slots_192_rate_1.6-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 66, 17280, 17280, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 17280, 17280, 1080, 66, 66, 1080, 17280, 17280, 1080, 1080, 66, 66, 1080, 17280, 17280, 66, 17280, 1080, 66, 1080, 17280, 66, 1080, 17280, 17280, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 17280, 1080, 17280, 17280, 66, 17280, 66, 17280, 1080, 66, 66, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 66, 1080, 1080, 66, 17280, 1080, 17280, 17280, 1080, 66, 1080, 1080, 1080, 66, 17280, 1080, 17280, 66, 17280, 66, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 17280, 66, 66, 66, 66, 17280, 1080, 1080, 17280, 1080, 1080, 66, 1080, 17280, 1080, 66, 66, 1080, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 1080, 17280, 1080, 1080, 1080, 66, 17280, 66, 17280, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 66, 66, 17280, 1080, 17280, 1080, 17280, 1080, 66, 1080, 66, 66, 66, 17280, 17280, 1080, 1080, 66, 66, 1080, 66, 17280, 66, 66, 1080, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 1080, 17280, 1080, 66, 1080, 66, 17280, 1080, 1080, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 1080, 1080, 17280, 66, 17280, 66, 66, 66, 17280, 1080, 17280, 17280, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 17280, 66, 66, 1080, 66, 1080, 1080, 66, 17280, 17280, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1971516 . Total input tokens: 439087091 . Total output tokens: 394634127
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.40108689799672,
    "estimated_duration": 3600.0356531088228,
    "input_throughput": 4173.079782425664,
    "output_throughput": 3669.47865879946,
    "total_throughput": 7842.558441225124,
    "itl": 230.3276253798607,
    "ttft": 2192612.64102065,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1373,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.4910530355083385,
    "arrivals": 657053,
    "finished_requests": 60667,
    "scheduler_time": 74.63067443967796
}
#Debug simulation 
Total elapsed time: 4.401177413004916. Arrivals time: 0.21146203757962212 Scheduler time: 4.075612125976477 Scheduler overhead time: 0.024447321833577007 Adapter cache time: 0.05373996531125158 Engine time: 0.024595155380666256 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-32/adapters_320_slots_192_rate_1.6-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-32/adapters_320_slots_192_rate_1.6-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 66, 17280, 17280, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 17280, 17280, 1080, 66, 66, 1080, 17280, 17280, 1080, 1080, 66, 66, 1080, 17280, 17280, 66, 17280, 1080, 66, 1080, 17280, 66, 1080, 17280, 17280, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 17280, 1080, 17280, 17280, 66, 17280, 66, 17280, 1080, 66, 66, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 66, 1080, 1080, 66, 17280, 1080, 17280, 17280, 1080, 66, 1080, 1080, 1080, 66, 17280, 1080, 17280, 66, 17280, 66, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 17280, 66, 66, 66, 66, 17280, 1080, 1080, 17280, 1080, 1080, 66, 1080, 17280, 1080, 66, 66, 1080, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 1080, 17280, 1080, 1080, 1080, 66, 17280, 66, 17280, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 66, 66, 17280, 1080, 17280, 1080, 17280, 1080, 66, 1080, 66, 66, 66, 17280, 17280, 1080, 1080, 66, 66, 1080, 66, 17280, 66, 66, 1080, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 1080, 17280, 1080, 66, 1080, 66, 17280, 1080, 1080, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 1080, 1080, 17280, 66, 17280, 66, 66, 66, 17280, 1080, 17280, 17280, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 17280, 66, 66, 1080, 66, 1080, 1080, 66, 17280, 17280, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1971516 . Total input tokens: 439087091 . Total output tokens: 394634127
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.3927832759800367,
    "estimated_duration": 3600.071754133744,
    "input_throughput": 2929.311336056282,
    "output_throughput": 2590.348092171264,
    "total_throughput": 5519.659428227546,
    "itl": 82.61748930656962,
    "ttft": 2388916.717216146,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1004,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.286370210424027,
    "arrivals": 657053,
    "finished_requests": 42615,
    "scheduler_time": 95.84314002050124
}
#Debug simulation 
Total elapsed time: 3.3928811289952137. Arrivals time: 0.16681583528406918 Scheduler time: 3.0122990738018416 Scheduler overhead time: 0.0545761666726321 Adapter cache time: 0.08131570043042302 Engine time: 0.05234718008432537 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-16/adapters_320_slots_192_rate_1.6-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-16/adapters_320_slots_192_rate_1.6-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 66, 17280, 17280, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 17280, 17280, 1080, 66, 66, 1080, 17280, 17280, 1080, 1080, 66, 66, 1080, 17280, 17280, 66, 17280, 1080, 66, 1080, 17280, 66, 1080, 17280, 17280, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 17280, 1080, 17280, 17280, 66, 17280, 66, 17280, 1080, 66, 66, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 66, 1080, 1080, 66, 17280, 1080, 17280, 17280, 1080, 66, 1080, 1080, 1080, 66, 17280, 1080, 17280, 66, 17280, 66, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 17280, 66, 66, 66, 66, 17280, 1080, 1080, 17280, 1080, 1080, 66, 1080, 17280, 1080, 66, 66, 1080, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 1080, 17280, 1080, 1080, 1080, 66, 17280, 66, 17280, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 66, 66, 17280, 1080, 17280, 1080, 17280, 1080, 66, 1080, 66, 66, 66, 17280, 17280, 1080, 1080, 66, 66, 1080, 66, 17280, 66, 66, 1080, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 1080, 17280, 1080, 66, 1080, 66, 17280, 1080, 1080, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 1080, 1080, 17280, 66, 17280, 66, 66, 66, 17280, 1080, 17280, 17280, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 17280, 66, 66, 1080, 66, 1080, 1080, 66, 17280, 17280, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1971516 . Total input tokens: 439087091 . Total output tokens: 394634127
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.444178520003334,
    "estimated_duration": 3600.0925018695943,
    "input_throughput": 4173.264712558826,
    "output_throughput": 3669.800704603829,
    "total_throughput": 7843.065417162656,
    "itl": 230.31920524544762,
    "ttft": 2192585.75767208,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1373,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.292067115427858,
    "arrivals": 657053,
    "finished_requests": 60671,
    "scheduler_time": 74.63566554547263
}
#Debug simulation 
Total elapsed time: 4.4442618119646795. Arrivals time: 0.2107644642237574 Scheduler time: 4.118827401252929 Scheduler overhead time: 0.02462269621901214 Adapter cache time: 0.053792442893609405 Engine time: 0.02488432714017108 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-32/adapters_320_slots_192_rate_1.6-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-32/adapters_320_slots_192_rate_1.6-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 66, 17280, 17280, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 17280, 17280, 1080, 66, 66, 1080, 17280, 17280, 1080, 1080, 66, 66, 1080, 17280, 17280, 66, 17280, 1080, 66, 1080, 17280, 66, 1080, 17280, 17280, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 17280, 1080, 17280, 17280, 66, 17280, 66, 17280, 1080, 66, 66, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 66, 1080, 1080, 66, 17280, 1080, 17280, 17280, 1080, 66, 1080, 1080, 1080, 66, 17280, 1080, 17280, 66, 17280, 66, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 17280, 66, 66, 66, 66, 17280, 1080, 1080, 17280, 1080, 1080, 66, 1080, 17280, 1080, 66, 66, 1080, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 1080, 17280, 1080, 1080, 1080, 66, 17280, 66, 17280, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 66, 66, 17280, 1080, 17280, 1080, 17280, 1080, 66, 1080, 66, 66, 66, 17280, 17280, 1080, 1080, 66, 66, 1080, 66, 17280, 66, 66, 1080, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 1080, 17280, 1080, 66, 1080, 66, 17280, 1080, 1080, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 1080, 1080, 17280, 66, 17280, 66, 66, 66, 17280, 1080, 17280, 17280, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 17280, 66, 66, 1080, 66, 1080, 1080, 66, 17280, 17280, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1971516 . Total input tokens: 439087091 . Total output tokens: 394634127
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 3.429401710978709,
    "estimated_duration": 3600.026050652022,
    "input_throughput": 2929.3485246002597,
    "output_throughput": 2590.3809774684864,
    "total_throughput": 5519.729502068746,
    "itl": 82.61865167386897,
    "ttft": 2388950.2068483434,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1004,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3317673273198327,
    "arrivals": 657053,
    "finished_requests": 42615,
    "scheduler_time": 95.84081894503186
}
#Debug simulation 
Total elapsed time: 3.4294829900027253. Arrivals time: 0.20865387230878696 Scheduler time: 3.0062539753271267 Scheduler overhead time: 0.054839440388605 Adapter cache time: 0.08151850092690438 Engine time: 0.05260504054604098 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-16/adapters_320_slots_192_rate_1.6-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-16/adapters_320_slots_192_rate_1.6-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 66, 17280, 17280, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 17280, 17280, 1080, 66, 66, 1080, 17280, 17280, 1080, 1080, 66, 66, 1080, 17280, 17280, 66, 17280, 1080, 66, 1080, 17280, 66, 1080, 17280, 17280, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 17280, 1080, 17280, 17280, 66, 17280, 66, 17280, 1080, 66, 66, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 66, 1080, 1080, 66, 17280, 1080, 17280, 17280, 1080, 66, 1080, 1080, 1080, 66, 17280, 1080, 17280, 66, 17280, 66, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 17280, 66, 66, 66, 66, 17280, 1080, 1080, 17280, 1080, 1080, 66, 1080, 17280, 1080, 66, 66, 1080, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 1080, 17280, 1080, 1080, 1080, 66, 17280, 66, 17280, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 66, 66, 17280, 1080, 17280, 1080, 17280, 1080, 66, 1080, 66, 66, 66, 17280, 17280, 1080, 1080, 66, 66, 1080, 66, 17280, 66, 66, 1080, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 1080, 17280, 1080, 66, 1080, 66, 17280, 1080, 1080, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 1080, 1080, 17280, 66, 17280, 66, 66, 66, 17280, 1080, 17280, 17280, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 17280, 66, 66, 1080, 66, 1080, 1080, 66, 17280, 17280, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1971516 . Total input tokens: 439087091 . Total output tokens: 394634127
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.402656825026497,
    "estimated_duration": 3600.1089029929517,
    "input_throughput": 4173.518747588124,
    "output_throughput": 3670.204251047866,
    "total_throughput": 7843.72299863599,
    "itl": 230.24399606465167,
    "ttft": 2192552.597219145,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1372,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.102349004605676,
    "arrivals": 657053,
    "finished_requests": 60676,
    "scheduler_time": 74.64505907628784
}
#Debug simulation 
Total elapsed time: 4.402736501011532. Arrivals time: 0.2055384240229614 Scheduler time: 4.0829951196792535 Scheduler overhead time: 0.0244898225646466 Adapter cache time: 0.05378722184104845 Engine time: 0.024605215119663626 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-32/adapters_320_slots_192_rate_1.6-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-32/adapters_320_slots_192_rate_1.6-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 66, 17280, 17280, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 17280, 17280, 1080, 66, 66, 1080, 17280, 17280, 1080, 1080, 66, 66, 1080, 17280, 17280, 66, 17280, 1080, 66, 1080, 17280, 66, 1080, 17280, 17280, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 17280, 1080, 17280, 17280, 66, 17280, 66, 17280, 1080, 66, 66, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 66, 1080, 1080, 66, 17280, 1080, 17280, 17280, 1080, 66, 1080, 1080, 1080, 66, 17280, 1080, 17280, 66, 17280, 66, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 17280, 66, 66, 66, 66, 17280, 1080, 1080, 17280, 1080, 1080, 66, 1080, 17280, 1080, 66, 66, 1080, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 1080, 17280, 1080, 1080, 1080, 66, 17280, 66, 17280, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 66, 66, 17280, 1080, 17280, 1080, 17280, 1080, 66, 1080, 66, 66, 66, 17280, 17280, 1080, 1080, 66, 66, 1080, 66, 17280, 66, 66, 1080, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 1080, 17280, 1080, 66, 1080, 66, 17280, 1080, 1080, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 1080, 1080, 17280, 66, 17280, 66, 66, 66, 17280, 1080, 17280, 17280, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 17280, 66, 66, 1080, 66, 1080, 1080, 66, 17280, 17280, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1971516 . Total input tokens: 439087091 . Total output tokens: 394634127
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.4095575499814004,
    "estimated_duration": 3600.0668110290776,
    "input_throughput": 2929.3153581740075,
    "output_throughput": 2590.351648872407,
    "total_throughput": 5519.667007046415,
    "itl": 82.61974128409132,
    "ttft": 2388964.5895324163,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1004,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.372385800331874,
    "arrivals": 657053,
    "finished_requests": 42615,
    "scheduler_time": 95.84096084910885
}
#Debug simulation 
Total elapsed time: 3.409634903015103. Arrivals time: 0.16700941935414448 Scheduler time: 3.0288496681605466 Scheduler overhead time: 0.05469599144998938 Adapter cache time: 0.08112371485913172 Engine time: 0.052389454969670624 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-8/adapters_320_slots_192_rate_1.6-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-8/adapters_320_slots_192_rate_1.6-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 33, 17280, 17280, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 17280, 17280, 1080, 33, 33, 1080, 17280, 17280, 1080, 1080, 33, 33, 1080, 17280, 17280, 33, 17280, 1080, 33, 1080, 17280, 33, 1080, 17280, 17280, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 17280, 1080, 17280, 17280, 33, 17280, 33, 17280, 1080, 33, 33, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 33, 1080, 1080, 33, 17280, 1080, 17280, 17280, 1080, 33, 1080, 1080, 1080, 33, 17280, 1080, 17280, 33, 17280, 33, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 17280, 33, 33, 33, 33, 17280, 1080, 1080, 17280, 1080, 1080, 33, 1080, 17280, 1080, 33, 33, 1080, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 1080, 17280, 1080, 1080, 1080, 33, 17280, 33, 17280, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 33, 33, 17280, 1080, 17280, 1080, 17280, 1080, 33, 1080, 33, 33, 33, 17280, 17280, 1080, 1080, 33, 33, 1080, 33, 17280, 33, 33, 1080, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 1080, 1080, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 1080, 1080, 17280, 33, 17280, 33, 33, 33, 17280, 1080, 17280, 17280, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 17280, 33, 33, 1080, 33, 1080, 1080, 33, 17280, 17280, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1968018 . Total input tokens: 438292478 . Total output tokens: 393947046
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.5798355099977925,
    "estimated_duration": 3600.1961444788894,
    "input_throughput": 4211.997733305421,
    "output_throughput": 3704.239564961347,
    "total_throughput": 7916.237298266768,
    "itl": 231.23579141382643,
    "ttft": 2191927.908256598,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1227,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7552184618055833,
    "arrivals": 655825,
    "finished_requests": 61220,
    "scheduler_time": 75.11682227937898
}
#Debug simulation 
Total elapsed time: 4.57992305397056. Arrivals time: 0.24699361843522638 Scheduler time: 4.219689341611229 Scheduler overhead time: 0.024543283507227898 Adapter cache time: 0.05256848339922726 Engine time: 0.02478933025849983 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-16/adapters_320_slots_192_rate_1.6-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-16/adapters_320_slots_192_rate_1.6-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 33, 17280, 17280, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 17280, 17280, 1080, 33, 33, 1080, 17280, 17280, 1080, 1080, 33, 33, 1080, 17280, 17280, 33, 17280, 1080, 33, 1080, 17280, 33, 1080, 17280, 17280, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 17280, 1080, 17280, 17280, 33, 17280, 33, 17280, 1080, 33, 33, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 33, 1080, 1080, 33, 17280, 1080, 17280, 17280, 1080, 33, 1080, 1080, 1080, 33, 17280, 1080, 17280, 33, 17280, 33, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 17280, 33, 33, 33, 33, 17280, 1080, 1080, 17280, 1080, 1080, 33, 1080, 17280, 1080, 33, 33, 1080, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 1080, 17280, 1080, 1080, 1080, 33, 17280, 33, 17280, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 33, 33, 17280, 1080, 17280, 1080, 17280, 1080, 33, 1080, 33, 33, 33, 17280, 17280, 1080, 1080, 33, 33, 1080, 33, 17280, 33, 33, 1080, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 1080, 1080, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 1080, 1080, 17280, 33, 17280, 33, 33, 33, 17280, 1080, 17280, 17280, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 17280, 33, 33, 1080, 33, 1080, 1080, 33, 17280, 17280, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1968018 . Total input tokens: 438292478 . Total output tokens: 393947046
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.434969231020659,
    "estimated_duration": 3600.2246542585303,
    "input_throughput": 4208.9192912103945,
    "output_throughput": 3702.0478664393113,
    "total_throughput": 7910.967157649706,
    "itl": 228.99948245280078,
    "ttft": 2192731.903963395,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1232,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.025327649535617,
    "arrivals": 655825,
    "finished_requests": 61179,
    "scheduler_time": 75.27904183473412
}
#Debug simulation 
Total elapsed time: 4.43505411100341. Arrivals time: 0.21325500786770135 Scheduler time: 4.108839088003151 Scheduler overhead time: 0.024638577247969806 Adapter cache time: 0.05220137053402141 Engine time: 0.024693438841495663 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-32/adapters_320_slots_192_rate_1.6-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-32/adapters_320_slots_192_rate_1.6-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 33, 17280, 17280, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 17280, 17280, 1080, 33, 33, 1080, 17280, 17280, 1080, 1080, 33, 33, 1080, 17280, 17280, 33, 17280, 1080, 33, 1080, 17280, 33, 1080, 17280, 17280, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 17280, 1080, 17280, 17280, 33, 17280, 33, 17280, 1080, 33, 33, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 33, 1080, 1080, 33, 17280, 1080, 17280, 17280, 1080, 33, 1080, 1080, 1080, 33, 17280, 1080, 17280, 33, 17280, 33, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 17280, 33, 33, 33, 33, 17280, 1080, 1080, 17280, 1080, 1080, 33, 1080, 17280, 1080, 33, 33, 1080, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 1080, 17280, 1080, 1080, 1080, 33, 17280, 33, 17280, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 33, 33, 17280, 1080, 17280, 1080, 17280, 1080, 33, 1080, 33, 33, 33, 17280, 17280, 1080, 1080, 33, 33, 1080, 33, 17280, 33, 33, 1080, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 1080, 1080, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 1080, 1080, 17280, 33, 17280, 33, 33, 33, 17280, 1080, 17280, 17280, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 17280, 33, 33, 1080, 33, 1080, 1080, 33, 17280, 17280, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1968018 . Total input tokens: 438292478 . Total output tokens: 393947046
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.202475970960222,
    "estimated_duration": 3600.017946159266,
    "input_throughput": 3665.4078388908742,
    "output_throughput": 3246.001874092608,
    "total_throughput": 6911.409712983483,
    "itl": 104.49072238602503,
    "ttft": 2272482.1933342125,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1061,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.473003437090621,
    "arrivals": 655825,
    "finished_requests": 53296,
    "scheduler_time": 93.25739969783852
}
#Debug simulation 
Total elapsed time: 4.202559357974678. Arrivals time: 0.19129448803141713 Scheduler time: 3.778959005489014 Scheduler overhead time: 0.04793779557803646 Adapter cache time: 0.11228683590888977 Engine time: 0.048943833098746836 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-16/adapters_320_slots_192_rate_1.6-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-16/adapters_320_slots_192_rate_1.6-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 33, 17280, 17280, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 17280, 17280, 1080, 33, 33, 1080, 17280, 17280, 1080, 1080, 33, 33, 1080, 17280, 17280, 33, 17280, 1080, 33, 1080, 17280, 33, 1080, 17280, 17280, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 17280, 1080, 17280, 17280, 33, 17280, 33, 17280, 1080, 33, 33, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 33, 1080, 1080, 33, 17280, 1080, 17280, 17280, 1080, 33, 1080, 1080, 1080, 33, 17280, 1080, 17280, 33, 17280, 33, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 17280, 33, 33, 33, 33, 17280, 1080, 1080, 17280, 1080, 1080, 33, 1080, 17280, 1080, 33, 33, 1080, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 1080, 17280, 1080, 1080, 1080, 33, 17280, 33, 17280, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 33, 33, 17280, 1080, 17280, 1080, 17280, 1080, 33, 1080, 33, 33, 33, 17280, 17280, 1080, 1080, 33, 33, 1080, 33, 17280, 33, 33, 1080, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 1080, 1080, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 1080, 1080, 17280, 33, 17280, 33, 33, 33, 17280, 1080, 17280, 17280, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 17280, 33, 33, 1080, 33, 1080, 1080, 33, 17280, 17280, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1968018 . Total input tokens: 438292478 . Total output tokens: 393947046
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.555146594997495,
    "estimated_duration": 3600.046314001957,
    "input_throughput": 4209.127794013087,
    "output_throughput": 3702.2312596817205,
    "total_throughput": 7911.359053694807,
    "itl": 228.98881716361416,
    "ttft": 2192663.649285579,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1232,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.847180090695572,
    "arrivals": 655825,
    "finished_requests": 61179,
    "scheduler_time": 75.27884913695479
}
#Debug simulation 
Total elapsed time: 4.5552489559631795. Arrivals time: 0.20964472298510373 Scheduler time: 4.2320944792591035 Scheduler overhead time: 0.02474073285702616 Adapter cache time: 0.05234146781731397 Engine time: 0.02493171946844086 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-32/adapters_320_slots_192_rate_1.6-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-32/adapters_320_slots_192_rate_1.6-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 33, 17280, 17280, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 17280, 17280, 1080, 33, 33, 1080, 17280, 17280, 1080, 1080, 33, 33, 1080, 17280, 17280, 33, 17280, 1080, 33, 1080, 17280, 33, 1080, 17280, 17280, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 17280, 1080, 17280, 17280, 33, 17280, 33, 17280, 1080, 33, 33, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 33, 1080, 1080, 33, 17280, 1080, 17280, 17280, 1080, 33, 1080, 1080, 1080, 33, 17280, 1080, 17280, 33, 17280, 33, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 17280, 33, 33, 33, 33, 17280, 1080, 1080, 17280, 1080, 1080, 33, 1080, 17280, 1080, 33, 33, 1080, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 1080, 17280, 1080, 1080, 1080, 33, 17280, 33, 17280, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 33, 33, 17280, 1080, 17280, 1080, 17280, 1080, 33, 1080, 33, 33, 33, 17280, 17280, 1080, 1080, 33, 33, 1080, 33, 17280, 33, 33, 1080, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 1080, 1080, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 1080, 1080, 17280, 33, 17280, 33, 33, 33, 17280, 1080, 17280, 17280, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 17280, 33, 33, 1080, 33, 1080, 1080, 33, 17280, 17280, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1968018 . Total input tokens: 438292478 . Total output tokens: 393947046
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.201750912005082,
    "estimated_duration": 3600.064956561376,
    "input_throughput": 3665.359975227723,
    "output_throughput": 3245.959487120375,
    "total_throughput": 6911.319462348099,
    "itl": 104.49212185945011,
    "ttft": 2272499.865096182,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1061,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.51990959942341,
    "arrivals": 655825,
    "finished_requests": 53296,
    "scheduler_time": 93.25750393765583
}
#Debug simulation 
Total elapsed time: 4.201834934006911. Arrivals time: 0.19275999395176768 Scheduler time: 3.7770701770787127 Scheduler overhead time: 0.04811102448729798 Adapter cache time: 0.11198059521848336 Engine time: 0.0488658036920242 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-16/adapters_320_slots_192_rate_1.6-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-16/adapters_320_slots_192_rate_1.6-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 33, 17280, 17280, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 17280, 17280, 1080, 33, 33, 1080, 17280, 17280, 1080, 1080, 33, 33, 1080, 17280, 17280, 33, 17280, 1080, 33, 1080, 17280, 33, 1080, 17280, 17280, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 17280, 1080, 17280, 17280, 33, 17280, 33, 17280, 1080, 33, 33, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 33, 1080, 1080, 33, 17280, 1080, 17280, 17280, 1080, 33, 1080, 1080, 1080, 33, 17280, 1080, 17280, 33, 17280, 33, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 17280, 33, 33, 33, 33, 17280, 1080, 1080, 17280, 1080, 1080, 33, 1080, 17280, 1080, 33, 33, 1080, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 1080, 17280, 1080, 1080, 1080, 33, 17280, 33, 17280, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 33, 33, 17280, 1080, 17280, 1080, 17280, 1080, 33, 1080, 33, 33, 33, 17280, 17280, 1080, 1080, 33, 33, 1080, 33, 17280, 33, 33, 1080, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 1080, 1080, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 1080, 1080, 17280, 33, 17280, 33, 33, 33, 17280, 1080, 17280, 17280, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 17280, 33, 33, 1080, 33, 1080, 1080, 33, 17280, 17280, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1968018 . Total input tokens: 438292478 . Total output tokens: 393947046
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.457910225959495,
    "estimated_duration": 3600.1395921314033,
    "input_throughput": 4209.232062312459,
    "output_throughput": 3702.3150516530036,
    "total_throughput": 7911.547113965462,
    "itl": 228.98073965537984,
    "ttft": 2192631.1143958624,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1232,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.6837419633193864,
    "arrivals": 655825,
    "finished_requests": 61183,
    "scheduler_time": 75.28408068116768
}
#Debug simulation 
Total elapsed time: 4.458028087974526. Arrivals time: 0.21068513923091814 Scheduler time: 4.1343409269466065 Scheduler overhead time: 0.02455686527537182 Adapter cache time: 0.05227528279647231 Engine time: 0.024743916001170874 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-32/adapters_320_slots_192_rate_1.6-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-32/adapters_320_slots_192_rate_1.6-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 33, 17280, 17280, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 17280, 17280, 1080, 33, 33, 1080, 17280, 17280, 1080, 1080, 33, 33, 1080, 17280, 17280, 33, 17280, 1080, 33, 1080, 17280, 33, 1080, 17280, 17280, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 17280, 1080, 17280, 17280, 33, 17280, 33, 17280, 1080, 33, 33, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 33, 1080, 1080, 33, 17280, 1080, 17280, 17280, 1080, 33, 1080, 1080, 1080, 33, 17280, 1080, 17280, 33, 17280, 33, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 17280, 33, 33, 33, 33, 17280, 1080, 1080, 17280, 1080, 1080, 33, 1080, 17280, 1080, 33, 33, 1080, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 1080, 17280, 1080, 1080, 1080, 33, 17280, 33, 17280, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 33, 33, 17280, 1080, 17280, 1080, 17280, 1080, 33, 1080, 33, 33, 33, 17280, 17280, 1080, 1080, 33, 33, 1080, 33, 17280, 33, 33, 1080, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 1080, 1080, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 1080, 1080, 17280, 33, 17280, 33, 33, 33, 17280, 1080, 17280, 17280, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 17280, 33, 33, 1080, 33, 1080, 1080, 33, 17280, 17280, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1968018 . Total input tokens: 438292478 . Total output tokens: 393947046
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.189687528996728,
    "estimated_duration": 3600.0198680434482,
    "input_throughput": 3665.4061598753224,
    "output_throughput": 3246.1498625981917,
    "total_throughput": 6911.556022473514,
    "itl": 104.49794188385636,
    "ttft": 2272507.7146614655,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1060,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5604169045389176,
    "arrivals": 655825,
    "finished_requests": 53297,
    "scheduler_time": 93.25487048131951
}
#Debug simulation 
Total elapsed time: 4.1897691619815305. Arrivals time: 0.19231713947374374 Scheduler time: 3.7654369364026934 Scheduler overhead time: 0.049226377857849 Adapter cache time: 0.11070042668143287 Engine time: 0.04897577530937269 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-8/adapters_320_slots_192_rate_1.6-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-8/adapters_320_slots_192_rate_1.6-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 270, 17280, 17280, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 17280, 17280, 540, 270, 270, 540, 17280, 17280, 540, 540, 270, 270, 540, 17280, 17280, 270, 17280, 540, 270, 540, 17280, 270, 540, 17280, 17280, 540, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 540, 540, 540, 270, 540, 270, 17280, 270, 17280, 540, 17280, 17280, 270, 17280, 270, 17280, 540, 270, 270, 540, 540, 17280, 540, 17280, 17280, 17280, 270, 540, 540, 270, 17280, 540, 17280, 17280, 540, 270, 540, 540, 540, 270, 17280, 540, 17280, 270, 17280, 270, 270, 540, 17280, 17280, 540, 270, 540, 270, 540, 17280, 17280, 540, 270, 540, 270, 17280, 270, 270, 270, 270, 17280, 540, 540, 17280, 540, 540, 270, 540, 17280, 540, 270, 270, 540, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 540, 17280, 540, 540, 540, 270, 17280, 270, 17280, 540, 270, 540, 270, 270, 540, 270, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 270, 270, 17280, 540, 17280, 540, 17280, 540, 270, 540, 270, 270, 270, 17280, 17280, 540, 540, 270, 270, 540, 270, 17280, 270, 270, 540, 270, 17280, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 270, 540, 17280, 540, 540, 17280, 540, 270, 540, 270, 17280, 540, 540, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 540, 270, 540, 270, 540, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 540, 540, 17280, 270, 17280, 270, 270, 270, 17280, 540, 17280, 17280, 270, 540, 540, 540, 270, 540, 270, 540, 540, 17280, 270, 270, 540, 270, 540, 540, 270, 17280, 17280, 17280, 270, 540, 540, 540, 540, 270, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 540, 540, 540, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1935360 . Total input tokens: 431032019 . Total output tokens: 387484439
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.632888450985774,
    "estimated_duration": 3600.2158456124444,
    "input_throughput": 4361.903750614868,
    "output_throughput": 3833.7645829821163,
    "total_throughput": 8195.668333596985,
    "itl": 223.0416652560484,
    "ttft": 2167456.6293988293,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1796,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.496635988103381,
    "arrivals": 644956,
    "finished_requests": 63392,
    "scheduler_time": 77.60462858171609
}
#Debug simulation 
Total elapsed time: 4.632996545988135. Arrivals time: 0.2533498740522191 Scheduler time: 4.264941720641218 Scheduler overhead time: 0.025383870815858245 Adapter cache time: 0.05209563055541366 Engine time: 0.025454504357185215 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-16/adapters_320_slots_192_rate_1.6-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-16/adapters_320_slots_192_rate_1.6-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 270, 17280, 17280, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 17280, 17280, 540, 270, 270, 540, 17280, 17280, 540, 540, 270, 270, 540, 17280, 17280, 270, 17280, 540, 270, 540, 17280, 270, 540, 17280, 17280, 540, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 540, 540, 540, 270, 540, 270, 17280, 270, 17280, 540, 17280, 17280, 270, 17280, 270, 17280, 540, 270, 270, 540, 540, 17280, 540, 17280, 17280, 17280, 270, 540, 540, 270, 17280, 540, 17280, 17280, 540, 270, 540, 540, 540, 270, 17280, 540, 17280, 270, 17280, 270, 270, 540, 17280, 17280, 540, 270, 540, 270, 540, 17280, 17280, 540, 270, 540, 270, 17280, 270, 270, 270, 270, 17280, 540, 540, 17280, 540, 540, 270, 540, 17280, 540, 270, 270, 540, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 540, 17280, 540, 540, 540, 270, 17280, 270, 17280, 540, 270, 540, 270, 270, 540, 270, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 270, 270, 17280, 540, 17280, 540, 17280, 540, 270, 540, 270, 270, 270, 17280, 17280, 540, 540, 270, 270, 540, 270, 17280, 270, 270, 540, 270, 17280, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 270, 540, 17280, 540, 540, 17280, 540, 270, 540, 270, 17280, 540, 540, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 540, 270, 540, 270, 540, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 540, 540, 17280, 270, 17280, 270, 270, 270, 17280, 540, 17280, 17280, 270, 540, 540, 540, 270, 540, 270, 540, 540, 17280, 270, 270, 540, 270, 540, 540, 270, 17280, 17280, 17280, 270, 540, 540, 540, 540, 270, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 540, 540, 540, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1935360 . Total input tokens: 431032019 . Total output tokens: 387484439
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.599314322986174,
    "estimated_duration": 3600.0139900603676,
    "input_throughput": 4357.593065836098,
    "output_throughput": 3830.984001195154,
    "total_throughput": 8188.577067031252,
    "itl": 220.1079379503147,
    "ttft": 2168396.6380618922,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1792,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.84072119954259,
    "arrivals": 644956,
    "finished_requests": 63334,
    "scheduler_time": 77.8293249129999
}
#Debug simulation 
Total elapsed time: 4.5993996020406485. Arrivals time: 0.21987828955752775 Scheduler time: 4.263546677946579 Scheduler overhead time: 0.025790734216570854 Adapter cache time: 0.05248819576809183 Engine time: 0.025794473534915596 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-32/adapters_320_slots_192_rate_1.6-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-32/adapters_320_slots_192_rate_1.6-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 270, 17280, 17280, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 17280, 17280, 540, 270, 270, 540, 17280, 17280, 540, 540, 270, 270, 540, 17280, 17280, 270, 17280, 540, 270, 540, 17280, 270, 540, 17280, 17280, 540, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 540, 540, 540, 270, 540, 270, 17280, 270, 17280, 540, 17280, 17280, 270, 17280, 270, 17280, 540, 270, 270, 540, 540, 17280, 540, 17280, 17280, 17280, 270, 540, 540, 270, 17280, 540, 17280, 17280, 540, 270, 540, 540, 540, 270, 17280, 540, 17280, 270, 17280, 270, 270, 540, 17280, 17280, 540, 270, 540, 270, 540, 17280, 17280, 540, 270, 540, 270, 17280, 270, 270, 270, 270, 17280, 540, 540, 17280, 540, 540, 270, 540, 17280, 540, 270, 270, 540, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 540, 17280, 540, 540, 540, 270, 17280, 270, 17280, 540, 270, 540, 270, 270, 540, 270, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 270, 270, 17280, 540, 17280, 540, 17280, 540, 270, 540, 270, 270, 270, 17280, 17280, 540, 540, 270, 270, 540, 270, 17280, 270, 270, 540, 270, 17280, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 270, 540, 17280, 540, 540, 17280, 540, 270, 540, 270, 17280, 540, 540, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 540, 270, 540, 270, 540, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 540, 540, 17280, 270, 17280, 270, 270, 270, 17280, 540, 17280, 17280, 270, 540, 540, 540, 270, 540, 270, 540, 540, 17280, 270, 270, 540, 270, 540, 540, 270, 17280, 17280, 17280, 270, 540, 540, 540, 540, 270, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 540, 540, 540, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1935360 . Total input tokens: 431032019 . Total output tokens: 387484439
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.2295372140361,
    "estimated_duration": 3600.0129530782724,
    "input_throughput": 3758.8048088630835,
    "output_throughput": 3319.3030568910262,
    "total_throughput": 7078.107865754109,
    "itl": 101.28164231430259,
    "ttft": 2257902.489108195,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1580,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.167253867741624,
    "arrivals": 644956,
    "finished_requests": 54648,
    "scheduler_time": 95.55151208867376
}
#Debug simulation 
Total elapsed time: 4.229621975042392. Arrivals time: 0.20210615504765883 Scheduler time: 3.8062827322864905 Scheduler overhead time: 0.04896088287932798 Adapter cache time: 0.09897995309438556 Engine time: 0.04968292749254033 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-16-16/adapters_320_slots_192_rate_1.6-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-16-16/adapters_320_slots_192_rate_1.6-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 270, 17280, 17280, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 17280, 17280, 540, 270, 270, 540, 17280, 17280, 540, 540, 270, 270, 540, 17280, 17280, 270, 17280, 540, 270, 540, 17280, 270, 540, 17280, 17280, 540, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 540, 540, 540, 270, 540, 270, 17280, 270, 17280, 540, 17280, 17280, 270, 17280, 270, 17280, 540, 270, 270, 540, 540, 17280, 540, 17280, 17280, 17280, 270, 540, 540, 270, 17280, 540, 17280, 17280, 540, 270, 540, 540, 540, 270, 17280, 540, 17280, 270, 17280, 270, 270, 540, 17280, 17280, 540, 270, 540, 270, 540, 17280, 17280, 540, 270, 540, 270, 17280, 270, 270, 270, 270, 17280, 540, 540, 17280, 540, 540, 270, 540, 17280, 540, 270, 270, 540, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 540, 17280, 540, 540, 540, 270, 17280, 270, 17280, 540, 270, 540, 270, 270, 540, 270, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 270, 270, 17280, 540, 17280, 540, 17280, 540, 270, 540, 270, 270, 270, 17280, 17280, 540, 540, 270, 270, 540, 270, 17280, 270, 270, 540, 270, 17280, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 270, 540, 17280, 540, 540, 17280, 540, 270, 540, 270, 17280, 540, 540, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 540, 270, 540, 270, 540, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 540, 540, 17280, 270, 17280, 270, 270, 270, 17280, 540, 17280, 17280, 270, 540, 540, 540, 270, 540, 270, 540, 540, 17280, 270, 270, 540, 270, 540, 540, 270, 17280, 17280, 17280, 270, 540, 540, 540, 540, 270, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 540, 540, 540, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1935360 . Total input tokens: 431032019 . Total output tokens: 387484439
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.554176275036298,
    "estimated_duration": 3600.008981556408,
    "input_throughput": 4357.402184374025,
    "output_throughput": 3830.7448872079754,
    "total_throughput": 8188.1470715820005,
    "itl": 219.7600496151094,
    "ttft": 2168465.375898122,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1793,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.593242319633567,
    "arrivals": 644956,
    "finished_requests": 63332,
    "scheduler_time": 77.86165431691258
}
#Debug simulation 
Total elapsed time: 4.554259585042018. Arrivals time: 0.21301312767900527 Scheduler time: 4.2256247190525755 Scheduler overhead time: 0.025465781800448895 Adapter cache time: 0.0525886386167258 Engine time: 0.025694543262943625 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-16-32/adapters_320_slots_192_rate_1.6-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-16-32/adapters_320_slots_192_rate_1.6-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 270, 17280, 17280, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 17280, 17280, 540, 270, 270, 540, 17280, 17280, 540, 540, 270, 270, 540, 17280, 17280, 270, 17280, 540, 270, 540, 17280, 270, 540, 17280, 17280, 540, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 540, 540, 540, 270, 540, 270, 17280, 270, 17280, 540, 17280, 17280, 270, 17280, 270, 17280, 540, 270, 270, 540, 540, 17280, 540, 17280, 17280, 17280, 270, 540, 540, 270, 17280, 540, 17280, 17280, 540, 270, 540, 540, 540, 270, 17280, 540, 17280, 270, 17280, 270, 270, 540, 17280, 17280, 540, 270, 540, 270, 540, 17280, 17280, 540, 270, 540, 270, 17280, 270, 270, 270, 270, 17280, 540, 540, 17280, 540, 540, 270, 540, 17280, 540, 270, 270, 540, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 540, 17280, 540, 540, 540, 270, 17280, 270, 17280, 540, 270, 540, 270, 270, 540, 270, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 270, 270, 17280, 540, 17280, 540, 17280, 540, 270, 540, 270, 270, 270, 17280, 17280, 540, 540, 270, 270, 540, 270, 17280, 270, 270, 540, 270, 17280, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 270, 540, 17280, 540, 540, 17280, 540, 270, 540, 270, 17280, 540, 540, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 540, 270, 540, 270, 540, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 540, 540, 17280, 270, 17280, 270, 270, 270, 17280, 540, 17280, 17280, 270, 540, 540, 540, 270, 540, 270, 540, 540, 17280, 270, 270, 540, 270, 540, 540, 270, 17280, 17280, 17280, 270, 540, 540, 540, 540, 270, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 540, 540, 540, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1935360 . Total input tokens: 431032019 . Total output tokens: 387484439
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.238202838983852,
    "estimated_duration": 3600.017196875294,
    "input_throughput": 3758.2687137560024,
    "output_throughput": 3319.0444230019343,
    "total_throughput": 7077.313136757936,
    "itl": 101.23924599850916,
    "ttft": 2258113.9847214026,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1585,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.252562047075425,
    "arrivals": 644956,
    "finished_requests": 54638,
    "scheduler_time": 95.56258866241903
}
#Debug simulation 
Total elapsed time: 4.238284314982593. Arrivals time: 0.19442772946786135 Scheduler time: 3.8227886450476944 Scheduler overhead time: 0.04922731767874211 Adapter cache time: 0.09858364280080423 Engine time: 0.04971465322887525 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_16-16-16/adapters_320_slots_192_rate_1.6-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_16-16-16/adapters_320_slots_192_rate_1.6-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 270, 17280, 17280, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 17280, 17280, 540, 270, 270, 540, 17280, 17280, 540, 540, 270, 270, 540, 17280, 17280, 270, 17280, 540, 270, 540, 17280, 270, 540, 17280, 17280, 540, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 540, 540, 540, 270, 540, 270, 17280, 270, 17280, 540, 17280, 17280, 270, 17280, 270, 17280, 540, 270, 270, 540, 540, 17280, 540, 17280, 17280, 17280, 270, 540, 540, 270, 17280, 540, 17280, 17280, 540, 270, 540, 540, 540, 270, 17280, 540, 17280, 270, 17280, 270, 270, 540, 17280, 17280, 540, 270, 540, 270, 540, 17280, 17280, 540, 270, 540, 270, 17280, 270, 270, 270, 270, 17280, 540, 540, 17280, 540, 540, 270, 540, 17280, 540, 270, 270, 540, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 540, 17280, 540, 540, 540, 270, 17280, 270, 17280, 540, 270, 540, 270, 270, 540, 270, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 270, 270, 17280, 540, 17280, 540, 17280, 540, 270, 540, 270, 270, 270, 17280, 17280, 540, 540, 270, 270, 540, 270, 17280, 270, 270, 540, 270, 17280, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 270, 540, 17280, 540, 540, 17280, 540, 270, 540, 270, 17280, 540, 540, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 540, 270, 540, 270, 540, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 540, 540, 17280, 270, 17280, 270, 270, 270, 17280, 540, 17280, 17280, 270, 540, 540, 540, 270, 540, 270, 540, 540, 17280, 270, 270, 540, 270, 540, 540, 270, 17280, 17280, 17280, 270, 540, 540, 540, 540, 270, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 540, 540, 540, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1935360 . Total input tokens: 431032019 . Total output tokens: 387484439
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.593974222021643,
    "estimated_duration": 3600.011289823472,
    "input_throughput": 4357.9704998006555,
    "output_throughput": 3831.1965962407617,
    "total_throughput": 8189.167096041418,
    "itl": 219.74654767688884,
    "ttft": 2168414.236664696,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1793,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.361160178759447,
    "arrivals": 644956,
    "finished_requests": 63338,
    "scheduler_time": 77.86662606518765
}
#Debug simulation 
Total elapsed time: 4.59407543198904. Arrivals time: 0.22304985485970974 Scheduler time: 4.2547599205281585 Scheduler overhead time: 0.02579200780019164 Adapter cache time: 0.05279849685030058 Engine time: 0.025763549259863794 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_16-16-32/adapters_320_slots_192_rate_1.6-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_16-16-32/adapters_320_slots_192_rate_1.6-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 270, 17280, 17280, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 17280, 17280, 540, 270, 270, 540, 17280, 17280, 540, 540, 270, 270, 540, 17280, 17280, 270, 17280, 540, 270, 540, 17280, 270, 540, 17280, 17280, 540, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 540, 540, 540, 270, 540, 270, 17280, 270, 17280, 540, 17280, 17280, 270, 17280, 270, 17280, 540, 270, 270, 540, 540, 17280, 540, 17280, 17280, 17280, 270, 540, 540, 270, 17280, 540, 17280, 17280, 540, 270, 540, 540, 540, 270, 17280, 540, 17280, 270, 17280, 270, 270, 540, 17280, 17280, 540, 270, 540, 270, 540, 17280, 17280, 540, 270, 540, 270, 17280, 270, 270, 270, 270, 17280, 540, 540, 17280, 540, 540, 270, 540, 17280, 540, 270, 270, 540, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 540, 17280, 540, 540, 540, 270, 17280, 270, 17280, 540, 270, 540, 270, 270, 540, 270, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 270, 270, 17280, 540, 17280, 540, 17280, 540, 270, 540, 270, 270, 270, 17280, 17280, 540, 540, 270, 270, 540, 270, 17280, 270, 270, 540, 270, 17280, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 270, 540, 17280, 540, 540, 17280, 540, 270, 540, 270, 17280, 540, 540, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 540, 270, 540, 270, 540, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 540, 540, 17280, 270, 17280, 270, 270, 270, 17280, 540, 17280, 17280, 270, 540, 540, 540, 270, 540, 270, 540, 540, 17280, 270, 270, 540, 270, 540, 540, 270, 17280, 17280, 17280, 270, 540, 540, 540, 540, 270, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 540, 540, 540, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1935360 . Total input tokens: 431032019 . Total output tokens: 387484439
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.217868059989996,
    "estimated_duration": 3600.0712931255784,
    "input_throughput": 3752.126805320134,
    "output_throughput": 3313.7618754329105,
    "total_throughput": 7065.888680753044,
    "itl": 100.90119985531956,
    "ttft": 2258308.0177522497,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1581,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.3035106602683,
    "arrivals": 644956,
    "finished_requests": 54557,
    "scheduler_time": 95.6553223631238
}
#Debug simulation 
Total elapsed time: 4.2179499010089785. Arrivals time: 0.19451622292399406 Scheduler time: 3.8022524907719344 Scheduler overhead time: 0.04931415605824441 Adapter cache time: 0.09822468570200726 Engine time: 0.049970173044130206 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-8/adapters_320_slots_192_rate_1.6-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-8/adapters_320_slots_192_rate_1.6-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 135, 17280, 17280, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 17280, 17280, 540, 135, 135, 540, 17280, 17280, 540, 540, 135, 135, 540, 17280, 17280, 135, 17280, 540, 135, 540, 17280, 135, 540, 17280, 17280, 540, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 540, 540, 540, 135, 540, 135, 17280, 135, 17280, 540, 17280, 17280, 135, 17280, 135, 17280, 540, 135, 135, 540, 540, 17280, 540, 17280, 17280, 17280, 135, 540, 540, 135, 17280, 540, 17280, 17280, 540, 135, 540, 540, 540, 135, 17280, 540, 17280, 135, 17280, 135, 135, 540, 17280, 17280, 540, 135, 540, 135, 540, 17280, 17280, 540, 135, 540, 135, 17280, 135, 135, 135, 135, 17280, 540, 540, 17280, 540, 540, 135, 540, 17280, 540, 135, 135, 540, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 540, 17280, 540, 540, 540, 135, 17280, 135, 17280, 540, 135, 540, 135, 135, 540, 135, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 135, 135, 17280, 540, 17280, 540, 17280, 540, 135, 540, 135, 135, 135, 17280, 17280, 540, 540, 135, 135, 540, 135, 17280, 135, 135, 540, 135, 17280, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 135, 540, 17280, 540, 540, 17280, 540, 135, 540, 135, 17280, 540, 540, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 540, 135, 540, 135, 540, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 540, 540, 17280, 135, 17280, 135, 135, 135, 17280, 540, 17280, 17280, 135, 540, 540, 540, 135, 540, 135, 540, 540, 17280, 135, 135, 540, 135, 540, 540, 135, 17280, 17280, 17280, 135, 540, 540, 540, 540, 135, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 540, 540, 540, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1921050 . Total input tokens: 427835857 . Total output tokens: 384618743
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.68480325397104,
    "estimated_duration": 3600.004136094736,
    "input_throughput": 4468.859587881495,
    "output_throughput": 3922.230771467209,
    "total_throughput": 8391.090359348704,
    "itl": 218.1285101366216,
    "ttft": 2159054.610877697,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1310,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.009238944552011,
    "arrivals": 640132,
    "finished_requests": 64837,
    "scheduler_time": 79.43906165433293
}
#Debug simulation 
Total elapsed time: 4.684889146999922. Arrivals time: 0.21709244040539488 Scheduler time: 4.359697618987411 Scheduler overhead time: 0.025628667965065688 Adapter cache time: 0.04465545737184584 Engine time: 0.025869774457532912 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-16/adapters_320_slots_192_rate_1.6-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-16/adapters_320_slots_192_rate_1.6-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 135, 17280, 17280, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 17280, 17280, 540, 135, 135, 540, 17280, 17280, 540, 540, 135, 135, 540, 17280, 17280, 135, 17280, 540, 135, 540, 17280, 135, 540, 17280, 17280, 540, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 540, 540, 540, 135, 540, 135, 17280, 135, 17280, 540, 17280, 17280, 135, 17280, 135, 17280, 540, 135, 135, 540, 540, 17280, 540, 17280, 17280, 17280, 135, 540, 540, 135, 17280, 540, 17280, 17280, 540, 135, 540, 540, 540, 135, 17280, 540, 17280, 135, 17280, 135, 135, 540, 17280, 17280, 540, 135, 540, 135, 540, 17280, 17280, 540, 135, 540, 135, 17280, 135, 135, 135, 135, 17280, 540, 540, 17280, 540, 540, 135, 540, 17280, 540, 135, 135, 540, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 540, 17280, 540, 540, 540, 135, 17280, 135, 17280, 540, 135, 540, 135, 135, 540, 135, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 135, 135, 17280, 540, 17280, 540, 17280, 540, 135, 540, 135, 135, 135, 17280, 17280, 540, 540, 135, 135, 540, 135, 17280, 135, 135, 540, 135, 17280, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 135, 540, 17280, 540, 540, 17280, 540, 135, 540, 135, 17280, 540, 540, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 540, 135, 540, 135, 540, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 540, 540, 17280, 135, 17280, 135, 135, 135, 17280, 540, 17280, 17280, 135, 540, 540, 540, 135, 540, 135, 540, 540, 17280, 135, 135, 540, 135, 540, 540, 135, 17280, 17280, 17280, 135, 540, 540, 540, 540, 135, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 540, 540, 540, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1921050 . Total input tokens: 427835857 . Total output tokens: 384618743
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.6865415460197255,
    "estimated_duration": 3600.159144412179,
    "input_throughput": 4463.066313315292,
    "output_throughput": 3917.8740256225556,
    "total_throughput": 8380.940338937848,
    "itl": 215.48063176681637,
    "ttft": 2159923.388527522,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1308,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.282398930194305,
    "arrivals": 640132,
    "finished_requests": 64759,
    "scheduler_time": 79.64289348522833
}
#Debug simulation 
Total elapsed time: 4.686625028029084. Arrivals time: 0.25435391429346055 Scheduler time: 4.322933431132697 Scheduler overhead time: 0.02598618291085586 Adapter cache time: 0.04510333447251469 Engine time: 0.026141754642594606 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-32/adapters_320_slots_192_rate_1.6-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-32/adapters_320_slots_192_rate_1.6-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 135, 17280, 17280, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 17280, 17280, 540, 135, 135, 540, 17280, 17280, 540, 540, 135, 135, 540, 17280, 17280, 135, 17280, 540, 135, 540, 17280, 135, 540, 17280, 17280, 540, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 540, 540, 540, 135, 540, 135, 17280, 135, 17280, 540, 17280, 17280, 135, 17280, 135, 17280, 540, 135, 135, 540, 540, 17280, 540, 17280, 17280, 17280, 135, 540, 540, 135, 17280, 540, 17280, 17280, 540, 135, 540, 540, 540, 135, 17280, 540, 17280, 135, 17280, 135, 135, 540, 17280, 17280, 540, 135, 540, 135, 540, 17280, 17280, 540, 135, 540, 135, 17280, 135, 135, 135, 135, 17280, 540, 540, 17280, 540, 540, 135, 540, 17280, 540, 135, 135, 540, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 540, 17280, 540, 540, 540, 135, 17280, 135, 17280, 540, 135, 540, 135, 135, 540, 135, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 135, 135, 17280, 540, 17280, 540, 17280, 540, 135, 540, 135, 135, 135, 17280, 17280, 540, 540, 135, 135, 540, 135, 17280, 135, 135, 540, 135, 17280, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 135, 540, 17280, 540, 540, 17280, 540, 135, 540, 135, 17280, 540, 540, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 540, 135, 540, 135, 540, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 540, 540, 17280, 135, 17280, 135, 135, 135, 17280, 540, 17280, 17280, 135, 540, 540, 540, 135, 540, 135, 540, 540, 17280, 135, 135, 540, 135, 540, 540, 135, 17280, 17280, 17280, 135, 540, 540, 540, 540, 135, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 540, 540, 540, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1921050 . Total input tokens: 427835857 . Total output tokens: 384618743
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.242411062004976,
    "estimated_duration": 3600.0411244510547,
    "input_throughput": 3803.603771911903,
    "output_throughput": 3351.0639414819325,
    "total_throughput": 7154.667713393836,
    "itl": 100.5878738352563,
    "ttft": 2253935.4238987975,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1112,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.643399035632559,
    "arrivals": 640132,
    "finished_requests": 55186,
    "scheduler_time": 96.4320996869413
}
#Debug simulation 
Total elapsed time: 4.242494856007397. Arrivals time: 0.1984014556510374 Scheduler time: 3.827809138747398 Scheduler overhead time: 0.04951320571126416 Adapter cache time: 0.09257736837025732 Engine time: 0.0505443774163723 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-16/adapters_320_slots_192_rate_1.6-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-16/adapters_320_slots_192_rate_1.6-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 135, 17280, 17280, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 17280, 17280, 540, 135, 135, 540, 17280, 17280, 540, 540, 135, 135, 540, 17280, 17280, 135, 17280, 540, 135, 540, 17280, 135, 540, 17280, 17280, 540, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 540, 540, 540, 135, 540, 135, 17280, 135, 17280, 540, 17280, 17280, 135, 17280, 135, 17280, 540, 135, 135, 540, 540, 17280, 540, 17280, 17280, 17280, 135, 540, 540, 135, 17280, 540, 17280, 17280, 540, 135, 540, 540, 540, 135, 17280, 540, 17280, 135, 17280, 135, 135, 540, 17280, 17280, 540, 135, 540, 135, 540, 17280, 17280, 540, 135, 540, 135, 17280, 135, 135, 135, 135, 17280, 540, 540, 17280, 540, 540, 135, 540, 17280, 540, 135, 135, 540, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 540, 17280, 540, 540, 540, 135, 17280, 135, 17280, 540, 135, 540, 135, 135, 540, 135, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 135, 135, 17280, 540, 17280, 540, 17280, 540, 135, 540, 135, 135, 135, 17280, 17280, 540, 540, 135, 135, 540, 135, 17280, 135, 135, 540, 135, 17280, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 135, 540, 17280, 540, 540, 17280, 540, 135, 540, 135, 17280, 540, 540, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 540, 135, 540, 135, 540, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 540, 540, 17280, 135, 17280, 135, 135, 135, 17280, 540, 17280, 17280, 135, 540, 540, 540, 135, 540, 135, 540, 540, 17280, 135, 135, 540, 135, 540, 540, 135, 17280, 17280, 17280, 135, 540, 540, 540, 540, 135, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 540, 540, 540, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1921050 . Total input tokens: 427835857 . Total output tokens: 384618743
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.6769044660031796,
    "estimated_duration": 3600.194622150342,
    "input_throughput": 4463.563692121125,
    "output_throughput": 3918.2723381699775,
    "total_throughput": 8381.836030291102,
    "itl": 215.4717009139112,
    "ttft": 2159848.1862971005,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1308,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.087907558616663,
    "arrivals": 640132,
    "finished_requests": 64766,
    "scheduler_time": 79.6479943359304
}
#Debug simulation 
Total elapsed time: 4.6769906860427. Arrivals time: 0.21634713863022625 Scheduler time: 4.351240404590499 Scheduler overhead time: 0.025958741432987154 Adapter cache time: 0.045178637956269085 Engine time: 0.02616551163373515 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-32/adapters_320_slots_192_rate_1.6-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-32/adapters_320_slots_192_rate_1.6-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 135, 17280, 17280, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 17280, 17280, 540, 135, 135, 540, 17280, 17280, 540, 540, 135, 135, 540, 17280, 17280, 135, 17280, 540, 135, 540, 17280, 135, 540, 17280, 17280, 540, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 540, 540, 540, 135, 540, 135, 17280, 135, 17280, 540, 17280, 17280, 135, 17280, 135, 17280, 540, 135, 135, 540, 540, 17280, 540, 17280, 17280, 17280, 135, 540, 540, 135, 17280, 540, 17280, 17280, 540, 135, 540, 540, 540, 135, 17280, 540, 17280, 135, 17280, 135, 135, 540, 17280, 17280, 540, 135, 540, 135, 540, 17280, 17280, 540, 135, 540, 135, 17280, 135, 135, 135, 135, 17280, 540, 540, 17280, 540, 540, 135, 540, 17280, 540, 135, 135, 540, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 540, 17280, 540, 540, 540, 135, 17280, 135, 17280, 540, 135, 540, 135, 135, 540, 135, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 135, 135, 17280, 540, 17280, 540, 17280, 540, 135, 540, 135, 135, 135, 17280, 17280, 540, 540, 135, 135, 540, 135, 17280, 135, 135, 540, 135, 17280, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 135, 540, 17280, 540, 540, 17280, 540, 135, 540, 135, 17280, 540, 540, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 540, 135, 540, 135, 540, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 540, 540, 17280, 135, 17280, 135, 135, 135, 17280, 540, 17280, 17280, 135, 540, 540, 540, 135, 540, 135, 540, 540, 17280, 135, 135, 540, 135, 540, 540, 135, 17280, 17280, 17280, 135, 540, 540, 540, 540, 135, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 540, 540, 540, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1921050 . Total input tokens: 427835857 . Total output tokens: 384618743
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.241630781965796,
    "estimated_duration": 3600.01314857561,
    "input_throughput": 3801.4836155292364,
    "output_throughput": 3349.4947108098722,
    "total_throughput": 7150.978326339108,
    "itl": 100.37181106707747,
    "ttft": 2254477.8497861554,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1111,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.690782785136256,
    "arrivals": 640132,
    "finished_requests": 55157,
    "scheduler_time": 96.4956357371897
}
#Debug simulation 
Total elapsed time: 4.241718048986513. Arrivals time: 0.19956941425334662 Scheduler time: 3.827959929185454 Scheduler overhead time: 0.049299403675831854 Adapter cache time: 0.09072286181617528 Engine time: 0.05037912825355306 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-16/adapters_320_slots_192_rate_1.6-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-16/adapters_320_slots_192_rate_1.6-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 135, 17280, 17280, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 17280, 17280, 540, 135, 135, 540, 17280, 17280, 540, 540, 135, 135, 540, 17280, 17280, 135, 17280, 540, 135, 540, 17280, 135, 540, 17280, 17280, 540, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 540, 540, 540, 135, 540, 135, 17280, 135, 17280, 540, 17280, 17280, 135, 17280, 135, 17280, 540, 135, 135, 540, 540, 17280, 540, 17280, 17280, 17280, 135, 540, 540, 135, 17280, 540, 17280, 17280, 540, 135, 540, 540, 540, 135, 17280, 540, 17280, 135, 17280, 135, 135, 540, 17280, 17280, 540, 135, 540, 135, 540, 17280, 17280, 540, 135, 540, 135, 17280, 135, 135, 135, 135, 17280, 540, 540, 17280, 540, 540, 135, 540, 17280, 540, 135, 135, 540, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 540, 17280, 540, 540, 540, 135, 17280, 135, 17280, 540, 135, 540, 135, 135, 540, 135, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 135, 135, 17280, 540, 17280, 540, 17280, 540, 135, 540, 135, 135, 135, 17280, 17280, 540, 540, 135, 135, 540, 135, 17280, 135, 135, 540, 135, 17280, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 135, 540, 17280, 540, 540, 17280, 540, 135, 540, 135, 17280, 540, 540, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 540, 135, 540, 135, 540, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 540, 540, 17280, 135, 17280, 135, 135, 135, 17280, 540, 17280, 17280, 135, 540, 540, 540, 135, 540, 135, 540, 540, 17280, 135, 135, 540, 135, 540, 540, 135, 17280, 17280, 17280, 135, 540, 540, 540, 540, 135, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 540, 540, 540, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1921050 . Total input tokens: 427835857 . Total output tokens: 384618743
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.711907681950834,
    "estimated_duration": 3600.2216732465504,
    "input_throughput": 4463.555152566159,
    "output_throughput": 3918.241508523344,
    "total_throughput": 8381.796661089504,
    "itl": 215.45001460818003,
    "ttft": 2159835.2087375247,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1309,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.9139758360268457,
    "arrivals": 640132,
    "finished_requests": 64766,
    "scheduler_time": 79.65242033879917
}
#Debug simulation 
Total elapsed time: 4.711990584968589. Arrivals time: 0.253364858799614 Scheduler time: 4.34939269523602 Scheduler overhead time: 0.026154494553338736 Adapter cache time: 0.044699580408632755 Engine time: 0.026293791946955025 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-32/adapters_320_slots_192_rate_1.6-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-32/adapters_320_slots_192_rate_1.6-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 135, 17280, 17280, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 17280, 17280, 540, 135, 135, 540, 17280, 17280, 540, 540, 135, 135, 540, 17280, 17280, 135, 17280, 540, 135, 540, 17280, 135, 540, 17280, 17280, 540, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 540, 540, 540, 135, 540, 135, 17280, 135, 17280, 540, 17280, 17280, 135, 17280, 135, 17280, 540, 135, 135, 540, 540, 17280, 540, 17280, 17280, 17280, 135, 540, 540, 135, 17280, 540, 17280, 17280, 540, 135, 540, 540, 540, 135, 17280, 540, 17280, 135, 17280, 135, 135, 540, 17280, 17280, 540, 135, 540, 135, 540, 17280, 17280, 540, 135, 540, 135, 17280, 135, 135, 135, 135, 17280, 540, 540, 17280, 540, 540, 135, 540, 17280, 540, 135, 135, 540, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 540, 17280, 540, 540, 540, 135, 17280, 135, 17280, 540, 135, 540, 135, 135, 540, 135, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 135, 135, 17280, 540, 17280, 540, 17280, 540, 135, 540, 135, 135, 135, 17280, 17280, 540, 540, 135, 135, 540, 135, 17280, 135, 135, 540, 135, 17280, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 135, 540, 17280, 540, 540, 17280, 540, 135, 540, 135, 17280, 540, 540, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 540, 135, 540, 135, 540, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 540, 540, 17280, 135, 17280, 135, 135, 135, 17280, 540, 17280, 17280, 135, 540, 540, 540, 135, 540, 135, 540, 540, 17280, 135, 135, 540, 135, 540, 540, 135, 17280, 17280, 17280, 135, 540, 540, 540, 540, 135, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 540, 540, 540, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1921050 . Total input tokens: 427835857 . Total output tokens: 384618743
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.260348568030167,
    "estimated_duration": 3600.0594228892755,
    "input_throughput": 3801.434752156565,
    "output_throughput": 3349.4516571958447,
    "total_throughput": 7150.88640935241,
    "itl": 100.37314810829807,
    "ttft": 2254496.2717048055,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1111,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7369344247505607,
    "arrivals": 640132,
    "finished_requests": 55157,
    "scheduler_time": 96.49575841127496
}
#Debug simulation 
Total elapsed time: 4.26043360499898. Arrivals time: 0.1946382629685104 Scheduler time: 3.839432193140965 Scheduler overhead time: 0.04972807609010488 Adapter cache time: 0.10221276135416701 Engine time: 0.05058097268920392 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-8/adapters_320_slots_192_rate_1.6-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-8/adapters_320_slots_192_rate_1.6-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 66, 17280, 17280, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 17280, 17280, 540, 66, 66, 540, 17280, 17280, 540, 540, 66, 66, 540, 17280, 17280, 66, 17280, 540, 66, 540, 17280, 66, 540, 17280, 17280, 540, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 540, 540, 540, 66, 540, 66, 17280, 66, 17280, 540, 17280, 17280, 66, 17280, 66, 17280, 540, 66, 66, 540, 540, 17280, 540, 17280, 17280, 17280, 66, 540, 540, 66, 17280, 540, 17280, 17280, 540, 66, 540, 540, 540, 66, 17280, 540, 17280, 66, 17280, 66, 66, 540, 17280, 17280, 540, 66, 540, 66, 540, 17280, 17280, 540, 66, 540, 66, 17280, 66, 66, 66, 66, 17280, 540, 540, 17280, 540, 540, 66, 540, 17280, 540, 66, 66, 540, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 540, 17280, 540, 540, 540, 66, 17280, 66, 17280, 540, 66, 540, 66, 66, 540, 66, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 66, 66, 17280, 540, 17280, 540, 17280, 540, 66, 540, 66, 66, 66, 17280, 17280, 540, 540, 66, 66, 540, 66, 17280, 66, 66, 540, 66, 17280, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 66, 540, 17280, 540, 540, 17280, 540, 66, 540, 66, 17280, 540, 540, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 540, 66, 540, 66, 540, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 540, 540, 17280, 66, 17280, 66, 66, 66, 17280, 540, 17280, 17280, 66, 540, 540, 540, 66, 540, 66, 540, 540, 17280, 66, 66, 540, 66, 540, 540, 66, 17280, 17280, 17280, 66, 540, 540, 540, 540, 66, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 540, 540, 540, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1913736 . Total input tokens: 426202907 . Total output tokens: 383168847
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.6969849659944884,
    "estimated_duration": 3600.0004890300856,
    "input_throughput": 4498.647444451682,
    "output_throughput": 3974.943904481345,
    "total_throughput": 8473.591348933027,
    "itl": 215.9548215936029,
    "ttft": 2154823.463661762,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 996,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0482457929570925,
    "arrivals": 637737,
    "finished_requests": 65508,
    "scheduler_time": 80.43550670036159
}
#Debug simulation 
Total elapsed time: 4.697085515013896. Arrivals time: 0.2175236894399859 Scheduler time: 4.374445536348503 Scheduler overhead time: 0.026001034420914948 Adapter cache time: 0.04091954615432769 Engine time: 0.026143707858864218 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-16/adapters_320_slots_192_rate_1.6-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-16/adapters_320_slots_192_rate_1.6-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 66, 17280, 17280, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 17280, 17280, 540, 66, 66, 540, 17280, 17280, 540, 540, 66, 66, 540, 17280, 17280, 66, 17280, 540, 66, 540, 17280, 66, 540, 17280, 17280, 540, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 540, 540, 540, 66, 540, 66, 17280, 66, 17280, 540, 17280, 17280, 66, 17280, 66, 17280, 540, 66, 66, 540, 540, 17280, 540, 17280, 17280, 17280, 66, 540, 540, 66, 17280, 540, 17280, 17280, 540, 66, 540, 540, 540, 66, 17280, 540, 17280, 66, 17280, 66, 66, 540, 17280, 17280, 540, 66, 540, 66, 540, 17280, 17280, 540, 66, 540, 66, 17280, 66, 66, 66, 66, 17280, 540, 540, 17280, 540, 540, 66, 540, 17280, 540, 66, 66, 540, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 540, 17280, 540, 540, 540, 66, 17280, 66, 17280, 540, 66, 540, 66, 66, 540, 66, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 66, 66, 17280, 540, 17280, 540, 17280, 540, 66, 540, 66, 66, 66, 17280, 17280, 540, 540, 66, 66, 540, 66, 17280, 66, 66, 540, 66, 17280, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 66, 540, 17280, 540, 540, 17280, 540, 66, 540, 66, 17280, 540, 540, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 540, 66, 540, 66, 540, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 540, 540, 17280, 66, 17280, 66, 66, 66, 17280, 540, 17280, 17280, 66, 540, 540, 540, 66, 540, 66, 540, 540, 17280, 66, 66, 540, 66, 540, 540, 66, 17280, 17280, 17280, 66, 540, 540, 540, 540, 66, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 540, 540, 540, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1913736 . Total input tokens: 426202907 . Total output tokens: 383168847
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.758801797986962,
    "estimated_duration": 3600.2064908510074,
    "input_throughput": 4493.642806631316,
    "output_throughput": 3972.0363363435213,
    "total_throughput": 8465.679142974837,
    "itl": 213.43007726402988,
    "ttft": 2155913.0801999946,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 997,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2552476026909485,
    "arrivals": 637737,
    "finished_requests": 65444,
    "scheduler_time": 80.64019264128248
}
#Debug simulation 
Total elapsed time: 4.758936400001403. Arrivals time: 0.25732017180416733 Scheduler time: 4.395669234043453 Scheduler overhead time: 0.026342655182816088 Adapter cache time: 0.04108692571753636 Engine time: 0.02627888461574912 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-32/adapters_320_slots_192_rate_1.6-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-32/adapters_320_slots_192_rate_1.6-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 66, 17280, 17280, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 17280, 17280, 540, 66, 66, 540, 17280, 17280, 540, 540, 66, 66, 540, 17280, 17280, 66, 17280, 540, 66, 540, 17280, 66, 540, 17280, 17280, 540, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 540, 540, 540, 66, 540, 66, 17280, 66, 17280, 540, 17280, 17280, 66, 17280, 66, 17280, 540, 66, 66, 540, 540, 17280, 540, 17280, 17280, 17280, 66, 540, 540, 66, 17280, 540, 17280, 17280, 540, 66, 540, 540, 540, 66, 17280, 540, 17280, 66, 17280, 66, 66, 540, 17280, 17280, 540, 66, 540, 66, 540, 17280, 17280, 540, 66, 540, 66, 17280, 66, 66, 66, 66, 17280, 540, 540, 17280, 540, 540, 66, 540, 17280, 540, 66, 66, 540, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 540, 17280, 540, 540, 540, 66, 17280, 66, 17280, 540, 66, 540, 66, 66, 540, 66, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 66, 66, 17280, 540, 17280, 540, 17280, 540, 66, 540, 66, 66, 66, 17280, 17280, 540, 540, 66, 66, 540, 66, 17280, 66, 66, 540, 66, 17280, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 66, 540, 17280, 540, 540, 17280, 540, 66, 540, 66, 17280, 540, 540, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 540, 66, 540, 66, 540, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 540, 540, 17280, 66, 17280, 66, 66, 66, 17280, 540, 17280, 17280, 66, 540, 540, 540, 66, 540, 66, 540, 540, 17280, 66, 66, 540, 66, 540, 540, 66, 17280, 17280, 17280, 66, 540, 540, 540, 540, 66, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 540, 540, 540, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1913736 . Total input tokens: 426202907 . Total output tokens: 383168847
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.271703574981075,
    "estimated_duration": 3600.077217612695,
    "input_throughput": 3792.925866477628,
    "output_throughput": 3370.0071600256492,
    "total_throughput": 7162.933026503277,
    "itl": 100.28377692832518,
    "ttft": 2255395.823236404,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 860,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8130297567695197,
    "arrivals": 637737,
    "finished_requests": 55204,
    "scheduler_time": 96.87547287703806
}
#Debug simulation 
Total elapsed time: 4.271786838013213. Arrivals time: 0.20104798598913476 Scheduler time: 3.8571041107643396 Scheduler overhead time: 0.05026228667702526 Adapter cache time: 0.08899840188678354 Engine time: 0.05059790704399347 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-16/adapters_320_slots_192_rate_1.6-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-16/adapters_320_slots_192_rate_1.6-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 66, 17280, 17280, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 17280, 17280, 540, 66, 66, 540, 17280, 17280, 540, 540, 66, 66, 540, 17280, 17280, 66, 17280, 540, 66, 540, 17280, 66, 540, 17280, 17280, 540, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 540, 540, 540, 66, 540, 66, 17280, 66, 17280, 540, 17280, 17280, 66, 17280, 66, 17280, 540, 66, 66, 540, 540, 17280, 540, 17280, 17280, 17280, 66, 540, 540, 66, 17280, 540, 17280, 17280, 540, 66, 540, 540, 540, 66, 17280, 540, 17280, 66, 17280, 66, 66, 540, 17280, 17280, 540, 66, 540, 66, 540, 17280, 17280, 540, 66, 540, 66, 17280, 66, 66, 66, 66, 17280, 540, 540, 17280, 540, 540, 66, 540, 17280, 540, 66, 66, 540, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 540, 17280, 540, 540, 540, 66, 17280, 66, 17280, 540, 66, 540, 66, 66, 540, 66, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 66, 66, 17280, 540, 17280, 540, 17280, 540, 66, 540, 66, 66, 66, 17280, 17280, 540, 540, 66, 66, 540, 66, 17280, 66, 66, 540, 66, 17280, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 66, 540, 17280, 540, 540, 17280, 540, 66, 540, 66, 17280, 540, 540, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 540, 66, 540, 66, 540, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 540, 540, 17280, 66, 17280, 66, 66, 66, 17280, 540, 17280, 17280, 66, 540, 540, 540, 66, 540, 66, 540, 540, 17280, 66, 66, 540, 66, 540, 540, 66, 17280, 17280, 17280, 66, 540, 540, 540, 540, 66, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 540, 540, 540, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1913736 . Total input tokens: 426202907 . Total output tokens: 383168847
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.688819297996815,
    "estimated_duration": 3600.0765780344104,
    "input_throughput": 4493.804964791326,
    "output_throughput": 3972.1796717467814,
    "total_throughput": 8465.984636538107,
    "itl": 213.40769938054385,
    "ttft": 2155865.5583906085,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 998,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1127777196210458,
    "arrivals": 637737,
    "finished_requests": 65444,
    "scheduler_time": 80.6413944952365
}
#Debug simulation 
Total elapsed time: 4.688902290014084. Arrivals time: 0.21304422448156402 Scheduler time: 4.369533551682252 Scheduler overhead time: 0.02623750502243638 Adapter cache time: 0.04146315157413483 Engine time: 0.026479722233489156 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-32/adapters_320_slots_192_rate_1.6-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-32/adapters_320_slots_192_rate_1.6-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 66, 17280, 17280, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 17280, 17280, 540, 66, 66, 540, 17280, 17280, 540, 540, 66, 66, 540, 17280, 17280, 66, 17280, 540, 66, 540, 17280, 66, 540, 17280, 17280, 540, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 540, 540, 540, 66, 540, 66, 17280, 66, 17280, 540, 17280, 17280, 66, 17280, 66, 17280, 540, 66, 66, 540, 540, 17280, 540, 17280, 17280, 17280, 66, 540, 540, 66, 17280, 540, 17280, 17280, 540, 66, 540, 540, 540, 66, 17280, 540, 17280, 66, 17280, 66, 66, 540, 17280, 17280, 540, 66, 540, 66, 540, 17280, 17280, 540, 66, 540, 66, 17280, 66, 66, 66, 66, 17280, 540, 540, 17280, 540, 540, 66, 540, 17280, 540, 66, 66, 540, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 540, 17280, 540, 540, 540, 66, 17280, 66, 17280, 540, 66, 540, 66, 66, 540, 66, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 66, 66, 17280, 540, 17280, 540, 17280, 540, 66, 540, 66, 66, 66, 17280, 17280, 540, 540, 66, 66, 540, 66, 17280, 66, 66, 540, 66, 17280, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 66, 540, 17280, 540, 540, 17280, 540, 66, 540, 66, 17280, 540, 540, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 540, 66, 540, 66, 540, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 540, 540, 17280, 66, 17280, 66, 66, 66, 17280, 540, 17280, 17280, 66, 540, 540, 540, 66, 540, 66, 540, 540, 17280, 66, 66, 540, 66, 540, 540, 66, 17280, 17280, 17280, 66, 540, 540, 540, 540, 66, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 540, 540, 540, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1913736 . Total input tokens: 426202907 . Total output tokens: 383168847
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.228725170018151,
    "estimated_duration": 3600.07245798468,
    "input_throughput": 3794.508071553412,
    "output_throughput": 3371.830745538749,
    "total_throughput": 7166.338817092161,
    "itl": 100.39468262925134,
    "ttft": 2254814.2356376927,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 860,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8521391843445634,
    "arrivals": 637737,
    "finished_requests": 55228,
    "scheduler_time": 96.85338544558715
}
#Debug simulation 
Total elapsed time: 4.228807161038276. Arrivals time: 0.19114199018804356 Scheduler time: 3.826279230241198 Scheduler overhead time: 0.04921337409177795 Adapter cache time: 0.0885875002713874 Engine time: 0.04997569666011259 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-16/adapters_320_slots_192_rate_1.6-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-16/adapters_320_slots_192_rate_1.6-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 66, 17280, 17280, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 17280, 17280, 540, 66, 66, 540, 17280, 17280, 540, 540, 66, 66, 540, 17280, 17280, 66, 17280, 540, 66, 540, 17280, 66, 540, 17280, 17280, 540, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 540, 540, 540, 66, 540, 66, 17280, 66, 17280, 540, 17280, 17280, 66, 17280, 66, 17280, 540, 66, 66, 540, 540, 17280, 540, 17280, 17280, 17280, 66, 540, 540, 66, 17280, 540, 17280, 17280, 540, 66, 540, 540, 540, 66, 17280, 540, 17280, 66, 17280, 66, 66, 540, 17280, 17280, 540, 66, 540, 66, 540, 17280, 17280, 540, 66, 540, 66, 17280, 66, 66, 66, 66, 17280, 540, 540, 17280, 540, 540, 66, 540, 17280, 540, 66, 66, 540, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 540, 17280, 540, 540, 540, 66, 17280, 66, 17280, 540, 66, 540, 66, 66, 540, 66, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 66, 66, 17280, 540, 17280, 540, 17280, 540, 66, 540, 66, 66, 66, 17280, 17280, 540, 540, 66, 66, 540, 66, 17280, 66, 66, 540, 66, 17280, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 66, 540, 17280, 540, 540, 17280, 540, 66, 540, 66, 17280, 540, 540, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 540, 66, 540, 66, 540, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 540, 540, 17280, 66, 17280, 66, 66, 66, 17280, 540, 17280, 17280, 66, 540, 540, 540, 66, 540, 66, 540, 540, 17280, 66, 66, 540, 66, 540, 540, 66, 17280, 17280, 17280, 66, 540, 540, 540, 540, 66, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 540, 540, 540, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1913736 . Total input tokens: 426202907 . Total output tokens: 383168847
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.67857113503851,
    "estimated_duration": 3600.1675466149554,
    "input_throughput": 4493.983346750719,
    "output_throughput": 3972.2795716678083,
    "total_throughput": 8466.262918418526,
    "itl": 213.41648621167937,
    "ttft": 2155829.749602741,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 997,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9810801440174,
    "arrivals": 637737,
    "finished_requests": 65448,
    "scheduler_time": 80.64501014763897
}
#Debug simulation 
Total elapsed time: 4.678657734009903. Arrivals time: 0.21838828740874305 Scheduler time: 4.3547992573003285 Scheduler overhead time: 0.026138609333429486 Adapter cache time: 0.04086942208232358 Engine time: 0.02630888595012948 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-32/adapters_320_slots_192_rate_1.6-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-32/adapters_320_slots_192_rate_1.6-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 66, 17280, 17280, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 17280, 17280, 540, 66, 66, 540, 17280, 17280, 540, 540, 66, 66, 540, 17280, 17280, 66, 17280, 540, 66, 540, 17280, 66, 540, 17280, 17280, 540, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 540, 540, 540, 66, 540, 66, 17280, 66, 17280, 540, 17280, 17280, 66, 17280, 66, 17280, 540, 66, 66, 540, 540, 17280, 540, 17280, 17280, 17280, 66, 540, 540, 66, 17280, 540, 17280, 17280, 540, 66, 540, 540, 540, 66, 17280, 540, 17280, 66, 17280, 66, 66, 540, 17280, 17280, 540, 66, 540, 66, 540, 17280, 17280, 540, 66, 540, 66, 17280, 66, 66, 66, 66, 17280, 540, 540, 17280, 540, 540, 66, 540, 17280, 540, 66, 66, 540, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 540, 17280, 540, 540, 540, 66, 17280, 66, 17280, 540, 66, 540, 66, 66, 540, 66, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 66, 66, 17280, 540, 17280, 540, 17280, 540, 66, 540, 66, 66, 66, 17280, 17280, 540, 540, 66, 66, 540, 66, 17280, 66, 66, 540, 66, 17280, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 66, 540, 17280, 540, 540, 17280, 540, 66, 540, 66, 17280, 540, 540, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 540, 66, 540, 66, 540, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 540, 540, 17280, 66, 17280, 66, 66, 66, 17280, 540, 17280, 17280, 66, 540, 540, 540, 66, 540, 66, 540, 540, 17280, 66, 66, 540, 66, 540, 540, 66, 17280, 17280, 17280, 66, 540, 540, 540, 540, 66, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 540, 540, 540, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1913736 . Total input tokens: 426202907 . Total output tokens: 383168847
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.248875391029287,
    "estimated_duration": 3600.0334577779086,
    "input_throughput": 3788.835620549799,
    "output_throughput": 3366.571211668913,
    "total_throughput": 7155.406832218711,
    "itl": 100.08566444522879,
    "ttft": 2255400.130536171,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 859,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.882460432760441,
    "arrivals": 637737,
    "finished_requests": 55146,
    "scheduler_time": 96.92493939867829
}
#Debug simulation 
Total elapsed time: 4.248956391005777. Arrivals time: 0.19463877624366432 Scheduler time: 3.842332207597792 Scheduler overhead time: 0.049882227496709675 Adapter cache time: 0.08781317510874942 Engine time: 0.05050966120325029 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-8/adapters_320_slots_192_rate_1.6-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-8/adapters_320_slots_192_rate_1.6-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 33, 17280, 17280, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 17280, 17280, 540, 33, 33, 540, 17280, 17280, 540, 540, 33, 33, 540, 17280, 17280, 33, 17280, 540, 33, 540, 17280, 33, 540, 17280, 17280, 540, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 540, 540, 540, 33, 540, 33, 17280, 33, 17280, 540, 17280, 17280, 33, 17280, 33, 17280, 540, 33, 33, 540, 540, 17280, 540, 17280, 17280, 17280, 33, 540, 540, 33, 17280, 540, 17280, 17280, 540, 33, 540, 540, 540, 33, 17280, 540, 17280, 33, 17280, 33, 33, 540, 17280, 17280, 540, 33, 540, 33, 540, 17280, 17280, 540, 33, 540, 33, 17280, 33, 33, 33, 33, 17280, 540, 540, 17280, 540, 540, 33, 540, 17280, 540, 33, 33, 540, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 540, 17280, 540, 540, 540, 33, 17280, 33, 17280, 540, 33, 540, 33, 33, 540, 33, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 33, 33, 17280, 540, 17280, 540, 17280, 540, 33, 540, 33, 33, 33, 17280, 17280, 540, 540, 33, 33, 540, 33, 17280, 33, 33, 540, 33, 17280, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 33, 540, 17280, 540, 540, 17280, 540, 33, 540, 33, 17280, 540, 540, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 540, 33, 540, 33, 540, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 540, 540, 17280, 33, 17280, 33, 33, 33, 17280, 540, 17280, 17280, 33, 540, 540, 540, 33, 540, 33, 540, 540, 17280, 33, 33, 540, 33, 540, 540, 33, 17280, 17280, 17280, 33, 540, 540, 540, 540, 33, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 540, 540, 540, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1910238 . Total input tokens: 425397056 . Total output tokens: 382469408
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.7017819820321165,
    "estimated_duration": 3600.2083035128794,
    "input_throughput": 4519.649872515159,
    "output_throughput": 3971.49270114416,
    "total_throughput": 8491.14257365932,
    "itl": 215.335258596302,
    "ttft": 2148357.732945198,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 861,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6350799475261564,
    "arrivals": 636613,
    "finished_requests": 65956,
    "scheduler_time": 80.47935109217555
}
#Debug simulation 
Total elapsed time: 4.7018674880382605. Arrivals time: 0.22305418888572603 Scheduler time: 4.375407926156186 Scheduler overhead time: 0.025822688941843808 Adapter cache time: 0.039486381923779845 Engine time: 0.026009602413978428 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-16/adapters_320_slots_192_rate_1.6-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-16/adapters_320_slots_192_rate_1.6-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 33, 17280, 17280, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 17280, 17280, 540, 33, 33, 540, 17280, 17280, 540, 540, 33, 33, 540, 17280, 17280, 33, 17280, 540, 33, 540, 17280, 33, 540, 17280, 17280, 540, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 540, 540, 540, 33, 540, 33, 17280, 33, 17280, 540, 17280, 17280, 33, 17280, 33, 17280, 540, 33, 33, 540, 540, 17280, 540, 17280, 17280, 17280, 33, 540, 540, 33, 17280, 540, 17280, 17280, 540, 33, 540, 540, 540, 33, 17280, 540, 17280, 33, 17280, 33, 33, 540, 17280, 17280, 540, 33, 540, 33, 540, 17280, 17280, 540, 33, 540, 33, 17280, 33, 33, 33, 33, 17280, 540, 540, 17280, 540, 540, 33, 540, 17280, 540, 33, 33, 540, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 540, 17280, 540, 540, 540, 33, 17280, 33, 17280, 540, 33, 540, 33, 33, 540, 33, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 33, 33, 17280, 540, 17280, 540, 17280, 540, 33, 540, 33, 33, 33, 17280, 17280, 540, 540, 33, 33, 540, 33, 17280, 33, 33, 540, 33, 17280, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 33, 540, 17280, 540, 540, 17280, 540, 33, 540, 33, 17280, 540, 540, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 540, 33, 540, 33, 540, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 540, 540, 17280, 33, 17280, 33, 33, 33, 17280, 540, 17280, 17280, 33, 540, 540, 540, 33, 540, 33, 540, 540, 17280, 33, 33, 540, 33, 540, 540, 33, 17280, 17280, 17280, 33, 540, 540, 540, 540, 33, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 540, 540, 540, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1910238 . Total input tokens: 425397056 . Total output tokens: 382469408
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.704888337990269,
    "estimated_duration": 3600.2269435036014,
    "input_throughput": 4515.626724402836,
    "output_throughput": 3968.262341289183,
    "total_throughput": 8483.889065692018,
    "itl": 213.305373611063,
    "ttft": 2149148.2358949627,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 861,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8073326354217767,
    "arrivals": 636613,
    "finished_requests": 65905,
    "scheduler_time": 80.6335782418973
}
#Debug simulation 
Total elapsed time: 4.704966718971264. Arrivals time: 0.22183253231924027 Scheduler time: 4.37801403622143 Scheduler overhead time: 0.026188926480244845 Adapter cache time: 0.0402862120536156 Engine time: 0.026439545035827905 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-32/adapters_320_slots_192_rate_1.6-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-32/adapters_320_slots_192_rate_1.6-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 33, 17280, 17280, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 17280, 17280, 540, 33, 33, 540, 17280, 17280, 540, 540, 33, 33, 540, 17280, 17280, 33, 17280, 540, 33, 540, 17280, 33, 540, 17280, 17280, 540, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 540, 540, 540, 33, 540, 33, 17280, 33, 17280, 540, 17280, 17280, 33, 17280, 33, 17280, 540, 33, 33, 540, 540, 17280, 540, 17280, 17280, 17280, 33, 540, 540, 33, 17280, 540, 17280, 17280, 540, 33, 540, 540, 540, 33, 17280, 540, 17280, 33, 17280, 33, 33, 540, 17280, 17280, 540, 33, 540, 33, 540, 17280, 17280, 540, 33, 540, 33, 17280, 33, 33, 33, 33, 17280, 540, 540, 17280, 540, 540, 33, 540, 17280, 540, 33, 33, 540, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 540, 17280, 540, 540, 540, 33, 17280, 33, 17280, 540, 33, 540, 33, 33, 540, 33, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 33, 33, 17280, 540, 17280, 540, 17280, 540, 33, 540, 33, 33, 33, 17280, 17280, 540, 540, 33, 33, 540, 33, 17280, 33, 33, 540, 33, 17280, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 33, 540, 17280, 540, 540, 17280, 540, 33, 540, 33, 17280, 540, 540, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 540, 33, 540, 33, 540, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 540, 540, 17280, 33, 17280, 33, 33, 33, 17280, 540, 17280, 17280, 33, 540, 540, 540, 33, 540, 33, 540, 540, 17280, 33, 33, 540, 33, 540, 540, 33, 17280, 17280, 17280, 33, 540, 540, 540, 540, 33, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 540, 540, 540, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1910238 . Total input tokens: 425397056 . Total output tokens: 382469408
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.233192680985667,
    "estimated_duration": 3600.0808881415282,
    "input_throughput": 3813.17793308991,
    "output_throughput": 3368.9229150240144,
    "total_throughput": 7182.100848113924,
    "itl": 100.22480705444826,
    "ttft": 2247445.0529859834,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 744,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4296292958036028,
    "arrivals": 636613,
    "finished_requests": 55696,
    "scheduler_time": 96.82660106366346
}
#Debug simulation 
Total elapsed time: 4.233276045997627. Arrivals time: 0.19882884371327236 Scheduler time: 3.8228618364664726 Scheduler overhead time: 0.04944847838487476 Adapter cache time: 0.08814692369196564 Engine time: 0.05024615011643618 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-16/adapters_320_slots_192_rate_1.6-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-16/adapters_320_slots_192_rate_1.6-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 33, 17280, 17280, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 17280, 17280, 540, 33, 33, 540, 17280, 17280, 540, 540, 33, 33, 540, 17280, 17280, 33, 17280, 540, 33, 540, 17280, 33, 540, 17280, 17280, 540, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 540, 540, 540, 33, 540, 33, 17280, 33, 17280, 540, 17280, 17280, 33, 17280, 33, 17280, 540, 33, 33, 540, 540, 17280, 540, 17280, 17280, 17280, 33, 540, 540, 33, 17280, 540, 17280, 17280, 540, 33, 540, 540, 540, 33, 17280, 540, 17280, 33, 17280, 33, 33, 540, 17280, 17280, 540, 33, 540, 33, 540, 17280, 17280, 540, 33, 540, 33, 17280, 33, 33, 33, 33, 17280, 540, 540, 17280, 540, 540, 33, 540, 17280, 540, 33, 33, 540, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 540, 17280, 540, 540, 540, 33, 17280, 33, 17280, 540, 33, 540, 33, 33, 540, 33, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 33, 33, 17280, 540, 17280, 540, 17280, 540, 33, 540, 33, 33, 33, 17280, 17280, 540, 540, 33, 33, 540, 33, 17280, 33, 33, 540, 33, 17280, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 33, 540, 17280, 540, 540, 17280, 540, 33, 540, 33, 17280, 540, 540, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 540, 33, 540, 33, 540, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 540, 540, 17280, 33, 17280, 33, 33, 33, 17280, 540, 17280, 17280, 33, 540, 540, 540, 33, 540, 33, 540, 540, 17280, 33, 33, 540, 33, 540, 540, 33, 17280, 17280, 17280, 33, 540, 540, 540, 540, 33, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 540, 540, 540, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1910238 . Total input tokens: 425397056 . Total output tokens: 382469408
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 5.203626450966112,
    "estimated_duration": 3600.1045112355278,
    "input_throughput": 4515.780291728428,
    "output_throughput": 3968.397293859932,
    "total_throughput": 8484.177585588359,
    "itl": 213.2992151531786,
    "ttft": 2149098.536227326,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 861,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6839368492527593,
    "arrivals": 636613,
    "finished_requests": 65905,
    "scheduler_time": 80.6333453601875
}
#Debug simulation 
Total elapsed time: 5.203749797015917. Arrivals time: 0.227914419490844 Scheduler time: 4.870755083451513 Scheduler overhead time: 0.026325978920795023 Adapter cache time: 0.03981826396193355 Engine time: 0.02650275663472712 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-32/adapters_320_slots_192_rate_1.6-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-32/adapters_320_slots_192_rate_1.6-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 33, 17280, 17280, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 17280, 17280, 540, 33, 33, 540, 17280, 17280, 540, 540, 33, 33, 540, 17280, 17280, 33, 17280, 540, 33, 540, 17280, 33, 540, 17280, 17280, 540, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 540, 540, 540, 33, 540, 33, 17280, 33, 17280, 540, 17280, 17280, 33, 17280, 33, 17280, 540, 33, 33, 540, 540, 17280, 540, 17280, 17280, 17280, 33, 540, 540, 33, 17280, 540, 17280, 17280, 540, 33, 540, 540, 540, 33, 17280, 540, 17280, 33, 17280, 33, 33, 540, 17280, 17280, 540, 33, 540, 33, 540, 17280, 17280, 540, 33, 540, 33, 17280, 33, 33, 33, 33, 17280, 540, 540, 17280, 540, 540, 33, 540, 17280, 540, 33, 33, 540, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 540, 17280, 540, 540, 540, 33, 17280, 33, 17280, 540, 33, 540, 33, 33, 540, 33, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 33, 33, 17280, 540, 17280, 540, 17280, 540, 33, 540, 33, 33, 33, 17280, 17280, 540, 540, 33, 33, 540, 33, 17280, 33, 33, 540, 33, 17280, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 33, 540, 17280, 540, 540, 17280, 540, 33, 540, 33, 17280, 540, 540, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 540, 33, 540, 33, 540, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 540, 540, 17280, 33, 17280, 33, 33, 33, 17280, 540, 17280, 17280, 33, 540, 540, 540, 33, 540, 33, 540, 540, 17280, 33, 33, 540, 33, 540, 540, 33, 17280, 17280, 17280, 33, 540, 540, 540, 540, 33, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 540, 540, 540, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1910238 . Total input tokens: 425397056 . Total output tokens: 382469408
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.217629016027786,
    "estimated_duration": 3600.113809544163,
    "input_throughput": 3813.1430633128157,
    "output_throughput": 3368.8921077569116,
    "total_throughput": 7182.035171069728,
    "itl": 100.22577306430821,
    "ttft": 2247458.277456785,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 744,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4624510340578905,
    "arrivals": 636613,
    "finished_requests": 55696,
    "scheduler_time": 96.82670072806894
}
#Debug simulation 
Total elapsed time: 4.217727206996642. Arrivals time: 0.19237975240685046 Scheduler time: 3.8145811925060116 Scheduler overhead time: 0.049457421933766454 Adapter cache time: 0.08743506524479017 Engine time: 0.050063499656971544 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-16/adapters_320_slots_192_rate_1.6-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-16/adapters_320_slots_192_rate_1.6-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 33, 17280, 17280, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 17280, 17280, 540, 33, 33, 540, 17280, 17280, 540, 540, 33, 33, 540, 17280, 17280, 33, 17280, 540, 33, 540, 17280, 33, 540, 17280, 17280, 540, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 540, 540, 540, 33, 540, 33, 17280, 33, 17280, 540, 17280, 17280, 33, 17280, 33, 17280, 540, 33, 33, 540, 540, 17280, 540, 17280, 17280, 17280, 33, 540, 540, 33, 17280, 540, 17280, 17280, 540, 33, 540, 540, 540, 33, 17280, 540, 17280, 33, 17280, 33, 33, 540, 17280, 17280, 540, 33, 540, 33, 540, 17280, 17280, 540, 33, 540, 33, 17280, 33, 33, 33, 33, 17280, 540, 540, 17280, 540, 540, 33, 540, 17280, 540, 33, 33, 540, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 540, 17280, 540, 540, 540, 33, 17280, 33, 17280, 540, 33, 540, 33, 33, 540, 33, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 33, 33, 17280, 540, 17280, 540, 17280, 540, 33, 540, 33, 33, 33, 17280, 17280, 540, 540, 33, 33, 540, 33, 17280, 33, 33, 540, 33, 17280, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 33, 540, 17280, 540, 540, 17280, 540, 33, 540, 33, 17280, 540, 540, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 540, 33, 540, 33, 540, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 540, 540, 17280, 33, 17280, 33, 33, 33, 17280, 540, 17280, 17280, 33, 540, 540, 540, 33, 540, 33, 540, 540, 17280, 33, 33, 540, 33, 540, 540, 33, 17280, 17280, 17280, 33, 540, 540, 540, 540, 33, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 540, 540, 540, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1910238 . Total input tokens: 425397056 . Total output tokens: 382469408
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.71113469399279,
    "estimated_duration": 3600.0646253432496,
    "input_throughput": 4516.197538662189,
    "output_throughput": 3968.710422424081,
    "total_throughput": 8484.90796108627,
    "itl": 213.44543548088805,
    "ttft": 2149015.8448842443,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 861,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.574433303910719,
    "arrivals": 636613,
    "finished_requests": 65909,
    "scheduler_time": 80.62252214872689
}
#Debug simulation 
Total elapsed time: 4.711223375983536. Arrivals time: 0.21498669037828222 Scheduler time: 4.391573272005189 Scheduler overhead time: 0.026162420224864036 Adapter cache time: 0.04009903874248266 Engine time: 0.026221322477795184 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-32/adapters_320_slots_192_rate_1.6-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-32/adapters_320_slots_192_rate_1.6-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 33, 17280, 17280, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 17280, 17280, 540, 33, 33, 540, 17280, 17280, 540, 540, 33, 33, 540, 17280, 17280, 33, 17280, 540, 33, 540, 17280, 33, 540, 17280, 17280, 540, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 540, 540, 540, 33, 540, 33, 17280, 33, 17280, 540, 17280, 17280, 33, 17280, 33, 17280, 540, 33, 33, 540, 540, 17280, 540, 17280, 17280, 17280, 33, 540, 540, 33, 17280, 540, 17280, 17280, 540, 33, 540, 540, 540, 33, 17280, 540, 17280, 33, 17280, 33, 33, 540, 17280, 17280, 540, 33, 540, 33, 540, 17280, 17280, 540, 33, 540, 33, 17280, 33, 33, 33, 33, 17280, 540, 540, 17280, 540, 540, 33, 540, 17280, 540, 33, 33, 540, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 540, 17280, 540, 540, 540, 33, 17280, 33, 17280, 540, 33, 540, 33, 33, 540, 33, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 33, 33, 17280, 540, 17280, 540, 17280, 540, 33, 540, 33, 33, 33, 17280, 17280, 540, 540, 33, 33, 540, 33, 17280, 33, 33, 540, 33, 17280, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 33, 540, 17280, 540, 540, 17280, 540, 33, 540, 33, 17280, 540, 540, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 540, 33, 540, 33, 540, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 540, 540, 17280, 33, 17280, 33, 33, 33, 17280, 540, 17280, 17280, 33, 540, 540, 540, 33, 540, 33, 540, 540, 17280, 33, 33, 540, 33, 540, 540, 33, 17280, 17280, 17280, 33, 540, 540, 540, 540, 33, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 540, 540, 540, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1910238 . Total input tokens: 425397056 . Total output tokens: 382469408
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.2782958970055915,
    "estimated_duration": 3600.073774568436,
    "input_throughput": 3813.1201913065256,
    "output_throughput": 3368.929016309925,
    "total_throughput": 7182.049207616451,
    "itl": 100.2305919196913,
    "ttft": 2247543.156032511,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 744,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4912486511469,
    "arrivals": 636613,
    "finished_requests": 55695,
    "scheduler_time": 96.82500737541945
}
#Debug simulation 
Total elapsed time: 4.278379964001942. Arrivals time: 0.1974310969817452 Scheduler time: 3.8689637779607438 Scheduler overhead time: 0.04978822876000777 Adapter cache time: 0.08802516461582854 Engine time: 0.05036548036150634 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-8/adapters_320_slots_192_rate_1.6-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-8/adapters_320_slots_192_rate_1.6-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [106 107 107]
Adapter prompts. [270, 17280, 17280, 135, 17280, 17280, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 17280, 17280, 270, 135, 135, 270, 17280, 17280, 270, 270, 135, 135, 270, 17280, 17280, 135, 17280, 270, 135, 270, 17280, 135, 270, 17280, 17280, 270, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 270, 270, 270, 135, 270, 135, 17280, 135, 17280, 270, 17280, 17280, 135, 17280, 135, 17280, 270, 135, 135, 270, 270, 17280, 270, 17280, 17280, 17280, 135, 270, 270, 135, 17280, 270, 17280, 17280, 270, 135, 270, 270, 270, 135, 17280, 270, 17280, 135, 17280, 135, 135, 270, 17280, 17280, 270, 135, 270, 135, 270, 17280, 17280, 270, 135, 270, 135, 17280, 135, 135, 135, 135, 17280, 270, 270, 17280, 270, 270, 135, 270, 17280, 270, 135, 135, 270, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 270, 17280, 270, 270, 270, 135, 17280, 135, 17280, 270, 135, 270, 135, 135, 270, 135, 270, 17280, 17280, 17280, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 135, 135, 17280, 270, 17280, 270, 17280, 270, 135, 270, 135, 135, 135, 17280, 17280, 270, 270, 135, 135, 270, 135, 17280, 135, 135, 270, 135, 17280, 270, 135, 17280, 135, 135, 17280, 270, 17280, 270, 135, 270, 17280, 270, 270, 17280, 270, 135, 270, 135, 17280, 270, 270, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 270, 135, 270, 135, 270, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 270, 270, 17280, 135, 17280, 135, 135, 135, 17280, 270, 17280, 17280, 135, 270, 270, 270, 135, 270, 135, 270, 270, 17280, 135, 135, 270, 135, 270, 270, 135, 17280, 17280, 17280, 135, 270, 270, 270, 270, 135, 270, 135, 17280, 135, 135, 17280, 270, 17280, 270, 270, 270, 270, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 270, 17280, 270, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1892160 . Total input tokens: 421336932 . Total output tokens: 378846953
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.857420786982402,
    "estimated_duration": 3600.045565925418,
    "input_throughput": 4658.439648301784,
    "output_throughput": 4099.628110180914,
    "total_throughput": 8758.067758482697,
    "itl": 208.83607322293625,
    "ttft": 2131658.5925911563,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1029,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.149241888506877,
    "arrivals": 630527,
    "finished_requests": 67947,
    "scheduler_time": 82.99167644247872
}
#Debug simulation 
Total elapsed time: 4.857505859981757. Arrivals time: 0.224586698517669 Scheduler time: 4.533008725091349 Scheduler overhead time: 0.026761768851429224 Adapter cache time: 0.03367468650685623 Engine time: 0.027019721863325685 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-16/adapters_320_slots_192_rate_1.6-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-16/adapters_320_slots_192_rate_1.6-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [106 107 107]
Adapter prompts. [270, 17280, 17280, 135, 17280, 17280, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 17280, 17280, 270, 135, 135, 270, 17280, 17280, 270, 270, 135, 135, 270, 17280, 17280, 135, 17280, 270, 135, 270, 17280, 135, 270, 17280, 17280, 270, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 270, 270, 270, 135, 270, 135, 17280, 135, 17280, 270, 17280, 17280, 135, 17280, 135, 17280, 270, 135, 135, 270, 270, 17280, 270, 17280, 17280, 17280, 135, 270, 270, 135, 17280, 270, 17280, 17280, 270, 135, 270, 270, 270, 135, 17280, 270, 17280, 135, 17280, 135, 135, 270, 17280, 17280, 270, 135, 270, 135, 270, 17280, 17280, 270, 135, 270, 135, 17280, 135, 135, 135, 135, 17280, 270, 270, 17280, 270, 270, 135, 270, 17280, 270, 135, 135, 270, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 270, 17280, 270, 270, 270, 135, 17280, 135, 17280, 270, 135, 270, 135, 135, 270, 135, 270, 17280, 17280, 17280, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 135, 135, 17280, 270, 17280, 270, 17280, 270, 135, 270, 135, 135, 135, 17280, 17280, 270, 270, 135, 135, 270, 135, 17280, 135, 135, 270, 135, 17280, 270, 135, 17280, 135, 135, 17280, 270, 17280, 270, 135, 270, 17280, 270, 270, 17280, 270, 135, 270, 135, 17280, 270, 270, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 270, 135, 270, 135, 270, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 270, 270, 17280, 135, 17280, 135, 135, 135, 17280, 270, 17280, 17280, 135, 270, 270, 270, 135, 270, 135, 270, 270, 17280, 135, 135, 270, 135, 270, 270, 135, 17280, 17280, 17280, 135, 270, 270, 270, 270, 135, 270, 135, 17280, 135, 135, 17280, 270, 17280, 270, 270, 270, 270, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 270, 17280, 270, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1892160 . Total input tokens: 421336932 . Total output tokens: 378846953
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.850472557998728,
    "estimated_duration": 3600.2046742132734,
    "input_throughput": 4653.058233046343,
    "output_throughput": 4094.8558023917158,
    "total_throughput": 8747.91403543806,
    "itl": 206.92273951849626,
    "ttft": 2132390.7610051455,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1029,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3599183091335063,
    "arrivals": 630527,
    "finished_requests": 67876,
    "scheduler_time": 83.13627358700165
}
#Debug simulation 
Total elapsed time: 4.850559080950916. Arrivals time: 0.22601574496366084 Scheduler time: 4.523239976842888 Scheduler overhead time: 0.026930133812129498 Adapter cache time: 0.0343852445948869 Engine time: 0.02732828032458201 
