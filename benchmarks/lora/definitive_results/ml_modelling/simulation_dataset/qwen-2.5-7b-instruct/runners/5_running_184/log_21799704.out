INFO 06-01 00:46:59 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:46:59 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-16-16/adapters_32_slots_16_rate_3.2-0.8-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-16-16/adapters_32_slots_16_rate_3.2-0.8-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 270, 270, 8640, 270, 34560, 8640, 270, 270, 270, 34560, 34560, 270, 270, 8640, 8640, 8640, 34560, 34560, 270, 34560, 34560, 34560, 34560, 8640, 270, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 477900 . Total input tokens: 106601693 . Total output tokens: 95531295
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 115.60388336703181,
    "estimated_duration": 3600.06541710964,
    "input_throughput": 8720.60764529265,
    "output_throughput": 7744.107056361008,
    "total_throughput": 16464.71470165366,
    "itl": 111.0785578518645,
    "ttft": 751095.0208427721,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.050700971947517236,
    "arrivals": 159140,
    "finished_requests": 126554,
    "scheduler_time": 147.53031810886506
}
#Debug simulation 
Total elapsed time: 115.60410934221. Arrivals time: 0.49461833806708455 Scheduler time: 114.89116145204753 Scheduler overhead time: 0.08402764098718762 Adapter cache time: 0.016142231412231922 Engine time: 0.08742755418643355 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-16-32/adapters_32_slots_16_rate_3.2-0.8-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-16-32/adapters_32_slots_16_rate_3.2-0.8-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 270, 270, 8640, 270, 34560, 8640, 270, 270, 270, 34560, 34560, 270, 270, 8640, 8640, 8640, 34560, 34560, 270, 34560, 34560, 34560, 34560, 8640, 270, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 477900 . Total input tokens: 106601693 . Total output tokens: 95531295
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 114.22878590226173,
    "estimated_duration": 3600.0756718784287,
    "input_throughput": 8720.582804755048,
    "output_throughput": 7744.084997372649,
    "total_throughput": 16464.667802127697,
    "itl": 111.07824964207737,
    "ttft": 751095.0164552119,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.0538350417278707,
    "arrivals": 159140,
    "finished_requests": 126554,
    "scheduler_time": 147.53075017408898
}
#Debug simulation 
Total elapsed time: 114.2289947043173. Arrivals time: 0.5101174167357385 Scheduler time: 113.49589486699551 Scheduler overhead time: 0.08783059567213058 Adapter cache time: 0.016002497635781765 Engine time: 0.08868107991293073 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_16-16-16/adapters_32_slots_16_rate_3.2-0.8-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_16-16-16/adapters_32_slots_16_rate_3.2-0.8-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 270, 270, 8640, 270, 34560, 8640, 270, 270, 270, 34560, 34560, 270, 270, 8640, 8640, 8640, 34560, 34560, 270, 34560, 34560, 34560, 34560, 8640, 270, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 477900 . Total input tokens: 106601693 . Total output tokens: 95531295
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 115.78247293224558,
    "estimated_duration": 3600.0523465697916,
    "input_throughput": 8720.639306790528,
    "output_throughput": 7744.135172524366,
    "total_throughput": 16464.774479314892,
    "itl": 111.07854441029482,
    "ttft": 751074.8127640828,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 159140,
    "finished_requests": 126554,
    "scheduler_time": 147.5294974116347
}
#Debug simulation 
Total elapsed time: 115.7826453470625. Arrivals time: 0.5101081854663789 Scheduler time: 115.05238204915076 Scheduler overhead time: 0.08625195687636733 Adapter cache time: 0.016207942739129066 Engine time: 0.08677352545782924 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_16-16-32/adapters_32_slots_16_rate_3.2-0.8-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_16-16-32/adapters_32_slots_16_rate_3.2-0.8-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 270, 270, 8640, 270, 34560, 8640, 270, 270, 270, 34560, 34560, 270, 270, 8640, 8640, 8640, 34560, 34560, 270, 34560, 34560, 34560, 34560, 8640, 270, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 477900 . Total input tokens: 106601693 . Total output tokens: 95531295
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 115.30882270261645,
    "estimated_duration": 3600.0826843394652,
    "input_throughput": 8720.565818270987,
    "output_throughput": 7744.069912970687,
    "total_throughput": 16464.635731241673,
    "itl": 111.07831013483258,
    "ttft": 751097.8780861842,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05471531823277473,
    "arrivals": 159140,
    "finished_requests": 126554,
    "scheduler_time": 147.53128673135356
}
#Debug simulation 
Total elapsed time: 115.30900419456884. Arrivals time: 0.5031537925824523 Scheduler time: 114.58844717685133 Scheduler overhead time: 0.08509068517014384 Adapter cache time: 0.016125452239066362 Engine time: 0.0854572276584804 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-8/adapters_32_slots_16_rate_3.2-0.8-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-8/adapters_32_slots_16_rate_3.2-0.8-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 135, 135, 8640, 135, 34560, 8640, 135, 135, 135, 34560, 34560, 135, 135, 8640, 8640, 8640, 34560, 34560, 135, 34560, 34560, 34560, 34560, 8640, 135, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 476550 . Total input tokens: 106318766 . Total output tokens: 95254797
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 173.10243095410988,
    "estimated_duration": 3600.048082035225,
    "input_throughput": 8779.94856727881,
    "output_throughput": 7736.205563192112,
    "total_throughput": 16516.15413047092,
    "itl": 109.70482827656829,
    "ttft": 643608.0346529329,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 18,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05508877939078958,
    "arrivals": 158673,
    "finished_requests": 127153,
    "scheduler_time": 146.66475050562306
}
#Debug simulation 
Total elapsed time: 173.1025949632749. Arrivals time: 0.5200324030593038 Scheduler time: 172.35000581247732 Scheduler overhead time: 0.09165715891867876 Adapter cache time: 0.0167995011433959 Engine time: 0.09109263494610786 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-16/adapters_32_slots_16_rate_3.2-0.8-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-16/adapters_32_slots_16_rate_3.2-0.8-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 135, 135, 8640, 135, 34560, 8640, 135, 135, 135, 34560, 34560, 135, 135, 8640, 8640, 8640, 34560, 34560, 135, 34560, 34560, 34560, 34560, 8640, 135, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 476550 . Total input tokens: 106318766 . Total output tokens: 95254797
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 173.71961525129154,
    "estimated_duration": 3600.0036313387413,
    "input_throughput": 8779.875310360734,
    "output_throughput": 7736.2333075322995,
    "total_throughput": 16516.108617893035,
    "itl": 109.70473502806321,
    "ttft": 643633.2198098074,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 18,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05954123976640402,
    "arrivals": 158673,
    "finished_requests": 127152,
    "scheduler_time": 146.662249489418
}
#Debug simulation 
Total elapsed time: 173.71978887030855. Arrivals time: 0.5172729520127177 Scheduler time: 172.9762373189442 Scheduler overhead time: 0.08895462471991777 Adapter cache time: 0.01642189361155033 Engine time: 0.08905064640566707 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-32/adapters_32_slots_16_rate_3.2-0.8-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-32/adapters_32_slots_16_rate_3.2-0.8-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 135, 135, 8640, 135, 34560, 8640, 135, 135, 135, 34560, 34560, 135, 135, 8640, 8640, 8640, 34560, 34560, 135, 34560, 34560, 34560, 34560, 8640, 135, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 476550 . Total input tokens: 106318766 . Total output tokens: 95254797
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 173.71164880739525,
    "estimated_duration": 3600.0035989549915,
    "input_throughput": 8779.8753893399,
    "output_throughput": 7736.233377123409,
    "total_throughput": 16516.10876646331,
    "itl": 109.70473720368133,
    "ttft": 643633.1946299474,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 18,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05950480420142411,
    "arrivals": 158673,
    "finished_requests": 127152,
    "scheduler_time": 146.66225027461917
}
#Debug simulation 
Total elapsed time: 173.71190212201327. Arrivals time: 0.5271027064882219 Scheduler time: 172.9549471028149 Scheduler overhead time: 0.09053390240296721 Adapter cache time: 0.016430572140961885 Engine time: 0.0906281634233892 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-16/adapters_32_slots_16_rate_3.2-0.8-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-16/adapters_32_slots_16_rate_3.2-0.8-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 135, 135, 8640, 135, 34560, 8640, 135, 135, 135, 34560, 34560, 135, 135, 8640, 8640, 8640, 34560, 34560, 135, 34560, 34560, 34560, 34560, 8640, 135, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 476550 . Total input tokens: 106318766 . Total output tokens: 95254797
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 174.26695592980832,
    "estimated_duration": 3600.051301359561,
    "input_throughput": 8779.940715862336,
    "output_throughput": 7736.198645136576,
    "total_throughput": 16516.13936099891,
    "itl": 109.70473157085706,
    "ttft": 643608.4477977306,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 18,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05668107253732158,
    "arrivals": 158673,
    "finished_requests": 127153,
    "scheduler_time": 146.6650453218418
}
#Debug simulation 
Total elapsed time: 174.26712273666635. Arrivals time: 0.5175509280525148 Scheduler time: 173.5216565555893 Scheduler overhead time: 0.08895956398919225 Adapter cache time: 0.017159519251435995 Engine time: 0.09029500233009458 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-32/adapters_32_slots_16_rate_3.2-0.8-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-32/adapters_32_slots_16_rate_3.2-0.8-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 135, 135, 8640, 135, 34560, 8640, 135, 135, 135, 34560, 34560, 135, 135, 8640, 8640, 8640, 34560, 34560, 135, 34560, 34560, 34560, 34560, 8640, 135, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 476550 . Total input tokens: 106318766 . Total output tokens: 95254797
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 174.76561337709427,
    "estimated_duration": 3600.0052994364387,
    "input_throughput": 8779.87124211956,
    "output_throughput": 7736.229722872864,
    "total_throughput": 16516.100964992424,
    "itl": 109.70476694717529,
    "ttft": 643632.6736226869,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 18,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.06038508070632814,
    "arrivals": 158673,
    "finished_requests": 127152,
    "scheduler_time": 146.66227588745787
}
#Debug simulation 
Total elapsed time: 174.76578247221187. Arrivals time: 0.5223722960799932 Scheduler time: 174.0124104442075 Scheduler overhead time: 0.091171286534518 Adapter cache time: 0.016842631623148918 Engine time: 0.09149412717670202 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-16/adapters_32_slots_16_rate_3.2-0.8-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-16/adapters_32_slots_16_rate_3.2-0.8-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 135, 135, 8640, 135, 34560, 8640, 135, 135, 135, 34560, 34560, 135, 135, 8640, 8640, 8640, 34560, 34560, 135, 34560, 34560, 34560, 34560, 8640, 135, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 476550 . Total input tokens: 106318766 . Total output tokens: 95254797
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 174.39653590833768,
    "estimated_duration": 3600.0484202880602,
    "input_throughput": 8779.947742333656,
    "output_throughput": 7736.204836314814,
    "total_throughput": 16516.15257864847,
    "itl": 109.7049789449392,
    "ttft": 643608.2890072812,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 18,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05382090530823915,
    "arrivals": 158673,
    "finished_requests": 127153,
    "scheduler_time": 146.66484543734643
}
#Debug simulation 
Total elapsed time: 174.39669944811612. Arrivals time: 0.5328223239630461 Scheduler time: 173.63373746629804 Scheduler overhead time: 0.0904794093221426 Adapter cache time: 0.016982325352728367 Engine time: 0.09126351401209831 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-32/adapters_32_slots_16_rate_3.2-0.8-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-32/adapters_32_slots_16_rate_3.2-0.8-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 135, 135, 8640, 135, 34560, 8640, 135, 135, 135, 34560, 34560, 135, 135, 8640, 8640, 8640, 34560, 34560, 135, 34560, 34560, 34560, 34560, 8640, 135, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 476550 . Total input tokens: 106318766 . Total output tokens: 95254797
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 175.3034943700768,
    "estimated_duration": 3600.0037650266613,
    "input_throughput": 8779.874984315722,
    "output_throughput": 7736.2330202434505,
    "total_throughput": 16516.108004559173,
    "itl": 109.70467138268039,
    "ttft": 643631.8932324221,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 18,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.06126535721123218,
    "arrivals": 158673,
    "finished_requests": 127152,
    "scheduler_time": 146.66216208852111
}
#Debug simulation 
Total elapsed time: 175.30365770310163. Arrivals time: 0.5347828092053533 Scheduler time: 174.538312620949 Scheduler overhead time: 0.09043981228023767 Adapter cache time: 0.01657791482284665 Engine time: 0.09204004006460309 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-8/adapters_32_slots_16_rate_3.2-0.8-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-8/adapters_32_slots_16_rate_3.2-0.8-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 66, 66, 8640, 66, 34560, 8640, 66, 66, 66, 34560, 34560, 66, 66, 8640, 8640, 8640, 34560, 34560, 66, 34560, 34560, 34560, 34560, 8640, 66, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 475860 . Total input tokens: 106162778 . Total output tokens: 95110281
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 115.67059465032071,
    "estimated_duration": 3600.109971650696,
    "input_throughput": 8739.958014552813,
    "output_throughput": 7745.1497925256745,
    "total_throughput": 16485.107807078486,
    "itl": 110.70443874879022,
    "ttft": 740601.8027167637,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 17,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05202829164685682,
    "arrivals": 158470,
    "finished_requests": 127201,
    "scheduler_time": 146.13035325539127
}
#Debug simulation 
Total elapsed time: 115.67077509034425. Arrivals time: 0.5148745281621814 Scheduler time: 114.93708977662027 Scheduler overhead time: 0.085158571600914 Adapter cache time: 0.01582628907635808 Engine time: 0.0868010176345706 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-16/adapters_32_slots_16_rate_3.2-0.8-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-16/adapters_32_slots_16_rate_3.2-0.8-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 66, 66, 8640, 66, 34560, 8640, 66, 66, 66, 34560, 34560, 66, 66, 8640, 8640, 8640, 34560, 34560, 66, 34560, 34560, 34560, 34560, 8640, 66, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 475860 . Total input tokens: 106162778 . Total output tokens: 95110281
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 115.64632193511352,
    "estimated_duration": 3600.0258092862914,
    "input_throughput": 8740.162339624429,
    "output_throughput": 7745.330860705109,
    "total_throughput": 16485.49320032954,
    "itl": 110.7046856228973,
    "ttft": 740563.7076268083,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 17,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.056551189471501846,
    "arrivals": 158470,
    "finished_requests": 127201,
    "scheduler_time": 146.12625737903502
}
#Debug simulation 
Total elapsed time: 115.64650002401322. Arrivals time: 0.515438667498529 Scheduler time: 114.90931874560192 Scheduler overhead time: 0.08631048072129488 Adapter cache time: 0.016011377796530724 Engine time: 0.08766463631764054 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-32/adapters_32_slots_16_rate_3.2-0.8-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-32/adapters_32_slots_16_rate_3.2-0.8-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 66, 66, 8640, 66, 34560, 8640, 66, 66, 66, 34560, 34560, 66, 66, 8640, 8640, 8640, 34560, 34560, 66, 34560, 34560, 34560, 34560, 8640, 66, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 475860 . Total input tokens: 106162778 . Total output tokens: 95110281
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 116.84847725601867,
    "estimated_duration": 3600.025711186588,
    "input_throughput": 8740.16257779143,
    "output_throughput": 7745.33107176323,
    "total_throughput": 16485.49364955466,
    "itl": 110.70468598218027,
    "ttft": 740563.6291810937,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 17,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.0564612853527069,
    "arrivals": 158470,
    "finished_requests": 127201,
    "scheduler_time": 146.12624918345205
}
#Debug simulation 
Total elapsed time: 116.84876023605466. Arrivals time: 0.5182786108925939 Scheduler time: 116.108562188223 Scheduler overhead time: 0.08658461831510067 Adapter cache time: 0.016407984774559736 Engine time: 0.0880643823184073 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-16/adapters_32_slots_16_rate_3.2-0.8-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-16/adapters_32_slots_16_rate_3.2-0.8-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 66, 66, 8640, 66, 34560, 8640, 66, 66, 66, 34560, 34560, 66, 66, 8640, 8640, 8640, 34560, 34560, 66, 34560, 34560, 34560, 34560, 8640, 66, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 475860 . Total input tokens: 106162778 . Total output tokens: 95110281
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 115.7835939200595,
    "estimated_duration": 3600.0162689259764,
    "input_throughput": 8740.185501824737,
    "output_throughput": 7745.351386514342,
    "total_throughput": 16485.536888339077,
    "itl": 110.70465258927685,
    "ttft": 740560.4170348465,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 17,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.054508212879300105,
    "arrivals": 158470,
    "finished_requests": 127201,
    "scheduler_time": 146.12546013023098
}
#Debug simulation 
Total elapsed time: 115.78377882484347. Arrivals time: 0.5032825255766511 Scheduler time: 115.05810676561669 Scheduler overhead time: 0.0873104864731431 Adapter cache time: 0.01612309506163001 Engine time: 0.08804894937202334 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-32/adapters_32_slots_16_rate_3.2-0.8-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-32/adapters_32_slots_16_rate_3.2-0.8-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 66, 66, 8640, 66, 34560, 8640, 66, 66, 66, 34560, 34560, 66, 66, 8640, 8640, 8640, 34560, 34560, 66, 34560, 34560, 34560, 34560, 8640, 66, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 475860 . Total input tokens: 106162778 . Total output tokens: 95110281
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 114.84718939522281,
    "estimated_duration": 3600.030653251123,
    "input_throughput": 8740.150579435955,
    "output_throughput": 7745.320439096542,
    "total_throughput": 16485.471018532495,
    "itl": 110.7047297945549,
    "ttft": 740563.4979137689,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 17,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.057090054284781214,
    "arrivals": 158470,
    "finished_requests": 127201,
    "scheduler_time": 146.12647729832645
}
#Debug simulation 
Total elapsed time: 114.84737544506788. Arrivals time: 0.5137913711369038 Scheduler time: 114.11302958568558 Scheduler overhead time: 0.08604439115151763 Adapter cache time: 0.015902599319815636 Engine time: 0.08749338518828154 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-16/adapters_32_slots_16_rate_3.2-0.8-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-16/adapters_32_slots_16_rate_3.2-0.8-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 66, 66, 8640, 66, 34560, 8640, 66, 66, 66, 34560, 34560, 66, 66, 8640, 8640, 8640, 34560, 34560, 66, 34560, 34560, 34560, 34560, 8640, 66, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 475860 . Total input tokens: 106162778 . Total output tokens: 95110281
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 116.2041470981203,
    "estimated_duration": 3600.1078403949896,
    "input_throughput": 8739.963188588208,
    "output_throughput": 7745.15437763685,
    "total_throughput": 16485.117566225057,
    "itl": 110.70456851218479,
    "ttft": 740602.1232130631,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 17,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05083085501333698,
    "arrivals": 158470,
    "finished_requests": 127201,
    "scheduler_time": 146.130319783546
}
#Debug simulation 
Total elapsed time: 116.20432033622637. Arrivals time: 0.5166538208723068 Scheduler time: 115.46498278481886 Scheduler overhead time: 0.08689110493287444 Adapter cache time: 0.0160901783965528 Engine time: 0.0878720530308783 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-32/adapters_32_slots_16_rate_3.2-0.8-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-32/adapters_32_slots_16_rate_3.2-0.8-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 66, 66, 8640, 66, 34560, 8640, 66, 66, 66, 34560, 34560, 66, 66, 8640, 8640, 8640, 34560, 34560, 66, 34560, 34560, 34560, 34560, 8640, 66, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 475860 . Total input tokens: 106162778 . Total output tokens: 95110281
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 115.78052048524842,
    "estimated_duration": 3600.030759842509,
    "input_throughput": 8740.150320653509,
    "output_throughput": 7745.320209769491,
    "total_throughput": 16485.470530423,
    "itl": 110.70449098054323,
    "ttft": 740580.1434733155,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 17,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.058221838362514974,
    "arrivals": 158470,
    "finished_requests": 127201,
    "scheduler_time": 146.12624921569204
}
#Debug simulation 
Total elapsed time: 115.7807008381933. Arrivals time: 0.5072164726443589 Scheduler time: 115.05178198497742 Scheduler overhead time: 0.08699654648080468 Adapter cache time: 0.01629587123170495 Engine time: 0.08740127412602305 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-8/adapters_32_slots_16_rate_3.2-0.8-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-8/adapters_32_slots_16_rate_3.2-0.8-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 33, 33, 8640, 33, 34560, 8640, 33, 33, 33, 34560, 34560, 33, 33, 8640, 8640, 8640, 34560, 34560, 33, 34560, 34560, 34560, 34560, 8640, 33, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 475530 . Total input tokens: 106083481 . Total output tokens: 95045931
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 112.21607842389494,
    "estimated_duration": 3600.1175317861102,
    "input_throughput": 8786.344812555777,
    "output_throughput": 7735.193019152375,
    "total_throughput": 16521.537831708152,
    "itl": 110.24842612846933,
    "ttft": 737340.1480345282,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 20,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.06120975487865509,
    "arrivals": 158357,
    "finished_requests": 127371,
    "scheduler_time": 145.66163047678126
}
#Debug simulation 
Total elapsed time: 112.216255558189. Arrivals time: 0.5102430060505867 Scheduler time: 111.48496615234762 Scheduler overhead time: 0.08574266685172915 Adapter cache time: 0.01529010059311986 Engine time: 0.08879957534372807 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-16/adapters_32_slots_16_rate_3.2-0.8-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-16/adapters_32_slots_16_rate_3.2-0.8-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 33, 33, 8640, 33, 34560, 8640, 33, 33, 33, 34560, 34560, 33, 33, 8640, 8640, 8640, 34560, 34560, 33, 34560, 34560, 34560, 34560, 8640, 33, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 475530 . Total input tokens: 106083481 . Total output tokens: 95045931
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 112.1461649602279,
    "estimated_duration": 3600.002854073939,
    "input_throughput": 8786.609145102175,
    "output_throughput": 7735.351645204017,
    "total_throughput": 16521.96079030619,
    "itl": 110.24759846278428,
    "ttft": 737312.7227704858,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 20,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.06633853099308906,
    "arrivals": 158357,
    "finished_requests": 127369,
    "scheduler_time": 145.65635709818207
}
#Debug simulation 
Total elapsed time: 112.1463522859849. Arrivals time: 0.503511703107506 Scheduler time: 111.4221461713314 Scheduler overhead time: 0.08656158810481429 Adapter cache time: 0.015648276079446077 Engine time: 0.08725372655317187 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-32/adapters_32_slots_16_rate_3.2-0.8-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-32/adapters_32_slots_16_rate_3.2-0.8-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 33, 33, 8640, 33, 34560, 8640, 33, 33, 33, 34560, 34560, 33, 33, 8640, 8640, 8640, 34560, 34560, 33, 34560, 34560, 34560, 34560, 8640, 33, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 475530 . Total input tokens: 106083481 . Total output tokens: 95045931
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 111.89951496198773,
    "estimated_duration": 3600.0027745224356,
    "input_throughput": 8786.60933926535,
    "output_throughput": 7735.351816136899,
    "total_throughput": 16521.96115540225,
    "itl": 110.2475994907039,
    "ttft": 737312.6590907798,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 20,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.06626633688807486,
    "arrivals": 158357,
    "finished_requests": 127369,
    "scheduler_time": 145.6563497407837
}
#Debug simulation 
Total elapsed time: 111.89978451374918. Arrivals time: 0.5159878162667155 Scheduler time: 111.1598073435016 Scheduler overhead time: 0.08750999439507723 Adapter cache time: 0.016166599933058023 Engine time: 0.08871966227889061 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-16/adapters_32_slots_16_rate_3.2-0.8-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-16/adapters_32_slots_16_rate_3.2-0.8-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 33, 33, 8640, 33, 34560, 8640, 33, 33, 33, 34560, 34560, 33, 33, 8640, 8640, 8640, 34560, 34560, 33, 34560, 34560, 34560, 34560, 8640, 33, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 475530 . Total input tokens: 106083481 . Total output tokens: 95045931
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 112.15738717000932,
    "estimated_duration": 3600.121984555531,
    "input_throughput": 8786.472829449225,
    "output_throughput": 7735.239005641103,
    "total_throughput": 16521.71183509033,
    "itl": 110.24825091659267,
    "ttft": 737320.5502187064,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 20,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.06347836376400663,
    "arrivals": 158357,
    "finished_requests": 127372,
    "scheduler_time": 145.6619952278552
}
#Debug simulation 
Total elapsed time: 112.15755934128538. Arrivals time: 0.5069579062983394 Scheduler time: 111.42905237525702 Scheduler overhead time: 0.08619837695732713 Adapter cache time: 0.015707680955529213 Engine time: 0.08849237160757184 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-32/adapters_32_slots_16_rate_3.2-0.8-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-32/adapters_32_slots_16_rate_3.2-0.8-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 33, 33, 8640, 33, 34560, 8640, 33, 33, 33, 34560, 34560, 33, 33, 8640, 8640, 8640, 34560, 34560, 33, 34560, 34560, 34560, 34560, 8640, 33, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 475530 . Total input tokens: 106083481 . Total output tokens: 95045931
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 111.41001347731799,
    "estimated_duration": 3600.0032482442075,
    "input_throughput": 8786.608183041908,
    "output_throughput": 7735.35079824766,
    "total_throughput": 16521.95898128957,
    "itl": 110.24758005084318,
    "ttft": 737312.5793864699,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 20,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.0671466133929789,
    "arrivals": 158357,
    "finished_requests": 127369,
    "scheduler_time": 145.65634334037196
}
#Debug simulation 
Total elapsed time: 111.41019391221926. Arrivals time: 0.5067165144719183 Scheduler time: 110.68188239727169 Scheduler overhead time: 0.0853931549936533 Adapter cache time: 0.015941630117595196 Engine time: 0.08905092533677816 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-16/adapters_32_slots_16_rate_3.2-0.8-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-16/adapters_32_slots_16_rate_3.2-0.8-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 33, 33, 8640, 33, 34560, 8640, 33, 33, 33, 34560, 34560, 33, 33, 8640, 8640, 8640, 34560, 34560, 33, 34560, 34560, 34560, 34560, 8640, 33, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 475530 . Total input tokens: 106083481 . Total output tokens: 95045931
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 111.96471978025511,
    "estimated_duration": 3600.086778108495,
    "input_throughput": 8786.419869750905,
    "output_throughput": 7735.259096901904,
    "total_throughput": 16521.67896665281,
    "itl": 110.24762405130751,
    "ttft": 737287.8735866988,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 20,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.0598010058980435,
    "arrivals": 158357,
    "finished_requests": 127371,
    "scheduler_time": 145.6602947173237
}
#Debug simulation 
Total elapsed time: 111.96489768195897. Arrivals time: 0.49645167402923107 Scheduler time: 111.25081707397476 Scheduler overhead time: 0.08536694664508104 Adapter cache time: 0.015476886183023453 Engine time: 0.08609176380559802 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-32/adapters_32_slots_16_rate_3.2-0.8-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-32/adapters_32_slots_16_rate_3.2-0.8-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 33, 33, 8640, 33, 34560, 8640, 33, 33, 33, 34560, 34560, 33, 33, 8640, 8640, 8640, 34560, 34560, 33, 34560, 34560, 34560, 34560, 8640, 33, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 475530 . Total input tokens: 106083481 . Total output tokens: 95045931
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 111.82090380089357,
    "estimated_duration": 3600.0090178922237,
    "input_throughput": 8786.59410095594,
    "output_throughput": 7735.338400986663,
    "total_throughput": 16521.932501942603,
    "itl": 110.2474621768629,
    "ttft": 737314.9854211976,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 20,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.06827839747071265,
    "arrivals": 158357,
    "finished_requests": 127369,
    "scheduler_time": 145.65681476803334
}
#Debug simulation 
Total elapsed time: 111.82107867486775. Arrivals time: 0.5040738466195762 Scheduler time: 111.0941998702474 Scheduler overhead time: 0.08726319018751383 Adapter cache time: 0.01603493234142661 Engine time: 0.08765031304210424 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-8/adapters_32_slots_16_rate_3.2-0.4-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-8/adapters_32_slots_16_rate_3.2-0.4-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 1080, 1080, 4320, 1080, 34560, 4320, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 4320, 4320, 4320, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 4320, 1080, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 438480 . Total input tokens: 97768473 . Total output tokens: 87638546
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 85.93538600299507,
    "estimated_duration": 3600.06157429387,
    "input_throughput": 8747.478438942217,
    "output_throughput": 7779.496384167634,
    "total_throughput": 16526.97482310985,
    "itl": 110.40573332952668,
    "ttft": 517704.067316026,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 25,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.07651219359831885,
    "arrivals": 145872,
    "finished_requests": 127192,
    "scheduler_time": 131.6100577421881
}
#Debug simulation 
Total elapsed time: 85.93556716106832. Arrivals time: 0.4712839648127556 Scheduler time: 85.25400685379282 Scheduler overhead time: 0.08243688754737377 Adapter cache time: 0.014907421544194221 Engine time: 0.08284140098839998 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-16/adapters_32_slots_16_rate_3.2-0.4-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-16/adapters_32_slots_16_rate_3.2-0.4-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 1080, 1080, 4320, 1080, 34560, 4320, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 4320, 4320, 4320, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 4320, 1080, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 438480 . Total input tokens: 97768473 . Total output tokens: 87638546
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 90.8236483251676,
    "estimated_duration": 3600.0812520001377,
    "input_throughput": 8747.43062604599,
    "output_throughput": 7779.453862170478,
    "total_throughput": 16526.88448821647,
    "itl": 110.40555077178506,
    "ttft": 517725.45391733694,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 25,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.08210597310448063,
    "arrivals": 145872,
    "finished_requests": 127192,
    "scheduler_time": 131.61086845523124
}
#Debug simulation 
Total elapsed time: 90.82382492907345. Arrivals time: 0.466167735401541 Scheduler time: 90.14793492201716 Scheduler overhead time: 0.08055218402296305 Adapter cache time: 0.01487724669277668 Engine time: 0.08446396281942725 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-32/adapters_32_slots_16_rate_3.2-0.4-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-32/adapters_32_slots_16_rate_3.2-0.4-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 1080, 1080, 4320, 1080, 34560, 4320, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 4320, 4320, 4320, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 4320, 1080, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 438480 . Total input tokens: 97768473 . Total output tokens: 87638546
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 85.6806851667352,
    "estimated_duration": 3600.0813102273164,
    "input_throughput": 8747.430484566352,
    "output_throughput": 7779.45373634675,
    "total_throughput": 16526.8842209131,
    "itl": 110.40555121466271,
    "ttft": 517725.50249950244,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 25,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.08215842612087725,
    "arrivals": 145872,
    "finished_requests": 127192,
    "scheduler_time": 131.61087422939204
}
#Debug simulation 
Total elapsed time: 85.68094655964524. Arrivals time: 0.4589907256886363 Scheduler time: 85.01478456705809 Scheduler overhead time: 0.08095670910552144 Adapter cache time: 0.014194427523761988 Engine time: 0.08287878660485148 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-16-16/adapters_32_slots_16_rate_3.2-0.4-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-16-16/adapters_32_slots_16_rate_3.2-0.4-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 1080, 1080, 4320, 1080, 34560, 4320, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 4320, 4320, 4320, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 4320, 1080, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 438480 . Total input tokens: 97768473 . Total output tokens: 87638546
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 85.83630104921758,
    "estimated_duration": 3600.06547554681,
    "input_throughput": 8747.468959635185,
    "output_throughput": 7779.487953825645,
    "total_throughput": 16526.95691346083,
    "itl": 110.4055137790279,
    "ttft": 517703.2348548937,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 25,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.07842861523851752,
    "arrivals": 145872,
    "finished_requests": 127192,
    "scheduler_time": 131.61006800278778
}
#Debug simulation 
Total elapsed time: 85.8364738970995. Arrivals time: 0.4519518003799021 Scheduler time: 85.17461843555793 Scheduler overhead time: 0.08247404079884291 Adapter cache time: 0.015125649515539408 Engine time: 0.08254146762192249 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-16-32/adapters_32_slots_16_rate_3.2-0.4-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-16-32/adapters_32_slots_16_rate_3.2-0.4-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 1080, 1080, 4320, 1080, 34560, 4320, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 4320, 4320, 4320, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 4320, 1080, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 438480 . Total input tokens: 97768473 . Total output tokens: 87638546
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 85.52261267602444,
    "estimated_duration": 3600.088493447234,
    "input_throughput": 8747.413030907364,
    "output_throughput": 7779.438214081914,
    "total_throughput": 16526.85124498928,
    "itl": 110.40549095137014,
    "ttft": 517770.9477031037,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 25,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.08329021019861098,
    "arrivals": 145872,
    "finished_requests": 127192,
    "scheduler_time": 131.61152358189045
}
#Debug simulation 
Total elapsed time: 85.5227958606556. Arrivals time: 0.44687750888988376 Scheduler time: 84.86453185463324 Scheduler overhead time: 0.08327968744561076 Adapter cache time: 0.01478371350094676 Engine time: 0.08323364285752177 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_16-16-16/adapters_32_slots_16_rate_3.2-0.4-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_16-16-16/adapters_32_slots_16_rate_3.2-0.4-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 1080, 1080, 4320, 1080, 34560, 4320, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 4320, 4320, 4320, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 4320, 1080, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 438480 . Total input tokens: 97768473 . Total output tokens: 87638546
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 85.58596847392619,
    "estimated_duration": 3600.04709436485,
    "input_throughput": 8747.513622611646,
    "output_throughput": 7779.527674468149,
    "total_throughput": 16527.041297079795,
    "itl": 110.4055996538378,
    "ttft": 517704.1663096653,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 25,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.07475125737255439,
    "arrivals": 145872,
    "finished_requests": 127192,
    "scheduler_time": 131.6094040822176
}
#Debug simulation 
Total elapsed time: 85.58614932419732. Arrivals time: 0.4407300208695233 Scheduler time: 84.93743030540645 Scheduler overhead time: 0.08113113977015018 Adapter cache time: 0.015150961931794882 Engine time: 0.08212774386629462 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_16-16-32/adapters_32_slots_16_rate_3.2-0.4-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_16-16-32/adapters_32_slots_16_rate_3.2-0.4-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 1080, 1080, 4320, 1080, 34560, 4320, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 4320, 4320, 4320, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 4320, 1080, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 438480 . Total input tokens: 97768473 . Total output tokens: 87638546
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 85.71313631907105,
    "estimated_duration": 3600.09394832038,
    "input_throughput": 8747.39977680091,
    "output_throughput": 7779.426426653804,
    "total_throughput": 16526.826203454715,
    "itl": 110.40556608085772,
    "ttft": 517768.6242590463,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 25,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.08442199427634473,
    "arrivals": 145872,
    "finished_requests": 127192,
    "scheduler_time": 131.6115450120177
}
#Debug simulation 
Total elapsed time: 85.71332299429923. Arrivals time: 0.4651362206786871 Scheduler time: 85.0418587489985 Scheduler overhead time: 0.08015086688101292 Adapter cache time: 0.014709186274558306 Engine time: 0.08198136370629072 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-8/adapters_32_slots_16_rate_3.2-0.4-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-8/adapters_32_slots_16_rate_3.2-0.4-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 540, 540, 4320, 540, 34560, 4320, 540, 540, 540, 34560, 34560, 540, 540, 4320, 4320, 4320, 34560, 34560, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 433080 . Total input tokens: 96509300 . Total output tokens: 86563691
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 77.94071047985926,
    "estimated_duration": 3600.0313513200085,
    "input_throughput": 8779.973260069071,
    "output_throughput": 7780.485575418585,
    "total_throughput": 16560.458835487654,
    "itl": 109.94262240670078,
    "ttft": 463734.54837555386,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 18,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05508877939078958,
    "arrivals": 144123,
    "finished_requests": 127690,
    "scheduler_time": 128.93988332291113
}
#Debug simulation 
Total elapsed time: 77.94089230289683. Arrivals time: 0.4588305684737861 Scheduler time: 77.27786097442731 Scheduler overhead time: 0.07997201243415475 Adapter cache time: 0.014790905173867941 Engine time: 0.08030462078750134 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-16/adapters_32_slots_16_rate_3.2-0.4-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-16/adapters_32_slots_16_rate_3.2-0.4-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 540, 540, 4320, 540, 34560, 4320, 540, 540, 540, 34560, 34560, 540, 540, 4320, 4320, 4320, 34560, 34560, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 433080 . Total input tokens: 96509300 . Total output tokens: 86563691
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 77.92036270815879,
    "estimated_duration": 3600.045514120411,
    "input_throughput": 8779.938719114427,
    "output_throughput": 7780.454966509945,
    "total_throughput": 16560.39368562437,
    "itl": 109.94218746950075,
    "ttft": 463737.410733131,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 18,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05954123976640402,
    "arrivals": 144123,
    "finished_requests": 127690,
    "scheduler_time": 128.94069199867678
}
#Debug simulation 
Total elapsed time: 77.92055289819837. Arrivals time: 0.4519898942671716 Scheduler time: 77.26272246520966 Scheduler overhead time: 0.08069783821702003 Adapter cache time: 0.014367165975272655 Engine time: 0.08152016717940569 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-32/adapters_32_slots_16_rate_3.2-0.4-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-32/adapters_32_slots_16_rate_3.2-0.4-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 540, 540, 4320, 540, 34560, 4320, 540, 540, 540, 34560, 34560, 540, 540, 4320, 4320, 4320, 34560, 34560, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 433080 . Total input tokens: 96509300 . Total output tokens: 86563691
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 78.01937042921782,
    "estimated_duration": 3600.0455873561327,
    "input_throughput": 8779.938540504147,
    "output_throughput": 7780.454808232162,
    "total_throughput": 16560.39334873631,
    "itl": 109.94219410388166,
    "ttft": 463737.4702549443,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 18,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05950480420142411,
    "arrivals": 144123,
    "finished_requests": 127690,
    "scheduler_time": 128.94070163138232
}
#Debug simulation 
Total elapsed time: 78.0196781042032. Arrivals time: 0.4557036217302084 Scheduler time: 77.36005902010947 Scheduler overhead time: 0.07910446636378765 Adapter cache time: 0.015076982323080301 Engine time: 0.08014527661725879 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-16-16/adapters_32_slots_16_rate_3.2-0.4-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-16-16/adapters_32_slots_16_rate_3.2-0.4-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 540, 540, 4320, 540, 34560, 4320, 540, 540, 540, 34560, 34560, 540, 540, 4320, 4320, 4320, 34560, 34560, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 433080 . Total input tokens: 96509300 . Total output tokens: 86563691
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 77.59436621516943,
    "estimated_duration": 3600.0396620354586,
    "input_throughput": 8779.952991442537,
    "output_throughput": 7780.467614116002,
    "total_throughput": 16560.42060555854,
    "itl": 109.94230928502823,
    "ttft": 463734.6870106975,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 18,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05708966785576193,
    "arrivals": 144123,
    "finished_requests": 127690,
    "scheduler_time": 128.94020396955756
}
#Debug simulation 
Total elapsed time: 77.59454704727978. Arrivals time: 0.4559317221865058 Scheduler time: 76.93486036546528 Scheduler overhead time: 0.07902797730639577 Adapter cache time: 0.014090318232774734 Engine time: 0.08165485551580787 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-16-32/adapters_32_slots_16_rate_3.2-0.4-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-16-32/adapters_32_slots_16_rate_3.2-0.4-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 540, 540, 4320, 540, 34560, 4320, 540, 540, 540, 34560, 34560, 540, 540, 4320, 4320, 4320, 34560, 34560, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 433080 . Total input tokens: 96509300 . Total output tokens: 86563691
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 78.00657084025443,
    "estimated_duration": 3600.04807734118,
    "input_throughput": 8779.932467830891,
    "output_throughput": 7780.449426855103,
    "total_throughput": 16560.381894685994,
    "itl": 109.9421981882244,
    "ttft": 463737.92371910124,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 18,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.060259326919913286,
    "arrivals": 144123,
    "finished_requests": 127690,
    "scheduler_time": 128.94083647642478
}
#Debug simulation 
Total elapsed time: 78.00674981996417. Arrivals time: 0.4588135709054768 Scheduler time: 77.34323675651103 Scheduler overhead time: 0.07946408400312066 Adapter cache time: 0.014788590837270021 Engine time: 0.08080986049026251 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_16-16-16/adapters_32_slots_16_rate_3.2-0.4-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_16-16-16/adapters_32_slots_16_rate_3.2-0.4-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 540, 540, 4320, 540, 34560, 4320, 540, 540, 540, 34560, 34560, 540, 540, 4320, 4320, 4320, 34560, 34560, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 433080 . Total input tokens: 96509300 . Total output tokens: 86563691
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 78.09004727005959,
    "estimated_duration": 3600.0304458562528,
    "input_throughput": 8779.975468369163,
    "output_throughput": 7780.487532331948,
    "total_throughput": 16560.46300070111,
    "itl": 109.94272992951271,
    "ttft": 463734.30330995517,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 18,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05382090530823915,
    "arrivals": 144123,
    "finished_requests": 127690,
    "scheduler_time": 128.93984557893214
}
#Debug simulation 
Total elapsed time: 78.09022920811549. Arrivals time: 0.45588817400857806 Scheduler time: 77.42805648315698 Scheduler overhead time: 0.08028620528057218 Adapter cache time: 0.015024859923869371 Engine time: 0.08154813759028912 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_16-16-32/adapters_32_slots_16_rate_3.2-0.4-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_16-16-32/adapters_32_slots_16_rate_3.2-0.4-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 540, 540, 4320, 540, 34560, 4320, 540, 540, 540, 34560, 34560, 540, 540, 4320, 4320, 4320, 34560, 34560, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 433080 . Total input tokens: 96509300 . Total output tokens: 86563691
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 77.5053625786677,
    "estimated_duration": 3600.0505602652042,
    "input_throughput": 8779.9264123867,
    "output_throughput": 7780.444060745801,
    "total_throughput": 16560.370473132498,
    "itl": 109.94216222350786,
    "ttft": 463739.8611517677,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 18,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.061265357211232184,
    "arrivals": 144123,
    "finished_requests": 127690,
    "scheduler_time": 128.94111290720747
}
#Debug simulation 
Total elapsed time: 77.50554023077711. Arrivals time: 0.45418693451210856 Scheduler time: 76.84610866429284 Scheduler overhead time: 0.08046428812667727 Adapter cache time: 0.014645784627646208 Engine time: 0.080652030184865 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-8/adapters_32_slots_16_rate_3.2-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-8/adapters_32_slots_16_rate_3.2-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 270, 270, 4320, 270, 34560, 4320, 270, 270, 270, 34560, 34560, 270, 270, 4320, 4320, 4320, 34560, 34560, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 430380 . Total input tokens: 95899884 . Total output tokens: 86032029
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 67.82581479102373,
    "estimated_duration": 3600.070922482645,
    "input_throughput": 8756.74165281725,
    "output_throughput": 7767.055872531855,
    "total_throughput": 16523.797525349106,
    "itl": 109.53934664667882,
    "ttft": 453159.8379164677,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 19,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.058149267134722335,
    "arrivals": 143211,
    "finished_requests": 127436,
    "scheduler_time": 127.61620431572658
}
#Debug simulation 
Total elapsed time: 67.8259927383624. Arrivals time: 0.444605503231287 Scheduler time: 67.18304003076628 Scheduler overhead time: 0.07695589866489172 Adapter cache time: 0.014455354772508144 Engine time: 0.07824132265523076 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-16/adapters_32_slots_16_rate_3.2-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-16/adapters_32_slots_16_rate_3.2-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 270, 270, 4320, 270, 34560, 4320, 270, 270, 270, 34560, 34560, 270, 270, 4320, 4320, 4320, 34560, 34560, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 430380 . Total input tokens: 95899884 . Total output tokens: 86032029
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 68.21247697714716,
    "estimated_duration": 3600.111942142659,
    "input_throughput": 8756.727431435735,
    "output_throughput": 7767.058483008682,
    "total_throughput": 16523.785914444416,
    "itl": 109.53954277331097,
    "ttft": 453127.5788069246,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 19,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.0633484806981869,
    "arrivals": 143211,
    "finished_requests": 127439,
    "scheduler_time": 127.6176163904345
}
#Debug simulation 
Total elapsed time: 68.2126580402255. Arrivals time: 0.44694834761321545 Scheduler time: 67.56503809429705 Scheduler overhead time: 0.07831837935373187 Adapter cache time: 0.01368515333160758 Engine time: 0.07936358638107777 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-32/adapters_32_slots_16_rate_3.2-0.4-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-32/adapters_32_slots_16_rate_3.2-0.4-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 270, 270, 4320, 270, 34560, 4320, 270, 270, 270, 34560, 34560, 270, 270, 4320, 4320, 4320, 34560, 34560, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 430380 . Total input tokens: 95899884 . Total output tokens: 86032029
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 68.12225822685286,
    "estimated_duration": 3600.111692019405,
    "input_throughput": 8756.728039822738,
    "output_throughput": 7767.059022636923,
    "total_throughput": 16523.78706245966,
    "itl": 109.53954734366083,
    "ttft": 453127.37616639194,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 19,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.06322281803935766,
    "arrivals": 143211,
    "finished_requests": 127439,
    "scheduler_time": 127.6175911517641
}
#Debug simulation 
Total elapsed time: 68.1225527189672. Arrivals time: 0.45444399816915393 Scheduler time: 67.47046030778438 Scheduler overhead time: 0.07732542511075735 Adapter cache time: 0.013205104973167181 Engine time: 0.07715886412188411 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-16-16/adapters_32_slots_16_rate_3.2-0.4-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-16-16/adapters_32_slots_16_rate_3.2-0.4-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 270, 270, 4320, 270, 34560, 4320, 270, 270, 270, 34560, 34560, 270, 270, 4320, 4320, 4320, 34560, 34560, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 430380 . Total input tokens: 95899884 . Total output tokens: 86032029
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 67.53474821243435,
    "estimated_duration": 3600.075066045446,
    "input_throughput": 8756.73157410825,
    "output_throughput": 7767.046932917209,
    "total_throughput": 16523.778507025458,
    "itl": 109.53910564579768,
    "ttft": 453161.75504079706,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 19,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.06048831346910445,
    "arrivals": 143211,
    "finished_requests": 127436,
    "scheduler_time": 127.61651152009324
}
#Debug simulation 
Total elapsed time: 67.53492881311104. Arrivals time: 0.4324141461402178 Scheduler time: 66.9055405263789 Scheduler overhead time: 0.07734340988099575 Adapter cache time: 0.014217398129403591 Engine time: 0.07706232229247689 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-16-32/adapters_32_slots_16_rate_3.2-0.4-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-16-32/adapters_32_slots_16_rate_3.2-0.4-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 270, 270, 4320, 270, 34560, 4320, 270, 270, 270, 34560, 34560, 270, 270, 4320, 4320, 4320, 34560, 34560, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 430380 . Total input tokens: 95899884 . Total output tokens: 86032029
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 68.33898053318262,
    "estimated_duration": 3600.113014446066,
    "input_throughput": 8756.724823220764,
    "output_throughput": 7767.056169569288,
    "total_throughput": 16523.780992790053,
    "itl": 109.53945357949803,
    "ttft": 453128.45813302725,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 19,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.06410309454426169,
    "arrivals": 143211,
    "finished_requests": 127439,
    "scheduler_time": 127.61773400284157
}
#Debug simulation 
Total elapsed time: 68.33916381793097. Arrivals time: 0.447571515571326 Scheduler time: 67.69323802227154 Scheduler overhead time: 0.07752975448966026 Adapter cache time: 0.013414054177701473 Engine time: 0.07926275487989187 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_16-16-16/adapters_32_slots_16_rate_3.2-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_16-16-16/adapters_32_slots_16_rate_3.2-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 270, 270, 4320, 270, 34560, 4320, 270, 270, 270, 34560, 34560, 270, 270, 4320, 4320, 4320, 34560, 34560, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 430380 . Total input tokens: 95899884 . Total output tokens: 86032029
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 67.7258266787976,
    "estimated_duration": 3600.070031588562,
    "input_throughput": 8756.74381981102,
    "output_throughput": 7767.057794612275,
    "total_throughput": 16523.801614423293,
    "itl": 109.53946854112982,
    "ttft": 453159.15508771857,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 19,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.056810955603141325,
    "arrivals": 143211,
    "finished_requests": 127436,
    "scheduler_time": 127.61614909031516
}
#Debug simulation 
Total elapsed time: 67.7260061679408. Arrivals time: 0.44364682864397764 Scheduler time: 67.08536681905389 Scheduler overhead time: 0.07639646483585238 Adapter cache time: 0.013903817161917686 Engine time: 0.07822316186502576 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_16-16-32/adapters_32_slots_16_rate_3.2-0.4-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_16-16-32/adapters_32_slots_16_rate_3.2-0.4-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 270, 270, 4320, 270, 34560, 4320, 270, 270, 270, 34560, 34560, 270, 270, 4320, 4320, 4320, 34560, 34560, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 430380 . Total input tokens: 95899884 . Total output tokens: 86032029
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 67.57646498410031,
    "estimated_duration": 3600.118078934439,
    "input_throughput": 8756.712504643961,
    "output_throughput": 7767.045243214984,
    "total_throughput": 16523.757747858945,
    "itl": 109.53928873373972,
    "ttft": 453129.0460583644,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 19,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.06523487862199544,
    "arrivals": 143211,
    "finished_requests": 127439,
    "scheduler_time": 127.61797841410791
}
#Debug simulation 
Total elapsed time: 67.57664444297552. Arrivals time: 0.44109470397233963 Scheduler time: 66.9376283516176 Scheduler overhead time: 0.07550435932353139 Adapter cache time: 0.013441555202007294 Engine time: 0.07975738495588303 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-8/adapters_32_slots_16_rate_3.2-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-8/adapters_32_slots_16_rate_3.2-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 135, 135, 4320, 135, 34560, 4320, 135, 135, 135, 34560, 34560, 135, 135, 4320, 4320, 4320, 34560, 34560, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 429030 . Total input tokens: 95601350 . Total output tokens: 85757126
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 66.86959255486727,
    "estimated_duration": 3600.044759382459,
    "input_throughput": 8750.06593123679,
    "output_throughput": 7778.935783232821,
    "total_throughput": 16529.00171446961,
    "itl": 110.11674325371813,
    "ttft": 435625.3282426632,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 18,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05508877939078958,
    "arrivals": 142732,
    "finished_requests": 127646,
    "scheduler_time": 126.92438589749615
}
#Debug simulation 
Total elapsed time: 66.8697751192376. Arrivals time: 0.43187942868098617 Scheduler time: 66.24016913957894 Scheduler overhead time: 0.0770480833016336 Adapter cache time: 0.013830129522830248 Engine time: 0.07807372882962227 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-16/adapters_32_slots_16_rate_3.2-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-16/adapters_32_slots_16_rate_3.2-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 135, 135, 4320, 135, 34560, 4320, 135, 135, 135, 34560, 34560, 135, 135, 4320, 4320, 4320, 34560, 34560, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 429030 . Total input tokens: 95601350 . Total output tokens: 85757126
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 67.02397868596017,
    "estimated_duration": 3600.0597396312837,
    "input_throughput": 8750.029521239634,
    "output_throughput": 7778.903414216179,
    "total_throughput": 16528.93293545581,
    "itl": 110.11655311832169,
    "ttft": 435627.7003457115,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 18,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05954123976640402,
    "arrivals": 142732,
    "finished_requests": 127646,
    "scheduler_time": 126.9251675469029
}
#Debug simulation 
Total elapsed time: 67.02416260633618. Arrivals time: 0.44027411146089435 Scheduler time: 66.3886116631329 Scheduler overhead time: 0.07573975017294288 Adapter cache time: 0.013746167067438364 Engine time: 0.07742158556357026 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-32/adapters_32_slots_16_rate_3.2-0.4-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-32/adapters_32_slots_16_rate_3.2-0.4-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 135, 135, 4320, 135, 34560, 4320, 135, 135, 135, 34560, 34560, 135, 135, 4320, 4320, 4320, 34560, 34560, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 429030 . Total input tokens: 95601350 . Total output tokens: 85757126
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 67.2643614700064,
    "estimated_duration": 3600.059719212356,
    "input_throughput": 8750.029570868315,
    "output_throughput": 7778.903458336798,
    "total_throughput": 16528.933029205113,
    "itl": 110.11655440907373,
    "ttft": 435627.6835401715,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 18,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05950480420142411,
    "arrivals": 142732,
    "finished_requests": 127646,
    "scheduler_time": 126.92516568427038
}
#Debug simulation 
Total elapsed time: 67.26464451570064. Arrivals time: 0.44234175607562065 Scheduler time: 66.62391152605414 Scheduler overhead time: 0.07770911045372486 Adapter cache time: 0.013688124250620604 Engine time: 0.07827856624498963 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-16/adapters_32_slots_16_rate_3.2-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-16/adapters_32_slots_16_rate_3.2-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 135, 135, 4320, 135, 34560, 4320, 135, 135, 135, 34560, 34560, 135, 135, 4320, 4320, 4320, 34560, 34560, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 429030 . Total input tokens: 95601350 . Total output tokens: 85757126
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 67.00937287090346,
    "estimated_duration": 3600.0521824352536,
    "input_throughput": 8750.047889220154,
    "output_throughput": 7778.919743617816,
    "total_throughput": 16528.96763283797,
    "itl": 110.11677035796342,
    "ttft": 435626.0988123725,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 18,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05668107253732158,
    "arrivals": 142732,
    "finished_requests": 127646,
    "scheduler_time": 126.92475992723989
}
#Debug simulation 
Total elapsed time: 67.00955628603697. Arrivals time: 0.43264047987759113 Scheduler time: 66.38047867454588 Scheduler overhead time: 0.07648613909259439 Adapter cache time: 0.013445578515529633 Engine time: 0.0781982927583158 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-32/adapters_32_slots_16_rate_3.2-0.4-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-32/adapters_32_slots_16_rate_3.2-0.4-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 135, 135, 4320, 135, 34560, 4320, 135, 135, 135, 34560, 34560, 135, 135, 4320, 4320, 4320, 34560, 34560, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 429030 . Total input tokens: 95601350 . Total output tokens: 85757126
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 67.17618996091187,
    "estimated_duration": 3600.059191850039,
    "input_throughput": 8750.030852634982,
    "output_throughput": 7778.9045978459935,
    "total_throughput": 16528.935450480974,
    "itl": 110.11643920843271,
    "ttft": 435627.35184668645,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 18,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.06038508070632814,
    "arrivals": 142732,
    "finished_requests": 127646,
    "scheduler_time": 126.92506589686735
}
#Debug simulation 
Total elapsed time: 67.17637551156804. Arrivals time: 0.44074114924296737 Scheduler time: 66.53871429152787 Scheduler overhead time: 0.07652523461729288 Adapter cache time: 0.013271055184304714 Engine time: 0.07794159278273582 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-16/adapters_32_slots_16_rate_3.2-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-16/adapters_32_slots_16_rate_3.2-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 135, 135, 4320, 135, 34560, 4320, 135, 135, 135, 34560, 34560, 135, 135, 4320, 4320, 4320, 34560, 34560, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 429030 . Total input tokens: 95601350 . Total output tokens: 85757126
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 66.7994759241119,
    "estimated_duration": 3600.0384368012856,
    "input_throughput": 8750.028799133835,
    "output_throughput": 7778.933056304417,
    "total_throughput": 16528.96185543825,
    "itl": 110.11683525381451,
    "ttft": 435628.35893259075,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 18,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05382090530823915,
    "arrivals": 142732,
    "finished_requests": 127645,
    "scheduler_time": 126.92424049634113
}
#Debug simulation 
Total elapsed time: 66.79965496482328. Arrivals time: 0.43970657978206873 Scheduler time: 66.16301379166543 Scheduler overhead time: 0.07655172841623425 Adapter cache time: 0.013945120386779308 Engine time: 0.07755034510046244 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-32/adapters_32_slots_16_rate_3.2-0.4-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-32/adapters_32_slots_16_rate_3.2-0.4-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 135, 135, 4320, 135, 34560, 4320, 135, 135, 135, 34560, 34560, 135, 135, 4320, 4320, 4320, 34560, 34560, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 429030 . Total input tokens: 95601350 . Total output tokens: 85757126
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 66.97269405797124,
    "estimated_duration": 3600.0585313590946,
    "input_throughput": 8750.032457974476,
    "output_throughput": 7778.906025016136,
    "total_throughput": 16528.938482990612,
    "itl": 110.11625772397934,
    "ttft": 435626.8361576208,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 18,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.06126535721123218,
    "arrivals": 142732,
    "finished_requests": 127646,
    "scheduler_time": 126.92495301805317
}
#Debug simulation 
Total elapsed time: 66.97287016827613. Arrivals time: 0.44273579912260175 Scheduler time: 66.32941626664251 Scheduler overhead time: 0.07756860507652164 Adapter cache time: 0.01430597435683012 Engine time: 0.07984791602939367 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-8/adapters_32_slots_16_rate_3.2-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-8/adapters_32_slots_16_rate_3.2-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 66, 66, 4320, 66, 34560, 4320, 66, 66, 66, 34560, 34560, 66, 66, 4320, 4320, 4320, 34560, 34560, 66, 34560, 34560, 34560, 34560, 4320, 66, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 428340 . Total input tokens: 95433402 . Total output tokens: 85618390
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 63.80295763397589,
    "estimated_duration": 3600.0984615739894,
    "input_throughput": 8766.18385215001,
    "output_throughput": 7777.794773912332,
    "total_throughput": 16543.97862606234,
    "itl": 109.80987299921799,
    "ttft": 425678.27343552967,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 20,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.06120975487865509,
    "arrivals": 142534,
    "finished_requests": 127760,
    "scheduler_time": 126.41093070329313
}
#Debug simulation 
Total elapsed time: 63.80314222956076. Arrivals time: 0.4329787064343691 Scheduler time: 63.17794498614967 Scheduler overhead time: 0.07409963058307767 Adapter cache time: 0.012867828365415335 Engine time: 0.07667002687230706 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-16/adapters_32_slots_16_rate_3.2-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-16/adapters_32_slots_16_rate_3.2-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 66, 66, 4320, 66, 34560, 4320, 66, 66, 66, 34560, 34560, 66, 66, 4320, 4320, 4320, 34560, 34560, 66, 34560, 34560, 34560, 34560, 4320, 66, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 428340 . Total input tokens: 95433402 . Total output tokens: 85618390
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 63.995595801156014,
    "estimated_duration": 3600.016625299938,
    "input_throughput": 8766.211738639035,
    "output_throughput": 7777.917969383574,
    "total_throughput": 16544.12970802261,
    "itl": 109.81101160041385,
    "ttft": 425705.24997402163,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 20,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.06592993567464872,
    "arrivals": 142534,
    "finished_requests": 127757,
    "scheduler_time": 126.40760270046921
}
#Debug simulation 
Total elapsed time: 63.99577872036025. Arrivals time: 0.43170454492792487 Scheduler time: 63.36729250615463 Scheduler overhead time: 0.07668613689020276 Adapter cache time: 0.013686051592230797 Engine time: 0.07741412287577987 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-32/adapters_32_slots_16_rate_3.2-0.4-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-32/adapters_32_slots_16_rate_3.2-0.4-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 66, 66, 4320, 66, 34560, 4320, 66, 66, 66, 34560, 34560, 66, 66, 4320, 4320, 4320, 34560, 34560, 66, 34560, 34560, 34560, 34560, 4320, 66, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 428340 . Total input tokens: 95433402 . Total output tokens: 85618390
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 64.1153493700549,
    "estimated_duration": 3600.0166244536567,
    "input_throughput": 8766.21174069977,
    "output_throughput": 7777.917971211984,
    "total_throughput": 16544.129711911755,
    "itl": 109.81101134501083,
    "ttft": 425705.2492173772,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 20,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.0659290893934667,
    "arrivals": 142534,
    "finished_requests": 127757,
    "scheduler_time": 126.40760270046921
}
#Debug simulation 
Total elapsed time: 64.11563588725403. Arrivals time: 0.43140089930966496 Scheduler time: 63.4879618245177 Scheduler overhead time: 0.07680501788854599 Adapter cache time: 0.013327686581760645 Engine time: 0.07775201322510839 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-16-16/adapters_32_slots_16_rate_3.2-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-16-16/adapters_32_slots_16_rate_3.2-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 66, 66, 4320, 66, 34560, 4320, 66, 66, 66, 34560, 34560, 66, 66, 4320, 4320, 4320, 34560, 34560, 66, 34560, 34560, 34560, 34560, 4320, 66, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 428340 . Total input tokens: 95433402 . Total output tokens: 85618390
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 64.28700714698061,
    "estimated_duration": 3600.105371503893,
    "input_throughput": 8766.186192715963,
    "output_throughput": 7777.780400995055,
    "total_throughput": 16543.96659371102,
    "itl": 109.8093981827213,
    "ttft": 425680.24942935,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 20,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.06306976844556628,
    "arrivals": 142534,
    "finished_requests": 127761,
    "scheduler_time": 126.41159368987167
}
#Debug simulation 
Total elapsed time: 64.28718512970954. Arrivals time: 0.434526395983994 Scheduler time: 63.655595146585256 Scheduler overhead time: 0.07658172957599163 Adapter cache time: 0.013475878164172173 Engine time: 0.07890925835818052 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-16-32/adapters_32_slots_16_rate_3.2-0.4-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-16-32/adapters_32_slots_16_rate_3.2-0.4-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 66, 66, 4320, 66, 34560, 4320, 66, 66, 66, 34560, 34560, 66, 66, 4320, 4320, 4320, 34560, 34560, 66, 34560, 34560, 34560, 34560, 4320, 66, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 428340 . Total input tokens: 95433402 . Total output tokens: 85618390
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 63.71959394076839,
    "estimated_duration": 3600.019724418999,
    "input_throughput": 8766.20419214319,
    "output_throughput": 7777.911273671973,
    "total_throughput": 16544.11546581516,
    "itl": 109.81104180133289,
    "ttft": 425706.3790671716,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 20,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.06680936589837072,
    "arrivals": 142534,
    "finished_requests": 127757,
    "scheduler_time": 126.40782161769825
}
#Debug simulation 
Total elapsed time: 63.71977939689532. Arrivals time: 0.4468697370029986 Scheduler time: 63.0759664028883 Scheduler overhead time: 0.07729909708723426 Adapter cache time: 0.013065219391137362 Engine time: 0.07817104225978255 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_16-16-16/adapters_32_slots_16_rate_3.2-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_16-16-16/adapters_32_slots_16_rate_3.2-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 66, 66, 4320, 66, 34560, 4320, 66, 66, 66, 34560, 34560, 66, 66, 4320, 4320, 4320, 34560, 34560, 66, 34560, 34560, 34560, 34560, 4320, 66, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 428340 . Total input tokens: 95433402 . Total output tokens: 85618390
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 64.13572705723345,
    "estimated_duration": 3600.0958298798246,
    "input_throughput": 8766.190260289122,
    "output_throughput": 7777.800459532406,
    "total_throughput": 16543.99071982153,
    "itl": 109.81001389042541,
    "ttft": 425676.7522734968,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 20,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.0598010058980435,
    "arrivals": 142534,
    "finished_requests": 127760,
    "scheduler_time": 126.41070161068873
}
#Debug simulation 
Total elapsed time: 64.13590886909515. Arrivals time: 0.43149836640805006 Scheduler time: 63.50950425118208 Scheduler overhead time: 0.07545834267511964 Adapter cache time: 0.013583229389041662 Engine time: 0.07738084625452757 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_16-16-32/adapters_32_slots_16_rate_3.2-0.4-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_16-16-32/adapters_32_slots_16_rate_3.2-0.4-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 66, 66, 4320, 66, 34560, 4320, 66, 66, 66, 34560, 34560, 66, 66, 4320, 4320, 4320, 34560, 34560, 66, 34560, 34560, 34560, 34560, 4320, 66, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 428340 . Total input tokens: 95433402 . Total output tokens: 85618390
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 63.913635628297925,
    "estimated_duration": 3600.0296432917444,
    "input_throughput": 8766.180039324336,
    "output_throughput": 7777.889843817279,
    "total_throughput": 16544.069883141616,
    "itl": 109.81125035233688,
    "ttft": 425704.108788328,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 20,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.06781539618968961,
    "arrivals": 142534,
    "finished_requests": 127757,
    "scheduler_time": 126.40803682024413
}
#Debug simulation 
Total elapsed time: 63.91381556726992. Arrivals time: 0.438388607930392 Scheduler time: 63.28241558698937 Scheduler overhead time: 0.0752602182328701 Adapter cache time: 0.013413130305707455 Engine time: 0.07596676284447312 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-8/adapters_32_slots_16_rate_3.2-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-8/adapters_32_slots_16_rate_3.2-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 33, 33, 4320, 33, 34560, 4320, 33, 33, 33, 34560, 34560, 33, 33, 4320, 4320, 4320, 34560, 34560, 33, 34560, 34560, 34560, 34560, 4320, 33, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 428010 . Total input tokens: 95363095 . Total output tokens: 85549163
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 65.59567222883925,
    "estimated_duration": 3600.056593311636,
    "input_throughput": 8845.690664742104,
    "output_throughput": 7770.825617567822,
    "total_throughput": 16616.516282309927,
    "itl": 109.23212693725917,
    "ttft": 421393.4529414749,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 17,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05202829164685682,
    "arrivals": 142385,
    "finished_requests": 127776,
    "scheduler_time": 126.18598188126106
}
#Debug simulation 
Total elapsed time: 65.59585693804547. Arrivals time: 0.43459297716617584 Scheduler time: 64.96442037634552 Scheduler overhead time: 0.07580418139696121 Adapter cache time: 0.014462435618042946 Engine time: 0.07777137123048306 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-16/adapters_32_slots_16_rate_3.2-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-16/adapters_32_slots_16_rate_3.2-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 33, 33, 4320, 33, 34560, 4320, 33, 33, 33, 34560, 34560, 33, 33, 4320, 4320, 4320, 34560, 34560, 33, 34560, 34560, 34560, 34560, 4320, 33, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 428010 . Total input tokens: 95363095 . Total output tokens: 85549163
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 65.84184660576284,
    "estimated_duration": 3600.11501718517,
    "input_throughput": 8845.797939227901,
    "output_throughput": 7770.910892139716,
    "total_throughput": 16616.708831367618,
    "itl": 109.23376303567348,
    "ttft": 421340.05855687894,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 17,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.056551189471501846,
    "arrivals": 142385,
    "finished_requests": 127779,
    "scheduler_time": 126.18836958930555
}
#Debug simulation 
Total elapsed time: 65.84202664485201. Arrivals time: 0.44593570567667484 Scheduler time: 65.19952208455652 Scheduler overhead time: 0.0766539559699595 Adapter cache time: 0.013948072213679552 Engine time: 0.07749450905248523 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-32/adapters_32_slots_16_rate_3.2-0.4-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-32/adapters_32_slots_16_rate_3.2-0.4-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 33, 33, 4320, 33, 34560, 4320, 33, 33, 33, 34560, 34560, 33, 33, 4320, 4320, 4320, 34560, 34560, 33, 34560, 34560, 34560, 34560, 4320, 33, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 428010 . Total input tokens: 95363095 . Total output tokens: 85549163
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 65.75676621776074,
    "estimated_duration": 3600.114570048307,
    "input_throughput": 8845.799037882476,
    "output_throughput": 7770.911857292534,
    "total_throughput": 16616.71089517501,
    "itl": 109.23375944475319,
    "ttft": 421339.68328180717,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 17,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.0564612853527069,
    "arrivals": 142385,
    "finished_requests": 127779,
    "scheduler_time": 126.18831247230659
}
#Debug simulation 
Total elapsed time: 65.75704692397267. Arrivals time: 0.44080110639333725 Scheduler time: 65.11752702528611 Scheduler overhead time: 0.07704513939097524 Adapter cache time: 0.013665335718542337 Engine time: 0.07929854188114405 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-16/adapters_32_slots_16_rate_3.2-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-16/adapters_32_slots_16_rate_3.2-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 33, 33, 4320, 33, 34560, 4320, 33, 33, 33, 34560, 34560, 33, 33, 4320, 4320, 4320, 34560, 34560, 33, 34560, 34560, 34560, 34560, 4320, 33, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 428010 . Total input tokens: 95363095 . Total output tokens: 85549163
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 65.53662728518248,
    "estimated_duration": 3600.080953496916,
    "input_throughput": 8845.697474960205,
    "output_throughput": 7770.782479995686,
    "total_throughput": 16616.479954955892,
    "itl": 109.23281189921684,
    "ttft": 421370.9965033512,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 17,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05409961756085976,
    "arrivals": 142385,
    "finished_requests": 127777,
    "scheduler_time": 126.18728142176428
}
#Debug simulation 
Total elapsed time: 65.53680510306731. Arrivals time: 0.4383310894481838 Scheduler time: 64.90397906815633 Scheduler overhead time: 0.07576392497867346 Adapter cache time: 0.013358863536268473 Engine time: 0.07691591139882803 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-32/adapters_32_slots_16_rate_3.2-0.4-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-32/adapters_32_slots_16_rate_3.2-0.4-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 33, 33, 4320, 33, 34560, 4320, 33, 33, 33, 34560, 34560, 33, 33, 4320, 4320, 4320, 34560, 34560, 33, 34560, 34560, 34560, 34560, 4320, 33, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 428010 . Total input tokens: 95363095 . Total output tokens: 85549163
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 65.40015603788197,
    "estimated_duration": 3600.115402078075,
    "input_throughput": 8845.796993512422,
    "output_throughput": 7770.910061341774,
    "total_throughput": 16616.707054854196,
    "itl": 109.23371544069578,
    "ttft": 421340.3358101981,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 17,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05721580807119608,
    "arrivals": 142385,
    "finished_requests": 127779,
    "scheduler_time": 126.18839079600325
}
#Debug simulation 
Total elapsed time: 65.40034592570737. Arrivals time: 0.4379525389522314 Scheduler time: 64.76194446673617 Scheduler overhead time: 0.0785045730881393 Adapter cache time: 0.012953463476151228 Engine time: 0.07998262858018279 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-16/adapters_32_slots_16_rate_3.2-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-16/adapters_32_slots_16_rate_3.2-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 33, 33, 4320, 33, 34560, 4320, 33, 33, 33, 34560, 34560, 33, 33, 4320, 4320, 4320, 34560, 34560, 33, 34560, 34560, 34560, 34560, 4320, 33, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 428010 . Total input tokens: 95363095 . Total output tokens: 85549163
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 65.7025214782916,
    "estimated_duration": 3600.0572966798227,
    "input_throughput": 8845.688936498109,
    "output_throughput": 7770.824099327673,
    "total_throughput": 16616.51303582578,
    "itl": 109.23228086356228,
    "ttft": 421394.6021483567,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 17,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05083085501333698,
    "arrivals": 142385,
    "finished_requests": 127776,
    "scheduler_time": 126.18618121353578
}
#Debug simulation 
Total elapsed time: 65.70269939908758. Arrivals time: 0.44019274739548564 Scheduler time: 65.06238388735801 Scheduler overhead time: 0.0779938343912363 Adapter cache time: 0.01414484204724431 Engine time: 0.07906473474577069 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-32/adapters_32_slots_16_rate_3.2-0.4-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-32/adapters_32_slots_16_rate_3.2-0.4-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 33, 33, 4320, 33, 34560, 4320, 33, 33, 33, 34560, 34560, 33, 33, 4320, 4320, 4320, 34560, 34560, 33, 34560, 34560, 34560, 34560, 4320, 33, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 428010 . Total input tokens: 95363095 . Total output tokens: 85549163
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 66.0189238791354,
    "estimated_duration": 3600.1184442522303,
    "input_throughput": 8845.789518631966,
    "output_throughput": 7770.903494762892,
    "total_throughput": 16616.69301339486,
    "itl": 109.23365353416536,
    "ttft": 421339.66629546485,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 17,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.058221838362514974,
    "arrivals": 142385,
    "finished_requests": 127779,
    "scheduler_time": 126.18843188481158
}
#Debug simulation 
Total elapsed time: 66.01910783024505. Arrivals time: 0.435488089453429 Scheduler time: 65.38456402579322 Scheduler overhead time: 0.07682925602421165 Adapter cache time: 0.013631443493068218 Engine time: 0.07952229492366314 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-8/adapters_32_slots_16_rate_3.2-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-8/adapters_32_slots_16_rate_3.2-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [10 11 11]
Adapter prompts. [34560, 1080, 540, 540, 1080, 540, 34560, 1080, 540, 540, 540, 34560, 34560, 540, 540, 1080, 1080, 1080, 34560, 34560, 540, 34560, 34560, 34560, 34560, 1080, 540, 1080, 1080, 1080, 1080, 34560]
Prompts retrieved: 397440 . Total input tokens: 88554180 . Total output tokens: 79454492
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 12.0868254089728,
    "estimated_duration": 3600.0267823365934,
    "input_throughput": 8881.259760864365,
    "output_throughput": 7788.643167204747,
    "total_throughput": 16669.90292806911,
    "itl": 108.11018633461626,
    "ttft": 141317.84035701028,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 130,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.39786340671125753,
    "arrivals": 132241,
    "finished_requests": 128384,
    "scheduler_time": 112.12458682910139
}
#Debug simulation 
Total elapsed time: 12.08692327607423. Arrivals time: 0.2850488321855664 Scheduler time: 11.657731185667217 Scheduler overhead time: 0.0547462897375226 Adapter cache time: 0.009690054226666689 Engine time: 0.054900120943784714 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-16/adapters_32_slots_16_rate_3.2-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-16/adapters_32_slots_16_rate_3.2-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [10 11 11]
Adapter prompts. [34560, 1080, 540, 540, 1080, 540, 34560, 1080, 540, 540, 540, 34560, 34560, 540, 540, 1080, 1080, 1080, 34560, 34560, 540, 34560, 34560, 34560, 34560, 1080, 540, 1080, 1080, 1080, 1080, 34560]
Prompts retrieved: 397440 . Total input tokens: 88554180 . Total output tokens: 79454492
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 12.032158012967557,
    "estimated_duration": 3600.085810621496,
    "input_throughput": 8879.638897963196,
    "output_throughput": 7789.270721621771,
    "total_throughput": 16668.909619584967,
    "itl": 108.12790514023436,
    "ttft": 141196.7799425825,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 129,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.41962989947292956,
    "arrivals": 132241,
    "finished_requests": 128387,
    "scheduler_time": 112.12406500717235
}
#Debug simulation 
Total elapsed time: 12.03227953100577. Arrivals time: 0.28407421614974737 Scheduler time: 11.604725384619087 Scheduler overhead time: 0.05458728736266494 Adapter cache time: 0.00970986345782876 Engine time: 0.05445169331505895 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-32/adapters_32_slots_16_rate_3.2-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-32/adapters_32_slots_16_rate_3.2-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [10 11 11]
Adapter prompts. [34560, 1080, 540, 540, 1080, 540, 34560, 1080, 540, 540, 540, 34560, 34560, 540, 540, 1080, 1080, 1080, 34560, 34560, 540, 34560, 34560, 34560, 34560, 1080, 540, 1080, 1080, 1080, 1080, 34560]
Prompts retrieved: 397440 . Total input tokens: 88554180 . Total output tokens: 79454492
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 12.036701417062432,
    "estimated_duration": 3600.0868254971047,
    "input_throughput": 8879.636394765532,
    "output_throughput": 7789.268525802268,
    "total_throughput": 16668.904920567802,
    "itl": 108.12796996190743,
    "ttft": 141197.15983227704,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 129,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42060547353699906,
    "arrivals": 132241,
    "finished_requests": 128387,
    "scheduler_time": 112.12410430871812
}
#Debug simulation 
Total elapsed time: 12.036893092095852. Arrivals time: 0.2869558543898165 Scheduler time: 11.605787529610097 Scheduler overhead time: 0.05487908609211445 Adapter cache time: 0.009672617074102163 Engine time: 0.054842581041157246 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-16-16/adapters_32_slots_16_rate_3.2-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-16-16/adapters_32_slots_16_rate_3.2-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [10 11 11]
Adapter prompts. [34560, 1080, 540, 540, 1080, 540, 34560, 1080, 540, 540, 540, 34560, 34560, 540, 540, 1080, 1080, 1080, 34560, 34560, 540, 34560, 34560, 34560, 34560, 1080, 540, 1080, 1080, 1080, 1080, 34560]
Prompts retrieved: 397440 . Total input tokens: 88554180 . Total output tokens: 79454492
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 12.037743743974715,
    "estimated_duration": 3600.0673262214414,
    "input_throughput": 8881.159740297964,
    "output_throughput": 7788.555451664153,
    "total_throughput": 16669.715191962117,
    "itl": 108.11093637969101,
    "ttft": 141315.26468493917,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 130,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.40341596980113564,
    "arrivals": 132241,
    "finished_requests": 128384,
    "scheduler_time": 112.12580022674105
}
#Debug simulation 
Total elapsed time: 12.037859852891415. Arrivals time: 0.28124349005520344 Scheduler time: 11.613064119126648 Scheduler overhead time: 0.05448012752458453 Adapter cache time: 0.009648398961871862 Engine time: 0.05462748883292079 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-16-32/adapters_32_slots_16_rate_3.2-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-16-32/adapters_32_slots_16_rate_3.2-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [10 11 11]
Adapter prompts. [34560, 1080, 540, 540, 1080, 540, 34560, 1080, 540, 540, 540, 34560, 34560, 540, 540, 1080, 1080, 1080, 34560, 34560, 540, 34560, 34560, 34560, 34560, 1080, 540, 1080, 1080, 1080, 1080, 34560]
Prompts retrieved: 397440 . Total input tokens: 88554180 . Total output tokens: 79454492
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 11.989441107027233,
    "estimated_duration": 3600.093340005144,
    "input_throughput": 8879.620326720285,
    "output_throughput": 7789.254430819822,
    "total_throughput": 16668.874757540107,
    "itl": 108.12795190764214,
    "ttft": 141252.21367307898,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 129,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4265159014984969,
    "arrivals": 132241,
    "finished_requests": 128387,
    "scheduler_time": 112.12439078159618
}
#Debug simulation 
Total elapsed time: 11.989533505868167. Arrivals time: 0.28209188580513 Scheduler time: 11.564072894398123 Scheduler overhead time: 0.05480205314233899 Adapter cache time: 0.009566899854689837 Engine time: 0.05432412773370743 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_16-16-16/adapters_32_slots_16_rate_3.2-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_16-16-16/adapters_32_slots_16_rate_3.2-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [10 11 11]
Adapter prompts. [34560, 1080, 540, 540, 1080, 540, 34560, 1080, 540, 540, 540, 34560, 34560, 540, 540, 1080, 1080, 1080, 34560, 34560, 540, 34560, 34560, 34560, 34560, 1080, 540, 1080, 1080, 1080, 1080, 34560]
Prompts retrieved: 397440 . Total input tokens: 88554180 . Total output tokens: 79454492
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 12.044638285879046,
    "estimated_duration": 3600.0188069175233,
    "input_throughput": 8881.279436252817,
    "output_throughput": 7788.660422029396,
    "total_throughput": 16669.939858282214,
    "itl": 108.11015126126145,
    "ttft": 141288.20222116885,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 130,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3887065383372833,
    "arrivals": 132241,
    "finished_requests": 128384,
    "scheduler_time": 112.12429539786066
}
#Debug simulation 
Total elapsed time: 12.044762076810002. Arrivals time: 0.2874144157394767 Scheduler time: 11.614366667345166 Scheduler overhead time: 0.0544921956025064 Adapter cache time: 0.009550147224217653 Engine time: 0.054260692559182644 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_16-16-32/adapters_32_slots_16_rate_3.2-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_16-16-32/adapters_32_slots_16_rate_3.2-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [10 11 11]
Adapter prompts. [34560, 1080, 540, 540, 1080, 540, 34560, 1080, 540, 540, 540, 34560, 34560, 540, 540, 1080, 1080, 1080, 34560, 34560, 540, 34560, 34560, 34560, 34560, 1080, 540, 1080, 1080, 1080, 1080, 34560]
Prompts retrieved: 397440 . Total input tokens: 88554180 . Total output tokens: 79454492
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 11.977178629022092,
    "estimated_duration": 3600.009525540754,
    "input_throughput": 8879.663726778135,
    "output_throughput": 7789.251889767689,
    "total_throughput": 16668.915616545823,
    "itl": 108.1295000628683,
    "ttft": 141250.33833464686,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 129,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4310430378094314,
    "arrivals": 132241,
    "finished_requests": 128383,
    "scheduler_time": 112.12135394345181
}
#Debug simulation 
Total elapsed time: 11.977267445996404. Arrivals time: 0.2823169701732695 Scheduler time: 11.551106362137944 Scheduler overhead time: 0.054667900782078505 Adapter cache time: 0.009502856526523829 Engine time: 0.05507381819188595 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-8/adapters_32_slots_16_rate_3.2-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-8/adapters_32_slots_16_rate_3.2-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 1080, 270, 270, 1080, 270, 34560, 1080, 270, 270, 270, 34560, 34560, 270, 270, 1080, 1080, 1080, 34560, 34560, 270, 34560, 34560, 34560, 34560, 1080, 270, 1080, 1080, 1080, 1080, 34560]
Prompts retrieved: 394740 . Total input tokens: 87955617 . Total output tokens: 78939968
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 11.501921528019011,
    "estimated_duration": 3599.9824981298975,
    "input_throughput": 8883.860134490578,
    "output_throughput": 7794.536227489045,
    "total_throughput": 16678.396361979623,
    "itl": 108.26379137012641,
    "ttft": 99748.60721687393,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 141,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.43152877189451777,
    "arrivals": 131339,
    "finished_requests": 128529,
    "scheduler_time": 110.6524806781852
}
#Debug simulation 
Total elapsed time: 11.502011204138398. Arrivals time: 0.27941181836649776 Scheduler time: 11.078330155927688 Scheduler overhead time: 0.05469276336953044 Adapter cache time: 0.009812621399760246 Engine time: 0.05499643040820956 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-16/adapters_32_slots_16_rate_3.2-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-16/adapters_32_slots_16_rate_3.2-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 1080, 270, 270, 1080, 270, 34560, 1080, 270, 270, 270, 34560, 34560, 270, 270, 1080, 1080, 1080, 34560, 34560, 270, 34560, 34560, 34560, 34560, 1080, 270, 1080, 1080, 1080, 1080, 34560]
Prompts retrieved: 394740 . Total input tokens: 87955617 . Total output tokens: 78939968
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 11.318556882906705,
    "estimated_duration": 3600.0177605744407,
    "input_throughput": 8883.839782750616,
    "output_throughput": 7794.568767772546,
    "total_throughput": 16678.408550523163,
    "itl": 108.26398248174667,
    "ttft": 99762.22208579442,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 141,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.45796207492239777,
    "arrivals": 131339,
    "finished_requests": 128529,
    "scheduler_time": 110.65417815874635
}
#Debug simulation 
Total elapsed time: 11.318665083963424. Arrivals time: 0.28008611546829343 Scheduler time: 10.894962622784078 Scheduler overhead time: 0.054626315366476774 Adapter cache time: 0.009656805545091629 Engine time: 0.0543469050899148 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-32/adapters_32_slots_16_rate_3.2-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-32/adapters_32_slots_16_rate_3.2-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 1080, 270, 270, 1080, 270, 34560, 1080, 270, 270, 270, 34560, 34560, 270, 270, 1080, 1080, 1080, 34560, 34560, 270, 34560, 34560, 34560, 34560, 1080, 270, 1080, 1080, 1080, 1080, 34560]
Prompts retrieved: 394740 . Total input tokens: 87955617 . Total output tokens: 78939968
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 11.15673162881285,
    "estimated_duration": 3600.0188957987657,
    "input_throughput": 8883.836981334482,
    "output_throughput": 7794.566309845429,
    "total_throughput": 16678.40329117991,
    "itl": 108.26401812840606,
    "ttft": 99762.6753276091,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 141,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.45915118468925487,
    "arrivals": 131339,
    "finished_requests": 128529,
    "scheduler_time": 110.65422431188422
}
#Debug simulation 
Total elapsed time: 11.156892776954919. Arrivals time: 0.2697506779804826 Scheduler time: 10.744795725680888 Scheduler overhead time: 0.05428355513140559 Adapter cache time: 0.009596027433872223 Engine time: 0.053963028360158205 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-16-16/adapters_32_slots_16_rate_3.2-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-16-16/adapters_32_slots_16_rate_3.2-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 1080, 270, 270, 1080, 270, 34560, 1080, 270, 270, 270, 34560, 34560, 270, 270, 1080, 1080, 1080, 34560, 34560, 270, 34560, 34560, 34560, 34560, 1080, 270, 1080, 1080, 1080, 1080, 34560]
Prompts retrieved: 394740 . Total input tokens: 87955617 . Total output tokens: 78939968
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 11.142608765978366,
    "estimated_duration": 3599.992480631495,
    "input_throughput": 8883.953278255134,
    "output_throughput": 7794.646836339425,
    "total_throughput": 16678.60011459456,
    "itl": 108.26379085328138,
    "ttft": 99722.9317677725,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 141,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4371237136819403,
    "arrivals": 131339,
    "finished_requests": 128530,
    "scheduler_time": 110.6527919724352
}
#Debug simulation 
Total elapsed time: 11.142722764983773. Arrivals time: 0.27013825019821525 Scheduler time: 10.730542834382504 Scheduler overhead time: 0.054017757065594196 Adapter cache time: 0.009664170909672976 Engine time: 0.05392695451155305 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-16-32/adapters_32_slots_16_rate_3.2-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-16-32/adapters_32_slots_16_rate_3.2-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 1080, 270, 270, 1080, 270, 34560, 1080, 270, 270, 270, 34560, 34560, 270, 270, 1080, 1080, 1080, 34560, 34560, 270, 34560, 34560, 34560, 34560, 1080, 270, 1080, 1080, 1080, 1080, 34560]
Prompts retrieved: 394740 . Total input tokens: 87955617 . Total output tokens: 78939968
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 11.15205288073048,
    "estimated_duration": 3600.027530068461,
    "input_throughput": 8883.815674429525,
    "output_throughput": 7794.547615436257,
    "total_throughput": 16678.36328986578,
    "itl": 108.26407497217323,
    "ttft": 99767.00943654815,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 141,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.46556462779641195,
    "arrivals": 131339,
    "finished_requests": 128529,
    "scheduler_time": 110.65474448260721
}
#Debug simulation 
Total elapsed time: 11.15214435569942. Arrivals time: 0.2723785643465817 Scheduler time: 10.738128278404474 Scheduler overhead time: 0.05403128685429692 Adapter cache time: 0.009576300624758005 Engine time: 0.05361955286934972 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_16-16-16/adapters_32_slots_16_rate_3.2-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_16-16-16/adapters_32_slots_16_rate_3.2-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 1080, 270, 270, 1080, 270, 34560, 1080, 270, 270, 270, 34560, 34560, 270, 270, 1080, 1080, 1080, 34560, 34560, 270, 34560, 34560, 34560, 34560, 1080, 270, 1080, 1080, 1080, 1080, 34560]
Prompts retrieved: 394740 . Total input tokens: 87955617 . Total output tokens: 78939968
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 11.174992308020592,
    "estimated_duration": 3600.045035318637,
    "input_throughput": 8883.823587270565,
    "output_throughput": 7794.533047422384,
    "total_throughput": 16678.356634692947,
    "itl": 108.26246105033897,
    "ttft": 99726.25619151343,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 141,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4215970915812073,
    "arrivals": 131339,
    "finished_requests": 128530,
    "scheduler_time": 110.65487229161366
}
#Debug simulation 
Total elapsed time: 11.175084662158042. Arrivals time: 0.2750489297322929 Scheduler time: 10.757824158295989 Scheduler overhead time: 0.054093541111797094 Adapter cache time: 0.009621986653655767 Engine time: 0.05401147948578 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_16-16-32/adapters_32_slots_16_rate_3.2-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_16-16-32/adapters_32_slots_16_rate_3.2-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 1080, 270, 270, 1080, 270, 34560, 1080, 270, 270, 270, 34560, 34560, 270, 270, 1080, 1080, 1080, 34560, 34560, 270, 34560, 34560, 34560, 34560, 1080, 270, 1080, 1080, 1080, 1080, 34560]
Prompts retrieved: 394740 . Total input tokens: 87955617 . Total output tokens: 78939968
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 11.164704612921923,
    "estimated_duration": 3600.03428360827,
    "input_throughput": 8883.799008698566,
    "output_throughput": 7794.532993134504,
    "total_throughput": 16678.33200183307,
    "itl": 108.26414117361759,
    "ttft": 99770.52380366405,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 141,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.47034327168017614,
    "arrivals": 131339,
    "finished_requests": 128529,
    "scheduler_time": 110.65516572023111
}
#Debug simulation 
Total elapsed time: 11.164791026618332. Arrivals time: 0.27021543495357037 Scheduler time: 10.753040889743716 Scheduler overhead time: 0.05397371668368578 Adapter cache time: 0.009565232787281275 Engine time: 0.05361923715099692 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-8/adapters_32_slots_16_rate_3.2-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-8/adapters_32_slots_16_rate_3.2-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 1080, 135, 135, 1080, 135, 34560, 1080, 135, 135, 135, 34560, 34560, 135, 135, 1080, 1080, 1080, 34560, 34560, 135, 34560, 34560, 34560, 34560, 1080, 135, 1080, 1080, 1080, 1080, 34560]
Prompts retrieved: 393390 . Total input tokens: 87639207 . Total output tokens: 78675947
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 11.014938108157367,
    "estimated_duration": 3600.0046528342814,
    "input_throughput": 8860.75493677102,
    "output_throughput": 7787.732712491739,
    "total_throughput": 16648.48764926276,
    "itl": 107.90617214859272,
    "ttft": 87351.09187340162,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 134,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4101053576869885,
    "arrivals": 130909,
    "finished_requests": 128407,
    "scheduler_time": 110.15505851768275
}
#Debug simulation 
Total elapsed time: 11.015045762993395. Arrivals time: 0.268725651782006 Scheduler time: 10.603725182823837 Scheduler overhead time: 0.05439239088445902 Adapter cache time: 0.009577184449881315 Engine time: 0.05405787145718932 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-16/adapters_32_slots_16_rate_3.2-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-16/adapters_32_slots_16_rate_3.2-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 1080, 135, 135, 1080, 135, 34560, 1080, 135, 135, 135, 34560, 34560, 135, 135, 1080, 1080, 1080, 34560, 34560, 135, 34560, 34560, 34560, 34560, 1080, 135, 1080, 1080, 1080, 1080, 34560]
Prompts retrieved: 393390 . Total input tokens: 87639207 . Total output tokens: 78675947
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 10.93244421388954,
    "estimated_duration": 3600.0403683086242,
    "input_throughput": 8860.667030516304,
    "output_throughput": 7787.655451533687,
    "total_throughput": 16648.322482049993,
    "itl": 107.90606745721514,
    "ttft": 87364.80378595408,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 134,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.43662312753964216,
    "arrivals": 130909,
    "finished_requests": 128407,
    "scheduler_time": 110.15672971365267
}
#Debug simulation 
Total elapsed time: 10.932538092136383. Arrivals time: 0.2682526339776814 Scheduler time: 10.522610110230744 Scheduler overhead time: 0.05397774372249842 Adapter cache time: 0.009564835112541914 Engine time: 0.05378359416499734 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-32/adapters_32_slots_16_rate_3.2-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-32/adapters_32_slots_16_rate_3.2-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 1080, 135, 135, 1080, 135, 34560, 1080, 135, 135, 135, 34560, 34560, 135, 135, 1080, 1080, 1080, 34560, 34560, 135, 34560, 34560, 34560, 34560, 1080, 135, 1080, 1080, 1080, 1080, 34560]
Prompts retrieved: 393390 . Total input tokens: 87639207 . Total output tokens: 78675947
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 10.95927592087537,
    "estimated_duration": 3600.0435375046814,
    "input_throughput": 8860.6592302798,
    "output_throughput": 7787.648595892444,
    "total_throughput": 16648.307826172244,
    "itl": 107.9061333001955,
    "ttft": 87366.77603313395,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 134,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4375093052536261,
    "arrivals": 130909,
    "finished_requests": 128407,
    "scheduler_time": 110.15701196038637
}
#Debug simulation 
Total elapsed time: 10.959397584199905. Arrivals time: 0.26521108532324433 Scheduler time: 10.552604548633099 Scheduler overhead time: 0.0544121409766376 Adapter cache time: 0.009526414796710014 Engine time: 0.053248003125190735 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-16/adapters_32_slots_16_rate_3.2-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-16/adapters_32_slots_16_rate_3.2-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 1080, 135, 135, 1080, 135, 34560, 1080, 135, 135, 135, 34560, 34560, 135, 135, 1080, 1080, 1080, 34560, 34560, 135, 34560, 34560, 34560, 34560, 1080, 135, 1080, 1080, 1080, 1080, 34560]
Prompts retrieved: 393390 . Total input tokens: 87639207 . Total output tokens: 78675947
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 10.931397834792733,
    "estimated_duration": 3600.0121262994157,
    "input_throughput": 8860.736542237679,
    "output_throughput": 7787.716545504834,
    "total_throughput": 16648.453087742513,
    "itl": 107.90575809215576,
    "ttft": 87354.06909834385,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 134,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4157847662991847,
    "arrivals": 130909,
    "finished_requests": 128407,
    "scheduler_time": 110.15539085311026
}
#Debug simulation 
Total elapsed time: 10.931490218732506. Arrivals time: 0.26561857061460614 Scheduler time: 10.524832421913743 Scheduler overhead time: 0.054084161296486855 Adapter cache time: 0.009500607382506132 Engine time: 0.05303006945177913 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-32/adapters_32_slots_16_rate_3.2-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-32/adapters_32_slots_16_rate_3.2-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 1080, 135, 135, 1080, 135, 34560, 1080, 135, 135, 135, 34560, 34560, 135, 135, 1080, 1080, 1080, 34560, 34560, 135, 34560, 34560, 34560, 34560, 1080, 135, 1080, 1080, 1080, 1080, 34560]
Prompts retrieved: 393390 . Total input tokens: 87639207 . Total output tokens: 78675947
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 10.937215920072049,
    "estimated_duration": 3600.046699155351,
    "input_throughput": 8860.651448628192,
    "output_throughput": 7787.641756585498,
    "total_throughput": 16648.29320521369,
    "itl": 107.90617344871484,
    "ttft": 87367.63330994724,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 134,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4439227483607832,
    "arrivals": 130909,
    "finished_requests": 128407,
    "scheduler_time": 110.15697528562774
}
#Debug simulation 
Total elapsed time: 10.937314350157976. Arrivals time: 0.27110982593148947 Scheduler time: 10.524552271235734 Scheduler overhead time: 0.05405823839828372 Adapter cache time: 0.009544490836560726 Engine time: 0.0535547211766243 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-16/adapters_32_slots_16_rate_3.2-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-16/adapters_32_slots_16_rate_3.2-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 1080, 135, 135, 1080, 135, 34560, 1080, 135, 135, 135, 34560, 34560, 135, 135, 1080, 1080, 1080, 34560, 34560, 135, 34560, 34560, 34560, 34560, 1080, 135, 1080, 1080, 1080, 1080, 34560]
Prompts retrieved: 393390 . Total input tokens: 87639207 . Total output tokens: 78675947
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 10.949668912217021,
    "estimated_duration": 3600.07547669515,
    "input_throughput": 8860.817281887565,
    "output_throughput": 7787.743390796163,
    "total_throughput": 16648.56067268373,
    "itl": 107.90518733562193,
    "ttft": 87298.75949336991,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 134,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.400666739516892,
    "arrivals": 130909,
    "finished_requests": 128410,
    "scheduler_time": 110.1574808809693
}
#Debug simulation 
Total elapsed time: 10.949761106166989. Arrivals time: 0.27295756805688143 Scheduler time: 10.53491562930867 Scheduler overhead time: 0.054324005264788866 Adapter cache time: 0.009504505898803473 Engine time: 0.05360908154398203 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-32/adapters_32_slots_16_rate_3.2-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-32/adapters_32_slots_16_rate_3.2-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 1080, 135, 135, 1080, 135, 34560, 1080, 135, 135, 135, 34560, 34560, 135, 135, 1080, 1080, 1080, 34560, 34560, 135, 34560, 34560, 34560, 34560, 1080, 135, 1080, 1080, 1080, 1080, 34560]
Prompts retrieved: 393390 . Total input tokens: 87639207 . Total output tokens: 78675947
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 10.959745632950217,
    "estimated_duration": 3600.1035641513054,
    "input_throughput": 8860.748151149388,
    "output_throughput": 7787.682632015994,
    "total_throughput": 16648.430783165382,
    "itl": 107.90791387052234,
    "ttft": 87310.71704721553,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 134,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4485756384581326,
    "arrivals": 130909,
    "finished_requests": 128410,
    "scheduler_time": 110.15888921861753
}
#Debug simulation 
Total elapsed time: 10.959833504166454. Arrivals time: 0.27041352819651365 Scheduler time: 10.547833661083132 Scheduler overhead time: 0.0541338506154716 Adapter cache time: 0.009508684277534485 Engine time: 0.05345346359536052 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-8/adapters_32_slots_16_rate_3.2-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-8/adapters_32_slots_16_rate_3.2-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 1080, 66, 66, 1080, 66, 34560, 1080, 66, 66, 66, 34560, 34560, 66, 66, 1080, 1080, 1080, 34560, 34560, 66, 34560, 34560, 34560, 34560, 1080, 66, 1080, 1080, 1080, 1080, 34560]
Prompts retrieved: 392700 . Total input tokens: 87482444 . Total output tokens: 78533017
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 10.417688127141446,
    "estimated_duration": 3600.0843604387496,
    "input_throughput": 8862.38787918615,
    "output_throughput": 7798.6950274071705,
    "total_throughput": 16661.08290659332,
    "itl": 108.33186931489244,
    "ttft": 78015.27158424769,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 138,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4223473086627195,
    "arrivals": 130707,
    "finished_requests": 128449,
    "scheduler_time": 109.99903668154052
}
#Debug simulation 
Total elapsed time: 10.417772877961397. Arrivals time: 0.2644494865089655 Scheduler time: 10.012417228426784 Scheduler overhead time: 0.05387470405548811 Adapter cache time: 0.009476705454289913 Engine time: 0.053276111371815205 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-16/adapters_32_slots_16_rate_3.2-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-16/adapters_32_slots_16_rate_3.2-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 1080, 66, 66, 1080, 66, 34560, 1080, 66, 66, 66, 34560, 34560, 66, 66, 1080, 1080, 1080, 34560, 34560, 66, 34560, 34560, 34560, 34560, 1080, 66, 1080, 1080, 1080, 1080, 34560]
Prompts retrieved: 392700 . Total input tokens: 87482444 . Total output tokens: 78533017
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 10.464257268235087,
    "estimated_duration": 3600.0461395805128,
    "input_throughput": 8862.815575946435,
    "output_throughput": 7799.260318166836,
    "total_throughput": 16662.07589411327,
    "itl": 108.33635182230522,
    "ttft": 77576.48759693211,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 134,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4362145322212018,
    "arrivals": 130707,
    "finished_requests": 128459,
    "scheduler_time": 109.99819281394554
}
#Debug simulation 
Total elapsed time: 10.464350753929466. Arrivals time: 0.26653739949688315 Scheduler time: 10.056997671723366 Scheduler overhead time: 0.05389456590637565 Adapter cache time: 0.009445528965443373 Engine time: 0.053138492628932 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-32/adapters_32_slots_16_rate_3.2-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-32/adapters_32_slots_16_rate_3.2-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 1080, 66, 66, 1080, 66, 34560, 1080, 66, 66, 66, 34560, 34560, 66, 66, 1080, 1080, 1080, 34560, 34560, 66, 34560, 34560, 34560, 34560, 1080, 66, 1080, 1080, 1080, 1080, 34560]
Prompts retrieved: 392700 . Total input tokens: 87482444 . Total output tokens: 78533017
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 10.411815852392465,
    "estimated_duration": 3600.0471612178367,
    "input_throughput": 8862.813060817387,
    "output_throughput": 7799.258104858209,
    "total_throughput": 16662.071165675596,
    "itl": 108.33640143716349,
    "ttft": 77576.88171952103,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 134,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4371720577590179,
    "arrivals": 130707,
    "finished_requests": 128459,
    "scheduler_time": 109.99824052465027
}
#Debug simulation 
Total elapsed time: 10.411936238408089. Arrivals time: 0.2639030050486326 Scheduler time: 10.00723573192954 Scheduler overhead time: 0.053897814359515905 Adapter cache time: 0.009414414409548044 Engine time: 0.05320335505530238 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-16/adapters_32_slots_16_rate_3.2-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-16/adapters_32_slots_16_rate_3.2-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 1080, 66, 66, 1080, 66, 34560, 1080, 66, 66, 66, 34560, 34560, 66, 66, 1080, 1080, 1080, 34560, 34560, 66, 34560, 34560, 34560, 34560, 1080, 66, 1080, 1080, 1080, 1080, 34560]
Prompts retrieved: 392700 . Total input tokens: 87482444 . Total output tokens: 78533017
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 10.438652900978923,
    "estimated_duration": 3600.003581573799,
    "input_throughput": 8862.883126925002,
    "output_throughput": 7799.279740640009,
    "total_throughput": 16662.162867565014,
    "itl": 108.3353709460385,
    "ttft": 77540.88611366333,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 134,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.414967575662304,
    "arrivals": 130707,
    "finished_requests": 128458,
    "scheduler_time": 109.99643372514201
}
#Debug simulation 
Total elapsed time: 10.43873455002904. Arrivals time: 0.2623084606602788 Scheduler time: 10.036191797349602 Scheduler overhead time: 0.05359263950958848 Adapter cache time: 0.009444672614336014 Engine time: 0.052871106658130884 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-32/adapters_32_slots_16_rate_3.2-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-32/adapters_32_slots_16_rate_3.2-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 1080, 66, 66, 1080, 66, 34560, 1080, 66, 66, 66, 34560, 34560, 66, 66, 1080, 1080, 1080, 34560, 34560, 66, 34560, 34560, 34560, 34560, 1080, 66, 1080, 1080, 1080, 1080, 34560]
Prompts retrieved: 392700 . Total input tokens: 87482444 . Total output tokens: 78533017
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 10.426713980268687,
    "estimated_duration": 3600.0532290802485,
    "input_throughput": 8862.798122613196,
    "output_throughput": 7799.2449592678295,
    "total_throughput": 16662.043081881024,
    "itl": 108.33647821596041,
    "ttft": 77606.89089294459,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 134,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.44371125465258987,
    "arrivals": 130707,
    "finished_requests": 128459,
    "scheduler_time": 109.99850872761046
}
#Debug simulation 
Total elapsed time: 10.42679514316842. Arrivals time: 0.26430434454232454 Scheduler time: 10.022540488746017 Scheduler overhead time: 0.05345927318558097 Adapter cache time: 0.009394307620823383 Engine time: 0.05276464344933629 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-16/adapters_32_slots_16_rate_3.2-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-16/adapters_32_slots_16_rate_3.2-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 1080, 66, 66, 1080, 66, 34560, 1080, 66, 66, 66, 34560, 34560, 66, 66, 1080, 1080, 1080, 34560, 34560, 66, 34560, 34560, 34560, 34560, 1080, 66, 1080, 1080, 1080, 1080, 34560]
Prompts retrieved: 392700 . Total input tokens: 87482444 . Total output tokens: 78533017
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 10.380072847940028,
    "estimated_duration": 3600.0763734327866,
    "input_throughput": 8862.407540975928,
    "output_throughput": 7798.71232932447,
    "total_throughput": 16661.119870300397,
    "itl": 108.3318161649709,
    "ttft": 77957.90358711935,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 138,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.41262694069650074,
    "arrivals": 130707,
    "finished_requests": 128449,
    "scheduler_time": 109.99875538881166
}
#Debug simulation 
Total elapsed time: 10.380159463733435. Arrivals time: 0.2636133967898786 Scheduler time: 9.975619193632156 Scheduler overhead time: 0.053772606421262026 Adapter cache time: 0.009474443271756172 Engine time: 0.05334085272625089 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-32/adapters_32_slots_16_rate_3.2-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-32/adapters_32_slots_16_rate_3.2-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 1080, 66, 66, 1080, 66, 34560, 1080, 66, 66, 66, 34560, 34560, 66, 66, 1080, 1080, 1080, 34560, 34560, 66, 34560, 34560, 34560, 34560, 1080, 66, 1080, 1080, 1080, 1080, 34560]
Prompts retrieved: 392700 . Total input tokens: 87482444 . Total output tokens: 78533017
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 10.489761486183852,
    "estimated_duration": 3600.0591082580995,
    "input_throughput": 8862.783648971277,
    "output_throughput": 7799.232222491338,
    "total_throughput": 16662.015871462616,
    "itl": 108.33644526029822,
    "ttft": 77610.44966995162,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 134,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.44811263717710953,
    "arrivals": 130707,
    "finished_requests": 128459,
    "scheduler_time": 109.99889923015644
}
#Debug simulation 
Total elapsed time: 10.489851876161993. Arrivals time: 0.2654308117926121 Scheduler time: 10.083603764884174 Scheduler overhead time: 0.05372416414320469 Adapter cache time: 0.009392009116709232 Engine time: 0.05341419344767928 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-8/adapters_32_slots_16_rate_3.2-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-8/adapters_32_slots_16_rate_3.2-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 1080, 33, 33, 1080, 33, 34560, 1080, 33, 33, 33, 34560, 34560, 33, 33, 1080, 1080, 1080, 34560, 34560, 33, 34560, 34560, 34560, 34560, 1080, 33, 1080, 1080, 1080, 1080, 34560]
Prompts retrieved: 392370 . Total input tokens: 87403798 . Total output tokens: 78465602
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 10.24050571816042,
    "estimated_duration": 3600.02713273363,
    "input_throughput": 8849.943021348156,
    "output_throughput": 7795.657634027207,
    "total_throughput": 16645.60065537536,
    "itl": 108.42103878783891,
    "ttft": 84420.05768327464,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 136,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.416226333174854,
    "arrivals": 130593,
    "finished_requests": 128166,
    "scheduler_time": 110.16007133056988
}
#Debug simulation 
Total elapsed time: 10.240612579043955. Arrivals time: 0.26726055704057217 Scheduler time: 9.833490247372538 Scheduler overhead time: 0.053174893371760845 Adapter cache time: 0.00942965503782034 Engine time: 0.053001285064965487 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-16/adapters_32_slots_16_rate_3.2-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-16/adapters_32_slots_16_rate_3.2-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 1080, 33, 33, 1080, 33, 34560, 1080, 33, 33, 33, 34560, 34560, 33, 33, 1080, 1080, 1080, 34560, 34560, 33, 34560, 34560, 34560, 34560, 1080, 33, 1080, 1080, 1080, 1080, 34560]
Prompts retrieved: 392370 . Total input tokens: 87403798 . Total output tokens: 78465602
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 10.204807816073298,
    "estimated_duration": 3600.1019528073093,
    "input_throughput": 8849.864925396263,
    "output_throughput": 7795.693668651544,
    "total_throughput": 16645.55859404781,
    "itl": 108.42243010396913,
    "ttft": 84349.47431626839,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 136,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4454633953585289,
    "arrivals": 130593,
    "finished_requests": 128169,
    "scheduler_time": 110.1630020420978
}
#Debug simulation 
Total elapsed time: 10.204894953873008. Arrivals time: 0.25969715882092714 Scheduler time: 9.805005341768265 Scheduler overhead time: 0.05364901898428798 Adapter cache time: 0.009411996696144342 Engine time: 0.05279737338423729 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-32/adapters_32_slots_16_rate_3.2-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-32/adapters_32_slots_16_rate_3.2-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 1080, 33, 33, 1080, 33, 34560, 1080, 33, 33, 33, 34560, 34560, 33, 33, 1080, 1080, 1080, 34560, 34560, 33, 34560, 34560, 34560, 34560, 1080, 33, 1080, 1080, 1080, 1080, 34560]
Prompts retrieved: 392370 . Total input tokens: 87403798 . Total output tokens: 78465602
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 10.213551182299852,
    "estimated_duration": 3600.1028189005656,
    "input_throughput": 8849.862796343645,
    "output_throughput": 7795.691793205743,
    "total_throughput": 16645.55458954939,
    "itl": 108.42250459876468,
    "ttft": 84350.07850290512,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 136,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.44595707541331775,
    "arrivals": 130593,
    "finished_requests": 128169,
    "scheduler_time": 110.16307433955195
}
#Debug simulation 
Total elapsed time: 10.213662337046117. Arrivals time: 0.26202730322256684 Scheduler time: 9.811479748692364 Scheduler overhead time: 0.05359409796074033 Adapter cache time: 0.009391982108354568 Engine time: 0.05290763918310404 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-16/adapters_32_slots_16_rate_3.2-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-16/adapters_32_slots_16_rate_3.2-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 1080, 33, 33, 1080, 33, 34560, 1080, 33, 33, 33, 34560, 34560, 33, 33, 1080, 1080, 1080, 34560, 34560, 33, 34560, 34560, 34560, 34560, 1080, 33, 1080, 1080, 1080, 1080, 34560]
Prompts retrieved: 392370 . Total input tokens: 87403798 . Total output tokens: 78465602
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 10.182695116847754,
    "estimated_duration": 3600.049951608756,
    "input_throughput": 8849.887481634161,
    "output_throughput": 7795.61822120239,
    "total_throughput": 16645.50570283655,
    "itl": 108.4213432175339,
    "ttft": 84395.6405626422,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 136,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4221734622074294,
    "arrivals": 130593,
    "finished_requests": 128167,
    "scheduler_time": 110.16098964452203
}
#Debug simulation 
Total elapsed time: 10.182776879984885. Arrivals time: 0.2604793952777982 Scheduler time: 9.782194443047047 Scheduler overhead time: 0.05338997347280383 Adapter cache time: 0.009394016582518816 Engine time: 0.05315357353538275 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-32/adapters_32_slots_16_rate_3.2-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-32/adapters_32_slots_16_rate_3.2-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 1080, 33, 33, 1080, 33, 34560, 1080, 33, 33, 33, 34560, 34560, 33, 33, 1080, 1080, 1080, 34560, 34560, 33, 34560, 34560, 34560, 34560, 1080, 33, 1080, 1080, 1080, 1080, 34560]
Prompts retrieved: 392370 . Total input tokens: 87403798 . Total output tokens: 78465602
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 10.223430813290179,
    "estimated_duration": 3600.116909493699,
    "input_throughput": 8849.828158630737,
    "output_throughput": 7795.661281440704,
    "total_throughput": 16645.48944007144,
    "itl": 108.4227824328422,
    "ttft": 84382.66230734116,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 136,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4531250412389639,
    "arrivals": 130593,
    "finished_requests": 128169,
    "scheduler_time": 110.16389951336487
}
#Debug simulation 
Total elapsed time: 10.223529586102813. Arrivals time: 0.26387281296774745 Scheduler time: 9.819465023465455 Scheduler overhead time: 0.05357910180464387 Adapter cache time: 0.009433807339519262 Engine time: 0.05295986542478204 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-16/adapters_32_slots_16_rate_3.2-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-16/adapters_32_slots_16_rate_3.2-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 1080, 33, 33, 1080, 33, 34560, 1080, 33, 33, 33, 34560, 34560, 33, 33, 1080, 1080, 1080, 34560, 34560, 33, 34560, 34560, 34560, 34560, 1080, 33, 1080, 1080, 1080, 1080, 34560]
Prompts retrieved: 392370 . Total input tokens: 87403798 . Total output tokens: 78465602
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 10.20757176168263,
    "estimated_duration": 3600.0144151112695,
    "input_throughput": 8849.974285176651,
    "output_throughput": 7795.685173425223,
    "total_throughput": 16645.659458601876,
    "itl": 108.42079791331163,
    "ttft": 84387.8018323612,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 136,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4066468401066964,
    "arrivals": 130593,
    "finished_requests": 128166,
    "scheduler_time": 110.15942436591435
}
#Debug simulation 
Total elapsed time: 10.207655869890004. Arrivals time: 0.2645247094333172 Scheduler time: 9.804302152711898 Scheduler overhead time: 0.053043839521706104 Adapter cache time: 0.00933791883289814 Engine time: 0.052322220522910357 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-32/adapters_32_slots_16_rate_3.2-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-32/adapters_32_slots_16_rate_3.2-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 1080, 33, 33, 1080, 33, 34560, 1080, 33, 33, 33, 34560, 34560, 33, 33, 1080, 1080, 1080, 34560, 34560, 33, 34560, 34560, 34560, 34560, 1080, 33, 1080, 1080, 1080, 1080, 34560]
Prompts retrieved: 392370 . Total input tokens: 87403798 . Total output tokens: 78465602
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 10.24627360375598,
    "estimated_duration": 3600.0042443253064,
    "input_throughput": 8849.925399454907,
    "output_throughput": 7795.464698197751,
    "total_throughput": 16645.39009765266,
    "itl": 108.42229548216277,
    "ttft": 84465.44802090069,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 136,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.45790368512272805,
    "arrivals": 130593,
    "finished_requests": 128164,
    "scheduler_time": 110.16023668471323
}
#Debug simulation 
Total elapsed time: 10.246379701886326. Arrivals time: 0.26398200122639537 Scheduler time: 9.842345017008483 Scheduler overhead time: 0.05376567365601659 Adapter cache time: 0.009382500778883696 Engine time: 0.05273448908701539 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-8/adapters_32_slots_16_rate_3.2-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-8/adapters_32_slots_16_rate_3.2-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 540, 270, 270, 540, 270, 34560, 540, 270, 270, 270, 34560, 34560, 270, 270, 540, 540, 540, 34560, 34560, 270, 34560, 34560, 34560, 34560, 540, 270, 540, 540, 540, 540, 34560]
Prompts retrieved: 388800 . Total input tokens: 86598199 . Total output tokens: 77761056
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 9.727040776982903,
    "estimated_duration": 3600.0637747838573,
    "input_throughput": 8847.96547858723,
    "output_throughput": 7776.549736728162,
    "total_throughput": 16624.51521531539,
    "itl": 106.67923680891369,
    "ttft": 37433.05719874197,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 237,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7253355953120617,
    "arrivals": 129421,
    "finished_requests": 128205,
    "scheduler_time": 108.34363034268841
}
#Debug simulation 
Total elapsed time: 9.727128037251532. Arrivals time: 0.2567774816416204 Scheduler time: 9.328648013528436 Scheduler overhead time: 0.054073688574135303 Adapter cache time: 0.010026132687926292 Engine time: 0.053179220762103796 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-16/adapters_32_slots_16_rate_3.2-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-16/adapters_32_slots_16_rate_3.2-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 540, 270, 270, 540, 270, 34560, 540, 270, 270, 270, 34560, 34560, 270, 270, 540, 540, 540, 34560, 34560, 270, 34560, 34560, 34560, 34560, 540, 270, 540, 540, 540, 540, 34560]
Prompts retrieved: 388800 . Total input tokens: 86598199 . Total output tokens: 77761056
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 9.773661543615162,
    "estimated_duration": 3600.0728043932118,
    "input_throughput": 8848.20383663574,
    "output_throughput": 7776.698839488833,
    "total_throughput": 16624.902676124573,
    "itl": 106.68887104630738,
    "ttft": 37326.35846397209,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 240,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.779718559179458,
    "arrivals": 129421,
    "finished_requests": 128208,
    "scheduler_time": 108.34303766580058
}
#Debug simulation 
Total elapsed time: 9.773740509990603. Arrivals time: 0.26189149590209126 Scheduler time: 9.369583382736892 Scheduler overhead time: 0.054213219322264194 Adapter cache time: 0.010159408673644066 Engine time: 0.0533038629218936 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-32/adapters_32_slots_16_rate_3.2-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-32/adapters_32_slots_16_rate_3.2-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 540, 270, 270, 540, 270, 34560, 540, 270, 270, 270, 34560, 34560, 270, 270, 540, 540, 540, 34560, 34560, 270, 34560, 34560, 34560, 34560, 540, 270, 540, 540, 540, 540, 34560]
Prompts retrieved: 388800 . Total input tokens: 86598199 . Total output tokens: 77761056
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 9.753621072974056,
    "estimated_duration": 3600.067513956138,
    "input_throughput": 8847.956288740892,
    "output_throughput": 7776.541659696522,
    "total_throughput": 16624.497948437413,
    "itl": 106.68536749226291,
    "ttft": 37433.95646087147,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 237,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7719010913372075,
    "arrivals": 129421,
    "finished_requests": 128205,
    "scheduler_time": 108.34407280063772
}
#Debug simulation 
Total elapsed time: 9.75372587190941. Arrivals time: 0.2622868283651769 Scheduler time: 9.350122496951371 Scheduler overhead time: 0.05394468177109957 Adapter cache time: 0.010093109216541052 Engine time: 0.05287992116063833 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-16-16/adapters_32_slots_16_rate_3.2-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-16-16/adapters_32_slots_16_rate_3.2-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 540, 270, 270, 540, 270, 34560, 540, 270, 270, 270, 34560, 34560, 270, 270, 540, 540, 540, 34560, 34560, 270, 34560, 34560, 34560, 34560, 540, 270, 540, 540, 540, 540, 34560]
Prompts retrieved: 388800 . Total input tokens: 86598199 . Total output tokens: 77761056
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 9.778808545786887,
    "estimated_duration": 3600.0794499712424,
    "input_throughput": 8847.926953460554,
    "output_throughput": 7776.515876677009,
    "total_throughput": 16624.442830137563,
    "itl": 106.67879666419643,
    "ttft": 37460.9445615162,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 237,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7343834249535591,
    "arrivals": 129421,
    "finished_requests": 128205,
    "scheduler_time": 108.34389367907941
}
#Debug simulation 
Total elapsed time: 9.778894321992993. Arrivals time: 0.25745078222826123 Scheduler time: 9.379157350864261 Scheduler overhead time: 0.05427049193531275 Adapter cache time: 0.010139491874724627 Engine time: 0.05341067863628268 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-16-32/adapters_32_slots_16_rate_3.2-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-16-32/adapters_32_slots_16_rate_3.2-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 540, 270, 270, 540, 270, 34560, 540, 270, 270, 270, 34560, 34560, 270, 270, 540, 540, 540, 34560, 34560, 270, 34560, 34560, 34560, 34560, 540, 270, 540, 540, 540, 540, 34560]
Prompts retrieved: 388800 . Total input tokens: 86598199 . Total output tokens: 77761056
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 9.771497863344848,
    "estimated_duration": 3600.096763076616,
    "input_throughput": 8847.88440318989,
    "output_throughput": 7776.478478893651,
    "total_throughput": 16624.362882083544,
    "itl": 106.68565271073648,
    "ttft": 37464.642499922404,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 237,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7828416707553002,
    "arrivals": 129421,
    "finished_requests": 128205,
    "scheduler_time": 108.34507956724889
}
#Debug simulation 
Total elapsed time: 9.771590345073491. Arrivals time: 0.26038428535684943 Scheduler time: 9.369424131698906 Scheduler overhead time: 0.053971771616488695 Adapter cache time: 0.010058929212391376 Engine time: 0.0533207138068974 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_16-16-16/adapters_32_slots_16_rate_3.2-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_16-16-16/adapters_32_slots_16_rate_3.2-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 540, 270, 270, 540, 270, 34560, 540, 270, 270, 270, 34560, 34560, 270, 270, 540, 540, 540, 34560, 34560, 270, 34560, 34560, 34560, 34560, 540, 270, 540, 540, 540, 540, 34560]
Prompts retrieved: 388800 . Total input tokens: 86598199 . Total output tokens: 77761056
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 9.735119550023228,
    "estimated_duration": 3600.0199892934015,
    "input_throughput": 8848.107814604678,
    "output_throughput": 7776.635708485318,
    "total_throughput": 16624.743523089997,
    "itl": 106.68164623440981,
    "ttft": 37376.490454466744,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 240,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7176120707765231,
    "arrivals": 129421,
    "finished_requests": 128206,
    "scheduler_time": 108.3408536930067
}
#Debug simulation 
Total elapsed time: 9.73519920092076. Arrivals time: 0.2568888464011252 Scheduler time: 9.336927098222077 Scheduler overhead time: 0.054039107635617256 Adapter cache time: 0.010062765330076218 Engine time: 0.05290842894464731 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_16-16-32/adapters_32_slots_16_rate_3.2-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_16-16-32/adapters_32_slots_16_rate_3.2-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 540, 270, 270, 540, 270, 34560, 540, 270, 270, 270, 34560, 34560, 270, 270, 540, 540, 540, 34560, 34560, 270, 34560, 34560, 34560, 34560, 540, 270, 540, 540, 540, 540, 34560]
Prompts retrieved: 388800 . Total input tokens: 86598199 . Total output tokens: 77761056
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 9.799833205062896,
    "estimated_duration": 3600.1122418268365,
    "input_throughput": 8847.84636154467,
    "output_throughput": 7776.445043778332,
    "total_throughput": 16624.291405323,
    "itl": 106.68581862429859,
    "ttft": 37493.09247236183,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 237,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7907641592994363,
    "arrivals": 129421,
    "finished_requests": 128205,
    "scheduler_time": 108.34546408400296
}
#Debug simulation 
Total elapsed time: 9.799914305098355. Arrivals time: 0.25741593446582556 Scheduler time: 9.40012558316812 Scheduler overhead time: 0.05423521203920245 Adapter cache time: 0.01006328733637929 Engine time: 0.05341321835294366 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-8/adapters_32_slots_16_rate_3.2-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-8/adapters_32_slots_16_rate_3.2-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 540, 135, 135, 540, 135, 34560, 540, 135, 135, 135, 34560, 34560, 135, 135, 540, 540, 540, 34560, 34560, 135, 34560, 34560, 34560, 34560, 540, 135, 540, 540, 540, 540, 34560]
Prompts retrieved: 387450 . Total input tokens: 86296579 . Total output tokens: 77492450
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 9.611824788153172,
    "estimated_duration": 3600.0223770152425,
    "input_throughput": 8736.284585562962,
    "output_throughput": 7799.250687791245,
    "total_throughput": 16535.535273354206,
    "itl": 108.53634036944322,
    "ttft": 37650.57791857436,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 252,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.771242911471053,
    "arrivals": 128920,
    "finished_requests": 127767,
    "scheduler_time": 108.94899013200845
}
#Debug simulation 
Total elapsed time: 9.611907870974392. Arrivals time: 0.2593093910254538 Scheduler time: 9.212572578340769 Scheduler overhead time: 0.05325631331652403 Adapter cache time: 0.010090242139995098 Engine time: 0.0525301368907094 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-16/adapters_32_slots_16_rate_3.2-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-16/adapters_32_slots_16_rate_3.2-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 540, 135, 135, 540, 135, 34560, 540, 135, 135, 135, 34560, 34560, 135, 135, 540, 540, 540, 34560, 34560, 135, 34560, 34560, 34560, 34560, 540, 135, 540, 540, 540, 540, 34560]
Prompts retrieved: 387450 . Total input tokens: 86296579 . Total output tokens: 77492450
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 9.562397431582212,
    "estimated_duration": 3600.0062985481322,
    "input_throughput": 8736.32332606862,
    "output_throughput": 7799.140243538829,
    "total_throughput": 16535.46356960745,
    "itl": 108.54178297153653,
    "ttft": 37692.32769800895,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 252,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8213194971764495,
    "arrivals": 128920,
    "finished_requests": 127766,
    "scheduler_time": 108.94971806984026
}
#Debug simulation 
Total elapsed time: 9.562488050665706. Arrivals time: 0.2553141163662076 Scheduler time: 9.167541986331344 Scheduler overhead time: 0.05331778526306152 Adapter cache time: 0.010064750909805298 Engine time: 0.052294847555458546 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-32/adapters_32_slots_16_rate_3.2-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-32/adapters_32_slots_16_rate_3.2-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 540, 135, 135, 540, 135, 34560, 540, 135, 135, 135, 34560, 34560, 135, 135, 540, 540, 540, 34560, 34560, 135, 34560, 34560, 34560, 34560, 540, 135, 540, 540, 540, 540, 34560]
Prompts retrieved: 387450 . Total input tokens: 86296579 . Total output tokens: 77492450
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 9.525108157191426,
    "estimated_duration": 3600.019830526284,
    "input_throughput": 8736.290487433851,
    "output_throughput": 7799.110927646044,
    "total_throughput": 16535.401415079894,
    "itl": 108.54221467687394,
    "ttft": 37692.75774567087,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 252,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8229498339816967,
    "arrivals": 128920,
    "finished_requests": 127766,
    "scheduler_time": 108.95021531302731
}
#Debug simulation 
Total elapsed time: 9.525218970142305. Arrivals time: 0.25436191260814667 Scheduler time: 9.130462801549584 Scheduler overhead time: 0.0534018874168396 Adapter cache time: 0.010108256712555885 Engine time: 0.05269160075113177 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-16/adapters_32_slots_16_rate_3.2-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-16/adapters_32_slots_16_rate_3.2-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 540, 135, 135, 540, 135, 34560, 540, 135, 135, 135, 34560, 34560, 135, 135, 540, 540, 540, 34560, 34560, 135, 34560, 34560, 34560, 34560, 540, 135, 540, 540, 540, 540, 34560]
Prompts retrieved: 387450 . Total input tokens: 86296579 . Total output tokens: 77492450
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 9.589644961990416,
    "estimated_duration": 3600.055530755861,
    "input_throughput": 8736.335240194627,
    "output_throughput": 7799.409970241411,
    "total_throughput": 16535.745210436038,
    "itl": 108.53724050930651,
    "ttft": 37653.03190812495,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 252,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7800513700139727,
    "arrivals": 128920,
    "finished_requests": 127769,
    "scheduler_time": 108.95018335543118
}
#Debug simulation 
Total elapsed time: 9.589753495063633. Arrivals time: 0.25542014045640826 Scheduler time: 9.19368178024888 Scheduler overhead time: 0.05339358188211918 Adapter cache time: 0.010077518876641989 Engine time: 0.05283591989427805 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-32/adapters_32_slots_16_rate_3.2-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-32/adapters_32_slots_16_rate_3.2-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 540, 135, 135, 540, 135, 34560, 540, 135, 135, 135, 34560, 34560, 135, 135, 540, 540, 540, 34560, 34560, 135, 34560, 34560, 34560, 34560, 540, 135, 540, 540, 540, 540, 34560]
Prompts retrieved: 387450 . Total input tokens: 86296579 . Total output tokens: 77492450
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 9.544847701210529,
    "estimated_duration": 3600.0741198908468,
    "input_throughput": 8736.290129758105,
    "output_throughput": 7799.369697658149,
    "total_throughput": 16535.659827416253,
    "itl": 108.54419540369118,
    "ttft": 37668.98314489616,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 252,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8356509664095975,
    "arrivals": 128920,
    "finished_requests": 127769,
    "scheduler_time": 108.95228993925575
}
#Debug simulation 
Total elapsed time: 9.544952977914363. Arrivals time: 0.2549656410701573 Scheduler time: 9.150467808824033 Scheduler overhead time: 0.05307538993656635 Adapter cache time: 0.010052406694740057 Engine time: 0.05226508527994156 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-16/adapters_32_slots_16_rate_3.2-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-16/adapters_32_slots_16_rate_3.2-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 540, 135, 135, 540, 135, 34560, 540, 135, 135, 135, 34560, 34560, 135, 135, 540, 540, 540, 34560, 34560, 135, 34560, 34560, 34560, 34560, 540, 135, 540, 540, 540, 540, 34560]
Prompts retrieved: 387450 . Total input tokens: 86296579 . Total output tokens: 77492450
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 9.557477317284793,
    "estimated_duration": 3600.050864269258,
    "input_throughput": 8736.346564476671,
    "output_throughput": 7799.42008005472,
    "total_throughput": 16535.76664453139,
    "itl": 108.53415612316833,
    "ttft": 37649.30170647643,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 252,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7534926743153493,
    "arrivals": 128920,
    "finished_requests": 127769,
    "scheduler_time": 108.94971058542002
}
#Debug simulation 
Total elapsed time: 9.55756075726822. Arrivals time: 0.26011177990585566 Scheduler time: 9.157108346931636 Scheduler overhead time: 0.05324983270838857 Adapter cache time: 0.01005508378148079 Engine time: 0.0528402766212821 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-32/adapters_32_slots_16_rate_3.2-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-32/adapters_32_slots_16_rate_3.2-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 540, 135, 135, 540, 135, 34560, 540, 135, 135, 135, 34560, 34560, 135, 135, 540, 540, 540, 34560, 34560, 135, 34560, 34560, 34560, 34560, 540, 135, 540, 540, 540, 540, 34560]
Prompts retrieved: 387450 . Total input tokens: 86296579 . Total output tokens: 77492450
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 9.554617315065116,
    "estimated_duration": 3600.0008766579076,
    "input_throughput": 8736.336483672649,
    "output_throughput": 7799.1519896699265,
    "total_throughput": 16535.488473342575,
    "itl": 108.54474421847627,
    "ttft": 37691.855010878244,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 252,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8438249625265634,
    "arrivals": 128920,
    "finished_requests": 127766,
    "scheduler_time": 108.94961398974633
}
#Debug simulation 
Total elapsed time: 9.554700097069144. Arrivals time: 0.25451318733394146 Scheduler time: 9.159603502135724 Scheduler overhead time: 0.05342278862372041 Adapter cache time: 0.010117418598383665 Engine time: 0.05289230216294527 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-8/adapters_32_slots_16_rate_3.2-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-8/adapters_32_slots_16_rate_3.2-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 540, 66, 66, 540, 66, 34560, 540, 66, 66, 66, 34560, 34560, 66, 66, 540, 540, 540, 34560, 34560, 66, 34560, 34560, 34560, 34560, 540, 66, 540, 540, 540, 540, 34560]
Prompts retrieved: 386760 . Total input tokens: 86146875 . Total output tokens: 77349204
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 9.310635678935796,
    "estimated_duration": 3600.0794657254573,
    "input_throughput": 8829.907868045984,
    "output_throughput": 7761.901443019695,
    "total_throughput": 16591.80931106568,
    "itl": 105.83834393425651,
    "ttft": 30290.144171164466,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 266,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8140897398861114,
    "arrivals": 128685,
    "finished_requests": 127689,
    "scheduler_time": 107.91793390876582
}
#Debug simulation 
Total elapsed time: 9.310715205967426. Arrivals time: 0.2527082716114819 Scheduler time: 8.91619364824146 Scheduler overhead time: 0.05396250123158097 Adapter cache time: 0.010277376044541597 Engine time: 0.05306512722745538 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-16/adapters_32_slots_16_rate_3.2-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-16/adapters_32_slots_16_rate_3.2-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 540, 66, 66, 540, 66, 34560, 540, 66, 66, 66, 34560, 34560, 66, 66, 540, 540, 540, 34560, 34560, 66, 34560, 34560, 34560, 34560, 540, 66, 540, 540, 540, 540, 34560]
Prompts retrieved: 386760 . Total input tokens: 86146875 . Total output tokens: 77349204
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 9.320328916888684,
    "estimated_duration": 3600.1110404833335,
    "input_throughput": 8829.733483923956,
    "output_throughput": 7762.046416281744,
    "total_throughput": 16591.7799002057,
    "itl": 105.85743354648069,
    "ttft": 30313.912650841346,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 269,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8795050679217136,
    "arrivals": 128685,
    "finished_requests": 127688,
    "scheduler_time": 107.91848122768172
}
#Debug simulation 
Total elapsed time: 9.320407440885901. Arrivals time: 0.2528904159553349 Scheduler time: 8.924640544690192 Scheduler overhead time: 0.05442024581134319 Adapter cache time: 0.010347039438784122 Engine time: 0.053550802636891603 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-32/adapters_32_slots_16_rate_3.2-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-32/adapters_32_slots_16_rate_3.2-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 540, 66, 66, 540, 66, 34560, 540, 66, 66, 66, 34560, 34560, 66, 66, 540, 540, 540, 34560, 34560, 66, 34560, 34560, 34560, 34560, 540, 66, 540, 540, 540, 540, 34560]
Prompts retrieved: 386760 . Total input tokens: 86146875 . Total output tokens: 77349204
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 9.315542339812964,
    "estimated_duration": 3600.119398806348,
    "input_throughput": 8829.712984113696,
    "output_throughput": 7762.028395298546,
    "total_throughput": 16591.74137941224,
    "itl": 105.85767606449954,
    "ttft": 30341.852053690716,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 269,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8807601093128368,
    "arrivals": 128685,
    "finished_requests": 127688,
    "scheduler_time": 107.91878188582501
}
#Debug simulation 
Total elapsed time: 9.315656099002808. Arrivals time: 0.2515606847591698 Scheduler time: 8.921221088152379 Scheduler overhead time: 0.054324240423738956 Adapter cache time: 0.010339571628719568 Engine time: 0.053695136215537786 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-16/adapters_32_slots_16_rate_3.2-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-16/adapters_32_slots_16_rate_3.2-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 540, 66, 66, 540, 66, 34560, 540, 66, 66, 66, 34560, 34560, 66, 66, 540, 540, 540, 34560, 34560, 66, 34560, 34560, 34560, 34560, 540, 66, 540, 540, 540, 540, 34560]
Prompts retrieved: 386760 . Total input tokens: 86146875 . Total output tokens: 77349204
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 9.315394144970924,
    "estimated_duration": 3600.0505884739987,
    "input_throughput": 8829.728699305355,
    "output_throughput": 7761.88481613661,
    "total_throughput": 16591.613515441964,
    "itl": 105.84017651385385,
    "ttft": 30320.481168891154,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 266,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8235464554163648,
    "arrivals": 128685,
    "finished_requests": 127687,
    "scheduler_time": 107.9176431409479
}
#Debug simulation 
Total elapsed time: 9.315477804746479. Arrivals time: 0.25258684903383255 Scheduler time: 8.921047830488533 Scheduler overhead time: 0.05386117473244667 Adapter cache time: 0.010317435953766108 Engine time: 0.053191596176475286 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-32/adapters_32_slots_16_rate_3.2-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-32/adapters_32_slots_16_rate_3.2-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 540, 66, 66, 540, 66, 34560, 540, 66, 66, 66, 34560, 34560, 66, 66, 540, 540, 540, 34560, 34560, 66, 34560, 34560, 34560, 34560, 540, 66, 540, 540, 540, 540, 34560]
Prompts retrieved: 386760 . Total input tokens: 86146875 . Total output tokens: 77349204
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 9.317248420789838,
    "estimated_duration": 3600.0858599807425,
    "input_throughput": 8829.764965708357,
    "output_throughput": 7761.829324856567,
    "total_throughput": 16591.594290564924,
    "itl": 105.8474106445334,
    "ttft": 30322.76028861968,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 266,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8837762317992789,
    "arrivals": 128685,
    "finished_requests": 127688,
    "scheduler_time": 107.91898541189599
}
#Debug simulation 
Total elapsed time: 9.317348862066865. Arrivals time: 0.25504467636346817 Scheduler time: 8.920986508950591 Scheduler overhead time: 0.053905760403722525 Adapter cache time: 0.010259850416332483 Engine time: 0.05289481347426772 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-16/adapters_32_slots_16_rate_3.2-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-16/adapters_32_slots_16_rate_3.2-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 540, 66, 66, 540, 66, 34560, 540, 66, 66, 66, 34560, 34560, 66, 66, 540, 540, 540, 34560, 34560, 66, 34560, 34560, 34560, 34560, 540, 66, 540, 540, 540, 540, 34560]
Prompts retrieved: 386760 . Total input tokens: 86146875 . Total output tokens: 77349204
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 9.262434757780284,
    "estimated_duration": 3600.114135279532,
    "input_throughput": 8829.822834917366,
    "output_throughput": 7761.826694927915,
    "total_throughput": 16591.649529845283,
    "itl": 105.83625930383519,
    "ttft": 30346.759835155204,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 266,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7953533784439798,
    "arrivals": 128685,
    "finished_requests": 127689,
    "scheduler_time": 107.91909570205763
}
#Debug simulation 
Total elapsed time: 9.262533864937723. Arrivals time: 0.25043672882020473 Scheduler time: 8.870393755845726 Scheduler overhead time: 0.054124407004565 Adapter cache time: 0.010227439925074577 Engine time: 0.05284893931820989 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-32/adapters_32_slots_16_rate_3.2-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-32/adapters_32_slots_16_rate_3.2-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 540, 66, 66, 540, 66, 34560, 540, 66, 66, 66, 34560, 34560, 66, 66, 540, 540, 540, 34560, 34560, 66, 34560, 34560, 34560, 34560, 540, 66, 540, 540, 540, 540, 34560]
Prompts retrieved: 386760 . Total input tokens: 86146875 . Total output tokens: 77349204
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 9.333518395666033,
    "estimated_duration": 3600.052998134411,
    "input_throughput": 8829.722789212445,
    "output_throughput": 7761.879620794604,
    "total_throughput": 16591.60241000705,
    "itl": 105.84943895712388,
    "ttft": 30323.71072139284,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 266,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8924532430619045,
    "arrivals": 128685,
    "finished_requests": 127687,
    "scheduler_time": 107.91843545219588
}
#Debug simulation 
Total elapsed time: 9.333592501934618. Arrivals time: 0.25519801722839475 Scheduler time: 8.935915370006114 Scheduler overhead time: 0.054117055144160986 Adapter cache time: 0.010299034416675568 Engine time: 0.053537615574896336 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-8/adapters_32_slots_16_rate_3.2-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-8/adapters_32_slots_16_rate_3.2-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 540, 33, 33, 540, 33, 34560, 540, 33, 33, 33, 34560, 34560, 33, 33, 540, 540, 540, 34560, 34560, 33, 34560, 34560, 34560, 34560, 540, 33, 540, 540, 540, 540, 34560]
Prompts retrieved: 386430 . Total input tokens: 86078451 . Total output tokens: 77288425
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 9.205170777160674,
    "estimated_duration": 3600.0710936413093,
    "input_throughput": 8727.31376207939,
    "output_throughput": 7789.886996824446,
    "total_throughput": 16517.200758903837,
    "itl": 107.72783780223692,
    "ttft": 32015.06019441802,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 255,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7804243747028512,
    "arrivals": 128584,
    "finished_requests": 127561,
    "scheduler_time": 108.49094497666837
}
#Debug simulation 
Total elapsed time: 9.205276975873858. Arrivals time: 0.2560751661658287 Scheduler time: 8.808812693227082 Scheduler overhead time: 0.053353880532085896 Adapter cache time: 0.01011770823970437 Engine time: 0.052834196481853724 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-16/adapters_32_slots_16_rate_3.2-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-16/adapters_32_slots_16_rate_3.2-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 540, 33, 33, 540, 33, 34560, 540, 33, 33, 33, 34560, 34560, 33, 33, 540, 540, 540, 34560, 34560, 33, 34560, 34560, 34560, 34560, 540, 33, 540, 540, 540, 540, 34560]
Prompts retrieved: 386430 . Total input tokens: 86078451 . Total output tokens: 77288425
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 9.239781443029642,
    "estimated_duration": 3600.0005179347336,
    "input_throughput": 8727.29152217572,
    "output_throughput": 7789.962212585555,
    "total_throughput": 16517.253734761274,
    "itl": 107.73529926804467,
    "ttft": 31968.231793348674,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 255,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8376443637930827,
    "arrivals": 128584,
    "finished_requests": 127559,
    "scheduler_time": 108.48985171469401
}
#Debug simulation 
Total elapsed time: 9.23988624336198. Arrivals time: 0.2639685198664665 Scheduler time: 8.836808696389198 Scheduler overhead time: 0.053187997080385685 Adapter cache time: 0.010127260349690914 Engine time: 0.05180005868896842 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-32/adapters_32_slots_16_rate_3.2-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-32/adapters_32_slots_16_rate_3.2-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 540, 33, 33, 540, 33, 34560, 540, 33, 33, 33, 34560, 34560, 33, 33, 540, 540, 540, 34560, 34560, 33, 34560, 34560, 34560, 34560, 540, 33, 540, 540, 540, 540, 34560]
Prompts retrieved: 386430 . Total input tokens: 86078451 . Total output tokens: 77288425
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 9.190216986928135,
    "estimated_duration": 3600.120568266641,
    "input_throughput": 8727.385765062778,
    "output_throughput": 7790.061601604352,
    "total_throughput": 16517.44736666713,
    "itl": 107.7357662858237,
    "ttft": 32050.170519170555,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 255,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8381508454307955,
    "arrivals": 128584,
    "finished_requests": 127564,
    "scheduler_time": 108.49345953315287
}
#Debug simulation 
Total elapsed time: 9.190326335839927. Arrivals time: 0.2549979742616415 Scheduler time: 8.795134578365833 Scheduler overhead time: 0.05360955325886607 Adapter cache time: 0.010045723989605904 Engine time: 0.05233719991520047 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-16/adapters_32_slots_16_rate_3.2-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-16/adapters_32_slots_16_rate_3.2-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 540, 33, 33, 540, 33, 34560, 540, 33, 33, 33, 34560, 34560, 33, 33, 540, 540, 540, 34560, 34560, 33, 34560, 34560, 34560, 34560, 540, 33, 540, 540, 540, 540, 34560]
Prompts retrieved: 386430 . Total input tokens: 86078451 . Total output tokens: 77288425
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 9.192320376634598,
    "estimated_duration": 3600.027015344278,
    "input_throughput": 8727.227286375073,
    "output_throughput": 7789.904875843858,
    "total_throughput": 16517.13216221893,
    "itl": 107.72958520414666,
    "ttft": 31989.19940539787,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 255,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7926988787646426,
    "arrivals": 128584,
    "finished_requests": 127559,
    "scheduler_time": 108.48992320662428
}
#Debug simulation 
Total elapsed time: 9.192420068662614. Arrivals time: 0.2529784585349262 Scheduler time: 8.799158373381943 Scheduler overhead time: 0.05356962280347943 Adapter cache time: 0.010107695125043392 Engine time: 0.052493881434202194 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-32/adapters_32_slots_16_rate_3.2-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-32/adapters_32_slots_16_rate_3.2-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 540, 33, 33, 540, 33, 34560, 540, 33, 33, 33, 34560, 34560, 33, 33, 540, 540, 540, 34560, 34560, 33, 34560, 34560, 34560, 34560, 540, 33, 540, 540, 540, 540, 34560]
Prompts retrieved: 386430 . Total input tokens: 86078451 . Total output tokens: 77288425
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 9.21184977190569,
    "estimated_duration": 3600.082264259876,
    "input_throughput": 8727.286682283433,
    "output_throughput": 7789.862825750029,
    "total_throughput": 16517.14950803346,
    "itl": 107.73782676151353,
    "ttft": 32052.94076176572,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 255,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8519837619364301,
    "arrivals": 128584,
    "finished_requests": 127561,
    "scheduler_time": 108.49260770758028
}
#Debug simulation 
Total elapsed time: 9.211937687825412. Arrivals time: 0.25423573423177004 Scheduler time: 8.817195564042777 Scheduler overhead time: 0.05350968707352877 Adapter cache time: 0.010136630851775408 Engine time: 0.052755529060959816 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-16/adapters_32_slots_16_rate_3.2-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-16/adapters_32_slots_16_rate_3.2-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 540, 33, 33, 540, 33, 34560, 540, 33, 33, 33, 34560, 34560, 33, 33, 540, 540, 540, 34560, 34560, 33, 34560, 34560, 34560, 34560, 540, 33, 540, 540, 540, 540, 34560]
Prompts retrieved: 386430 . Total input tokens: 86078451 . Total output tokens: 77288425
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 9.20918498095125,
    "estimated_duration": 3600.0085185195967,
    "input_throughput": 8727.272126822601,
    "output_throughput": 7789.944900333808,
    "total_throughput": 16517.21702715641,
    "itl": 107.7262750878978,
    "ttft": 31982.501386937773,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 255,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7624628252000558,
    "arrivals": 128584,
    "finished_requests": 127559,
    "scheduler_time": 108.48871672967421
}
#Debug simulation 
Total elapsed time: 9.209273393731564. Arrivals time: 0.25202310224995017 Scheduler time: 8.817284628283232 Scheduler overhead time: 0.053338322788476944 Adapter cache time: 0.010062005836516619 Engine time: 0.052461277693510056 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-32/adapters_32_slots_16_rate_3.2-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-32/adapters_32_slots_16_rate_3.2-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 540, 33, 33, 540, 33, 34560, 540, 33, 33, 33, 34560, 34560, 33, 33, 540, 540, 540, 34560, 34560, 33, 34560, 34560, 34560, 34560, 540, 33, 540, 540, 540, 540, 34560]
Prompts retrieved: 386430 . Total input tokens: 86078451 . Total output tokens: 77288425
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 9.133511410094798,
    "estimated_duration": 3600.1158092033575,
    "input_throughput": 8727.397301964187,
    "output_throughput": 7790.071899438674,
    "total_throughput": 16517.469201402862,
    "itl": 107.73874547368105,
    "ttft": 32053.514810806162,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 255,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8612895421311298,
    "arrivals": 128584,
    "finished_requests": 127564,
    "scheduler_time": 108.49365670326809
}
#Debug simulation 
Total elapsed time: 9.133593693841249. Arrivals time: 0.25206993892788887 Scheduler time: 8.741101638879627 Scheduler overhead time: 0.05336465314030647 Adapter cache time: 0.0100163365714252 Engine time: 0.052943289279937744 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-8/adapters_32_slots_16_rate_3.2-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-8/adapters_32_slots_16_rate_3.2-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 135, 135, 270, 135, 34560, 270, 135, 135, 135, 34560, 34560, 135, 135, 270, 270, 270, 34560, 34560, 135, 34560, 34560, 34560, 34560, 270, 135, 270, 270, 270, 270, 34560]
Prompts retrieved: 384480 . Total input tokens: 85647737 . Total output tokens: 76906968
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 9.120499174576253,
    "estimated_duration": 3600.051286200132,
    "input_throughput": 8769.808674954771,
    "output_throughput": 7713.168728023601,
    "total_throughput": 16482.977402978373,
    "itl": 102.96687050500657,
    "ttft": 27904.376597109575,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 368,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1262594897672564,
    "arrivals": 127929,
    "finished_requests": 126978,
    "scheduler_time": 106.86446983923858
}
#Debug simulation 
Total elapsed time: 9.120584979653358. Arrivals time: 0.25073070684447885 Scheduler time: 8.72174209356308 Scheduler overhead time: 0.05651262076571584 Adapter cache time: 0.011132291983813047 Engine time: 0.05538984201848507 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-16/adapters_32_slots_16_rate_3.2-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-16/adapters_32_slots_16_rate_3.2-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 135, 135, 270, 135, 34560, 270, 135, 135, 135, 34560, 34560, 135, 135, 270, 270, 270, 34560, 34560, 135, 34560, 34560, 34560, 34560, 270, 135, 270, 270, 270, 270, 34560]
Prompts retrieved: 384480 . Total input tokens: 85647737 . Total output tokens: 76906968
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 9.160697166342288,
    "estimated_duration": 3600.0849655913385,
    "input_throughput": 8769.806907825043,
    "output_throughput": 7713.153790924186,
    "total_throughput": 16482.96069874923,
    "itl": 102.97726198496783,
    "ttft": 27877.097811920594,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 368,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1959498130390465,
    "arrivals": 127929,
    "finished_requests": 126979,
    "scheduler_time": 106.86618311616532
}
#Debug simulation 
Total elapsed time: 9.160777460318059. Arrivals time: 0.2528877039439976 Scheduler time: 8.762404347304255 Scheduler overhead time: 0.05520079052075744 Adapter cache time: 0.010988593567162752 Engine time: 0.05432753777131438 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-32/adapters_32_slots_16_rate_3.2-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-32/adapters_32_slots_16_rate_3.2-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 135, 135, 270, 135, 34560, 270, 135, 135, 135, 34560, 34560, 135, 135, 270, 270, 270, 34560, 34560, 135, 34560, 34560, 34560, 34560, 270, 135, 270, 270, 270, 270, 34560]
Prompts retrieved: 384480 . Total input tokens: 85647737 . Total output tokens: 76906968
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 9.125699443742633,
    "estimated_duration": 3600.0941928994694,
    "input_throughput": 8769.784430160224,
    "output_throughput": 7713.134021539588,
    "total_throughput": 16482.91845169981,
    "itl": 102.97749123413624,
    "ttft": 27877.096259728067,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 368,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1989308500662512,
    "arrivals": 127929,
    "finished_requests": 126979,
    "scheduler_time": 106.86642217251472
}
#Debug simulation 
Total elapsed time: 9.125812560785562. Arrivals time: 0.2530530751682818 Scheduler time: 8.726845521014184 Scheduler overhead time: 0.05530737014487386 Adapter cache time: 0.011058267671614885 Engine time: 0.05466907378286123 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-16/adapters_32_slots_16_rate_3.2-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-16/adapters_32_slots_16_rate_3.2-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 135, 135, 270, 135, 34560, 270, 135, 135, 135, 34560, 34560, 135, 135, 270, 270, 270, 34560, 34560, 135, 34560, 34560, 34560, 34560, 270, 135, 270, 270, 270, 270, 34560]
Prompts retrieved: 384480 . Total input tokens: 85647737 . Total output tokens: 76906968
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 9.131089047994465,
    "estimated_duration": 3600.012848194068,
    "input_throughput": 8769.63620167005,
    "output_throughput": 7713.076916914142,
    "total_throughput": 16482.71311858419,
    "itl": 102.96826852767211,
    "ttft": 27905.422851271604,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 368,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1371120871836318,
    "arrivals": 127929,
    "finished_requests": 126976,
    "scheduler_time": 106.86363706087724
}
#Debug simulation 
Total elapsed time: 9.131168445106596. Arrivals time: 0.2524010534398258 Scheduler time: 8.731980113312602 Scheduler overhead time: 0.05588269513100386 Adapter cache time: 0.011136123444885015 Engine time: 0.05484392307698727 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-32/adapters_32_slots_16_rate_3.2-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-32/adapters_32_slots_16_rate_3.2-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 135, 135, 270, 135, 34560, 270, 135, 135, 135, 34560, 34560, 135, 135, 270, 270, 270, 34560, 34560, 135, 34560, 34560, 34560, 34560, 270, 135, 270, 270, 270, 270, 34560]
Prompts retrieved: 384480 . Total input tokens: 85647737 . Total output tokens: 76906968
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 9.079624983016402,
    "estimated_duration": 3600.0402505992497,
    "input_throughput": 8769.83555801763,
    "output_throughput": 7713.1923720513605,
    "total_throughput": 16483.02793006899,
    "itl": 102.97783391229959,
    "ttft": 27906.21711665442,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 368,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2170393953099894,
    "arrivals": 127929,
    "finished_requests": 126978,
    "scheduler_time": 106.86477510792106
}
#Debug simulation 
Total elapsed time: 9.079700809903443. Arrivals time: 0.2509699952788651 Scheduler time: 8.683192761149257 Scheduler overhead time: 0.05527955573052168 Adapter cache time: 0.011051794048398733 Engine time: 0.05427147774025798 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-16/adapters_32_slots_16_rate_3.2-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-16/adapters_32_slots_16_rate_3.2-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 135, 135, 270, 135, 34560, 270, 135, 135, 135, 34560, 34560, 135, 135, 270, 270, 270, 34560, 34560, 135, 34560, 34560, 34560, 34560, 270, 135, 270, 270, 270, 270, 34560]
Prompts retrieved: 384480 . Total input tokens: 85647737 . Total output tokens: 76906968
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 9.089009770192206,
    "estimated_duration": 3600.044904176442,
    "input_throughput": 8769.824221740495,
    "output_throughput": 7713.182401637919,
    "total_throughput": 16483.006623378413,
    "itl": 102.9634659472343,
    "ttft": 27903.243879640457,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 368,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1003385085239985,
    "arrivals": 127929,
    "finished_requests": 126978,
    "scheduler_time": 106.86408203300829
}
#Debug simulation 
Total elapsed time: 9.089093636255711. Arrivals time: 0.254070698749274 Scheduler time: 8.688778881449252 Scheduler overhead time: 0.05569863738492131 Adapter cache time: 0.01102615986019373 Engine time: 0.054717539343982935 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-32/adapters_32_slots_16_rate_3.2-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-32/adapters_32_slots_16_rate_3.2-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 135, 135, 270, 135, 34560, 270, 135, 135, 135, 34560, 34560, 135, 135, 270, 270, 270, 34560, 34560, 135, 34560, 34560, 34560, 34560, 270, 135, 270, 270, 270, 270, 34560]
Prompts retrieved: 384480 . Total input tokens: 85647737 . Total output tokens: 76906968
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 9.090713602025062,
    "estimated_duration": 3600.101049431955,
    "input_throughput": 8769.767727764649,
    "output_throughput": 7713.119331575818,
    "total_throughput": 16482.887059340464,
    "itl": 102.9802447254375,
    "ttft": 27876.726224615915,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 368,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2283572360873254,
    "arrivals": 127929,
    "finished_requests": 126979,
    "scheduler_time": 106.86656709937456
}
#Debug simulation 
Total elapsed time: 9.090796409640461. Arrivals time: 0.2516060248017311 Scheduler time: 8.69289756892249 Scheduler overhead time: 0.05569850327447057 Adapter cache time: 0.011038337368518114 Engine time: 0.054676521103829145 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-8/adapters_32_slots_16_rate_3.2-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-8/adapters_32_slots_16_rate_3.2-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 66, 66, 270, 66, 34560, 270, 66, 66, 66, 34560, 34560, 66, 66, 270, 270, 270, 34560, 34560, 66, 34560, 34560, 34560, 34560, 270, 66, 270, 270, 270, 270, 34560]
Prompts retrieved: 383790 . Total input tokens: 85486715 . Total output tokens: 76768251
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 9.088591800071299,
    "estimated_duration": 3600.0879607522693,
    "input_throughput": 8674.776100046798,
    "output_throughput": 7768.039088177263,
    "total_throughput": 16442.81518822406,
    "itl": 106.52766944472481,
    "ttft": 28658.655823963385,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 409,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2517394872685037,
    "arrivals": 127708,
    "finished_requests": 126744,
    "scheduler_time": 107.95351264280683
}
#Debug simulation 
Total elapsed time: 9.088694577105343. Arrivals time: 0.2599637075327337 Scheduler time: 8.68747279746458 Scheduler overhead time: 0.05348723288625479 Adapter cache time: 0.01094756554812193 Engine time: 0.05261938972398639 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-16/adapters_32_slots_16_rate_3.2-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-16/adapters_32_slots_16_rate_3.2-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 66, 66, 270, 66, 34560, 270, 66, 66, 66, 34560, 34560, 66, 66, 270, 270, 270, 34560, 34560, 66, 34560, 34560, 34560, 34560, 270, 66, 270, 270, 270, 270, 34560]
Prompts retrieved: 383790 . Total input tokens: 85486715 . Total output tokens: 76768251
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 9.062114996369928,
    "estimated_duration": 3600.079818411419,
    "input_throughput": 8674.79571988507,
    "output_throughput": 7768.0566572382795,
    "total_throughput": 16442.85237712335,
    "itl": 106.53983028581688,
    "ttft": 28636.92080551615,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 410,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.335832761570351,
    "arrivals": 127708,
    "finished_requests": 126744,
    "scheduler_time": 107.95456658202185
}
#Debug simulation 
Total elapsed time: 9.062195341102779. Arrivals time: 0.2490382748655975 Scheduler time: 8.671621665824205 Scheduler overhead time: 0.05360422423109412 Adapter cache time: 0.010994902811944485 Engine time: 0.052787155378609896 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-32/adapters_32_slots_16_rate_3.2-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-32/adapters_32_slots_16_rate_3.2-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 66, 66, 270, 66, 34560, 270, 66, 66, 66, 34560, 34560, 66, 66, 270, 270, 270, 34560, 34560, 66, 34560, 34560, 34560, 34560, 270, 66, 270, 270, 270, 270, 34560]
Prompts retrieved: 383790 . Total input tokens: 85486715 . Total output tokens: 76768251
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 9.029461476951838,
    "estimated_duration": 3600.080939179108,
    "input_throughput": 8674.79301927058,
    "output_throughput": 7768.054238907399,
    "total_throughput": 16442.84725817798,
    "itl": 106.53969922720636,
    "ttft": 28665.46358316832,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 410,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.338562304023661,
    "arrivals": 127708,
    "finished_requests": 126744,
    "scheduler_time": 107.9545559745672
}
#Debug simulation 
Total elapsed time: 9.029565792065114. Arrivals time: 0.24492051638662815 Scheduler time: 8.642418985255063 Scheduler overhead time: 0.05367608182132244 Adapter cache time: 0.010964933782815933 Engine time: 0.05324946716427803 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-16/adapters_32_slots_16_rate_3.2-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-16/adapters_32_slots_16_rate_3.2-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 66, 66, 270, 66, 34560, 270, 66, 66, 66, 34560, 34560, 66, 66, 270, 270, 270, 34560, 34560, 66, 34560, 34560, 34560, 34560, 270, 66, 270, 270, 270, 270, 34560]
Prompts retrieved: 383790 . Total input tokens: 85486715 . Total output tokens: 76768251
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 9.085628584958613,
    "estimated_duration": 3600.0751671375224,
    "input_throughput": 8674.806927665191,
    "output_throughput": 7768.0666935173795,
    "total_throughput": 16442.87362118257,
    "itl": 106.53032679496994,
    "ttft": 28604.890190924332,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 409,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.265424483732783,
    "arrivals": 127708,
    "finished_requests": 126744,
    "scheduler_time": 107.9537279015032
}
#Debug simulation 
Total elapsed time: 9.085707132704556. Arrivals time: 0.2501674215309322 Scheduler time: 8.694694234989583 Scheduler overhead time: 0.053276675287634134 Adapter cache time: 0.010934960562735796 Engine time: 0.05244705127552152 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-32/adapters_32_slots_16_rate_3.2-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-32/adapters_32_slots_16_rate_3.2-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 66, 66, 270, 66, 34560, 270, 66, 66, 66, 34560, 34560, 66, 66, 270, 270, 270, 34560, 34560, 66, 34560, 34560, 34560, 34560, 270, 66, 270, 270, 270, 270, 34560]
Prompts retrieved: 383790 . Total input tokens: 85486715 . Total output tokens: 76768251
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 9.06670914683491,
    "estimated_duration": 3600.0837666095567,
    "input_throughput": 8674.786206269686,
    "output_throughput": 7768.048138040167,
    "total_throughput": 16442.834344309853,
    "itl": 106.54284775925473,
    "ttft": 28666.94848937352,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 410,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3593116787821096,
    "arrivals": 127708,
    "finished_requests": 126744,
    "scheduler_time": 107.95505933640028
}
#Debug simulation 
Total elapsed time: 9.066792555619031. Arrivals time: 0.2516165915876627 Scheduler time: 8.673885201103985 Scheduler overhead time: 0.0534280464053154 Adapter cache time: 0.010971648152917624 Engine time: 0.052706376649439335 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-16/adapters_32_slots_16_rate_3.2-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-16/adapters_32_slots_16_rate_3.2-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 66, 66, 270, 66, 34560, 270, 66, 66, 66, 34560, 34560, 66, 66, 270, 270, 270, 34560, 34560, 66, 34560, 34560, 34560, 34560, 270, 66, 270, 270, 270, 270, 34560]
Prompts retrieved: 383790 . Total input tokens: 85486715 . Total output tokens: 76768251
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 9.048166051972657,
    "estimated_duration": 3600.1028138271568,
    "input_throughput": 8674.740310208088,
    "output_throughput": 7768.0070392963635,
    "total_throughput": 16442.74734950445,
    "itl": 106.52497147680879,
    "ttft": 28656.782615204065,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 409,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2229305706149833,
    "arrivals": 127708,
    "finished_requests": 126744,
    "scheduler_time": 107.95397236124634
}
#Debug simulation 
Total elapsed time: 9.048257078975439. Arrivals time: 0.26253067096695304 Scheduler time: 8.644001799169928 Scheduler overhead time: 0.053459486458450556 Adapter cache time: 0.010996094904839993 Engine time: 0.05291076237335801 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-32/adapters_32_slots_16_rate_3.2-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-32/adapters_32_slots_16_rate_3.2-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 66, 66, 270, 66, 34560, 270, 66, 66, 66, 34560, 34560, 66, 66, 270, 270, 270, 34560, 34560, 66, 34560, 34560, 34560, 34560, 270, 66, 270, 270, 270, 270, 34560]
Prompts retrieved: 383790 . Total input tokens: 85486715 . Total output tokens: 76768251
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 9.075051933061332,
    "estimated_duration": 3600.0716373127643,
    "input_throughput": 8674.815433203788,
    "output_throughput": 7768.074310008633,
    "total_throughput": 16442.88974321242,
    "itl": 106.54607060728041,
    "ttft": 28611.960670469147,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 410,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3723900725692528,
    "arrivals": 127708,
    "finished_requests": 126744,
    "scheduler_time": 107.95519192316887
}
#Debug simulation 
Total elapsed time: 9.075139058288187. Arrivals time: 0.2494412432424724 Scheduler time: 8.684754947200418 Scheduler overhead time: 0.053102589212358 Adapter cache time: 0.010986790526658297 Engine time: 0.052489320281893015 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-8/adapters_32_slots_16_rate_3.2-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-8/adapters_32_slots_16_rate_3.2-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 33, 33, 270, 33, 34560, 270, 33, 33, 33, 34560, 34560, 33, 33, 270, 270, 270, 34560, 34560, 33, 34560, 34560, 34560, 34560, 270, 33, 270, 270, 270, 270, 34560]
Prompts retrieved: 383460 . Total input tokens: 85416634 . Total output tokens: 76698531
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 8.945604118984193,
    "estimated_duration": 3600.035482672587,
    "input_throughput": 8694.849023199698,
    "output_throughput": 7738.847890276142,
    "total_throughput": 16433.69691347584,
    "itl": 104.27100380045016,
    "ttft": 27574.035928149788,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 415,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2701024137321009,
    "arrivals": 127594,
    "finished_requests": 126641,
    "scheduler_time": 107.28960872998609
}
#Debug simulation 
Total elapsed time: 8.945704776793718. Arrivals time: 0.2554285512305796 Scheduler time: 8.546796815469861 Scheduler overhead time: 0.054340660106390715 Adapter cache time: 0.01111895451322198 Engine time: 0.05343568976968527 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-16/adapters_32_slots_16_rate_3.2-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-16/adapters_32_slots_16_rate_3.2-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 33, 33, 270, 33, 34560, 270, 33, 33, 33, 34560, 34560, 33, 33, 270, 270, 270, 34560, 34560, 33, 34560, 34560, 34560, 34560, 270, 33, 270, 270, 270, 270, 34560]
Prompts retrieved: 383460 . Total input tokens: 85416634 . Total output tokens: 76698531
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.949251160025597,
    "estimated_duration": 3600.0933112675516,
    "input_throughput": 8694.709357124693,
    "output_throughput": 7738.723580525963,
    "total_throughput": 16433.432937650658,
    "itl": 104.282011938977,
    "ttft": 27636.18640731503,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 413,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3574693673267098,
    "arrivals": 127594,
    "finished_requests": 126641,
    "scheduler_time": 107.29213350485307
}
#Debug simulation 
Total elapsed time: 8.949333522934467. Arrivals time: 0.25593321584165096 Scheduler time: 8.549925269559026 Scheduler overhead time: 0.05408962955698371 Adapter cache time: 0.011095070745795965 Engine time: 0.053723507560789585 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-32/adapters_32_slots_16_rate_3.2-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-32/adapters_32_slots_16_rate_3.2-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 33, 33, 270, 33, 34560, 270, 33, 33, 33, 34560, 34560, 33, 33, 270, 270, 270, 34560, 34560, 33, 34560, 34560, 34560, 34560, 270, 33, 270, 270, 270, 270, 34560]
Prompts retrieved: 383460 . Total input tokens: 85416634 . Total output tokens: 76698531
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.964733727276325,
    "estimated_duration": 3600.0933366244117,
    "input_throughput": 8694.709295884468,
    "output_throughput": 7738.723526019118,
    "total_throughput": 16433.432821903585,
    "itl": 104.2821402564215,
    "ttft": 27636.190263875527,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 413,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.358147532902666,
    "arrivals": 127594,
    "finished_requests": 126641,
    "scheduler_time": 107.29213721728298
}
#Debug simulation 
Total elapsed time: 8.964846696238965. Arrivals time: 0.24871027283370495 Scheduler time: 8.573420484550297 Scheduler overhead time: 0.053911248221993446 Adapter cache time: 0.01103892456740141 Engine time: 0.05325085902586579 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-16/adapters_32_slots_16_rate_3.2-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-16/adapters_32_slots_16_rate_3.2-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 33, 33, 270, 33, 34560, 270, 33, 33, 33, 34560, 34560, 33, 33, 270, 270, 270, 34560, 34560, 33, 34560, 34560, 34560, 34560, 270, 33, 270, 270, 270, 270, 34560]
Prompts retrieved: 383460 . Total input tokens: 85416634 . Total output tokens: 76698531
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 8.979196070227772,
    "estimated_duration": 3600.0343029448313,
    "input_throughput": 8694.851872493306,
    "output_throughput": 7738.850426289103,
    "total_throughput": 16433.70229878241,
    "itl": 104.27057987829821,
    "ttft": 27580.17573441734,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 413,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2794276615045932,
    "arrivals": 127594,
    "finished_requests": 126641,
    "scheduler_time": 107.2896803153585
}
#Debug simulation 
Total elapsed time: 8.979274724144489. Arrivals time: 0.2518231486901641 Scheduler time: 8.584195797331631 Scheduler overhead time: 0.053944322280585766 Adapter cache time: 0.01116872113198042 Engine time: 0.053559056017547846 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-32/adapters_32_slots_16_rate_3.2-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-32/adapters_32_slots_16_rate_3.2-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 33, 33, 270, 33, 34560, 270, 33, 33, 33, 34560, 34560, 33, 33, 270, 270, 270, 34560, 34560, 33, 34560, 34560, 34560, 34560, 270, 33, 270, 270, 270, 270, 34560]
Prompts retrieved: 383460 . Total input tokens: 85416634 . Total output tokens: 76698531
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 8.914931044913828,
    "estimated_duration": 3600.092723758325,
    "input_throughput": 8694.710776038693,
    "output_throughput": 7738.7248434299645,
    "total_throughput": 16433.43561946866,
    "itl": 104.28828652790554,
    "ttft": 27633.047621560905,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 416,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3916343101486597,
    "arrivals": 127594,
    "finished_requests": 126641,
    "scheduler_time": 107.29238920852775
}
#Debug simulation 
Total elapsed time: 8.915011079981923. Arrivals time: 0.2514498536475003 Scheduler time: 8.519923114217818 Scheduler overhead time: 0.05421381210908294 Adapter cache time: 0.011101174633949995 Engine time: 0.053682209458202124 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-16/adapters_32_slots_16_rate_3.2-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-16/adapters_32_slots_16_rate_3.2-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 33, 33, 270, 33, 34560, 270, 33, 33, 33, 34560, 34560, 33, 33, 270, 270, 270, 34560, 34560, 33, 34560, 34560, 34560, 34560, 270, 33, 270, 270, 270, 270, 34560]
Prompts retrieved: 383460 . Total input tokens: 85416634 . Total output tokens: 76698531
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 8.96052018320188,
    "estimated_duration": 3600.0725263273566,
    "input_throughput": 8694.759555839491,
    "output_throughput": 7738.7682598777355,
    "total_throughput": 16433.527815717225,
    "itl": 104.26602198619686,
    "ttft": 27607.579361113923,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 414,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2378808220894937,
    "arrivals": 127594,
    "finished_requests": 126641,
    "scheduler_time": 107.29093388119671
}
#Debug simulation 
Total elapsed time: 8.960599326062948. Arrivals time: 0.2502507376484573 Scheduler time: 8.568011859431863 Scheduler overhead time: 0.05375689873471856 Adapter cache time: 0.01109024928882718 Engine time: 0.052944993134588 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-32/adapters_32_slots_16_rate_3.2-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-32/adapters_32_slots_16_rate_3.2-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 33, 33, 270, 33, 34560, 270, 33, 33, 33, 34560, 34560, 33, 33, 270, 270, 270, 34560, 34560, 33, 34560, 34560, 34560, 34560, 270, 33, 270, 270, 270, 270, 34560]
Prompts retrieved: 383460 . Total input tokens: 85416634 . Total output tokens: 76698531
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.934956932906061,
    "estimated_duration": 3600.027303812329,
    "input_throughput": 8694.868776926302,
    "output_throughput": 7738.865472074864,
    "total_throughput": 16433.734249001165,
    "itl": 104.28961147182623,
    "ttft": 27575.405310931783,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 414,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3989171876758346,
    "arrivals": 127594,
    "finished_requests": 126641,
    "scheduler_time": 107.2904193336025
}
#Debug simulation 
Total elapsed time: 8.935044029261917. Arrivals time: 0.24762251554057002 Scheduler time: 8.543994961772114 Scheduler overhead time: 0.054091832134872675 Adapter cache time: 0.011079255025833845 Engine time: 0.053620561957359314 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-8/adapters_32_slots_16_rate_3.2-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-8/adapters_32_slots_16_rate_3.2-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 135, 66, 66, 135, 66, 34560, 135, 66, 66, 66, 34560, 34560, 66, 66, 135, 135, 135, 34560, 34560, 66, 34560, 34560, 34560, 34560, 135, 66, 135, 135, 135, 135, 34560]
Prompts retrieved: 382305 . Total input tokens: 85170431 . Total output tokens: 76468123
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 8.784592834301293,
    "estimated_duration": 3600.0547369771384,
    "input_throughput": 8679.006093733851,
    "output_throughput": 7690.59334449109,
    "total_throughput": 16369.599438224941,
    "itl": 98.40101245972248,
    "ttft": 23694.53510581957,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 508,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5547277739178569,
    "arrivals": 127174,
    "finished_requests": 126346,
    "scheduler_time": 106.04258860629413
}
#Debug simulation 
Total elapsed time: 8.784676047042012. Arrivals time: 0.24492740165442228 Scheduler time: 8.390567337162793 Scheduler overhead time: 0.05629579396918416 Adapter cache time: 0.011895591858774424 Engine time: 0.0555801996961236 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-16/adapters_32_slots_16_rate_3.2-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-16/adapters_32_slots_16_rate_3.2-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 135, 66, 66, 135, 66, 34560, 135, 66, 66, 66, 34560, 34560, 66, 66, 135, 135, 135, 34560, 34560, 66, 34560, 34560, 34560, 34560, 135, 66, 135, 135, 135, 135, 34560]
Prompts retrieved: 382305 . Total input tokens: 85170431 . Total output tokens: 76468123
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.84076933003962,
    "estimated_duration": 3600.0187357442737,
    "input_throughput": 8679.08899744667,
    "output_throughput": 7690.516086793685,
    "total_throughput": 16369.605084240355,
    "itl": 98.41693298480016,
    "ttft": 23724.05718055685,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 508,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6623625065828735,
    "arrivals": 127174,
    "finished_requests": 126345,
    "scheduler_time": 106.042532941755
}
#Debug simulation 
Total elapsed time: 8.840867895167321. Arrivals time: 0.24818047508597374 Scheduler time: 8.443584808614105 Scheduler overhead time: 0.05618025781586766 Adapter cache time: 0.01195635600015521 Engine time: 0.055648508947342634 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-32/adapters_32_slots_16_rate_3.2-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-32/adapters_32_slots_16_rate_3.2-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 135, 66, 66, 135, 66, 34560, 135, 66, 66, 66, 34560, 34560, 66, 66, 135, 135, 135, 34560, 34560, 66, 34560, 34560, 34560, 34560, 135, 66, 135, 135, 135, 135, 34560]
Prompts retrieved: 382305 . Total input tokens: 85170431 . Total output tokens: 76468123
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.847416962031275,
    "estimated_duration": 3600.0185896654057,
    "input_throughput": 8679.089349620268,
    "output_throughput": 7690.516398853708,
    "total_throughput": 16369.605748473976,
    "itl": 98.41701841898555,
    "ttft": 23723.951900363438,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 508,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6644814457558197,
    "arrivals": 127174,
    "finished_requests": 126345,
    "scheduler_time": 106.0424423197568
}
#Debug simulation 
Total elapsed time: 8.847530995029956. Arrivals time: 0.2412972478196025 Scheduler time: 8.456615699920803 Scheduler overhead time: 0.05616126907989383 Adapter cache time: 0.01199097279459238 Engine time: 0.05606728792190552 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-16/adapters_32_slots_16_rate_3.2-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-16/adapters_32_slots_16_rate_3.2-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 135, 66, 66, 135, 66, 34560, 135, 66, 66, 66, 34560, 34560, 66, 66, 135, 135, 135, 34560, 34560, 66, 34560, 34560, 34560, 34560, 135, 66, 135, 135, 135, 135, 34560]
Prompts retrieved: 382305 . Total input tokens: 85170431 . Total output tokens: 76468123
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 8.757341224234551,
    "estimated_duration": 3600.0552856831396,
    "input_throughput": 8679.004770914518,
    "output_throughput": 7690.592172321668,
    "total_throughput": 16369.596943236187,
    "itl": 98.40324574650427,
    "ttft": 23695.300934972453,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 508,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5761488943919448,
    "arrivals": 127174,
    "finished_requests": 126346,
    "scheduler_time": 106.04275532102899
}
#Debug simulation 
Total elapsed time: 8.757414437830448. Arrivals time: 0.2409078604541719 Scheduler time: 8.365123967640102 Scheduler overhead time: 0.056607394479215145 Adapter cache time: 0.01195419579744339 Engine time: 0.05724571831524372 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-32/adapters_32_slots_16_rate_3.2-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-32/adapters_32_slots_16_rate_3.2-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 135, 66, 66, 135, 66, 34560, 135, 66, 66, 66, 34560, 34560, 66, 66, 135, 135, 135, 34560, 34560, 66, 34560, 34560, 34560, 34560, 135, 66, 135, 135, 135, 135, 34560]
Prompts retrieved: 382305 . Total input tokens: 85170431 . Total output tokens: 76468123
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 8.79092477587983,
    "estimated_duration": 3600.0440126671874,
    "input_throughput": 8679.031947959824,
    "output_throughput": 7690.616254296204,
    "total_throughput": 16369.648202256027,
    "itl": 98.42056876067859,
    "ttft": 23695.667033239824,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 508,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6910154946893488,
    "arrivals": 127174,
    "finished_requests": 126346,
    "scheduler_time": 106.04359501559422
}
#Debug simulation 
Total elapsed time: 8.790999014861882. Arrivals time: 0.23934117145836353 Scheduler time: 8.403674709610641 Scheduler overhead time: 0.05557026341557503 Adapter cache time: 0.011892665643244982 Engine time: 0.055297537706792355 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-16/adapters_32_slots_16_rate_3.2-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-16/adapters_32_slots_16_rate_3.2-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 135, 66, 66, 135, 66, 34560, 135, 66, 66, 66, 34560, 34560, 66, 66, 135, 135, 135, 34560, 34560, 66, 34560, 34560, 34560, 34560, 135, 66, 135, 135, 135, 135, 34560]
Prompts retrieved: 382305 . Total input tokens: 85170431 . Total output tokens: 76468123
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 8.838693171739578,
    "estimated_duration": 3600.029521852249,
    "input_throughput": 8679.06688274162,
    "output_throughput": 7690.647210513708,
    "total_throughput": 16369.714093255327,
    "itl": 98.39410486311456,
    "ttft": 23694.791777652896,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 507,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.515955499515386,
    "arrivals": 127174,
    "finished_requests": 126346,
    "scheduler_time": 106.04159757813594
}
#Debug simulation 
Total elapsed time: 8.83876310987398. Arrivals time: 0.24186678091064095 Scheduler time: 8.448171493131667 Scheduler overhead time: 0.055802291724830866 Adapter cache time: 0.011886605992913246 Engine time: 0.0557117098942399 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-32/adapters_32_slots_16_rate_3.2-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-32/adapters_32_slots_16_rate_3.2-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 135, 66, 66, 135, 66, 34560, 135, 66, 66, 66, 34560, 34560, 66, 66, 135, 135, 135, 34560, 34560, 66, 34560, 34560, 34560, 34560, 135, 66, 135, 135, 135, 135, 34560]
Prompts retrieved: 382305 . Total input tokens: 85170431 . Total output tokens: 76468123
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.826913999859244,
    "estimated_duration": 3600.042876240489,
    "input_throughput": 8679.034687672643,
    "output_throughput": 7690.618681995523,
    "total_throughput": 16369.653369668167,
    "itl": 98.42343550781601,
    "ttft": 23695.508339232438,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 508,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.708621024787424,
    "arrivals": 127174,
    "finished_requests": 126346,
    "scheduler_time": 106.04340267865445
}
#Debug simulation 
Total elapsed time: 8.826983267907053. Arrivals time: 0.24221518030390143 Scheduler time: 8.434649718925357 Scheduler overhead time: 0.05625469470396638 Adapter cache time: 0.011998360510915518 Engine time: 0.05653642304241657 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-8/adapters_32_slots_16_rate_3.2-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-8/adapters_32_slots_16_rate_3.2-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 135, 33, 33, 135, 33, 34560, 135, 33, 33, 33, 34560, 34560, 33, 33, 135, 135, 135, 34560, 34560, 33, 34560, 34560, 34560, 34560, 135, 33, 135, 135, 135, 135, 34560]
Prompts retrieved: 381975 . Total input tokens: 85089706 . Total output tokens: 76410156
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 8.855051573365927,
    "estimated_duration": 3600.079757651382,
    "input_throughput": 8648.898384493838,
    "output_throughput": 7748.329447622535,
    "total_throughput": 16397.227832116372,
    "itl": 99.56633058258677,
    "ttft": 24596.007799391406,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 426,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3037677789153623,
    "arrivals": 127046,
    "finished_requests": 126188,
    "scheduler_time": 106.96982063540302
}
#Debug simulation 
Total elapsed time: 8.855137131176889. Arrivals time: 0.2514861901290715 Scheduler time: 8.458189868368208 Scheduler overhead time: 0.05473187705501914 Adapter cache time: 0.011376227252185345 Engine time: 0.05452735582366586 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-16/adapters_32_slots_16_rate_3.2-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-16/adapters_32_slots_16_rate_3.2-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 135, 33, 33, 135, 33, 34560, 135, 33, 33, 33, 34560, 34560, 33, 33, 135, 135, 135, 34560, 34560, 33, 34560, 34560, 34560, 34560, 135, 33, 135, 135, 135, 135, 34560]
Prompts retrieved: 381975 . Total input tokens: 85089706 . Total output tokens: 76410156
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.862877788953483,
    "estimated_duration": 3600.0969811688983,
    "input_throughput": 8648.857006593851,
    "output_throughput": 7748.292378207832,
    "total_throughput": 16397.149384801683,
    "itl": 99.58142266084138,
    "ttft": 24652.532195828408,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 426,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3955228305235565,
    "arrivals": 127046,
    "finished_requests": 126188,
    "scheduler_time": 106.97134825848129
}
#Debug simulation 
Total elapsed time: 8.862957649864256. Arrivals time: 0.24987345095723867 Scheduler time: 8.467536423355341 Scheduler overhead time: 0.05482469080016017 Adapter cache time: 0.01139179291203618 Engine time: 0.05421198019757867 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-32/adapters_32_slots_16_rate_3.2-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-32/adapters_32_slots_16_rate_3.2-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 135, 33, 33, 135, 33, 34560, 135, 33, 33, 33, 34560, 34560, 33, 33, 135, 135, 135, 34560, 34560, 33, 34560, 34560, 34560, 34560, 135, 33, 135, 135, 135, 135, 34560]
Prompts retrieved: 381975 . Total input tokens: 85089706 . Total output tokens: 76410156
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.857826851774007,
    "estimated_duration": 3600.097589200043,
    "input_throughput": 8648.855545862776,
    "output_throughput": 7748.291069575784,
    "total_throughput": 16397.14661543856,
    "itl": 99.58171149996453,
    "ttft": 24652.56313311019,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 426,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3970387829467736,
    "arrivals": 127046,
    "finished_requests": 126188,
    "scheduler_time": 106.97141557026019
}
#Debug simulation 
Total elapsed time: 8.857946710661054. Arrivals time: 0.24167213309556246 Scheduler time: 8.470012648031116 Scheduler overhead time: 0.05512761604040861 Adapter cache time: 0.011414812877774239 Engine time: 0.05461556138470769 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-16/adapters_32_slots_16_rate_3.2-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-16/adapters_32_slots_16_rate_3.2-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 135, 33, 33, 135, 33, 34560, 135, 33, 33, 33, 34560, 34560, 33, 33, 135, 135, 135, 34560, 34560, 33, 34560, 34560, 34560, 34560, 135, 33, 135, 135, 135, 135, 34560]
Prompts retrieved: 381975 . Total input tokens: 85089706 . Total output tokens: 76410156
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 8.853270814288408,
    "estimated_duration": 3600.0296866991052,
    "input_throughput": 8648.7997904675,
    "output_throughput": 7748.260549922352,
    "total_throughput": 16397.06034038985,
    "itl": 99.56762566282316,
    "ttft": 24710.00405259971,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 426,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.316255338746119,
    "arrivals": 127046,
    "finished_requests": 126184,
    "scheduler_time": 106.96833003224305
}
#Debug simulation 
Total elapsed time: 8.853361445013434. Arrivals time: 0.23897840082645416 Scheduler time: 8.467907776124775 Scheduler overhead time: 0.055111963767558336 Adapter cache time: 0.01145505579188466 Engine time: 0.05474889324977994 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-32/adapters_32_slots_16_rate_3.2-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-32/adapters_32_slots_16_rate_3.2-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 135, 33, 33, 135, 33, 34560, 135, 33, 33, 33, 34560, 34560, 33, 33, 135, 135, 135, 34560, 34560, 33, 34560, 34560, 34560, 34560, 135, 33, 135, 135, 135, 135, 34560]
Prompts retrieved: 381975 . Total input tokens: 85089706 . Total output tokens: 76410156
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 8.830815771128982,
    "estimated_duration": 3600.0026811128514,
    "input_throughput": 8648.741892151935,
    "output_throughput": 7748.2933960975,
    "total_throughput": 16397.035288249434,
    "itl": 99.58508626704618,
    "ttft": 24738.143919524093,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 426,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4214350175112527,
    "arrivals": 127046,
    "finished_requests": 126183,
    "scheduler_time": 106.96859854246436
}
#Debug simulation 
Total elapsed time: 8.830888270866126. Arrivals time: 0.25016596633940935 Scheduler time: 8.435521930456161 Scheduler overhead time: 0.054954893887043 Adapter cache time: 0.011354262940585613 Engine time: 0.054063860792666674 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-16/adapters_32_slots_16_rate_3.2-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-16/adapters_32_slots_16_rate_3.2-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 135, 33, 33, 135, 33, 34560, 135, 33, 33, 33, 34560, 34560, 33, 33, 135, 135, 135, 34560, 34560, 33, 34560, 34560, 34560, 34560, 135, 33, 135, 135, 135, 135, 34560]
Prompts retrieved: 381975 . Total input tokens: 85089706 . Total output tokens: 76410156
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 8.859450358897448,
    "estimated_duration": 3600.0431068738303,
    "input_throughput": 8648.881437155309,
    "output_throughput": 7748.2322216475595,
    "total_throughput": 16397.113658802868,
    "itl": 99.56169777539006,
    "ttft": 24680.69770930501,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 426,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2737614256283185,
    "arrivals": 127046,
    "finished_requests": 126185,
    "scheduler_time": 106.96847385788449
}
#Debug simulation 
Total elapsed time: 8.859520484227687. Arrivals time: 0.23872505640611053 Scheduler time: 8.474734724499285 Scheduler overhead time: 0.055083558429032564 Adapter cache time: 0.011335156857967377 Engine time: 0.05481863161548972 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-32/adapters_32_slots_16_rate_3.2-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-32/adapters_32_slots_16_rate_3.2-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 135, 33, 33, 135, 33, 34560, 135, 33, 33, 33, 34560, 34560, 33, 33, 135, 135, 135, 34560, 34560, 33, 34560, 34560, 34560, 34560, 135, 33, 135, 135, 135, 135, 34560]
Prompts retrieved: 381975 . Total input tokens: 85089706 . Total output tokens: 76410156
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.848693248815835,
    "estimated_duration": 3600.1065470165563,
    "input_throughput": 8649.007353908408,
    "output_throughput": 7748.302067092049,
    "total_throughput": 16397.309421000456,
    "itl": 99.58796333434198,
    "ttft": 24624.679520852093,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 426,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4345134112983953,
    "arrivals": 127046,
    "finished_requests": 126189,
    "scheduler_time": 106.9720282544469
}
#Debug simulation 
Total elapsed time: 8.848761832807213. Arrivals time: 0.2380041591823101 Scheduler time: 8.465316464193165 Scheduler overhead time: 0.054811208974570036 Adapter cache time: 0.011378959752619267 Engine time: 0.054307954385876656 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-8/adapters_32_slots_16_rate_3.2-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-8/adapters_32_slots_16_rate_3.2-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 66, 33, 33, 66, 33, 34560, 66, 33, 33, 33, 34560, 34560, 33, 33, 66, 66, 66, 34560, 34560, 33, 34560, 34560, 34560, 34560, 66, 33, 66, 66, 66, 66, 34560]
Prompts retrieved: 381216 . Total input tokens: 84915272 . Total output tokens: 76248271
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 8.775248602032661,
    "estimated_duration": 3600.0175821400835,
    "input_throughput": 8676.114015374445,
    "output_throughput": 7697.080741346715,
    "total_throughput": 16373.19475672116,
    "itl": 90.45727124218661,
    "ttft": 22391.670838311806,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 283,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8661180315329682,
    "arrivals": 126799,
    "finished_requests": 126014,
    "scheduler_time": 105.51851095566911
}
#Debug simulation 
Total elapsed time: 8.775329647120088. Arrivals time: 0.24104306008666754 Scheduler time: 8.379387252498418 Scheduler overhead time: 0.058492602314800024 Adapter cache time: 0.011399523355066776 Engine time: 0.05832864809781313 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-16/adapters_32_slots_16_rate_3.2-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-16/adapters_32_slots_16_rate_3.2-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 66, 33, 33, 66, 33, 34560, 66, 33, 33, 33, 34560, 34560, 33, 33, 66, 66, 66, 34560, 34560, 33, 34560, 34560, 34560, 34560, 66, 33, 66, 66, 66, 66, 34560]
Prompts retrieved: 381216 . Total input tokens: 84915272 . Total output tokens: 76248271
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.799729575403035,
    "estimated_duration": 3600.081320526946,
    "input_throughput": 8676.006795154342,
    "output_throughput": 7696.956133186492,
    "total_throughput": 16372.962928340834,
    "itl": 90.46610963081476,
    "ttft": 22419.646507326117,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 283,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9238173439609868,
    "arrivals": 126799,
    "finished_requests": 126015,
    "scheduler_time": 105.52128158147715
}
#Debug simulation 
Total elapsed time: 8.799813085235655. Arrivals time: 0.24368277844041586 Scheduler time: 8.401041750330478 Scheduler overhead time: 0.058498109225183725 Adapter cache time: 0.011492751073092222 Engine time: 0.05851096147671342 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-32/adapters_32_slots_16_rate_3.2-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-32/adapters_32_slots_16_rate_3.2-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 66, 33, 33, 66, 33, 34560, 66, 33, 33, 33, 34560, 34560, 33, 33, 66, 66, 66, 34560, 34560, 33, 34560, 34560, 34560, 34560, 66, 33, 66, 66, 66, 66, 34560]
Prompts retrieved: 381216 . Total input tokens: 84915272 . Total output tokens: 76248271
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.770454084966332,
    "estimated_duration": 3600.084078157218,
    "input_throughput": 8676.000149415393,
    "output_throughput": 7696.950237391067,
    "total_throughput": 16372.95038680646,
    "itl": 90.46617765001754,
    "ttft": 22419.63410243597,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 283,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.925392858162527,
    "arrivals": 126799,
    "finished_requests": 126015,
    "scheduler_time": 105.521263353349
}
#Debug simulation 
Total elapsed time: 8.770564868114889. Arrivals time: 0.24054985353723168 Scheduler time: 8.372052912600338 Scheduler overhead time: 0.0605644965544343 Adapter cache time: 0.011400275398045778 Engine time: 0.058836251962929964 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-16/adapters_32_slots_16_rate_3.2-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-16/adapters_32_slots_16_rate_3.2-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 66, 33, 33, 66, 33, 34560, 66, 33, 33, 33, 34560, 34560, 33, 33, 66, 66, 66, 34560, 34560, 33, 34560, 34560, 34560, 34560, 66, 33, 66, 66, 66, 66, 34560]
Prompts retrieved: 381216 . Total input tokens: 84915272 . Total output tokens: 76248271
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 8.786314425058663,
    "estimated_duration": 3600.0035377120166,
    "input_throughput": 8676.147862857624,
    "output_throughput": 7697.110769399649,
    "total_throughput": 16373.258632257273,
    "itl": 90.45926269908159,
    "ttft": 22363.535476526817,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 283,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8727429291559406,
    "arrivals": 126799,
    "finished_requests": 126014,
    "scheduler_time": 105.51854361056174
}
#Debug simulation 
Total elapsed time: 8.78638718323782. Arrivals time: 0.24093817733228207 Scheduler time: 8.390633895527571 Scheduler overhead time: 0.05874603008851409 Adapter cache time: 0.011338388547301292 Engine time: 0.058275409042835236 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-32/adapters_32_slots_16_rate_3.2-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-32/adapters_32_slots_16_rate_3.2-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 66, 33, 33, 66, 33, 34560, 66, 33, 33, 33, 34560, 34560, 33, 33, 66, 66, 66, 34560, 34560, 33, 34560, 34560, 34560, 34560, 66, 33, 66, 66, 66, 66, 34560]
Prompts retrieved: 381216 . Total input tokens: 84915272 . Total output tokens: 76248271
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 8.79384785098955,
    "estimated_duration": 3600.051495710975,
    "input_throughput": 8676.078671988975,
    "output_throughput": 7697.01989902442,
    "total_throughput": 16373.098571013395,
    "itl": 90.46787337551406,
    "ttft": 22363.143692558137,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 283,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.941112081464385,
    "arrivals": 126799,
    "finished_requests": 126015,
    "scheduler_time": 105.52044161123581
}
#Debug simulation 
Total elapsed time: 8.793919523712248. Arrivals time: 0.2411008570343256 Scheduler time: 8.3975923624821 Scheduler overhead time: 0.05882072262465954 Adapter cache time: 0.011343044228851795 Engine time: 0.05840666592121124 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-16/adapters_32_slots_16_rate_3.2-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-16/adapters_32_slots_16_rate_3.2-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 66, 33, 33, 66, 33, 34560, 66, 33, 33, 33, 34560, 34560, 33, 33, 66, 66, 66, 34560, 34560, 33, 34560, 34560, 34560, 34560, 66, 33, 66, 66, 66, 66, 34560]
Prompts retrieved: 381216 . Total input tokens: 84915272 . Total output tokens: 76248271
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 8.741399294231087,
    "estimated_duration": 3600.005552760082,
    "input_throughput": 8676.143006516513,
    "output_throughput": 7697.106461059582,
    "total_throughput": 16373.249467576095,
    "itl": 90.45446612947009,
    "ttft": 22363.635925953175,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 283,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8461842334573169,
    "arrivals": 126799,
    "finished_requests": 126014,
    "scheduler_time": 105.51818124580988
}
#Debug simulation 
Total elapsed time: 8.741470591165125. Arrivals time: 0.241736956872046 Scheduler time: 8.345317007508129 Scheduler overhead time: 0.05836874293163419 Adapter cache time: 0.011276606936007738 Engine time: 0.058125616516917944 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-32/adapters_32_slots_16_rate_3.2-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-32/adapters_32_slots_16_rate_3.2-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 66, 33, 33, 66, 33, 34560, 66, 33, 33, 33, 34560, 34560, 33, 33, 66, 66, 66, 34560, 34560, 33, 34560, 34560, 34560, 34560, 66, 33, 66, 66, 66, 66, 34560]
Prompts retrieved: 381216 . Total input tokens: 84915272 . Total output tokens: 76248271
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.804789821617305,
    "estimated_duration": 3600.0856328756536,
    "input_throughput": 8675.996402633024,
    "output_throughput": 7696.946913417237,
    "total_throughput": 16372.94331605026,
    "itl": 90.46858871777154,
    "ttft": 22419.644003717174,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 283,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9492860775813511,
    "arrivals": 126799,
    "finished_requests": 126015,
    "scheduler_time": 105.52160280187944
}
#Debug simulation 
Total elapsed time: 8.804870896972716. Arrivals time: 0.24185935873538256 Scheduler time: 8.407465615775436 Scheduler overhead time: 0.05865731928497553 Adapter cache time: 0.011410802137106657 Engine time: 0.0587656507268548 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-8/adapters_32_slots_16_rate_1.6-0.8-0.4_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-8/adapters_32_slots_16_rate_1.6-0.8-0.4_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 4320, 4320, 8640, 4320, 17280, 8640, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 8640, 8640, 8640, 17280, 17280, 4320, 17280, 17280, 17280, 17280, 8640, 4320, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 328320 . Total input tokens: 73169787 . Total output tokens: 65646572
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 111.95703966589645,
    "estimated_duration": 3600.044352212307,
    "input_throughput": 6900.249988513206,
    "output_throughput": 6050.818231340326,
    "total_throughput": 12951.06821985353,
    "itl": 79.3874311210083,
    "ttft": 613309.1752250999,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 59,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.18056877689203232,
    "arrivals": 109373,
    "finished_requests": 99970,
    "scheduler_time": 128.63449464248367
}
#Debug simulation 
Total elapsed time: 111.957163636107. Arrivals time: 0.3392695803195238 Scheduler time: 111.32467119116336 Scheduler overhead time: 0.11877896962687373 Adapter cache time: 0.01940527092665434 Engine time: 0.11183368507772684 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-16/adapters_32_slots_16_rate_1.6-0.8-0.4_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-16/adapters_32_slots_16_rate_1.6-0.8-0.4_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 4320, 4320, 8640, 4320, 17280, 8640, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 8640, 8640, 8640, 17280, 17280, 4320, 17280, 17280, 17280, 17280, 8640, 4320, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 328320 . Total input tokens: 73169787 . Total output tokens: 65646572
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 111.64492698200047,
    "estimated_duration": 3600.0880246224856,
    "input_throughput": 6900.166282074426,
    "output_throughput": 6050.744829297401,
    "total_throughput": 12950.911111371826,
    "itl": 79.38861237801085,
    "ttft": 613339.3939439083,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 59,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19316537545528262,
    "arrivals": 109373,
    "finished_requests": 99970,
    "scheduler_time": 128.6352325983778
}
#Debug simulation 
Total elapsed time: 111.6450466690585. Arrivals time: 0.33984389854595065 Scheduler time: 111.01304740738124 Scheduler overhead time: 0.11874398263171315 Adapter cache time: 0.018621913623064756 Engine time: 0.11165508488193154 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-32/adapters_32_slots_16_rate_1.6-0.8-0.4_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-32/adapters_32_slots_16_rate_1.6-0.8-0.4_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 4320, 4320, 8640, 4320, 17280, 8640, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 8640, 8640, 8640, 17280, 17280, 4320, 17280, 17280, 17280, 17280, 8640, 4320, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 328320 . Total input tokens: 73169787 . Total output tokens: 65646572
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 111.09655864117667,
    "estimated_duration": 3600.0882664458723,
    "input_throughput": 6900.165818579796,
    "output_throughput": 6050.744422859698,
    "total_throughput": 12950.910241439493,
    "itl": 79.38859723726048,
    "ttft": 613339.5514308644,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 59,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19339475935325023,
    "arrivals": 109373,
    "finished_requests": 99970,
    "scheduler_time": 128.63524503786743
}
#Debug simulation 
Total elapsed time: 111.09682905813679. Arrivals time: 0.3345140595920384 Scheduler time: 110.4712628973648 Scheduler overhead time: 0.11796429939568043 Adapter cache time: 0.018721775617450476 Engine time: 0.11105546727776527 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-16-16/adapters_32_slots_16_rate_1.6-0.8-0.4_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-16-16/adapters_32_slots_16_rate_1.6-0.8-0.4_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 4320, 4320, 8640, 4320, 17280, 8640, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 8640, 8640, 8640, 17280, 17280, 4320, 17280, 17280, 17280, 17280, 8640, 4320, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 328320 . Total input tokens: 73169787 . Total output tokens: 65646572
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 112.32123189605772,
    "estimated_duration": 3600.076280661221,
    "input_throughput": 6900.188791399011,
    "output_throughput": 6050.764567688301,
    "total_throughput": 12950.953359087312,
    "itl": 79.38840333856655,
    "ttft": 613334.9179482742,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 59,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.18499346908647574,
    "arrivals": 109373,
    "finished_requests": 99970,
    "scheduler_time": 128.63453137813372
}
#Debug simulation 
Total elapsed time: 112.32135165994987. Arrivals time: 0.34120285231620073 Scheduler time: 111.68691365467384 Scheduler overhead time: 0.1183602912351489 Adapter cache time: 0.01949236122891307 Engine time: 0.11111617321148515 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-16-32/adapters_32_slots_16_rate_1.6-0.8-0.4_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-16-32/adapters_32_slots_16_rate_1.6-0.8-0.4_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 4320, 4320, 8640, 4320, 17280, 8640, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 8640, 8640, 8640, 17280, 17280, 4320, 17280, 17280, 17280, 17280, 8640, 4320, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 328320 . Total input tokens: 73169787 . Total output tokens: 65646572
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 110.99294085614383,
    "estimated_duration": 3600.090073548011,
    "input_throughput": 6900.162354970788,
    "output_throughput": 6050.741385626472,
    "total_throughput": 12950.90374059726,
    "itl": 79.38860849017922,
    "ttft": 613340.2564842919,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 59,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19590983508154736,
    "arrivals": 109373,
    "finished_requests": 99970,
    "scheduler_time": 128.63531532328903
}
#Debug simulation 
Total elapsed time: 110.99306881334633. Arrivals time: 0.34143235068768263 Scheduler time: 110.3580181831494 Scheduler overhead time: 0.11883906368166208 Adapter cache time: 0.019274722319096327 Engine time: 0.11196906119585037 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_16-16-16/adapters_32_slots_16_rate_1.6-0.8-0.4_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_16-16-16/adapters_32_slots_16_rate_1.6-0.8-0.4_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 4320, 4320, 8640, 4320, 17280, 8640, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 8640, 8640, 8640, 17280, 17280, 4320, 17280, 17280, 17280, 17280, 8640, 4320, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 328320 . Total input tokens: 73169787 . Total output tokens: 65646572
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 112.89499475201592,
    "estimated_duration": 3600.0397370991755,
    "input_throughput": 6900.258834369545,
    "output_throughput": 6050.825988257669,
    "total_throughput": 12951.084822627216,
    "itl": 79.38739176461938,
    "ttft": 613307.186489342,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 59,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.17641296739922852,
    "arrivals": 109373,
    "finished_requests": 99970,
    "scheduler_time": 128.63421418301317
}
#Debug simulation 
Total elapsed time: 112.89511316083372. Arrivals time: 0.343455171212554 Scheduler time: 112.25530918780714 Scheduler overhead time: 0.11906252522021532 Adapter cache time: 0.019605118315666914 Engine time: 0.11355159897357225 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_16-16-32/adapters_32_slots_16_rate_1.6-0.8-0.4_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_16-16-32/adapters_32_slots_16_rate_1.6-0.8-0.4_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 4320, 4320, 8640, 4320, 17280, 8640, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 8640, 8640, 8640, 17280, 17280, 4320, 17280, 17280, 17280, 17280, 8640, 4320, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 328320 . Total input tokens: 73169787 . Total output tokens: 65646572
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 112.87760726409033,
    "estimated_duration": 3600.032370770294,
    "input_throughput": 6900.830726331588,
    "output_throughput": 6051.1053114055385,
    "total_throughput": 12951.936037737127,
    "itl": 79.39352359278762,
    "ttft": 613111.1029355788,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 59,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.1985506645962594,
    "arrivals": 109373,
    "finished_requests": 99975,
    "scheduler_time": 128.63847129593415
}
#Debug simulation 
Total elapsed time: 112.87772364914417. Arrivals time: 0.3437343635596335 Scheduler time: 112.23747124522924 Scheduler overhead time: 0.11944332532584667 Adapter cache time: 0.01943576568737626 Engine time: 0.11373455123975873 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-8/adapters_32_slots_16_rate_1.6-0.8-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-8/adapters_32_slots_16_rate_1.6-0.8-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 1080, 1080, 8640, 1080, 17280, 8640, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 8640, 8640, 8640, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 8640, 1080, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 295920 . Total input tokens: 66039020 . Total output tokens: 59116830
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 57.45474597485736,
    "estimated_duration": 3600.093278160494,
    "input_throughput": 6458.884313097898,
    "output_throughput": 5643.90292975464,
    "total_throughput": 12102.787242852539,
    "itl": 66.80386593980562,
    "ttft": 324815.50442064204,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 108,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.33053267634473704,
    "arrivals": 98647,
    "finished_requests": 93239,
    "scheduler_time": 93.84521522968068
}
#Debug simulation 
Total elapsed time: 57.45485746208578. Arrivals time: 0.2805837457999587 Scheduler time: 56.89232255658135 Scheduler overhead time: 0.11373251490294933 Adapter cache time: 0.017625534441322088 Engine time: 0.10590772097930312 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-16/adapters_32_slots_16_rate_1.6-0.8-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-16/adapters_32_slots_16_rate_1.6-0.8-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 1080, 1080, 8640, 1080, 17280, 8640, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 8640, 8640, 8640, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 8640, 1080, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 295920 . Total input tokens: 66039020 . Total output tokens: 59116830
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 56.85854070680216,
    "estimated_duration": 3600.002271649671,
    "input_throughput": 6498.31728836102,
    "output_throughput": 5703.156679007224,
    "total_throughput": 12201.473967368243,
    "itl": 66.81925539873423,
    "ttft": 294209.1155871152,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 92,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.30164332282962275,
    "arrivals": 98647,
    "finished_requests": 93837,
    "scheduler_time": 93.65530464014849
}
#Debug simulation 
Total elapsed time: 56.85865592490882. Arrivals time: 0.27560240076854825 Scheduler time: 56.3065262301825 Scheduler overhead time: 0.11053763097152114 Adapter cache time: 0.01707318890839815 Engine time: 0.10419549560174346 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-32/adapters_32_slots_16_rate_1.6-0.8-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-32/adapters_32_slots_16_rate_1.6-0.8-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 1080, 1080, 8640, 1080, 17280, 8640, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 8640, 8640, 8640, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 8640, 1080, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 295920 . Total input tokens: 66039020 . Total output tokens: 59116830
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 57.30396281462163,
    "estimated_duration": 3600.003291883139,
    "input_throughput": 6498.315446751375,
    "output_throughput": 5703.155062744448,
    "total_throughput": 12201.470509495823,
    "itl": 66.81931698607217,
    "ttft": 294209.2100248604,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 92,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3019248212315145,
    "arrivals": 98647,
    "finished_requests": 93837,
    "scheduler_time": 93.65534310515218
}
#Debug simulation 
Total elapsed time: 57.30411035288125. Arrivals time: 0.276263359002769 Scheduler time: 56.75183268589899 Scheduler overhead time: 0.11055101826786995 Adapter cache time: 0.01751330913975835 Engine time: 0.10312101989984512 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-16-16/adapters_32_slots_16_rate_1.6-0.8-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-16-16/adapters_32_slots_16_rate_1.6-0.8-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 1080, 1080, 8640, 1080, 17280, 8640, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 8640, 8640, 8640, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 8640, 1080, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 295920 . Total input tokens: 66039020 . Total output tokens: 59116830
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 57.749586342833936,
    "estimated_duration": 3600.021597343226,
    "input_throughput": 6486.80969504016,
    "output_throughput": 5691.374189288391,
    "total_throughput": 12178.18388432855,
    "itl": 66.56165151163394,
    "ttft": 299137.6032547189,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 90,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.28177098141284673,
    "arrivals": 98647,
    "finished_requests": 93671,
    "scheduler_time": 93.54047983464315
}
#Debug simulation 
Total elapsed time: 57.74970363685861. Arrivals time: 0.28163126250728965 Scheduler time: 57.18886328442022 Scheduler overhead time: 0.11160294152796268 Adapter cache time: 0.01788196573033929 Engine time: 0.10498859966173768 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-16-32/adapters_32_slots_16_rate_1.6-0.8-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-16-32/adapters_32_slots_16_rate_1.6-0.8-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 1080, 1080, 8640, 1080, 17280, 8640, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 8640, 8640, 8640, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 8640, 1080, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 295920 . Total input tokens: 66039020 . Total output tokens: 59116830
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 56.976075541228056,
    "estimated_duration": 3600.0102608790335,
    "input_throughput": 6498.302867138988,
    "output_throughput": 5703.1440224247435,
    "total_throughput": 12201.446889563731,
    "itl": 66.81923901493145,
    "ttft": 294243.91771486634,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 92,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3062004499696195,
    "arrivals": 98647,
    "finished_requests": 93837,
    "scheduler_time": 93.65565032563912
}
#Debug simulation 
Total elapsed time: 56.97619305923581. Arrivals time: 0.27717427536845207 Scheduler time: 56.419848535675555 Scheduler overhead time: 0.111186349298805 Adapter cache time: 0.01676273997873068 Engine time: 0.10655258176848292 
