INFO 06-01 00:47:14 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:47:15 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-16/adapters_256_slots_64_rate_1.6-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-16/adapters_256_slots_64_rate_1.6-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 33, 17280, 17280, 33, 17280, 1080, 17280, 33, 1080, 33, 17280, 1080, 1080, 1080, 1080, 17280, 33, 33, 33, 1080, 17280, 33, 17280, 17280, 1080, 1080, 1080, 33, 17280, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 17280, 1080, 33, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 33, 17280, 17280, 1080, 33, 33, 17280, 1080, 33, 1080, 1080, 17280, 1080, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 17280, 17280, 33, 17280, 33, 1080, 17280, 17280, 17280, 1080, 33, 17280, 1080, 33, 33, 33, 33, 33, 17280, 1080, 33, 17280, 33, 17280, 33, 33, 1080, 1080, 17280, 1080, 17280, 33, 1080, 33, 17280, 17280, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 33, 1080, 17280, 17280, 33, 17280, 1080, 33, 1080, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 1080, 17280, 17280, 1080, 33, 17280, 33, 1080, 1080, 33, 1080, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 17280, 33, 17280, 33, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 1080, 1080, 33, 1080, 17280, 1080, 1080, 17280, 33, 17280, 17280, 1080, 33, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 33, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 17280, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 33, 33, 33, 33]
Prompts retrieved: 1580685 . Total input tokens: 352385458 . Total output tokens: 315982175
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 125.10571351088583,
    "estimated_duration": 3600.1044418617475,
    "input_throughput": 6259.773393781287,
    "output_throughput": 5526.123844815945,
    "total_throughput": 11785.897238597232,
    "itl": 154.55040603796792,
    "ttft": 1930295.7294277677,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 414,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2378808220894937,
    "arrivals": 526966,
    "finished_requests": 91209,
    "scheduler_time": 160.40709607799212
}
#Debug simulation 
Total elapsed time: 125.10594118293375. Arrivals time: 0.7057933378964663 Scheduler time: 124.15973192732781 Scheduler overhead time: 0.09241621382534504 Adapter cache time: 0.02477653045207262 Engine time: 0.09480518056079745 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-32/adapters_256_slots_64_rate_1.6-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-32/adapters_256_slots_64_rate_1.6-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 33, 17280, 17280, 33, 17280, 1080, 17280, 33, 1080, 33, 17280, 1080, 1080, 1080, 1080, 17280, 33, 33, 33, 1080, 17280, 33, 17280, 17280, 1080, 1080, 1080, 33, 17280, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 17280, 1080, 33, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 33, 17280, 17280, 1080, 33, 33, 17280, 1080, 33, 1080, 1080, 17280, 1080, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 17280, 17280, 33, 17280, 33, 1080, 17280, 17280, 17280, 1080, 33, 17280, 1080, 33, 33, 33, 33, 33, 17280, 1080, 33, 17280, 33, 17280, 33, 33, 1080, 1080, 17280, 1080, 17280, 33, 1080, 33, 17280, 17280, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 33, 1080, 17280, 17280, 33, 17280, 1080, 33, 1080, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 1080, 17280, 17280, 1080, 33, 17280, 33, 1080, 1080, 33, 1080, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 17280, 33, 17280, 33, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 1080, 1080, 33, 1080, 17280, 1080, 1080, 17280, 33, 17280, 17280, 1080, 33, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 33, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 17280, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 33, 33, 33, 33]
Prompts retrieved: 1580685 . Total input tokens: 352385458 . Total output tokens: 315982175
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 123.31715365825221,
    "estimated_duration": 3600.058742786307,
    "input_throughput": 6259.5539712107475,
    "output_throughput": 5525.825388227791,
    "total_throughput": 11785.379359438539,
    "itl": 154.55528772884824,
    "ttft": 1930326.7464750991,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 414,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3859531518071906,
    "arrivals": 526966,
    "finished_requests": 91203,
    "scheduler_time": 160.4003557408817
}
#Debug simulation 
Total elapsed time: 123.31735372496769. Arrivals time: 0.7060491680167615 Scheduler time: 122.36850729305297 Scheduler overhead time: 0.09343439433723688 Adapter cache time: 0.024542740546166897 Engine time: 0.09646314801648259 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-8/adapters_256_slots_64_rate_1.6-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-8/adapters_256_slots_64_rate_1.6-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 270, 17280, 17280, 270, 17280, 540, 17280, 270, 540, 270, 17280, 540, 540, 540, 540, 17280, 270, 270, 270, 540, 17280, 270, 17280, 17280, 540, 540, 540, 270, 17280, 270, 540, 540, 270, 540, 270, 270, 540, 540, 17280, 540, 270, 540, 17280, 540, 540, 17280, 540, 17280, 270, 17280, 17280, 540, 270, 270, 17280, 540, 270, 540, 540, 17280, 540, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 17280, 17280, 270, 17280, 270, 540, 17280, 17280, 17280, 540, 270, 17280, 540, 270, 270, 270, 270, 270, 17280, 540, 270, 17280, 270, 17280, 270, 270, 540, 540, 17280, 540, 17280, 270, 540, 270, 17280, 17280, 270, 17280, 540, 270, 17280, 270, 270, 17280, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 270, 540, 17280, 17280, 270, 17280, 540, 270, 540, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 540, 17280, 17280, 540, 270, 17280, 270, 540, 540, 270, 540, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 540, 17280, 540, 17280, 270, 17280, 270, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 540, 540, 270, 540, 17280, 540, 540, 17280, 270, 17280, 17280, 540, 270, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 270, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 17280, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 17280, 540, 270, 270, 270, 270]
Prompts retrieved: 1554930 . Total input tokens: 346648835 . Total output tokens: 310860275
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 125.08808709681034,
    "estimated_duration": 3600.1692196342697,
    "input_throughput": 6255.807887354789,
    "output_throughput": 5534.01459335402,
    "total_throughput": 11789.822480708808,
    "itl": 154.91661638796705,
    "ttft": 1932546.1117268815,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 540,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6526633817237084,
    "arrivals": 518548,
    "finished_requests": 91034,
    "scheduler_time": 160.2976436148478
}
#Debug simulation 
Total elapsed time: 125.08826287975535. Arrivals time: 0.6881345571018755 Scheduler time: 124.160158211831 Scheduler overhead time: 0.09131384827196598 Adapter cache time: 0.025791906286031008 Engine time: 0.09402537904679775 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-16/adapters_256_slots_64_rate_1.6-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-16/adapters_256_slots_64_rate_1.6-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 270, 17280, 17280, 270, 17280, 540, 17280, 270, 540, 270, 17280, 540, 540, 540, 540, 17280, 270, 270, 270, 540, 17280, 270, 17280, 17280, 540, 540, 540, 270, 17280, 270, 540, 540, 270, 540, 270, 270, 540, 540, 17280, 540, 270, 540, 17280, 540, 540, 17280, 540, 17280, 270, 17280, 17280, 540, 270, 270, 17280, 540, 270, 540, 540, 17280, 540, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 17280, 17280, 270, 17280, 270, 540, 17280, 17280, 17280, 540, 270, 17280, 540, 270, 270, 270, 270, 270, 17280, 540, 270, 17280, 270, 17280, 270, 270, 540, 540, 17280, 540, 17280, 270, 540, 270, 17280, 17280, 270, 17280, 540, 270, 17280, 270, 270, 17280, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 270, 540, 17280, 17280, 270, 17280, 540, 270, 540, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 540, 17280, 17280, 540, 270, 17280, 270, 540, 540, 270, 540, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 540, 17280, 540, 17280, 270, 17280, 270, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 540, 540, 270, 540, 17280, 540, 540, 17280, 270, 17280, 17280, 540, 270, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 270, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 17280, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 17280, 540, 270, 270, 270, 270]
Prompts retrieved: 1554930 . Total input tokens: 346648835 . Total output tokens: 310860275
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 124.52203303389251,
    "estimated_duration": 3600.0024109031747,
    "input_throughput": 6257.470253845861,
    "output_throughput": 5532.851572452939,
    "total_throughput": 11790.3218262988,
    "itl": 154.9172721978548,
    "ttft": 1932286.9618191284,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 514,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6782598317600843,
    "arrivals": 518548,
    "finished_requests": 91015,
    "scheduler_time": 160.288279426109
}
#Debug simulation 
Total elapsed time: 124.52222182694823. Arrivals time: 1.006716432981193 Scheduler time: 123.27642915677279 Scheduler overhead time: 0.09227743092924356 Adapter cache time: 0.024608761072158813 Engine time: 0.09344142209738493 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-32/adapters_256_slots_64_rate_1.6-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-32/adapters_256_slots_64_rate_1.6-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 270, 17280, 17280, 270, 17280, 540, 17280, 270, 540, 270, 17280, 540, 540, 540, 540, 17280, 270, 270, 270, 540, 17280, 270, 17280, 17280, 540, 540, 540, 270, 17280, 270, 540, 540, 270, 540, 270, 270, 540, 540, 17280, 540, 270, 540, 17280, 540, 540, 17280, 540, 17280, 270, 17280, 17280, 540, 270, 270, 17280, 540, 270, 540, 540, 17280, 540, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 17280, 17280, 270, 17280, 270, 540, 17280, 17280, 17280, 540, 270, 17280, 540, 270, 270, 270, 270, 270, 17280, 540, 270, 17280, 270, 17280, 270, 270, 540, 540, 17280, 540, 17280, 270, 540, 270, 17280, 17280, 270, 17280, 540, 270, 17280, 270, 270, 17280, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 270, 540, 17280, 17280, 270, 17280, 540, 270, 540, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 540, 17280, 17280, 540, 270, 17280, 270, 540, 540, 270, 540, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 540, 17280, 540, 17280, 270, 17280, 270, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 540, 540, 270, 540, 17280, 540, 540, 17280, 270, 17280, 17280, 540, 270, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 270, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 17280, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 17280, 540, 270, 270, 270, 270]
Prompts retrieved: 1554930 . Total input tokens: 346648835 . Total output tokens: 310860275
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 123.87311131181195,
    "estimated_duration": 3600.009185698372,
    "input_throughput": 6256.06653712772,
    "output_throughput": 5533.976435156019,
    "total_throughput": 11790.04297228374,
    "itl": 154.92396809224294,
    "ttft": 1932417.8046681108,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 541,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7689645376987864,
    "arrivals": 518548,
    "finished_requests": 91029,
    "scheduler_time": 160.28623646708436
}
#Debug simulation 
Total elapsed time: 123.87329480983317. Arrivals time: 0.6934953364543617 Scheduler time: 122.94730443973094 Scheduler overhead time: 0.08813642850145698 Adapter cache time: 0.023761644959449768 Engine time: 0.09266308462247252 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-16-16/adapters_256_slots_64_rate_1.6-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-16-16/adapters_256_slots_64_rate_1.6-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 270, 17280, 17280, 270, 17280, 540, 17280, 270, 540, 270, 17280, 540, 540, 540, 540, 17280, 270, 270, 270, 540, 17280, 270, 17280, 17280, 540, 540, 540, 270, 17280, 270, 540, 540, 270, 540, 270, 270, 540, 540, 17280, 540, 270, 540, 17280, 540, 540, 17280, 540, 17280, 270, 17280, 17280, 540, 270, 270, 17280, 540, 270, 540, 540, 17280, 540, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 17280, 17280, 270, 17280, 270, 540, 17280, 17280, 17280, 540, 270, 17280, 540, 270, 270, 270, 270, 270, 17280, 540, 270, 17280, 270, 17280, 270, 270, 540, 540, 17280, 540, 17280, 270, 540, 270, 17280, 17280, 270, 17280, 540, 270, 17280, 270, 270, 17280, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 270, 540, 17280, 17280, 270, 17280, 540, 270, 540, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 540, 17280, 17280, 540, 270, 17280, 270, 540, 540, 270, 540, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 540, 17280, 540, 17280, 270, 17280, 270, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 540, 540, 270, 540, 17280, 540, 540, 17280, 270, 17280, 17280, 540, 270, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 270, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 17280, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 17280, 540, 270, 270, 270, 270]
Prompts retrieved: 1554930 . Total input tokens: 346648835 . Total output tokens: 310860275
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 120.5640109013766,
    "estimated_duration": 3600.1108114652675,
    "input_throughput": 6257.71877028162,
    "output_throughput": 5533.281069171386,
    "total_throughput": 11790.999839453007,
    "itl": 154.91652276153573,
    "ttft": 1932292.0333935688,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 515,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.613831654512317,
    "arrivals": 518548,
    "finished_requests": 91022,
    "scheduler_time": 160.29455131280696
}
#Debug simulation 
Total elapsed time: 120.56416132021695. Arrivals time: 0.6533835525624454 Scheduler time: 119.68923858180642 Scheduler overhead time: 0.08485879376530647 Adapter cache time: 0.022454005666077137 Engine time: 0.087182960473001 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-16-32/adapters_256_slots_64_rate_1.6-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-16-32/adapters_256_slots_64_rate_1.6-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 270, 17280, 17280, 270, 17280, 540, 17280, 270, 540, 270, 17280, 540, 540, 540, 540, 17280, 270, 270, 270, 540, 17280, 270, 17280, 17280, 540, 540, 540, 270, 17280, 270, 540, 540, 270, 540, 270, 270, 540, 540, 17280, 540, 270, 540, 17280, 540, 540, 17280, 540, 17280, 270, 17280, 17280, 540, 270, 270, 17280, 540, 270, 540, 540, 17280, 540, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 17280, 17280, 270, 17280, 270, 540, 17280, 17280, 17280, 540, 270, 17280, 540, 270, 270, 270, 270, 270, 17280, 540, 270, 17280, 270, 17280, 270, 270, 540, 540, 17280, 540, 17280, 270, 540, 270, 17280, 17280, 270, 17280, 540, 270, 17280, 270, 270, 17280, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 270, 540, 17280, 17280, 270, 17280, 540, 270, 540, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 540, 17280, 17280, 540, 270, 17280, 270, 540, 540, 270, 540, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 540, 17280, 540, 17280, 270, 17280, 270, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 540, 540, 270, 540, 17280, 540, 540, 17280, 270, 17280, 17280, 540, 270, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 270, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 17280, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 17280, 540, 270, 270, 270, 270]
Prompts retrieved: 1554930 . Total input tokens: 346648835 . Total output tokens: 310860275
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 120.0520744570531,
    "estimated_duration": 3600.034521612488,
    "input_throughput": 6256.02250889312,
    "output_throughput": 5533.937488765134,
    "total_throughput": 11789.959997658254,
    "itl": 154.92479037312555,
    "ttft": 1932424.2198734966,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 541,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.790719942748551,
    "arrivals": 518548,
    "finished_requests": 91029,
    "scheduler_time": 160.28646757704988
}
#Debug simulation 
Total elapsed time: 120.0522393360734. Arrivals time: 0.7015569400973618 Scheduler time: 119.12110197218135 Scheduler overhead time: 0.08864585356786847 Adapter cache time: 0.025517158675938845 Engine time: 0.08853234443813562 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_16-16-16/adapters_256_slots_64_rate_1.6-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_16-16-16/adapters_256_slots_64_rate_1.6-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 270, 17280, 17280, 270, 17280, 540, 17280, 270, 540, 270, 17280, 540, 540, 540, 540, 17280, 270, 270, 270, 540, 17280, 270, 17280, 17280, 540, 540, 540, 270, 17280, 270, 540, 540, 270, 540, 270, 270, 540, 540, 17280, 540, 270, 540, 17280, 540, 540, 17280, 540, 17280, 270, 17280, 17280, 540, 270, 270, 17280, 540, 270, 540, 540, 17280, 540, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 17280, 17280, 270, 17280, 270, 540, 17280, 17280, 17280, 540, 270, 17280, 540, 270, 270, 270, 270, 270, 17280, 540, 270, 17280, 270, 17280, 270, 270, 540, 540, 17280, 540, 17280, 270, 540, 270, 17280, 17280, 270, 17280, 540, 270, 17280, 270, 270, 17280, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 270, 540, 17280, 17280, 270, 17280, 540, 270, 540, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 540, 17280, 17280, 540, 270, 17280, 270, 540, 540, 270, 540, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 540, 17280, 540, 17280, 270, 17280, 270, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 540, 540, 270, 540, 17280, 540, 540, 17280, 270, 17280, 17280, 540, 270, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 270, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 17280, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 17280, 540, 270, 270, 270, 270]
Prompts retrieved: 1554930 . Total input tokens: 346648835 . Total output tokens: 310860275
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 121.72630859771743,
    "estimated_duration": 3600.0422867633392,
    "input_throughput": 6256.086791760668,
    "output_throughput": 5534.723598459179,
    "total_throughput": 11790.810390219847,
    "itl": 154.92767060471687,
    "ttft": 1932458.222978624,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 536,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.602666958067546,
    "arrivals": 518548,
    "finished_requests": 91030,
    "scheduler_time": 160.29226562173176
}
#Debug simulation 
Total elapsed time: 121.72646410483867. Arrivals time: 0.6625623623840511 Scheduler time: 120.84317306941375 Scheduler overhead time: 0.08384636463597417 Adapter cache time: 0.022815934382379055 Engine time: 0.08724707458168268 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_16-16-32/adapters_256_slots_64_rate_1.6-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_16-16-32/adapters_256_slots_64_rate_1.6-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 270, 17280, 17280, 270, 17280, 540, 17280, 270, 540, 270, 17280, 540, 540, 540, 540, 17280, 270, 270, 270, 540, 17280, 270, 17280, 17280, 540, 540, 540, 270, 17280, 270, 540, 540, 270, 540, 270, 270, 540, 540, 17280, 540, 270, 540, 17280, 540, 540, 17280, 540, 17280, 270, 17280, 17280, 540, 270, 270, 17280, 540, 270, 540, 540, 17280, 540, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 17280, 17280, 270, 17280, 270, 540, 17280, 17280, 17280, 540, 270, 17280, 540, 270, 270, 270, 270, 270, 17280, 540, 270, 17280, 270, 17280, 270, 270, 540, 540, 17280, 540, 17280, 270, 540, 270, 17280, 17280, 270, 17280, 540, 270, 17280, 270, 270, 17280, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 270, 540, 17280, 17280, 270, 17280, 540, 270, 540, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 540, 17280, 17280, 540, 270, 17280, 270, 540, 540, 270, 540, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 540, 17280, 540, 17280, 270, 17280, 270, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 540, 540, 270, 540, 17280, 540, 540, 17280, 270, 17280, 17280, 540, 270, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 270, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 17280, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 17280, 540, 270, 270, 270, 270]
Prompts retrieved: 1554930 . Total input tokens: 346648835 . Total output tokens: 310860275
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 120.8842780678533,
    "estimated_duration": 3600.0289524838417,
    "input_throughput": 6258.714665184662,
    "output_throughput": 5534.537989271748,
    "total_throughput": 11793.252654456412,
    "itl": 154.92616285824107,
    "ttft": 1932210.4666521256,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 521,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7472607672587013,
    "arrivals": 518548,
    "finished_requests": 91041,
    "scheduler_time": 160.28797527075207
}
#Debug simulation 
Total elapsed time: 120.88444123091176. Arrivals time: 0.8660927945747972 Scheduler time: 119.80139894085005 Scheduler overhead time: 0.08364009112119675 Adapter cache time: 0.022970900870859623 Engine time: 0.08411891805008054 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-8/adapters_256_slots_64_rate_1.6-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-8/adapters_256_slots_64_rate_1.6-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 135, 17280, 17280, 135, 17280, 540, 17280, 135, 540, 135, 17280, 540, 540, 540, 540, 17280, 135, 135, 135, 540, 17280, 135, 17280, 17280, 540, 540, 540, 135, 17280, 135, 540, 540, 135, 540, 135, 135, 540, 540, 17280, 540, 135, 540, 17280, 540, 540, 17280, 540, 17280, 135, 17280, 17280, 540, 135, 135, 17280, 540, 135, 540, 540, 17280, 540, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 17280, 17280, 135, 17280, 135, 540, 17280, 17280, 17280, 540, 135, 17280, 540, 135, 135, 135, 135, 135, 17280, 540, 135, 17280, 135, 17280, 135, 135, 540, 540, 17280, 540, 17280, 135, 540, 135, 17280, 17280, 135, 17280, 540, 135, 17280, 135, 135, 17280, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 135, 540, 17280, 17280, 135, 17280, 540, 135, 540, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 540, 17280, 17280, 540, 135, 17280, 135, 540, 540, 135, 540, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 540, 17280, 540, 17280, 135, 17280, 135, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 540, 540, 135, 540, 17280, 540, 540, 17280, 135, 17280, 17280, 540, 135, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 135, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 17280, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 17280, 540, 135, 135, 135, 135]
Prompts retrieved: 1543455 . Total input tokens: 344115126 . Total output tokens: 308543642
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 123.77472600992769,
    "estimated_duration": 3600.0873022447554,
    "input_throughput": 6256.132173782707,
    "output_throughput": 5530.560324908022,
    "total_throughput": 11786.692498690729,
    "itl": 155.08683801804364,
    "ttft": 1929263.6838656848,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 562,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7199941120902313,
    "arrivals": 514751,
    "finished_requests": 91106,
    "scheduler_time": 160.2118723657397
}
#Debug simulation 
Total elapsed time: 123.77489329408854. Arrivals time: 0.6054622307419777 Scheduler time: 122.94805270200595 Scheduler overhead time: 0.08637533988803625 Adapter cache time: 0.02280562464147806 Engine time: 0.08525075577199459 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-16/adapters_256_slots_64_rate_1.6-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-16/adapters_256_slots_64_rate_1.6-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 135, 17280, 17280, 135, 17280, 540, 17280, 135, 540, 135, 17280, 540, 540, 540, 540, 17280, 135, 135, 135, 540, 17280, 135, 17280, 17280, 540, 540, 540, 135, 17280, 135, 540, 540, 135, 540, 135, 135, 540, 540, 17280, 540, 135, 540, 17280, 540, 540, 17280, 540, 17280, 135, 17280, 17280, 540, 135, 135, 17280, 540, 135, 540, 540, 17280, 540, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 17280, 17280, 135, 17280, 135, 540, 17280, 17280, 17280, 540, 135, 17280, 540, 135, 135, 135, 135, 135, 17280, 540, 135, 17280, 135, 17280, 135, 135, 540, 540, 17280, 540, 17280, 135, 540, 135, 17280, 17280, 135, 17280, 540, 135, 17280, 135, 135, 17280, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 135, 540, 17280, 17280, 135, 17280, 540, 135, 540, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 540, 17280, 17280, 540, 135, 17280, 135, 540, 540, 135, 540, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 540, 17280, 540, 17280, 135, 17280, 135, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 540, 540, 135, 540, 17280, 540, 540, 17280, 135, 17280, 17280, 540, 135, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 135, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 17280, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 17280, 540, 135, 135, 135, 135]
Prompts retrieved: 1543455 . Total input tokens: 344115126 . Total output tokens: 308543642
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 121.84340639505535,
    "estimated_duration": 3600.0795664065977,
    "input_throughput": 6256.2214485945715,
    "output_throughput": 5530.090552935151,
    "total_throughput": 11786.312001529723,
    "itl": 155.08734420011808,
    "ttft": 1929308.7173577219,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 560,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8268342189234734,
    "arrivals": 514751,
    "finished_requests": 91101,
    "scheduler_time": 160.20982136122421
}
#Debug simulation 
Total elapsed time: 121.84356438880786. Arrivals time: 0.6382638500072062 Scheduler time: 120.98343492485583 Scheduler overhead time: 0.08608556212857366 Adapter cache time: 0.02414680039510131 Engine time: 0.08470369316637516 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-32/adapters_256_slots_64_rate_1.6-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-32/adapters_256_slots_64_rate_1.6-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 135, 17280, 17280, 135, 17280, 540, 17280, 135, 540, 135, 17280, 540, 540, 540, 540, 17280, 135, 135, 135, 540, 17280, 135, 17280, 17280, 540, 540, 540, 135, 17280, 135, 540, 540, 135, 540, 135, 135, 540, 540, 17280, 540, 135, 540, 17280, 540, 540, 17280, 540, 17280, 135, 17280, 17280, 540, 135, 135, 17280, 540, 135, 540, 540, 17280, 540, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 17280, 17280, 135, 17280, 135, 540, 17280, 17280, 17280, 540, 135, 17280, 540, 135, 135, 135, 135, 135, 17280, 540, 135, 17280, 135, 17280, 135, 135, 540, 540, 17280, 540, 17280, 135, 540, 135, 17280, 17280, 135, 17280, 540, 135, 17280, 135, 135, 17280, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 135, 540, 17280, 17280, 135, 17280, 540, 135, 540, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 540, 17280, 17280, 540, 135, 17280, 135, 540, 540, 135, 540, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 540, 17280, 540, 17280, 135, 17280, 135, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 540, 540, 135, 540, 17280, 540, 540, 17280, 135, 17280, 17280, 540, 135, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 135, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 17280, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 17280, 540, 135, 135, 135, 135]
Prompts retrieved: 1543455 . Total input tokens: 344115126 . Total output tokens: 308543642
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 122.87322192918509,
    "estimated_duration": 3600.083049593077,
    "input_throughput": 6256.215395515889,
    "output_throughput": 5530.085202409517,
    "total_throughput": 11786.300597925407,
    "itl": 155.08744265375256,
    "ttft": 1929309.3765488048,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 560,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8301638707704955,
    "arrivals": 514751,
    "finished_requests": 91101,
    "scheduler_time": 160.20983565786563
}
#Debug simulation 
Total elapsed time: 122.87337748380378. Arrivals time: 0.61080093216151 Scheduler time: 122.04262033570558 Scheduler overhead time: 0.08454199275001884 Adapter cache time: 0.02349103707820177 Engine time: 0.08475076034665108 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-16/adapters_256_slots_64_rate_1.6-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-16/adapters_256_slots_64_rate_1.6-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 135, 17280, 17280, 135, 17280, 540, 17280, 135, 540, 135, 17280, 540, 540, 540, 540, 17280, 135, 135, 135, 540, 17280, 135, 17280, 17280, 540, 540, 540, 135, 17280, 135, 540, 540, 135, 540, 135, 135, 540, 540, 17280, 540, 135, 540, 17280, 540, 540, 17280, 540, 17280, 135, 17280, 17280, 540, 135, 135, 17280, 540, 135, 540, 540, 17280, 540, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 17280, 17280, 135, 17280, 135, 540, 17280, 17280, 17280, 540, 135, 17280, 540, 135, 135, 135, 135, 135, 17280, 540, 135, 17280, 135, 17280, 135, 135, 540, 540, 17280, 540, 17280, 135, 540, 135, 17280, 17280, 135, 17280, 540, 135, 17280, 135, 135, 17280, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 135, 540, 17280, 17280, 135, 17280, 540, 135, 540, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 540, 17280, 17280, 540, 135, 17280, 135, 540, 540, 135, 540, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 540, 17280, 540, 17280, 135, 17280, 135, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 540, 540, 135, 540, 17280, 540, 540, 17280, 135, 17280, 17280, 540, 135, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 135, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 17280, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 17280, 540, 135, 135, 135, 135]
Prompts retrieved: 1543455 . Total input tokens: 344115126 . Total output tokens: 308543642
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 122.789206514135,
    "estimated_duration": 3600.1252405780942,
    "input_throughput": 6256.066246290755,
    "output_throughput": 5530.502043535254,
    "total_throughput": 11786.56828982601,
    "itl": 155.08816189923135,
    "ttft": 1929268.6522555042,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 562,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7592671621940021,
    "arrivals": 514751,
    "finished_requests": 91106,
    "scheduler_time": 160.2119675942664
}
#Debug simulation 
Total elapsed time: 122.78932638093829. Arrivals time: 0.5865446561947465 Scheduler time: 121.9795166705735 Scheduler overhead time: 0.08732661278918386 Adapter cache time: 0.02341804141178727 Engine time: 0.08600793313235044 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-32/adapters_256_slots_64_rate_1.6-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-32/adapters_256_slots_64_rate_1.6-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 135, 17280, 17280, 135, 17280, 540, 17280, 135, 540, 135, 17280, 540, 540, 540, 540, 17280, 135, 135, 135, 540, 17280, 135, 17280, 17280, 540, 540, 540, 135, 17280, 135, 540, 540, 135, 540, 135, 135, 540, 540, 17280, 540, 135, 540, 17280, 540, 540, 17280, 540, 17280, 135, 17280, 17280, 540, 135, 135, 17280, 540, 135, 540, 540, 17280, 540, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 17280, 17280, 135, 17280, 135, 540, 17280, 17280, 17280, 540, 135, 17280, 540, 135, 135, 135, 135, 135, 17280, 540, 135, 17280, 135, 17280, 135, 135, 540, 540, 17280, 540, 17280, 135, 540, 135, 17280, 17280, 135, 17280, 540, 135, 17280, 135, 135, 17280, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 135, 540, 17280, 17280, 135, 17280, 540, 135, 540, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 540, 17280, 17280, 540, 135, 17280, 135, 540, 540, 135, 540, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 540, 17280, 540, 17280, 135, 17280, 135, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 540, 540, 135, 540, 17280, 540, 540, 17280, 135, 17280, 17280, 540, 135, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 135, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 17280, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 17280, 540, 135, 135, 135, 135]
Prompts retrieved: 1543455 . Total input tokens: 344115126 . Total output tokens: 308543642
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 123.68366443086416,
    "estimated_duration": 3600.1392614366423,
    "input_throughput": 6256.241596335365,
    "output_throughput": 5530.2957897397955,
    "total_throughput": 11786.53738607516,
    "itl": 155.08177697604154,
    "ttft": 1929284.5531683853,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 550,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8196263700164899,
    "arrivals": 514751,
    "finished_requests": 91096,
    "scheduler_time": 160.2154656514121
}
#Debug simulation 
Total elapsed time: 123.68378481594846. Arrivals time: 0.6026938618160784 Scheduler time: 122.85803884733468 Scheduler overhead time: 0.08806388126686215 Adapter cache time: 0.02301168628036976 Engine time: 0.08472901349887252 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-16/adapters_256_slots_64_rate_1.6-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-16/adapters_256_slots_64_rate_1.6-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 135, 17280, 17280, 135, 17280, 540, 17280, 135, 540, 135, 17280, 540, 540, 540, 540, 17280, 135, 135, 135, 540, 17280, 135, 17280, 17280, 540, 540, 540, 135, 17280, 135, 540, 540, 135, 540, 135, 135, 540, 540, 17280, 540, 135, 540, 17280, 540, 540, 17280, 540, 17280, 135, 17280, 17280, 540, 135, 135, 17280, 540, 135, 540, 540, 17280, 540, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 17280, 17280, 135, 17280, 135, 540, 17280, 17280, 17280, 540, 135, 17280, 540, 135, 135, 135, 135, 135, 17280, 540, 135, 17280, 135, 17280, 135, 135, 540, 540, 17280, 540, 17280, 135, 540, 135, 17280, 17280, 135, 17280, 540, 135, 17280, 135, 135, 17280, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 135, 540, 17280, 17280, 135, 17280, 540, 135, 540, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 540, 17280, 17280, 540, 135, 17280, 135, 540, 540, 135, 540, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 540, 17280, 540, 17280, 135, 17280, 135, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 540, 540, 135, 540, 17280, 540, 540, 17280, 135, 17280, 17280, 540, 135, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 135, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 17280, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 17280, 540, 135, 135, 135, 135]
Prompts retrieved: 1543455 . Total input tokens: 344115126 . Total output tokens: 308543642
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 123.66840040776879,
    "estimated_duration": 3600.0484209479523,
    "input_throughput": 6256.199741354984,
    "output_throughput": 5530.620056148366,
    "total_throughput": 11786.81979750335,
    "itl": 155.0857122680752,
    "ttft": 1929256.2985157126,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 562,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.680408265735,
    "arrivals": 514751,
    "finished_requests": 91106,
    "scheduler_time": 160.2116796247966
}
#Debug simulation 
Total elapsed time: 123.66852397378534. Arrivals time: 0.6369924047030509 Scheduler time: 122.81064072437584 Scheduler overhead time: 0.0842001186683774 Adapter cache time: 0.023383483290672302 Engine time: 0.08664107788354158 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-32/adapters_256_slots_64_rate_1.6-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-32/adapters_256_slots_64_rate_1.6-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 135, 17280, 17280, 135, 17280, 540, 17280, 135, 540, 135, 17280, 540, 540, 540, 540, 17280, 135, 135, 135, 540, 17280, 135, 17280, 17280, 540, 540, 540, 135, 17280, 135, 540, 540, 135, 540, 135, 135, 540, 540, 17280, 540, 135, 540, 17280, 540, 540, 17280, 540, 17280, 135, 17280, 17280, 540, 135, 135, 17280, 540, 135, 540, 540, 17280, 540, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 17280, 17280, 135, 17280, 135, 540, 17280, 17280, 17280, 540, 135, 17280, 540, 135, 135, 135, 135, 135, 17280, 540, 135, 17280, 135, 17280, 135, 135, 540, 540, 17280, 540, 17280, 135, 540, 135, 17280, 17280, 135, 17280, 540, 135, 17280, 135, 135, 17280, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 135, 540, 17280, 17280, 135, 17280, 540, 135, 540, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 540, 17280, 17280, 540, 135, 17280, 135, 540, 540, 135, 540, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 540, 17280, 540, 17280, 135, 17280, 135, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 540, 540, 135, 540, 17280, 540, 540, 17280, 135, 17280, 17280, 540, 135, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 135, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 17280, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 17280, 540, 135, 135, 135, 135]
Prompts retrieved: 1543455 . Total input tokens: 344115126 . Total output tokens: 308543642
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 122.58903177827597,
    "estimated_duration": 3600.0441651211386,
    "input_throughput": 6255.934640524657,
    "output_throughput": 5530.439374298635,
    "total_throughput": 11786.374014823292,
    "itl": 155.09402570400349,
    "ttft": 1929264.3472379027,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 562,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8836200720816814,
    "arrivals": 514751,
    "finished_requests": 91102,
    "scheduler_time": 160.20254900797877
}
#Debug simulation 
Total elapsed time: 122.58917706320062. Arrivals time: 0.6470366292633116 Scheduler time: 121.71918485080823 Scheduler overhead time: 0.08695721114054322 Adapter cache time: 0.024747026152908802 Engine time: 0.08371455362066627 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-8/adapters_256_slots_64_rate_1.6-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-8/adapters_256_slots_64_rate_1.6-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 66, 17280, 17280, 66, 17280, 540, 17280, 66, 540, 66, 17280, 540, 540, 540, 540, 17280, 66, 66, 66, 540, 17280, 66, 17280, 17280, 540, 540, 540, 66, 17280, 66, 540, 540, 66, 540, 66, 66, 540, 540, 17280, 540, 66, 540, 17280, 540, 540, 17280, 540, 17280, 66, 17280, 17280, 540, 66, 66, 17280, 540, 66, 540, 540, 17280, 540, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 17280, 17280, 66, 17280, 66, 540, 17280, 17280, 17280, 540, 66, 17280, 540, 66, 66, 66, 66, 66, 17280, 540, 66, 17280, 66, 17280, 66, 66, 540, 540, 17280, 540, 17280, 66, 540, 66, 17280, 17280, 66, 17280, 540, 66, 17280, 66, 66, 17280, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 66, 540, 17280, 17280, 66, 17280, 540, 66, 540, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 540, 17280, 17280, 540, 66, 17280, 66, 540, 540, 66, 540, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 540, 17280, 540, 17280, 66, 17280, 66, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 540, 540, 66, 540, 17280, 540, 540, 17280, 66, 17280, 17280, 540, 66, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 66, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 17280, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 17280, 540, 66, 66, 66, 66]
Prompts retrieved: 1537590 . Total input tokens: 342761459 . Total output tokens: 307388398
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 125.3112272308208,
    "estimated_duration": 3600.0962805761255,
    "input_throughput": 6304.31167145561,
    "output_throughput": 5529.192123943555,
    "total_throughput": 11833.503795399165,
    "itl": 154.3431429281851,
    "ttft": 1931244.5714941935,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 583,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7842643547128214,
    "arrivals": 512803,
    "finished_requests": 91365,
    "scheduler_time": 160.49411906332628
}
#Debug simulation 
Total elapsed time: 125.31137193227187. Arrivals time: 0.6348549397662282 Scheduler time: 124.45431772107258 Scheduler overhead time: 0.08538691466674209 Adapter cache time: 0.024625482503324747 Engine time: 0.08578227832913399 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-16/adapters_256_slots_64_rate_1.6-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-16/adapters_256_slots_64_rate_1.6-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 66, 17280, 17280, 66, 17280, 540, 17280, 66, 540, 66, 17280, 540, 540, 540, 540, 17280, 66, 66, 66, 540, 17280, 66, 17280, 17280, 540, 540, 540, 66, 17280, 66, 540, 540, 66, 540, 66, 66, 540, 540, 17280, 540, 66, 540, 17280, 540, 540, 17280, 540, 17280, 66, 17280, 17280, 540, 66, 66, 17280, 540, 66, 540, 540, 17280, 540, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 17280, 17280, 66, 17280, 66, 540, 17280, 17280, 17280, 540, 66, 17280, 540, 66, 66, 66, 66, 66, 17280, 540, 66, 17280, 66, 17280, 66, 66, 540, 540, 17280, 540, 17280, 66, 540, 66, 17280, 17280, 66, 17280, 540, 66, 17280, 66, 66, 17280, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 66, 540, 17280, 17280, 66, 17280, 540, 66, 540, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 540, 17280, 17280, 540, 66, 17280, 66, 540, 540, 66, 540, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 540, 17280, 540, 17280, 66, 17280, 66, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 540, 540, 66, 540, 17280, 540, 540, 17280, 66, 17280, 17280, 540, 66, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 66, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 17280, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 17280, 540, 66, 66, 66, 66]
Prompts retrieved: 1537590 . Total input tokens: 342761459 . Total output tokens: 307388398
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 125.42129514692351,
    "estimated_duration": 3600.1031150207414,
    "input_throughput": 6303.859993707221,
    "output_throughput": 5529.073297081192,
    "total_throughput": 11832.933290788415,
    "itl": 154.35211039787515,
    "ttft": 1931264.5139801344,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 586,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.906618503183131,
    "arrivals": 512803,
    "finished_requests": 91361,
    "scheduler_time": 160.48810813658739
}
#Debug simulation 
Total elapsed time: 125.42143335519359. Arrivals time: 0.6249220687896013 Scheduler time: 124.5708353924565 Scheduler overhead time: 0.08738583838567138 Adapter cache time: 0.02408616989850998 Engine time: 0.08738289773464203 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-32/adapters_256_slots_64_rate_1.6-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-32/adapters_256_slots_64_rate_1.6-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 66, 17280, 17280, 66, 17280, 540, 17280, 66, 540, 66, 17280, 540, 540, 540, 540, 17280, 66, 66, 66, 540, 17280, 66, 17280, 17280, 540, 540, 540, 66, 17280, 66, 540, 540, 66, 540, 66, 66, 540, 540, 17280, 540, 66, 540, 17280, 540, 540, 17280, 540, 17280, 66, 17280, 17280, 540, 66, 66, 17280, 540, 66, 540, 540, 17280, 540, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 17280, 17280, 66, 17280, 66, 540, 17280, 17280, 17280, 540, 66, 17280, 540, 66, 66, 66, 66, 66, 17280, 540, 66, 17280, 66, 17280, 66, 66, 540, 540, 17280, 540, 17280, 66, 540, 66, 17280, 17280, 66, 17280, 540, 66, 17280, 66, 66, 17280, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 66, 540, 17280, 17280, 66, 17280, 540, 66, 540, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 540, 17280, 17280, 540, 66, 17280, 66, 540, 540, 66, 540, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 540, 17280, 540, 17280, 66, 17280, 66, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 540, 540, 66, 540, 17280, 540, 540, 17280, 66, 17280, 17280, 540, 66, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 66, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 17280, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 17280, 540, 66, 66, 66, 66]
Prompts retrieved: 1537590 . Total input tokens: 342761459 . Total output tokens: 307388398
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 124.80041588144377,
    "estimated_duration": 3600.1086422636963,
    "input_throughput": 6303.8503153977035,
    "output_throughput": 5529.064808300862,
    "total_throughput": 11832.915123698565,
    "itl": 154.3522756400737,
    "ttft": 1931266.0712357832,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 586,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9109815983101843,
    "arrivals": 512803,
    "finished_requests": 91361,
    "scheduler_time": 160.48815559205997
}
#Debug simulation 
Total elapsed time: 124.80055461637676. Arrivals time: 0.6294010449200869 Scheduler time: 123.94680318888277 Scheduler overhead time: 0.08584468299522996 Adapter cache time: 0.02463352493941784 Engine time: 0.08623678144067526 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-16/adapters_256_slots_64_rate_1.6-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-16/adapters_256_slots_64_rate_1.6-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 66, 17280, 17280, 66, 17280, 540, 17280, 66, 540, 66, 17280, 540, 540, 540, 540, 17280, 66, 66, 66, 540, 17280, 66, 17280, 17280, 540, 540, 540, 66, 17280, 66, 540, 540, 66, 540, 66, 66, 540, 540, 17280, 540, 66, 540, 17280, 540, 540, 17280, 540, 17280, 66, 17280, 17280, 540, 66, 66, 17280, 540, 66, 540, 540, 17280, 540, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 17280, 17280, 66, 17280, 66, 540, 17280, 17280, 17280, 540, 66, 17280, 540, 66, 66, 66, 66, 66, 17280, 540, 66, 17280, 66, 17280, 66, 66, 540, 540, 17280, 540, 17280, 66, 540, 66, 17280, 17280, 66, 17280, 540, 66, 17280, 66, 66, 17280, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 66, 540, 17280, 17280, 66, 17280, 540, 66, 540, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 540, 17280, 17280, 540, 66, 17280, 66, 540, 540, 66, 540, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 540, 17280, 540, 17280, 66, 17280, 66, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 540, 540, 66, 540, 17280, 540, 540, 17280, 66, 17280, 17280, 540, 66, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 66, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 17280, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 17280, 540, 66, 66, 66, 66]
Prompts retrieved: 1537590 . Total input tokens: 342761459 . Total output tokens: 307388398
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 125.7382309390232,
    "estimated_duration": 3600.0406146156547,
    "input_throughput": 6304.125266770903,
    "output_throughput": 5529.012067027763,
    "total_throughput": 11833.137333798666,
    "itl": 154.34315038419226,
    "ttft": 1931233.1841204227,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 580,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8171740206866438,
    "arrivals": 512803,
    "finished_requests": 91363,
    "scheduler_time": 160.49055678723857
}
#Debug simulation 
Total elapsed time: 125.7383690951392. Arrivals time: 0.640504589304328 Scheduler time: 124.87022693129256 Scheduler overhead time: 0.08807518240064383 Adapter cache time: 0.02482148539274931 Engine time: 0.08740386599674821 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-32/adapters_256_slots_64_rate_1.6-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-32/adapters_256_slots_64_rate_1.6-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 66, 17280, 17280, 66, 17280, 540, 17280, 66, 540, 66, 17280, 540, 540, 540, 540, 17280, 66, 66, 66, 540, 17280, 66, 17280, 17280, 540, 540, 540, 66, 17280, 66, 540, 540, 66, 540, 66, 66, 540, 540, 17280, 540, 66, 540, 17280, 540, 540, 17280, 540, 17280, 66, 17280, 17280, 540, 66, 66, 17280, 540, 66, 540, 540, 17280, 540, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 17280, 17280, 66, 17280, 66, 540, 17280, 17280, 17280, 540, 66, 17280, 540, 66, 66, 66, 66, 66, 17280, 540, 66, 17280, 66, 17280, 66, 66, 540, 540, 17280, 540, 17280, 66, 540, 66, 17280, 17280, 66, 17280, 540, 66, 17280, 66, 66, 17280, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 66, 540, 17280, 17280, 66, 17280, 540, 66, 540, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 540, 17280, 17280, 540, 66, 17280, 66, 540, 540, 66, 540, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 540, 17280, 540, 17280, 66, 17280, 66, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 540, 540, 66, 540, 17280, 540, 540, 17280, 66, 17280, 17280, 540, 66, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 66, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 17280, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 17280, 540, 66, 66, 66, 66]
Prompts retrieved: 1537590 . Total input tokens: 342761459 . Total output tokens: 307388398
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 124.48803958389908,
    "estimated_duration": 3600.1357597649658,
    "input_throughput": 6303.802832558073,
    "output_throughput": 5529.023161420865,
    "total_throughput": 11832.825993978939,
    "itl": 154.35287149167107,
    "ttft": 1931273.488693178,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 586,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9327370033599485,
    "arrivals": 512803,
    "finished_requests": 91361,
    "scheduler_time": 160.48849138257637
}
#Debug simulation 
Total elapsed time: 124.48817818332464. Arrivals time: 0.637821823824197 Scheduler time: 123.63156291889027 Scheduler overhead time: 0.08357988996431231 Adapter cache time: 0.024115036241710186 Engine time: 0.08505997946485877 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-16/adapters_256_slots_64_rate_1.6-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-16/adapters_256_slots_64_rate_1.6-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 66, 17280, 17280, 66, 17280, 540, 17280, 66, 540, 66, 17280, 540, 540, 540, 540, 17280, 66, 66, 66, 540, 17280, 66, 17280, 17280, 540, 540, 540, 66, 17280, 66, 540, 540, 66, 540, 66, 66, 540, 540, 17280, 540, 66, 540, 17280, 540, 540, 17280, 540, 17280, 66, 17280, 17280, 540, 66, 66, 17280, 540, 66, 540, 540, 17280, 540, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 17280, 17280, 66, 17280, 66, 540, 17280, 17280, 17280, 540, 66, 17280, 540, 66, 66, 66, 66, 66, 17280, 540, 66, 17280, 66, 17280, 66, 66, 540, 540, 17280, 540, 17280, 66, 540, 66, 17280, 17280, 66, 17280, 540, 66, 17280, 66, 66, 17280, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 66, 540, 17280, 17280, 66, 17280, 540, 66, 540, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 540, 17280, 17280, 540, 66, 17280, 66, 540, 540, 66, 540, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 540, 17280, 540, 17280, 66, 17280, 66, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 540, 540, 66, 540, 17280, 540, 540, 17280, 66, 17280, 17280, 540, 66, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 66, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 17280, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 17280, 540, 66, 66, 66, 66]
Prompts retrieved: 1537590 . Total input tokens: 342761459 . Total output tokens: 307388398
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 125.58477173559368,
    "estimated_duration": 3600.054066617757,
    "input_throughput": 6304.385595331618,
    "output_throughput": 5529.256958827091,
    "total_throughput": 11833.642554158709,
    "itl": 154.34197338381517,
    "ttft": 1931236.1978193664,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 583,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7431993219279434,
    "arrivals": 512803,
    "finished_requests": 91365,
    "scheduler_time": 160.4938260455224
}
#Debug simulation 
Total elapsed time: 125.58490351494402. Arrivals time: 0.636923901271075 Scheduler time: 124.72470087138936 Scheduler overhead time: 0.08674421161413193 Adapter cache time: 0.02359463833272457 Engine time: 0.08589144749566913 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-32/adapters_256_slots_64_rate_1.6-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-32/adapters_256_slots_64_rate_1.6-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 66, 17280, 17280, 66, 17280, 540, 17280, 66, 540, 66, 17280, 540, 540, 540, 540, 17280, 66, 66, 66, 540, 17280, 66, 17280, 17280, 540, 540, 540, 66, 17280, 66, 540, 540, 66, 540, 66, 66, 540, 540, 17280, 540, 66, 540, 17280, 540, 540, 17280, 540, 17280, 66, 17280, 17280, 540, 66, 66, 17280, 540, 66, 540, 540, 17280, 540, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 17280, 17280, 66, 17280, 66, 540, 17280, 17280, 17280, 540, 66, 17280, 540, 66, 66, 66, 66, 66, 17280, 540, 66, 17280, 66, 17280, 66, 66, 540, 540, 17280, 540, 17280, 66, 540, 66, 17280, 17280, 66, 17280, 540, 66, 17280, 66, 66, 17280, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 66, 540, 17280, 17280, 66, 17280, 540, 66, 540, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 540, 17280, 17280, 540, 66, 17280, 66, 540, 540, 66, 540, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 540, 17280, 540, 17280, 66, 17280, 66, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 540, 540, 66, 540, 17280, 540, 540, 17280, 66, 17280, 17280, 540, 66, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 66, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 17280, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 17280, 540, 66, 66, 66, 66]
Prompts retrieved: 1537590 . Total input tokens: 342761459 . Total output tokens: 307388398
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 125.45941828284413,
    "estimated_duration": 3600.157329992331,
    "input_throughput": 6303.765063525249,
    "output_throughput": 5528.990034455634,
    "total_throughput": 11832.755097980882,
    "itl": 154.35364861232637,
    "ttft": 1931276.348025742,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 586,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9585165295749856,
    "arrivals": 512803,
    "finished_requests": 91361,
    "scheduler_time": 160.4885180888073
}
#Debug simulation 
Total elapsed time: 125.45955161005259. Arrivals time: 0.6288421703502536 Scheduler time: 124.60549838794395 Scheduler overhead time: 0.0878444048576057 Adapter cache time: 0.024670425802469254 Engine time: 0.08559055998921394 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-8/adapters_256_slots_64_rate_1.6-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-8/adapters_256_slots_64_rate_1.6-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 33, 17280, 17280, 33, 17280, 540, 17280, 33, 540, 33, 17280, 540, 540, 540, 540, 17280, 33, 33, 33, 540, 17280, 33, 17280, 17280, 540, 540, 540, 33, 17280, 33, 540, 540, 33, 540, 33, 33, 540, 540, 17280, 540, 33, 540, 17280, 540, 540, 17280, 540, 17280, 33, 17280, 17280, 540, 33, 33, 17280, 540, 33, 540, 540, 17280, 540, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 17280, 17280, 33, 17280, 33, 540, 17280, 17280, 17280, 540, 33, 17280, 540, 33, 33, 33, 33, 33, 17280, 540, 33, 17280, 33, 17280, 33, 33, 540, 540, 17280, 540, 17280, 33, 540, 33, 17280, 17280, 33, 17280, 540, 33, 17280, 33, 33, 17280, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 33, 540, 17280, 17280, 33, 17280, 540, 33, 540, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 540, 17280, 17280, 540, 33, 17280, 33, 540, 540, 33, 540, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 540, 17280, 540, 17280, 33, 17280, 33, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 540, 540, 33, 540, 17280, 540, 540, 17280, 33, 17280, 17280, 540, 33, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 33, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 17280, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 17280, 540, 33, 33, 33, 33]
Prompts retrieved: 1534785 . Total input tokens: 342133886 . Total output tokens: 306836984
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 128.2385613117367,
    "estimated_duration": 3600.023975339315,
    "input_throughput": 6244.412580024881,
    "output_throughput": 5543.269749507456,
    "total_throughput": 11787.682329532337,
    "itl": 155.23762884807905,
    "ttft": 1929678.9035018897,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 486,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.487397043551334,
    "arrivals": 511802,
    "finished_requests": 90996,
    "scheduler_time": 159.99712797236006
}
#Debug simulation 
Total elapsed time: 128.2386839990504. Arrivals time: 0.6288016131147742 Scheduler time: 127.38491629902273 Scheduler overhead time: 0.08778682490810752 Adapter cache time: 0.022328180260956287 Engine time: 0.08822171483188868 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-16/adapters_256_slots_64_rate_1.6-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-16/adapters_256_slots_64_rate_1.6-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 33, 17280, 17280, 33, 17280, 540, 17280, 33, 540, 33, 17280, 540, 540, 540, 540, 17280, 33, 33, 33, 540, 17280, 33, 17280, 17280, 540, 540, 540, 33, 17280, 33, 540, 540, 33, 540, 33, 33, 540, 540, 17280, 540, 33, 540, 17280, 540, 540, 17280, 540, 17280, 33, 17280, 17280, 540, 33, 33, 17280, 540, 33, 540, 540, 17280, 540, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 17280, 17280, 33, 17280, 33, 540, 17280, 17280, 17280, 540, 33, 17280, 540, 33, 33, 33, 33, 33, 17280, 540, 33, 17280, 33, 17280, 33, 33, 540, 540, 17280, 540, 17280, 33, 540, 33, 17280, 17280, 33, 17280, 540, 33, 17280, 33, 33, 17280, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 33, 540, 17280, 17280, 33, 17280, 540, 33, 540, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 540, 17280, 17280, 540, 33, 17280, 33, 540, 540, 33, 540, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 540, 17280, 540, 17280, 33, 17280, 33, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 540, 540, 33, 540, 17280, 540, 540, 17280, 33, 17280, 17280, 540, 33, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 33, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 17280, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 17280, 540, 33, 33, 33, 33]
Prompts retrieved: 1534785 . Total input tokens: 342133886 . Total output tokens: 306836984
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 127.87003268301487,
    "estimated_duration": 3600.098770805505,
    "input_throughput": 6245.19421031592,
    "output_throughput": 5542.553765972217,
    "total_throughput": 11787.747976288138,
    "itl": 155.2231802361906,
    "ttft": 1929781.0835644314,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 463,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5143265978037441,
    "arrivals": 511802,
    "finished_requests": 91001,
    "scheduler_time": 160.00493501390127
}
#Debug simulation 
Total elapsed time: 127.87027119705454. Arrivals time: 0.6415514913387597 Scheduler time: 127.00830839667469 Scheduler overhead time: 0.08584805252030492 Adapter cache time: 0.02127449307590723 Engine time: 0.08579658856615424 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-32/adapters_256_slots_64_rate_1.6-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-32/adapters_256_slots_64_rate_1.6-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 33, 17280, 17280, 33, 17280, 540, 17280, 33, 540, 33, 17280, 540, 540, 540, 540, 17280, 33, 33, 33, 540, 17280, 33, 17280, 17280, 540, 540, 540, 33, 17280, 33, 540, 540, 33, 540, 33, 33, 540, 540, 17280, 540, 33, 540, 17280, 540, 540, 17280, 540, 17280, 33, 17280, 17280, 540, 33, 33, 17280, 540, 33, 540, 540, 17280, 540, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 17280, 17280, 33, 17280, 33, 540, 17280, 17280, 17280, 540, 33, 17280, 540, 33, 33, 33, 33, 33, 17280, 540, 33, 17280, 33, 17280, 33, 33, 540, 540, 17280, 540, 17280, 33, 540, 33, 17280, 17280, 33, 17280, 540, 33, 17280, 33, 33, 17280, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 33, 540, 17280, 17280, 33, 17280, 540, 33, 540, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 540, 17280, 17280, 540, 33, 17280, 33, 540, 540, 33, 540, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 540, 17280, 540, 17280, 33, 17280, 33, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 540, 540, 33, 540, 17280, 540, 540, 17280, 33, 17280, 17280, 540, 33, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 33, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 17280, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 17280, 540, 33, 33, 33, 33]
Prompts retrieved: 1534785 . Total input tokens: 342133886 . Total output tokens: 306836984
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 128.88241999177262,
    "estimated_duration": 3600.100847749085,
    "input_throughput": 6245.190607384622,
    "output_throughput": 5542.550568403052,
    "total_throughput": 11787.741175787674,
    "itl": 155.22326098156628,
    "ttft": 1929781.5206252034,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 463,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5163939302414746,
    "arrivals": 511802,
    "finished_requests": 91001,
    "scheduler_time": 160.00494462499506
}
#Debug simulation 
Total elapsed time: 128.88254167279229. Arrivals time: 0.9639223013073206 Scheduler time: 127.6938750371337 Scheduler overhead time: 0.08825257699936628 Adapter cache time: 0.02317400136962533 Engine time: 0.08658056380227208 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-16/adapters_256_slots_64_rate_1.6-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-16/adapters_256_slots_64_rate_1.6-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 33, 17280, 17280, 33, 17280, 540, 17280, 33, 540, 33, 17280, 540, 540, 540, 540, 17280, 33, 33, 33, 540, 17280, 33, 17280, 17280, 540, 540, 540, 33, 17280, 33, 540, 540, 33, 540, 33, 33, 540, 540, 17280, 540, 33, 540, 17280, 540, 540, 17280, 540, 17280, 33, 17280, 17280, 540, 33, 33, 17280, 540, 33, 540, 540, 17280, 540, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 17280, 17280, 33, 17280, 33, 540, 17280, 17280, 17280, 540, 33, 17280, 540, 33, 33, 33, 33, 33, 17280, 540, 33, 17280, 33, 17280, 33, 33, 540, 540, 17280, 540, 17280, 33, 540, 33, 17280, 17280, 33, 17280, 540, 33, 17280, 33, 33, 17280, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 33, 540, 17280, 17280, 33, 17280, 540, 33, 540, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 540, 17280, 17280, 540, 33, 17280, 33, 540, 540, 33, 540, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 540, 17280, 540, 17280, 33, 17280, 33, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 540, 540, 33, 540, 17280, 540, 540, 17280, 33, 17280, 17280, 540, 33, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 33, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 17280, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 17280, 540, 33, 33, 33, 33]
Prompts retrieved: 1534785 . Total input tokens: 342133886 . Total output tokens: 306836984
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 127.53896789019927,
    "estimated_duration": 3600.060733585725,
    "input_throughput": 6244.348821751539,
    "output_throughput": 5543.213150219153,
    "total_throughput": 11787.561971970692,
    "itl": 155.2389460227329,
    "ttft": 1929683.6446065928,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 486,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.525894410004836,
    "arrivals": 511802,
    "finished_requests": 90996,
    "scheduler_time": 159.9972128284964
}
#Debug simulation 
Total elapsed time: 127.5391035801731. Arrivals time: 0.9393304460681975 Scheduler time: 126.36996141076088 Scheduler overhead time: 0.0879413541406393 Adapter cache time: 0.023321779910475016 Engine time: 0.08974080765619874 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-32/adapters_256_slots_64_rate_1.6-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-32/adapters_256_slots_64_rate_1.6-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 33, 17280, 17280, 33, 17280, 540, 17280, 33, 540, 33, 17280, 540, 540, 540, 540, 17280, 33, 33, 33, 540, 17280, 33, 17280, 17280, 540, 540, 540, 33, 17280, 33, 540, 540, 33, 540, 33, 33, 540, 540, 17280, 540, 33, 540, 17280, 540, 540, 17280, 540, 17280, 33, 17280, 17280, 540, 33, 33, 17280, 540, 33, 540, 540, 17280, 540, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 17280, 17280, 33, 17280, 33, 540, 17280, 17280, 17280, 540, 33, 17280, 540, 33, 33, 33, 33, 33, 17280, 540, 33, 17280, 33, 17280, 33, 33, 540, 540, 17280, 540, 17280, 33, 540, 33, 17280, 17280, 33, 17280, 540, 33, 17280, 33, 33, 17280, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 33, 540, 17280, 17280, 33, 17280, 540, 33, 540, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 540, 17280, 17280, 540, 33, 17280, 33, 540, 540, 33, 540, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 540, 17280, 540, 17280, 33, 17280, 33, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 540, 540, 33, 540, 17280, 540, 540, 17280, 33, 17280, 17280, 540, 33, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 33, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 17280, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 17280, 540, 33, 33, 33, 33]
Prompts retrieved: 1534785 . Total input tokens: 342133886 . Total output tokens: 306836984
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 129.0744330212474,
    "estimated_duration": 3600.0962524446722,
    "input_throughput": 6244.014721755128,
    "output_throughput": 5542.395425247494,
    "total_throughput": 11786.410147002622,
    "itl": 155.23407600660414,
    "ttft": 1929739.4399605591,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 471,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5618801415339159,
    "arrivals": 511802,
    "finished_requests": 90996,
    "scheduler_time": 159.99912803484108
}
#Debug simulation 
Total elapsed time: 129.07458146801218. Arrivals time: 0.9259174047037959 Scheduler time: 127.92182743828744 Scheduler overhead time: 0.08959972485899925 Adapter cache time: 0.02270151488482952 Engine time: 0.086737637873739 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-16/adapters_256_slots_64_rate_1.6-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-16/adapters_256_slots_64_rate_1.6-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 33, 17280, 17280, 33, 17280, 540, 17280, 33, 540, 33, 17280, 540, 540, 540, 540, 17280, 33, 33, 33, 540, 17280, 33, 17280, 17280, 540, 540, 540, 33, 17280, 33, 540, 540, 33, 540, 33, 33, 540, 540, 17280, 540, 33, 540, 17280, 540, 540, 17280, 540, 17280, 33, 17280, 17280, 540, 33, 33, 17280, 540, 33, 540, 540, 17280, 540, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 17280, 17280, 33, 17280, 33, 540, 17280, 17280, 17280, 540, 33, 17280, 540, 33, 33, 33, 33, 33, 17280, 540, 33, 17280, 33, 17280, 33, 33, 540, 540, 17280, 540, 17280, 33, 540, 33, 17280, 17280, 33, 17280, 540, 33, 17280, 33, 33, 17280, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 33, 540, 17280, 17280, 33, 17280, 540, 33, 540, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 540, 17280, 17280, 540, 33, 17280, 33, 540, 540, 33, 540, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 540, 17280, 540, 17280, 33, 17280, 33, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 540, 540, 33, 540, 17280, 540, 540, 17280, 33, 17280, 17280, 540, 33, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 33, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 17280, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 17280, 540, 33, 33, 33, 33]
Prompts retrieved: 1534785 . Total input tokens: 342133886 . Total output tokens: 306836984
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 126.9180146260187,
    "estimated_duration": 3600.140710227867,
    "input_throughput": 6244.524536535984,
    "output_throughput": 5543.228614177383,
    "total_throughput": 11787.753150713366,
    "itl": 155.23591866728765,
    "ttft": 1929702.6628846198,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 486,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4531644433224427,
    "arrivals": 511802,
    "finished_requests": 91001,
    "scheduler_time": 160.00336419198916
}
#Debug simulation 
Total elapsed time: 126.91814741306007. Arrivals time: 0.9465342569164932 Scheduler time: 125.74682630086318 Scheduler overhead time: 0.08765708236023784 Adapter cache time: 0.022975936997681856 Engine time: 0.08716820413246751 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-32/adapters_256_slots_64_rate_1.6-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-32/adapters_256_slots_64_rate_1.6-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 33, 17280, 17280, 33, 17280, 540, 17280, 33, 540, 33, 17280, 540, 540, 540, 540, 17280, 33, 33, 33, 540, 17280, 33, 17280, 17280, 540, 540, 540, 33, 17280, 33, 540, 540, 33, 540, 33, 33, 540, 540, 17280, 540, 33, 540, 17280, 540, 540, 17280, 540, 17280, 33, 17280, 17280, 540, 33, 33, 17280, 540, 33, 540, 540, 17280, 540, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 17280, 17280, 33, 17280, 33, 540, 17280, 17280, 17280, 540, 33, 17280, 540, 33, 33, 33, 33, 33, 17280, 540, 33, 17280, 33, 17280, 33, 33, 540, 540, 17280, 540, 17280, 33, 540, 33, 17280, 17280, 33, 17280, 540, 33, 17280, 33, 33, 17280, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 33, 540, 17280, 17280, 33, 17280, 540, 33, 540, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 540, 17280, 17280, 540, 33, 17280, 33, 540, 540, 33, 540, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 540, 17280, 540, 17280, 33, 17280, 33, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 540, 540, 33, 540, 17280, 540, 540, 17280, 33, 17280, 17280, 540, 33, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 33, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 17280, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 17280, 540, 33, 33, 33, 33]
Prompts retrieved: 1534785 . Total input tokens: 342133886 . Total output tokens: 306836984
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 129.2011445700191,
    "estimated_duration": 3600.1081887289224,
    "input_throughput": 6243.661807268125,
    "output_throughput": 5542.595653783691,
    "total_throughput": 11786.257461051815,
    "itl": 155.24166675077902,
    "ttft": 1929693.744132466,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 477,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6036229110136615,
    "arrivals": 511802,
    "finished_requests": 90991,
    "scheduler_time": 159.99562625053997
}
#Debug simulation 
Total elapsed time: 129.20125909289345. Arrivals time: 0.6598277729935944 Scheduler time: 128.30886317649856 Scheduler overhead time: 0.08973782742395997 Adapter cache time: 0.023821263574063778 Engine time: 0.09028114378452301 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-8/adapters_256_slots_64_rate_1.6-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-8/adapters_256_slots_64_rate_1.6-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 135, 17280, 17280, 135, 17280, 270, 17280, 135, 270, 135, 17280, 270, 270, 270, 270, 17280, 135, 135, 135, 270, 17280, 135, 17280, 17280, 270, 270, 270, 135, 17280, 135, 270, 270, 135, 270, 135, 135, 270, 270, 17280, 270, 135, 270, 17280, 270, 270, 17280, 270, 17280, 135, 17280, 17280, 270, 135, 135, 17280, 270, 135, 270, 270, 17280, 270, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 17280, 17280, 135, 17280, 135, 270, 17280, 17280, 17280, 270, 135, 17280, 270, 135, 135, 135, 135, 135, 17280, 270, 135, 17280, 135, 17280, 135, 135, 270, 270, 17280, 270, 17280, 135, 270, 135, 17280, 17280, 135, 17280, 270, 135, 17280, 135, 135, 17280, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 135, 270, 17280, 17280, 135, 17280, 270, 135, 270, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 270, 17280, 17280, 270, 135, 17280, 135, 270, 270, 135, 270, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 270, 17280, 270, 135, 270, 17280, 270, 17280, 135, 17280, 135, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 135, 17280, 135, 17280, 270, 270, 135, 270, 17280, 270, 270, 17280, 135, 17280, 17280, 270, 135, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 135, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 17280, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 17280, 270, 135, 135, 135, 135]
Prompts retrieved: 1520505 . Total input tokens: 338953303 . Total output tokens: 303979113
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 129.4301988692023,
    "estimated_duration": 3600.0295029067343,
    "input_throughput": 6273.873584025774,
    "output_throughput": 5532.537715015497,
    "total_throughput": 11806.411299041272,
    "itl": 154.77726620139575,
    "ttft": 1925075.3026874033,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 691,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.11479703105757,
    "arrivals": 507065,
    "finished_requests": 91440,
    "scheduler_time": 160.154647175339
}
#Debug simulation 
Total elapsed time: 129.4303318071179. Arrivals time: 0.7104032156057656 Scheduler time: 128.48914479091763 Scheduler overhead time: 0.08991152746602893 Adapter cache time: 0.02484271675348282 Engine time: 0.08813294628635049 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-16/adapters_256_slots_64_rate_1.6-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-16/adapters_256_slots_64_rate_1.6-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 135, 17280, 17280, 135, 17280, 270, 17280, 135, 270, 135, 17280, 270, 270, 270, 270, 17280, 135, 135, 135, 270, 17280, 135, 17280, 17280, 270, 270, 270, 135, 17280, 135, 270, 270, 135, 270, 135, 135, 270, 270, 17280, 270, 135, 270, 17280, 270, 270, 17280, 270, 17280, 135, 17280, 17280, 270, 135, 135, 17280, 270, 135, 270, 270, 17280, 270, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 17280, 17280, 135, 17280, 135, 270, 17280, 17280, 17280, 270, 135, 17280, 270, 135, 135, 135, 135, 135, 17280, 270, 135, 17280, 135, 17280, 135, 135, 270, 270, 17280, 270, 17280, 135, 270, 135, 17280, 17280, 135, 17280, 270, 135, 17280, 135, 135, 17280, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 135, 270, 17280, 17280, 135, 17280, 270, 135, 270, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 270, 17280, 17280, 270, 135, 17280, 135, 270, 270, 135, 270, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 270, 17280, 270, 135, 270, 17280, 270, 17280, 135, 17280, 135, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 135, 17280, 135, 17280, 270, 270, 135, 270, 17280, 270, 270, 17280, 135, 17280, 17280, 270, 135, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 135, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 17280, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 17280, 270, 135, 135, 135, 135]
Prompts retrieved: 1520505 . Total input tokens: 338953303 . Total output tokens: 303979113
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 129.33667193213478,
    "estimated_duration": 3600.079343397828,
    "input_throughput": 6274.0950533278265,
    "output_throughput": 5532.376400682863,
    "total_throughput": 11806.471454010689,
    "itl": 154.78499558209342,
    "ttft": 1924903.1745520844,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 667,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.173736891495069,
    "arrivals": 507065,
    "finished_requests": 91436,
    "scheduler_time": 160.15441177538582
}
#Debug simulation 
Total elapsed time: 129.3367836792022. Arrivals time: 0.6406626836396754 Scheduler time: 128.46276867063716 Scheduler overhead time: 0.0923639815300703 Adapter cache time: 0.024150417186319828 Engine time: 0.08873871294781566 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-32/adapters_256_slots_64_rate_1.6-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-32/adapters_256_slots_64_rate_1.6-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 135, 17280, 17280, 135, 17280, 270, 17280, 135, 270, 135, 17280, 270, 270, 270, 270, 17280, 135, 135, 135, 270, 17280, 135, 17280, 17280, 270, 270, 270, 135, 17280, 135, 270, 270, 135, 270, 135, 135, 270, 270, 17280, 270, 135, 270, 17280, 270, 270, 17280, 270, 17280, 135, 17280, 17280, 270, 135, 135, 17280, 270, 135, 270, 270, 17280, 270, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 17280, 17280, 135, 17280, 135, 270, 17280, 17280, 17280, 270, 135, 17280, 270, 135, 135, 135, 135, 135, 17280, 270, 135, 17280, 135, 17280, 135, 135, 270, 270, 17280, 270, 17280, 135, 270, 135, 17280, 17280, 135, 17280, 270, 135, 17280, 135, 135, 17280, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 135, 270, 17280, 17280, 135, 17280, 270, 135, 270, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 270, 17280, 17280, 270, 135, 17280, 135, 270, 270, 135, 270, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 270, 17280, 270, 135, 270, 17280, 270, 17280, 135, 17280, 135, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 135, 17280, 135, 17280, 270, 270, 135, 270, 17280, 270, 270, 17280, 135, 17280, 17280, 270, 135, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 135, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 17280, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 17280, 270, 135, 135, 135, 135]
Prompts retrieved: 1520505 . Total input tokens: 338953303 . Total output tokens: 303979113
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 128.56111504603177,
    "estimated_duration": 3600.0841158386957,
    "input_throughput": 6274.086736092262,
    "output_throughput": 5532.369066704439,
    "total_throughput": 11806.455802796701,
    "itl": 154.78518742229048,
    "ttft": 1924902.90675073,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 667,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1780787222273705,
    "arrivals": 507065,
    "finished_requests": 91436,
    "scheduler_time": 160.1545858952526
}
#Debug simulation 
Total elapsed time: 128.56125398166478. Arrivals time: 0.6536970897577703 Scheduler time: 127.67678740480915 Scheduler overhead time: 0.09155016206204891 Adapter cache time: 0.02422928810119629 Engine time: 0.08751164237037301 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-16/adapters_256_slots_64_rate_1.6-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-16/adapters_256_slots_64_rate_1.6-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 135, 17280, 17280, 135, 17280, 270, 17280, 135, 270, 135, 17280, 270, 270, 270, 270, 17280, 135, 135, 135, 270, 17280, 135, 17280, 17280, 270, 270, 270, 135, 17280, 135, 270, 270, 135, 270, 135, 135, 270, 270, 17280, 270, 135, 270, 17280, 270, 270, 17280, 270, 17280, 135, 17280, 17280, 270, 135, 135, 17280, 270, 135, 270, 270, 17280, 270, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 17280, 17280, 135, 17280, 135, 270, 17280, 17280, 17280, 270, 135, 17280, 270, 135, 135, 135, 135, 135, 17280, 270, 135, 17280, 135, 17280, 135, 135, 270, 270, 17280, 270, 17280, 135, 270, 135, 17280, 17280, 135, 17280, 270, 135, 17280, 135, 135, 17280, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 135, 270, 17280, 17280, 135, 17280, 270, 135, 270, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 270, 17280, 17280, 270, 135, 17280, 135, 270, 270, 135, 270, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 270, 17280, 270, 135, 270, 17280, 270, 17280, 135, 17280, 135, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 135, 17280, 135, 17280, 270, 270, 135, 270, 17280, 270, 270, 17280, 135, 17280, 17280, 270, 135, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 135, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 17280, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 17280, 270, 135, 135, 135, 135]
Prompts retrieved: 1520505 . Total input tokens: 338953303 . Total output tokens: 303979113
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 129.04156381404027,
    "estimated_duration": 3600.002345866099,
    "input_throughput": 6272.522579306091,
    "output_throughput": 5531.476673304554,
    "total_throughput": 11803.999252610645,
    "itl": 154.776765382183,
    "ttft": 1924885.540469028,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 644,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.021203694432031,
    "arrivals": 507065,
    "finished_requests": 91422,
    "scheduler_time": 160.15731447873364
}
#Debug simulation 
Total elapsed time: 129.04169261083007. Arrivals time: 0.6556575312279165 Scheduler time: 128.15261619584635 Scheduler overhead time: 0.09075881261378527 Adapter cache time: 0.025295476894825697 Engine time: 0.08908722409978509 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-32/adapters_256_slots_64_rate_1.6-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-32/adapters_256_slots_64_rate_1.6-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 135, 17280, 17280, 135, 17280, 270, 17280, 135, 270, 135, 17280, 270, 270, 270, 270, 17280, 135, 135, 135, 270, 17280, 135, 17280, 17280, 270, 270, 270, 135, 17280, 135, 270, 270, 135, 270, 135, 135, 270, 270, 17280, 270, 135, 270, 17280, 270, 270, 17280, 270, 17280, 135, 17280, 17280, 270, 135, 135, 17280, 270, 135, 270, 270, 17280, 270, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 17280, 17280, 135, 17280, 135, 270, 17280, 17280, 17280, 270, 135, 17280, 270, 135, 135, 135, 135, 135, 17280, 270, 135, 17280, 135, 17280, 135, 135, 270, 270, 17280, 270, 17280, 135, 270, 135, 17280, 17280, 135, 17280, 270, 135, 17280, 135, 135, 17280, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 135, 270, 17280, 17280, 135, 17280, 270, 135, 270, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 270, 17280, 17280, 270, 135, 17280, 135, 270, 270, 135, 270, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 270, 17280, 270, 135, 270, 17280, 270, 17280, 135, 17280, 135, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 135, 17280, 135, 17280, 270, 270, 135, 270, 17280, 270, 270, 17280, 135, 17280, 17280, 270, 135, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 135, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 17280, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 17280, 270, 135, 135, 135, 135]
Prompts retrieved: 1520505 . Total input tokens: 338953303 . Total output tokens: 303979113
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 129.1799278985709,
    "estimated_duration": 3600.1083896517407,
    "input_throughput": 6274.044432919141,
    "output_throughput": 5532.331764579645,
    "total_throughput": 11806.376197498786,
    "itl": 154.7858705088749,
    "ttft": 1924907.2158470955,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 667,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2031037257239254,
    "arrivals": 507065,
    "finished_requests": 91436,
    "scheduler_time": 160.15484435163125
}
#Debug simulation 
Total elapsed time: 129.18004290899262. Arrivals time: 0.6551128616556525 Scheduler time: 128.29029871383682 Scheduler overhead time: 0.09152475465089083 Adapter cache time: 0.02400571061298251 Engine time: 0.09069334762170911 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-16/adapters_256_slots_64_rate_1.6-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-16/adapters_256_slots_64_rate_1.6-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 135, 17280, 17280, 135, 17280, 270, 17280, 135, 270, 135, 17280, 270, 270, 270, 270, 17280, 135, 135, 135, 270, 17280, 135, 17280, 17280, 270, 270, 270, 135, 17280, 135, 270, 270, 135, 270, 135, 135, 270, 270, 17280, 270, 135, 270, 17280, 270, 270, 17280, 270, 17280, 135, 17280, 17280, 270, 135, 135, 17280, 270, 135, 270, 270, 17280, 270, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 17280, 17280, 135, 17280, 135, 270, 17280, 17280, 17280, 270, 135, 17280, 270, 135, 135, 135, 135, 135, 17280, 270, 135, 17280, 135, 17280, 135, 135, 270, 270, 17280, 270, 17280, 135, 270, 135, 17280, 17280, 135, 17280, 270, 135, 17280, 135, 135, 17280, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 135, 270, 17280, 17280, 135, 17280, 270, 135, 270, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 270, 17280, 17280, 270, 135, 17280, 135, 270, 270, 135, 270, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 270, 17280, 270, 135, 270, 17280, 270, 17280, 135, 17280, 135, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 135, 17280, 135, 17280, 270, 270, 135, 270, 17280, 270, 270, 17280, 135, 17280, 17280, 270, 135, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 135, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 17280, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 17280, 270, 135, 135, 135, 135]
Prompts retrieved: 1520505 . Total input tokens: 338953303 . Total output tokens: 303979113
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 130.41706460062414,
    "estimated_duration": 3600.1282066039666,
    "input_throughput": 6274.2157233637645,
    "output_throughput": 5532.736018529005,
    "total_throughput": 11806.95174189277,
    "itl": 154.7743773483078,
    "ttft": 1925143.826235595,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 693,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.072104854367171,
    "arrivals": 507065,
    "finished_requests": 91444,
    "scheduler_time": 160.1613013899261
}
#Debug simulation 
Total elapsed time: 130.41720014391467. Arrivals time: 0.6441198252141476 Scheduler time: 129.54447834892198 Scheduler overhead time: 0.0900427969172597 Adapter cache time: 0.02409858861938119 Engine time: 0.08721328107640147 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-32/adapters_256_slots_64_rate_1.6-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-32/adapters_256_slots_64_rate_1.6-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 135, 17280, 17280, 135, 17280, 270, 17280, 135, 270, 135, 17280, 270, 270, 270, 270, 17280, 135, 135, 135, 270, 17280, 135, 17280, 17280, 270, 270, 270, 135, 17280, 135, 270, 270, 135, 270, 135, 135, 270, 270, 17280, 270, 135, 270, 17280, 270, 270, 17280, 270, 17280, 135, 17280, 17280, 270, 135, 135, 17280, 270, 135, 270, 270, 17280, 270, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 17280, 17280, 135, 17280, 135, 270, 17280, 17280, 17280, 270, 135, 17280, 270, 135, 135, 135, 135, 135, 17280, 270, 135, 17280, 135, 17280, 135, 135, 270, 270, 17280, 270, 17280, 135, 270, 135, 17280, 17280, 135, 17280, 270, 135, 17280, 135, 135, 17280, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 135, 270, 17280, 17280, 135, 17280, 270, 135, 270, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 270, 17280, 17280, 270, 135, 17280, 135, 270, 270, 135, 270, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 270, 17280, 270, 135, 270, 17280, 270, 17280, 135, 17280, 135, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 135, 17280, 135, 17280, 270, 270, 135, 270, 17280, 270, 270, 17280, 135, 17280, 17280, 270, 135, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 135, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 17280, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 17280, 270, 135, 135, 135, 135]
Prompts retrieved: 1520505 . Total input tokens: 338953303 . Total output tokens: 303979113
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 129.8513024081476,
    "estimated_duration": 3600.139778942603,
    "input_throughput": 6273.989730097119,
    "output_throughput": 5532.283528682829,
    "total_throughput": 11806.273258779947,
    "itl": 154.78697918871273,
    "ttft": 1924912.6596488971,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 667,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.233284634463492,
    "arrivals": 507065,
    "finished_requests": 91436,
    "scheduler_time": 160.15496877566787
}
#Debug simulation 
Total elapsed time: 129.8514305902645. Arrivals time: 0.6599997328594327 Scheduler time: 128.95667314203456 Scheduler overhead time: 0.09346958715468645 Adapter cache time: 0.024560575373470783 Engine time: 0.08891477948054671 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-8/adapters_256_slots_64_rate_1.6-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-8/adapters_256_slots_64_rate_1.6-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 66, 17280, 17280, 66, 17280, 270, 17280, 66, 270, 66, 17280, 270, 270, 270, 270, 17280, 66, 66, 66, 270, 17280, 66, 17280, 17280, 270, 270, 270, 66, 17280, 66, 270, 270, 66, 270, 66, 66, 270, 270, 17280, 270, 66, 270, 17280, 270, 270, 17280, 270, 17280, 66, 17280, 17280, 270, 66, 66, 17280, 270, 66, 270, 270, 17280, 270, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 17280, 17280, 66, 17280, 66, 270, 17280, 17280, 17280, 270, 66, 17280, 270, 66, 66, 66, 66, 66, 17280, 270, 66, 17280, 66, 17280, 66, 66, 270, 270, 17280, 270, 17280, 66, 270, 66, 17280, 17280, 66, 17280, 270, 66, 17280, 66, 66, 17280, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 66, 270, 17280, 17280, 66, 17280, 270, 66, 270, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 270, 17280, 17280, 270, 66, 17280, 66, 270, 270, 66, 270, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 270, 17280, 270, 66, 270, 17280, 270, 17280, 66, 17280, 66, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 66, 17280, 66, 17280, 270, 270, 66, 270, 17280, 270, 270, 17280, 66, 17280, 17280, 270, 66, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 66, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 17280, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 17280, 270, 66, 66, 66, 66]
Prompts retrieved: 1514640 . Total input tokens: 337655110 . Total output tokens: 302796901
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 132.21228528907523,
    "estimated_duration": 3600.1055807930034,
    "input_throughput": 6293.865413527385,
    "output_throughput": 5524.371314582156,
    "total_throughput": 11818.23672810954,
    "itl": 154.25246569089003,
    "ttft": 1923976.2701879928,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 742,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.270881905998146,
    "arrivals": 505172,
    "finished_requests": 91125,
    "scheduler_time": 160.48877043968707
}
#Debug simulation 
Total elapsed time: 132.2125073117204. Arrivals time: 0.6886225468479097 Scheduler time: 131.2922858176753 Scheduler overhead time: 0.09132576268166304 Adapter cache time: 0.024276732932776213 Engine time: 0.0880900239571929 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-16/adapters_256_slots_64_rate_1.6-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-16/adapters_256_slots_64_rate_1.6-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 66, 17280, 17280, 66, 17280, 270, 17280, 66, 270, 66, 17280, 270, 270, 270, 270, 17280, 66, 66, 66, 270, 17280, 66, 17280, 17280, 270, 270, 270, 66, 17280, 66, 270, 270, 66, 270, 66, 66, 270, 270, 17280, 270, 66, 270, 17280, 270, 270, 17280, 270, 17280, 66, 17280, 17280, 270, 66, 66, 17280, 270, 66, 270, 270, 17280, 270, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 17280, 17280, 66, 17280, 66, 270, 17280, 17280, 17280, 270, 66, 17280, 270, 66, 66, 66, 66, 66, 17280, 270, 66, 17280, 66, 17280, 66, 66, 270, 270, 17280, 270, 17280, 66, 270, 66, 17280, 17280, 66, 17280, 270, 66, 17280, 66, 66, 17280, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 66, 270, 17280, 17280, 66, 17280, 270, 66, 270, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 270, 17280, 17280, 270, 66, 17280, 66, 270, 270, 66, 270, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 270, 17280, 270, 66, 270, 17280, 270, 17280, 66, 17280, 66, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 66, 17280, 66, 17280, 270, 270, 66, 270, 17280, 270, 270, 17280, 66, 17280, 17280, 270, 66, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 66, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 17280, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 17280, 270, 66, 66, 66, 66]
Prompts retrieved: 1514640 . Total input tokens: 337655110 . Total output tokens: 302796901
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 133.9216814842075,
    "estimated_duration": 3600.0370777290887,
    "input_throughput": 6293.621846331721,
    "output_throughput": 5524.210881890414,
    "total_throughput": 11817.832728222136,
    "itl": 154.25931798900282,
    "ttft": 1923941.2033003995,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 742,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.420872001445393,
    "arrivals": 505172,
    "finished_requests": 91120,
    "scheduler_time": 160.4787982080776
}
#Debug simulation 
Total elapsed time: 133.92180406395346. Arrivals time: 0.6320962263271213 Scheduler time: 133.05368948401883 Scheduler overhead time: 0.09423828544095159 Adapter cache time: 0.02509601227939129 Engine time: 0.08863313961774111 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-32/adapters_256_slots_64_rate_1.6-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-32/adapters_256_slots_64_rate_1.6-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 66, 17280, 17280, 66, 17280, 270, 17280, 66, 270, 66, 17280, 270, 270, 270, 270, 17280, 66, 66, 66, 270, 17280, 66, 17280, 17280, 270, 270, 270, 66, 17280, 66, 270, 270, 66, 270, 66, 66, 270, 270, 17280, 270, 66, 270, 17280, 270, 270, 17280, 270, 17280, 66, 17280, 17280, 270, 66, 66, 17280, 270, 66, 270, 270, 17280, 270, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 17280, 17280, 66, 17280, 66, 270, 17280, 17280, 17280, 270, 66, 17280, 270, 66, 66, 66, 66, 66, 17280, 270, 66, 17280, 66, 17280, 66, 66, 270, 270, 17280, 270, 17280, 66, 270, 66, 17280, 17280, 66, 17280, 270, 66, 17280, 66, 66, 17280, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 66, 270, 17280, 17280, 66, 17280, 270, 66, 270, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 270, 17280, 17280, 270, 66, 17280, 66, 270, 270, 66, 270, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 270, 17280, 270, 66, 270, 17280, 270, 17280, 66, 17280, 66, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 66, 17280, 66, 17280, 270, 270, 66, 270, 17280, 270, 270, 17280, 66, 17280, 17280, 270, 66, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 66, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 17280, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 17280, 270, 66, 66, 66, 66]
Prompts retrieved: 1514640 . Total input tokens: 337655110 . Total output tokens: 302796901
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 131.0861518001184,
    "estimated_duration": 3600.0468479559718,
    "input_throughput": 6293.60476596695,
    "output_throughput": 5524.195889642829,
    "total_throughput": 11817.800655609779,
    "itl": 154.25952022661707,
    "ttft": 1923945.1250950133,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 742,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4252284955792103,
    "arrivals": 505172,
    "finished_requests": 91120,
    "scheduler_time": 160.47900276865138
}
#Debug simulation 
Total elapsed time: 131.08632770599797. Arrivals time: 1.0921735363081098 Scheduler time: 129.76170536642894 Scheduler overhead time: 0.09040485695004463 Adapter cache time: 0.026357303373515606 Engine time: 0.08715125126764178 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-16/adapters_256_slots_64_rate_1.6-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-16/adapters_256_slots_64_rate_1.6-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 66, 17280, 17280, 66, 17280, 270, 17280, 66, 270, 66, 17280, 270, 270, 270, 270, 17280, 66, 66, 66, 270, 17280, 66, 17280, 17280, 270, 270, 270, 66, 17280, 66, 270, 270, 66, 270, 66, 66, 270, 270, 17280, 270, 66, 270, 17280, 270, 270, 17280, 270, 17280, 66, 17280, 17280, 270, 66, 66, 17280, 270, 66, 270, 270, 17280, 270, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 17280, 17280, 66, 17280, 66, 270, 17280, 17280, 17280, 270, 66, 17280, 270, 66, 66, 66, 66, 66, 17280, 270, 66, 17280, 66, 17280, 66, 66, 270, 270, 17280, 270, 17280, 66, 270, 66, 17280, 17280, 66, 17280, 270, 66, 17280, 66, 66, 17280, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 66, 270, 17280, 17280, 66, 17280, 270, 66, 270, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 270, 17280, 17280, 270, 66, 17280, 66, 270, 270, 66, 270, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 270, 17280, 270, 66, 270, 17280, 270, 17280, 66, 17280, 66, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 66, 17280, 66, 17280, 270, 270, 66, 270, 17280, 270, 270, 17280, 66, 17280, 17280, 270, 66, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 66, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 17280, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 17280, 270, 66, 66, 66, 66]
Prompts retrieved: 1514640 . Total input tokens: 337655110 . Total output tokens: 302796901
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 132.3269872381352,
    "estimated_duration": 3600.1624594786654,
    "input_throughput": 6293.765977239027,
    "output_throughput": 5524.284035471,
    "total_throughput": 11818.050012710026,
    "itl": 154.25453286841804,
    "ttft": 1923985.6374026902,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 742,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.324034910975007,
    "arrivals": 505172,
    "finished_requests": 91125,
    "scheduler_time": 160.48903266459337
}
#Debug simulation 
Total elapsed time: 132.32713283924386. Arrivals time: 0.7239004047587514 Scheduler time: 131.3685481576249 Scheduler overhead time: 0.09112729784101248 Adapter cache time: 0.025565175339579582 Engine time: 0.0896814432926476 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-32/adapters_256_slots_64_rate_1.6-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-32/adapters_256_slots_64_rate_1.6-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 66, 17280, 17280, 66, 17280, 270, 17280, 66, 270, 66, 17280, 270, 270, 270, 270, 17280, 66, 66, 66, 270, 17280, 66, 17280, 17280, 270, 270, 270, 66, 17280, 66, 270, 270, 66, 270, 66, 66, 270, 270, 17280, 270, 66, 270, 17280, 270, 270, 17280, 270, 17280, 66, 17280, 17280, 270, 66, 66, 17280, 270, 66, 270, 270, 17280, 270, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 17280, 17280, 66, 17280, 66, 270, 17280, 17280, 17280, 270, 66, 17280, 270, 66, 66, 66, 66, 66, 17280, 270, 66, 17280, 66, 17280, 66, 66, 270, 270, 17280, 270, 17280, 66, 270, 66, 17280, 17280, 66, 17280, 270, 66, 17280, 66, 66, 17280, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 66, 270, 17280, 17280, 66, 17280, 270, 66, 270, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 270, 17280, 17280, 270, 66, 17280, 66, 270, 270, 66, 270, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 270, 17280, 270, 66, 270, 17280, 270, 17280, 66, 17280, 66, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 66, 17280, 66, 17280, 270, 270, 66, 270, 17280, 270, 270, 17280, 66, 17280, 17280, 270, 66, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 66, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 17280, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 17280, 270, 66, 66, 66, 66]
Prompts retrieved: 1514640 . Total input tokens: 337655110 . Total output tokens: 302796901
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 132.05695347487926,
    "estimated_duration": 3600.077929248161,
    "input_throughput": 6293.55043009631,
    "output_throughput": 5524.148196467866,
    "total_throughput": 11817.698626564177,
    "itl": 154.2599046132827,
    "ttft": 1923946.65693131,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 742,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4550321429595354,
    "arrivals": 505172,
    "finished_requests": 91120,
    "scheduler_time": 160.47960402182375
}
#Debug simulation 
Total elapsed time: 132.0571161918342. Arrivals time: 0.6568200881592929 Scheduler time: 131.16541974106804 Scheduler overhead time: 0.0927669177763164 Adapter cache time: 0.025814420077949762 Engine time: 0.08866101782768965 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-16/adapters_256_slots_64_rate_1.6-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-16/adapters_256_slots_64_rate_1.6-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 66, 17280, 17280, 66, 17280, 270, 17280, 66, 270, 66, 17280, 270, 270, 270, 270, 17280, 66, 66, 66, 270, 17280, 66, 17280, 17280, 270, 270, 270, 66, 17280, 66, 270, 270, 66, 270, 66, 66, 270, 270, 17280, 270, 66, 270, 17280, 270, 270, 17280, 270, 17280, 66, 17280, 17280, 270, 66, 66, 17280, 270, 66, 270, 270, 17280, 270, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 17280, 17280, 66, 17280, 66, 270, 17280, 17280, 17280, 270, 66, 17280, 270, 66, 66, 66, 66, 66, 17280, 270, 66, 17280, 66, 17280, 66, 66, 270, 270, 17280, 270, 17280, 66, 270, 66, 17280, 17280, 66, 17280, 270, 66, 17280, 66, 66, 17280, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 66, 270, 17280, 17280, 66, 17280, 270, 66, 270, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 270, 17280, 17280, 270, 66, 17280, 66, 270, 270, 66, 270, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 270, 17280, 270, 66, 270, 17280, 270, 17280, 66, 17280, 66, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 66, 17280, 66, 17280, 270, 270, 66, 270, 17280, 270, 270, 17280, 66, 17280, 17280, 270, 66, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 66, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 17280, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 17280, 270, 66, 66, 66, 66]
Prompts retrieved: 1514640 . Total input tokens: 337655110 . Total output tokens: 302796901
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 131.6438494529575,
    "estimated_duration": 3600.0422698184807,
    "input_throughput": 6293.904988271836,
    "output_throughput": 5524.401245711702,
    "total_throughput": 11818.30623398354,
    "itl": 154.2497165917893,
    "ttft": 1923974.7350423324,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 742,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2186173188173726,
    "arrivals": 505172,
    "finished_requests": 91124,
    "scheduler_time": 160.48755931462168
}
#Debug simulation 
Total elapsed time: 131.64398050587624. Arrivals time: 0.6773316063918173 Scheduler time: 130.73622512631118 Scheduler overhead time: 0.09034337382763624 Adapter cache time: 0.024732934776693583 Engine time: 0.08753183437511325 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-32/adapters_256_slots_64_rate_1.6-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-32/adapters_256_slots_64_rate_1.6-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 66, 17280, 17280, 66, 17280, 270, 17280, 66, 270, 66, 17280, 270, 270, 270, 270, 17280, 66, 66, 66, 270, 17280, 66, 17280, 17280, 270, 270, 270, 66, 17280, 66, 270, 270, 66, 270, 66, 66, 270, 270, 17280, 270, 66, 270, 17280, 270, 270, 17280, 270, 17280, 66, 17280, 17280, 270, 66, 66, 17280, 270, 66, 270, 270, 17280, 270, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 17280, 17280, 66, 17280, 66, 270, 17280, 17280, 17280, 270, 66, 17280, 270, 66, 66, 66, 66, 66, 17280, 270, 66, 17280, 66, 17280, 66, 66, 270, 270, 17280, 270, 17280, 66, 270, 66, 17280, 17280, 66, 17280, 270, 66, 17280, 66, 66, 17280, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 66, 270, 17280, 17280, 66, 17280, 270, 66, 270, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 270, 17280, 17280, 270, 66, 17280, 66, 270, 270, 66, 270, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 270, 17280, 270, 66, 270, 17280, 270, 17280, 66, 17280, 66, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 66, 17280, 66, 17280, 270, 270, 66, 270, 17280, 270, 270, 17280, 66, 17280, 17280, 270, 66, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 66, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 17280, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 17280, 270, 66, 66, 66, 66]
Prompts retrieved: 1514640 . Total input tokens: 337655110 . Total output tokens: 302796901
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 131.71901993872598,
    "estimated_duration": 3600.1129498310734,
    "input_throughput": 6293.489208738059,
    "output_throughput": 5524.094459573322,
    "total_throughput": 11817.58366831138,
    "itl": 154.26108187686776,
    "ttft": 1923952.4507831878,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 742,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4874766198545792,
    "arrivals": 505172,
    "finished_requests": 91120,
    "scheduler_time": 160.4797946429655
}
#Debug simulation 
Total elapsed time: 131.7191427978687. Arrivals time: 0.6433628257364035 Scheduler time: 130.84399052057415 Scheduler overhead time: 0.09061412885785103 Adapter cache time: 0.025075063575059175 Engine time: 0.08811780856922269 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-8/adapters_256_slots_64_rate_1.6-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-8/adapters_256_slots_64_rate_1.6-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 33, 17280, 17280, 33, 17280, 270, 17280, 33, 270, 33, 17280, 270, 270, 270, 270, 17280, 33, 33, 33, 270, 17280, 33, 17280, 17280, 270, 270, 270, 33, 17280, 33, 270, 270, 33, 270, 33, 33, 270, 270, 17280, 270, 33, 270, 17280, 270, 270, 17280, 270, 17280, 33, 17280, 17280, 270, 33, 33, 17280, 270, 33, 270, 270, 17280, 270, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 17280, 17280, 33, 17280, 33, 270, 17280, 17280, 17280, 270, 33, 17280, 270, 33, 33, 33, 33, 33, 17280, 270, 33, 17280, 33, 17280, 33, 33, 270, 270, 17280, 270, 17280, 33, 270, 33, 17280, 17280, 33, 17280, 270, 33, 17280, 33, 33, 17280, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 33, 270, 17280, 17280, 33, 17280, 270, 33, 270, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 270, 17280, 17280, 270, 33, 17280, 33, 270, 270, 33, 270, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 270, 17280, 270, 33, 270, 17280, 270, 17280, 33, 17280, 33, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 33, 17280, 33, 17280, 270, 270, 33, 270, 17280, 270, 270, 17280, 33, 17280, 17280, 270, 33, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 33, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 17280, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 17280, 270, 33, 33, 33, 33]
Prompts retrieved: 1511835 . Total input tokens: 337040131 . Total output tokens: 302236107
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 133.93862350843847,
    "estimated_duration": 3600.082831981072,
    "input_throughput": 6278.254155491841,
    "output_throughput": 5534.107110817929,
    "total_throughput": 11812.36126630977,
    "itl": 154.59478747727547,
    "ttft": 1922574.1426814252,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 709,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1698858104483616,
    "arrivals": 504244,
    "finished_requests": 91415,
    "scheduler_time": 160.150179115447
}
#Debug simulation 
Total elapsed time: 133.93874295428395. Arrivals time: 0.6660425909794867 Scheduler time: 133.038002287969 Scheduler overhead time: 0.09166122460737824 Adapter cache time: 0.025803180877119303 Engine time: 0.08909233938902617 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-16/adapters_256_slots_64_rate_1.6-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-16/adapters_256_slots_64_rate_1.6-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 33, 17280, 17280, 33, 17280, 270, 17280, 33, 270, 33, 17280, 270, 270, 270, 270, 17280, 33, 33, 33, 270, 17280, 33, 17280, 17280, 270, 270, 270, 33, 17280, 33, 270, 270, 33, 270, 33, 33, 270, 270, 17280, 270, 33, 270, 17280, 270, 270, 17280, 270, 17280, 33, 17280, 17280, 270, 33, 33, 17280, 270, 33, 270, 270, 17280, 270, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 17280, 17280, 33, 17280, 33, 270, 17280, 17280, 17280, 270, 33, 17280, 270, 33, 33, 33, 33, 33, 17280, 270, 33, 17280, 33, 17280, 33, 33, 270, 270, 17280, 270, 17280, 33, 270, 33, 17280, 17280, 33, 17280, 270, 33, 17280, 33, 33, 17280, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 33, 270, 17280, 17280, 33, 17280, 270, 33, 270, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 270, 17280, 17280, 270, 33, 17280, 33, 270, 270, 33, 270, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 270, 17280, 270, 33, 270, 17280, 270, 17280, 33, 17280, 33, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 33, 17280, 33, 17280, 270, 270, 33, 270, 17280, 270, 270, 17280, 33, 17280, 17280, 270, 33, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 33, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 17280, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 17280, 270, 33, 33, 33, 33]
Prompts retrieved: 1511835 . Total input tokens: 337040131 . Total output tokens: 302236107
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 132.2111177300103,
    "estimated_duration": 3600.094293046233,
    "input_throughput": 6278.255001169698,
    "output_throughput": 5534.036716338903,
    "total_throughput": 11812.2917175086,
    "itl": 154.59731283440976,
    "ttft": 1922586.7481601946,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 686,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2366767768748153,
    "arrivals": 504244,
    "finished_requests": 91416,
    "scheduler_time": 160.14702746633287
}
#Debug simulation 
Total elapsed time: 132.21123704127967. Arrivals time: 0.6497036442160606 Scheduler time: 131.32963538402691 Scheduler overhead time: 0.0911389528773725 Adapter cache time: 0.024682529270648956 Engine time: 0.08840236393734813 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-32/adapters_256_slots_64_rate_1.6-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-32/adapters_256_slots_64_rate_1.6-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 33, 17280, 17280, 33, 17280, 270, 17280, 33, 270, 33, 17280, 270, 270, 270, 270, 17280, 33, 33, 33, 270, 17280, 33, 17280, 17280, 270, 270, 270, 33, 17280, 33, 270, 270, 33, 270, 33, 33, 270, 270, 17280, 270, 33, 270, 17280, 270, 270, 17280, 270, 17280, 33, 17280, 17280, 270, 33, 33, 17280, 270, 33, 270, 270, 17280, 270, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 17280, 17280, 33, 17280, 33, 270, 17280, 17280, 17280, 270, 33, 17280, 270, 33, 33, 33, 33, 33, 17280, 270, 33, 17280, 33, 17280, 33, 33, 270, 270, 17280, 270, 17280, 33, 270, 33, 17280, 17280, 33, 17280, 270, 33, 17280, 33, 33, 17280, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 33, 270, 17280, 17280, 33, 17280, 270, 33, 270, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 270, 17280, 17280, 270, 33, 17280, 33, 270, 270, 33, 270, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 270, 17280, 270, 33, 270, 17280, 270, 17280, 33, 17280, 33, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 33, 17280, 33, 17280, 270, 270, 33, 270, 17280, 270, 270, 17280, 33, 17280, 17280, 270, 33, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 33, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 17280, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 17280, 270, 33, 33, 33, 33]
Prompts retrieved: 1511835 . Total input tokens: 337040131 . Total output tokens: 302236107
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 133.43659309856594,
    "estimated_duration": 3600.0993913262473,
    "input_throughput": 6278.246110220166,
    "output_throughput": 5534.0288793139425,
    "total_throughput": 11812.27498953411,
    "itl": 154.59743464766575,
    "ttft": 1922588.0496126944,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 686,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2409642927721185,
    "arrivals": 504244,
    "finished_requests": 91416,
    "scheduler_time": 160.14706153784834
}
#Debug simulation 
Total elapsed time: 133.43673702981323. Arrivals time: 0.6391677157953382 Scheduler time: 132.5629637390375 Scheduler overhead time: 0.09271009871736169 Adapter cache time: 0.024825822096318007 Engine time: 0.08876526029780507 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-16/adapters_256_slots_64_rate_1.6-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-16/adapters_256_slots_64_rate_1.6-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 33, 17280, 17280, 33, 17280, 270, 17280, 33, 270, 33, 17280, 270, 270, 270, 270, 17280, 33, 33, 33, 270, 17280, 33, 17280, 17280, 270, 270, 270, 33, 17280, 33, 270, 270, 33, 270, 33, 33, 270, 270, 17280, 270, 33, 270, 17280, 270, 270, 17280, 270, 17280, 33, 17280, 17280, 270, 33, 33, 17280, 270, 33, 270, 270, 17280, 270, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 17280, 17280, 33, 17280, 33, 270, 17280, 17280, 17280, 270, 33, 17280, 270, 33, 33, 33, 33, 33, 17280, 270, 33, 17280, 33, 17280, 33, 33, 270, 270, 17280, 270, 17280, 33, 270, 33, 17280, 17280, 33, 17280, 270, 33, 17280, 33, 33, 17280, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 33, 270, 17280, 17280, 33, 17280, 270, 33, 270, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 270, 17280, 17280, 270, 33, 17280, 33, 270, 270, 33, 270, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 270, 17280, 270, 33, 270, 17280, 270, 17280, 33, 17280, 33, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 33, 17280, 33, 17280, 270, 270, 33, 270, 17280, 270, 270, 17280, 33, 17280, 17280, 270, 33, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 33, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 17280, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 17280, 270, 33, 33, 33, 33]
Prompts retrieved: 1511835 . Total input tokens: 337040131 . Total output tokens: 302236107
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 132.56844836985692,
    "estimated_duration": 3600.1403928090963,
    "input_throughput": 6278.153775654305,
    "output_throughput": 5534.018628771976,
    "total_throughput": 11812.172404426281,
    "itl": 154.59703114995145,
    "ttft": 1922581.5414275324,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 709,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2269976325170004,
    "arrivals": 504244,
    "finished_requests": 91415,
    "scheduler_time": 160.1503232416679
}
#Debug simulation 
Total elapsed time: 132.56856814026833. Arrivals time: 0.6769918915815651 Scheduler time: 131.65853427443653 Scheduler overhead time: 0.09179095271974802 Adapter cache time: 0.025001803413033485 Engine time: 0.08822317095473409 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-32/adapters_256_slots_64_rate_1.6-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-32/adapters_256_slots_64_rate_1.6-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 33, 17280, 17280, 33, 17280, 270, 17280, 33, 270, 33, 17280, 270, 270, 270, 270, 17280, 33, 33, 33, 270, 17280, 33, 17280, 17280, 270, 270, 270, 33, 17280, 33, 270, 270, 33, 270, 33, 33, 270, 270, 17280, 270, 33, 270, 17280, 270, 270, 17280, 270, 17280, 33, 17280, 17280, 270, 33, 33, 17280, 270, 33, 270, 270, 17280, 270, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 17280, 17280, 33, 17280, 33, 270, 17280, 17280, 17280, 270, 33, 17280, 270, 33, 33, 33, 33, 33, 17280, 270, 33, 17280, 33, 17280, 33, 33, 270, 270, 17280, 270, 17280, 33, 270, 33, 17280, 17280, 33, 17280, 270, 33, 17280, 33, 33, 17280, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 33, 270, 17280, 17280, 33, 17280, 270, 33, 270, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 270, 17280, 17280, 270, 33, 17280, 33, 270, 270, 33, 270, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 270, 17280, 270, 33, 270, 17280, 270, 17280, 33, 17280, 33, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 33, 17280, 33, 17280, 270, 270, 33, 270, 17280, 270, 270, 17280, 33, 17280, 17280, 270, 33, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 33, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 17280, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 17280, 270, 33, 33, 33, 33]
Prompts retrieved: 1511835 . Total input tokens: 337040131 . Total output tokens: 302236107
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 133.09263504995033,
    "estimated_duration": 3600.126098940558,
    "input_throughput": 6278.199534913899,
    "output_throughput": 5533.987824999502,
    "total_throughput": 11812.1873599134,
    "itl": 154.59781698481106,
    "ttft": 1922590.9034386124,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 686,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2658635424822586,
    "arrivals": 504244,
    "finished_requests": 91416,
    "scheduler_time": 160.14746568434154
}
#Debug simulation 
Total elapsed time: 133.0927609768696. Arrivals time: 0.6305911736562848 Scheduler time: 132.22597181471065 Scheduler overhead time: 0.09233993105590343 Adapter cache time: 0.02525539230555296 Engine time: 0.0903403484262526 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-16/adapters_256_slots_64_rate_1.6-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-16/adapters_256_slots_64_rate_1.6-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 33, 17280, 17280, 33, 17280, 270, 17280, 33, 270, 33, 17280, 270, 270, 270, 270, 17280, 33, 33, 33, 270, 17280, 33, 17280, 17280, 270, 270, 270, 33, 17280, 33, 270, 270, 33, 270, 33, 33, 270, 270, 17280, 270, 33, 270, 17280, 270, 270, 17280, 270, 17280, 33, 17280, 17280, 270, 33, 33, 17280, 270, 33, 270, 270, 17280, 270, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 17280, 17280, 33, 17280, 33, 270, 17280, 17280, 17280, 270, 33, 17280, 270, 33, 33, 33, 33, 33, 17280, 270, 33, 17280, 33, 17280, 33, 33, 270, 270, 17280, 270, 17280, 33, 270, 33, 17280, 17280, 33, 17280, 270, 33, 17280, 33, 33, 17280, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 33, 270, 17280, 17280, 33, 17280, 270, 33, 270, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 270, 17280, 17280, 270, 33, 17280, 33, 270, 270, 33, 270, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 270, 17280, 270, 33, 270, 17280, 270, 17280, 33, 17280, 33, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 33, 17280, 33, 17280, 270, 270, 33, 270, 17280, 270, 270, 17280, 33, 17280, 17280, 270, 33, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 33, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 17280, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 17280, 270, 33, 33, 33, 33]
Prompts retrieved: 1511835 . Total input tokens: 337040131 . Total output tokens: 302236107
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 137.3910295511596,
    "estimated_duration": 3600.0331670101777,
    "input_throughput": 6277.802162242164,
    "output_throughput": 5533.919849006679,
    "total_throughput": 11811.722011248843,
    "itl": 154.59402774607457,
    "ttft": 1922604.0888868824,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 713,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1319058602652126,
    "arrivals": 504244,
    "finished_requests": 91411,
    "scheduler_time": 160.14844130076975
}
#Debug simulation 
Total elapsed time: 137.39116054493934. Arrivals time: 0.614719261880964 Scheduler time: 136.5558949476108 Scheduler overhead time: 0.08719192212447524 Adapter cache time: 0.024637701455503702 Engine time: 0.08266255958005786 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-32/adapters_256_slots_64_rate_1.6-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-32/adapters_256_slots_64_rate_1.6-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 33, 17280, 17280, 33, 17280, 270, 17280, 33, 270, 33, 17280, 270, 270, 270, 270, 17280, 33, 33, 33, 270, 17280, 33, 17280, 17280, 270, 270, 270, 33, 17280, 33, 270, 270, 33, 270, 33, 33, 270, 270, 17280, 270, 33, 270, 17280, 270, 270, 17280, 270, 17280, 33, 17280, 17280, 270, 33, 33, 17280, 270, 33, 270, 270, 17280, 270, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 17280, 17280, 33, 17280, 33, 270, 17280, 17280, 17280, 270, 33, 17280, 270, 33, 33, 33, 33, 33, 17280, 270, 33, 17280, 33, 17280, 33, 33, 270, 270, 17280, 270, 17280, 33, 270, 33, 17280, 17280, 33, 17280, 270, 33, 17280, 33, 33, 17280, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 33, 270, 17280, 17280, 33, 17280, 270, 33, 270, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 270, 17280, 17280, 270, 33, 17280, 33, 270, 270, 33, 270, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 270, 17280, 270, 33, 270, 17280, 270, 17280, 33, 17280, 33, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 33, 17280, 33, 17280, 270, 270, 33, 270, 17280, 270, 270, 17280, 33, 17280, 17280, 270, 33, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 33, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 17280, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 17280, 270, 33, 33, 33, 33]
Prompts retrieved: 1511835 . Total input tokens: 337040131 . Total output tokens: 302236107
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 133.2480346369557,
    "estimated_duration": 3600.159797178882,
    "input_throughput": 6278.140769671218,
    "output_throughput": 5533.936025731938,
    "total_throughput": 11812.076795403154,
    "itl": 154.59910026209545,
    "ttft": 1922596.365083101,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 686,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2980565118044654,
    "arrivals": 504244,
    "finished_requests": 91416,
    "scheduler_time": 160.1476195427711
}
#Debug simulation 
Total elapsed time: 133.24817263893783. Arrivals time: 0.6497167320922017 Scheduler time: 132.36289521539584 Scheduler overhead time: 0.0922234388999641 Adapter cache time: 0.025419656187295914 Engine time: 0.08942487835884094 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-8/adapters_256_slots_64_rate_1.6-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-8/adapters_256_slots_64_rate_1.6-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 17280, 66, 17280, 17280, 66, 17280, 135, 17280, 66, 135, 66, 17280, 135, 135, 135, 135, 17280, 66, 66, 66, 135, 17280, 66, 17280, 17280, 135, 135, 135, 66, 17280, 66, 135, 135, 66, 135, 66, 66, 135, 135, 17280, 135, 66, 135, 17280, 135, 135, 17280, 135, 17280, 66, 17280, 17280, 135, 66, 66, 17280, 135, 66, 135, 135, 17280, 135, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 17280, 17280, 66, 17280, 66, 135, 17280, 17280, 17280, 135, 66, 17280, 135, 66, 66, 66, 66, 66, 17280, 135, 66, 17280, 66, 17280, 66, 66, 135, 135, 17280, 135, 17280, 66, 135, 66, 17280, 17280, 66, 17280, 135, 66, 17280, 66, 66, 17280, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 66, 135, 17280, 17280, 66, 17280, 135, 66, 135, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 135, 17280, 17280, 135, 66, 17280, 66, 135, 135, 66, 135, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 135, 17280, 135, 66, 135, 17280, 135, 17280, 66, 17280, 66, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 135, 66, 17280, 66, 17280, 135, 135, 66, 135, 17280, 135, 135, 17280, 66, 17280, 17280, 135, 66, 17280, 17280, 135, 135, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 17280, 66, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 17280, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 17280, 135, 66, 66, 66, 66]
Prompts retrieved: 1503165 . Total input tokens: 335100538 . Total output tokens: 300507985
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 135.63257163297385,
    "estimated_duration": 3600.0783269425065,
    "input_throughput": 6256.104160691414,
    "output_throughput": 5547.700962651571,
    "total_throughput": 11803.805123342985,
    "itl": 154.78327455181704,
    "ttft": 1920465.8755623763,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 785,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.402482878987259,
    "arrivals": 501368,
    "finished_requests": 91213,
    "scheduler_time": 160.55094131733193
}
#Debug simulation 
Total elapsed time: 135.63270617229864. Arrivals time: 0.6563549619168043 Scheduler time: 134.74237871076912 Scheduler overhead time: 0.09138544974848628 Adapter cache time: 0.025325533002614975 Engine time: 0.08922442561015487 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-16/adapters_256_slots_64_rate_1.6-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-16/adapters_256_slots_64_rate_1.6-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 17280, 66, 17280, 17280, 66, 17280, 135, 17280, 66, 135, 66, 17280, 135, 135, 135, 135, 17280, 66, 66, 66, 135, 17280, 66, 17280, 17280, 135, 135, 135, 66, 17280, 66, 135, 135, 66, 135, 66, 66, 135, 135, 17280, 135, 66, 135, 17280, 135, 135, 17280, 135, 17280, 66, 17280, 17280, 135, 66, 66, 17280, 135, 66, 135, 135, 17280, 135, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 17280, 17280, 66, 17280, 66, 135, 17280, 17280, 17280, 135, 66, 17280, 135, 66, 66, 66, 66, 66, 17280, 135, 66, 17280, 66, 17280, 66, 66, 135, 135, 17280, 135, 17280, 66, 135, 66, 17280, 17280, 66, 17280, 135, 66, 17280, 66, 66, 17280, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 66, 135, 17280, 17280, 66, 17280, 135, 66, 135, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 135, 17280, 17280, 135, 66, 17280, 66, 135, 135, 66, 135, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 135, 17280, 135, 66, 135, 17280, 135, 17280, 66, 17280, 66, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 135, 66, 17280, 66, 17280, 135, 135, 66, 135, 17280, 135, 135, 17280, 66, 17280, 17280, 135, 66, 17280, 17280, 135, 135, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 17280, 66, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 17280, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 17280, 135, 66, 66, 66, 66]
Prompts retrieved: 1503165 . Total input tokens: 335100538 . Total output tokens: 300507985
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 135.09139510197565,
    "estimated_duration": 3600.083728989616,
    "input_throughput": 6255.944776684654,
    "output_throughput": 5547.4376440697515,
    "total_throughput": 11803.382420754406,
    "itl": 154.789684691477,
    "ttft": 1920419.027799545,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 785,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5637450002715996,
    "arrivals": 501368,
    "finished_requests": 91210,
    "scheduler_time": 160.54388861744255
}
#Debug simulation 
Total elapsed time: 135.09156884765252. Arrivals time: 0.6509600626304746 Scheduler time: 134.20492385467514 Scheduler overhead time: 0.09417561767622828 Adapter cache time: 0.02567282784730196 Engine time: 0.08813266130164266 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-32/adapters_256_slots_64_rate_1.6-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-32/adapters_256_slots_64_rate_1.6-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 17280, 66, 17280, 17280, 66, 17280, 135, 17280, 66, 135, 66, 17280, 135, 135, 135, 135, 17280, 66, 66, 66, 135, 17280, 66, 17280, 17280, 135, 135, 135, 66, 17280, 66, 135, 135, 66, 135, 66, 66, 135, 135, 17280, 135, 66, 135, 17280, 135, 135, 17280, 135, 17280, 66, 17280, 17280, 135, 66, 66, 17280, 135, 66, 135, 135, 17280, 135, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 17280, 17280, 66, 17280, 66, 135, 17280, 17280, 17280, 135, 66, 17280, 135, 66, 66, 66, 66, 66, 17280, 135, 66, 17280, 66, 17280, 66, 66, 135, 135, 17280, 135, 17280, 66, 135, 66, 17280, 17280, 66, 17280, 135, 66, 17280, 66, 66, 17280, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 66, 135, 17280, 17280, 66, 17280, 135, 66, 135, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 135, 17280, 17280, 135, 66, 17280, 66, 135, 135, 66, 135, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 135, 17280, 135, 66, 135, 17280, 135, 17280, 66, 17280, 66, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 135, 66, 17280, 66, 17280, 135, 135, 66, 135, 17280, 135, 135, 17280, 66, 17280, 17280, 135, 66, 17280, 17280, 135, 135, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 17280, 66, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 17280, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 17280, 135, 66, 66, 66, 66]
Prompts retrieved: 1503165 . Total input tokens: 335100538 . Total output tokens: 300507985
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 134.52072908729315,
    "estimated_duration": 3600.0879052383334,
    "input_throughput": 6255.937519533707,
    "output_throughput": 5547.431208815959,
    "total_throughput": 11803.368728349666,
    "itl": 154.78984321775363,
    "ttft": 1920419.7862601578,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 785,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.567903468385329,
    "arrivals": 501368,
    "finished_requests": 91210,
    "scheduler_time": 160.54390639796605
}
#Debug simulation 
Total elapsed time: 134.52085692808032. Arrivals time: 0.6406081230379641 Scheduler time: 133.642408256419 Scheduler overhead time: 0.09393404191359878 Adapter cache time: 0.02573943231254816 Engine time: 0.09015806624665856 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-16/adapters_256_slots_64_rate_1.6-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-16/adapters_256_slots_64_rate_1.6-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 17280, 66, 17280, 17280, 66, 17280, 135, 17280, 66, 135, 66, 17280, 135, 135, 135, 135, 17280, 66, 66, 66, 135, 17280, 66, 17280, 17280, 135, 135, 135, 66, 17280, 66, 135, 135, 66, 135, 66, 66, 135, 135, 17280, 135, 66, 135, 17280, 135, 135, 17280, 135, 17280, 66, 17280, 17280, 135, 66, 66, 17280, 135, 66, 135, 135, 17280, 135, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 17280, 17280, 66, 17280, 66, 135, 17280, 17280, 17280, 135, 66, 17280, 135, 66, 66, 66, 66, 66, 17280, 135, 66, 17280, 66, 17280, 66, 66, 135, 135, 17280, 135, 17280, 66, 135, 66, 17280, 17280, 66, 17280, 135, 66, 17280, 66, 66, 17280, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 66, 135, 17280, 17280, 66, 17280, 135, 66, 135, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 135, 17280, 17280, 135, 66, 17280, 66, 135, 135, 66, 135, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 135, 17280, 135, 66, 135, 17280, 135, 17280, 66, 17280, 66, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 135, 66, 17280, 66, 17280, 135, 135, 66, 135, 17280, 135, 135, 17280, 66, 17280, 17280, 135, 66, 17280, 17280, 135, 135, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 17280, 66, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 17280, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 17280, 135, 66, 66, 66, 66]
Prompts retrieved: 1503165 . Total input tokens: 335100538 . Total output tokens: 300507985
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 135.33263703016564,
    "estimated_duration": 3600.1360131863894,
    "input_throughput": 6256.003916936998,
    "output_throughput": 5547.612069890422,
    "total_throughput": 11803.61598682742,
    "itl": 154.78559100759475,
    "ttft": 1920471.5398595845,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 785,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.459144598750845,
    "arrivals": 501368,
    "finished_requests": 91213,
    "scheduler_time": 160.5512092279653
}
#Debug simulation 
Total elapsed time: 135.3327500182204. Arrivals time: 1.0113838850520551 Scheduler time: 134.0789191564545 Scheduler overhead time: 0.09479031851515174 Adapter cache time: 0.025887972209602594 Engine time: 0.09280776232481003 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-32/adapters_256_slots_64_rate_1.6-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-32/adapters_256_slots_64_rate_1.6-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 17280, 66, 17280, 17280, 66, 17280, 135, 17280, 66, 135, 66, 17280, 135, 135, 135, 135, 17280, 66, 66, 66, 135, 17280, 66, 17280, 17280, 135, 135, 135, 66, 17280, 66, 135, 135, 66, 135, 66, 66, 135, 135, 17280, 135, 66, 135, 17280, 135, 135, 17280, 135, 17280, 66, 17280, 17280, 135, 66, 66, 17280, 135, 66, 135, 135, 17280, 135, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 17280, 17280, 66, 17280, 66, 135, 17280, 17280, 17280, 135, 66, 17280, 135, 66, 66, 66, 66, 66, 17280, 135, 66, 17280, 66, 17280, 66, 66, 135, 135, 17280, 135, 17280, 66, 135, 66, 17280, 17280, 66, 17280, 135, 66, 17280, 66, 66, 17280, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 66, 135, 17280, 17280, 66, 17280, 135, 66, 135, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 135, 17280, 17280, 135, 66, 17280, 66, 135, 135, 66, 135, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 135, 17280, 135, 66, 135, 17280, 135, 17280, 66, 17280, 66, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 135, 66, 17280, 66, 17280, 135, 135, 66, 135, 17280, 135, 135, 17280, 66, 17280, 17280, 135, 66, 17280, 17280, 135, 135, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 17280, 66, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 17280, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 17280, 135, 66, 66, 66, 66]
Prompts retrieved: 1503165 . Total input tokens: 335100538 . Total output tokens: 300507985
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 135.1228669960983,
    "estimated_duration": 3600.1052073075507,
    "input_throughput": 6255.907453561257,
    "output_throughput": 5547.404547917672,
    "total_throughput": 11803.31200147893,
    "itl": 154.78920423914101,
    "ttft": 1920418.561765941,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 785,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6000964377075455,
    "arrivals": 501368,
    "finished_requests": 91210,
    "scheduler_time": 160.5447581770961
}
#Debug simulation 
Total elapsed time: 135.12299404013902. Arrivals time: 0.6791309281252325 Scheduler time: 134.21267894329503 Scheduler overhead time: 0.09036968182772398 Adapter cache time: 0.025141116231679916 Engine time: 0.08762299781665206 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-16/adapters_256_slots_64_rate_1.6-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-16/adapters_256_slots_64_rate_1.6-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 17280, 66, 17280, 17280, 66, 17280, 135, 17280, 66, 135, 66, 17280, 135, 135, 135, 135, 17280, 66, 66, 66, 135, 17280, 66, 17280, 17280, 135, 135, 135, 66, 17280, 66, 135, 135, 66, 135, 66, 66, 135, 135, 17280, 135, 66, 135, 17280, 135, 135, 17280, 135, 17280, 66, 17280, 17280, 135, 66, 66, 17280, 135, 66, 135, 135, 17280, 135, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 17280, 17280, 66, 17280, 66, 135, 17280, 17280, 17280, 135, 66, 17280, 135, 66, 66, 66, 66, 66, 17280, 135, 66, 17280, 66, 17280, 66, 66, 135, 135, 17280, 135, 17280, 66, 135, 66, 17280, 17280, 66, 17280, 135, 66, 17280, 66, 66, 17280, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 66, 135, 17280, 17280, 66, 17280, 135, 66, 135, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 135, 17280, 17280, 135, 66, 17280, 66, 135, 135, 66, 135, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 135, 17280, 135, 66, 135, 17280, 135, 17280, 66, 17280, 66, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 135, 66, 17280, 66, 17280, 135, 135, 66, 135, 17280, 135, 135, 17280, 66, 17280, 17280, 135, 66, 17280, 17280, 135, 135, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 17280, 66, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 17280, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 17280, 135, 66, 66, 66, 66]
Prompts retrieved: 1503165 . Total input tokens: 335100538 . Total output tokens: 300507985
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 136.08131766179577,
    "estimated_duration": 3600.0179989544267,
    "input_throughput": 6256.192331966481,
    "output_throughput": 5547.762262799962,
    "total_throughput": 11803.954594766443,
    "itl": 154.7811936683694,
    "ttft": 1920452.4096309247,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 785,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3471894814981615,
    "arrivals": 501368,
    "finished_requests": 91212,
    "scheduler_time": 160.55000871528924
}
#Debug simulation 
Total elapsed time: 136.08143678074703. Arrivals time: 0.6407907614484429 Scheduler time: 135.2039896300994 Scheduler overhead time: 0.09333185339346528 Adapter cache time: 0.025157497730106115 Engine time: 0.08990082191303372 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-32/adapters_256_slots_64_rate_1.6-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-32/adapters_256_slots_64_rate_1.6-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 17280, 66, 17280, 17280, 66, 17280, 135, 17280, 66, 135, 66, 17280, 135, 135, 135, 135, 17280, 66, 66, 66, 135, 17280, 66, 17280, 17280, 135, 135, 135, 66, 17280, 66, 135, 135, 66, 135, 66, 66, 135, 135, 17280, 135, 66, 135, 17280, 135, 135, 17280, 135, 17280, 66, 17280, 17280, 135, 66, 66, 17280, 135, 66, 135, 135, 17280, 135, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 17280, 17280, 66, 17280, 66, 135, 17280, 17280, 17280, 135, 66, 17280, 135, 66, 66, 66, 66, 66, 17280, 135, 66, 17280, 66, 17280, 66, 66, 135, 135, 17280, 135, 17280, 66, 135, 66, 17280, 17280, 66, 17280, 135, 66, 17280, 66, 66, 17280, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 66, 135, 17280, 17280, 66, 17280, 135, 66, 135, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 135, 17280, 17280, 135, 66, 17280, 66, 135, 135, 66, 135, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 135, 17280, 135, 66, 135, 17280, 135, 17280, 66, 17280, 66, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 135, 66, 17280, 66, 17280, 135, 135, 66, 135, 17280, 135, 135, 17280, 66, 17280, 17280, 135, 66, 17280, 17280, 135, 135, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 17280, 66, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 17280, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 17280, 135, 66, 66, 66, 66]
Prompts retrieved: 1503165 . Total input tokens: 335100538 . Total output tokens: 300507985
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 135.46255261311308,
    "estimated_duration": 3600.1440757123682,
    "input_throughput": 6255.839912613369,
    "output_throughput": 5547.344656213028,
    "total_throughput": 11803.184568826398,
    "itl": 154.79052205129247,
    "ttft": 1920439.3525350618,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 785,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6345529751852315,
    "arrivals": 501368,
    "finished_requests": 91210,
    "scheduler_time": 160.54504783324717
}
#Debug simulation 
Total elapsed time: 135.46268624812365. Arrivals time: 0.6806967072188854 Scheduler time: 134.54744211770594 Scheduler overhead time: 0.09138978272676468 Adapter cache time: 0.026070223189890385 Engine time: 0.08884171955287457 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-8/adapters_256_slots_64_rate_1.6-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-8/adapters_256_slots_64_rate_1.6-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 17280, 33, 17280, 17280, 33, 17280, 135, 17280, 33, 135, 33, 17280, 135, 135, 135, 135, 17280, 33, 33, 33, 135, 17280, 33, 17280, 17280, 135, 135, 135, 33, 17280, 33, 135, 135, 33, 135, 33, 33, 135, 135, 17280, 135, 33, 135, 17280, 135, 135, 17280, 135, 17280, 33, 17280, 17280, 135, 33, 33, 17280, 135, 33, 135, 135, 17280, 135, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 17280, 17280, 33, 17280, 33, 135, 17280, 17280, 17280, 135, 33, 17280, 135, 33, 33, 33, 33, 33, 17280, 135, 33, 17280, 33, 17280, 33, 33, 135, 135, 17280, 135, 17280, 33, 135, 33, 17280, 17280, 33, 17280, 135, 33, 17280, 33, 33, 17280, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 33, 135, 17280, 17280, 33, 17280, 135, 33, 135, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 135, 17280, 17280, 135, 33, 17280, 33, 135, 135, 33, 135, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 135, 17280, 135, 33, 135, 17280, 135, 17280, 33, 17280, 33, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 135, 33, 17280, 33, 17280, 135, 135, 33, 135, 17280, 135, 135, 17280, 33, 17280, 17280, 135, 33, 17280, 17280, 135, 135, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 17280, 33, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 17280, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 17280, 135, 33, 33, 33, 33]
Prompts retrieved: 1500360 . Total input tokens: 334451225 . Total output tokens: 299936524
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 136.3837505937554,
    "estimated_duration": 3600.0587397240315,
    "input_throughput": 6361.156207622179,
    "output_throughput": 5608.770150663665,
    "total_throughput": 11969.926358285844,
    "itl": 152.73305208922054,
    "ttft": 1932356.5075263234,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 629,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.925046790933733,
    "arrivals": 500381,
    "finished_requests": 92276,
    "scheduler_time": 162.48356303734124
}
#Debug simulation 
Total elapsed time: 136.38387787295505. Arrivals time: 0.6689329980872571 Scheduler time: 135.48012171452865 Scheduler overhead time: 0.09317214274778962 Adapter cache time: 0.02472222736105323 Engine time: 0.08901719143614173 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-16/adapters_256_slots_64_rate_1.6-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-16/adapters_256_slots_64_rate_1.6-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 17280, 33, 17280, 17280, 33, 17280, 135, 17280, 33, 135, 33, 17280, 135, 135, 135, 135, 17280, 33, 33, 33, 135, 17280, 33, 17280, 17280, 135, 135, 135, 33, 17280, 33, 135, 135, 33, 135, 33, 33, 135, 135, 17280, 135, 33, 135, 17280, 135, 135, 17280, 135, 17280, 33, 17280, 17280, 135, 33, 33, 17280, 135, 33, 135, 135, 17280, 135, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 17280, 17280, 33, 17280, 33, 135, 17280, 17280, 17280, 135, 33, 17280, 135, 33, 33, 33, 33, 33, 17280, 135, 33, 17280, 33, 17280, 33, 33, 135, 135, 17280, 135, 17280, 33, 135, 33, 17280, 17280, 33, 17280, 135, 33, 17280, 33, 33, 17280, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 33, 135, 17280, 17280, 33, 17280, 135, 33, 135, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 135, 17280, 17280, 135, 33, 17280, 33, 135, 135, 33, 135, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 135, 17280, 135, 33, 135, 17280, 135, 17280, 33, 17280, 33, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 135, 33, 17280, 33, 17280, 135, 135, 33, 135, 17280, 135, 135, 17280, 33, 17280, 17280, 135, 33, 17280, 17280, 135, 135, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 17280, 33, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 17280, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 17280, 135, 33, 33, 33, 33]
Prompts retrieved: 1500360 . Total input tokens: 334451225 . Total output tokens: 299936524
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 135.41663871891797,
    "estimated_duration": 3600.093490796935,
    "input_throughput": 6352.562248303563,
    "output_throughput": 5602.563392189885,
    "total_throughput": 11955.125640493448,
    "itl": 152.90458588102473,
    "ttft": 1931701.7552039074,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 628,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.047318642351316,
    "arrivals": 500381,
    "finished_requests": 92164,
    "scheduler_time": 162.29368328149945
}
#Debug simulation 
Total elapsed time: 135.41676456481218. Arrivals time: 0.6517936238087714 Scheduler time: 134.5273821032606 Scheduler overhead time: 0.09463503723964095 Adapter cache time: 0.024784880224615335 Engine time: 0.08996085682883859 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-32/adapters_256_slots_64_rate_1.6-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-32/adapters_256_slots_64_rate_1.6-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 17280, 33, 17280, 17280, 33, 17280, 135, 17280, 33, 135, 33, 17280, 135, 135, 135, 135, 17280, 33, 33, 33, 135, 17280, 33, 17280, 17280, 135, 135, 135, 33, 17280, 33, 135, 135, 33, 135, 33, 33, 135, 135, 17280, 135, 33, 135, 17280, 135, 135, 17280, 135, 17280, 33, 17280, 17280, 135, 33, 33, 17280, 135, 33, 135, 135, 17280, 135, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 17280, 17280, 33, 17280, 33, 135, 17280, 17280, 17280, 135, 33, 17280, 135, 33, 33, 33, 33, 33, 17280, 135, 33, 17280, 33, 17280, 33, 33, 135, 135, 17280, 135, 17280, 33, 135, 33, 17280, 17280, 33, 17280, 135, 33, 17280, 33, 33, 17280, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 33, 135, 17280, 17280, 33, 17280, 135, 33, 135, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 135, 17280, 17280, 135, 33, 17280, 33, 135, 135, 33, 135, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 135, 17280, 135, 33, 135, 17280, 135, 17280, 33, 17280, 33, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 135, 33, 17280, 33, 17280, 135, 135, 33, 135, 17280, 135, 135, 17280, 33, 17280, 17280, 135, 33, 17280, 17280, 135, 135, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 17280, 33, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 17280, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 17280, 135, 33, 33, 33, 33]
Prompts retrieved: 1500360 . Total input tokens: 334451225 . Total output tokens: 299936524
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 134.97758979490027,
    "estimated_duration": 3600.099538131645,
    "input_throughput": 6352.551577468,
    "output_throughput": 5602.553981178964,
    "total_throughput": 11955.105558646965,
    "itl": 152.90459603836638,
    "ttft": 1931703.356661938,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 628,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0512875472568077,
    "arrivals": 500381,
    "finished_requests": 92164,
    "scheduler_time": 162.29379965666328
}
#Debug simulation 
Total elapsed time: 134.97778402268887. Arrivals time: 0.6717343674972653 Scheduler time: 134.07394819054753 Scheduler overhead time: 0.09146506432443857 Adapter cache time: 0.024029556661844254 Engine time: 0.0886385552585125 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-16/adapters_256_slots_64_rate_1.6-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-16/adapters_256_slots_64_rate_1.6-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 17280, 33, 17280, 17280, 33, 17280, 135, 17280, 33, 135, 33, 17280, 135, 135, 135, 135, 17280, 33, 33, 33, 135, 17280, 33, 17280, 17280, 135, 135, 135, 33, 17280, 33, 135, 135, 33, 135, 33, 33, 135, 135, 17280, 135, 33, 135, 17280, 135, 135, 17280, 135, 17280, 33, 17280, 17280, 135, 33, 33, 17280, 135, 33, 135, 135, 17280, 135, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 17280, 17280, 33, 17280, 33, 135, 17280, 17280, 17280, 135, 33, 17280, 135, 33, 33, 33, 33, 33, 17280, 135, 33, 17280, 33, 17280, 33, 33, 135, 135, 17280, 135, 17280, 33, 135, 33, 17280, 17280, 33, 17280, 135, 33, 17280, 33, 33, 17280, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 33, 135, 17280, 17280, 33, 17280, 135, 33, 135, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 135, 17280, 17280, 135, 33, 17280, 33, 135, 135, 33, 135, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 135, 17280, 135, 33, 135, 17280, 135, 17280, 33, 17280, 33, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 135, 33, 17280, 33, 17280, 135, 135, 33, 135, 17280, 135, 135, 17280, 33, 17280, 17280, 135, 33, 17280, 17280, 135, 135, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 17280, 33, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 17280, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 17280, 135, 33, 33, 33, 33]
Prompts retrieved: 1500360 . Total input tokens: 334451225 . Total output tokens: 299936524
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 135.47835257276893,
    "estimated_duration": 3600.105029984424,
    "input_throughput": 6361.147191335993,
    "output_throughput": 5608.797752238735,
    "total_throughput": 11969.944943574726,
    "itl": 152.73415231612248,
    "ttft": 1932356.7215608808,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 629,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9702240102318933,
    "arrivals": 500381,
    "finished_requests": 92277,
    "scheduler_time": 162.4839057945066
}
#Debug simulation 
Total elapsed time: 135.4785063820891. Arrivals time: 0.6615866590291262 Scheduler time: 134.58071299316362 Scheduler overhead time: 0.09299180097877979 Adapter cache time: 0.024947033263742924 Engine time: 0.08915985049679875 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-32/adapters_256_slots_64_rate_1.6-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-32/adapters_256_slots_64_rate_1.6-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 17280, 33, 17280, 17280, 33, 17280, 135, 17280, 33, 135, 33, 17280, 135, 135, 135, 135, 17280, 33, 33, 33, 135, 17280, 33, 17280, 17280, 135, 135, 135, 33, 17280, 33, 135, 135, 33, 135, 33, 33, 135, 135, 17280, 135, 33, 135, 17280, 135, 135, 17280, 135, 17280, 33, 17280, 17280, 135, 33, 33, 17280, 135, 33, 135, 135, 17280, 135, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 17280, 17280, 33, 17280, 33, 135, 17280, 17280, 17280, 135, 33, 17280, 135, 33, 33, 33, 33, 33, 17280, 135, 33, 17280, 33, 17280, 33, 33, 135, 135, 17280, 135, 17280, 33, 135, 33, 17280, 17280, 33, 17280, 135, 33, 17280, 33, 33, 17280, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 33, 135, 17280, 17280, 33, 17280, 135, 33, 135, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 135, 17280, 17280, 135, 33, 17280, 33, 135, 135, 33, 135, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 135, 17280, 135, 33, 135, 17280, 135, 17280, 33, 17280, 33, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 135, 33, 17280, 33, 17280, 135, 135, 33, 135, 17280, 135, 135, 17280, 33, 17280, 17280, 135, 33, 17280, 17280, 135, 135, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 17280, 33, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 17280, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 17280, 135, 33, 33, 33, 33]
Prompts retrieved: 1500360 . Total input tokens: 334451225 . Total output tokens: 299936524
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 136.00712060695514,
    "estimated_duration": 3600.127507008159,
    "input_throughput": 6352.502225401921,
    "output_throughput": 5602.510455737114,
    "total_throughput": 11955.012681139035,
    "itl": 152.90464478233943,
    "ttft": 1931704.3917184896,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 628,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.076061043180528,
    "arrivals": 500381,
    "finished_requests": 92164,
    "scheduler_time": 162.2946825991577
}
#Debug simulation 
Total elapsed time: 136.00724165001884. Arrivals time: 0.6608435553498566 Scheduler time: 135.1079643201083 Scheduler overhead time: 0.0971806044690311 Adapter cache time: 0.02414550445973873 Engine time: 0.08865898149088025 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-16/adapters_256_slots_64_rate_1.6-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-16/adapters_256_slots_64_rate_1.6-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 17280, 33, 17280, 17280, 33, 17280, 135, 17280, 33, 135, 33, 17280, 135, 135, 135, 135, 17280, 33, 33, 33, 135, 17280, 33, 17280, 17280, 135, 135, 135, 33, 17280, 33, 135, 135, 33, 135, 33, 33, 135, 135, 17280, 135, 33, 135, 17280, 135, 135, 17280, 135, 17280, 33, 17280, 17280, 135, 33, 33, 17280, 135, 33, 135, 135, 17280, 135, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 17280, 17280, 33, 17280, 33, 135, 17280, 17280, 17280, 135, 33, 17280, 135, 33, 33, 33, 33, 33, 17280, 135, 33, 17280, 33, 17280, 33, 33, 135, 135, 17280, 135, 17280, 33, 135, 33, 17280, 17280, 33, 17280, 135, 33, 17280, 33, 33, 17280, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 33, 135, 17280, 17280, 33, 17280, 135, 33, 135, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 135, 17280, 17280, 135, 33, 17280, 33, 135, 135, 33, 135, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 135, 17280, 135, 33, 135, 17280, 135, 17280, 33, 17280, 33, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 135, 33, 17280, 33, 17280, 135, 135, 33, 135, 17280, 135, 135, 17280, 33, 17280, 17280, 135, 33, 17280, 17280, 135, 135, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 17280, 33, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 17280, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 17280, 135, 33, 33, 33, 33]
Prompts retrieved: 1500360 . Total input tokens: 334451225 . Total output tokens: 299936524
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 137.68315038783476,
    "estimated_duration": 3600.015996631633,
    "input_throughput": 6361.231733810895,
    "output_throughput": 5608.836743751312,
    "total_throughput": 11970.068477562207,
    "itl": 152.7317463590453,
    "ttft": 1932354.5212937433,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 629,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8807416354934385,
    "arrivals": 500381,
    "finished_requests": 92276,
    "scheduler_time": 162.48260801164287
}
#Debug simulation 
Total elapsed time: 137.68327847961336. Arrivals time: 0.6725516435690224 Scheduler time: 136.77936657471582 Scheduler overhead time: 0.0924898935481906 Adapter cache time: 0.023382721934467554 Engine time: 0.08783890958875418 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-32/adapters_256_slots_64_rate_1.6-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-32/adapters_256_slots_64_rate_1.6-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 17280, 33, 17280, 17280, 33, 17280, 135, 17280, 33, 135, 33, 17280, 135, 135, 135, 135, 17280, 33, 33, 33, 135, 17280, 33, 17280, 17280, 135, 135, 135, 33, 17280, 33, 135, 135, 33, 135, 33, 33, 135, 135, 17280, 135, 33, 135, 17280, 135, 135, 17280, 135, 17280, 33, 17280, 17280, 135, 33, 33, 17280, 135, 33, 135, 135, 17280, 135, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 17280, 17280, 33, 17280, 33, 135, 17280, 17280, 17280, 135, 33, 17280, 135, 33, 33, 33, 33, 33, 17280, 135, 33, 17280, 33, 17280, 33, 33, 135, 135, 17280, 135, 17280, 33, 135, 33, 17280, 17280, 33, 17280, 135, 33, 17280, 33, 33, 17280, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 33, 135, 17280, 17280, 33, 17280, 135, 33, 135, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 135, 17280, 17280, 135, 33, 17280, 33, 135, 135, 33, 135, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 135, 17280, 135, 33, 135, 17280, 135, 17280, 33, 17280, 33, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 135, 33, 17280, 33, 17280, 135, 135, 33, 135, 17280, 135, 135, 17280, 33, 17280, 17280, 135, 33, 17280, 17280, 135, 135, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 17280, 33, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 17280, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 17280, 135, 33, 33, 33, 33]
Prompts retrieved: 1500360 . Total input tokens: 334451225 . Total output tokens: 299936524
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 136.28575641894713,
    "estimated_duration": 3600.1632855105545,
    "input_throughput": 6352.439094094238,
    "output_throughput": 5602.454777864233,
    "total_throughput": 11954.89387195847,
    "itl": 152.90573874248236,
    "ttft": 1931707.550055759,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 628,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.103475368618963,
    "arrivals": 500381,
    "finished_requests": 92164,
    "scheduler_time": 162.29538096958171
}
#Debug simulation 
Total elapsed time: 136.2858926197514. Arrivals time: 0.6554655735380948 Scheduler time: 135.39806535793468 Scheduler overhead time: 0.09182191966101527 Adapter cache time: 0.024571762420237064 Engine time: 0.08804955519735813 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-8/adapters_256_slots_64_rate_1.6-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-8/adapters_256_slots_64_rate_1.6-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 17280, 33, 17280, 17280, 33, 17280, 66, 17280, 33, 66, 33, 17280, 66, 66, 66, 66, 17280, 33, 33, 33, 66, 17280, 33, 17280, 17280, 66, 66, 66, 33, 17280, 33, 66, 66, 33, 66, 33, 33, 66, 66, 17280, 66, 33, 66, 17280, 66, 66, 17280, 66, 17280, 33, 17280, 17280, 66, 33, 33, 17280, 66, 33, 66, 66, 17280, 66, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 17280, 17280, 33, 17280, 33, 66, 17280, 17280, 17280, 66, 33, 17280, 66, 33, 33, 33, 33, 33, 17280, 66, 33, 17280, 33, 17280, 33, 33, 66, 66, 17280, 66, 17280, 33, 66, 33, 17280, 17280, 33, 17280, 66, 33, 17280, 33, 33, 17280, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 33, 66, 17280, 17280, 33, 17280, 66, 33, 66, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 66, 17280, 17280, 66, 33, 17280, 33, 66, 66, 33, 66, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 66, 17280, 66, 33, 66, 17280, 66, 17280, 33, 17280, 33, 66, 17280, 66, 17280, 66, 17280, 66, 17280, 66, 33, 17280, 33, 17280, 66, 66, 33, 66, 17280, 66, 66, 17280, 33, 17280, 17280, 66, 33, 17280, 17280, 66, 66, 17280, 17280, 66, 66, 66, 66, 17280, 17280, 66, 66, 17280, 33, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 17280, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 17280, 66, 33, 33, 33, 33]
Prompts retrieved: 1494495 . Total input tokens: 333126301 . Total output tokens: 298768414
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 140.88467062916607,
    "estimated_duration": 3600.087531772658,
    "input_throughput": 6441.235052021608,
    "output_throughput": 5683.621806252272,
    "total_throughput": 12124.85685827388,
    "itl": 150.79882194302425,
    "ttft": 1934106.225123209,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 462,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4139453376969453,
    "arrivals": 498436,
    "finished_requests": 93733,
    "scheduler_time": 164.54928083730493
}
#Debug simulation 
Total elapsed time: 140.88479840476066. Arrivals time: 0.6700865495949984 Scheduler time: 139.97641688166186 Scheduler overhead time: 0.09463562397286296 Adapter cache time: 0.023567430209368467 Engine time: 0.09164719143882394 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-16/adapters_256_slots_64_rate_1.6-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-16/adapters_256_slots_64_rate_1.6-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 17280, 33, 17280, 17280, 33, 17280, 66, 17280, 33, 66, 33, 17280, 66, 66, 66, 66, 17280, 33, 33, 33, 66, 17280, 33, 17280, 17280, 66, 66, 66, 33, 17280, 33, 66, 66, 33, 66, 33, 33, 66, 66, 17280, 66, 33, 66, 17280, 66, 66, 17280, 66, 17280, 33, 17280, 17280, 66, 33, 33, 17280, 66, 33, 66, 66, 17280, 66, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 17280, 17280, 33, 17280, 33, 66, 17280, 17280, 17280, 66, 33, 17280, 66, 33, 33, 33, 33, 33, 17280, 66, 33, 17280, 33, 17280, 33, 33, 66, 66, 17280, 66, 17280, 33, 66, 33, 17280, 17280, 33, 17280, 66, 33, 17280, 33, 33, 17280, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 33, 66, 17280, 17280, 33, 17280, 66, 33, 66, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 66, 17280, 17280, 66, 33, 17280, 33, 66, 66, 33, 66, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 66, 17280, 66, 33, 66, 17280, 66, 17280, 33, 17280, 33, 66, 17280, 66, 17280, 66, 17280, 66, 17280, 66, 33, 17280, 33, 17280, 66, 66, 33, 66, 17280, 66, 66, 17280, 33, 17280, 17280, 66, 33, 17280, 17280, 66, 66, 17280, 17280, 66, 66, 66, 66, 17280, 17280, 66, 66, 17280, 33, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 17280, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 17280, 66, 33, 33, 33, 33]
Prompts retrieved: 1494495 . Total input tokens: 333126301 . Total output tokens: 298768414
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 140.67934126313776,
    "estimated_duration": 3600.048258427896,
    "input_throughput": 6441.061712357717,
    "output_throughput": 5683.313814502798,
    "total_throughput": 12124.375526860515,
    "itl": 150.80150382466996,
    "ttft": 1934118.9952468993,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 462,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5060248083691163,
    "arrivals": 498436,
    "finished_requests": 93728,
    "scheduler_time": 164.54324611534398
}
#Debug simulation 
Total elapsed time: 140.67947642784566. Arrivals time: 0.6763009205460548 Scheduler time: 139.76286781113595 Scheduler overhead time: 0.09577052062377334 Adapter cache time: 0.02410286432132125 Engine time: 0.0905933347530663 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-32/adapters_256_slots_64_rate_1.6-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-32/adapters_256_slots_64_rate_1.6-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 17280, 33, 17280, 17280, 33, 17280, 66, 17280, 33, 66, 33, 17280, 66, 66, 66, 66, 17280, 33, 33, 33, 66, 17280, 33, 17280, 17280, 66, 66, 66, 33, 17280, 33, 66, 66, 33, 66, 33, 33, 66, 66, 17280, 66, 33, 66, 17280, 66, 66, 17280, 66, 17280, 33, 17280, 17280, 66, 33, 33, 17280, 66, 33, 66, 66, 17280, 66, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 17280, 17280, 33, 17280, 33, 66, 17280, 17280, 17280, 66, 33, 17280, 66, 33, 33, 33, 33, 33, 17280, 66, 33, 17280, 33, 17280, 33, 33, 66, 66, 17280, 66, 17280, 33, 66, 33, 17280, 17280, 33, 17280, 66, 33, 17280, 33, 33, 17280, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 33, 66, 17280, 17280, 33, 17280, 66, 33, 66, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 66, 17280, 17280, 66, 33, 17280, 33, 66, 66, 33, 66, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 66, 17280, 66, 33, 66, 17280, 66, 17280, 33, 17280, 33, 66, 17280, 66, 17280, 66, 17280, 66, 17280, 66, 33, 17280, 33, 17280, 66, 66, 33, 66, 17280, 66, 66, 17280, 33, 17280, 17280, 66, 33, 17280, 17280, 66, 66, 17280, 17280, 66, 66, 66, 66, 17280, 17280, 66, 66, 17280, 33, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 17280, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 17280, 66, 33, 33, 33, 33]
Prompts retrieved: 1494495 . Total input tokens: 333126301 . Total output tokens: 298768414
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 141.42075878707692,
    "estimated_duration": 3600.036745467055,
    "input_throughput": 6441.0823109505955,
    "output_throughput": 5683.331989808779,
    "total_throughput": 12124.414300759376,
    "itl": 150.80107984377042,
    "ttft": 1934112.5390197914,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 462,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5089661939628511,
    "arrivals": 498436,
    "finished_requests": 93728,
    "scheduler_time": 164.54369310878752
}
#Debug simulation 
Total elapsed time: 141.42088236287236. Arrivals time: 0.6764266821555793 Scheduler time: 140.5014722365886 Scheduler overhead time: 0.09827086189761758 Adapter cache time: 0.023832153994590044 Engine time: 0.09209844656288624 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-16/adapters_256_slots_64_rate_1.6-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-16/adapters_256_slots_64_rate_1.6-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 17280, 33, 17280, 17280, 33, 17280, 66, 17280, 33, 66, 33, 17280, 66, 66, 66, 66, 17280, 33, 33, 33, 66, 17280, 33, 17280, 17280, 66, 66, 66, 33, 17280, 33, 66, 66, 33, 66, 33, 33, 66, 66, 17280, 66, 33, 66, 17280, 66, 66, 17280, 66, 17280, 33, 17280, 17280, 66, 33, 33, 17280, 66, 33, 66, 66, 17280, 66, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 17280, 17280, 33, 17280, 33, 66, 17280, 17280, 17280, 66, 33, 17280, 66, 33, 33, 33, 33, 33, 17280, 66, 33, 17280, 33, 17280, 33, 33, 66, 66, 17280, 66, 17280, 33, 66, 33, 17280, 17280, 33, 17280, 66, 33, 17280, 33, 33, 17280, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 33, 66, 17280, 17280, 33, 17280, 66, 33, 66, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 66, 17280, 17280, 66, 33, 17280, 33, 66, 66, 33, 66, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 66, 17280, 66, 33, 66, 17280, 66, 17280, 33, 17280, 33, 66, 17280, 66, 17280, 66, 17280, 66, 17280, 66, 33, 17280, 33, 17280, 66, 66, 33, 66, 17280, 66, 66, 17280, 33, 17280, 17280, 66, 33, 17280, 17280, 66, 66, 17280, 17280, 66, 66, 66, 66, 17280, 17280, 66, 66, 17280, 33, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 17280, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 17280, 66, 33, 33, 33, 33]
Prompts retrieved: 1494495 . Total input tokens: 333126301 . Total output tokens: 298768414
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 141.06486228574067,
    "estimated_duration": 3600.1231428865385,
    "input_throughput": 6441.171337657997,
    "output_throughput": 5683.565585924422,
    "total_throughput": 12124.736923582419,
    "itl": 150.80005459785494,
    "ttft": 1934111.6376351698,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 462,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.447187082513698,
    "arrivals": 498436,
    "finished_requests": 93733,
    "scheduler_time": 164.54947718603293
}
#Debug simulation 
Total elapsed time: 141.06498565757647. Arrivals time: 0.6683411030098796 Scheduler time: 140.15587852243334 Scheduler overhead time: 0.09587563946843147 Adapter cache time: 0.023579865228384733 Engine time: 0.09299137257039547 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-32/adapters_256_slots_64_rate_1.6-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-32/adapters_256_slots_64_rate_1.6-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 17280, 33, 17280, 17280, 33, 17280, 66, 17280, 33, 66, 33, 17280, 66, 66, 66, 66, 17280, 33, 33, 33, 66, 17280, 33, 17280, 17280, 66, 66, 66, 33, 17280, 33, 66, 66, 33, 66, 33, 33, 66, 66, 17280, 66, 33, 66, 17280, 66, 66, 17280, 66, 17280, 33, 17280, 17280, 66, 33, 33, 17280, 66, 33, 66, 66, 17280, 66, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 17280, 17280, 33, 17280, 33, 66, 17280, 17280, 17280, 66, 33, 17280, 66, 33, 33, 33, 33, 33, 17280, 66, 33, 17280, 33, 17280, 33, 33, 66, 66, 17280, 66, 17280, 33, 66, 33, 17280, 17280, 33, 17280, 66, 33, 17280, 33, 33, 17280, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 33, 66, 17280, 17280, 33, 17280, 66, 33, 66, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 66, 17280, 17280, 66, 33, 17280, 33, 66, 66, 33, 66, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 66, 17280, 66, 33, 66, 17280, 66, 17280, 33, 17280, 33, 66, 17280, 66, 17280, 66, 17280, 66, 17280, 66, 33, 17280, 33, 17280, 66, 66, 33, 66, 17280, 66, 66, 17280, 33, 17280, 17280, 66, 33, 17280, 17280, 66, 66, 17280, 17280, 66, 66, 66, 66, 17280, 17280, 66, 66, 17280, 33, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 17280, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 17280, 66, 33, 33, 33, 33]
Prompts retrieved: 1494495 . Total input tokens: 333126301 . Total output tokens: 298768414
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 141.51097065862268,
    "estimated_duration": 3600.0588187086605,
    "input_throughput": 6441.0428183830545,
    "output_throughput": 5683.297143278083,
    "total_throughput": 12124.339961661137,
    "itl": 150.80157753921986,
    "ttft": 1934118.2417135872,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 462,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.527074739206587,
    "arrivals": 498436,
    "finished_requests": 93728,
    "scheduler_time": 164.54396582552525
}
#Debug simulation 
Total elapsed time: 141.5110959140584. Arrivals time: 0.6742151803337038 Scheduler time: 140.59790466725826 Scheduler overhead time: 0.09524900559335947 Adapter cache time: 0.023198595270514488 Engine time: 0.09090778976678848 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-16/adapters_256_slots_64_rate_1.6-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-16/adapters_256_slots_64_rate_1.6-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 17280, 33, 17280, 17280, 33, 17280, 66, 17280, 33, 66, 33, 17280, 66, 66, 66, 66, 17280, 33, 33, 33, 66, 17280, 33, 17280, 17280, 66, 66, 66, 33, 17280, 33, 66, 66, 33, 66, 33, 33, 66, 66, 17280, 66, 33, 66, 17280, 66, 66, 17280, 66, 17280, 33, 17280, 17280, 66, 33, 33, 17280, 66, 33, 66, 66, 17280, 66, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 17280, 17280, 33, 17280, 33, 66, 17280, 17280, 17280, 66, 33, 17280, 66, 33, 33, 33, 33, 33, 17280, 66, 33, 17280, 33, 17280, 33, 33, 66, 66, 17280, 66, 17280, 33, 66, 33, 17280, 17280, 33, 17280, 66, 33, 17280, 33, 33, 17280, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 33, 66, 17280, 17280, 33, 17280, 66, 33, 66, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 66, 17280, 17280, 66, 33, 17280, 33, 66, 66, 33, 66, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 66, 17280, 66, 33, 66, 17280, 66, 17280, 33, 17280, 33, 66, 17280, 66, 17280, 66, 17280, 66, 17280, 66, 33, 17280, 33, 17280, 66, 66, 33, 66, 17280, 66, 66, 17280, 33, 17280, 17280, 66, 33, 17280, 17280, 66, 66, 17280, 17280, 66, 66, 66, 66, 17280, 17280, 66, 66, 17280, 33, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 17280, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 17280, 66, 33, 33, 33, 33]
Prompts retrieved: 1494495 . Total input tokens: 333126301 . Total output tokens: 298768414
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 140.51427866797894,
    "estimated_duration": 3600.0534633917778,
    "input_throughput": 6441.296007352223,
    "output_throughput": 5683.675592062524,
    "total_throughput": 12124.971599414746,
    "itl": 150.7976352337949,
    "ttft": 1934100.7878798586,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 462,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.381403236244793,
    "arrivals": 498436,
    "finished_requests": 93733,
    "scheduler_time": 164.5486540728747
}
#Debug simulation 
Total elapsed time: 140.51439102832228. Arrivals time: 0.6682490464299917 Scheduler time: 139.60751853697002 Scheduler overhead time: 0.09463516809046268 Adapter cache time: 0.022636267822235823 Engine time: 0.09167682379484177 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-32/adapters_256_slots_64_rate_1.6-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-32/adapters_256_slots_64_rate_1.6-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 17280, 33, 17280, 17280, 33, 17280, 66, 17280, 33, 66, 33, 17280, 66, 66, 66, 66, 17280, 33, 33, 33, 66, 17280, 33, 17280, 17280, 66, 66, 66, 33, 17280, 33, 66, 66, 33, 66, 33, 33, 66, 66, 17280, 66, 33, 66, 17280, 66, 66, 17280, 66, 17280, 33, 17280, 17280, 66, 33, 33, 17280, 66, 33, 66, 66, 17280, 66, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 17280, 17280, 33, 17280, 33, 66, 17280, 17280, 17280, 66, 33, 17280, 66, 33, 33, 33, 33, 33, 17280, 66, 33, 17280, 33, 17280, 33, 33, 66, 66, 17280, 66, 17280, 33, 66, 33, 17280, 17280, 33, 17280, 66, 33, 17280, 33, 33, 17280, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 33, 66, 17280, 17280, 33, 17280, 66, 33, 66, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 66, 17280, 17280, 66, 33, 17280, 33, 66, 66, 33, 66, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 66, 17280, 66, 33, 66, 17280, 66, 17280, 33, 17280, 33, 66, 17280, 66, 17280, 66, 17280, 66, 17280, 66, 33, 17280, 33, 17280, 66, 66, 33, 66, 17280, 66, 66, 17280, 33, 17280, 17280, 66, 33, 17280, 17280, 66, 66, 17280, 17280, 66, 66, 66, 66, 17280, 17280, 66, 66, 17280, 33, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 17280, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 17280, 66, 33, 33, 33, 33]
Prompts retrieved: 1494495 . Total input tokens: 333126301 . Total output tokens: 298768414
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 141.44303931482136,
    "estimated_duration": 3600.0780139146236,
    "input_throughput": 6441.008475476307,
    "output_throughput": 5683.266840584976,
    "total_throughput": 12124.275316061283,
    "itl": 150.80292923273123,
    "ttft": 1934119.0511388395,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 462,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5473210988193749,
    "arrivals": 498436,
    "finished_requests": 93728,
    "scheduler_time": 164.54467176092083
}
#Debug simulation 
Total elapsed time: 141.44315572688356. Arrivals time: 0.6489111273549497 Scheduler time: 140.55540396133438 Scheduler overhead time: 0.09591896925121546 Adapter cache time: 0.022753434721380472 Engine time: 0.09118548454716802 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-8/adapters_256_slots_64_rate_0.8-0.4-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-8/adapters_256_slots_64_rate_0.8-0.4-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 1080, 8640, 8640, 1080, 8640, 4320, 8640, 1080, 4320, 1080, 8640, 4320, 4320, 4320, 4320, 8640, 1080, 1080, 1080, 4320, 8640, 1080, 8640, 8640, 4320, 4320, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 1080, 8640, 8640, 4320, 1080, 1080, 8640, 4320, 1080, 4320, 4320, 8640, 4320, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 4320, 1080, 4320, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 8640, 8640, 1080, 8640, 1080, 4320, 8640, 8640, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 1080, 1080, 1080, 8640, 4320, 1080, 8640, 1080, 8640, 1080, 1080, 4320, 4320, 8640, 4320, 8640, 1080, 4320, 1080, 8640, 8640, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 1080, 4320, 8640, 8640, 1080, 8640, 4320, 1080, 4320, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 1080, 1080, 8640, 1080, 4320, 8640, 8640, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 8640, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 8640, 1080, 8640, 1080, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 8640, 4320, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 1080, 8640, 8640, 4320, 1080, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 8640, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 1080, 1080, 1080, 1080]
Prompts retrieved: 1202040 . Total input tokens: 267960373 . Total output tokens: 240348610
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 115.45011620689183,
    "estimated_duration": 3600.043970737827,
    "input_throughput": 6265.862357058067,
    "output_throughput": 5505.8596953574515,
    "total_throughput": 11771.722052415518,
    "itl": 152.40542828825568,
    "ttft": 1849375.0571486717,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 420,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2854048524517652,
    "arrivals": 401058,
    "finished_requests": 91021,
    "scheduler_time": 160.35654215361612
}
#Debug simulation 
Total elapsed time: 115.4502466688864. Arrivals time: 0.674277778249234 Scheduler time: 114.56266353046522 Scheduler overhead time: 0.08375589177012444 Adapter cache time: 0.02151233097538352 Engine time: 0.08259096648544073 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-16/adapters_256_slots_64_rate_0.8-0.4-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-16/adapters_256_slots_64_rate_0.8-0.4-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 1080, 8640, 8640, 1080, 8640, 4320, 8640, 1080, 4320, 1080, 8640, 4320, 4320, 4320, 4320, 8640, 1080, 1080, 1080, 4320, 8640, 1080, 8640, 8640, 4320, 4320, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 1080, 8640, 8640, 4320, 1080, 1080, 8640, 4320, 1080, 4320, 4320, 8640, 4320, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 4320, 1080, 4320, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 8640, 8640, 1080, 8640, 1080, 4320, 8640, 8640, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 1080, 1080, 1080, 8640, 4320, 1080, 8640, 1080, 8640, 1080, 1080, 4320, 4320, 8640, 4320, 8640, 1080, 4320, 1080, 8640, 8640, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 1080, 4320, 8640, 8640, 1080, 8640, 4320, 1080, 4320, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 1080, 1080, 8640, 1080, 4320, 8640, 8640, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 8640, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 8640, 1080, 8640, 1080, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 8640, 4320, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 1080, 8640, 8640, 4320, 1080, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 8640, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 1080, 1080, 1080, 1080]
Prompts retrieved: 1202040 . Total input tokens: 267960373 . Total output tokens: 240348610
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 115.88867945829406,
    "estimated_duration": 3600.16575611319,
    "input_throughput": 6275.21829005745,
    "output_throughput": 5520.72108520303,
    "total_throughput": 11795.939375260481,
    "itl": 152.17445866316837,
    "ttft": 1851439.5422444856,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 456,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4868587206443826,
    "arrivals": 401058,
    "finished_requests": 91201,
    "scheduler_time": 160.83860107656687
}
#Debug simulation 
Total elapsed time: 115.8888177331537. Arrivals time: 0.738718505948782 Scheduler time: 114.91856155358255 Scheduler overhead time: 0.09177865367382765 Adapter cache time: 0.023787760641425848 Engine time: 0.08842958277091384 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-32/adapters_256_slots_64_rate_0.8-0.4-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-32/adapters_256_slots_64_rate_0.8-0.4-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 1080, 8640, 8640, 1080, 8640, 4320, 8640, 1080, 4320, 1080, 8640, 4320, 4320, 4320, 4320, 8640, 1080, 1080, 1080, 4320, 8640, 1080, 8640, 8640, 4320, 4320, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 1080, 8640, 8640, 4320, 1080, 1080, 8640, 4320, 1080, 4320, 4320, 8640, 4320, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 4320, 1080, 4320, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 8640, 8640, 1080, 8640, 1080, 4320, 8640, 8640, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 1080, 1080, 1080, 8640, 4320, 1080, 8640, 1080, 8640, 1080, 1080, 4320, 4320, 8640, 4320, 8640, 1080, 4320, 1080, 8640, 8640, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 1080, 4320, 8640, 8640, 1080, 8640, 4320, 1080, 4320, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 1080, 1080, 8640, 1080, 4320, 8640, 8640, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 8640, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 8640, 1080, 8640, 1080, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 8640, 4320, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 1080, 8640, 8640, 4320, 1080, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 8640, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 1080, 1080, 1080, 1080]
Prompts retrieved: 1202040 . Total input tokens: 267960373 . Total output tokens: 240348610
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 115.67535167001188,
    "estimated_duration": 3600.1658357581564,
    "input_throughput": 6275.218151233415,
    "output_throughput": 5520.720963070422,
    "total_throughput": 11795.939114303837,
    "itl": 152.17441847397646,
    "ttft": 1851439.029312563,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 456,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4896933383867232,
    "arrivals": 401058,
    "finished_requests": 91201,
    "scheduler_time": 160.83840941338661
}
#Debug simulation 
Total elapsed time: 115.67550706071779. Arrivals time: 0.7358487057499588 Scheduler time: 114.70777409384027 Scheduler overhead time: 0.09233751660212874 Adapter cache time: 0.02362457849085331 Engine time: 0.08803617628291249 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-16-16/adapters_256_slots_64_rate_0.8-0.4-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-16-16/adapters_256_slots_64_rate_0.8-0.4-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 1080, 8640, 8640, 1080, 8640, 4320, 8640, 1080, 4320, 1080, 8640, 4320, 4320, 4320, 4320, 8640, 1080, 1080, 1080, 4320, 8640, 1080, 8640, 8640, 4320, 4320, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 1080, 8640, 8640, 4320, 1080, 1080, 8640, 4320, 1080, 4320, 4320, 8640, 4320, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 4320, 1080, 4320, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 8640, 8640, 1080, 8640, 1080, 4320, 8640, 8640, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 1080, 1080, 1080, 8640, 4320, 1080, 8640, 1080, 8640, 1080, 1080, 4320, 4320, 8640, 4320, 8640, 1080, 4320, 1080, 8640, 8640, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 1080, 4320, 8640, 8640, 1080, 8640, 4320, 1080, 4320, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 1080, 1080, 8640, 1080, 4320, 8640, 8640, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 8640, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 8640, 1080, 8640, 1080, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 8640, 4320, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 1080, 8640, 8640, 4320, 1080, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 8640, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 1080, 1080, 1080, 1080]
Prompts retrieved: 1202040 . Total input tokens: 267960373 . Total output tokens: 240348610
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 119.04153168899938,
    "estimated_duration": 3600.0628580933553,
    "input_throughput": 6252.910820541083,
    "output_throughput": 5507.489947134097,
    "total_throughput": 11760.40076767518,
    "itl": 152.70922558690862,
    "ttft": 1848262.0045042115,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 428,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.338579252073539,
    "arrivals": 401058,
    "finished_requests": 90959,
    "scheduler_time": 160.33494937860536
}
#Debug simulation 
Total elapsed time: 119.04166277311742. Arrivals time: 0.7193136527203023 Scheduler time: 118.09287934098393 Scheduler overhead time: 0.08960516657680273 Adapter cache time: 0.023458734154701233 Engine time: 0.08798506250604987 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-16-32/adapters_256_slots_64_rate_0.8-0.4-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-16-32/adapters_256_slots_64_rate_0.8-0.4-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 1080, 8640, 8640, 1080, 8640, 4320, 8640, 1080, 4320, 1080, 8640, 4320, 4320, 4320, 4320, 8640, 1080, 1080, 1080, 4320, 8640, 1080, 8640, 8640, 4320, 4320, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 1080, 8640, 8640, 4320, 1080, 1080, 8640, 4320, 1080, 4320, 4320, 8640, 4320, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 4320, 1080, 4320, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 8640, 8640, 1080, 8640, 1080, 4320, 8640, 8640, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 1080, 1080, 1080, 8640, 4320, 1080, 8640, 1080, 8640, 1080, 1080, 4320, 4320, 8640, 4320, 8640, 1080, 4320, 1080, 8640, 8640, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 1080, 4320, 8640, 8640, 1080, 8640, 4320, 1080, 4320, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 1080, 1080, 8640, 1080, 4320, 8640, 8640, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 8640, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 8640, 1080, 8640, 1080, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 8640, 4320, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 1080, 8640, 8640, 4320, 1080, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 8640, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 1080, 1080, 1080, 1080]
Prompts retrieved: 1202040 . Total input tokens: 267960373 . Total output tokens: 240348610
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 115.97605931898579,
    "estimated_duration": 3600.0151862234006,
    "input_throughput": 6275.341305906948,
    "output_throughput": 5520.801711075518,
    "total_throughput": 11796.143016982467,
    "itl": 152.17384330429434,
    "ttft": 1851429.694685223,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 456,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5084306525625333,
    "arrivals": 401058,
    "finished_requests": 91199,
    "scheduler_time": 160.8311269268687
}
#Debug simulation 
Total elapsed time: 115.9761909446679. Arrivals time: 0.7309897327795625 Scheduler time: 115.0161346718669 Scheduler overhead time: 0.0905729909427464 Adapter cache time: 0.02398168621584773 Engine time: 0.08776015881448984 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_16-16-16/adapters_256_slots_64_rate_0.8-0.4-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_16-16-16/adapters_256_slots_64_rate_0.8-0.4-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 1080, 8640, 8640, 1080, 8640, 4320, 8640, 1080, 4320, 1080, 8640, 4320, 4320, 4320, 4320, 8640, 1080, 1080, 1080, 4320, 8640, 1080, 8640, 8640, 4320, 4320, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 1080, 8640, 8640, 4320, 1080, 1080, 8640, 4320, 1080, 4320, 4320, 8640, 4320, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 4320, 1080, 4320, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 8640, 8640, 1080, 8640, 1080, 4320, 8640, 8640, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 1080, 1080, 1080, 8640, 4320, 1080, 8640, 1080, 8640, 1080, 1080, 4320, 4320, 8640, 4320, 8640, 1080, 4320, 1080, 8640, 8640, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 1080, 4320, 8640, 8640, 1080, 8640, 4320, 1080, 4320, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 1080, 1080, 8640, 1080, 4320, 8640, 8640, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 8640, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 8640, 1080, 8640, 1080, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 8640, 4320, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 1080, 8640, 8640, 4320, 1080, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 8640, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 1080, 1080, 1080, 1080]
Prompts retrieved: 1202040 . Total input tokens: 267960373 . Total output tokens: 240348610
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 118.29488573875278,
    "estimated_duration": 3600.161623928956,
    "input_throughput": 6250.216615398276,
    "output_throughput": 5505.90142071665,
    "total_throughput": 11756.118036114925,
    "itl": 152.30986328466483,
    "ttft": 1854275.3960228795,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 414,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2378808220894937,
    "arrivals": 401058,
    "finished_requests": 90845,
    "scheduler_time": 160.57981931896592
}
#Debug simulation 
Total elapsed time: 118.29502558289096. Arrivals time: 0.708139137364924 Scheduler time: 117.36757355835289 Scheduler overhead time: 0.08591555710881948 Adapter cache time: 0.022086381912231445 Engine time: 0.08451809454709291 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_16-16-32/adapters_256_slots_64_rate_0.8-0.4-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_16-16-32/adapters_256_slots_64_rate_0.8-0.4-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 1080, 8640, 8640, 1080, 8640, 4320, 8640, 1080, 4320, 1080, 8640, 4320, 4320, 4320, 4320, 8640, 1080, 1080, 1080, 4320, 8640, 1080, 8640, 8640, 4320, 4320, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 1080, 8640, 8640, 4320, 1080, 1080, 8640, 4320, 1080, 4320, 4320, 8640, 4320, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 4320, 1080, 4320, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 8640, 8640, 1080, 8640, 1080, 4320, 8640, 8640, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 1080, 1080, 1080, 8640, 4320, 1080, 8640, 1080, 8640, 1080, 1080, 4320, 4320, 8640, 4320, 8640, 1080, 4320, 1080, 8640, 8640, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 1080, 4320, 8640, 8640, 1080, 8640, 4320, 1080, 4320, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 1080, 1080, 8640, 1080, 4320, 8640, 8640, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 8640, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 8640, 1080, 8640, 1080, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 8640, 4320, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 1080, 8640, 8640, 4320, 1080, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 8640, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 1080, 1080, 1080, 1080]
Prompts retrieved: 1202040 . Total input tokens: 267960373 . Total output tokens: 240348610
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 115.96412777574733,
    "estimated_duration": 3600.0336893977014,
    "input_throughput": 6275.309052393787,
    "output_throughput": 5520.773335686521,
    "total_throughput": 11796.082388080307,
    "itl": 152.17448220521555,
    "ttft": 1851436.6703986085,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 456,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5276709818840026,
    "arrivals": 401058,
    "finished_requests": 91199,
    "scheduler_time": 160.8312251994662
}
#Debug simulation 
Total elapsed time: 115.96426289202645. Arrivals time: 0.7312429407611489 Scheduler time: 115.00179519783705 Scheduler overhead time: 0.09088092716410756 Adapter cache time: 0.02356122573837638 Engine time: 0.0883343149907887 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-8/adapters_256_slots_64_rate_0.8-0.4-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-8/adapters_256_slots_64_rate_0.8-0.4-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 540, 8640, 8640, 540, 8640, 4320, 8640, 540, 4320, 540, 8640, 4320, 4320, 4320, 4320, 8640, 540, 540, 540, 4320, 8640, 540, 8640, 8640, 4320, 4320, 4320, 540, 8640, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 8640, 4320, 540, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 540, 8640, 8640, 4320, 540, 540, 8640, 4320, 540, 4320, 4320, 8640, 4320, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 8640, 8640, 540, 8640, 540, 4320, 8640, 8640, 8640, 4320, 540, 8640, 4320, 540, 540, 540, 540, 540, 8640, 4320, 540, 8640, 540, 8640, 540, 540, 4320, 4320, 8640, 4320, 8640, 540, 4320, 540, 8640, 8640, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 540, 4320, 8640, 8640, 540, 8640, 4320, 540, 4320, 8640, 540, 540, 540, 540, 540, 540, 8640, 540, 540, 540, 8640, 540, 4320, 8640, 8640, 4320, 540, 8640, 540, 4320, 4320, 540, 4320, 540, 8640, 540, 540, 8640, 540, 8640, 8640, 4320, 8640, 4320, 540, 4320, 8640, 4320, 8640, 540, 8640, 540, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 540, 8640, 540, 8640, 4320, 4320, 540, 4320, 8640, 4320, 4320, 8640, 540, 8640, 8640, 4320, 540, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 540, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 8640, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 540, 540, 540, 540]
Prompts retrieved: 1156140 . Total input tokens: 257714928 . Total output tokens: 231188240
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 109.34905410697684,
    "estimated_duration": 3600.158271820799,
    "input_throughput": 6247.288675068427,
    "output_throughput": 5499.934032062908,
    "total_throughput": 11747.222707131335,
    "itl": 152.64732777923535,
    "ttft": 1845548.059256791,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 513,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5700302126375212,
    "arrivals": 385672,
    "finished_requests": 90655,
    "scheduler_time": 160.41062835231202
}
#Debug simulation 
Total elapsed time: 109.34918677806854. Arrivals time: 0.6979245487600565 Scheduler time: 108.435361742042 Scheduler overhead time: 0.08434801734983921 Adapter cache time: 0.024383888114243746 Engine time: 0.08073099562898278 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-16/adapters_256_slots_64_rate_0.8-0.4-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-16/adapters_256_slots_64_rate_0.8-0.4-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 540, 8640, 8640, 540, 8640, 4320, 8640, 540, 4320, 540, 8640, 4320, 4320, 4320, 4320, 8640, 540, 540, 540, 4320, 8640, 540, 8640, 8640, 4320, 4320, 4320, 540, 8640, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 8640, 4320, 540, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 540, 8640, 8640, 4320, 540, 540, 8640, 4320, 540, 4320, 4320, 8640, 4320, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 8640, 8640, 540, 8640, 540, 4320, 8640, 8640, 8640, 4320, 540, 8640, 4320, 540, 540, 540, 540, 540, 8640, 4320, 540, 8640, 540, 8640, 540, 540, 4320, 4320, 8640, 4320, 8640, 540, 4320, 540, 8640, 8640, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 540, 4320, 8640, 8640, 540, 8640, 4320, 540, 4320, 8640, 540, 540, 540, 540, 540, 540, 8640, 540, 540, 540, 8640, 540, 4320, 8640, 8640, 4320, 540, 8640, 540, 4320, 4320, 540, 4320, 540, 8640, 540, 540, 8640, 540, 8640, 8640, 4320, 8640, 4320, 540, 4320, 8640, 4320, 8640, 540, 8640, 540, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 540, 8640, 540, 8640, 4320, 4320, 540, 4320, 8640, 4320, 4320, 8640, 540, 8640, 8640, 4320, 540, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 540, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 8640, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 540, 540, 540, 540]
Prompts retrieved: 1156140 . Total input tokens: 257714928 . Total output tokens: 231188240
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 110.11157580604777,
    "estimated_duration": 3600.094463171697,
    "input_throughput": 6247.037468063071,
    "output_throughput": 5499.910128068126,
    "total_throughput": 11746.947596131198,
    "itl": 152.64968661914625,
    "ttft": 1845562.507367245,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 513,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6740439955098614,
    "arrivals": 385672,
    "finished_requests": 90652,
    "scheduler_time": 160.40454456788655
}
#Debug simulation 
Total elapsed time: 110.11170862289146. Arrivals time: 0.6943379533477128 Scheduler time: 109.1968817031011 Scheduler overhead time: 0.08591538108885288 Adapter cache time: 0.022687968332320452 Engine time: 0.08564978744834661 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-32/adapters_256_slots_64_rate_0.8-0.4-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-32/adapters_256_slots_64_rate_0.8-0.4-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 540, 8640, 8640, 540, 8640, 4320, 8640, 540, 4320, 540, 8640, 4320, 4320, 4320, 4320, 8640, 540, 540, 540, 4320, 8640, 540, 8640, 8640, 4320, 4320, 4320, 540, 8640, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 8640, 4320, 540, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 540, 8640, 8640, 4320, 540, 540, 8640, 4320, 540, 4320, 4320, 8640, 4320, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 8640, 8640, 540, 8640, 540, 4320, 8640, 8640, 8640, 4320, 540, 8640, 4320, 540, 540, 540, 540, 540, 8640, 4320, 540, 8640, 540, 8640, 540, 540, 4320, 4320, 8640, 4320, 8640, 540, 4320, 540, 8640, 8640, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 540, 4320, 8640, 8640, 540, 8640, 4320, 540, 4320, 8640, 540, 540, 540, 540, 540, 540, 8640, 540, 540, 540, 8640, 540, 4320, 8640, 8640, 4320, 540, 8640, 540, 4320, 4320, 540, 4320, 540, 8640, 540, 540, 8640, 540, 8640, 8640, 4320, 8640, 4320, 540, 4320, 8640, 4320, 8640, 540, 8640, 540, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 540, 8640, 540, 8640, 4320, 4320, 540, 4320, 8640, 4320, 4320, 8640, 540, 8640, 8640, 4320, 540, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 540, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 8640, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 540, 540, 540, 540]
Prompts retrieved: 1156140 . Total input tokens: 257714928 . Total output tokens: 231188240
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 110.46445626672357,
    "estimated_duration": 3600.097122007682,
    "input_throughput": 6247.03285434087,
    "output_throughput": 5499.906066133553,
    "total_throughput": 11746.938920474424,
    "itl": 152.64982673914673,
    "ttft": 1845563.2006700828,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 513,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6770010600425405,
    "arrivals": 385672,
    "finished_requests": 90652,
    "scheduler_time": 160.40452678736304
}
#Debug simulation 
Total elapsed time: 110.46457173582166. Arrivals time: 0.690645435359329 Scheduler time: 109.55596987111494 Scheduler overhead time: 0.08575656870380044 Adapter cache time: 0.02247985126450658 Engine time: 0.08286243071779609 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-16-16/adapters_256_slots_64_rate_0.8-0.4-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-16-16/adapters_256_slots_64_rate_0.8-0.4-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 540, 8640, 8640, 540, 8640, 4320, 8640, 540, 4320, 540, 8640, 4320, 4320, 4320, 4320, 8640, 540, 540, 540, 4320, 8640, 540, 8640, 8640, 4320, 4320, 4320, 540, 8640, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 8640, 4320, 540, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 540, 8640, 8640, 4320, 540, 540, 8640, 4320, 540, 4320, 4320, 8640, 4320, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 8640, 8640, 540, 8640, 540, 4320, 8640, 8640, 8640, 4320, 540, 8640, 4320, 540, 540, 540, 540, 540, 8640, 4320, 540, 8640, 540, 8640, 540, 540, 4320, 4320, 8640, 4320, 8640, 540, 4320, 540, 8640, 8640, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 540, 4320, 8640, 8640, 540, 8640, 4320, 540, 4320, 8640, 540, 540, 540, 540, 540, 540, 8640, 540, 540, 540, 8640, 540, 4320, 8640, 8640, 4320, 540, 8640, 540, 4320, 4320, 540, 4320, 540, 8640, 540, 540, 8640, 540, 8640, 8640, 4320, 8640, 4320, 540, 4320, 8640, 4320, 8640, 540, 8640, 540, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 540, 8640, 540, 8640, 4320, 4320, 540, 4320, 8640, 4320, 4320, 8640, 540, 8640, 8640, 4320, 540, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 540, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 8640, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 540, 540, 540, 540]
Prompts retrieved: 1156140 . Total input tokens: 257714928 . Total output tokens: 231188240
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 107.74660609290004,
    "estimated_duration": 3600.025182325815,
    "input_throughput": 6247.157689455457,
    "output_throughput": 5500.01597133495,
    "total_throughput": 11747.173660790408,
    "itl": 152.64816349554437,
    "ttft": 1845537.4043519646,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 513,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.605399982011871,
    "arrivals": 385672,
    "finished_requests": 90652,
    "scheduler_time": 160.4034186299229
}
#Debug simulation 
Total elapsed time: 107.74674148671329. Arrivals time: 0.7242608303204179 Scheduler time: 106.80000167293474 Scheduler overhead time: 0.08667053189128637 Adapter cache time: 0.023858968634158373 Engine time: 0.08379746414721012 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-16-32/adapters_256_slots_64_rate_0.8-0.4-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-16-32/adapters_256_slots_64_rate_0.8-0.4-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 540, 8640, 8640, 540, 8640, 4320, 8640, 540, 4320, 540, 8640, 4320, 4320, 4320, 4320, 8640, 540, 540, 540, 4320, 8640, 540, 8640, 8640, 4320, 4320, 4320, 540, 8640, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 8640, 4320, 540, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 540, 8640, 8640, 4320, 540, 540, 8640, 4320, 540, 4320, 4320, 8640, 4320, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 8640, 8640, 540, 8640, 540, 4320, 8640, 8640, 8640, 4320, 540, 8640, 4320, 540, 540, 540, 540, 540, 8640, 4320, 540, 8640, 540, 8640, 540, 540, 4320, 4320, 8640, 4320, 8640, 540, 4320, 540, 8640, 8640, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 540, 4320, 8640, 8640, 540, 8640, 4320, 540, 4320, 8640, 540, 540, 540, 540, 540, 540, 8640, 540, 540, 540, 8640, 540, 4320, 8640, 8640, 4320, 540, 8640, 540, 4320, 4320, 540, 4320, 540, 8640, 540, 540, 8640, 540, 8640, 8640, 4320, 8640, 4320, 540, 4320, 8640, 4320, 8640, 540, 8640, 540, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 540, 8640, 540, 8640, 4320, 4320, 540, 4320, 8640, 4320, 4320, 8640, 540, 8640, 8640, 4320, 540, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 540, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 8640, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 540, 540, 540, 540]
Prompts retrieved: 1156140 . Total input tokens: 257714928 . Total output tokens: 231188240
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 109.76971380598843,
    "estimated_duration": 3600.0918207689583,
    "input_throughput": 6247.042053276376,
    "output_throughput": 5499.914164903382,
    "total_throughput": 11746.956218179757,
    "itl": 152.65279588102786,
    "ttft": 1845551.8329482032,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 513,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6981276961602314,
    "arrivals": 385672,
    "finished_requests": 90652,
    "scheduler_time": 160.40177511042003
}
#Debug simulation 
Total elapsed time: 109.76984236296266. Arrivals time: 0.6809007660485804 Scheduler time: 108.86749463574961 Scheduler overhead time: 0.08645468950271606 Adapter cache time: 0.023309506475925446 Engine time: 0.0845134831033647 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_16-16-16/adapters_256_slots_64_rate_0.8-0.4-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_16-16-16/adapters_256_slots_64_rate_0.8-0.4-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 540, 8640, 8640, 540, 8640, 4320, 8640, 540, 4320, 540, 8640, 4320, 4320, 4320, 4320, 8640, 540, 540, 540, 4320, 8640, 540, 8640, 8640, 4320, 4320, 4320, 540, 8640, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 8640, 4320, 540, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 540, 8640, 8640, 4320, 540, 540, 8640, 4320, 540, 4320, 4320, 8640, 4320, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 8640, 8640, 540, 8640, 540, 4320, 8640, 8640, 8640, 4320, 540, 8640, 4320, 540, 540, 540, 540, 540, 8640, 4320, 540, 8640, 540, 8640, 540, 540, 4320, 4320, 8640, 4320, 8640, 540, 4320, 540, 8640, 8640, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 540, 4320, 8640, 8640, 540, 8640, 4320, 540, 4320, 8640, 540, 540, 540, 540, 540, 540, 8640, 540, 540, 540, 8640, 540, 4320, 8640, 8640, 4320, 540, 8640, 540, 4320, 4320, 540, 4320, 540, 8640, 540, 540, 8640, 540, 8640, 8640, 4320, 8640, 4320, 540, 4320, 8640, 4320, 8640, 540, 8640, 540, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 540, 8640, 540, 8640, 4320, 4320, 540, 4320, 8640, 4320, 4320, 8640, 540, 8640, 8640, 4320, 540, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 540, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 8640, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 540, 540, 540, 540]
Prompts retrieved: 1156140 . Total input tokens: 257714928 . Total output tokens: 231188240
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 108.50576145900413,
    "estimated_duration": 3600.1252511840594,
    "input_throughput": 6247.34597569981,
    "output_throughput": 5499.984477897732,
    "total_throughput": 11747.330453597542,
    "itl": 152.64582093969187,
    "ttft": 1845536.8634155518,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 513,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5338958012847985,
    "arrivals": 385672,
    "finished_requests": 90655,
    "scheduler_time": 160.4097020477035
}
#Debug simulation 
Total elapsed time: 108.50591754214838. Arrivals time: 0.7374834027141333 Scheduler time: 107.54914478771389 Scheduler overhead time: 0.08606284903362393 Adapter cache time: 0.02356888959184289 Engine time: 0.08296436630189419 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_16-16-32/adapters_256_slots_64_rate_0.8-0.4-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_16-16-32/adapters_256_slots_64_rate_0.8-0.4-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 540, 8640, 8640, 540, 8640, 4320, 8640, 540, 4320, 540, 8640, 4320, 4320, 4320, 4320, 8640, 540, 540, 540, 4320, 8640, 540, 8640, 8640, 4320, 4320, 4320, 540, 8640, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 8640, 4320, 540, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 540, 8640, 8640, 4320, 540, 540, 8640, 4320, 540, 4320, 4320, 8640, 4320, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 8640, 8640, 540, 8640, 540, 4320, 8640, 8640, 8640, 4320, 540, 8640, 4320, 540, 540, 540, 540, 540, 8640, 4320, 540, 8640, 540, 8640, 540, 540, 4320, 4320, 8640, 4320, 8640, 540, 4320, 540, 8640, 8640, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 540, 4320, 8640, 8640, 540, 8640, 4320, 540, 4320, 8640, 540, 540, 540, 540, 540, 540, 8640, 540, 540, 540, 8640, 540, 4320, 8640, 8640, 4320, 540, 8640, 540, 4320, 4320, 540, 4320, 540, 8640, 540, 540, 8640, 540, 8640, 8640, 4320, 8640, 4320, 540, 4320, 8640, 4320, 8640, 540, 8640, 540, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 540, 8640, 540, 8640, 4320, 4320, 540, 4320, 8640, 4320, 4320, 8640, 540, 8640, 8640, 4320, 540, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 540, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 8640, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 540, 540, 540, 540]
Prompts retrieved: 1156140 . Total input tokens: 257714928 . Total output tokens: 231188240
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 109.41479271790013,
    "estimated_duration": 3600.116430786359,
    "input_throughput": 6246.999349153721,
    "output_throughput": 5499.876568068417,
    "total_throughput": 11746.875917222138,
    "itl": 152.65352934576836,
    "ttft": 1845561.0121688608,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 513,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7201346087828255,
    "arrivals": 385672,
    "finished_requests": 90652,
    "scheduler_time": 160.40266878139926
}
#Debug simulation 
Total elapsed time: 109.41491788299754. Arrivals time: 0.6731733651831746 Scheduler time: 108.52202942362055 Scheduler overhead time: 0.08551791962236166 Adapter cache time: 0.02351780328899622 Engine time: 0.08429878810420632 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-8/adapters_256_slots_64_rate_0.8-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-8/adapters_256_slots_64_rate_0.8-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 270, 8640, 8640, 270, 8640, 4320, 8640, 270, 4320, 270, 8640, 4320, 4320, 4320, 4320, 8640, 270, 270, 270, 4320, 8640, 270, 8640, 8640, 4320, 4320, 4320, 270, 8640, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 8640, 4320, 270, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 270, 8640, 8640, 4320, 270, 270, 8640, 4320, 270, 4320, 4320, 8640, 4320, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 8640, 8640, 270, 8640, 270, 4320, 8640, 8640, 8640, 4320, 270, 8640, 4320, 270, 270, 270, 270, 270, 8640, 4320, 270, 8640, 270, 8640, 270, 270, 4320, 4320, 8640, 4320, 8640, 270, 4320, 270, 8640, 8640, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 270, 4320, 8640, 8640, 270, 8640, 4320, 270, 4320, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 4320, 8640, 8640, 4320, 270, 8640, 270, 4320, 4320, 270, 4320, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 4320, 8640, 4320, 270, 4320, 8640, 4320, 8640, 270, 8640, 270, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 270, 8640, 270, 8640, 4320, 4320, 270, 4320, 8640, 4320, 4320, 8640, 270, 8640, 8640, 4320, 270, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 270, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 8640, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 270, 270, 270, 270]
Prompts retrieved: 1133190 . Total input tokens: 252615163 . Total output tokens: 226586703
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 114.1198748620227,
    "estimated_duration": 3600.0371523204967,
    "input_throughput": 6206.95955473592,
    "output_throughput": 5494.795237668407,
    "total_throughput": 11701.754792404327,
    "itl": 152.9829391779403,
    "ttft": 1827762.024142639,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 499,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5271833842224611,
    "arrivals": 378122,
    "finished_requests": 90623,
    "scheduler_time": 160.48109068614832
}
#Debug simulation 
Total elapsed time: 114.11999780172482. Arrivals time: 0.7077357233501971 Scheduler time: 113.19035702897236 Scheduler overhead time: 0.08655802812427282 Adapter cache time: 0.024396414402872324 Engine time: 0.08355653751641512 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-16/adapters_256_slots_64_rate_0.8-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-16/adapters_256_slots_64_rate_0.8-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 270, 8640, 8640, 270, 8640, 4320, 8640, 270, 4320, 270, 8640, 4320, 4320, 4320, 4320, 8640, 270, 270, 270, 4320, 8640, 270, 8640, 8640, 4320, 4320, 4320, 270, 8640, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 8640, 4320, 270, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 270, 8640, 8640, 4320, 270, 270, 8640, 4320, 270, 4320, 4320, 8640, 4320, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 8640, 8640, 270, 8640, 270, 4320, 8640, 8640, 8640, 4320, 270, 8640, 4320, 270, 270, 270, 270, 270, 8640, 4320, 270, 8640, 270, 8640, 270, 270, 4320, 4320, 8640, 4320, 8640, 270, 4320, 270, 8640, 8640, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 270, 4320, 8640, 8640, 270, 8640, 4320, 270, 4320, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 4320, 8640, 8640, 4320, 270, 8640, 270, 4320, 4320, 270, 4320, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 4320, 8640, 4320, 270, 4320, 8640, 4320, 8640, 270, 8640, 270, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 270, 8640, 270, 8640, 4320, 4320, 270, 4320, 8640, 4320, 4320, 8640, 270, 8640, 8640, 4320, 270, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 270, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 8640, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 270, 270, 270, 270]
Prompts retrieved: 1133190 . Total input tokens: 252615163 . Total output tokens: 226586703
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 110.63371634297073,
    "estimated_duration": 3600.051856092167,
    "input_throughput": 6188.689466319067,
    "output_throughput": 5485.4318185950115,
    "total_throughput": 11674.12128491408,
    "itl": 152.85357380160977,
    "ttft": 1828696.9812804875,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 573,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.869382230623165,
    "arrivals": 378122,
    "finished_requests": 90376,
    "scheduler_time": 160.79044279170253
}
#Debug simulation 
Total elapsed time: 110.63384616794065. Arrivals time: 0.6963542997837067 Scheduler time: 109.71304775075987 Scheduler overhead time: 0.08666034182533622 Adapter cache time: 0.026095513254404068 Engine time: 0.08464963175356388 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-32/adapters_256_slots_64_rate_0.8-0.4-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-32/adapters_256_slots_64_rate_0.8-0.4-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 270, 8640, 8640, 270, 8640, 4320, 8640, 270, 4320, 270, 8640, 4320, 4320, 4320, 4320, 8640, 270, 270, 270, 4320, 8640, 270, 8640, 8640, 4320, 4320, 4320, 270, 8640, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 8640, 4320, 270, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 270, 8640, 8640, 4320, 270, 270, 8640, 4320, 270, 4320, 4320, 8640, 4320, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 8640, 8640, 270, 8640, 270, 4320, 8640, 8640, 8640, 4320, 270, 8640, 4320, 270, 270, 270, 270, 270, 8640, 4320, 270, 8640, 270, 8640, 270, 270, 4320, 4320, 8640, 4320, 8640, 270, 4320, 270, 8640, 8640, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 270, 4320, 8640, 8640, 270, 8640, 4320, 270, 4320, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 4320, 8640, 8640, 4320, 270, 8640, 270, 4320, 4320, 270, 4320, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 4320, 8640, 4320, 270, 4320, 8640, 4320, 8640, 270, 8640, 270, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 270, 8640, 270, 8640, 4320, 4320, 270, 4320, 8640, 4320, 4320, 8640, 270, 8640, 8640, 4320, 270, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 270, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 8640, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 270, 270, 270, 270]
Prompts retrieved: 1133190 . Total input tokens: 252615163 . Total output tokens: 226586703
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 110.07235617563128,
    "estimated_duration": 3600.0556964252264,
    "input_throughput": 6188.682864579884,
    "output_throughput": 5485.425967050775,
    "total_throughput": 11674.10883163066,
    "itl": 152.8536884191765,
    "ttft": 1828698.4454368246,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 573,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.872764843255293,
    "arrivals": 378122,
    "finished_requests": 90376,
    "scheduler_time": 160.79048279829863
}
#Debug simulation 
Total elapsed time: 110.07249486073852. Arrivals time: 0.6972455214709044 Scheduler time: 109.15390603942797 Scheduler overhead time: 0.08554136380553246 Adapter cache time: 0.025010515470057726 Engine time: 0.08440266875550151 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-16-16/adapters_256_slots_64_rate_0.8-0.4-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-16-16/adapters_256_slots_64_rate_0.8-0.4-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 270, 8640, 8640, 270, 8640, 4320, 8640, 270, 4320, 270, 8640, 4320, 4320, 4320, 4320, 8640, 270, 270, 270, 4320, 8640, 270, 8640, 8640, 4320, 4320, 4320, 270, 8640, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 8640, 4320, 270, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 270, 8640, 8640, 4320, 270, 270, 8640, 4320, 270, 4320, 4320, 8640, 4320, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 8640, 8640, 270, 8640, 270, 4320, 8640, 8640, 8640, 4320, 270, 8640, 4320, 270, 270, 270, 270, 270, 8640, 4320, 270, 8640, 270, 8640, 270, 270, 4320, 4320, 8640, 4320, 8640, 270, 4320, 270, 8640, 8640, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 270, 4320, 8640, 8640, 270, 8640, 4320, 270, 4320, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 4320, 8640, 8640, 4320, 270, 8640, 270, 4320, 4320, 270, 4320, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 4320, 8640, 4320, 270, 4320, 8640, 4320, 8640, 270, 8640, 270, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 270, 8640, 270, 8640, 4320, 4320, 270, 4320, 8640, 4320, 4320, 8640, 270, 8640, 8640, 4320, 270, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 270, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 8640, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 270, 270, 270, 270]
Prompts retrieved: 1133190 . Total input tokens: 252615163 . Total output tokens: 226586703
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 114.53012174414471,
    "estimated_duration": 3600.065620920624,
    "input_throughput": 6206.910471339067,
    "output_throughput": 5494.75178592478,
    "total_throughput": 11701.662257263846,
    "itl": 152.98387225464674,
    "ttft": 1827771.4148840439,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 499,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5574103481066346,
    "arrivals": 378122,
    "finished_requests": 90623,
    "scheduler_time": 160.48114078216236
}
#Debug simulation 
Total elapsed time: 114.53026753012091. Arrivals time: 0.6733680847100914 Scheduler time: 113.63356822729111 Scheduler overhead time: 0.0878035044297576 Adapter cache time: 0.023693039547652006 Engine time: 0.08461709367111325 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-16-32/adapters_256_slots_64_rate_0.8-0.4-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-16-32/adapters_256_slots_64_rate_0.8-0.4-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 270, 8640, 8640, 270, 8640, 4320, 8640, 270, 4320, 270, 8640, 4320, 4320, 4320, 4320, 8640, 270, 270, 270, 4320, 8640, 270, 8640, 8640, 4320, 4320, 4320, 270, 8640, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 8640, 4320, 270, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 270, 8640, 8640, 4320, 270, 270, 8640, 4320, 270, 4320, 4320, 8640, 4320, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 8640, 8640, 270, 8640, 270, 4320, 8640, 8640, 8640, 4320, 270, 8640, 4320, 270, 270, 270, 270, 270, 8640, 4320, 270, 8640, 270, 8640, 270, 270, 4320, 4320, 8640, 4320, 8640, 270, 4320, 270, 8640, 8640, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 270, 4320, 8640, 8640, 270, 8640, 4320, 270, 4320, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 4320, 8640, 8640, 4320, 270, 8640, 270, 4320, 4320, 270, 4320, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 4320, 8640, 4320, 270, 4320, 8640, 4320, 8640, 270, 8640, 270, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 270, 8640, 270, 8640, 4320, 4320, 270, 4320, 8640, 4320, 4320, 8640, 270, 8640, 8640, 4320, 270, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 270, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 8640, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 270, 270, 270, 270]
Prompts retrieved: 1133190 . Total input tokens: 252615163 . Total output tokens: 226586703
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 108.59755654586479,
    "estimated_duration": 3600.1332771549773,
    "input_throughput": 6213.215811187062,
    "output_throughput": 5505.879775557741,
    "total_throughput": 11719.095586744803,
    "itl": 153.6791448523056,
    "ttft": 1833338.5865769626,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 542,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.795609754528854,
    "arrivals": 378122,
    "finished_requests": 90631,
    "scheduler_time": 159.95762824553256
}
#Debug simulation 
Total elapsed time: 108.59768258687109. Arrivals time: 0.6754915229976177 Scheduler time: 107.69998898450285 Scheduler overhead time: 0.08632520353421569 Adapter cache time: 0.024815239012241364 Engine time: 0.08485287660732865 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_16-16-16/adapters_256_slots_64_rate_0.8-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_16-16-16/adapters_256_slots_64_rate_0.8-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 270, 8640, 8640, 270, 8640, 4320, 8640, 270, 4320, 270, 8640, 4320, 4320, 4320, 4320, 8640, 270, 270, 270, 4320, 8640, 270, 8640, 8640, 4320, 4320, 4320, 270, 8640, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 8640, 4320, 270, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 270, 8640, 8640, 4320, 270, 270, 8640, 4320, 270, 4320, 4320, 8640, 4320, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 8640, 8640, 270, 8640, 270, 4320, 8640, 8640, 8640, 4320, 270, 8640, 4320, 270, 270, 270, 270, 270, 8640, 4320, 270, 8640, 270, 8640, 270, 270, 4320, 4320, 8640, 4320, 8640, 270, 4320, 270, 8640, 8640, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 270, 4320, 8640, 8640, 270, 8640, 4320, 270, 4320, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 4320, 8640, 8640, 4320, 270, 8640, 270, 4320, 4320, 270, 4320, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 4320, 8640, 4320, 270, 4320, 8640, 4320, 8640, 270, 8640, 270, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 270, 8640, 270, 8640, 4320, 4320, 270, 4320, 8640, 4320, 4320, 8640, 270, 8640, 8640, 4320, 270, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 270, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 8640, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 270, 270, 270, 270]
Prompts retrieved: 1133190 . Total input tokens: 252615163 . Total output tokens: 226586703
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 116.51801437698305,
    "estimated_duration": 3600.0007155867906,
    "input_throughput": 6207.022377315771,
    "output_throughput": 5494.850852210365,
    "total_throughput": 11701.873229526136,
    "itl": 152.9823061650724,
    "ttft": 1827747.3989660637,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 499,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4920350971561696,
    "arrivals": 378122,
    "finished_requests": 90623,
    "scheduler_time": 160.48066359302908
}
#Debug simulation 
Total elapsed time: 116.51814289437607. Arrivals time: 0.7220743433572352 Scheduler time: 115.56909221131355 Scheduler overhead time: 0.08897639019414783 Adapter cache time: 0.023515849839895964 Engine time: 0.08658238127827644 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_16-16-32/adapters_256_slots_64_rate_0.8-0.4-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_16-16-32/adapters_256_slots_64_rate_0.8-0.4-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 270, 8640, 8640, 270, 8640, 4320, 8640, 270, 4320, 270, 8640, 4320, 4320, 4320, 4320, 8640, 270, 270, 270, 4320, 8640, 270, 8640, 8640, 4320, 4320, 4320, 270, 8640, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 8640, 4320, 270, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 270, 8640, 8640, 4320, 270, 270, 8640, 4320, 270, 4320, 4320, 8640, 4320, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 8640, 8640, 270, 8640, 270, 4320, 8640, 8640, 8640, 4320, 270, 8640, 4320, 270, 270, 270, 270, 270, 8640, 4320, 270, 8640, 270, 8640, 270, 270, 4320, 4320, 8640, 4320, 8640, 270, 4320, 270, 8640, 8640, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 270, 4320, 8640, 8640, 270, 8640, 4320, 270, 4320, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 4320, 8640, 8640, 4320, 270, 8640, 270, 4320, 4320, 270, 4320, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 4320, 8640, 4320, 270, 4320, 8640, 4320, 8640, 270, 8640, 270, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 270, 8640, 270, 8640, 4320, 4320, 270, 4320, 8640, 4320, 4320, 8640, 270, 8640, 8640, 4320, 270, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 270, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 8640, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 270, 270, 270, 270]
Prompts retrieved: 1133190 . Total input tokens: 252615163 . Total output tokens: 226586703
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 108.78356646280736,
    "estimated_duration": 3600.154874783876,
    "input_throughput": 6213.178537588002,
    "output_throughput": 5505.846745326462,
    "total_throughput": 11719.025282914465,
    "itl": 153.67975527584755,
    "ttft": 1833345.7241165969,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 542,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.818119682297107,
    "arrivals": 378122,
    "finished_requests": 90631,
    "scheduler_time": 159.95771266185773
}
#Debug simulation 
Total elapsed time: 108.78368091210723. Arrivals time: 0.6809521606191993 Scheduler time: 107.88083587400615 Scheduler overhead time: 0.08591337082907557 Adapter cache time: 0.024327747523784637 Engine time: 0.08479479188099504 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-8/adapters_256_slots_64_rate_0.8-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-8/adapters_256_slots_64_rate_0.8-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 135, 8640, 8640, 135, 8640, 4320, 8640, 135, 4320, 135, 8640, 4320, 4320, 4320, 4320, 8640, 135, 135, 135, 4320, 8640, 135, 8640, 8640, 4320, 4320, 4320, 135, 8640, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 8640, 4320, 135, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 135, 8640, 8640, 4320, 135, 135, 8640, 4320, 135, 4320, 4320, 8640, 4320, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 8640, 8640, 135, 8640, 135, 4320, 8640, 8640, 8640, 4320, 135, 8640, 4320, 135, 135, 135, 135, 135, 8640, 4320, 135, 8640, 135, 8640, 135, 135, 4320, 4320, 8640, 4320, 8640, 135, 4320, 135, 8640, 8640, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 135, 4320, 8640, 8640, 135, 8640, 4320, 135, 4320, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 4320, 8640, 8640, 4320, 135, 8640, 135, 4320, 4320, 135, 4320, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 4320, 8640, 4320, 135, 4320, 8640, 4320, 8640, 135, 8640, 135, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 135, 8640, 135, 8640, 4320, 4320, 135, 4320, 8640, 4320, 4320, 8640, 135, 8640, 8640, 4320, 135, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 135, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 8640, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 135, 135, 135, 135]
Prompts retrieved: 1121715 . Total input tokens: 250060486 . Total output tokens: 224302544
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 112.98264906136319,
    "estimated_duration": 3600.0359740486965,
    "input_throughput": 6223.871972812936,
    "output_throughput": 5511.2157609044,
    "total_throughput": 11735.087733717335,
    "itl": 153.74963234191938,
    "ttft": 1832708.9445783808,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 621,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.90056288898227,
    "arrivals": 374287,
    "finished_requests": 90515,
    "scheduler_time": 159.48414949870502
}
#Debug simulation 
Total elapsed time: 112.98278357600793. Arrivals time: 0.771762459538877 Scheduler time: 111.9835404115729 Scheduler overhead time: 0.0884407008998096 Adapter cache time: 0.025471267756074667 Engine time: 0.08623688668012619 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-16/adapters_256_slots_64_rate_0.8-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-16/adapters_256_slots_64_rate_0.8-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 135, 8640, 8640, 135, 8640, 4320, 8640, 135, 4320, 135, 8640, 4320, 4320, 4320, 4320, 8640, 135, 135, 135, 4320, 8640, 135, 8640, 8640, 4320, 4320, 4320, 135, 8640, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 8640, 4320, 135, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 135, 8640, 8640, 4320, 135, 135, 8640, 4320, 135, 4320, 4320, 8640, 4320, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 8640, 8640, 135, 8640, 135, 4320, 8640, 8640, 8640, 4320, 135, 8640, 4320, 135, 135, 135, 135, 135, 8640, 4320, 135, 8640, 135, 8640, 135, 135, 4320, 4320, 8640, 4320, 8640, 135, 4320, 135, 8640, 8640, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 135, 4320, 8640, 8640, 135, 8640, 4320, 135, 4320, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 4320, 8640, 8640, 4320, 135, 8640, 135, 4320, 4320, 135, 4320, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 4320, 8640, 4320, 135, 4320, 8640, 4320, 8640, 135, 8640, 135, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 135, 8640, 135, 8640, 4320, 4320, 135, 4320, 8640, 4320, 4320, 8640, 135, 8640, 8640, 4320, 135, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 135, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 8640, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 135, 135, 135, 135]
Prompts retrieved: 1121715 . Total input tokens: 250060486 . Total output tokens: 224302544
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 110.69395738607273,
    "estimated_duration": 3600.0304723356116,
    "input_throughput": 6219.929295618617,
    "output_throughput": 5511.8572335657045,
    "total_throughput": 11731.78652918432,
    "itl": 153.65539765466787,
    "ttft": 1832891.150022801,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 592,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9310963300475905,
    "arrivals": 374287,
    "finished_requests": 90478,
    "scheduler_time": 159.561298001384
}
#Debug simulation 
Total elapsed time: 110.69409081805497. Arrivals time: 0.7709097806364298 Scheduler time: 109.69471875065938 Scheduler overhead time: 0.08923271391540766 Adapter cache time: 0.025258314330130816 Engine time: 0.08667492819949985 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-32/adapters_256_slots_64_rate_0.8-0.4-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-32/adapters_256_slots_64_rate_0.8-0.4-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 135, 8640, 8640, 135, 8640, 4320, 8640, 135, 4320, 135, 8640, 4320, 4320, 4320, 4320, 8640, 135, 135, 135, 4320, 8640, 135, 8640, 8640, 4320, 4320, 4320, 135, 8640, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 8640, 4320, 135, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 135, 8640, 8640, 4320, 135, 135, 8640, 4320, 135, 4320, 4320, 8640, 4320, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 8640, 8640, 135, 8640, 135, 4320, 8640, 8640, 8640, 4320, 135, 8640, 4320, 135, 135, 135, 135, 135, 8640, 4320, 135, 8640, 135, 8640, 135, 135, 4320, 4320, 8640, 4320, 8640, 135, 4320, 135, 8640, 8640, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 135, 4320, 8640, 8640, 135, 8640, 4320, 135, 4320, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 4320, 8640, 8640, 4320, 135, 8640, 135, 4320, 4320, 135, 4320, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 4320, 8640, 4320, 135, 4320, 8640, 4320, 8640, 135, 8640, 135, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 135, 8640, 135, 8640, 4320, 4320, 135, 4320, 8640, 4320, 4320, 8640, 135, 8640, 8640, 4320, 135, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 135, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 8640, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 135, 135, 135, 135]
Prompts retrieved: 1121715 . Total input tokens: 250060486 . Total output tokens: 224302544
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 109.64386518206447,
    "estimated_duration": 3600.034324949759,
    "input_throughput": 6219.922639296639,
    "output_throughput": 5511.851334994401,
    "total_throughput": 11731.773974291042,
    "itl": 153.65554316866147,
    "ttft": 1832892.5870173576,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 592,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9346386713162185,
    "arrivals": 374287,
    "finished_requests": 90478,
    "scheduler_time": 159.56132979836474
}
#Debug simulation 
Total elapsed time: 109.64399904804304. Arrivals time: 0.6961936857551336 Scheduler time: 108.72637732839212 Scheduler overhead time: 0.08577739400789142 Adapter cache time: 0.02488754875957966 Engine time: 0.08368850033730268 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-16/adapters_256_slots_64_rate_0.8-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-16/adapters_256_slots_64_rate_0.8-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 135, 8640, 8640, 135, 8640, 4320, 8640, 135, 4320, 135, 8640, 4320, 4320, 4320, 4320, 8640, 135, 135, 135, 4320, 8640, 135, 8640, 8640, 4320, 4320, 4320, 135, 8640, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 8640, 4320, 135, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 135, 8640, 8640, 4320, 135, 135, 8640, 4320, 135, 4320, 4320, 8640, 4320, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 8640, 8640, 135, 8640, 135, 4320, 8640, 8640, 8640, 4320, 135, 8640, 4320, 135, 135, 135, 135, 135, 8640, 4320, 135, 8640, 135, 8640, 135, 135, 4320, 4320, 8640, 4320, 8640, 135, 4320, 135, 8640, 8640, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 135, 4320, 8640, 8640, 135, 8640, 4320, 135, 4320, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 4320, 8640, 8640, 4320, 135, 8640, 135, 4320, 4320, 135, 4320, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 4320, 8640, 4320, 135, 4320, 8640, 4320, 8640, 135, 8640, 135, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 135, 8640, 135, 8640, 4320, 4320, 135, 4320, 8640, 4320, 4320, 8640, 135, 8640, 8640, 4320, 135, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 135, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 8640, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 135, 135, 135, 135]
Prompts retrieved: 1121715 . Total input tokens: 250060486 . Total output tokens: 224302544
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 111.804943326395,
    "estimated_duration": 3600.062922972859,
    "input_throughput": 6229.246121476491,
    "output_throughput": 5514.895273998432,
    "total_throughput": 11744.141395474922,
    "itl": 153.63207613489118,
    "ttft": 1830133.027465243,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 567,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7725830323947496,
    "arrivals": 374287,
    "finished_requests": 90640,
    "scheduler_time": 159.49844516610392
}
#Debug simulation 
Total elapsed time: 111.80507517512888. Arrivals time: 0.7569143013097346 Scheduler time: 110.82363796047866 Scheduler overhead time: 0.08609540201723576 Adapter cache time: 0.02540651150047779 Engine time: 0.08530541742220521 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-32/adapters_256_slots_64_rate_0.8-0.4-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-32/adapters_256_slots_64_rate_0.8-0.4-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 135, 8640, 8640, 135, 8640, 4320, 8640, 135, 4320, 135, 8640, 4320, 4320, 4320, 4320, 8640, 135, 135, 135, 4320, 8640, 135, 8640, 8640, 4320, 4320, 4320, 135, 8640, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 8640, 4320, 135, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 135, 8640, 8640, 4320, 135, 135, 8640, 4320, 135, 4320, 4320, 8640, 4320, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 8640, 8640, 135, 8640, 135, 4320, 8640, 8640, 8640, 4320, 135, 8640, 4320, 135, 135, 135, 135, 135, 8640, 4320, 135, 8640, 135, 8640, 135, 135, 4320, 4320, 8640, 4320, 8640, 135, 4320, 135, 8640, 8640, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 135, 4320, 8640, 8640, 135, 8640, 4320, 135, 4320, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 4320, 8640, 8640, 4320, 135, 8640, 135, 4320, 4320, 135, 4320, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 4320, 8640, 4320, 135, 4320, 8640, 4320, 8640, 135, 8640, 135, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 135, 8640, 135, 8640, 4320, 4320, 135, 4320, 8640, 4320, 4320, 8640, 135, 8640, 8640, 4320, 135, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 135, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 8640, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 135, 135, 135, 135]
Prompts retrieved: 1121715 . Total input tokens: 250060486 . Total output tokens: 224302544
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 114.04702388495207,
    "estimated_duration": 3600.1062979179915,
    "input_throughput": 6224.327046387242,
    "output_throughput": 5508.092083688722,
    "total_throughput": 11732.419130075963,
    "itl": 153.4829350514839,
    "ttft": 1827236.5377126732,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 555,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8389252358675037,
    "arrivals": 374287,
    "finished_requests": 90453,
    "scheduler_time": 159.85345210711228
}
#Debug simulation 
Total elapsed time: 114.04715137230232. Arrivals time: 0.7684352532960474 Scheduler time: 113.04874509200454 Scheduler overhead time: 0.08921383647248149 Adapter cache time: 0.025001045782119036 Engine time: 0.08784671872854233 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-16/adapters_256_slots_64_rate_0.8-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-16/adapters_256_slots_64_rate_0.8-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 135, 8640, 8640, 135, 8640, 4320, 8640, 135, 4320, 135, 8640, 4320, 4320, 4320, 4320, 8640, 135, 135, 135, 4320, 8640, 135, 8640, 8640, 4320, 4320, 4320, 135, 8640, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 8640, 4320, 135, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 135, 8640, 8640, 4320, 135, 135, 8640, 4320, 135, 4320, 4320, 8640, 4320, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 8640, 8640, 135, 8640, 135, 4320, 8640, 8640, 8640, 4320, 135, 8640, 4320, 135, 135, 135, 135, 135, 8640, 4320, 135, 8640, 135, 8640, 135, 135, 4320, 4320, 8640, 4320, 8640, 135, 4320, 135, 8640, 8640, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 135, 4320, 8640, 8640, 135, 8640, 4320, 135, 4320, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 4320, 8640, 8640, 4320, 135, 8640, 135, 4320, 4320, 135, 4320, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 4320, 8640, 4320, 135, 4320, 8640, 4320, 8640, 135, 8640, 135, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 135, 8640, 135, 8640, 4320, 4320, 135, 4320, 8640, 4320, 4320, 8640, 135, 8640, 8640, 4320, 135, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 135, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 8640, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 135, 135, 135, 135]
Prompts retrieved: 1121715 . Total input tokens: 250060486 . Total output tokens: 224302544
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 119.3749851770699,
    "estimated_duration": 3600.1686645658756,
    "input_throughput": 6224.266996308103,
    "output_throughput": 5511.712047077875,
    "total_throughput": 11735.979043385978,
    "itl": 153.74951892253694,
    "ttft": 1832686.0068889838,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 621,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.856821233134222,
    "arrivals": 374287,
    "finished_requests": 90523,
    "scheduler_time": 159.49121754396603
}
#Debug simulation 
Total elapsed time: 119.37510821595788. Arrivals time: 0.8002248862758279 Scheduler time: 118.32479889225215 Scheduler overhead time: 0.09749969048425555 Adapter cache time: 0.02849114267155528 Engine time: 0.095327855553478 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-32/adapters_256_slots_64_rate_0.8-0.4-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-32/adapters_256_slots_64_rate_0.8-0.4-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 135, 8640, 8640, 135, 8640, 4320, 8640, 135, 4320, 135, 8640, 4320, 4320, 4320, 4320, 8640, 135, 135, 135, 4320, 8640, 135, 8640, 8640, 4320, 4320, 4320, 135, 8640, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 8640, 4320, 135, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 135, 8640, 8640, 4320, 135, 135, 8640, 4320, 135, 4320, 4320, 8640, 4320, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 8640, 8640, 135, 8640, 135, 4320, 8640, 8640, 8640, 4320, 135, 8640, 4320, 135, 135, 135, 135, 135, 8640, 4320, 135, 8640, 135, 8640, 135, 135, 4320, 4320, 8640, 4320, 8640, 135, 4320, 135, 8640, 8640, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 135, 4320, 8640, 8640, 135, 8640, 4320, 135, 4320, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 4320, 8640, 8640, 4320, 135, 8640, 135, 4320, 4320, 135, 4320, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 4320, 8640, 4320, 135, 4320, 8640, 4320, 8640, 135, 8640, 135, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 135, 8640, 135, 8640, 4320, 4320, 135, 4320, 8640, 4320, 4320, 8640, 135, 8640, 8640, 4320, 135, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 135, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 8640, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 135, 135, 135, 135]
Prompts retrieved: 1121715 . Total input tokens: 250060486 . Total output tokens: 224302544
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 114.26719248620793,
    "estimated_duration": 3600.1302082559496,
    "input_throughput": 6224.285707392642,
    "output_throughput": 5508.055501583185,
    "total_throughput": 11732.341208975826,
    "itl": 153.48332301547632,
    "ttft": 1827244.9832409953,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 555,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8623154401406605,
    "arrivals": 374287,
    "finished_requests": 90453,
    "scheduler_time": 159.85370656054135
}
#Debug simulation 
Total elapsed time: 114.26732893893495. Arrivals time: 0.7150569800287485 Scheduler time: 113.32525352947414 Scheduler overhead time: 0.08759420225396752 Adapter cache time: 0.024891437496989965 Engine time: 0.08752462267875671 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-8/adapters_256_slots_64_rate_0.8-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-8/adapters_256_slots_64_rate_0.8-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 66, 8640, 8640, 66, 8640, 4320, 8640, 66, 4320, 66, 8640, 4320, 4320, 4320, 4320, 8640, 66, 66, 66, 4320, 8640, 66, 8640, 8640, 4320, 4320, 4320, 66, 8640, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 8640, 4320, 66, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 66, 8640, 8640, 4320, 66, 66, 8640, 4320, 66, 4320, 4320, 8640, 4320, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 8640, 8640, 66, 8640, 66, 4320, 8640, 8640, 8640, 4320, 66, 8640, 4320, 66, 66, 66, 66, 66, 8640, 4320, 66, 8640, 66, 8640, 66, 66, 4320, 4320, 8640, 4320, 8640, 66, 4320, 66, 8640, 8640, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 66, 4320, 8640, 8640, 66, 8640, 4320, 66, 4320, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 4320, 8640, 8640, 4320, 66, 8640, 66, 4320, 4320, 66, 4320, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 4320, 8640, 4320, 66, 4320, 8640, 4320, 8640, 66, 8640, 66, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 66, 8640, 66, 8640, 4320, 4320, 66, 4320, 8640, 4320, 4320, 8640, 66, 8640, 8640, 4320, 66, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 66, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 8640, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 66, 66, 66, 66]
Prompts retrieved: 1115850 . Total input tokens: 248770296 . Total output tokens: 223140963
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 107.36924088280648,
    "estimated_duration": 3600.0959823447874,
    "input_throughput": 6211.944100844309,
    "output_throughput": 5524.622981592267,
    "total_throughput": 11736.567082436575,
    "itl": 153.68662730047876,
    "ttft": 1841178.7084890518,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 510,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5608487494057226,
    "arrivals": 372356,
    "finished_requests": 90478,
    "scheduler_time": 159.66417180971956
}
#Debug simulation 
Total elapsed time: 107.3693772079423. Arrivals time: 0.7007686025463045 Scheduler time: 106.45108572114259 Scheduler overhead time: 0.0842707073315978 Adapter cache time: 0.022072714287787676 Engine time: 0.08461658889427781 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-16/adapters_256_slots_64_rate_0.8-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-16/adapters_256_slots_64_rate_0.8-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 66, 8640, 8640, 66, 8640, 4320, 8640, 66, 4320, 66, 8640, 4320, 4320, 4320, 4320, 8640, 66, 66, 66, 4320, 8640, 66, 8640, 8640, 4320, 4320, 4320, 66, 8640, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 8640, 4320, 66, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 66, 8640, 8640, 4320, 66, 66, 8640, 4320, 66, 4320, 4320, 8640, 4320, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 8640, 8640, 66, 8640, 66, 4320, 8640, 8640, 8640, 4320, 66, 8640, 4320, 66, 66, 66, 66, 66, 8640, 4320, 66, 8640, 66, 8640, 66, 66, 4320, 4320, 8640, 4320, 8640, 66, 4320, 66, 8640, 8640, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 66, 4320, 8640, 8640, 66, 8640, 4320, 66, 4320, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 4320, 8640, 8640, 4320, 66, 8640, 66, 4320, 4320, 66, 4320, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 4320, 8640, 4320, 66, 4320, 8640, 4320, 8640, 66, 8640, 66, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 66, 8640, 66, 8640, 4320, 4320, 66, 4320, 8640, 4320, 4320, 8640, 66, 8640, 8640, 4320, 66, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 66, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 8640, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 66, 66, 66, 66]
Prompts retrieved: 1115850 . Total input tokens: 248770296 . Total output tokens: 223140963
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 107.3177851731889,
    "estimated_duration": 3600.1506801442856,
    "input_throughput": 6211.442516373725,
    "output_throughput": 5524.533489582411,
    "total_throughput": 11735.976005956136,
    "itl": 153.91404953271135,
    "ttft": 1841069.1328533753,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 499,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6272801475599472,
    "arrivals": 372356,
    "finished_requests": 90511,
    "scheduler_time": 159.43919898991237
}
#Debug simulation 
Total elapsed time: 107.31792000634596. Arrivals time: 0.7178374663926661 Scheduler time: 106.38175059156492 Scheduler overhead time: 0.08599859708920121 Adapter cache time: 0.02251497283577919 Engine time: 0.08269199915230274 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-32/adapters_256_slots_64_rate_0.8-0.4-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-32/adapters_256_slots_64_rate_0.8-0.4-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 66, 8640, 8640, 66, 8640, 4320, 8640, 66, 4320, 66, 8640, 4320, 4320, 4320, 4320, 8640, 66, 66, 66, 4320, 8640, 66, 8640, 8640, 4320, 4320, 4320, 66, 8640, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 8640, 4320, 66, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 66, 8640, 8640, 4320, 66, 66, 8640, 4320, 66, 4320, 4320, 8640, 4320, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 8640, 8640, 66, 8640, 66, 4320, 8640, 8640, 8640, 4320, 66, 8640, 4320, 66, 66, 66, 66, 66, 8640, 4320, 66, 8640, 66, 8640, 66, 66, 4320, 4320, 8640, 4320, 8640, 66, 4320, 66, 8640, 8640, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 66, 4320, 8640, 8640, 66, 8640, 4320, 66, 4320, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 4320, 8640, 8640, 4320, 66, 8640, 66, 4320, 4320, 66, 4320, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 4320, 8640, 4320, 66, 4320, 8640, 4320, 8640, 66, 8640, 66, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 66, 8640, 66, 8640, 4320, 4320, 66, 4320, 8640, 4320, 4320, 8640, 66, 8640, 8640, 4320, 66, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 66, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 8640, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 66, 66, 66, 66]
Prompts retrieved: 1115850 . Total input tokens: 248770296 . Total output tokens: 223140963
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 108.02697615418583,
    "estimated_duration": 3600.153757958139,
    "input_throughput": 6211.437206138354,
    "output_throughput": 5524.528766593658,
    "total_throughput": 11735.965972732012,
    "itl": 153.9141493082384,
    "ttft": 1841070.3271511581,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 499,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6303448262252012,
    "arrivals": 372356,
    "finished_requests": 90511,
    "scheduler_time": 159.43921212507388
}
#Debug simulation 
Total elapsed time: 108.0271173180081. Arrivals time: 0.7504729651845992 Scheduler time: 107.05040488019586 Scheduler overhead time: 0.08856852632015944 Adapter cache time: 0.022708529606461525 Engine time: 0.08786376425996423 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-16/adapters_256_slots_64_rate_0.8-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-16/adapters_256_slots_64_rate_0.8-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 66, 8640, 8640, 66, 8640, 4320, 8640, 66, 4320, 66, 8640, 4320, 4320, 4320, 4320, 8640, 66, 66, 66, 4320, 8640, 66, 8640, 8640, 4320, 4320, 4320, 66, 8640, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 8640, 4320, 66, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 66, 8640, 8640, 4320, 66, 66, 8640, 4320, 66, 4320, 4320, 8640, 4320, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 8640, 8640, 66, 8640, 66, 4320, 8640, 8640, 8640, 4320, 66, 8640, 4320, 66, 66, 66, 66, 66, 8640, 4320, 66, 8640, 66, 8640, 66, 66, 4320, 4320, 8640, 4320, 8640, 66, 4320, 66, 8640, 8640, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 66, 4320, 8640, 8640, 66, 8640, 4320, 66, 4320, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 4320, 8640, 8640, 4320, 66, 8640, 66, 4320, 4320, 66, 4320, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 4320, 8640, 4320, 66, 4320, 8640, 4320, 8640, 66, 8640, 66, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 66, 8640, 66, 8640, 4320, 4320, 66, 4320, 8640, 4320, 4320, 8640, 66, 8640, 8640, 4320, 66, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 66, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 8640, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 66, 66, 66, 66]
Prompts retrieved: 1115850 . Total input tokens: 248770296 . Total output tokens: 223140963
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 108.65996983880177,
    "estimated_duration": 3600.123016004752,
    "input_throughput": 6211.897454775884,
    "output_throughput": 5524.58149668232,
    "total_throughput": 11736.478951458204,
    "itl": 153.6872687602537,
    "ttft": 1841187.906248785,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 510,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.588666520076796,
    "arrivals": 372356,
    "finished_requests": 90478,
    "scheduler_time": 159.66456666381623
}
#Debug simulation 
Total elapsed time: 108.66010493272915. Arrivals time: 0.9519628244452178 Scheduler time: 107.49116248963401 Scheduler overhead time: 0.0855250870808959 Adapter cache time: 0.02240604069083929 Engine time: 0.08249398274347186 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-32/adapters_256_slots_64_rate_0.8-0.4-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-32/adapters_256_slots_64_rate_0.8-0.4-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 66, 8640, 8640, 66, 8640, 4320, 8640, 66, 4320, 66, 8640, 4320, 4320, 4320, 4320, 8640, 66, 66, 66, 4320, 8640, 66, 8640, 8640, 4320, 4320, 4320, 66, 8640, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 8640, 4320, 66, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 66, 8640, 8640, 4320, 66, 66, 8640, 4320, 66, 4320, 4320, 8640, 4320, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 8640, 8640, 66, 8640, 66, 4320, 8640, 8640, 8640, 4320, 66, 8640, 4320, 66, 66, 66, 66, 66, 8640, 4320, 66, 8640, 66, 8640, 66, 66, 4320, 4320, 8640, 4320, 8640, 66, 4320, 66, 8640, 8640, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 66, 4320, 8640, 8640, 66, 8640, 4320, 66, 4320, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 4320, 8640, 8640, 4320, 66, 8640, 66, 4320, 4320, 66, 4320, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 4320, 8640, 4320, 66, 4320, 8640, 4320, 8640, 66, 8640, 66, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 66, 8640, 66, 8640, 4320, 4320, 66, 4320, 8640, 4320, 4320, 8640, 66, 8640, 8640, 4320, 66, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 66, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 8640, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 66, 66, 66, 66]
Prompts retrieved: 1115850 . Total input tokens: 248770296 . Total output tokens: 223140963
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 108.14474453916773,
    "estimated_duration": 3600.049534646995,
    "input_throughput": 6206.545711374758,
    "output_throughput": 5526.530345908391,
    "total_throughput": 11733.076057283148,
    "itl": 153.816999612544,
    "ttft": 1840431.0554762403,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 508,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6835331586562121,
    "arrivals": 372356,
    "finished_requests": 90475,
    "scheduler_time": 159.60711460792743
}
#Debug simulation 
Total elapsed time: 108.1448964853771. Arrivals time: 0.6978782271035016 Scheduler time: 107.22387052001432 Scheduler overhead time: 0.08671817276626825 Adapter cache time: 0.02242413954809308 Engine time: 0.08562473300844431 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-16/adapters_256_slots_64_rate_0.8-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-16/adapters_256_slots_64_rate_0.8-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 66, 8640, 8640, 66, 8640, 4320, 8640, 66, 4320, 66, 8640, 4320, 4320, 4320, 4320, 8640, 66, 66, 66, 4320, 8640, 66, 8640, 8640, 4320, 4320, 4320, 66, 8640, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 8640, 4320, 66, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 66, 8640, 8640, 4320, 66, 66, 8640, 4320, 66, 4320, 4320, 8640, 4320, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 8640, 8640, 66, 8640, 66, 4320, 8640, 8640, 8640, 4320, 66, 8640, 4320, 66, 66, 66, 66, 66, 8640, 4320, 66, 8640, 66, 8640, 66, 66, 4320, 4320, 8640, 4320, 8640, 66, 4320, 66, 8640, 8640, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 66, 4320, 8640, 8640, 66, 8640, 4320, 66, 4320, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 4320, 8640, 8640, 4320, 66, 8640, 66, 4320, 4320, 66, 4320, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 4320, 8640, 4320, 66, 4320, 8640, 4320, 8640, 66, 8640, 66, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 66, 8640, 66, 8640, 4320, 4320, 66, 4320, 8640, 4320, 4320, 8640, 66, 8640, 8640, 4320, 66, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 66, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 8640, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 66, 66, 66, 66]
Prompts retrieved: 1115850 . Total input tokens: 248770296 . Total output tokens: 223140963
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 106.44351104507223,
    "estimated_duration": 3600.079860059467,
    "input_throughput": 6206.503985617396,
    "output_throughput": 5526.48434850869,
    "total_throughput": 11732.988334126087,
    "itl": 153.80915825296103,
    "ttft": 1840458.7866756492,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 509,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5219356001051902,
    "arrivals": 372356,
    "finished_requests": 90476,
    "scheduler_time": 159.61485028655008
}
#Debug simulation 
Total elapsed time: 106.44364527100697. Arrivals time: 0.7037234054878354 Scheduler time: 105.52079273294657 Scheduler overhead time: 0.08564795972779393 Adapter cache time: 0.02244842005893588 Engine time: 0.08381872531026602 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-32/adapters_256_slots_64_rate_0.8-0.4-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-32/adapters_256_slots_64_rate_0.8-0.4-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 66, 8640, 8640, 66, 8640, 4320, 8640, 66, 4320, 66, 8640, 4320, 4320, 4320, 4320, 8640, 66, 66, 66, 4320, 8640, 66, 8640, 8640, 4320, 4320, 4320, 66, 8640, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 8640, 4320, 66, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 66, 8640, 8640, 4320, 66, 66, 8640, 4320, 66, 4320, 4320, 8640, 4320, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 8640, 8640, 66, 8640, 66, 4320, 8640, 8640, 8640, 4320, 66, 8640, 4320, 66, 66, 66, 66, 66, 8640, 4320, 66, 8640, 66, 8640, 66, 66, 4320, 4320, 8640, 4320, 8640, 66, 4320, 66, 8640, 8640, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 66, 4320, 8640, 8640, 66, 8640, 4320, 66, 4320, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 4320, 8640, 8640, 4320, 66, 8640, 66, 4320, 4320, 66, 4320, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 4320, 8640, 4320, 66, 4320, 8640, 4320, 8640, 66, 8640, 66, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 66, 8640, 66, 8640, 4320, 4320, 66, 4320, 8640, 4320, 4320, 8640, 66, 8640, 8640, 4320, 66, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 66, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 8640, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 66, 66, 66, 66]
Prompts retrieved: 1115850 . Total input tokens: 248770296 . Total output tokens: 223140963
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 107.88499262230471,
    "estimated_duration": 3600.071817221372,
    "input_throughput": 6206.507296080992,
    "output_throughput": 5526.4961395564815,
    "total_throughput": 11733.003435637474,
    "itl": 153.81712754815388,
    "ttft": 1840440.129609656,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 509,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.706571529544887,
    "arrivals": 372356,
    "finished_requests": 90475,
    "scheduler_time": 159.60741623385675
}
#Debug simulation 
Total elapsed time: 107.88513444922864. Arrivals time: 0.7004408175125718 Scheduler time: 106.96198052307591 Scheduler overhead time: 0.08757639536634088 Adapter cache time: 0.022433501202613115 Engine time: 0.08511336939409375 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-8/adapters_256_slots_64_rate_0.8-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-8/adapters_256_slots_64_rate_0.8-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 33, 8640, 8640, 33, 8640, 4320, 8640, 33, 4320, 33, 8640, 4320, 4320, 4320, 4320, 8640, 33, 33, 33, 4320, 8640, 33, 8640, 8640, 4320, 4320, 4320, 33, 8640, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 8640, 4320, 33, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 33, 8640, 8640, 4320, 33, 33, 8640, 4320, 33, 4320, 4320, 8640, 4320, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 8640, 8640, 33, 8640, 33, 4320, 8640, 8640, 8640, 4320, 33, 8640, 4320, 33, 33, 33, 33, 33, 8640, 4320, 33, 8640, 33, 8640, 33, 33, 4320, 4320, 8640, 4320, 8640, 33, 4320, 33, 8640, 8640, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 33, 4320, 8640, 8640, 33, 8640, 4320, 33, 4320, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 4320, 8640, 8640, 4320, 33, 8640, 33, 4320, 4320, 33, 4320, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 4320, 8640, 4320, 33, 4320, 8640, 4320, 8640, 33, 8640, 33, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 33, 8640, 33, 8640, 4320, 4320, 33, 4320, 8640, 4320, 4320, 8640, 33, 8640, 8640, 4320, 33, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 33, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 8640, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 33, 33, 33, 33]
Prompts retrieved: 1113045 . Total input tokens: 248170653 . Total output tokens: 222577894
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 108.28139055008069,
    "estimated_duration": 3600.083815168292,
    "input_throughput": 6254.585491906778,
    "output_throughput": 5526.340502455763,
    "total_throughput": 11780.92599436254,
    "itl": 152.41757331697437,
    "ttft": 1833631.2812098458,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 422,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2915258279396309,
    "arrivals": 371350,
    "finished_requests": 91161,
    "scheduler_time": 160.13127964816076
}
#Debug simulation 
Total elapsed time: 108.28152442211285. Arrivals time: 0.7180525129660964 Scheduler time: 107.34399677719921 Scheduler overhead time: 0.08607085375115275 Adapter cache time: 0.02203369652852416 Engine time: 0.08516794955357909 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-16/adapters_256_slots_64_rate_0.8-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-16/adapters_256_slots_64_rate_0.8-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 33, 8640, 8640, 33, 8640, 4320, 8640, 33, 4320, 33, 8640, 4320, 4320, 4320, 4320, 8640, 33, 33, 33, 4320, 8640, 33, 8640, 8640, 4320, 4320, 4320, 33, 8640, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 8640, 4320, 33, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 33, 8640, 8640, 4320, 33, 33, 8640, 4320, 33, 4320, 4320, 8640, 4320, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 8640, 8640, 33, 8640, 33, 4320, 8640, 8640, 8640, 4320, 33, 8640, 4320, 33, 33, 33, 33, 33, 8640, 4320, 33, 8640, 33, 8640, 33, 33, 4320, 4320, 8640, 4320, 8640, 33, 4320, 33, 8640, 8640, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 33, 4320, 8640, 8640, 33, 8640, 4320, 33, 4320, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 4320, 8640, 8640, 4320, 33, 8640, 33, 4320, 4320, 33, 4320, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 4320, 8640, 4320, 33, 4320, 8640, 4320, 8640, 33, 8640, 33, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 33, 8640, 33, 8640, 4320, 4320, 33, 4320, 8640, 4320, 4320, 8640, 33, 8640, 8640, 4320, 33, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 33, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 8640, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 33, 33, 33, 33]
Prompts retrieved: 1113045 . Total input tokens: 248170653 . Total output tokens: 222577894
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 110.76070968294516,
    "estimated_duration": 3600.1270597364883,
    "input_throughput": 6253.841496818715,
    "output_throughput": 5530.686464565337,
    "total_throughput": 11784.527961384052,
    "itl": 152.78628760418854,
    "ttft": 1830160.7318830078,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 416,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3599019931163698,
    "arrivals": 371350,
    "finished_requests": 91147,
    "scheduler_time": 159.87239551499138
}
#Debug simulation 
Total elapsed time: 110.76085593085736. Arrivals time: 0.7048485772684216 Scheduler time: 109.83106273366138 Scheduler overhead time: 0.08870996441692114 Adapter cache time: 0.021944121923297644 Engine time: 0.0871807737275958 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-32/adapters_256_slots_64_rate_0.8-0.4-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-32/adapters_256_slots_64_rate_0.8-0.4-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 33, 8640, 8640, 33, 8640, 4320, 8640, 33, 4320, 33, 8640, 4320, 4320, 4320, 4320, 8640, 33, 33, 33, 4320, 8640, 33, 8640, 8640, 4320, 4320, 4320, 33, 8640, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 8640, 4320, 33, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 33, 8640, 8640, 4320, 33, 33, 8640, 4320, 33, 4320, 4320, 8640, 4320, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 8640, 8640, 33, 8640, 33, 4320, 8640, 8640, 8640, 4320, 33, 8640, 4320, 33, 33, 33, 33, 33, 8640, 4320, 33, 8640, 33, 8640, 33, 33, 4320, 4320, 8640, 4320, 8640, 33, 4320, 33, 8640, 8640, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 33, 4320, 8640, 8640, 33, 8640, 4320, 33, 4320, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 4320, 8640, 8640, 4320, 33, 8640, 33, 4320, 4320, 33, 4320, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 4320, 8640, 4320, 33, 4320, 8640, 4320, 8640, 33, 8640, 33, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 33, 8640, 33, 8640, 4320, 4320, 33, 4320, 8640, 4320, 4320, 8640, 33, 8640, 8640, 4320, 33, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 33, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 8640, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 33, 33, 33, 33]
Prompts retrieved: 1113045 . Total input tokens: 248170653 . Total output tokens: 222577894
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 107.88067645113915,
    "estimated_duration": 3600.129176323593,
    "input_throughput": 6253.837820061683,
    "output_throughput": 5530.683212965442,
    "total_throughput": 11784.521033027124,
    "itl": 152.78632825152158,
    "ttft": 1830161.6197267496,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 416,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.361882129535087,
    "arrivals": 371350,
    "finished_requests": 91147,
    "scheduler_time": 159.87241477736458
}
#Debug simulation 
Total elapsed time: 107.88081696024165. Arrivals time: 0.7210783190093935 Scheduler time: 106.94531489908695 Scheduler overhead time: 0.08454626426100731 Adapter cache time: 0.021944822743535042 Engine time: 0.08147254912182689 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-16/adapters_256_slots_64_rate_0.8-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-16/adapters_256_slots_64_rate_0.8-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 33, 8640, 8640, 33, 8640, 4320, 8640, 33, 4320, 33, 8640, 4320, 4320, 4320, 4320, 8640, 33, 33, 33, 4320, 8640, 33, 8640, 8640, 4320, 4320, 4320, 33, 8640, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 8640, 4320, 33, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 33, 8640, 8640, 4320, 33, 33, 8640, 4320, 33, 4320, 4320, 8640, 4320, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 8640, 8640, 33, 8640, 33, 4320, 8640, 8640, 8640, 4320, 33, 8640, 4320, 33, 33, 33, 33, 33, 8640, 4320, 33, 8640, 33, 8640, 33, 33, 4320, 4320, 8640, 4320, 8640, 33, 4320, 33, 8640, 8640, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 33, 4320, 8640, 8640, 33, 8640, 4320, 33, 4320, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 4320, 8640, 8640, 4320, 33, 8640, 33, 4320, 4320, 33, 4320, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 4320, 8640, 4320, 33, 4320, 8640, 4320, 8640, 33, 8640, 33, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 33, 8640, 33, 8640, 4320, 4320, 33, 4320, 8640, 4320, 4320, 8640, 33, 8640, 8640, 4320, 33, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 33, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 8640, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 33, 33, 33, 33]
Prompts retrieved: 1113045 . Total input tokens: 248170653 . Total output tokens: 222577894
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 109.05580408498645,
    "estimated_duration": 3600.063595927025,
    "input_throughput": 6257.986949310736,
    "output_throughput": 5534.604172699145,
    "total_throughput": 11792.59112200988,
    "itl": 152.7014430019135,
    "ttft": 1830055.721036245,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 415,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.297257026329169,
    "arrivals": 371350,
    "finished_requests": 91246,
    "scheduler_time": 159.94945157172785
}
#Debug simulation 
Total elapsed time: 109.05595492571592. Arrivals time: 0.7081765332259238 Scheduler time: 108.122671474237 Scheduler overhead time: 0.08819464687258005 Adapter cache time: 0.02172890119254589 Engine time: 0.0875762696377933 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-32/adapters_256_slots_64_rate_0.8-0.4-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-32/adapters_256_slots_64_rate_0.8-0.4-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 33, 8640, 8640, 33, 8640, 4320, 8640, 33, 4320, 33, 8640, 4320, 4320, 4320, 4320, 8640, 33, 33, 33, 4320, 8640, 33, 8640, 8640, 4320, 4320, 4320, 33, 8640, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 8640, 4320, 33, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 33, 8640, 8640, 4320, 33, 33, 8640, 4320, 33, 4320, 4320, 8640, 4320, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 8640, 8640, 33, 8640, 33, 4320, 8640, 8640, 8640, 4320, 33, 8640, 4320, 33, 33, 33, 33, 33, 8640, 4320, 33, 8640, 33, 8640, 33, 33, 4320, 4320, 8640, 4320, 8640, 33, 4320, 33, 8640, 8640, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 33, 4320, 8640, 8640, 33, 8640, 4320, 33, 4320, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 4320, 8640, 8640, 4320, 33, 8640, 33, 4320, 4320, 33, 4320, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 4320, 8640, 4320, 33, 4320, 8640, 4320, 8640, 33, 8640, 33, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 33, 8640, 33, 8640, 4320, 4320, 33, 4320, 8640, 4320, 4320, 8640, 33, 8640, 8640, 4320, 33, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 33, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 8640, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 33, 33, 33, 33]
Prompts retrieved: 1113045 . Total input tokens: 248170653 . Total output tokens: 222577894
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 110.93638431932777,
    "estimated_duration": 3600.028463202972,
    "input_throughput": 6255.508874494781,
    "output_throughput": 5534.468464250211,
    "total_throughput": 11789.977338744991,
    "itl": 152.81338534475978,
    "ttft": 1829184.5284638633,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 419,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3904702213034077,
    "arrivals": 371350,
    "finished_requests": 91267,
    "scheduler_time": 159.87988687283297
}
#Debug simulation 
Total elapsed time: 110.93653313117102. Arrivals time: 0.7171051916666329 Scheduler time: 109.99786558374763 Scheduler overhead time: 0.08791272900998592 Adapter cache time: 0.021937081590294838 Engine time: 0.0848725032992661 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-16/adapters_256_slots_64_rate_0.8-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-16/adapters_256_slots_64_rate_0.8-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 33, 8640, 8640, 33, 8640, 4320, 8640, 33, 4320, 33, 8640, 4320, 4320, 4320, 4320, 8640, 33, 33, 33, 4320, 8640, 33, 8640, 8640, 4320, 4320, 4320, 33, 8640, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 8640, 4320, 33, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 33, 8640, 8640, 4320, 33, 33, 8640, 4320, 33, 4320, 4320, 8640, 4320, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 8640, 8640, 33, 8640, 33, 4320, 8640, 8640, 8640, 4320, 33, 8640, 4320, 33, 33, 33, 33, 33, 8640, 4320, 33, 8640, 33, 8640, 33, 33, 4320, 4320, 8640, 4320, 8640, 33, 4320, 33, 8640, 8640, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 33, 4320, 8640, 8640, 33, 8640, 4320, 33, 4320, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 4320, 8640, 8640, 4320, 33, 8640, 33, 4320, 4320, 33, 4320, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 4320, 8640, 4320, 33, 4320, 8640, 4320, 8640, 33, 8640, 33, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 33, 8640, 33, 8640, 4320, 4320, 33, 4320, 8640, 4320, 4320, 8640, 33, 8640, 8640, 4320, 33, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 33, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 8640, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 33, 33, 33, 33]
Prompts retrieved: 1113045 . Total input tokens: 248170653 . Total output tokens: 222577894
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 108.24907428910956,
    "estimated_duration": 3600.0539181599347,
    "input_throughput": 6254.637433738476,
    "output_throughput": 5526.386396504004,
    "total_throughput": 11781.023830242479,
    "itl": 152.41662065027234,
    "ttft": 1833619.8814851034,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 422,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2618012244487102,
    "arrivals": 371350,
    "finished_requests": 91161,
    "scheduler_time": 160.13043616292168
}
#Debug simulation 
Total elapsed time: 108.24920135783032. Arrivals time: 0.7230555261485279 Scheduler time: 107.311920595821 Scheduler overhead time: 0.08376221219077706 Adapter cache time: 0.02199014462530613 Engine time: 0.08198236813768744 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-32/adapters_256_slots_64_rate_0.8-0.4-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-32/adapters_256_slots_64_rate_0.8-0.4-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 33, 8640, 8640, 33, 8640, 4320, 8640, 33, 4320, 33, 8640, 4320, 4320, 4320, 4320, 8640, 33, 33, 33, 4320, 8640, 33, 8640, 8640, 4320, 4320, 4320, 33, 8640, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 8640, 4320, 33, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 33, 8640, 8640, 4320, 33, 33, 8640, 4320, 33, 4320, 4320, 8640, 4320, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 8640, 8640, 33, 8640, 33, 4320, 8640, 8640, 8640, 4320, 33, 8640, 4320, 33, 33, 33, 33, 33, 8640, 4320, 33, 8640, 33, 8640, 33, 33, 4320, 4320, 8640, 4320, 8640, 33, 4320, 33, 8640, 8640, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 33, 4320, 8640, 8640, 33, 8640, 4320, 33, 4320, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 4320, 8640, 8640, 4320, 33, 8640, 33, 4320, 4320, 33, 4320, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 4320, 8640, 4320, 33, 4320, 8640, 4320, 8640, 33, 8640, 33, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 33, 8640, 33, 8640, 4320, 4320, 33, 4320, 8640, 4320, 4320, 8640, 33, 8640, 8640, 4320, 33, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 33, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 8640, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 33, 33, 33, 33]
Prompts retrieved: 1113045 . Total input tokens: 248170653 . Total output tokens: 222577894
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 109.12514526862651,
    "estimated_duration": 3600.005280278092,
    "input_throughput": 6254.306659867101,
    "output_throughput": 5526.404671957356,
    "total_throughput": 11780.711331824457,
    "itl": 152.42192765400299,
    "ttft": 1833665.8634299692,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 422,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.41678332053125,
    "arrivals": 371350,
    "finished_requests": 91157,
    "scheduler_time": 160.12270212063234
}
#Debug simulation 
Total elapsed time: 109.12528862571344. Arrivals time: 0.706360952463001 Scheduler time: 108.19624410243705 Scheduler overhead time: 0.08789065107703209 Adapter cache time: 0.021211376413702965 Engine time: 0.08622464071959257 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-8/adapters_256_slots_64_rate_0.8-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-8/adapters_256_slots_64_rate_0.8-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 540, 8640, 8640, 540, 8640, 1080, 8640, 540, 1080, 540, 8640, 1080, 1080, 1080, 1080, 8640, 540, 540, 540, 1080, 8640, 540, 8640, 8640, 1080, 1080, 1080, 540, 8640, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 8640, 1080, 540, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 540, 8640, 8640, 1080, 540, 540, 8640, 1080, 540, 1080, 1080, 8640, 1080, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 8640, 8640, 540, 8640, 540, 1080, 8640, 8640, 8640, 1080, 540, 8640, 1080, 540, 540, 540, 540, 540, 8640, 1080, 540, 8640, 540, 8640, 540, 540, 1080, 1080, 8640, 1080, 8640, 540, 1080, 540, 8640, 8640, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 540, 1080, 8640, 8640, 540, 8640, 1080, 540, 1080, 8640, 540, 540, 540, 540, 540, 540, 8640, 540, 540, 540, 8640, 540, 1080, 8640, 8640, 1080, 540, 8640, 540, 1080, 1080, 540, 1080, 540, 8640, 540, 540, 8640, 540, 8640, 8640, 1080, 8640, 1080, 540, 1080, 8640, 1080, 8640, 540, 8640, 540, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 540, 8640, 540, 8640, 1080, 1080, 540, 1080, 8640, 1080, 1080, 8640, 540, 8640, 8640, 1080, 540, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 540, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 8640, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 540, 540, 540, 540]
Prompts retrieved: 880740 . Total input tokens: 196366859 . Total output tokens: 176168866
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 115.7143606771715,
    "estimated_duration": 3600.0525559842204,
    "input_throughput": 6251.372903595645,
    "output_throughput": 5526.0162707711315,
    "total_throughput": 11777.389174366775,
    "itl": 154.2817469856141,
    "ttft": 1744736.0217321583,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 427,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3068282666592952,
    "arrivals": 293562,
    "finished_requests": 90941,
    "scheduler_time": 157.51016469891778
}
#Debug simulation 
Total elapsed time: 115.71448499290273. Arrivals time: 0.6806246181949973 Scheduler time: 114.8006734107621 Scheduler overhead time: 0.09177873469889164 Adapter cache time: 0.024277030024677515 Engine time: 0.08867551013827324 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-16/adapters_256_slots_64_rate_0.8-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-16/adapters_256_slots_64_rate_0.8-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 540, 8640, 8640, 540, 8640, 1080, 8640, 540, 1080, 540, 8640, 1080, 1080, 1080, 1080, 8640, 540, 540, 540, 1080, 8640, 540, 8640, 8640, 1080, 1080, 1080, 540, 8640, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 8640, 1080, 540, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 540, 8640, 8640, 1080, 540, 540, 8640, 1080, 540, 1080, 1080, 8640, 1080, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 8640, 8640, 540, 8640, 540, 1080, 8640, 8640, 8640, 1080, 540, 8640, 1080, 540, 540, 540, 540, 540, 8640, 1080, 540, 8640, 540, 8640, 540, 540, 1080, 1080, 8640, 1080, 8640, 540, 1080, 540, 8640, 8640, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 540, 1080, 8640, 8640, 540, 8640, 1080, 540, 1080, 8640, 540, 540, 540, 540, 540, 540, 8640, 540, 540, 540, 8640, 540, 1080, 8640, 8640, 1080, 540, 8640, 540, 1080, 1080, 540, 1080, 540, 8640, 540, 540, 8640, 540, 8640, 8640, 1080, 8640, 1080, 540, 1080, 8640, 1080, 8640, 540, 8640, 540, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 540, 8640, 540, 8640, 1080, 1080, 540, 1080, 8640, 1080, 1080, 8640, 540, 8640, 8640, 1080, 540, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 540, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 8640, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 540, 540, 540, 540]
Prompts retrieved: 880740 . Total input tokens: 196366859 . Total output tokens: 176168866
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 104.9779214640148,
    "estimated_duration": 3600.0347953715936,
    "input_throughput": 6241.725226903151,
    "output_throughput": 5525.378261780607,
    "total_throughput": 11767.103488683759,
    "itl": 154.2623258733412,
    "ttft": 1742509.560402612,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 442,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4392776820575865,
    "arrivals": 293562,
    "finished_requests": 90945,
    "scheduler_time": 157.54967869471184
}
#Debug simulation 
Total elapsed time: 104.97805669903755. Arrivals time: 0.7107066782191396 Scheduler time: 104.0399107481353 Scheduler overhead time: 0.08855220675468445 Adapter cache time: 0.024662781972438097 Engine time: 0.08704519225284457 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-32/adapters_256_slots_64_rate_0.8-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-32/adapters_256_slots_64_rate_0.8-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 540, 8640, 8640, 540, 8640, 1080, 8640, 540, 1080, 540, 8640, 1080, 1080, 1080, 1080, 8640, 540, 540, 540, 1080, 8640, 540, 8640, 8640, 1080, 1080, 1080, 540, 8640, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 8640, 1080, 540, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 540, 8640, 8640, 1080, 540, 540, 8640, 1080, 540, 1080, 1080, 8640, 1080, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 8640, 8640, 540, 8640, 540, 1080, 8640, 8640, 8640, 1080, 540, 8640, 1080, 540, 540, 540, 540, 540, 8640, 1080, 540, 8640, 540, 8640, 540, 540, 1080, 1080, 8640, 1080, 8640, 540, 1080, 540, 8640, 8640, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 540, 1080, 8640, 8640, 540, 8640, 1080, 540, 1080, 8640, 540, 540, 540, 540, 540, 540, 8640, 540, 540, 540, 8640, 540, 1080, 8640, 8640, 1080, 540, 8640, 540, 1080, 1080, 540, 1080, 540, 8640, 540, 540, 8640, 540, 8640, 8640, 1080, 8640, 1080, 540, 1080, 8640, 1080, 8640, 540, 8640, 540, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 540, 8640, 540, 8640, 1080, 1080, 540, 1080, 8640, 1080, 1080, 8640, 540, 8640, 8640, 1080, 540, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 540, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 8640, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 540, 540, 540, 540]
Prompts retrieved: 880740 . Total input tokens: 196366859 . Total output tokens: 176168866
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 105.60698028793558,
    "estimated_duration": 3600.0386343563,
    "input_throughput": 6241.718570894669,
    "output_throughput": 5525.372369665328,
    "total_throughput": 11767.090940559996,
    "itl": 154.26245372614187,
    "ttft": 1742510.9066171646,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 442,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4423626095801676,
    "arrivals": 293562,
    "finished_requests": 90945,
    "scheduler_time": 157.54973656220272
}
#Debug simulation 
Total elapsed time: 105.60710661299527. Arrivals time: 0.7131548086181283 Scheduler time: 104.66650521429256 Scheduler overhead time: 0.08907469641417265 Adapter cache time: 0.02345956861972809 Engine time: 0.087389444001019 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-16-16/adapters_256_slots_64_rate_0.8-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-16-16/adapters_256_slots_64_rate_0.8-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 540, 8640, 8640, 540, 8640, 1080, 8640, 540, 1080, 540, 8640, 1080, 1080, 1080, 1080, 8640, 540, 540, 540, 1080, 8640, 540, 8640, 8640, 1080, 1080, 1080, 540, 8640, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 8640, 1080, 540, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 540, 8640, 8640, 1080, 540, 540, 8640, 1080, 540, 1080, 1080, 8640, 1080, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 8640, 8640, 540, 8640, 540, 1080, 8640, 8640, 8640, 1080, 540, 8640, 1080, 540, 540, 540, 540, 540, 8640, 1080, 540, 8640, 540, 8640, 540, 540, 1080, 1080, 8640, 1080, 8640, 540, 1080, 540, 8640, 8640, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 540, 1080, 8640, 8640, 540, 8640, 1080, 540, 1080, 8640, 540, 540, 540, 540, 540, 540, 8640, 540, 540, 540, 8640, 540, 1080, 8640, 8640, 1080, 540, 8640, 540, 1080, 1080, 540, 1080, 540, 8640, 540, 540, 8640, 540, 8640, 8640, 1080, 8640, 1080, 540, 1080, 8640, 1080, 8640, 540, 8640, 540, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 540, 8640, 540, 8640, 1080, 1080, 540, 1080, 8640, 1080, 1080, 8640, 540, 8640, 8640, 1080, 540, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 540, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 8640, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 540, 540, 540, 540]
Prompts retrieved: 880740 . Total input tokens: 196366859 . Total output tokens: 176168866
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 114.04374098498374,
    "estimated_duration": 3600.0780267754812,
    "input_throughput": 6251.227288025532,
    "output_throughput": 5526.597160401164,
    "total_throughput": 11777.824448426696,
    "itl": 154.23594533722834,
    "ttft": 1744345.1753850759,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 420,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3093471105745973,
    "arrivals": 293562,
    "finished_requests": 91005,
    "scheduler_time": 157.52894307093683
}
#Debug simulation 
Total elapsed time: 114.04386170674115. Arrivals time: 0.6812977273948491 Scheduler time: 113.13467386504635 Scheduler overhead time: 0.08881324110552669 Adapter cache time: 0.02380151255056262 Engine time: 0.08722410351037979 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-16-32/adapters_256_slots_64_rate_0.8-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-16-32/adapters_256_slots_64_rate_0.8-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 540, 8640, 8640, 540, 8640, 1080, 8640, 540, 1080, 540, 8640, 1080, 1080, 1080, 1080, 8640, 540, 540, 540, 1080, 8640, 540, 8640, 8640, 1080, 1080, 1080, 540, 8640, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 8640, 1080, 540, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 540, 8640, 8640, 1080, 540, 540, 8640, 1080, 540, 1080, 1080, 8640, 1080, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 8640, 8640, 540, 8640, 540, 1080, 8640, 8640, 8640, 1080, 540, 8640, 1080, 540, 540, 540, 540, 540, 8640, 1080, 540, 8640, 540, 8640, 540, 540, 1080, 1080, 8640, 1080, 8640, 540, 1080, 540, 8640, 8640, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 540, 1080, 8640, 8640, 540, 8640, 1080, 540, 1080, 8640, 540, 540, 540, 540, 540, 540, 8640, 540, 540, 540, 8640, 540, 1080, 8640, 8640, 1080, 540, 8640, 540, 1080, 1080, 540, 1080, 540, 8640, 540, 540, 8640, 540, 8640, 8640, 1080, 8640, 1080, 540, 1080, 8640, 1080, 8640, 540, 8640, 540, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 540, 8640, 540, 8640, 1080, 1080, 540, 1080, 8640, 1080, 1080, 8640, 540, 8640, 8640, 1080, 540, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 540, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 8640, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 540, 540, 540, 540]
Prompts retrieved: 880740 . Total input tokens: 196366859 . Total output tokens: 176168866
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 103.76293924078345,
    "estimated_duration": 3600.0973972122897,
    "input_throughput": 6247.907630892808,
    "output_throughput": 5524.291930379474,
    "total_throughput": 11772.199561272282,
    "itl": 154.05101132484992,
    "ttft": 1746172.635247018,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 469,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5487509203143461,
    "arrivals": 293562,
    "finished_requests": 90987,
    "scheduler_time": 157.68669068256096
}
#Debug simulation 
Total elapsed time: 103.76308072498068. Arrivals time: 0.6740407608449459 Scheduler time: 102.86635424755514 Scheduler overhead time: 0.08744926191866398 Adapter cache time: 0.024098556023091078 Engine time: 0.08423631684854627 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_16-16-16/adapters_256_slots_64_rate_0.8-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_16-16-16/adapters_256_slots_64_rate_0.8-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 540, 8640, 8640, 540, 8640, 1080, 8640, 540, 1080, 540, 8640, 1080, 1080, 1080, 1080, 8640, 540, 540, 540, 1080, 8640, 540, 8640, 8640, 1080, 1080, 1080, 540, 8640, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 8640, 1080, 540, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 540, 8640, 8640, 1080, 540, 540, 8640, 1080, 540, 1080, 1080, 8640, 1080, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 8640, 8640, 540, 8640, 540, 1080, 8640, 8640, 8640, 1080, 540, 8640, 1080, 540, 540, 540, 540, 540, 8640, 1080, 540, 8640, 540, 8640, 540, 540, 1080, 1080, 8640, 1080, 8640, 540, 1080, 540, 8640, 8640, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 540, 1080, 8640, 8640, 540, 8640, 1080, 540, 1080, 8640, 540, 540, 540, 540, 540, 540, 8640, 540, 540, 540, 8640, 540, 1080, 8640, 8640, 1080, 540, 8640, 540, 1080, 1080, 540, 1080, 540, 8640, 540, 540, 8640, 540, 8640, 8640, 1080, 8640, 1080, 540, 1080, 8640, 1080, 8640, 540, 8640, 540, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 540, 8640, 540, 8640, 1080, 1080, 540, 1080, 8640, 1080, 1080, 8640, 540, 8640, 8640, 1080, 540, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 540, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 8640, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 540, 540, 540, 540]
Prompts retrieved: 880740 . Total input tokens: 196366859 . Total output tokens: 176168866
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 117.63401482114568,
    "estimated_duration": 3600.145883889235,
    "input_throughput": 6243.22228179227,
    "output_throughput": 5519.43022334796,
    "total_throughput": 11762.652505140231,
    "itl": 153.6520986022952,
    "ttft": 1743304.821665274,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 413,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2348907717945916,
    "arrivals": 293562,
    "finished_requests": 90895,
    "scheduler_time": 157.93026032597388
}
#Debug simulation 
Total elapsed time: 117.63415932282805. Arrivals time: 0.6950300890021026 Scheduler time: 116.7092833626084 Scheduler overhead time: 0.09053028048947453 Adapter cache time: 0.023890566546469927 Engine time: 0.08630438009276986 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_16-16-32/adapters_256_slots_64_rate_0.8-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_16-16-32/adapters_256_slots_64_rate_0.8-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 540, 8640, 8640, 540, 8640, 1080, 8640, 540, 1080, 540, 8640, 1080, 1080, 1080, 1080, 8640, 540, 540, 540, 1080, 8640, 540, 8640, 8640, 1080, 1080, 1080, 540, 8640, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 8640, 1080, 540, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 540, 8640, 8640, 1080, 540, 540, 8640, 1080, 540, 1080, 1080, 8640, 1080, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 8640, 8640, 540, 8640, 540, 1080, 8640, 8640, 8640, 1080, 540, 8640, 1080, 540, 540, 540, 540, 540, 8640, 1080, 540, 8640, 540, 8640, 540, 540, 1080, 1080, 8640, 1080, 8640, 540, 1080, 540, 8640, 8640, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 540, 1080, 8640, 8640, 540, 8640, 1080, 540, 1080, 8640, 540, 540, 540, 540, 540, 540, 8640, 540, 540, 540, 8640, 540, 1080, 8640, 8640, 1080, 540, 8640, 540, 1080, 1080, 540, 1080, 540, 8640, 540, 540, 8640, 540, 8640, 8640, 1080, 8640, 1080, 540, 1080, 8640, 1080, 8640, 540, 8640, 540, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 540, 8640, 540, 8640, 1080, 1080, 540, 1080, 8640, 1080, 1080, 8640, 540, 8640, 8640, 1080, 540, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 540, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 8640, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 540, 540, 540, 540]
Prompts retrieved: 880740 . Total input tokens: 196366859 . Total output tokens: 176168866
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 115.51723783276975,
    "estimated_duration": 3600.146818394767,
    "input_throughput": 6256.409845541521,
    "output_throughput": 5531.337471642083,
    "total_throughput": 11787.747317183605,
    "itl": 154.20489494951454,
    "ttft": 1744750.3563708267,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 441,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4750731799379,
    "arrivals": 293562,
    "finished_requests": 91080,
    "scheduler_time": 157.55401886012925
}
#Debug simulation 
Total elapsed time: 115.51736410101876. Arrivals time: 0.6895688781514764 Scheduler time: 114.60052929865196 Scheduler overhead time: 0.08794945664703846 Adapter cache time: 0.02408155146986246 Engine time: 0.08698765793815255 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-8/adapters_256_slots_64_rate_0.8-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-8/adapters_256_slots_64_rate_0.8-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 270, 8640, 8640, 270, 8640, 1080, 8640, 270, 1080, 270, 8640, 1080, 1080, 1080, 1080, 8640, 270, 270, 270, 1080, 8640, 270, 8640, 8640, 1080, 1080, 1080, 270, 8640, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 8640, 1080, 270, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 270, 8640, 8640, 1080, 270, 270, 8640, 1080, 270, 1080, 1080, 8640, 1080, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 8640, 8640, 270, 8640, 270, 1080, 8640, 8640, 8640, 1080, 270, 8640, 1080, 270, 270, 270, 270, 270, 8640, 1080, 270, 8640, 270, 8640, 270, 270, 1080, 1080, 8640, 1080, 8640, 270, 1080, 270, 8640, 8640, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 270, 1080, 8640, 8640, 270, 8640, 1080, 270, 1080, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 1080, 8640, 8640, 1080, 270, 8640, 270, 1080, 1080, 270, 1080, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 1080, 8640, 1080, 270, 1080, 8640, 1080, 8640, 270, 8640, 270, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 270, 8640, 270, 8640, 1080, 1080, 270, 1080, 8640, 1080, 1080, 8640, 270, 8640, 8640, 1080, 270, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 270, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 8640, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 270, 270, 270, 270]
Prompts retrieved: 857790 . Total input tokens: 191327038 . Total output tokens: 171596853
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 107.19546689698473,
    "estimated_duration": 3600.157707557297,
    "input_throughput": 6243.18038979749,
    "output_throughput": 5524.687976376227,
    "total_throughput": 11767.868366173716,
    "itl": 153.81295258447372,
    "ttft": 1730501.6344380362,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 419,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2823443647078323,
    "arrivals": 285871,
    "finished_requests": 90856,
    "scheduler_time": 157.3879597686708
}
#Debug simulation 
Total elapsed time: 107.195597412996. Arrivals time: 0.6681269248947501 Scheduler time: 106.31018808949739 Scheduler overhead time: 0.08467662381008267 Adapter cache time: 0.022011129185557365 Engine time: 0.08319439925253391 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-16/adapters_256_slots_64_rate_0.8-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-16/adapters_256_slots_64_rate_0.8-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 270, 8640, 8640, 270, 8640, 1080, 8640, 270, 1080, 270, 8640, 1080, 1080, 1080, 1080, 8640, 270, 270, 270, 1080, 8640, 270, 8640, 8640, 1080, 1080, 1080, 270, 8640, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 8640, 1080, 270, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 270, 8640, 8640, 1080, 270, 270, 8640, 1080, 270, 1080, 1080, 8640, 1080, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 8640, 8640, 270, 8640, 270, 1080, 8640, 8640, 8640, 1080, 270, 8640, 1080, 270, 270, 270, 270, 270, 8640, 1080, 270, 8640, 270, 8640, 270, 270, 1080, 1080, 8640, 1080, 8640, 270, 1080, 270, 8640, 8640, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 270, 1080, 8640, 8640, 270, 8640, 1080, 270, 1080, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 1080, 8640, 8640, 1080, 270, 8640, 270, 1080, 1080, 270, 1080, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 1080, 8640, 1080, 270, 1080, 8640, 1080, 8640, 270, 8640, 270, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 270, 8640, 270, 8640, 1080, 1080, 270, 1080, 8640, 1080, 1080, 8640, 270, 8640, 8640, 1080, 270, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 270, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 8640, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 270, 270, 270, 270]
Prompts retrieved: 857790 . Total input tokens: 191327038 . Total output tokens: 171596853
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 107.0437881667167,
    "estimated_duration": 3600.12883532856,
    "input_throughput": 6243.052687293282,
    "output_throughput": 5527.754952742906,
    "total_throughput": 11770.80764003619,
    "itl": 153.92187989952848,
    "ttft": 1730320.9558755336,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 414,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3510617252974824,
    "arrivals": 285871,
    "finished_requests": 90879,
    "scheduler_time": 157.25499295629552
}
#Debug simulation 
Total elapsed time: 107.04392144782469. Arrivals time: 0.7569463443942368 Scheduler time: 106.06794127682224 Scheduler overhead time: 0.08571568317711353 Adapter cache time: 0.02320424420759082 Engine time: 0.08313832711428404 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-32/adapters_256_slots_64_rate_0.8-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-32/adapters_256_slots_64_rate_0.8-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 270, 8640, 8640, 270, 8640, 1080, 8640, 270, 1080, 270, 8640, 1080, 1080, 1080, 1080, 8640, 270, 270, 270, 1080, 8640, 270, 8640, 8640, 1080, 1080, 1080, 270, 8640, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 8640, 1080, 270, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 270, 8640, 8640, 1080, 270, 270, 8640, 1080, 270, 1080, 1080, 8640, 1080, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 8640, 8640, 270, 8640, 270, 1080, 8640, 8640, 8640, 1080, 270, 8640, 1080, 270, 270, 270, 270, 270, 8640, 1080, 270, 8640, 270, 8640, 270, 270, 1080, 1080, 8640, 1080, 8640, 270, 1080, 270, 8640, 8640, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 270, 1080, 8640, 8640, 270, 8640, 1080, 270, 1080, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 1080, 8640, 8640, 1080, 270, 8640, 270, 1080, 1080, 270, 1080, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 1080, 8640, 1080, 270, 1080, 8640, 1080, 8640, 270, 8640, 270, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 270, 8640, 270, 8640, 1080, 1080, 270, 1080, 8640, 1080, 1080, 8640, 270, 8640, 8640, 1080, 270, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 270, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 8640, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 270, 270, 270, 270]
Prompts retrieved: 857790 . Total input tokens: 191327038 . Total output tokens: 171596853
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 108.24031929299235,
    "estimated_duration": 3600.134537176157,
    "input_throughput": 6243.042799625308,
    "output_throughput": 5527.746197954448,
    "total_throughput": 11770.788997579757,
    "itl": 153.92195797970743,
    "ttft": 1730323.4772784763,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 414,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.353434359375395,
    "arrivals": 285871,
    "finished_requests": 90879,
    "scheduler_time": 157.2551746880122
}
#Debug simulation 
Total elapsed time: 108.24044696986675. Arrivals time: 0.8862172840163112 Scheduler time: 107.12912539439276 Scheduler overhead time: 0.08898713206872344 Adapter cache time: 0.02268410101532936 Engine time: 0.08597860857844353 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-16-16/adapters_256_slots_64_rate_0.8-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-16-16/adapters_256_slots_64_rate_0.8-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 270, 8640, 8640, 270, 8640, 1080, 8640, 270, 1080, 270, 8640, 1080, 1080, 1080, 1080, 8640, 270, 270, 270, 1080, 8640, 270, 8640, 8640, 1080, 1080, 1080, 270, 8640, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 8640, 1080, 270, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 270, 8640, 8640, 1080, 270, 270, 8640, 1080, 270, 1080, 1080, 8640, 1080, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 8640, 8640, 270, 8640, 270, 1080, 8640, 8640, 8640, 1080, 270, 8640, 1080, 270, 270, 270, 270, 270, 8640, 1080, 270, 8640, 270, 8640, 270, 270, 1080, 1080, 8640, 1080, 8640, 270, 1080, 270, 8640, 8640, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 270, 1080, 8640, 8640, 270, 8640, 1080, 270, 1080, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 1080, 8640, 8640, 1080, 270, 8640, 270, 1080, 1080, 270, 1080, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 1080, 8640, 1080, 270, 1080, 8640, 1080, 8640, 270, 8640, 270, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 270, 8640, 270, 8640, 1080, 1080, 270, 1080, 8640, 1080, 1080, 8640, 270, 8640, 8640, 1080, 270, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 270, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 8640, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 270, 270, 270, 270]
Prompts retrieved: 857790 . Total input tokens: 191327038 . Total output tokens: 171596853
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 105.42503382870927,
    "estimated_duration": 3600.0166398522783,
    "input_throughput": 6243.060310110743,
    "output_throughput": 5524.571408874404,
    "total_throughput": 11767.631718985147,
    "itl": 153.81466843814158,
    "ttft": 1730522.9270799472,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 419,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.312894585374742,
    "arrivals": 285871,
    "finished_requests": 90850,
    "scheduler_time": 157.3809223485657
}
#Debug simulation 
Total elapsed time: 105.42517427587882. Arrivals time: 0.6988920029252768 Scheduler time: 104.50680801132694 Scheduler overhead time: 0.08541904808953404 Adapter cache time: 0.02194380247965455 Engine time: 0.0843281103298068 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-16-32/adapters_256_slots_64_rate_0.8-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-16-32/adapters_256_slots_64_rate_0.8-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 270, 8640, 8640, 270, 8640, 1080, 8640, 270, 1080, 270, 8640, 1080, 1080, 1080, 1080, 8640, 270, 270, 270, 1080, 8640, 270, 8640, 8640, 1080, 1080, 1080, 270, 8640, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 8640, 1080, 270, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 270, 8640, 8640, 1080, 270, 270, 8640, 1080, 270, 1080, 1080, 8640, 1080, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 8640, 8640, 270, 8640, 270, 1080, 8640, 8640, 8640, 1080, 270, 8640, 1080, 270, 270, 270, 270, 270, 8640, 1080, 270, 8640, 270, 8640, 270, 270, 1080, 1080, 8640, 1080, 8640, 270, 1080, 270, 8640, 8640, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 270, 1080, 8640, 8640, 270, 8640, 1080, 270, 1080, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 1080, 8640, 8640, 1080, 270, 8640, 270, 1080, 1080, 270, 1080, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 1080, 8640, 1080, 270, 1080, 8640, 1080, 8640, 270, 8640, 270, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 270, 8640, 270, 8640, 1080, 1080, 270, 1080, 8640, 1080, 1080, 8640, 270, 8640, 8640, 1080, 270, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 270, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 8640, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 270, 270, 270, 270]
Prompts retrieved: 857790 . Total input tokens: 191327038 . Total output tokens: 171596853
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 106.6339137465693,
    "estimated_duration": 3600.150369909585,
    "input_throughput": 6243.015343985329,
    "output_throughput": 5527.721888044301,
    "total_throughput": 11770.73723202963,
    "itl": 153.92370555808571,
    "ttft": 1730323.5198176636,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 414,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3704111205413985,
    "arrivals": 285871,
    "finished_requests": 90879,
    "scheduler_time": 157.25596944286585
}
#Debug simulation 
Total elapsed time: 106.63404855458066. Arrivals time: 0.6994772208854556 Scheduler time: 105.71918221795931 Scheduler overhead time: 0.08461435791105032 Adapter cache time: 0.022718090564012527 Engine time: 0.0810578502714634 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_16-16-16/adapters_256_slots_64_rate_0.8-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_16-16-16/adapters_256_slots_64_rate_0.8-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 270, 8640, 8640, 270, 8640, 1080, 8640, 270, 1080, 270, 8640, 1080, 1080, 1080, 1080, 8640, 270, 270, 270, 1080, 8640, 270, 8640, 8640, 1080, 1080, 1080, 270, 8640, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 8640, 1080, 270, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 270, 8640, 8640, 1080, 270, 270, 8640, 1080, 270, 1080, 1080, 8640, 1080, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 8640, 8640, 270, 8640, 270, 1080, 8640, 8640, 8640, 1080, 270, 8640, 1080, 270, 270, 270, 270, 270, 8640, 1080, 270, 8640, 270, 8640, 270, 270, 1080, 1080, 8640, 1080, 8640, 270, 1080, 270, 8640, 8640, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 270, 1080, 8640, 8640, 270, 8640, 1080, 270, 1080, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 1080, 8640, 8640, 1080, 270, 8640, 270, 1080, 1080, 270, 1080, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 1080, 8640, 1080, 270, 1080, 8640, 1080, 8640, 270, 8640, 270, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 270, 8640, 270, 8640, 1080, 1080, 270, 1080, 8640, 1080, 1080, 8640, 270, 8640, 8640, 1080, 270, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 270, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 8640, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 270, 270, 270, 270]
Prompts retrieved: 857790 . Total input tokens: 191327038 . Total output tokens: 171596853
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 106.89781442424282,
    "estimated_duration": 3600.1252249339527,
    "input_throughput": 6243.236719748366,
    "output_throughput": 5524.737823630814,
    "total_throughput": 11767.97454337918,
    "itl": 153.8123253383222,
    "ttft": 1730491.5055574114,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 419,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.252831073564004,
    "arrivals": 285871,
    "finished_requests": 90856,
    "scheduler_time": 157.38750195800583
}
#Debug simulation 
Total elapsed time: 106.89793425705284. Arrivals time: 0.6681288573890924 Scheduler time: 106.00761992111802 Scheduler overhead time: 0.08793288841843605 Adapter cache time: 0.022666210308670998 Engine time: 0.08517440780997276 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_16-16-32/adapters_256_slots_64_rate_0.8-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_16-16-32/adapters_256_slots_64_rate_0.8-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 270, 8640, 8640, 270, 8640, 1080, 8640, 270, 1080, 270, 8640, 1080, 1080, 1080, 1080, 8640, 270, 270, 270, 1080, 8640, 270, 8640, 8640, 1080, 1080, 1080, 270, 8640, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 8640, 1080, 270, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 270, 8640, 8640, 1080, 270, 270, 8640, 1080, 270, 1080, 1080, 8640, 1080, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 8640, 8640, 270, 8640, 270, 1080, 8640, 8640, 8640, 1080, 270, 8640, 1080, 270, 270, 270, 270, 270, 8640, 1080, 270, 8640, 270, 8640, 270, 270, 1080, 1080, 8640, 1080, 8640, 270, 1080, 270, 8640, 8640, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 270, 1080, 8640, 8640, 270, 8640, 1080, 270, 1080, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 1080, 8640, 8640, 1080, 270, 8640, 270, 1080, 1080, 270, 1080, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 1080, 8640, 1080, 270, 1080, 8640, 1080, 8640, 270, 8640, 270, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 270, 8640, 270, 8640, 1080, 1080, 270, 1080, 8640, 1080, 1080, 8640, 270, 8640, 8640, 1080, 270, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 270, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 8640, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 270, 270, 270, 270]
Prompts retrieved: 857790 . Total input tokens: 191327038 . Total output tokens: 171596853
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 106.89657442877069,
    "estimated_duration": 3600.168982631826,
    "input_throughput": 6242.983067858541,
    "output_throughput": 5527.693309954599,
    "total_throughput": 11770.67637781314,
    "itl": 153.92388005266326,
    "ttft": 1730330.0464916844,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 414,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3882681582123055,
    "arrivals": 285871,
    "finished_requests": 90879,
    "scheduler_time": 157.2562849669261
}
#Debug simulation 
Total elapsed time: 106.8967771618627. Arrivals time: 0.6799631454050541 Scheduler time: 105.99476049421355 Scheduler overhead time: 0.08890792028978467 Adapter cache time: 0.022311421111226082 Engine time: 0.08409950276836753 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-8/adapters_256_slots_64_rate_0.8-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-8/adapters_256_slots_64_rate_0.8-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 135, 8640, 8640, 135, 8640, 1080, 8640, 135, 1080, 135, 8640, 1080, 1080, 1080, 1080, 8640, 135, 135, 135, 1080, 8640, 135, 8640, 8640, 1080, 1080, 1080, 135, 8640, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 8640, 1080, 135, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 135, 8640, 8640, 1080, 135, 135, 8640, 1080, 135, 1080, 1080, 8640, 1080, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 8640, 8640, 135, 8640, 135, 1080, 8640, 8640, 8640, 1080, 135, 8640, 1080, 135, 135, 135, 135, 135, 8640, 1080, 135, 8640, 135, 8640, 135, 135, 1080, 1080, 8640, 1080, 8640, 135, 1080, 135, 8640, 8640, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 135, 1080, 8640, 8640, 135, 8640, 1080, 135, 1080, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 1080, 8640, 8640, 1080, 135, 8640, 135, 1080, 1080, 135, 1080, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 1080, 8640, 1080, 135, 1080, 8640, 1080, 8640, 135, 8640, 135, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 135, 8640, 135, 8640, 1080, 1080, 135, 1080, 8640, 1080, 1080, 8640, 135, 8640, 8640, 1080, 135, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 135, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 8640, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 135, 135, 135, 135]
Prompts retrieved: 846315 . Total input tokens: 188744173 . Total output tokens: 169308446
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 118.84276765491813,
    "estimated_duration": 3600.0599439734674,
    "input_throughput": 6241.479961358556,
    "output_throughput": 5530.015974685872,
    "total_throughput": 11771.495936044428,
    "itl": 154.37990879174737,
    "ttft": 1724866.3004819797,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 416,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2731629014760337,
    "arrivals": 281942,
    "finished_requests": 90795,
    "scheduler_time": 157.22605370028103
}
#Debug simulation 
Total elapsed time: 118.84289135877043. Arrivals time: 0.7149014617316425 Scheduler time: 117.90076608629897 Scheduler overhead time: 0.09088067291304469 Adapter cache time: 0.023439678363502026 Engine time: 0.08487918740138412 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-16/adapters_256_slots_64_rate_0.8-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-16/adapters_256_slots_64_rate_0.8-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 135, 8640, 8640, 135, 8640, 1080, 8640, 135, 1080, 135, 8640, 1080, 1080, 1080, 1080, 8640, 135, 135, 135, 1080, 8640, 135, 8640, 8640, 1080, 1080, 1080, 135, 8640, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 8640, 1080, 135, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 135, 8640, 8640, 1080, 135, 135, 8640, 1080, 135, 1080, 1080, 8640, 1080, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 8640, 8640, 135, 8640, 135, 1080, 8640, 8640, 8640, 1080, 135, 8640, 1080, 135, 135, 135, 135, 135, 8640, 1080, 135, 8640, 135, 8640, 135, 135, 1080, 1080, 8640, 1080, 8640, 135, 1080, 135, 8640, 8640, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 135, 1080, 8640, 8640, 135, 8640, 1080, 135, 1080, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 1080, 8640, 8640, 1080, 135, 8640, 135, 1080, 1080, 135, 1080, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 1080, 8640, 1080, 135, 1080, 8640, 1080, 8640, 135, 8640, 135, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 135, 8640, 135, 8640, 1080, 1080, 135, 1080, 8640, 1080, 1080, 8640, 135, 8640, 8640, 1080, 135, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 135, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 8640, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 135, 135, 135, 135]
Prompts retrieved: 846315 . Total input tokens: 188744173 . Total output tokens: 169308446
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 119.3084383700043,
    "estimated_duration": 3600.095591991941,
    "input_throughput": 6232.45617419434,
    "output_throughput": 5528.9056891366445,
    "total_throughput": 11761.361863330985,
    "itl": 154.35905765586722,
    "ttft": 1724385.3422087731,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 407,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3284969919594058,
    "arrivals": 281942,
    "finished_requests": 90723,
    "scheduler_time": 157.29393154925313
}
#Debug simulation 
Total elapsed time: 119.30856843013316. Arrivals time: 0.6870546089485288 Scheduler time: 118.39801989356056 Scheduler overhead time: 0.08868264313787222 Adapter cache time: 0.023448053281754255 Engine time: 0.08415579330176115 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-32/adapters_256_slots_64_rate_0.8-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-32/adapters_256_slots_64_rate_0.8-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 135, 8640, 8640, 135, 8640, 1080, 8640, 135, 1080, 135, 8640, 1080, 1080, 1080, 1080, 8640, 135, 135, 135, 1080, 8640, 135, 8640, 8640, 1080, 1080, 1080, 135, 8640, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 8640, 1080, 135, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 135, 8640, 8640, 1080, 135, 135, 8640, 1080, 135, 1080, 1080, 8640, 1080, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 8640, 8640, 135, 8640, 135, 1080, 8640, 8640, 8640, 1080, 135, 8640, 1080, 135, 135, 135, 135, 135, 8640, 1080, 135, 8640, 135, 8640, 135, 135, 1080, 1080, 8640, 1080, 8640, 135, 1080, 135, 8640, 8640, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 135, 1080, 8640, 8640, 135, 8640, 1080, 135, 1080, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 1080, 8640, 8640, 1080, 135, 8640, 135, 1080, 1080, 135, 1080, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 1080, 8640, 1080, 135, 1080, 8640, 1080, 8640, 135, 8640, 135, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 135, 8640, 135, 8640, 1080, 1080, 135, 1080, 8640, 1080, 1080, 8640, 135, 8640, 8640, 1080, 135, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 135, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 8640, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 135, 135, 135, 135]
Prompts retrieved: 846315 . Total input tokens: 188744173 . Total output tokens: 169308446
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 120.53057928197086,
    "estimated_duration": 3600.098469168677,
    "input_throughput": 6232.451193253383,
    "output_throughput": 5528.901270468944,
    "total_throughput": 11761.352463722327,
    "itl": 154.35912947249085,
    "ttft": 1724386.3709450883,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 407,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.330780737455942,
    "arrivals": 281942,
    "finished_requests": 90723,
    "scheduler_time": 157.2939750397313
}
#Debug simulation 
Total elapsed time: 120.53082410106435. Arrivals time: 0.6867431616410613 Scheduler time: 119.61521967779845 Scheduler overhead time: 0.09065315220504999 Adapter cache time: 0.023257989902049303 Engine time: 0.08733550272881985 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-16/adapters_256_slots_64_rate_0.8-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-16/adapters_256_slots_64_rate_0.8-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 135, 8640, 8640, 135, 8640, 1080, 8640, 135, 1080, 135, 8640, 1080, 1080, 1080, 1080, 8640, 135, 135, 135, 1080, 8640, 135, 8640, 8640, 1080, 1080, 1080, 135, 8640, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 8640, 1080, 135, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 135, 8640, 8640, 1080, 135, 135, 8640, 1080, 135, 1080, 1080, 8640, 1080, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 8640, 8640, 135, 8640, 135, 1080, 8640, 8640, 8640, 1080, 135, 8640, 1080, 135, 135, 135, 135, 135, 8640, 1080, 135, 8640, 135, 8640, 135, 135, 1080, 1080, 8640, 1080, 8640, 135, 1080, 135, 8640, 8640, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 135, 1080, 8640, 8640, 135, 8640, 1080, 135, 1080, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 1080, 8640, 8640, 1080, 135, 8640, 135, 1080, 1080, 135, 1080, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 1080, 8640, 1080, 135, 1080, 8640, 1080, 8640, 135, 8640, 135, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 135, 8640, 135, 8640, 1080, 1080, 135, 1080, 8640, 1080, 1080, 8640, 135, 8640, 8640, 1080, 135, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 135, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 8640, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 135, 135, 135, 135]
Prompts retrieved: 846315 . Total input tokens: 188744173 . Total output tokens: 169308446
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 119.92894440470263,
    "estimated_duration": 3600.0682627225665,
    "input_throughput": 6238.244211240585,
    "output_throughput": 5526.072437569531,
    "total_throughput": 11764.316648810116,
    "itl": 154.08885499081953,
    "ttft": 1724889.9968188289,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 402,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2571605865401203,
    "arrivals": 281942,
    "finished_requests": 90715,
    "scheduler_time": 157.4962727456146
}
#Debug simulation 
Total elapsed time: 119.92907376587391. Arrivals time: 0.7058381838724017 Scheduler time: 118.99613133864477 Scheduler overhead time: 0.090279639698565 Adapter cache time: 0.023934607859700918 Engine time: 0.08569231489673257 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-32/adapters_256_slots_64_rate_0.8-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-32/adapters_256_slots_64_rate_0.8-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 135, 8640, 8640, 135, 8640, 1080, 8640, 135, 1080, 135, 8640, 1080, 1080, 1080, 1080, 8640, 135, 135, 135, 1080, 8640, 135, 8640, 8640, 1080, 1080, 1080, 135, 8640, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 8640, 1080, 135, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 135, 8640, 8640, 1080, 135, 135, 8640, 1080, 135, 1080, 1080, 8640, 1080, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 8640, 8640, 135, 8640, 135, 1080, 8640, 8640, 8640, 1080, 135, 8640, 1080, 135, 135, 135, 135, 135, 8640, 1080, 135, 8640, 135, 8640, 135, 135, 1080, 1080, 8640, 1080, 8640, 135, 1080, 135, 8640, 8640, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 135, 1080, 8640, 8640, 135, 8640, 1080, 135, 1080, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 1080, 8640, 8640, 1080, 135, 8640, 135, 1080, 1080, 135, 1080, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 1080, 8640, 1080, 135, 1080, 8640, 1080, 8640, 135, 8640, 135, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 135, 8640, 135, 8640, 1080, 1080, 135, 1080, 8640, 1080, 1080, 8640, 135, 8640, 8640, 1080, 135, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 135, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 8640, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 135, 135, 135, 135]
Prompts retrieved: 846315 . Total input tokens: 188744173 . Total output tokens: 169308446
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 121.11859691981226,
    "estimated_duration": 3600.1194739563803,
    "input_throughput": 6232.414830206231,
    "output_throughput": 5528.869012262444,
    "total_throughput": 11761.283842468674,
    "itl": 154.3592957444995,
    "ttft": 1724393.1390816134,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 407,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.34813475998119,
    "arrivals": 281942,
    "finished_requests": 90723,
    "scheduler_time": 157.2943663736634
}
#Debug simulation 
Total elapsed time: 121.1187244206667. Arrivals time: 0.6630053822882473 Scheduler time: 120.22948452085257 Scheduler overhead time: 0.08959896862506866 Adapter cache time: 0.022814407013356686 Engine time: 0.08714579651132226 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-16/adapters_256_slots_64_rate_0.8-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-16/adapters_256_slots_64_rate_0.8-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 135, 8640, 8640, 135, 8640, 1080, 8640, 135, 1080, 135, 8640, 1080, 1080, 1080, 1080, 8640, 135, 135, 135, 1080, 8640, 135, 8640, 8640, 1080, 1080, 1080, 135, 8640, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 8640, 1080, 135, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 135, 8640, 8640, 1080, 135, 135, 8640, 1080, 135, 1080, 1080, 8640, 1080, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 8640, 8640, 135, 8640, 135, 1080, 8640, 8640, 8640, 1080, 135, 8640, 1080, 135, 135, 135, 135, 135, 8640, 1080, 135, 8640, 135, 8640, 135, 135, 1080, 1080, 8640, 1080, 8640, 135, 1080, 135, 8640, 8640, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 135, 1080, 8640, 8640, 135, 8640, 1080, 135, 1080, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 1080, 8640, 8640, 1080, 135, 8640, 135, 1080, 1080, 135, 1080, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 1080, 8640, 1080, 135, 1080, 8640, 1080, 8640, 135, 8640, 135, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 135, 8640, 135, 8640, 1080, 1080, 135, 1080, 8640, 1080, 1080, 8640, 135, 8640, 8640, 1080, 135, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 135, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 8640, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 135, 135, 135, 135]
Prompts retrieved: 846315 . Total input tokens: 188744173 . Total output tokens: 169308446
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 119.61351787205786,
    "estimated_duration": 3600.0138249822703,
    "input_throughput": 6232.597731790795,
    "output_throughput": 5529.031267011323,
    "total_throughput": 11761.628998802116,
    "itl": 154.3540216209939,
    "ttft": 1724373.3285123673,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 407,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2169504700251792,
    "arrivals": 281942,
    "finished_requests": 90723,
    "scheduler_time": 157.29421190365238
}
#Debug simulation 
Total elapsed time: 119.61365842679515. Arrivals time: 0.6804789872840047 Scheduler time: 118.70844215573743 Scheduler overhead time: 0.08916929317638278 Adapter cache time: 0.023146835155785084 Engine time: 0.0854733632877469 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-32/adapters_256_slots_64_rate_0.8-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-32/adapters_256_slots_64_rate_0.8-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 135, 8640, 8640, 135, 8640, 1080, 8640, 135, 1080, 135, 8640, 1080, 1080, 1080, 1080, 8640, 135, 135, 135, 1080, 8640, 135, 8640, 8640, 1080, 1080, 1080, 135, 8640, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 8640, 1080, 135, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 135, 8640, 8640, 1080, 135, 135, 8640, 1080, 135, 1080, 1080, 8640, 1080, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 8640, 8640, 135, 8640, 135, 1080, 8640, 8640, 8640, 1080, 135, 8640, 1080, 135, 135, 135, 135, 135, 8640, 1080, 135, 8640, 135, 8640, 135, 135, 1080, 1080, 8640, 1080, 8640, 135, 1080, 135, 8640, 8640, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 135, 1080, 8640, 8640, 135, 8640, 1080, 135, 1080, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 1080, 8640, 8640, 1080, 135, 8640, 135, 1080, 1080, 135, 1080, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 1080, 8640, 1080, 135, 1080, 8640, 1080, 8640, 135, 8640, 135, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 135, 8640, 135, 8640, 1080, 1080, 135, 1080, 8640, 1080, 1080, 8640, 135, 8640, 8640, 1080, 135, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 135, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 8640, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 135, 135, 135, 135]
Prompts retrieved: 846315 . Total input tokens: 188744173 . Total output tokens: 169308446
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 120.37615229003131,
    "estimated_duration": 3600.133122713277,
    "input_throughput": 6232.3912019924965,
    "output_throughput": 5528.848051318365,
    "total_throughput": 11761.239253310861,
    "itl": 154.359396372229,
    "ttft": 1724396.082003187,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 407,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3651115211471934,
    "arrivals": 281942,
    "finished_requests": 90723,
    "scheduler_time": 157.29448114195935
}
#Debug simulation 
Total elapsed time: 120.3763125021942. Arrivals time: 0.6701521435752511 Scheduler time: 119.47914715763181 Scheduler overhead time: 0.08997973660007119 Adapter cache time: 0.023081387393176556 Engine time: 0.08644861495122313 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-8/adapters_256_slots_64_rate_0.8-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-8/adapters_256_slots_64_rate_0.8-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 66, 8640, 8640, 66, 8640, 1080, 8640, 66, 1080, 66, 8640, 1080, 1080, 1080, 1080, 8640, 66, 66, 66, 1080, 8640, 66, 8640, 8640, 1080, 1080, 1080, 66, 8640, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 8640, 1080, 66, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 66, 8640, 8640, 1080, 66, 66, 8640, 1080, 66, 1080, 1080, 8640, 1080, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 8640, 8640, 66, 8640, 66, 1080, 8640, 8640, 8640, 1080, 66, 8640, 1080, 66, 66, 66, 66, 66, 8640, 1080, 66, 8640, 66, 8640, 66, 66, 1080, 1080, 8640, 1080, 8640, 66, 1080, 66, 8640, 8640, 66, 8640, 1080, 66, 8640, 66, 66, 8640, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 66, 1080, 8640, 8640, 66, 8640, 1080, 66, 1080, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 1080, 8640, 8640, 1080, 66, 8640, 66, 1080, 1080, 66, 1080, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 1080, 8640, 1080, 66, 1080, 8640, 1080, 8640, 66, 8640, 66, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 66, 8640, 66, 8640, 1080, 1080, 66, 1080, 8640, 1080, 1080, 8640, 66, 8640, 8640, 1080, 66, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 66, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 8640, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 66, 66, 66, 66]
Prompts retrieved: 840450 . Total input tokens: 187460075 . Total output tokens: 168134870
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 122.89271775027737,
    "estimated_duration": 3600.1175691763424,
    "input_throughput": 6277.89497584959,
    "output_throughput": 5528.081130015219,
    "total_throughput": 11805.97610586481,
    "itl": 153.9424246541528,
    "ttft": 1715666.0756872797,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 385,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.178287781414115,
    "arrivals": 279961,
    "finished_requests": 90980,
    "scheduler_time": 157.1500135363098
}
#Debug simulation 
Total elapsed time: 122.89284865697846. Arrivals time: 0.6980182211846113 Scheduler time: 121.9672307507135 Scheduler overhead time: 0.08999275136739016 Adapter cache time: 0.023620665073394775 Engine time: 0.08712134044617414 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-16/adapters_256_slots_64_rate_0.8-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-16/adapters_256_slots_64_rate_0.8-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 66, 8640, 8640, 66, 8640, 1080, 8640, 66, 1080, 66, 8640, 1080, 1080, 1080, 1080, 8640, 66, 66, 66, 1080, 8640, 66, 8640, 8640, 1080, 1080, 1080, 66, 8640, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 8640, 1080, 66, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 66, 8640, 8640, 1080, 66, 66, 8640, 1080, 66, 1080, 1080, 8640, 1080, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 8640, 8640, 66, 8640, 66, 1080, 8640, 8640, 8640, 1080, 66, 8640, 1080, 66, 66, 66, 66, 66, 8640, 1080, 66, 8640, 66, 8640, 66, 66, 1080, 1080, 8640, 1080, 8640, 66, 1080, 66, 8640, 8640, 66, 8640, 1080, 66, 8640, 66, 66, 8640, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 66, 1080, 8640, 8640, 66, 8640, 1080, 66, 1080, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 1080, 8640, 8640, 1080, 66, 8640, 66, 1080, 1080, 66, 1080, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 1080, 8640, 1080, 66, 1080, 8640, 1080, 8640, 66, 8640, 66, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 66, 8640, 66, 8640, 1080, 1080, 66, 1080, 8640, 1080, 1080, 8640, 66, 8640, 8640, 1080, 66, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 66, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 8640, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 66, 66, 66, 66]
Prompts retrieved: 840450 . Total input tokens: 187460075 . Total output tokens: 168134870
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 114.20521100284532,
    "estimated_duration": 3600.12883436768,
    "input_throughput": 6283.88511656512,
    "output_throughput": 5526.62027260327,
    "total_throughput": 11810.50538916839,
    "itl": 153.8462120743023,
    "ttft": 1721776.976365044,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 401,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3085137135977916,
    "arrivals": 279961,
    "finished_requests": 90970,
    "scheduler_time": 157.2017677039982
}
#Debug simulation 
Total elapsed time: 114.20535106491297. Arrivals time: 0.6794504122808576 Scheduler time: 113.30169720528647 Scheduler overhead time: 0.08878553006798029 Adapter cache time: 0.02313163224607706 Engine time: 0.08527546050027013 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-32/adapters_256_slots_64_rate_0.8-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-32/adapters_256_slots_64_rate_0.8-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 66, 8640, 8640, 66, 8640, 1080, 8640, 66, 1080, 66, 8640, 1080, 1080, 1080, 1080, 8640, 66, 66, 66, 1080, 8640, 66, 8640, 8640, 1080, 1080, 1080, 66, 8640, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 8640, 1080, 66, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 66, 8640, 8640, 1080, 66, 66, 8640, 1080, 66, 1080, 1080, 8640, 1080, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 8640, 8640, 66, 8640, 66, 1080, 8640, 8640, 8640, 1080, 66, 8640, 1080, 66, 66, 66, 66, 66, 8640, 1080, 66, 8640, 66, 8640, 66, 66, 1080, 1080, 8640, 1080, 8640, 66, 1080, 66, 8640, 8640, 66, 8640, 1080, 66, 8640, 66, 66, 8640, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 66, 1080, 8640, 8640, 66, 8640, 1080, 66, 1080, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 1080, 8640, 8640, 1080, 66, 8640, 66, 1080, 1080, 66, 1080, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 1080, 8640, 1080, 66, 1080, 8640, 1080, 8640, 66, 8640, 66, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 66, 8640, 66, 8640, 1080, 1080, 66, 1080, 8640, 1080, 1080, 8640, 66, 8640, 8640, 1080, 66, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 66, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 8640, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 66, 66, 66, 66]
Prompts retrieved: 840450 . Total input tokens: 187460075 . Total output tokens: 168134870
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 113.90576917910948,
    "estimated_duration": 3600.131323113509,
    "input_throughput": 6283.880772558897,
    "output_throughput": 5526.616452088983,
    "total_throughput": 11810.497224647881,
    "itl": 153.84626928812074,
    "ttft": 1721777.798691668,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 401,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3108333868905977,
    "arrivals": 279961,
    "finished_requests": 90970,
    "scheduler_time": 157.20179753857454
}
#Debug simulation 
Total elapsed time: 113.90590000199154. Arrivals time: 0.6709057651460171 Scheduler time: 113.01143920700997 Scheduler overhead time: 0.08887672750279307 Adapter cache time: 0.02290294226258993 Engine time: 0.08473042212426662 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-16/adapters_256_slots_64_rate_0.8-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-16/adapters_256_slots_64_rate_0.8-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 66, 8640, 8640, 66, 8640, 1080, 8640, 66, 1080, 66, 8640, 1080, 1080, 1080, 1080, 8640, 66, 66, 66, 1080, 8640, 66, 8640, 8640, 1080, 1080, 1080, 66, 8640, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 8640, 1080, 66, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 66, 8640, 8640, 1080, 66, 66, 8640, 1080, 66, 1080, 1080, 8640, 1080, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 8640, 8640, 66, 8640, 66, 1080, 8640, 8640, 8640, 1080, 66, 8640, 1080, 66, 66, 66, 66, 66, 8640, 1080, 66, 8640, 66, 8640, 66, 66, 1080, 1080, 8640, 1080, 8640, 66, 1080, 66, 8640, 8640, 66, 8640, 1080, 66, 8640, 66, 66, 8640, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 66, 1080, 8640, 8640, 66, 8640, 1080, 66, 1080, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 1080, 8640, 8640, 1080, 66, 8640, 66, 1080, 1080, 66, 1080, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 1080, 8640, 1080, 66, 1080, 8640, 1080, 8640, 66, 8640, 66, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 66, 8640, 66, 8640, 1080, 1080, 66, 1080, 8640, 1080, 1080, 8640, 66, 8640, 8640, 1080, 66, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 66, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 8640, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 66, 66, 66, 66]
Prompts retrieved: 840450 . Total input tokens: 187460075 . Total output tokens: 168134870
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 113.9518723981455,
    "estimated_duration": 3600.084723940988,
    "input_throughput": 6282.700195799824,
    "output_throughput": 5529.850691460096,
    "total_throughput": 11812.550887259918,
    "itl": 154.1410646551942,
    "ttft": 1722127.9336133741,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 391,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2230442473408762,
    "arrivals": 279961,
    "finished_requests": 91015,
    "scheduler_time": 157.03747077322842
}
#Debug simulation 
Total elapsed time: 113.95200031623244. Arrivals time: 0.6712113446556032 Scheduler time: 113.05673066200688 Scheduler overhead time: 0.08892838284373283 Adapter cache time: 0.022164198104292154 Engine time: 0.08530545700341463 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-32/adapters_256_slots_64_rate_0.8-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-32/adapters_256_slots_64_rate_0.8-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 66, 8640, 8640, 66, 8640, 1080, 8640, 66, 1080, 66, 8640, 1080, 1080, 1080, 1080, 8640, 66, 66, 66, 1080, 8640, 66, 8640, 8640, 1080, 1080, 1080, 66, 8640, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 8640, 1080, 66, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 66, 8640, 8640, 1080, 66, 66, 8640, 1080, 66, 1080, 1080, 8640, 1080, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 8640, 8640, 66, 8640, 66, 1080, 8640, 8640, 8640, 1080, 66, 8640, 1080, 66, 66, 66, 66, 66, 8640, 1080, 66, 8640, 66, 8640, 66, 66, 1080, 1080, 8640, 1080, 8640, 66, 1080, 66, 8640, 8640, 66, 8640, 1080, 66, 8640, 66, 66, 8640, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 66, 1080, 8640, 8640, 66, 8640, 1080, 66, 1080, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 1080, 8640, 8640, 1080, 66, 8640, 66, 1080, 1080, 66, 1080, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 1080, 8640, 1080, 66, 1080, 8640, 1080, 8640, 66, 8640, 66, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 66, 8640, 66, 8640, 1080, 1080, 66, 1080, 8640, 1080, 1080, 8640, 66, 8640, 8640, 1080, 66, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 66, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 8640, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 66, 66, 66, 66]
Prompts retrieved: 840450 . Total input tokens: 187460075 . Total output tokens: 168134870
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 114.52748082531616,
    "estimated_duration": 3600.055616313044,
    "input_throughput": 6282.025449140575,
    "output_throughput": 5527.880711015529,
    "total_throughput": 11809.906160156104,
    "itl": 153.87655559385075,
    "ttft": 1721668.0522245124,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 406,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3437879772111818,
    "arrivals": 279961,
    "finished_requests": 90967,
    "scheduler_time": 157.19617459604146
}
#Debug simulation 
Total elapsed time: 114.52760075591505. Arrivals time: 0.6637959131039679 Scheduler time: 113.64099156949669 Scheduler overhead time: 0.08816453022882342 Adapter cache time: 0.02277451381087303 Engine time: 0.084560910705477 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-16/adapters_256_slots_64_rate_0.8-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-16/adapters_256_slots_64_rate_0.8-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 66, 8640, 8640, 66, 8640, 1080, 8640, 66, 1080, 66, 8640, 1080, 1080, 1080, 1080, 8640, 66, 66, 66, 1080, 8640, 66, 8640, 8640, 1080, 1080, 1080, 66, 8640, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 8640, 1080, 66, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 66, 8640, 8640, 1080, 66, 66, 8640, 1080, 66, 1080, 1080, 8640, 1080, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 8640, 8640, 66, 8640, 66, 1080, 8640, 8640, 8640, 1080, 66, 8640, 1080, 66, 66, 66, 66, 66, 8640, 1080, 66, 8640, 66, 8640, 66, 66, 1080, 1080, 8640, 1080, 8640, 66, 1080, 66, 8640, 8640, 66, 8640, 1080, 66, 8640, 66, 66, 8640, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 66, 1080, 8640, 8640, 66, 8640, 1080, 66, 1080, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 1080, 8640, 8640, 1080, 66, 8640, 66, 1080, 1080, 66, 1080, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 1080, 8640, 1080, 66, 1080, 8640, 1080, 8640, 66, 8640, 66, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 66, 8640, 66, 8640, 1080, 1080, 66, 1080, 8640, 1080, 1080, 8640, 66, 8640, 8640, 1080, 66, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 66, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 8640, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 66, 66, 66, 66]
Prompts retrieved: 840450 . Total input tokens: 187460075 . Total output tokens: 168134870
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 122.41481622401625,
    "estimated_duration": 3600.072530161919,
    "input_throughput": 6277.899350817659,
    "output_throughput": 5526.795039072478,
    "total_throughput": 11804.694389890137,
    "itl": 153.84948474649093,
    "ttft": 1715951.363471602,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 391,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.169109665306746,
    "arrivals": 279961,
    "finished_requests": 90992,
    "scheduler_time": 157.200156660622
}
#Debug simulation 
Total elapsed time: 122.41494238330051. Arrivals time: 0.6875640642829239 Scheduler time: 121.50172180496156 Scheduler overhead time: 0.08900720765814185 Adapter cache time: 0.02353947702795267 Engine time: 0.0856201876886189 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-32/adapters_256_slots_64_rate_0.8-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-32/adapters_256_slots_64_rate_0.8-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 66, 8640, 8640, 66, 8640, 1080, 8640, 66, 1080, 66, 8640, 1080, 1080, 1080, 1080, 8640, 66, 66, 66, 1080, 8640, 66, 8640, 8640, 1080, 1080, 1080, 66, 8640, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 8640, 1080, 66, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 66, 8640, 8640, 1080, 66, 66, 8640, 1080, 66, 1080, 1080, 8640, 1080, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 8640, 8640, 66, 8640, 66, 1080, 8640, 8640, 8640, 1080, 66, 8640, 1080, 66, 66, 66, 66, 66, 8640, 1080, 66, 8640, 66, 8640, 66, 66, 1080, 1080, 8640, 1080, 8640, 66, 1080, 66, 8640, 8640, 66, 8640, 1080, 66, 8640, 66, 66, 8640, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 66, 1080, 8640, 8640, 66, 8640, 1080, 66, 1080, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 1080, 8640, 8640, 1080, 66, 8640, 66, 1080, 1080, 66, 1080, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 1080, 8640, 1080, 66, 1080, 8640, 1080, 8640, 66, 8640, 66, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 66, 8640, 66, 8640, 1080, 1080, 66, 1080, 8640, 1080, 1080, 8640, 66, 8640, 8640, 1080, 66, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 66, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 8640, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 66, 66, 66, 66]
Prompts retrieved: 840450 . Total input tokens: 187460075 . Total output tokens: 168134870
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 114.25780579680577,
    "estimated_duration": 3600.084095689205,
    "input_throughput": 6285.953993990713,
    "output_throughput": 5530.711080844407,
    "total_throughput": 11816.665074835119,
    "itl": 154.11313373959885,
    "ttft": 1722151.15911887,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 386,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.293789604827764,
    "arrivals": 279961,
    "finished_requests": 91038,
    "scheduler_time": 157.0439015866203
}
#Debug simulation 
Total elapsed time: 114.25798511970788. Arrivals time: 0.6939726402051747 Scheduler time: 113.33971032639965 Scheduler overhead time: 0.08852930180728436 Adapter cache time: 0.023004842456430197 Engine time: 0.08497975021600723 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-8/adapters_256_slots_64_rate_0.8-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-8/adapters_256_slots_64_rate_0.8-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 33, 8640, 8640, 33, 8640, 1080, 8640, 33, 1080, 33, 8640, 1080, 1080, 1080, 1080, 8640, 33, 33, 33, 1080, 8640, 33, 8640, 8640, 1080, 1080, 1080, 33, 8640, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 8640, 1080, 33, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 33, 8640, 8640, 1080, 33, 33, 8640, 1080, 33, 1080, 1080, 8640, 1080, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 8640, 8640, 33, 8640, 33, 1080, 8640, 8640, 8640, 1080, 33, 8640, 1080, 33, 33, 33, 33, 33, 8640, 1080, 33, 8640, 33, 8640, 33, 33, 1080, 1080, 8640, 1080, 8640, 33, 1080, 33, 8640, 8640, 33, 8640, 1080, 33, 8640, 33, 33, 8640, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 33, 1080, 8640, 8640, 33, 8640, 1080, 33, 1080, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 1080, 8640, 8640, 1080, 33, 8640, 33, 1080, 1080, 33, 1080, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 1080, 8640, 1080, 33, 1080, 8640, 1080, 8640, 33, 8640, 33, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 33, 8640, 33, 8640, 1080, 1080, 33, 1080, 8640, 1080, 1080, 8640, 33, 8640, 8640, 1080, 33, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 33, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 8640, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 33, 33, 33, 33]
Prompts retrieved: 837645 . Total input tokens: 186835947 . Total output tokens: 167577567
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 122.39866996137425,
    "estimated_duration": 3600.101420952408,
    "input_throughput": 6241.226113584269,
    "output_throughput": 5529.865876593363,
    "total_throughput": 11771.091990177632,
    "itl": 154.36287177304942,
    "ttft": 1721333.9027413344,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 391,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1966507078777122,
    "arrivals": 278999,
    "finished_requests": 90552,
    "scheduler_time": 157.08310033629297
}
#Debug simulation 
Total elapsed time: 122.39879636606202. Arrivals time: 0.6726019964553416 Scheduler time: 121.49730802327394 Scheduler overhead time: 0.09032489219680429 Adapter cache time: 0.023200560361146927 Engine time: 0.08771697897464037 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-16/adapters_256_slots_64_rate_0.8-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-16/adapters_256_slots_64_rate_0.8-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 33, 8640, 8640, 33, 8640, 1080, 8640, 33, 1080, 33, 8640, 1080, 1080, 1080, 1080, 8640, 33, 33, 33, 1080, 8640, 33, 8640, 8640, 1080, 1080, 1080, 33, 8640, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 8640, 1080, 33, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 33, 8640, 8640, 1080, 33, 33, 8640, 1080, 33, 1080, 1080, 8640, 1080, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 8640, 8640, 33, 8640, 33, 1080, 8640, 8640, 8640, 1080, 33, 8640, 1080, 33, 33, 33, 33, 33, 8640, 1080, 33, 8640, 33, 8640, 33, 33, 1080, 1080, 8640, 1080, 8640, 33, 1080, 33, 8640, 8640, 33, 8640, 1080, 33, 8640, 33, 33, 8640, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 33, 1080, 8640, 8640, 33, 8640, 1080, 33, 1080, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 1080, 8640, 8640, 1080, 33, 8640, 33, 1080, 1080, 33, 1080, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 1080, 8640, 1080, 33, 1080, 8640, 1080, 8640, 33, 8640, 33, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 33, 8640, 33, 8640, 1080, 1080, 33, 1080, 8640, 1080, 1080, 8640, 33, 8640, 8640, 1080, 33, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 33, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 8640, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 33, 33, 33, 33]
Prompts retrieved: 837645 . Total input tokens: 186835947 . Total output tokens: 167577567
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 124.27604025509208,
    "estimated_duration": 3600.028696410001,
    "input_throughput": 6232.0342119419765,
    "output_throughput": 5527.567327406018,
    "total_throughput": 11759.601539347994,
    "itl": 154.25071395714133,
    "ttft": 1719444.5699141866,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 371,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2122746796556807,
    "arrivals": 278999,
    "finished_requests": 90449,
    "scheduler_time": 157.12811160043847
}
#Debug simulation 
Total elapsed time: 124.27617078600451. Arrivals time: 0.7052810355089605 Scheduler time: 123.33998125977814 Scheduler overhead time: 0.09244481846690178 Adapter cache time: 0.02336239255964756 Engine time: 0.08745828084647655 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-32/adapters_256_slots_64_rate_0.8-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-32/adapters_256_slots_64_rate_0.8-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 33, 8640, 8640, 33, 8640, 1080, 8640, 33, 1080, 33, 8640, 1080, 1080, 1080, 1080, 8640, 33, 33, 33, 1080, 8640, 33, 8640, 8640, 1080, 1080, 1080, 33, 8640, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 8640, 1080, 33, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 33, 8640, 8640, 1080, 33, 33, 8640, 1080, 33, 1080, 1080, 8640, 1080, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 8640, 8640, 33, 8640, 33, 1080, 8640, 8640, 8640, 1080, 33, 8640, 1080, 33, 33, 33, 33, 33, 8640, 1080, 33, 8640, 33, 8640, 33, 33, 1080, 1080, 8640, 1080, 8640, 33, 1080, 33, 8640, 8640, 33, 8640, 1080, 33, 8640, 33, 33, 8640, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 33, 1080, 8640, 8640, 33, 8640, 1080, 33, 1080, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 1080, 8640, 8640, 1080, 33, 8640, 33, 1080, 1080, 33, 1080, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 1080, 8640, 1080, 33, 1080, 8640, 1080, 8640, 33, 8640, 33, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 33, 8640, 33, 8640, 1080, 1080, 33, 1080, 8640, 1080, 1080, 8640, 33, 8640, 8640, 1080, 33, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 33, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 8640, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 33, 33, 33, 33]
Prompts retrieved: 837645 . Total input tokens: 186835947 . Total output tokens: 167577567
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 124.64819996803999,
    "estimated_duration": 3600.030407576069,
    "input_throughput": 6232.031249732141,
    "output_throughput": 5527.564700043307,
    "total_throughput": 11759.595949775448,
    "itl": 154.25074511237625,
    "ttft": 1719444.8630588737,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 371,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.21413186151535,
    "arrivals": 278999,
    "finished_requests": 90449,
    "scheduler_time": 157.12812197227112
}
#Debug simulation 
Total elapsed time: 124.64831959316507. Arrivals time: 0.6948541910387576 Scheduler time: 123.72284707659855 Scheduler overhead time: 0.09246227983385324 Adapter cache time: 0.023020424880087376 Engine time: 0.08754441142082214 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-16/adapters_256_slots_64_rate_0.8-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-16/adapters_256_slots_64_rate_0.8-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 33, 8640, 8640, 33, 8640, 1080, 8640, 33, 1080, 33, 8640, 1080, 1080, 1080, 1080, 8640, 33, 33, 33, 1080, 8640, 33, 8640, 8640, 1080, 1080, 1080, 33, 8640, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 8640, 1080, 33, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 33, 8640, 8640, 1080, 33, 33, 8640, 1080, 33, 1080, 1080, 8640, 1080, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 8640, 8640, 33, 8640, 33, 1080, 8640, 8640, 8640, 1080, 33, 8640, 1080, 33, 33, 33, 33, 33, 8640, 1080, 33, 8640, 33, 8640, 33, 33, 1080, 1080, 8640, 1080, 8640, 33, 1080, 33, 8640, 8640, 33, 8640, 1080, 33, 8640, 33, 33, 8640, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 33, 1080, 8640, 8640, 33, 8640, 1080, 33, 1080, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 1080, 8640, 8640, 1080, 33, 8640, 33, 1080, 1080, 33, 1080, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 1080, 8640, 1080, 33, 1080, 8640, 1080, 8640, 33, 8640, 33, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 33, 8640, 33, 8640, 1080, 1080, 33, 1080, 8640, 1080, 1080, 8640, 33, 8640, 8640, 1080, 33, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 33, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 8640, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 33, 33, 33, 33]
Prompts retrieved: 837645 . Total input tokens: 186835947 . Total output tokens: 167577567
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 120.11948839295655,
    "estimated_duration": 3600.131441461988,
    "input_throughput": 6232.5604953157135,
    "output_throughput": 5520.86620257636,
    "total_throughput": 11753.426697892073,
    "itl": 153.7699273548775,
    "ttft": 1722854.1362481806,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 390,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2212799830012953,
    "arrivals": 278999,
    "finished_requests": 90394,
    "scheduler_time": 157.40861364675956
}
#Debug simulation 
Total elapsed time: 120.11961667984724. Arrivals time: 0.691131220664829 Scheduler time: 119.20137154962867 Scheduler overhead time: 0.08996974071487784 Adapter cache time: 0.02293616672977805 Engine time: 0.08679320523515344 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-32/adapters_256_slots_64_rate_0.8-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-32/adapters_256_slots_64_rate_0.8-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 33, 8640, 8640, 33, 8640, 1080, 8640, 33, 1080, 33, 8640, 1080, 1080, 1080, 1080, 8640, 33, 33, 33, 1080, 8640, 33, 8640, 8640, 1080, 1080, 1080, 33, 8640, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 8640, 1080, 33, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 33, 8640, 8640, 1080, 33, 33, 8640, 1080, 33, 1080, 1080, 8640, 1080, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 8640, 8640, 33, 8640, 33, 1080, 8640, 8640, 8640, 1080, 33, 8640, 1080, 33, 33, 33, 33, 33, 8640, 1080, 33, 8640, 33, 8640, 33, 33, 1080, 1080, 8640, 1080, 8640, 33, 1080, 33, 8640, 8640, 33, 8640, 1080, 33, 8640, 33, 33, 8640, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 33, 1080, 8640, 8640, 33, 8640, 1080, 33, 1080, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 1080, 8640, 8640, 1080, 33, 8640, 33, 1080, 1080, 33, 1080, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 1080, 8640, 1080, 33, 1080, 8640, 1080, 8640, 33, 8640, 33, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 33, 8640, 33, 8640, 1080, 1080, 33, 1080, 8640, 1080, 1080, 8640, 33, 8640, 8640, 1080, 33, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 33, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 8640, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 33, 33, 33, 33]
Prompts retrieved: 837645 . Total input tokens: 186835947 . Total output tokens: 167577567
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 123.84833305096254,
    "estimated_duration": 3600.047936480304,
    "input_throughput": 6232.00090550315,
    "output_throughput": 5527.537785914943,
    "total_throughput": 11759.538691418093,
    "itl": 154.25146443179415,
    "ttft": 1719449.1385450277,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 371,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2295995772443757,
    "arrivals": 278999,
    "finished_requests": 90449,
    "scheduler_time": 157.12863003969164
}
#Debug simulation 
Total elapsed time: 123.84846457093954. Arrivals time: 0.6895572789944708 Scheduler time: 122.92747623752803 Scheduler overhead time: 0.09180623153224587 Adapter cache time: 0.023101724684238434 Engine time: 0.08810193371027708 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-16/adapters_256_slots_64_rate_0.8-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-16/adapters_256_slots_64_rate_0.8-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 33, 8640, 8640, 33, 8640, 1080, 8640, 33, 1080, 33, 8640, 1080, 1080, 1080, 1080, 8640, 33, 33, 33, 1080, 8640, 33, 8640, 8640, 1080, 1080, 1080, 33, 8640, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 8640, 1080, 33, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 33, 8640, 8640, 1080, 33, 33, 8640, 1080, 33, 1080, 1080, 8640, 1080, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 8640, 8640, 33, 8640, 33, 1080, 8640, 8640, 8640, 1080, 33, 8640, 1080, 33, 33, 33, 33, 33, 8640, 1080, 33, 8640, 33, 8640, 33, 33, 1080, 1080, 8640, 1080, 8640, 33, 1080, 33, 8640, 8640, 33, 8640, 1080, 33, 8640, 33, 33, 8640, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 33, 1080, 8640, 8640, 33, 8640, 1080, 33, 1080, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 1080, 8640, 8640, 1080, 33, 8640, 33, 1080, 1080, 33, 1080, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 1080, 8640, 1080, 33, 1080, 8640, 1080, 8640, 33, 8640, 33, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 33, 8640, 33, 8640, 1080, 1080, 33, 1080, 8640, 1080, 1080, 8640, 33, 8640, 8640, 1080, 33, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 33, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 8640, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 33, 33, 33, 33]
Prompts retrieved: 837645 . Total input tokens: 186835947 . Total output tokens: 167577567
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 120.78124914411455,
    "estimated_duration": 3600.065764021171,
    "input_throughput": 6241.164598866441,
    "output_throughput": 5529.6387079785945,
    "total_throughput": 11770.803306845035,
    "itl": 154.36005812647247,
    "ttft": 1721246.288224364,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 396,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1840599167812564,
    "arrivals": 278999,
    "finished_requests": 90567,
    "scheduler_time": 157.0810872729509
}
#Debug simulation 
Total elapsed time: 120.7813856373541. Arrivals time: 0.708042424172163 Scheduler time: 119.84812282258645 Scheduler overhead time: 0.08844583155587316 Adapter cache time: 0.02305527962744236 Engine time: 0.0860269176773727 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-32/adapters_256_slots_64_rate_0.8-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-32/adapters_256_slots_64_rate_0.8-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 33, 8640, 8640, 33, 8640, 1080, 8640, 33, 1080, 33, 8640, 1080, 1080, 1080, 1080, 8640, 33, 33, 33, 1080, 8640, 33, 8640, 8640, 1080, 1080, 1080, 33, 8640, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 8640, 1080, 33, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 33, 8640, 8640, 1080, 33, 33, 8640, 1080, 33, 1080, 1080, 8640, 1080, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 8640, 8640, 33, 8640, 33, 1080, 8640, 8640, 8640, 1080, 33, 8640, 1080, 33, 33, 33, 33, 33, 8640, 1080, 33, 8640, 33, 8640, 33, 33, 1080, 1080, 8640, 1080, 8640, 33, 1080, 33, 8640, 8640, 33, 8640, 1080, 33, 8640, 33, 33, 8640, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 33, 1080, 8640, 8640, 33, 8640, 1080, 33, 1080, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 1080, 8640, 8640, 1080, 33, 8640, 33, 1080, 1080, 33, 1080, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 1080, 8640, 1080, 33, 1080, 8640, 1080, 8640, 33, 8640, 33, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 33, 8640, 33, 8640, 1080, 1080, 33, 1080, 8640, 1080, 1080, 8640, 33, 8640, 8640, 1080, 33, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 33, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 8640, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 33, 33, 33, 33]
Prompts retrieved: 837645 . Total input tokens: 186835947 . Total output tokens: 167577567
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 124.1743610939011,
    "estimated_duration": 3600.0940906490027,
    "input_throughput": 6233.486524224274,
    "output_throughput": 5528.250512033743,
    "total_throughput": 11761.737036258017,
    "itl": 154.2409044105991,
    "ttft": 1719389.2882640606,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 369,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2388087754324106,
    "arrivals": 278999,
    "finished_requests": 90462,
    "scheduler_time": 157.13668567871295
}
#Debug simulation 
Total elapsed time: 124.17448946321383. Arrivals time: 0.6644231569953263 Scheduler time: 123.27722901385278 Scheduler overhead time: 0.09347350848838687 Adapter cache time: 0.02291828626766801 Engine time: 0.08888106886297464 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-8/adapters_256_slots_64_rate_0.8-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-8/adapters_256_slots_64_rate_0.8-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 270, 8640, 8640, 270, 8640, 540, 8640, 270, 540, 270, 8640, 540, 540, 540, 540, 8640, 270, 270, 270, 540, 8640, 270, 8640, 8640, 540, 540, 540, 270, 8640, 270, 540, 540, 270, 540, 270, 270, 540, 540, 8640, 540, 270, 540, 8640, 540, 540, 8640, 540, 8640, 270, 8640, 8640, 540, 270, 270, 8640, 540, 270, 540, 540, 8640, 540, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 8640, 8640, 270, 8640, 270, 540, 8640, 8640, 8640, 540, 270, 8640, 540, 270, 270, 270, 270, 270, 8640, 540, 270, 8640, 270, 8640, 270, 270, 540, 540, 8640, 540, 8640, 270, 540, 270, 8640, 8640, 270, 8640, 540, 270, 8640, 270, 270, 8640, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 270, 540, 8640, 8640, 270, 8640, 540, 270, 540, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 540, 8640, 8640, 540, 270, 8640, 270, 540, 540, 270, 540, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 540, 8640, 540, 270, 540, 8640, 540, 8640, 270, 8640, 270, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 270, 8640, 270, 8640, 540, 540, 270, 540, 8640, 540, 540, 8640, 270, 8640, 8640, 540, 270, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 270, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 8640, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 8640, 540, 270, 270, 270, 270]
Prompts retrieved: 811890 . Total input tokens: 181009391 . Total output tokens: 162494279
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 127.12742880731821,
    "estimated_duration": 3600.057200725848,
    "input_throughput": 6245.81409302788,
    "output_throughput": 5524.828882160487,
    "total_throughput": 11770.642975188368,
    "itl": 153.76503737446663,
    "ttft": 1698646.359906347,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 508,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5547277739178569,
    "arrivals": 270522,
    "finished_requests": 90781,
    "scheduler_time": 157.26370046151618
}
#Debug simulation 
Total elapsed time: 127.12753963517025. Arrivals time: 0.6634365394711494 Scheduler time: 126.23404562380165 Scheduler overhead time: 0.09051065612584352 Adapter cache time: 0.026419904548674822 Engine time: 0.08568200748413801 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-16/adapters_256_slots_64_rate_0.8-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-16/adapters_256_slots_64_rate_0.8-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 270, 8640, 8640, 270, 8640, 540, 8640, 270, 540, 270, 8640, 540, 540, 540, 540, 8640, 270, 270, 270, 540, 8640, 270, 8640, 8640, 540, 540, 540, 270, 8640, 270, 540, 540, 270, 540, 270, 270, 540, 540, 8640, 540, 270, 540, 8640, 540, 540, 8640, 540, 8640, 270, 8640, 8640, 540, 270, 270, 8640, 540, 270, 540, 540, 8640, 540, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 8640, 8640, 270, 8640, 270, 540, 8640, 8640, 8640, 540, 270, 8640, 540, 270, 270, 270, 270, 270, 8640, 540, 270, 8640, 270, 8640, 270, 270, 540, 540, 8640, 540, 8640, 270, 540, 270, 8640, 8640, 270, 8640, 540, 270, 8640, 270, 270, 8640, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 270, 540, 8640, 8640, 270, 8640, 540, 270, 540, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 540, 8640, 8640, 540, 270, 8640, 270, 540, 540, 270, 540, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 540, 8640, 540, 270, 540, 8640, 540, 8640, 270, 8640, 270, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 270, 8640, 270, 8640, 540, 540, 270, 540, 8640, 540, 540, 8640, 270, 8640, 8640, 540, 270, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 270, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 8640, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 8640, 540, 270, 270, 270, 270]
Prompts retrieved: 811890 . Total input tokens: 181009391 . Total output tokens: 162494279
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 127.68867286806926,
    "estimated_duration": 3600.167915051929,
    "input_throughput": 6253.448597737215,
    "output_throughput": 5533.568841805715,
    "total_throughput": 11787.017439542931,
    "itl": 154.30208723690683,
    "ttft": 1698718.0117390957,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 496,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.617901401356799,
    "arrivals": 270522,
    "finished_requests": 90923,
    "scheduler_time": 156.80745912259206
}
#Debug simulation 
Total elapsed time: 127.68879186175764. Arrivals time: 0.6880633230321109 Scheduler time: 126.76730124978349 Scheduler overhead time: 0.09246526658535004 Adapter cache time: 0.024979349225759506 Engine time: 0.08853294560685754 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-32/adapters_256_slots_64_rate_0.8-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-32/adapters_256_slots_64_rate_0.8-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 270, 8640, 8640, 270, 8640, 540, 8640, 270, 540, 270, 8640, 540, 540, 540, 540, 8640, 270, 270, 270, 540, 8640, 270, 8640, 8640, 540, 540, 540, 270, 8640, 270, 540, 540, 270, 540, 270, 270, 540, 540, 8640, 540, 270, 540, 8640, 540, 540, 8640, 540, 8640, 270, 8640, 8640, 540, 270, 270, 8640, 540, 270, 540, 540, 8640, 540, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 8640, 8640, 270, 8640, 270, 540, 8640, 8640, 8640, 540, 270, 8640, 540, 270, 270, 270, 270, 270, 8640, 540, 270, 8640, 270, 8640, 270, 270, 540, 540, 8640, 540, 8640, 270, 540, 270, 8640, 8640, 270, 8640, 540, 270, 8640, 270, 270, 8640, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 270, 540, 8640, 8640, 270, 8640, 540, 270, 540, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 540, 8640, 8640, 540, 270, 8640, 270, 540, 540, 270, 540, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 540, 8640, 540, 270, 540, 8640, 540, 8640, 270, 8640, 270, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 270, 8640, 270, 8640, 540, 540, 270, 540, 8640, 540, 540, 8640, 270, 8640, 8640, 540, 270, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 270, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 8640, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 8640, 540, 270, 270, 270, 270]
Prompts retrieved: 811890 . Total input tokens: 181009391 . Total output tokens: 162494279
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 127.58126594917849,
    "estimated_duration": 3600.0029942357223,
    "input_throughput": 6253.358409991907,
    "output_throughput": 5533.674564131651,
    "total_throughput": 11787.032974123558,
    "itl": 154.30270697874315,
    "ttft": 1698693.1127485875,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 496,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6208770221844413,
    "arrivals": 270522,
    "finished_requests": 90919,
    "scheduler_time": 156.79981346118947
}
#Debug simulation 
Total elapsed time: 127.58137942804024. Arrivals time: 0.6916492404416203 Scheduler time: 126.65788384713233 Scheduler overhead time: 0.09120210446417332 Adapter cache time: 0.0253852098248899 Engine time: 0.0877182325348258 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-16-16/adapters_256_slots_64_rate_0.8-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-16-16/adapters_256_slots_64_rate_0.8-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 270, 8640, 8640, 270, 8640, 540, 8640, 270, 540, 270, 8640, 540, 540, 540, 540, 8640, 270, 270, 270, 540, 8640, 270, 8640, 8640, 540, 540, 540, 270, 8640, 270, 540, 540, 270, 540, 270, 270, 540, 540, 8640, 540, 270, 540, 8640, 540, 540, 8640, 540, 8640, 270, 8640, 8640, 540, 270, 270, 8640, 540, 270, 540, 540, 8640, 540, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 8640, 8640, 270, 8640, 270, 540, 8640, 8640, 8640, 540, 270, 8640, 540, 270, 270, 270, 270, 270, 8640, 540, 270, 8640, 270, 8640, 270, 270, 540, 540, 8640, 540, 8640, 270, 540, 270, 8640, 8640, 270, 8640, 540, 270, 8640, 270, 270, 8640, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 270, 540, 8640, 8640, 270, 8640, 540, 270, 540, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 540, 8640, 8640, 540, 270, 8640, 270, 540, 540, 270, 540, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 540, 8640, 540, 270, 540, 8640, 540, 8640, 270, 8640, 270, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 270, 8640, 270, 8640, 540, 540, 270, 540, 8640, 540, 540, 8640, 270, 8640, 8640, 540, 270, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 270, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 8640, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 8640, 540, 270, 270, 270, 270]
Prompts retrieved: 811890 . Total input tokens: 181009391 . Total output tokens: 162494279
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 127.00966218160465,
    "estimated_duration": 3600.1027381149365,
    "input_throughput": 6253.602365744828,
    "output_throughput": 5533.872905647048,
    "total_throughput": 11787.475271391877,
    "itl": 154.29770187287414,
    "ttft": 1698714.7123608259,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 497,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5555162007012342,
    "arrivals": 270522,
    "finished_requests": 90927,
    "scheduler_time": 156.8065759445615
}
#Debug simulation 
Total elapsed time: 127.00979443080723. Arrivals time: 0.6783540956676006 Scheduler time: 126.09635665733367 Scheduler overhead time: 0.09347024885937572 Adapter cache time: 0.02623808104544878 Engine time: 0.08788731275126338 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-16-32/adapters_256_slots_64_rate_0.8-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-16-32/adapters_256_slots_64_rate_0.8-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 270, 8640, 8640, 270, 8640, 540, 8640, 270, 540, 270, 8640, 540, 540, 540, 540, 8640, 270, 270, 270, 540, 8640, 270, 8640, 8640, 540, 540, 540, 270, 8640, 270, 540, 540, 270, 540, 270, 270, 540, 540, 8640, 540, 270, 540, 8640, 540, 540, 8640, 540, 8640, 270, 8640, 8640, 540, 270, 270, 8640, 540, 270, 540, 540, 8640, 540, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 8640, 8640, 270, 8640, 270, 540, 8640, 8640, 8640, 540, 270, 8640, 540, 270, 270, 270, 270, 270, 8640, 540, 270, 8640, 270, 8640, 270, 270, 540, 540, 8640, 540, 8640, 270, 540, 270, 8640, 8640, 270, 8640, 540, 270, 8640, 270, 270, 8640, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 270, 540, 8640, 8640, 270, 8640, 540, 270, 540, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 540, 8640, 8640, 540, 270, 8640, 270, 540, 540, 270, 540, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 540, 8640, 540, 270, 540, 8640, 540, 8640, 270, 8640, 270, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 270, 8640, 270, 8640, 540, 540, 270, 540, 8640, 540, 540, 8640, 270, 8640, 8640, 540, 270, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 270, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 8640, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 8640, 540, 270, 270, 270, 270]
Prompts retrieved: 811890 . Total input tokens: 181009391 . Total output tokens: 162494279
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 127.15332942083478,
    "estimated_duration": 3600.0389052207224,
    "input_throughput": 6253.274920821936,
    "output_throughput": 5533.644642314942,
    "total_throughput": 11786.919563136877,
    "itl": 154.30436482160735,
    "ttft": 1698715.9371464904,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 496,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6411233817972286,
    "arrivals": 270522,
    "finished_requests": 90919,
    "scheduler_time": 156.80081550979705
}
#Debug simulation 
Total elapsed time: 127.15345553075895. Arrivals time: 0.6794917206279933 Scheduler time: 126.23799816193059 Scheduler overhead time: 0.09368931828066707 Adapter cache time: 0.02632847521454096 Engine time: 0.08784232893958688 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_16-16-16/adapters_256_slots_64_rate_0.8-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_16-16-16/adapters_256_slots_64_rate_0.8-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 270, 8640, 8640, 270, 8640, 540, 8640, 270, 540, 270, 8640, 540, 540, 540, 540, 8640, 270, 270, 270, 540, 8640, 270, 8640, 8640, 540, 540, 540, 270, 8640, 270, 540, 540, 270, 540, 270, 270, 540, 540, 8640, 540, 270, 540, 8640, 540, 540, 8640, 540, 8640, 270, 8640, 8640, 540, 270, 270, 8640, 540, 270, 540, 540, 8640, 540, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 8640, 8640, 270, 8640, 270, 540, 8640, 8640, 8640, 540, 270, 8640, 540, 270, 270, 270, 270, 270, 8640, 540, 270, 8640, 270, 8640, 270, 270, 540, 540, 8640, 540, 8640, 270, 540, 270, 8640, 8640, 270, 8640, 540, 270, 8640, 270, 270, 8640, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 270, 540, 8640, 8640, 270, 8640, 540, 270, 540, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 540, 8640, 8640, 540, 270, 8640, 270, 540, 540, 270, 540, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 540, 8640, 540, 270, 540, 8640, 540, 8640, 270, 8640, 270, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 270, 8640, 270, 8640, 540, 540, 270, 540, 8640, 540, 540, 8640, 270, 8640, 8640, 540, 270, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 270, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 8640, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 8640, 540, 270, 270, 270, 270]
Prompts retrieved: 811890 . Total input tokens: 181009391 . Total output tokens: 162494279
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 127.09325478924438,
    "estimated_duration": 3600.031727340935,
    "input_throughput": 6245.356625400302,
    "output_throughput": 5524.452978832462,
    "total_throughput": 11769.809604232763,
    "itl": 153.67656178350063,
    "ttft": 1698242.9438949577,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 504,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.50698534863068,
    "arrivals": 270522,
    "finished_requests": 90777,
    "scheduler_time": 157.33597902206125
}
#Debug simulation 
Total elapsed time: 127.09339047316462. Arrivals time: 0.6781074074096978 Scheduler time: 126.18445421988145 Scheduler overhead time: 0.09067460568621755 Adapter cache time: 0.026314469520002604 Engine time: 0.08557445323094726 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_16-16-32/adapters_256_slots_64_rate_0.8-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_16-16-32/adapters_256_slots_64_rate_0.8-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 270, 8640, 8640, 270, 8640, 540, 8640, 270, 540, 270, 8640, 540, 540, 540, 540, 8640, 270, 270, 270, 540, 8640, 270, 8640, 8640, 540, 540, 540, 270, 8640, 270, 540, 540, 270, 540, 270, 270, 540, 540, 8640, 540, 270, 540, 8640, 540, 540, 8640, 540, 8640, 270, 8640, 8640, 540, 270, 270, 8640, 540, 270, 540, 540, 8640, 540, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 8640, 8640, 270, 8640, 270, 540, 8640, 8640, 8640, 540, 270, 8640, 540, 270, 270, 270, 270, 270, 8640, 540, 270, 8640, 270, 8640, 270, 270, 540, 540, 8640, 540, 8640, 270, 540, 270, 8640, 8640, 270, 8640, 540, 270, 8640, 270, 270, 8640, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 270, 540, 8640, 8640, 270, 8640, 540, 270, 540, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 540, 8640, 8640, 540, 270, 8640, 270, 540, 540, 270, 540, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 540, 8640, 540, 270, 540, 8640, 540, 8640, 270, 8640, 270, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 270, 8640, 270, 8640, 540, 540, 270, 540, 8640, 540, 540, 8640, 270, 8640, 8640, 540, 270, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 270, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 8640, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 8640, 540, 270, 270, 270, 270]
Prompts retrieved: 811890 . Total input tokens: 181009391 . Total output tokens: 162494279
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 127.68340340489522,
    "estimated_duration": 3600.143380133209,
    "input_throughput": 6253.211781572715,
    "output_throughput": 5533.558221579186,
    "total_throughput": 11786.770003151902,
    "itl": 154.30593587660894,
    "ttft": 1698745.4564681984,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 496,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6623757717013348,
    "arrivals": 270522,
    "finished_requests": 90921,
    "scheduler_time": 156.80342859825768
}
#Debug simulation 
Total elapsed time: 127.68353392323479. Arrivals time: 0.6829829188063741 Scheduler time: 126.7667368883267 Scheduler overhead time: 0.09159757569432259 Adapter cache time: 0.026545699685811996 Engine time: 0.08796529890969396 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-8/adapters_256_slots_64_rate_0.8-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-8/adapters_256_slots_64_rate_0.8-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 135, 8640, 8640, 135, 8640, 540, 8640, 135, 540, 135, 8640, 540, 540, 540, 540, 8640, 135, 135, 135, 540, 8640, 135, 8640, 8640, 540, 540, 540, 135, 8640, 135, 540, 540, 135, 540, 135, 135, 540, 540, 8640, 540, 135, 540, 8640, 540, 540, 8640, 540, 8640, 135, 8640, 8640, 540, 135, 135, 8640, 540, 135, 540, 540, 8640, 540, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 8640, 8640, 135, 8640, 135, 540, 8640, 8640, 8640, 540, 135, 8640, 540, 135, 135, 135, 135, 135, 8640, 540, 135, 8640, 135, 8640, 135, 135, 540, 540, 8640, 540, 8640, 135, 540, 135, 8640, 8640, 135, 8640, 540, 135, 8640, 135, 135, 8640, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 135, 540, 8640, 8640, 135, 8640, 540, 135, 540, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 540, 8640, 8640, 540, 135, 8640, 135, 540, 540, 135, 540, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 540, 8640, 540, 135, 540, 8640, 540, 8640, 135, 8640, 135, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 135, 8640, 135, 8640, 540, 540, 135, 540, 8640, 540, 540, 8640, 135, 8640, 8640, 540, 135, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 135, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 8640, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 8640, 540, 135, 135, 135, 135]
Prompts retrieved: 800415 . Total input tokens: 178436095 . Total output tokens: 160189560
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 129.86425050534308,
    "estimated_duration": 3600.1610102590766,
    "input_throughput": 6248.62941848846,
    "output_throughput": 5535.150495551301,
    "total_throughput": 11783.77991403976,
    "itl": 154.81925228574025,
    "ttft": 1695969.7683003775,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 467,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4292477764166096,
    "arrivals": 266663,
    "finished_requests": 90567,
    "scheduler_time": 156.42891616968438
}
#Debug simulation 
Total elapsed time: 129.86438808916137. Arrivals time: 0.6658362103626132 Scheduler time: 128.96251607406884 Scheduler overhead time: 0.09344198042526841 Adapter cache time: 0.02535677468404174 Engine time: 0.08904264168813825 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-16/adapters_256_slots_64_rate_0.8-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-16/adapters_256_slots_64_rate_0.8-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 135, 8640, 8640, 135, 8640, 540, 8640, 135, 540, 135, 8640, 540, 540, 540, 540, 8640, 135, 135, 135, 540, 8640, 135, 8640, 8640, 540, 540, 540, 135, 8640, 135, 540, 540, 135, 540, 135, 135, 540, 540, 8640, 540, 135, 540, 8640, 540, 540, 8640, 540, 8640, 135, 8640, 8640, 540, 135, 135, 8640, 540, 135, 540, 540, 8640, 540, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 8640, 8640, 135, 8640, 135, 540, 8640, 8640, 8640, 540, 135, 8640, 540, 135, 135, 135, 135, 135, 8640, 540, 135, 8640, 135, 8640, 135, 135, 540, 540, 8640, 540, 8640, 135, 540, 135, 8640, 8640, 135, 8640, 540, 135, 8640, 135, 135, 8640, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 135, 540, 8640, 8640, 135, 8640, 540, 135, 540, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 540, 8640, 8640, 540, 135, 8640, 135, 540, 540, 135, 540, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 540, 8640, 540, 135, 540, 8640, 540, 8640, 135, 8640, 135, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 135, 8640, 135, 8640, 540, 540, 135, 540, 8640, 540, 540, 8640, 135, 8640, 8640, 540, 135, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 135, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 8640, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 8640, 540, 135, 135, 135, 135]
Prompts retrieved: 800415 . Total input tokens: 178436095 . Total output tokens: 160189560
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 127.88874151278287,
    "estimated_duration": 3600.0372449843712,
    "input_throughput": 6248.755351445721,
    "output_throughput": 5535.248566598235,
    "total_throughput": 11784.003918043956,
    "itl": 154.82442338678575,
    "ttft": 1695939.9084045005,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 467,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5234266317542702,
    "arrivals": 266663,
    "finished_requests": 90564,
    "scheduler_time": 156.4189192613623
}
#Debug simulation 
Total elapsed time: 127.88886424899101. Arrivals time: 0.7018193285912275 Scheduler time: 126.95057392539456 Scheduler overhead time: 0.09319197712466121 Adapter cache time: 0.025712696369737387 Engine time: 0.08927392913028598 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-32/adapters_256_slots_64_rate_0.8-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-32/adapters_256_slots_64_rate_0.8-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 135, 8640, 8640, 135, 8640, 540, 8640, 135, 540, 135, 8640, 540, 540, 540, 540, 8640, 135, 135, 135, 540, 8640, 135, 8640, 8640, 540, 540, 540, 135, 8640, 135, 540, 540, 135, 540, 135, 135, 540, 540, 8640, 540, 135, 540, 8640, 540, 540, 8640, 540, 8640, 135, 8640, 8640, 540, 135, 135, 8640, 540, 135, 540, 540, 8640, 540, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 8640, 8640, 135, 8640, 135, 540, 8640, 8640, 8640, 540, 135, 8640, 540, 135, 135, 135, 135, 135, 8640, 540, 135, 8640, 135, 8640, 135, 135, 540, 540, 8640, 540, 8640, 135, 540, 135, 8640, 8640, 135, 8640, 540, 135, 8640, 135, 135, 8640, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 135, 540, 8640, 8640, 135, 8640, 540, 135, 540, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 540, 8640, 8640, 540, 135, 8640, 135, 540, 540, 135, 540, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 540, 8640, 540, 135, 540, 8640, 540, 8640, 135, 8640, 135, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 135, 8640, 135, 8640, 540, 540, 135, 540, 8640, 540, 540, 8640, 135, 8640, 8640, 540, 135, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 135, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 8640, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 8640, 540, 135, 135, 135, 135]
Prompts retrieved: 800415 . Total input tokens: 178436095 . Total output tokens: 160189560
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 127.32768026087433,
    "estimated_duration": 3600.0401538436586,
    "input_throughput": 6248.709191752235,
    "output_throughput": 5535.195761281884,
    "total_throughput": 11783.90495303412,
    "itl": 154.8246032317979,
    "ttft": 1695946.9966104398,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 467,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5262072731740863,
    "arrivals": 266663,
    "finished_requests": 90563,
    "scheduler_time": 156.41919570030782
}
#Debug simulation 
Total elapsed time: 127.32781314477324. Arrivals time: 0.7032600715756416 Scheduler time: 126.39179965248331 Scheduler overhead time: 0.09183805342763662 Adapter cache time: 0.025577408727258444 Engine time: 0.08737936476245522 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-16/adapters_256_slots_64_rate_0.8-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-16/adapters_256_slots_64_rate_0.8-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 135, 8640, 8640, 135, 8640, 540, 8640, 135, 540, 135, 8640, 540, 540, 540, 540, 8640, 135, 135, 135, 540, 8640, 135, 8640, 8640, 540, 540, 540, 135, 8640, 135, 540, 540, 135, 540, 135, 135, 540, 540, 8640, 540, 135, 540, 8640, 540, 540, 8640, 540, 8640, 135, 8640, 8640, 540, 135, 135, 8640, 540, 135, 540, 540, 8640, 540, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 8640, 8640, 135, 8640, 135, 540, 8640, 8640, 8640, 540, 135, 8640, 540, 135, 135, 135, 135, 135, 8640, 540, 135, 8640, 135, 8640, 135, 135, 540, 540, 8640, 540, 8640, 135, 540, 135, 8640, 8640, 135, 8640, 540, 135, 8640, 135, 135, 8640, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 135, 540, 8640, 8640, 135, 8640, 540, 135, 540, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 540, 8640, 8640, 540, 135, 8640, 135, 540, 540, 135, 540, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 540, 8640, 540, 135, 540, 8640, 540, 8640, 135, 8640, 135, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 135, 8640, 135, 8640, 540, 540, 135, 540, 8640, 540, 540, 8640, 135, 8640, 8640, 540, 135, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 135, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 8640, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 8640, 540, 135, 135, 135, 135]
Prompts retrieved: 800415 . Total input tokens: 178436095 . Total output tokens: 160189560
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 127.93250598898157,
    "estimated_duration": 3600.0184808555036,
    "input_throughput": 6248.77264370436,
    "output_throughput": 5535.235473364733,
    "total_throughput": 11784.008117069094,
    "itl": 154.82088328546178,
    "ttft": 1695932.673190656,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 467,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4609115480328878,
    "arrivals": 266663,
    "finished_requests": 90564,
    "scheduler_time": 156.42112405408244
}
#Debug simulation 
Total elapsed time: 127.93263073591515. Arrivals time: 0.6932892017066479 Scheduler time: 127.0064842524007 Scheduler overhead time: 0.09247058443725109 Adapter cache time: 0.02569983247667551 Engine time: 0.08673743344843388 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-32/adapters_256_slots_64_rate_0.8-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-32/adapters_256_slots_64_rate_0.8-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 135, 8640, 8640, 135, 8640, 540, 8640, 135, 540, 135, 8640, 540, 540, 540, 540, 8640, 135, 135, 135, 540, 8640, 135, 8640, 8640, 540, 540, 540, 135, 8640, 135, 540, 540, 135, 540, 135, 135, 540, 540, 8640, 540, 135, 540, 8640, 540, 540, 8640, 540, 8640, 135, 8640, 8640, 540, 135, 135, 8640, 540, 135, 540, 540, 8640, 540, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 8640, 8640, 135, 8640, 135, 540, 8640, 8640, 8640, 540, 135, 8640, 540, 135, 135, 135, 135, 135, 8640, 540, 135, 8640, 135, 8640, 135, 135, 540, 540, 8640, 540, 8640, 135, 540, 135, 8640, 8640, 135, 8640, 540, 135, 8640, 135, 135, 8640, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 135, 540, 8640, 8640, 135, 8640, 540, 135, 540, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 540, 8640, 8640, 540, 135, 8640, 135, 540, 540, 135, 540, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 540, 8640, 540, 135, 540, 8640, 540, 8640, 135, 8640, 135, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 135, 8640, 135, 8640, 540, 540, 135, 540, 8640, 540, 540, 8640, 135, 8640, 8640, 540, 135, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 135, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 8640, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 8640, 540, 135, 135, 135, 135]
Prompts retrieved: 800415 . Total input tokens: 178436095 . Total output tokens: 160189560
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 127.46377602871507,
    "estimated_duration": 3600.118427109952,
    "input_throughput": 6249.6155211376445,
    "output_throughput": 5535.897611012483,
    "total_throughput": 11785.513132150129,
    "itl": 154.82394817096565,
    "ttft": 1695884.426953791,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 469,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.552334888968621,
    "arrivals": 266663,
    "finished_requests": 90577,
    "scheduler_time": 156.42409748049144
}
#Debug simulation 
Total elapsed time: 127.4639160996303. Arrivals time: 0.6977399801835418 Scheduler time: 126.53338355058804 Scheduler overhead time: 0.09067340288311243 Adapter cache time: 0.026015699841082096 Engine time: 0.0872732400894165 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-16/adapters_256_slots_64_rate_0.8-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-16/adapters_256_slots_64_rate_0.8-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 135, 8640, 8640, 135, 8640, 540, 8640, 135, 540, 135, 8640, 540, 540, 540, 540, 8640, 135, 135, 135, 540, 8640, 135, 8640, 8640, 540, 540, 540, 135, 8640, 135, 540, 540, 135, 540, 135, 135, 540, 540, 8640, 540, 135, 540, 8640, 540, 540, 8640, 540, 8640, 135, 8640, 8640, 540, 135, 135, 8640, 540, 135, 540, 540, 8640, 540, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 8640, 8640, 135, 8640, 135, 540, 8640, 8640, 8640, 540, 135, 8640, 540, 135, 135, 135, 135, 135, 8640, 540, 135, 8640, 135, 8640, 135, 135, 540, 540, 8640, 540, 8640, 135, 540, 135, 8640, 8640, 135, 8640, 540, 135, 8640, 135, 135, 8640, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 135, 540, 8640, 8640, 135, 8640, 540, 135, 540, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 540, 8640, 8640, 540, 135, 8640, 135, 540, 540, 135, 540, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 540, 8640, 540, 135, 540, 8640, 540, 8640, 135, 8640, 135, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 135, 8640, 135, 8640, 540, 540, 135, 540, 8640, 540, 540, 8640, 135, 8640, 8640, 540, 135, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 135, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 8640, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 8640, 540, 135, 135, 135, 135]
Prompts retrieved: 800415 . Total input tokens: 178436095 . Total output tokens: 160189560
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 127.76099810563028,
    "estimated_duration": 3600.1633914999716,
    "input_throughput": 6250.4893675463,
    "output_throughput": 5536.432053906173,
    "total_throughput": 11786.921421452473,
    "itl": 154.8148091187265,
    "ttft": 1695900.1074103983,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 468,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3993435380142054,
    "arrivals": 266663,
    "finished_requests": 90583,
    "scheduler_time": 156.43496973805807
}
#Debug simulation 
Total elapsed time: 127.76113386079669. Arrivals time: 0.6935592419467866 Scheduler time: 126.83753481647 Scheduler overhead time: 0.09045783756300807 Adapter cache time: 0.02551325596868992 Engine time: 0.08649456920102239 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-32/adapters_256_slots_64_rate_0.8-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-32/adapters_256_slots_64_rate_0.8-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 135, 8640, 8640, 135, 8640, 540, 8640, 135, 540, 135, 8640, 540, 540, 540, 540, 8640, 135, 135, 135, 540, 8640, 135, 8640, 8640, 540, 540, 540, 135, 8640, 135, 540, 540, 135, 540, 135, 135, 540, 540, 8640, 540, 135, 540, 8640, 540, 540, 8640, 540, 8640, 135, 8640, 8640, 540, 135, 135, 8640, 540, 135, 540, 540, 8640, 540, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 8640, 8640, 135, 8640, 135, 540, 8640, 8640, 8640, 540, 135, 8640, 540, 135, 135, 135, 135, 135, 8640, 540, 135, 8640, 135, 8640, 135, 135, 540, 540, 8640, 540, 8640, 135, 540, 135, 8640, 8640, 135, 8640, 540, 135, 8640, 135, 135, 8640, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 135, 540, 8640, 8640, 135, 8640, 540, 135, 540, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 540, 8640, 8640, 540, 135, 8640, 135, 540, 540, 135, 540, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 540, 8640, 540, 135, 540, 8640, 540, 8640, 135, 8640, 135, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 135, 8640, 135, 8640, 540, 540, 135, 540, 8640, 540, 540, 8640, 135, 8640, 8640, 540, 135, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 135, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 8640, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 8640, 540, 135, 135, 135, 135]
Prompts retrieved: 800415 . Total input tokens: 178436095 . Total output tokens: 160189560
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 126.91087003098801,
    "estimated_duration": 3600.132255860073,
    "input_throughput": 6250.341487697443,
    "output_throughput": 5536.151336539859,
    "total_throughput": 11786.4928242373,
    "itl": 154.82108118618132,
    "ttft": 1695924.2247052828,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 468,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5692862221598614,
    "arrivals": 266663,
    "finished_requests": 90579,
    "scheduler_time": 156.42712488478548
}
#Debug simulation 
Total elapsed time: 126.91102311527357. Arrivals time: 0.6927378824912012 Scheduler time: 125.98829518537968 Scheduler overhead time: 0.09143972164019942 Adapter cache time: 0.02512938529253006 Engine time: 0.08521447563543916 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-8/adapters_256_slots_64_rate_0.8-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-8/adapters_256_slots_64_rate_0.8-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 66, 8640, 8640, 66, 8640, 540, 8640, 66, 540, 66, 8640, 540, 540, 540, 540, 8640, 66, 66, 66, 540, 8640, 66, 8640, 8640, 540, 540, 540, 66, 8640, 66, 540, 540, 66, 540, 66, 66, 540, 540, 8640, 540, 66, 540, 8640, 540, 540, 8640, 540, 8640, 66, 8640, 8640, 540, 66, 66, 8640, 540, 66, 540, 540, 8640, 540, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 8640, 8640, 66, 8640, 66, 540, 8640, 8640, 8640, 540, 66, 8640, 540, 66, 66, 66, 66, 66, 8640, 540, 66, 8640, 66, 8640, 66, 66, 540, 540, 8640, 540, 8640, 66, 540, 66, 8640, 8640, 66, 8640, 540, 66, 8640, 66, 66, 8640, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 66, 540, 8640, 8640, 66, 8640, 540, 66, 540, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 540, 8640, 8640, 540, 66, 8640, 66, 540, 540, 66, 540, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 540, 8640, 540, 66, 540, 8640, 540, 8640, 66, 8640, 66, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 66, 8640, 66, 8640, 540, 540, 66, 540, 8640, 540, 540, 8640, 66, 8640, 8640, 540, 66, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 66, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 8640, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 8640, 540, 66, 66, 66, 66]
Prompts retrieved: 794550 . Total input tokens: 177125970 . Total output tokens: 159040310
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 123.70053580170497,
    "estimated_duration": 3600.0439517522113,
    "input_throughput": 6272.738972814162,
    "output_throughput": 5528.295561589813,
    "total_throughput": 11801.034534403974,
    "itl": 154.2746855823432,
    "ttft": 1696435.1437143036,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 477,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4598526538559382,
    "arrivals": 264754,
    "finished_requests": 91121,
    "scheduler_time": 156.72069650012816
}
#Debug simulation 
Total elapsed time: 123.70065899798647. Arrivals time: 0.6771604213863611 Scheduler time: 122.79706046544015 Scheduler overhead time: 0.08971763169392943 Adapter cache time: 0.024792364798486233 Engine time: 0.08454194571822882 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-16/adapters_256_slots_64_rate_0.8-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-16/adapters_256_slots_64_rate_0.8-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 66, 8640, 8640, 66, 8640, 540, 8640, 66, 540, 66, 8640, 540, 540, 540, 540, 8640, 66, 66, 66, 540, 8640, 66, 8640, 8640, 540, 540, 540, 66, 8640, 66, 540, 540, 66, 540, 66, 66, 540, 540, 8640, 540, 66, 540, 8640, 540, 540, 8640, 540, 8640, 66, 8640, 8640, 540, 66, 66, 8640, 540, 66, 540, 540, 8640, 540, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 8640, 8640, 66, 8640, 66, 540, 8640, 8640, 8640, 540, 66, 8640, 540, 66, 66, 66, 66, 66, 8640, 540, 66, 8640, 66, 8640, 66, 66, 540, 540, 8640, 540, 8640, 66, 540, 66, 8640, 8640, 66, 8640, 540, 66, 8640, 66, 66, 8640, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 66, 540, 8640, 8640, 66, 8640, 540, 66, 540, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 540, 8640, 8640, 540, 66, 8640, 66, 540, 540, 66, 540, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 540, 8640, 540, 66, 540, 8640, 540, 8640, 66, 8640, 66, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 66, 8640, 66, 8640, 540, 540, 66, 540, 8640, 540, 540, 8640, 66, 8640, 8640, 540, 66, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 66, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 8640, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 8640, 540, 66, 66, 66, 66]
Prompts retrieved: 794550 . Total input tokens: 177125970 . Total output tokens: 159040310
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 123.43365328107029,
    "estimated_duration": 3600.081149825163,
    "input_throughput": 6268.58536260939,
    "output_throughput": 5526.151264941952,
    "total_throughput": 11794.736627551343,
    "itl": 154.282808839142,
    "ttft": 1696443.1126220294,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 484,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5767090586782484,
    "arrivals": 264754,
    "finished_requests": 91085,
    "scheduler_time": 156.71763444964938
}
#Debug simulation 
Total elapsed time: 123.43380405334756. Arrivals time: 0.6663337154313922 Scheduler time: 122.53757322579622 Scheduler overhead time: 0.0897106803022325 Adapter cache time: 0.026207275688648224 Engine time: 0.08651690930128098 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-32/adapters_256_slots_64_rate_0.8-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-32/adapters_256_slots_64_rate_0.8-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 66, 8640, 8640, 66, 8640, 540, 8640, 66, 540, 66, 8640, 540, 540, 540, 540, 8640, 66, 66, 66, 540, 8640, 66, 8640, 8640, 540, 540, 540, 66, 8640, 66, 540, 540, 66, 540, 66, 66, 540, 540, 8640, 540, 66, 540, 8640, 540, 540, 8640, 540, 8640, 66, 8640, 8640, 540, 66, 66, 8640, 540, 66, 540, 540, 8640, 540, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 8640, 8640, 66, 8640, 66, 540, 8640, 8640, 8640, 540, 66, 8640, 540, 66, 66, 66, 66, 66, 8640, 540, 66, 8640, 66, 8640, 66, 66, 540, 540, 8640, 540, 8640, 66, 540, 66, 8640, 8640, 66, 8640, 540, 66, 8640, 66, 66, 8640, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 66, 540, 8640, 8640, 66, 8640, 540, 66, 540, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 540, 8640, 8640, 540, 66, 8640, 66, 540, 540, 66, 540, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 540, 8640, 540, 66, 540, 8640, 540, 8640, 66, 8640, 66, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 66, 8640, 66, 8640, 540, 540, 66, 540, 8640, 540, 540, 8640, 66, 8640, 8640, 540, 66, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 66, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 8640, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 8640, 540, 66, 66, 66, 66]
Prompts retrieved: 794550 . Total input tokens: 177125970 . Total output tokens: 159040310
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 124.59595206612721,
    "estimated_duration": 3600.0841372740397,
    "input_throughput": 6268.580160764771,
    "output_throughput": 5526.146679189575,
    "total_throughput": 11794.726839954346,
    "itl": 154.28289653288348,
    "ttft": 1696443.656998571,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 484,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5799705785699283,
    "arrivals": 264754,
    "finished_requests": 91085,
    "scheduler_time": 156.71763885445523
}
#Debug simulation 
Total elapsed time: 124.5960720977746. Arrivals time: 0.6421213638968766 Scheduler time: 123.72227095486596 Scheduler overhead time: 0.09169585956260562 Adapter cache time: 0.025687495712190866 Engine time: 0.08656571106985211 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-16/adapters_256_slots_64_rate_0.8-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-16/adapters_256_slots_64_rate_0.8-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 66, 8640, 8640, 66, 8640, 540, 8640, 66, 540, 66, 8640, 540, 540, 540, 540, 8640, 66, 66, 66, 540, 8640, 66, 8640, 8640, 540, 540, 540, 66, 8640, 66, 540, 540, 66, 540, 66, 66, 540, 540, 8640, 540, 66, 540, 8640, 540, 540, 8640, 540, 8640, 66, 8640, 8640, 540, 66, 66, 8640, 540, 66, 540, 540, 8640, 540, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 8640, 8640, 66, 8640, 66, 540, 8640, 8640, 8640, 540, 66, 8640, 540, 66, 66, 66, 66, 66, 8640, 540, 66, 8640, 66, 8640, 66, 66, 540, 540, 8640, 540, 8640, 66, 540, 66, 8640, 8640, 66, 8640, 540, 66, 8640, 66, 66, 8640, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 66, 540, 8640, 8640, 66, 8640, 540, 66, 540, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 540, 8640, 8640, 540, 66, 8640, 66, 540, 540, 66, 540, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 540, 8640, 540, 66, 540, 8640, 540, 8640, 66, 8640, 66, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 66, 8640, 66, 8640, 540, 540, 66, 540, 8640, 540, 540, 8640, 66, 8640, 8640, 540, 66, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 66, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 8640, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 8640, 540, 66, 66, 66, 66]
Prompts retrieved: 794550 . Total input tokens: 177125970 . Total output tokens: 159040310
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 124.81607999000698,
    "estimated_duration": 3600.073682067314,
    "input_throughput": 6272.687170956008,
    "output_throughput": 5528.249907532829,
    "total_throughput": 11800.937078488836,
    "itl": 154.27564416338686,
    "ttft": 1696440.4628003952,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 476,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4890477866423275,
    "arrivals": 264754,
    "finished_requests": 91121,
    "scheduler_time": 156.72096212575752
}
#Debug simulation 
Total elapsed time: 124.81620152387768. Arrivals time: 0.6462276689708233 Scheduler time: 123.94182332698256 Scheduler overhead time: 0.09022857062518597 Adapter cache time: 0.02502391953021288 Engine time: 0.08446840802207589 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-32/adapters_256_slots_64_rate_0.8-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-32/adapters_256_slots_64_rate_0.8-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 66, 8640, 8640, 66, 8640, 540, 8640, 66, 540, 66, 8640, 540, 540, 540, 540, 8640, 66, 66, 66, 540, 8640, 66, 8640, 8640, 540, 540, 540, 66, 8640, 66, 540, 540, 66, 540, 66, 66, 540, 540, 8640, 540, 66, 540, 8640, 540, 540, 8640, 540, 8640, 66, 8640, 8640, 540, 66, 66, 8640, 540, 66, 540, 540, 8640, 540, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 8640, 8640, 66, 8640, 66, 540, 8640, 8640, 8640, 540, 66, 8640, 540, 66, 66, 66, 66, 66, 8640, 540, 66, 8640, 66, 8640, 66, 66, 540, 540, 8640, 540, 8640, 66, 540, 66, 8640, 8640, 66, 8640, 540, 66, 8640, 66, 66, 8640, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 66, 540, 8640, 8640, 66, 8640, 540, 66, 540, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 540, 8640, 8640, 540, 66, 8640, 66, 540, 540, 66, 540, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 540, 8640, 540, 66, 540, 8640, 540, 8640, 66, 8640, 66, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 66, 8640, 66, 8640, 540, 540, 66, 540, 8640, 540, 540, 8640, 66, 8640, 8640, 540, 66, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 66, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 8640, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 8640, 540, 66, 66, 66, 66]
Prompts retrieved: 794550 . Total input tokens: 177125970 . Total output tokens: 159040310
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 124.49365183105692,
    "estimated_duration": 3600.058568372537,
    "input_throughput": 6268.409408184046,
    "output_throughput": 5526.113706809371,
    "total_throughput": 11794.523114993417,
    "itl": 154.2854986399726,
    "ttft": 1696439.8108600213,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 484,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5989594003185676,
    "arrivals": 264754,
    "finished_requests": 91085,
    "scheduler_time": 156.7137375528523
}
#Debug simulation 
Total elapsed time: 124.49377815425396. Arrivals time: 0.6578355436213315 Scheduler time: 123.60743809724227 Scheduler overhead time: 0.09018297027796507 Adapter cache time: 0.024714999832212925 Engine time: 0.08592823520302773 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-16/adapters_256_slots_64_rate_0.8-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-16/adapters_256_slots_64_rate_0.8-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 66, 8640, 8640, 66, 8640, 540, 8640, 66, 540, 66, 8640, 540, 540, 540, 540, 8640, 66, 66, 66, 540, 8640, 66, 8640, 8640, 540, 540, 540, 66, 8640, 66, 540, 540, 66, 540, 66, 66, 540, 540, 8640, 540, 66, 540, 8640, 540, 540, 8640, 540, 8640, 66, 8640, 8640, 540, 66, 66, 8640, 540, 66, 540, 540, 8640, 540, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 8640, 8640, 66, 8640, 66, 540, 8640, 8640, 8640, 540, 66, 8640, 540, 66, 66, 66, 66, 66, 8640, 540, 66, 8640, 66, 8640, 66, 66, 540, 540, 8640, 540, 8640, 66, 540, 66, 8640, 8640, 66, 8640, 540, 66, 8640, 66, 66, 8640, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 66, 540, 8640, 8640, 66, 8640, 540, 66, 540, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 540, 8640, 8640, 540, 66, 8640, 66, 540, 540, 66, 540, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 540, 8640, 540, 66, 540, 8640, 540, 8640, 66, 8640, 66, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 66, 8640, 66, 8640, 540, 540, 66, 540, 8640, 540, 540, 8640, 66, 8640, 8640, 540, 66, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 66, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 8640, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 8640, 540, 66, 66, 66, 66]
Prompts retrieved: 794550 . Total input tokens: 177125970 . Total output tokens: 159040310
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 122.86210439074785,
    "estimated_duration": 3600.000852089436,
    "input_throughput": 6272.8140708337205,
    "output_throughput": 5528.3617470392655,
    "total_throughput": 11801.175817872987,
    "itl": 154.2733768247905,
    "ttft": 1696427.1143427063,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 477,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.426253990668324,
    "arrivals": 264754,
    "finished_requests": 91121,
    "scheduler_time": 156.71962122121005
}
#Debug simulation 
Total elapsed time: 122.86224788194522. Arrivals time: 0.6955247833393514 Scheduler time: 121.9372458443977 Scheduler overhead time: 0.09096968965604901 Adapter cache time: 0.025289185345172882 Engine time: 0.08590052975341678 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-32/adapters_256_slots_64_rate_0.8-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-32/adapters_256_slots_64_rate_0.8-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 66, 8640, 8640, 66, 8640, 540, 8640, 66, 540, 66, 8640, 540, 540, 540, 540, 8640, 66, 66, 66, 540, 8640, 66, 8640, 8640, 540, 540, 540, 66, 8640, 66, 540, 540, 66, 540, 66, 66, 540, 540, 8640, 540, 66, 540, 8640, 540, 540, 8640, 540, 8640, 66, 8640, 8640, 540, 66, 66, 8640, 540, 66, 540, 540, 8640, 540, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 8640, 8640, 66, 8640, 66, 540, 8640, 8640, 8640, 540, 66, 8640, 540, 66, 66, 66, 66, 66, 8640, 540, 66, 8640, 66, 8640, 66, 66, 540, 540, 8640, 540, 8640, 66, 540, 66, 8640, 8640, 66, 8640, 540, 66, 8640, 66, 66, 8640, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 66, 540, 8640, 8640, 66, 8640, 540, 66, 540, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 540, 8640, 8640, 540, 66, 8640, 66, 540, 540, 66, 540, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 540, 8640, 540, 66, 540, 8640, 540, 8640, 66, 8640, 66, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 66, 8640, 66, 8640, 540, 540, 66, 540, 8640, 540, 540, 8640, 66, 8640, 8640, 540, 66, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 66, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 8640, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 8640, 540, 66, 66, 66, 66]
Prompts retrieved: 794550 . Total input tokens: 177125970 . Total output tokens: 159040310
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 124.46275066025555,
    "estimated_duration": 3600.1467067070516,
    "input_throughput": 6269.285070508816,
    "output_throughput": 5526.008138206362,
    "total_throughput": 11795.293208715178,
    "itl": 154.28984600439495,
    "ttft": 1696378.4064949502,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 485,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6233410489931694,
    "arrivals": 264754,
    "finished_requests": 91093,
    "scheduler_time": 156.71918673672295
}
#Debug simulation 
Total elapsed time: 124.46289387298748. Arrivals time: 0.6468371055088937 Scheduler time: 123.58376180939376 Scheduler overhead time: 0.09133481420576572 Adapter cache time: 0.02600179659202695 Engine time: 0.08702002372592688 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-8/adapters_256_slots_64_rate_0.8-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-8/adapters_256_slots_64_rate_0.8-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 33, 8640, 8640, 33, 8640, 540, 8640, 33, 540, 33, 8640, 540, 540, 540, 540, 8640, 33, 33, 33, 540, 8640, 33, 8640, 8640, 540, 540, 540, 33, 8640, 33, 540, 540, 33, 540, 33, 33, 540, 540, 8640, 540, 33, 540, 8640, 540, 540, 8640, 540, 8640, 33, 8640, 8640, 540, 33, 33, 8640, 540, 33, 540, 540, 8640, 540, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 8640, 8640, 33, 8640, 33, 540, 8640, 8640, 8640, 540, 33, 8640, 540, 33, 33, 33, 33, 33, 8640, 540, 33, 8640, 33, 8640, 33, 33, 540, 540, 8640, 540, 8640, 33, 540, 33, 8640, 8640, 33, 8640, 540, 33, 8640, 33, 33, 8640, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 33, 540, 8640, 8640, 33, 8640, 540, 33, 540, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 540, 8640, 8640, 540, 33, 8640, 33, 540, 540, 33, 540, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 540, 8640, 540, 33, 540, 8640, 540, 8640, 33, 8640, 33, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 33, 8640, 33, 8640, 540, 540, 33, 540, 8640, 540, 540, 8640, 33, 8640, 8640, 540, 33, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 33, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 8640, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 8640, 540, 33, 33, 33, 33]
Prompts retrieved: 791745 . Total input tokens: 176476708 . Total output tokens: 158497887
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 123.97879577195272,
    "estimated_duration": 3600.1577053209558,
    "input_throughput": 6292.902382169465,
    "output_throughput": 5523.788296998258,
    "total_throughput": 11816.690679167725,
    "itl": 154.0841322095949,
    "ttft": 1694383.3224678165,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 454,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3894614357454824,
    "arrivals": 263766,
    "finished_requests": 91055,
    "scheduler_time": 156.71877421320045
}
#Debug simulation 
Total elapsed time: 123.97892071167007. Arrivals time: 0.6449485109187663 Scheduler time: 123.10393340000883 Scheduler overhead time: 0.09105008142068982 Adapter cache time: 0.024417605251073837 Engine time: 0.08682588767260313 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-16/adapters_256_slots_64_rate_0.8-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-16/adapters_256_slots_64_rate_0.8-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 33, 8640, 8640, 33, 8640, 540, 8640, 33, 540, 33, 8640, 540, 540, 540, 540, 8640, 33, 33, 33, 540, 8640, 33, 8640, 8640, 540, 540, 540, 33, 8640, 33, 540, 540, 33, 540, 33, 33, 540, 540, 8640, 540, 33, 540, 8640, 540, 540, 8640, 540, 8640, 33, 8640, 8640, 540, 33, 33, 8640, 540, 33, 540, 540, 8640, 540, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 8640, 8640, 33, 8640, 33, 540, 8640, 8640, 8640, 540, 33, 8640, 540, 33, 33, 33, 33, 33, 8640, 540, 33, 8640, 33, 8640, 33, 33, 540, 540, 8640, 540, 8640, 33, 540, 33, 8640, 8640, 33, 8640, 540, 33, 8640, 33, 33, 8640, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 33, 540, 8640, 8640, 33, 8640, 540, 33, 540, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 540, 8640, 8640, 540, 33, 8640, 33, 540, 540, 33, 540, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 540, 8640, 540, 33, 540, 8640, 540, 8640, 33, 8640, 33, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 33, 8640, 33, 8640, 540, 540, 33, 540, 8640, 540, 540, 8640, 33, 8640, 8640, 540, 33, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 33, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 8640, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 8640, 540, 33, 33, 33, 33]
Prompts retrieved: 791745 . Total input tokens: 176476708 . Total output tokens: 158497887
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 123.71219930890948,
    "estimated_duration": 3600.0375120053163,
    "input_throughput": 6292.659708254325,
    "output_throughput": 5523.5185560396,
    "total_throughput": 11816.178264293925,
    "itl": 154.08743800063928,
    "ttft": 1694390.5699250384,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 454,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4821044060099005,
    "arrivals": 263766,
    "finished_requests": 91049,
    "scheduler_time": 156.70857484387042
}
#Debug simulation 
Total elapsed time: 123.71232785005122. Arrivals time: 0.7134065092541277 Scheduler time: 122.77324956422672 Scheduler overhead time: 0.08954076748341322 Adapter cache time: 0.02351111825555563 Engine time: 0.08503912948071957 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-32/adapters_256_slots_64_rate_0.8-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-32/adapters_256_slots_64_rate_0.8-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 33, 8640, 8640, 33, 8640, 540, 8640, 33, 540, 33, 8640, 540, 540, 540, 540, 8640, 33, 33, 33, 540, 8640, 33, 8640, 8640, 540, 540, 540, 33, 8640, 33, 540, 540, 33, 540, 33, 33, 540, 540, 8640, 540, 33, 540, 8640, 540, 540, 8640, 540, 8640, 33, 8640, 8640, 540, 33, 33, 8640, 540, 33, 540, 540, 8640, 540, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 8640, 8640, 33, 8640, 33, 540, 8640, 8640, 8640, 540, 33, 8640, 540, 33, 33, 33, 33, 33, 8640, 540, 33, 8640, 33, 8640, 33, 33, 540, 540, 8640, 540, 8640, 33, 540, 33, 8640, 8640, 33, 8640, 540, 33, 8640, 33, 33, 8640, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 33, 540, 8640, 8640, 33, 8640, 540, 33, 540, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 540, 8640, 8640, 540, 33, 8640, 33, 540, 540, 33, 540, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 540, 8640, 540, 33, 540, 8640, 540, 8640, 33, 8640, 33, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 33, 8640, 33, 8640, 540, 540, 33, 540, 8640, 540, 540, 8640, 33, 8640, 8640, 540, 33, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 33, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 8640, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 8640, 540, 33, 33, 33, 33]
Prompts retrieved: 791745 . Total input tokens: 176476708 . Total output tokens: 158497887
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 122.50376753881574,
    "estimated_duration": 3600.0406378586054,
    "input_throughput": 6292.6542444462675,
    "output_throughput": 5523.513760063559,
    "total_throughput": 11816.168004509827,
    "itl": 154.0874481954548,
    "ttft": 1694391.5291767847,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 454,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4846180431731133,
    "arrivals": 263766,
    "finished_requests": 91049,
    "scheduler_time": 156.70863010821728
}
#Debug simulation 
Total elapsed time: 122.50390937412158. Arrivals time: 0.7002056450583041 Scheduler time: 121.57469631917775 Scheduler overhead time: 0.09111712453886867 Adapter cache time: 0.02471639309078455 Engine time: 0.08568756142631173 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-16/adapters_256_slots_64_rate_0.8-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-16/adapters_256_slots_64_rate_0.8-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 33, 8640, 8640, 33, 8640, 540, 8640, 33, 540, 33, 8640, 540, 540, 540, 540, 8640, 33, 33, 33, 540, 8640, 33, 8640, 8640, 540, 540, 540, 33, 8640, 33, 540, 540, 33, 540, 33, 33, 540, 540, 8640, 540, 33, 540, 8640, 540, 540, 8640, 540, 8640, 33, 8640, 8640, 540, 33, 33, 8640, 540, 33, 540, 540, 8640, 540, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 8640, 8640, 33, 8640, 33, 540, 8640, 8640, 8640, 540, 33, 8640, 540, 33, 33, 33, 33, 33, 8640, 540, 33, 8640, 33, 8640, 33, 33, 540, 540, 8640, 540, 8640, 33, 540, 33, 8640, 8640, 33, 8640, 540, 33, 8640, 33, 33, 8640, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 33, 540, 8640, 8640, 33, 8640, 540, 33, 540, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 540, 8640, 8640, 540, 33, 8640, 33, 540, 540, 33, 540, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 540, 8640, 540, 33, 540, 8640, 540, 8640, 33, 8640, 33, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 33, 8640, 33, 8640, 540, 540, 33, 540, 8640, 540, 540, 8640, 33, 8640, 8640, 540, 33, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 33, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 8640, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 8640, 540, 33, 33, 33, 33]
Prompts retrieved: 791745 . Total input tokens: 176476708 . Total output tokens: 158497887
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 126.17392168799415,
    "estimated_duration": 3600.0817930063617,
    "input_throughput": 6294.013942688207,
    "output_throughput": 5524.046714336653,
    "total_throughput": 11818.06065702486,
    "itl": 154.08745230442787,
    "ttft": 1694621.414016314,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 460,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4403897912870132,
    "arrivals": 263766,
    "finished_requests": 91058,
    "scheduler_time": 156.71574383153649
}
#Debug simulation 
Total elapsed time: 126.17405155301094. Arrivals time: 0.7701538326218724 Scheduler time: 125.15587934898213 Scheduler overhead time: 0.09792489279061556 Adapter cache time: 0.026716845110058784 Engine time: 0.09393654204905033 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-32/adapters_256_slots_64_rate_0.8-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-32/adapters_256_slots_64_rate_0.8-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 33, 8640, 8640, 33, 8640, 540, 8640, 33, 540, 33, 8640, 540, 540, 540, 540, 8640, 33, 33, 33, 540, 8640, 33, 8640, 8640, 540, 540, 540, 33, 8640, 33, 540, 540, 33, 540, 33, 33, 540, 540, 8640, 540, 33, 540, 8640, 540, 540, 8640, 540, 8640, 33, 8640, 8640, 540, 33, 33, 8640, 540, 33, 540, 540, 8640, 540, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 8640, 8640, 33, 8640, 33, 540, 8640, 8640, 8640, 540, 33, 8640, 540, 33, 33, 33, 33, 33, 8640, 540, 33, 8640, 33, 8640, 33, 33, 540, 540, 8640, 540, 8640, 33, 540, 33, 8640, 8640, 33, 8640, 540, 33, 8640, 33, 33, 8640, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 33, 540, 8640, 8640, 33, 8640, 540, 33, 540, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 540, 8640, 8640, 540, 33, 8640, 33, 540, 540, 33, 540, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 540, 8640, 540, 33, 540, 8640, 540, 8640, 33, 8640, 33, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 33, 8640, 33, 8640, 540, 540, 33, 540, 8640, 540, 540, 8640, 33, 8640, 8640, 540, 33, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 33, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 8640, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 8640, 540, 33, 33, 33, 33]
Prompts retrieved: 791745 . Total input tokens: 176476708 . Total output tokens: 158497887
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 122.7118218159303,
    "estimated_duration": 3600.062239378909,
    "input_throughput": 6292.616486516157,
    "output_throughput": 5523.48061722138,
    "total_throughput": 11816.097103737537,
    "itl": 154.087957702327,
    "ttft": 1694398.3440596345,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 454,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5034811111353383,
    "arrivals": 263766,
    "finished_requests": 91049,
    "scheduler_time": 156.70892849472392
}
#Debug simulation 
Total elapsed time: 122.71196221280843. Arrivals time: 0.6643025316298008 Scheduler time: 121.82123649073765 Scheduler overhead time: 0.08844052627682686 Adapter cache time: 0.023770879954099655 Engine time: 0.08653703052550554 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-16/adapters_256_slots_64_rate_0.8-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-16/adapters_256_slots_64_rate_0.8-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 33, 8640, 8640, 33, 8640, 540, 8640, 33, 540, 33, 8640, 540, 540, 540, 540, 8640, 33, 33, 33, 540, 8640, 33, 8640, 8640, 540, 540, 540, 33, 8640, 33, 540, 540, 33, 540, 33, 33, 540, 540, 8640, 540, 33, 540, 8640, 540, 540, 8640, 540, 8640, 33, 8640, 8640, 540, 33, 33, 8640, 540, 33, 540, 540, 8640, 540, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 8640, 8640, 33, 8640, 33, 540, 8640, 8640, 8640, 540, 33, 8640, 540, 33, 33, 33, 33, 33, 8640, 540, 33, 8640, 33, 8640, 33, 33, 540, 540, 8640, 540, 8640, 33, 540, 33, 8640, 8640, 33, 8640, 540, 33, 8640, 33, 33, 8640, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 33, 540, 8640, 8640, 33, 8640, 540, 33, 540, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 540, 8640, 8640, 540, 33, 8640, 33, 540, 540, 33, 540, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 540, 8640, 540, 33, 540, 8640, 540, 8640, 33, 8640, 33, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 33, 8640, 33, 8640, 540, 540, 33, 540, 8640, 540, 540, 8640, 33, 8640, 8640, 540, 33, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 33, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 8640, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 8640, 540, 33, 33, 33, 33]
Prompts retrieved: 791745 . Total input tokens: 176476708 . Total output tokens: 158497887
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 121.6445535668172,
    "estimated_duration": 3600.1234930051346,
    "input_throughput": 6292.962184219075,
    "output_throughput": 5523.840790083596,
    "total_throughput": 11816.802974302673,
    "itl": 154.0831757653189,
    "ttft": 1694375.7869017953,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 454,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3574828338855764,
    "arrivals": 263766,
    "finished_requests": 91055,
    "scheduler_time": 156.71804352951727
}
#Debug simulation 
Total elapsed time: 121.64470513910055. Arrivals time: 0.7280827420763671 Scheduler time: 120.689008184243 Scheduler overhead time: 0.08816030295565724 Adapter cache time: 0.025089002680033445 Engine time: 0.086911475751549 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-32/adapters_256_slots_64_rate_0.8-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-32/adapters_256_slots_64_rate_0.8-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 33, 8640, 8640, 33, 8640, 540, 8640, 33, 540, 33, 8640, 540, 540, 540, 540, 8640, 33, 33, 33, 540, 8640, 33, 8640, 8640, 540, 540, 540, 33, 8640, 33, 540, 540, 33, 540, 33, 33, 540, 540, 8640, 540, 33, 540, 8640, 540, 540, 8640, 540, 8640, 33, 8640, 8640, 540, 33, 33, 8640, 540, 33, 540, 540, 8640, 540, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 8640, 8640, 33, 8640, 33, 540, 8640, 8640, 8640, 540, 33, 8640, 540, 33, 33, 33, 33, 33, 8640, 540, 33, 8640, 33, 8640, 33, 33, 540, 540, 8640, 540, 8640, 33, 540, 33, 8640, 8640, 33, 8640, 540, 33, 8640, 33, 33, 8640, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 33, 540, 8640, 8640, 33, 8640, 540, 33, 540, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 540, 8640, 8640, 540, 33, 8640, 33, 540, 540, 33, 540, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 540, 8640, 540, 33, 540, 8640, 540, 8640, 33, 8640, 33, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 33, 8640, 33, 8640, 540, 540, 33, 540, 8640, 540, 540, 8640, 33, 8640, 8640, 540, 33, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 33, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 8640, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 8640, 540, 33, 33, 33, 33]
Prompts retrieved: 791745 . Total input tokens: 176476708 . Total output tokens: 158497887
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 123.02284981729463,
    "estimated_duration": 3600.081931426558,
    "input_throughput": 6292.582066604041,
    "output_throughput": 5523.450404396901,
    "total_throughput": 11816.032471000943,
    "itl": 154.08849354872066,
    "ttft": 1694400.4799705679,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 454,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.522972948029637,
    "arrivals": 263766,
    "finished_requests": 91049,
    "scheduler_time": 156.70940772719104
}
#Debug simulation 
Total elapsed time: 123.02299421513453. Arrivals time: 0.7096204115077853 Scheduler time: 122.08318362757564 Scheduler overhead time: 0.08977815415710211 Adapter cache time: 0.02428324520587921 Engine time: 0.08802881836891174 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-8/adapters_256_slots_64_rate_0.8-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-8/adapters_256_slots_64_rate_0.8-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 8640, 135, 8640, 8640, 135, 8640, 270, 8640, 135, 270, 135, 8640, 270, 270, 270, 270, 8640, 135, 135, 135, 270, 8640, 135, 8640, 8640, 270, 270, 270, 135, 8640, 135, 270, 270, 135, 270, 135, 135, 270, 270, 8640, 270, 135, 270, 8640, 270, 270, 8640, 270, 8640, 135, 8640, 8640, 270, 135, 135, 8640, 270, 135, 270, 270, 8640, 270, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 8640, 8640, 135, 8640, 135, 270, 8640, 8640, 8640, 270, 135, 8640, 270, 135, 135, 135, 135, 135, 8640, 270, 135, 8640, 135, 8640, 135, 135, 270, 270, 8640, 270, 8640, 135, 270, 135, 8640, 8640, 135, 8640, 270, 135, 8640, 135, 135, 8640, 8640, 270, 8640, 8640, 135, 8640, 270, 270, 135, 270, 8640, 8640, 135, 8640, 270, 135, 270, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 270, 8640, 8640, 270, 135, 8640, 135, 270, 270, 135, 270, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 270, 8640, 270, 135, 270, 8640, 270, 8640, 135, 8640, 135, 270, 8640, 270, 8640, 270, 8640, 270, 8640, 270, 135, 8640, 135, 8640, 270, 270, 135, 270, 8640, 270, 270, 8640, 135, 8640, 8640, 270, 135, 8640, 8640, 270, 270, 8640, 8640, 270, 270, 270, 270, 8640, 8640, 270, 270, 8640, 135, 8640, 270, 8640, 8640, 135, 8640, 270, 270, 8640, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 8640, 270, 135, 135, 135, 135]
Prompts retrieved: 777465 . Total input tokens: 173287228 . Total output tokens: 155617124
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 126.92954248003662,
    "estimated_duration": 3600.0846939855546,
    "input_throughput": 6241.116226386799,
    "output_throughput": 5537.475280319056,
    "total_throughput": 11778.591506705854,
    "itl": 154.91973220979176,
    "ttft": 1688494.417213971,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 526,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6098165533086484,
    "arrivals": 258949,
    "finished_requests": 90727,
    "scheduler_time": 156.11158381708978
}
#Debug simulation 
Total elapsed time: 126.9296841067262. Arrivals time: 0.6842643087729812 Scheduler time: 126.01178914215416 Scheduler overhead time: 0.08910493832081556 Adapter cache time: 0.026243472006171942 Engine time: 0.08896987931802869 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-16/adapters_256_slots_64_rate_0.8-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-16/adapters_256_slots_64_rate_0.8-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 8640, 135, 8640, 8640, 135, 8640, 270, 8640, 135, 270, 135, 8640, 270, 270, 270, 270, 8640, 135, 135, 135, 270, 8640, 135, 8640, 8640, 270, 270, 270, 135, 8640, 135, 270, 270, 135, 270, 135, 135, 270, 270, 8640, 270, 135, 270, 8640, 270, 270, 8640, 270, 8640, 135, 8640, 8640, 270, 135, 135, 8640, 270, 135, 270, 270, 8640, 270, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 8640, 8640, 135, 8640, 135, 270, 8640, 8640, 8640, 270, 135, 8640, 270, 135, 135, 135, 135, 135, 8640, 270, 135, 8640, 135, 8640, 135, 135, 270, 270, 8640, 270, 8640, 135, 270, 135, 8640, 8640, 135, 8640, 270, 135, 8640, 135, 135, 8640, 8640, 270, 8640, 8640, 135, 8640, 270, 270, 135, 270, 8640, 8640, 135, 8640, 270, 135, 270, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 270, 8640, 8640, 270, 135, 8640, 135, 270, 270, 135, 270, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 270, 8640, 270, 135, 270, 8640, 270, 8640, 135, 8640, 135, 270, 8640, 270, 8640, 270, 8640, 270, 8640, 270, 135, 8640, 135, 8640, 270, 270, 135, 270, 8640, 270, 270, 8640, 135, 8640, 8640, 270, 135, 8640, 8640, 270, 270, 8640, 8640, 270, 270, 270, 270, 8640, 8640, 270, 270, 8640, 135, 8640, 270, 8640, 8640, 135, 8640, 270, 270, 8640, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 8640, 270, 135, 135, 135, 135]
Prompts retrieved: 777465 . Total input tokens: 173287228 . Total output tokens: 155617124
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 127.04681388614699,
    "estimated_duration": 3600.019438023472,
    "input_throughput": 6240.576859866811,
    "output_throughput": 5537.169824545273,
    "total_throughput": 11777.746684412083,
    "itl": 154.92631527716668,
    "ttft": 1688467.568982849,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 524,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7089775253459873,
    "arrivals": 258949,
    "finished_requests": 90725,
    "scheduler_time": 156.10575633184416
}
#Debug simulation 
Total elapsed time: 127.04694574000314. Arrivals time: 0.6777278250083327 Scheduler time: 126.13358623115346 Scheduler overhead time: 0.0916460040025413 Adapter cache time: 0.025958096142858267 Engine time: 0.08881856547668576 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-32/adapters_256_slots_64_rate_0.8-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-32/adapters_256_slots_64_rate_0.8-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 8640, 135, 8640, 8640, 135, 8640, 270, 8640, 135, 270, 135, 8640, 270, 270, 270, 270, 8640, 135, 135, 135, 270, 8640, 135, 8640, 8640, 270, 270, 270, 135, 8640, 135, 270, 270, 135, 270, 135, 135, 270, 270, 8640, 270, 135, 270, 8640, 270, 270, 8640, 270, 8640, 135, 8640, 8640, 270, 135, 135, 8640, 270, 135, 270, 270, 8640, 270, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 8640, 8640, 135, 8640, 135, 270, 8640, 8640, 8640, 270, 135, 8640, 270, 135, 135, 135, 135, 135, 8640, 270, 135, 8640, 135, 8640, 135, 135, 270, 270, 8640, 270, 8640, 135, 270, 135, 8640, 8640, 135, 8640, 270, 135, 8640, 135, 135, 8640, 8640, 270, 8640, 8640, 135, 8640, 270, 270, 135, 270, 8640, 8640, 135, 8640, 270, 135, 270, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 270, 8640, 8640, 270, 135, 8640, 135, 270, 270, 135, 270, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 270, 8640, 270, 135, 270, 8640, 270, 8640, 135, 8640, 135, 270, 8640, 270, 8640, 270, 8640, 270, 8640, 270, 135, 8640, 135, 8640, 270, 270, 135, 270, 8640, 270, 270, 8640, 135, 8640, 8640, 270, 135, 8640, 8640, 270, 270, 8640, 8640, 270, 270, 270, 270, 8640, 8640, 270, 270, 8640, 135, 8640, 270, 8640, 8640, 135, 8640, 270, 270, 8640, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 8640, 270, 135, 135, 135, 135]
Prompts retrieved: 777465 . Total input tokens: 173287228 . Total output tokens: 155617124
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 127.88498860877007,
    "estimated_duration": 3600.01494881111,
    "input_throughput": 6240.503531080967,
    "output_throughput": 5536.983952409104,
    "total_throughput": 11777.487483490071,
    "itl": 154.92490171532026,
    "ttft": 1688450.3517703097,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 524,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7121660048514709,
    "arrivals": 258949,
    "finished_requests": 90721,
    "scheduler_time": 156.10575067737966
}
#Debug simulation 
Total elapsed time: 127.8851336450316. Arrivals time: 0.6855402002111077 Scheduler time: 126.96496794419363 Scheduler overhead time: 0.08984147431328893 Adapter cache time: 0.02645644126459956 Engine time: 0.0904509536921978 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-16/adapters_256_slots_64_rate_0.8-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-16/adapters_256_slots_64_rate_0.8-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 8640, 135, 8640, 8640, 135, 8640, 270, 8640, 135, 270, 135, 8640, 270, 270, 270, 270, 8640, 135, 135, 135, 270, 8640, 135, 8640, 8640, 270, 270, 270, 135, 8640, 135, 270, 270, 135, 270, 135, 135, 270, 270, 8640, 270, 135, 270, 8640, 270, 270, 8640, 270, 8640, 135, 8640, 8640, 270, 135, 135, 8640, 270, 135, 270, 270, 8640, 270, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 8640, 8640, 135, 8640, 135, 270, 8640, 8640, 8640, 270, 135, 8640, 270, 135, 135, 135, 135, 135, 8640, 270, 135, 8640, 135, 8640, 135, 135, 270, 270, 8640, 270, 8640, 135, 270, 135, 8640, 8640, 135, 8640, 270, 135, 8640, 135, 135, 8640, 8640, 270, 8640, 8640, 135, 8640, 270, 270, 135, 270, 8640, 8640, 135, 8640, 270, 135, 270, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 270, 8640, 8640, 270, 135, 8640, 135, 270, 270, 135, 270, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 270, 8640, 270, 135, 270, 8640, 270, 8640, 135, 8640, 135, 270, 8640, 270, 8640, 270, 8640, 270, 8640, 270, 135, 8640, 135, 8640, 270, 270, 135, 270, 8640, 270, 270, 8640, 135, 8640, 8640, 270, 135, 8640, 8640, 270, 270, 8640, 8640, 270, 270, 270, 270, 8640, 8640, 270, 270, 8640, 135, 8640, 270, 8640, 8640, 135, 8640, 270, 270, 8640, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 8640, 270, 135, 135, 135, 135]
Prompts retrieved: 777465 . Total input tokens: 173287228 . Total output tokens: 155617124
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 126.0947380848229,
    "estimated_duration": 3600.1582943062003,
    "input_throughput": 6241.190570852423,
    "output_throughput": 5537.269578264963,
    "total_throughput": 11778.460149117385,
    "itl": 154.92163238401417,
    "ttft": 1688472.9059745069,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 526,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6475393983931226,
    "arrivals": 258949,
    "finished_requests": 90728,
    "scheduler_time": 156.11284106142867
}
#Debug simulation 
Total elapsed time: 126.09486431488767. Arrivals time: 0.6838822197169065 Scheduler time: 125.17660673009232 Scheduler overhead time: 0.09010539157316089 Adapter cache time: 0.026476576924324036 Engine time: 0.08992371195927262 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-32/adapters_256_slots_64_rate_0.8-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-32/adapters_256_slots_64_rate_0.8-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 8640, 135, 8640, 8640, 135, 8640, 270, 8640, 135, 270, 135, 8640, 270, 270, 270, 270, 8640, 135, 135, 135, 270, 8640, 135, 8640, 8640, 270, 270, 270, 135, 8640, 135, 270, 270, 135, 270, 135, 135, 270, 270, 8640, 270, 135, 270, 8640, 270, 270, 8640, 270, 8640, 135, 8640, 8640, 270, 135, 135, 8640, 270, 135, 270, 270, 8640, 270, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 8640, 8640, 135, 8640, 135, 270, 8640, 8640, 8640, 270, 135, 8640, 270, 135, 135, 135, 135, 135, 8640, 270, 135, 8640, 135, 8640, 135, 135, 270, 270, 8640, 270, 8640, 135, 270, 135, 8640, 8640, 135, 8640, 270, 135, 8640, 135, 135, 8640, 8640, 270, 8640, 8640, 135, 8640, 270, 270, 135, 270, 8640, 8640, 135, 8640, 270, 135, 270, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 270, 8640, 8640, 270, 135, 8640, 135, 270, 270, 135, 270, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 270, 8640, 270, 135, 270, 8640, 270, 8640, 135, 8640, 135, 270, 8640, 270, 8640, 270, 8640, 270, 8640, 270, 135, 8640, 135, 8640, 270, 270, 135, 270, 8640, 270, 270, 8640, 135, 8640, 8640, 270, 135, 8640, 8640, 270, 270, 8640, 8640, 270, 270, 270, 270, 8640, 8640, 270, 270, 8640, 135, 8640, 270, 8640, 8640, 135, 8640, 270, 270, 8640, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 8640, 270, 135, 135, 135, 135]
Prompts retrieved: 777465 . Total input tokens: 173287228 . Total output tokens: 155617124
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 126.28300161473453,
    "estimated_duration": 3600.065857511918,
    "input_throughput": 6240.569447673119,
    "output_throughput": 5536.76732285557,
    "total_throughput": 11777.336770528687,
    "itl": 154.92661066815154,
    "ttft": 1688473.3570160898,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 525,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7365476535260724,
    "arrivals": 258949,
    "finished_requests": 90724,
    "scheduler_time": 156.10449345626648
}
#Debug simulation 
Total elapsed time: 126.28314220486209. Arrivals time: 0.6785991787910461 Scheduler time: 125.37500950181857 Scheduler overhead time: 0.08829988352954388 Adapter cache time: 0.025828172452747822 Engine time: 0.08738926751539111 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-16/adapters_256_slots_64_rate_0.8-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-16/adapters_256_slots_64_rate_0.8-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 8640, 135, 8640, 8640, 135, 8640, 270, 8640, 135, 270, 135, 8640, 270, 270, 270, 270, 8640, 135, 135, 135, 270, 8640, 135, 8640, 8640, 270, 270, 270, 135, 8640, 135, 270, 270, 135, 270, 135, 135, 270, 270, 8640, 270, 135, 270, 8640, 270, 270, 8640, 270, 8640, 135, 8640, 8640, 270, 135, 135, 8640, 270, 135, 270, 270, 8640, 270, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 8640, 8640, 135, 8640, 135, 270, 8640, 8640, 8640, 270, 135, 8640, 270, 135, 135, 135, 135, 135, 8640, 270, 135, 8640, 135, 8640, 135, 135, 270, 270, 8640, 270, 8640, 135, 270, 135, 8640, 8640, 135, 8640, 270, 135, 8640, 135, 135, 8640, 8640, 270, 8640, 8640, 135, 8640, 270, 270, 135, 270, 8640, 8640, 135, 8640, 270, 135, 270, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 270, 8640, 8640, 270, 135, 8640, 135, 270, 270, 135, 270, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 270, 8640, 270, 135, 270, 8640, 270, 8640, 135, 8640, 135, 270, 8640, 270, 8640, 270, 8640, 270, 8640, 270, 135, 8640, 135, 8640, 270, 270, 135, 270, 8640, 270, 270, 8640, 135, 8640, 8640, 270, 135, 8640, 8640, 270, 270, 8640, 8640, 270, 270, 270, 270, 8640, 8640, 270, 270, 8640, 135, 8640, 270, 8640, 8640, 135, 8640, 270, 270, 8640, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 8640, 270, 135, 135, 135, 135]
Prompts retrieved: 777465 . Total input tokens: 173287228 . Total output tokens: 155617124
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 126.3366814777255,
    "estimated_duration": 3600.0448356847032,
    "input_throughput": 6241.185325606269,
    "output_throughput": 5537.536589098739,
    "total_throughput": 11778.721914705007,
    "itl": 154.91844889196457,
    "ttft": 1688487.3381848868,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 526,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5727664551185254,
    "arrivals": 258949,
    "finished_requests": 90727,
    "scheduler_time": 156.11092549623592
}
#Debug simulation 
Total elapsed time: 126.33681806502864. Arrivals time: 0.6849223864264786 Scheduler time: 125.41713750269264 Scheduler overhead time: 0.09143889555707574 Adapter cache time: 0.025533401407301426 Engine time: 0.08960760571062565 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-32/adapters_256_slots_64_rate_0.8-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-32/adapters_256_slots_64_rate_0.8-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 8640, 135, 8640, 8640, 135, 8640, 270, 8640, 135, 270, 135, 8640, 270, 270, 270, 270, 8640, 135, 135, 135, 270, 8640, 135, 8640, 8640, 270, 270, 270, 135, 8640, 135, 270, 270, 135, 270, 135, 135, 270, 270, 8640, 270, 135, 270, 8640, 270, 270, 8640, 270, 8640, 135, 8640, 8640, 270, 135, 135, 8640, 270, 135, 270, 270, 8640, 270, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 8640, 8640, 135, 8640, 135, 270, 8640, 8640, 8640, 270, 135, 8640, 270, 135, 135, 135, 135, 135, 8640, 270, 135, 8640, 135, 8640, 135, 135, 270, 270, 8640, 270, 8640, 135, 270, 135, 8640, 8640, 135, 8640, 270, 135, 8640, 135, 135, 8640, 8640, 270, 8640, 8640, 135, 8640, 270, 270, 135, 270, 8640, 8640, 135, 8640, 270, 135, 270, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 270, 8640, 8640, 270, 135, 8640, 135, 270, 270, 135, 270, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 270, 8640, 270, 135, 270, 8640, 270, 8640, 135, 8640, 135, 270, 8640, 270, 8640, 270, 8640, 270, 8640, 270, 135, 8640, 135, 8640, 270, 270, 135, 270, 8640, 270, 270, 8640, 135, 8640, 8640, 270, 135, 8640, 8640, 270, 270, 8640, 8640, 270, 270, 270, 270, 8640, 8640, 270, 270, 8640, 135, 8640, 270, 8640, 8640, 135, 8640, 270, 270, 8640, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 8640, 270, 135, 135, 135, 135]
Prompts retrieved: 777465 . Total input tokens: 173287228 . Total output tokens: 155617124
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 126.67315791593865,
    "estimated_duration": 3600.12564567322,
    "input_throughput": 6241.193005861967,
    "output_throughput": 5537.181743631134,
    "total_throughput": 11778.374749493101,
    "itl": 154.9229384645165,
    "ttft": 1688456.80275837,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 527,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7655218803510042,
    "arrivals": 258949,
    "finished_requests": 90730,
    "scheduler_time": 156.10855116308562
}
#Debug simulation 
Total elapsed time: 126.67328059393913. Arrivals time: 0.7013376597315073 Scheduler time: 125.73895116103813 Scheduler overhead time: 0.0895084603689611 Adapter cache time: 0.02657779259607196 Engine time: 0.08854061737656593 
