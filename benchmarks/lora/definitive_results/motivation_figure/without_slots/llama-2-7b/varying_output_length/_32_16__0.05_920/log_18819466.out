WARNING 04-09 14:01:48 _custom_ops.py:14] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
Namespace(backend='openai', base_url=None, host='localhost', port=17562, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/dummy_dataset_mean.json', model='/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-2-7b', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=4096, sharegpt_output_len=920, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, request_rate=inf, request_rate_by_lora=0.05, seed=0, trust_remote_code=False, disable_tqdm=True, save_result=True, metadata=None, result_dir='benchmarks/lora/definitive_results/model_without_offloading/example_maximum_variance/llama-2-7b/varying_output_length/_32_16__0.05_920', launch_server=True, server_args='--port=17562 --disable-log-requests --model=/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-2-7b --enable-lora --dummy-lora-modules=/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-2-7b/lora/yard1_sql-lora-test_dummy_rank_16/ --max-num-seqs=4096 --max-loras=32 --max-lora-rank=16', disable_log_stats=False, disable_loras_users=False, user_lora_request_relation=None, infinite_behaviour=True, restrict_loras=None, lora_pre_loading=False)
Server started
Requests users. Values: ['0' '1' '10' '11' '12' '13' '14' '15' '16' '17' '18' '19' '2' '20' '21'
 '22' '23' '24' '25' '26' '27' '28' '29' '3' '30' '31' '4' '5' '6' '7' '8'
 '9']. Counts: [128 128 128 128 128 128 128 128 128 128 128 128 128 128 128 128 128 128
 128 128 128 128 128 128 128 128 128 128 128 128 128 128]
Requests loras. Values: ['dummy-1' 'dummy-10' 'dummy-11' 'dummy-12' 'dummy-13' 'dummy-14'
 'dummy-15' 'dummy-16' 'dummy-17' 'dummy-18' 'dummy-19' 'dummy-2'
 'dummy-20' 'dummy-21' 'dummy-22' 'dummy-23' 'dummy-24' 'dummy-25'
 'dummy-26' 'dummy-27' 'dummy-28' 'dummy-29' 'dummy-3' 'dummy-30'
 'dummy-31' 'dummy-32' 'dummy-4' 'dummy-5' 'dummy-6' 'dummy-7' 'dummy-8'
 'dummy-9']. Counts: [128 128 128 128 128 128 128 128 128 128 128 128 128 128 128 128 128 128
 128 128 128 128 128 128 128 128 128 128 128 128 128 128]
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 1.6
===== Serving Benchmark Intermediate Result ======
Successful requests:                     3994      
Benchmark duration (s):                  2588.88   
Total input tokens:                      998500    
Total generated tokens:                  3678474   
Request throughput (req/s):              1.54      
Input token throughput (tok/s):          385.69    
Output token throughput (tok/s):         1420.88   
---------------Time to First Token----------------
Mean TTFT (ms):                          64530.20  
Median TTFT (ms):                        56.87     
P99 TTFT (ms):                           2588875.11
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          40.36     
Median TPOT (ms):                        39.89     
P99 TPOT (ms):                           58.60     
---------------Inter-token Latency----------------
Mean ITL (ms):                           40.40     
Median ITL (ms):                         37.42     
P99 ITL (ms):                            83.35     
==================================================
Concurrent checker terminated
Server terminated
