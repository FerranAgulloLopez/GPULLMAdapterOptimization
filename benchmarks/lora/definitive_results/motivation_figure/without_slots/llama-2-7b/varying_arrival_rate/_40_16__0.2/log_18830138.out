WARNING 04-09 17:29:29 _custom_ops.py:14] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
Namespace(backend='openai', base_url=None, host='localhost', port=8414, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path='/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/dummy_dataset_mean.json', model='/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-2-7b', tokenizer=None, best_of=1, use_beam_search=False, num_prompts=4096, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, request_rate=inf, request_rate_by_lora=0.2, seed=0, trust_remote_code=False, disable_tqdm=True, save_result=True, metadata=None, result_dir='benchmarks/lora/definitive_results/model_without_offloading/maximum_variation/llama-2-7b/varying_arrival_rate/_40_16__0.2', launch_server=True, server_args='--port=8414 --disable-log-requests --model=/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-2-7b --enable-lora --dummy-lora-modules=/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-2-7b/lora/yard1_sql-lora-test_dummy_rank_16/ --max-num-seqs=4096 --max-loras=40 --max-lora-rank=16', disable_log_stats=False, disable_loras_users=False, user_lora_request_relation=None, infinite_behaviour=True, restrict_loras=None, lora_pre_loading=False)
Server started
Requests users. Values: ['0' '1' '10' '11' '12' '13' '14' '15' '16' '17' '18' '19' '2' '20' '21'
 '22' '23' '24' '25' '26' '27' '28' '29' '3' '30' '31' '32' '33' '34' '35'
 '36' '37' '38' '39' '4' '5' '6' '7' '8' '9']. Counts: [103 103 103 103 103 103 103 103 102 102 102 102 103 102 102 102 102 102
 102 102 102 102 102 103 102 102 102 102 102 102 102 102 102 102 103 103
 103 103 103 103]
Requests loras. Values: ['dummy-1' 'dummy-10' 'dummy-11' 'dummy-12' 'dummy-13' 'dummy-14'
 'dummy-15' 'dummy-16' 'dummy-17' 'dummy-18' 'dummy-19' 'dummy-2'
 'dummy-20' 'dummy-21' 'dummy-22' 'dummy-23' 'dummy-24' 'dummy-25'
 'dummy-26' 'dummy-27' 'dummy-28' 'dummy-29' 'dummy-3' 'dummy-30'
 'dummy-31' 'dummy-32' 'dummy-33' 'dummy-34' 'dummy-35' 'dummy-36'
 'dummy-37' 'dummy-38' 'dummy-39' 'dummy-4' 'dummy-40' 'dummy-5' 'dummy-6'
 'dummy-7' 'dummy-8' 'dummy-9']. Counts: [103 103 103 103 103 103 103 103 102 102 102 103 102 102 102 102 102 102
 102 102 102 102 103 102 102 102 102 102 102 102 102 102 102 103 102 103
 103 103 103 103]
Starting initial single prompt test run...
Initial test run completed. Starting main benchmark run...
Traffic request rate: 8.0
===== Serving Benchmark Intermediate Result ======
Successful requests:                     3887      
Benchmark duration (s):                  520.27    
Total input tokens:                      971750    
Total generated tokens:                  897897    
Request throughput (req/s):              7.47      
Input token throughput (tok/s):          1867.77   
Output token throughput (tok/s):         1725.82   
---------------Time to First Token----------------
Mean TTFT (ms):                          26619.60  
Median TTFT (ms):                        65.74     
P99 TTFT (ms):                           520272.28 
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          59.72     
Median TPOT (ms):                        57.86     
P99 TPOT (ms):                           91.31     
---------------Inter-token Latency----------------
Mean ITL (ms):                           59.98     
Median ITL (ms):                         44.97     
P99 ITL (ms):                            208.45    
==================================================
Concurrent checker terminated
Server terminated
