PYTHONPATH=. python3 benchmarks/lora/deployment/slurm/launcher.py --user bsc98 --queue acc_debug --max-duration 00:15:00 --results-path benchmarks/lora/definitive_results/model_with_offloading/example_maximum_variance/llama-2-7b/loaded_adapters_without_offloading_rate_0.0125 --default-server-args "{'--disable-log-requests': '', '--model': '/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-2-7b', '--enable-lora': '', '--dummy-lora-modules': '/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-2-7b/lora/yard1_sql-lora-test_dummy_rank_16/', '--max-num-seqs': '4096'}" --default-benchmark-args "{'--backend': 'openai', '--dataset-path': '/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/dummy_dataset_mean.json', '--endpoint': '/v1/completions', '--model': '/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-2-7b', '--save-result': '', '--total-time': '300', '--adapter-rates': '0.0125'}" --test-server-args "{'--max-loras': ['12'], '--max-lora-rank': ['16']}" --test-benchmark-args "{}" --benchmark-executable benchmarks/lora/benchmark_serving_by_time.py
