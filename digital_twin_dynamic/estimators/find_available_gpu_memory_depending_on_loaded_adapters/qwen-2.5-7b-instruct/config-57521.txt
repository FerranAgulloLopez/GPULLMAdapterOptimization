PYTHONPATH=. python3 benchmarks/lora/deployment/slurm/launcher.py --user bsc98 --queue acc_bsccs --max-duration 00:25:00 --results-path benchmarks/lora/definitive_results/finding_maximum/check_available_gpu_memory/qwen-2.5-7b-instruct/ --default-server-args "{'--disable-log-stats': '', '--disable-log-requests': '', '--model': '/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct', '--enable-lora': '', '--max-num-seqs': '2048', '--scheduler-cls': 'vllm.v1.core.sched.scheduler.Scheduler', '--no-enable-prefix-caching': ''}" --default-benchmark-args "{'--disable-log-stats': '', '--disable-loras-users': '', '--disable-tqdm': '', '--backend': 'openai', '--dataset-path': '/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json', '--endpoint': '/v1/completions', '--model': '/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct', '--save-result': '', '--num-prompts': '1', '--server-init-time': '1800'}" --test-server-args "{'--max-loras': ['96', '160', '192', '224', '288', '352'], '--max-lora-rank': ['8', '16', '32']}" --test-benchmark-args "{}"
