{"date": "20250511-132624", "backend": "openai", "model_id": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct", "tokenizer_id": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct", "num_prompts": 4096, "request_rate": "inf", "start_time": 1038070.405230633, "end_time": 1038148.676936849, "duration": 78.27170621603727, "completed": 4096, "total_input_tokens": 20480, "total_output_tokens": 819200, "request_throughput": 52.330531657182156, "input_throughput": 261.6526582859108, "output_throughput": 10466.106331436431, "mean_ttft_ms": 37952.88602391344, "mean_ttfts_ms_by_lora": {"/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct": 37952.88602391344}, "mean_ttfts_ms_by_user": {"0": 37952.88602391344}, "median_ttft_ms": 38867.768038006034, "p99_ttft_ms": 73265.230762586, "mean_tpot_ms": 17.531631499157303, "median_tpot_ms": 17.68665769355063, "p99_tpot_ms": 17.757001685548396, "mean_itl_ms": 17.536623304733858, "median_itl_ms": 17.518592008855194, "p99_itl_ms": 21.79587980848738}