{"date": "20250529-164718", "backend": "openai", "model_id": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct", "tokenizer_id": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct", "num_prompts": 8192, "request_rate": "inf", "start_time": 2025445.184249313, "end_time": 2025490.099541029, "duration": 44.91529171587899, "completed": 8192, "total_input_tokens": 40960, "total_output_tokens": 819200, "request_throughput": 182.38777233865468, "input_throughput": 911.9388616932733, "output_throughput": 18238.77723386547, "mean_ttft_ms": 22722.417060724154, "mean_ttfts_ms_by_lora": {"/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct": 22722.417060724154}, "mean_ttfts_ms_by_user": {"0": 22722.417060724154}, "median_ttft_ms": 24011.22541294899, "p99_ttft_ms": 39743.92919817241, "mean_tpot_ms": 40.665938982188855, "median_tpot_ms": 41.71321105042642, "p99_tpot_ms": 45.38418017285453, "mean_itl_ms": 40.675619547735316, "median_itl_ms": 39.84757116995752, "p99_itl_ms": 188.60115817748004}