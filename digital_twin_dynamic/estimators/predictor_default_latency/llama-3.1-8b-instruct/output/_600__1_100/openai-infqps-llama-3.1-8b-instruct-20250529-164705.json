{"date": "20250529-164705", "backend": "openai", "model_id": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct", "tokenizer_id": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct", "num_prompts": 8192, "request_rate": "inf", "start_time": 2605032.787265677, "end_time": 2605084.643616147, "duration": 51.85635046986863, "completed": 8192, "total_input_tokens": 40960, "total_output_tokens": 819200, "request_throughput": 157.97486567744482, "input_throughput": 789.8743283872242, "output_throughput": 15797.486567744483, "mean_ttft_ms": 26863.42919292065, "mean_ttfts_ms_by_lora": {"/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct": 26863.42919292065}, "mean_ttfts_ms_by_user": {"0": 26863.42919292065}, "median_ttft_ms": 25815.392744727433, "p99_ttft_ms": 46235.21834787913, "mean_tpot_ms": 30.420796957729284, "median_tpot_ms": 30.783507384999535, "p99_tpot_ms": 36.78457357713746, "mean_itl_ms": 30.425599755851223, "median_itl_ms": 29.83348839916289, "p99_itl_ms": 46.562171038240194}