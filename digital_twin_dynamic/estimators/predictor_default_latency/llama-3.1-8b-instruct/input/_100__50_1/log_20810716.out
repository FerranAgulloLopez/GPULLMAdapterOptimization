INFO 05-11 13:22:30 [__init__.py:239] Automatically detected platform cuda.
Namespace(backend='openai', base_url=None, host='localhost', port=59475, endpoint='/v1/completions', dataset=None, dataset_name='sharegpt', dataset_path=None, model='/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct', tokenizer=None, num_prompts=4096, sharegpt_output_len=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, request_rate=inf, request_rate_by_lora=None, seed=0, trust_remote_code=False, disable_tqdm=True, save_result=True, metadata=None, result_dir='digital_twin_dynamic/estimators/predictor_default_latency/llama-3.1-8b/input/_100__50_1', launch_server=True, server_args='--port=59475 --disable-log-requests --model="/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct" --scheduler-cls="vllm.v1.core.sched.scheduler.Scheduler" --no-enable-prefix-caching --max-num-seqs=100', server_init_time=300, disable_log_stats=False, disable_loras_users=True, user_lora_request_relation=None, restrict_loras=None, lora_pre_loading=False, use_synthetic_dataset='/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/common_american_words.txt', synthetic_input_length=50, synthetic_output_length=1)
All available words: 63366
Generated prompt with 111 input length: Swoon harbored sewers trustee impedimenta armadillos drearier zeds mass lighted hording upon slumps subscribing extol laughing ghosted outskirts tumbrel unhooking deliriums malleability chocolates engendering choppered sequitur brainstormed photograph speaker divinities unkindlier missive reposeful stabilizing pastrami underclothing cleave fasting brilliant runny bestridden unbiassed tangy rebelled foci lagniappe nix brooder gayest infernos.
Server started
Starting initial single prompt test run for base model
Initial test run completed. Starting main benchmark run...
Traffic request rate: inf
============ Serving Benchmark Result ============
Successful requests:                     4096      
Benchmark duration (s):                  16.31     
Total input tokens:                      454656    
Total generated tokens:                  4096      
Request throughput (req/s):              251.07    
Input token throughput (tok/s):          27868.88  
Output token throughput (tok/s):         251.07    
---------------Time to First Token----------------
Mean TTFT (ms):                          9268.23   
Median TTFT (ms):                        9284.47   
P99 TTFT (ms):                           14363.45  
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          0.00      
Median TPOT (ms):                        0.00      
P99 TPOT (ms):                           0.00      
---------------Inter-token Latency----------------
Mean ITL (ms):                           0.00      
Median ITL (ms):                         0.00      
P99 ITL (ms):                            0.00      
==================================================
Concurrent checker terminated
Server terminated
