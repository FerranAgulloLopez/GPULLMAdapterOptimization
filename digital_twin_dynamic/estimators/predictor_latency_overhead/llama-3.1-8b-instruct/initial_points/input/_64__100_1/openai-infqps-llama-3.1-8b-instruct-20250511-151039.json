{"date": "20250511-151039", "backend": "openai", "model_id": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct", "tokenizer_id": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct", "num_prompts": 4096, "request_rate": "inf", "start_time": 1044637.884816263, "end_time": 1044665.390704655, "duration": 27.505888391984627, "completed": 4096, "total_input_tokens": 856064, "total_output_tokens": 4096, "request_throughput": 148.91356867402973, "input_throughput": 31122.935852872215, "output_throughput": 148.91356867402973, "mean_ttft_ms": 14958.686483483718, "mean_ttfts_ms_by_lora": {"/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct": 14958.686483483718}, "mean_ttfts_ms_by_user": {"0": 14958.686483483718}, "median_ttft_ms": 14957.946061505936, "p99_ttft_ms": 25290.5239775253, "mean_tpot_ms": 0.0, "median_tpot_ms": 0.0, "p99_tpot_ms": 0.0, "mean_itl_ms": 0.0, "median_itl_ms": 0.0, "p99_itl_ms": 0.0}