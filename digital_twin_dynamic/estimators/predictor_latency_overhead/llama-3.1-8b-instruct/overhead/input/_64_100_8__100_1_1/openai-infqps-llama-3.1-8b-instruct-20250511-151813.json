{"date": "20250511-151813", "backend": "openai", "model_id": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct", "tokenizer_id": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct", "num_prompts": 4096, "request_rate": "inf", "start_time": 1043863.773195617, "end_time": 1043915.526218582, "duration": 51.75302296492737, "completed": 4096, "total_input_tokens": 856064, "total_output_tokens": 4096, "request_throughput": 79.14513520834963, "input_throughput": 16541.333258545073, "output_throughput": 79.14513520834963, "mean_ttft_ms": 28330.810838733556, "mean_ttfts_ms_by_lora": {"dummy-38": 28330.810838733556}, "mean_ttfts_ms_by_user": {"0": 28330.810838733556}, "median_ttft_ms": 28324.274508515373, "p99_ttft_ms": 49300.79710140126, "mean_tpot_ms": 0.0, "median_tpot_ms": 0.0, "p99_tpot_ms": 0.0, "mean_itl_ms": 0.0, "median_itl_ms": 0.0, "p99_itl_ms": 0.0}