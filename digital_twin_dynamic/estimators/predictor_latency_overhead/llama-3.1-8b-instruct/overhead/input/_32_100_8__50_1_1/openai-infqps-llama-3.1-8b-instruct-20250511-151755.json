{"date": "20250511-151755", "backend": "openai", "model_id": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct", "tokenizer_id": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct", "num_prompts": 4096, "request_rate": "inf", "start_time": 196019.327121355, "end_time": 196048.070017599, "duration": 28.742896244017174, "completed": 4096, "total_input_tokens": 454656, "total_output_tokens": 4096, "request_throughput": 142.50477631851666, "input_throughput": 15818.030171355349, "output_throughput": 142.50477631851666, "mean_ttft_ms": 15792.988808548402, "mean_ttfts_ms_by_lora": {"dummy-30": 15792.988808548402}, "mean_ttfts_ms_by_user": {"0": 15792.988808548402}, "median_ttft_ms": 15751.683341004536, "p99_ttft_ms": 26768.53202195489, "mean_tpot_ms": 0.0, "median_tpot_ms": 0.0, "p99_tpot_ms": 0.0, "mean_itl_ms": 0.0, "median_itl_ms": 0.0, "p99_itl_ms": 0.0}