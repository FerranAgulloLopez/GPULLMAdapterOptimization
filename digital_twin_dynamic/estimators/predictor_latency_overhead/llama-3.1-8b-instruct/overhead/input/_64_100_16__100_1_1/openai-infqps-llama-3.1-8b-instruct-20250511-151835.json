{"date": "20250511-151835", "backend": "openai", "model_id": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct", "tokenizer_id": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct", "num_prompts": 4096, "request_rate": "inf", "start_time": 1043896.320531782, "end_time": 1043945.776877471, "duration": 49.456345689017326, "completed": 4096, "total_input_tokens": 856064, "total_output_tokens": 4096, "request_throughput": 82.82051459595792, "input_throughput": 17309.487550555205, "output_throughput": 82.82051459595792, "mean_ttft_ms": 25840.985211957304, "mean_ttfts_ms_by_lora": {"dummy-58": 25840.985211957304}, "mean_ttfts_ms_by_user": {"0": 25840.985211957304}, "median_ttft_ms": 25830.771441978868, "p99_ttft_ms": 47135.51196135231, "mean_tpot_ms": 0.0, "median_tpot_ms": 0.0, "p99_tpot_ms": 0.0, "mean_itl_ms": 0.0, "median_itl_ms": 0.0, "p99_itl_ms": 0.0}