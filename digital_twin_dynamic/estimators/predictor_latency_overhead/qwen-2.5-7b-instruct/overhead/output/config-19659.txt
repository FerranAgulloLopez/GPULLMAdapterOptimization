PYTHONPATH=. python3 benchmarks/lora/deployment/slurm/launcher.py --user bsc98 --queue acc_bsccs --max-duration 02:45:00 --results-path digital_twin_dynamic/estimators/predictor_latency_overhead/qwen-2.5-7b-instruct/overhead/output --default-server-args "{'--disable-log-requests': '', '--model': '/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct',  '--enable-lora': '', '--dummy-lora-modules': '/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct/lora/lora-medical_dummy_rank_32', '--scheduler-cls': 'vllm.v1.core.sched.scheduler.Scheduler', '--no-enable-prefix-caching': ''}" --default-benchmark-args "{'--backend': 'openai', '--disable-tqdm': '', '--use-synthetic-dataset': '/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/common_american_words.txt', '--endpoint': '/v1/completions', '--model': '/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct', '--num-prompts': '4096', '--save-result': '', '--lora-pre-loading': '', '--server-init-time': '900'}" --test-server-args "{'--max-num-seqs': ['32', '64', '96'], '--max-loras': ['100'], '--max-lora-rank': ['32']}" --test-benchmark-args "{'--synthetic-input-length': ['1'], '--synthetic-output-length': ['100'], '--restrict-loras': ['1', '32', '64', '96']}"
